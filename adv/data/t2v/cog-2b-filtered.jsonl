{"id": "a416b7de9fd64040930c56e0673fffa4", "source": "vatex", "video_id": "HJyq6PywM3U_000098_000108", "video_description": "A woman is demonstrating how to clean a toilet using a toilet brush and cleaning solution in a bathroom.", "task": "ActionRecognition", "clean_prompt": "A person cleaning a toilet in a bathroom.", "clean_property": {"obj": "person", "action": "cleaning toilet", "target": null}, "target_prompt": "A person cleaning the floor in a bathroom.", "target_property": {"obj": "person", "action": "cleaning floor", "target": null}, "evaluation_question": "Is the person **cleaning the toilet**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person cleaning a toilet in a bathroom. superbe gemachtktuellzieht aufzu", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e6e879f4181a4c379c50fe875f641109.mp4", "clean_score": 1.0, "clean_xclip": 0.2190839946269989, "clean_vbench": {"subject_consistency": 0.8972546470661958, "background_consistency": 0.919036865234375, "motion_smoothness": 0.970843344970447, "aesthetic_quality": 0.4418039917945862, "imaging_quality": 0.6139628756776148, "dynamic_degree": 1.0}, "adv_vid_id": "vids/148862072cea47069756af96bb7956c0.mp4", "adv_score": 0.0, "adv_xclip": 0.18680575489997864, "adv_vbench": {"subject_consistency": 0.9572343844920397, "background_consistency": 0.9507242838541666, "motion_smoothness": 0.9782490167395405, "aesthetic_quality": 0.4987676739692688, "imaging_quality": 0.6316405759538923, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ac19c793.mp4", "clean_score": 1.0, "clean_xclip": 0.24883341789245605, "clean_vbench": {}, "adv_vid_id": "vids/707189ea.mp4", "adv_score": 1.0, "adv_xclip": 0.24778972566127777, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2a9e2fb9.mp4", "clean_score": 1.0, "clean_xclip": 0.2471216320991516, "clean_vbench": {}, "adv_vid_id": "vids/ef524574.mp4", "adv_score": 1.0, "adv_xclip": 0.23342007398605347, "adv_vbench": {}}}}
{"id": "3153b91b171c41bda85afb5202d55385", "source": "vatex", "video_id": "6LRgQW0n2LA_000065_000075", "video_description": "A person is carving letters into a wooden board using precision tools, while an announcer describes the process.", "task": "Counting", "clean_prompt": "A person is carving letters into a wooden board with seven precision tools, while an announcer describes the process.", "clean_property": {"obj": "wooden board", "count": "seven"}, "target_prompt": "A person is carving letters into a wooden board with three precision tools, while an announcer describes the process.", "target_property": {"obj": "wooden board", "count": "three"}, "evaluation_question": "Are there exactly **seven** precision tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is carving letters into a wooden board with seven precision tools, while an announcer describes the process. FE|)L", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/30cc54e554b941a680e31b5da4e4dd6a.mp4", "clean_score": 1.0, "clean_xclip": 0.09940578788518906, "clean_vbench": {"subject_consistency": 0.9742887013902267, "background_consistency": 0.95806884765625, "motion_smoothness": 0.9690589319575567, "aesthetic_quality": 0.3429228365421295, "imaging_quality": 0.610989374433245, "dynamic_degree": 1.0}, "adv_vid_id": "vids/84bee198456843019133ce859eab383c.mp4", "adv_score": 0.0, "adv_xclip": 0.1055685505270958, "adv_vbench": {"subject_consistency": 0.97998664714396, "background_consistency": 0.9654947916666666, "motion_smoothness": 0.9733104838353809, "aesthetic_quality": 0.36473745107650757, "imaging_quality": 0.6567813554102061, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f1677842.mp4", "clean_score": 0.0, "clean_xclip": 0.21241113543510437, "clean_vbench": {}, "adv_vid_id": "vids/37b86aa1.mp4", "adv_score": 0.0, "adv_xclip": 0.19771277904510498, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7f778a72.mp4", "clean_score": 0.0, "clean_xclip": 0.1264389306306839, "clean_vbench": {}, "adv_vid_id": "vids/700f2559.mp4", "adv_score": 0.0, "adv_xclip": 0.12698346376419067, "adv_vbench": {}}}}
{"id": "b8bcb22bb0f248d18afe798657989dbe", "source": "vatex", "video_id": "wPUeRxWYMPE_000050_000060", "video_description": "A doctor is demonstrating and explaining how to bandage a young man's head.", "task": "AttributeRecognition", "clean_prompt": "A doctor is demonstrating how to bandage a young man's head using a plastic bandage.", "clean_property": {"obj": "bandage", "attribute": "plastic"}, "target_prompt": "A doctor is demonstrating how to bandage a young man's head using a cloth bandage.", "target_property": {"obj": "bandage", "attribute": "cloth"}, "evaluation_question": "Is the bandage being used **plastic**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A doctor is demonstrating how to bandage a young man's head using a plastic bandage.   partial cr 800-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a2d0470244d4e1b8ab7d6a204fb52ed.mp4", "clean_score": 1.0, "clean_xclip": 0.18342892825603485, "clean_vbench": {"subject_consistency": 0.9666429882248243, "background_consistency": 0.980621337890625, "motion_smoothness": 0.9818934433437727, "aesthetic_quality": 0.5989212989807129, "imaging_quality": 0.7058567810058594, "dynamic_degree": 1.0}, "adv_vid_id": "vids/49846515c5ec43e6b34e2a0e39c023d4.mp4", "adv_score": 0.0, "adv_xclip": 0.20822188258171082, "adv_vbench": {"subject_consistency": 0.9482963532209396, "background_consistency": 0.9653981526692709, "motion_smoothness": 0.9791934301369725, "aesthetic_quality": 0.5363052487373352, "imaging_quality": 0.7180419485909598, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8b90c138.mp4", "clean_score": 0.0, "clean_xclip": 0.12075826525688171, "clean_vbench": {}, "adv_vid_id": "vids/4721af87.mp4", "adv_score": 0.0, "adv_xclip": 0.14127269387245178, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4039c36c.mp4", "clean_score": 0.0, "clean_xclip": 0.19616279006004333, "clean_vbench": {}, "adv_vid_id": "vids/73acbc7f.mp4", "adv_score": 0.0, "adv_xclip": 0.22427651286125183, "adv_vbench": {}}}}
{"id": "bbee5f3cafd8465a89c054337ab8d07d", "source": "vatex", "video_id": "eAz-jW31Iq8_000205_000215", "video_description": "A man is demonstrating how to shuffle a deck of cards on a table, occasionally chatting with another man.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a table demonstrating how to shuffle a deck of cards.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "table"}, "target_prompt": "A person beside a table demonstrating how to shuffle a deck of cards.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "table"}, "evaluation_question": "Is the person **above** the table?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person above a table demonstrating how to shuffle a deck of cards. ))!%-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d43a9a373d734e0dae0094b73ec2c206.mp4", "clean_score": 1.0, "clean_xclip": 0.19836539030075073, "clean_vbench": {"subject_consistency": 0.8425161074846983, "background_consistency": 0.9258015950520834, "motion_smoothness": 0.9324770001525559, "aesthetic_quality": 0.35241609811782837, "imaging_quality": 0.38997966299251635, "dynamic_degree": 1.0}, "adv_vid_id": "vids/61add3d073c34118bafc2057b5c3761d.mp4", "adv_score": 0.0, "adv_xclip": 0.1867777407169342, "adv_vbench": {"subject_consistency": 0.7590493789563576, "background_consistency": 0.8784128824869791, "motion_smoothness": 0.9407012029220124, "aesthetic_quality": 0.3430035710334778, "imaging_quality": 0.4475397900172642, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2f3fd2b3.mp4", "clean_score": 0.0, "clean_xclip": 0.19774816930294037, "clean_vbench": {}, "adv_vid_id": "vids/a017ed8d.mp4", "adv_score": 0.0, "adv_xclip": 0.15334109961986542, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/22166d68.mp4", "clean_score": 1.0, "clean_xclip": 0.18304263055324554, "clean_vbench": {}, "adv_vid_id": "vids/6304392b.mp4", "adv_score": 0.0, "adv_xclip": 0.18789677321910858, "adv_vbench": {}}}}
{"id": "fbe9a2f5d0f943e8a9fa2058d6cdfd25", "source": "vatex", "video_id": "jIBunMqpvcs_000346_000356", "video_description": "A woman and a boy are setting a dining table by placing drinking glasses upside down at each place setting.", "task": "Counting", "clean_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman setting a dining table by placing drinking glasses upside down at each place setting.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women setting the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting. )!0DK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1eba90fc4f644cb29982592b360bf147.mp4", "clean_score": 1.0, "clean_xclip": 0.23553188145160675, "clean_vbench": {"subject_consistency": 0.9689091139783462, "background_consistency": 0.9530080159505209, "motion_smoothness": 0.9836039430336178, "aesthetic_quality": 0.48566821217536926, "imaging_quality": 0.7002152680377571, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7a8862db80bc41808ac5b00cc1826f25.mp4", "adv_score": 0.0, "adv_xclip": 0.19555361568927765, "adv_vbench": {"subject_consistency": 0.9746629608174165, "background_consistency": 0.9486846923828125, "motion_smoothness": 0.9852071470853002, "aesthetic_quality": 0.5007456541061401, "imaging_quality": 0.6173669799493284, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/32b31401.mp4", "clean_score": 0.0, "clean_xclip": 0.24277061223983765, "clean_vbench": {}, "adv_vid_id": "vids/87bf1b12.mp4", "adv_score": 1.0, "adv_xclip": 0.20811186730861664, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f44e3f3e.mp4", "clean_score": 1.0, "clean_xclip": 0.1993853747844696, "clean_vbench": {}, "adv_vid_id": "vids/731c589f.mp4", "adv_score": 1.0, "adv_xclip": 0.17167875170707703, "adv_vbench": {}}}}
{"id": "1293d3c8324f466589066209d22f3ea0", "source": "vatex", "video_id": "4UDnIHZjJeI_000323_000333", "video_description": "A man is shaving a woman's head bald using a razor and shaving cream. The woman is happy and looks into the camera while the man, wearing a Planet Hollywood shirt, talks about the process.", "task": "ActionRecognition", "clean_prompt": "A man shaving a woman's head bald using a razor and shaving cream.", "clean_property": {"obj": "man", "action": "shaving head", "target": "woman"}, "target_prompt": "A man shaving another man's head bald using a razor and shaving cream.", "target_property": {"obj": "man", "action": "shaving head", "target": "man"}, "evaluation_question": "Is the man **shaving a woman's head**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man shaving a woman's head bald using a razor and shaving cream. ~H$SV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/02cf68db1ae744258de3951919653c7f.mp4", "clean_score": 1.0, "clean_xclip": 0.24292221665382385, "clean_vbench": {"subject_consistency": 0.9181712282200655, "background_consistency": 0.9526926676432291, "motion_smoothness": 0.9738510452599249, "aesthetic_quality": 0.47354862093925476, "imaging_quality": 0.6811002357638613, "dynamic_degree": 1.0}, "adv_vid_id": "vids/701b3469a2004cc7a2265829fcf35b5f.mp4", "adv_score": 0.0, "adv_xclip": 0.21870382130146027, "adv_vbench": {"subject_consistency": 0.9295724456508955, "background_consistency": 0.9552256266276041, "motion_smoothness": 0.9710421019552369, "aesthetic_quality": 0.4411125183105469, "imaging_quality": 0.6958638934699856, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/36324f70.mp4", "clean_score": 0.0, "clean_xclip": 0.11558105051517487, "clean_vbench": {}, "adv_vid_id": "vids/351691e2.mp4", "adv_score": 0.0, "adv_xclip": 0.13829092681407928, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a07d70e6.mp4", "clean_score": 1.0, "clean_xclip": 0.2355922907590866, "clean_vbench": {}, "adv_vid_id": "vids/d717acc3.mp4", "adv_score": 1.0, "adv_xclip": 0.24005764722824097, "adv_vbench": {}}}}
{"id": "6e477cb7e9ca4105bf36cc2c32ebe4b7", "source": "vatex", "video_id": "TtHPzsTmMHU_000000_000010", "video_description": "A man and a woman are arranging flowers in a warehouse. The man is creating floral displays and bouquets, while the woman assists by unwrapping flowers.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse.", "clean_property": {"obj_1": "flowers", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A woman standing to the left of a bouquet of flowers in a warehouse.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "flowers"}, "evaluation_question": "Is the woman to the **right** of the bouquet of flowers?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse.Enhanced spehnenbesuchArrangement", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f0b6abab60c48538955a2ee5790659e.mp4", "clean_score": 1.0, "clean_xclip": 0.2491762638092041, "clean_vbench": {"subject_consistency": 0.983472378924489, "background_consistency": 0.9423472086588541, "motion_smoothness": 0.9864714033375696, "aesthetic_quality": 0.5638502240180969, "imaging_quality": 0.716396257828693, "dynamic_degree": 0.0}, "adv_vid_id": "vids/02c92dd44f2a4fc5b520eef2cd159cbd.mp4", "adv_score": 0.0, "adv_xclip": 0.26958584785461426, "adv_vbench": {"subject_consistency": 0.9705878918369611, "background_consistency": 0.9491424560546875, "motion_smoothness": 0.9903404084273885, "aesthetic_quality": 0.4621151387691498, "imaging_quality": 0.7875741047761877, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3e4662ae.mp4", "clean_score": 0.0, "clean_xclip": 0.24630817770957947, "clean_vbench": {}, "adv_vid_id": "vids/620bd37e.mp4", "adv_score": 0.0, "adv_xclip": 0.2740950584411621, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/65155ba1.mp4", "clean_score": 0.0, "clean_xclip": 0.2539077699184418, "clean_vbench": {}, "adv_vid_id": "vids/a49e7dd1.mp4", "adv_score": 1.0, "adv_xclip": 0.2905935049057007, "adv_vbench": {}}}}
{"id": "c4bc67b0f38440608be6a87b255ee348", "source": "vatex", "video_id": "7Jz__8pemqw_000001_000011", "video_description": "A person is playing a video game set in medieval times, using a yellow controller in front of a television screen.", "task": "AttributeRecognition", "clean_prompt": "A person playing a video game set in a medieval setting using a yellow controller in front of a television screen.", "clean_property": {"obj": "video game", "attribute": "medieval setting"}, "target_prompt": "A person playing a video game set in a futuristic setting using a yellow controller in front of a television screen.", "target_property": {"obj": "video game", "attribute": "futuristic setting"}, "evaluation_question": "Is the video game set in a **medieval** setting?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing a video game set in a medieval setting using a yellow controller in front of a television screen. gratuiteflipped Sammlung Oferttorilor", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c1f8ea6599914bc2ba4cbba06a2e5f17.mp4", "clean_score": 1.0, "clean_xclip": 0.23166874051094055, "clean_vbench": {"subject_consistency": 0.9048769734799862, "background_consistency": 0.94940185546875, "motion_smoothness": 0.9728830574089203, "aesthetic_quality": 0.38492196798324585, "imaging_quality": 0.504068984206842, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a44806cec4c54227bcfe6cab4e0907be.mp4", "adv_score": 0.0, "adv_xclip": 0.2525438964366913, "adv_vbench": {"subject_consistency": 0.948648426681757, "background_consistency": 0.9400126139322916, "motion_smoothness": 0.9293426953471718, "aesthetic_quality": 0.35272839665412903, "imaging_quality": 0.5996620435130839, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/52d81c8a.mp4", "clean_score": 1.0, "clean_xclip": 0.21823975443840027, "clean_vbench": {}, "adv_vid_id": "vids/b4b5382a.mp4", "adv_score": 1.0, "adv_xclip": 0.23444457352161407, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3def8b7c.mp4", "clean_score": 1.0, "clean_xclip": 0.2260269820690155, "clean_vbench": {}, "adv_vid_id": "vids/f13306e7.mp4", "adv_score": 0.0, "adv_xclip": 0.22691650688648224, "adv_vbench": {}}}}
{"id": "5565beb58afa4031bc62fae5e6d5c6ee", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "ActionRecognition", "clean_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "clean_property": {"obj": "person", "action": "playing laser tag", "target": null}, "target_prompt": "A person watching a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "target_property": {"obj": "person", "action": "watching a laser tag game", "target": null}, "evaluation_question": "Is the person **playing** laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain. =|R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a80f0a90696145009deeb01ae81037a0.mp4", "clean_score": 1.0, "clean_xclip": 0.24105766415596008, "clean_vbench": {"subject_consistency": 0.927732652053237, "background_consistency": 0.9335784912109375, "motion_smoothness": 0.9521597340421508, "aesthetic_quality": 0.34579282999038696, "imaging_quality": 0.6296553514441665, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d1cee0e456574a328ad66b3a40dad505.mp4", "adv_score": 0.0, "adv_xclip": 0.22489584982395172, "adv_vbench": {"subject_consistency": 0.8862859718501568, "background_consistency": 0.9187723795572916, "motion_smoothness": 0.9349373925174493, "aesthetic_quality": 0.3817567527294159, "imaging_quality": 0.731837571591747, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2a243177.mp4", "clean_score": 1.0, "clean_xclip": 0.20918722450733185, "clean_vbench": {}, "adv_vid_id": "vids/26e957d8.mp4", "adv_score": 1.0, "adv_xclip": 0.21656261384487152, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fb7b8b29.mp4", "clean_score": 1.0, "clean_xclip": 0.21237359941005707, "clean_vbench": {}, "adv_vid_id": "vids/89c48263.mp4", "adv_score": 1.0, "adv_xclip": 0.226655513048172, "adv_vbench": {}}}}
{"id": "81b92e0dfe524b1c9833d69e0ea9615e", "source": "vatex", "video_id": "0cmkVC2QT5Q_000031_000041", "video_description": "A young man is sitting in a chair getting his eyebrows waxed and makeup applied by a beautician in a salon setting.", "task": "ActionRecognition", "clean_prompt": "A beautician waxing eyebrows on a young man in a salon.", "clean_property": {"obj": "beautician", "action": "waxing eyebrows", "target": "young man"}, "target_prompt": "A beautician applying makeup on a young man in a salon.", "target_property": {"obj": "beautician", "action": "applying makeup", "target": "young man"}, "evaluation_question": "Is the beautician **waxing eyebrows**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A beautician waxing eyebrows on a young man in a salon. 2SBS@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7642c9e784714fc9a7d8eb08b52af4f5.mp4", "clean_score": 1.0, "clean_xclip": 0.22029827535152435, "clean_vbench": {"subject_consistency": 0.9608622118830681, "background_consistency": 0.9777679443359375, "motion_smoothness": 0.9771301935190229, "aesthetic_quality": 0.5301492214202881, "imaging_quality": 0.7365862492152623, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f1fb863bf0ae4809b5e8a3b1f6991416.mp4", "adv_score": 0.0, "adv_xclip": 0.22076958417892456, "adv_vbench": {"subject_consistency": 0.9651204161345959, "background_consistency": 0.9774831136067709, "motion_smoothness": 0.9768130054201465, "aesthetic_quality": 0.48477455973625183, "imaging_quality": 0.7399813780492666, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/57d1e2e2.mp4", "clean_score": 0.0, "clean_xclip": 0.1581047922372818, "clean_vbench": {}, "adv_vid_id": "vids/830460bd.mp4", "adv_score": 1.0, "adv_xclip": 0.19355615973472595, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/19abaf6c.mp4", "clean_score": 0.0, "clean_xclip": 0.18713943660259247, "clean_vbench": {}, "adv_vid_id": "vids/9709b57f.mp4", "adv_score": 0.0, "adv_xclip": 0.16022254526615143, "adv_vbench": {}}}}
{"id": "a66b98e9ceed4e7ca7067983e9a6552f", "source": "vatex", "video_id": "z-KDduwJNOU_000012_000022", "video_description": "A person, sometimes identified as a child or young woman, is sitting on the floor with their feet in an electric foot massager, laughing uncontrollably as the machine tickles their feet.", "task": "Counting", "clean_prompt": "A child sitting on the floor with three foot massagers, laughing uncontrollably as they enjoy the tickling sensation.", "clean_property": {"obj": "foot massager", "count": "three"}, "target_prompt": "A child sitting on the floor with one foot massager, laughing uncontrollably as they enjoy the tickling sensation.", "target_property": {"obj": "foot massager", "count": "one"}, "evaluation_question": "Are there exactly **three** foot massagers present?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child sitting on the floor with three foot massagers, laughing uncontrollably as they enjoy the tickling sensation. 2BC1%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46e984d8a524456e89d7c757b54db483.mp4", "clean_score": 1.0, "clean_xclip": 0.2448597550392151, "clean_vbench": {"subject_consistency": 0.941870857651035, "background_consistency": 0.943572998046875, "motion_smoothness": 0.9651796285579561, "aesthetic_quality": 0.45257848501205444, "imaging_quality": 0.6529282651628766, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2c27f7901cfb444cb7721c59cf26487f.mp4", "adv_score": 0.0, "adv_xclip": 0.24100328981876373, "adv_vbench": {"subject_consistency": 0.9167225565761328, "background_consistency": 0.9052174886067709, "motion_smoothness": 0.9677930061009743, "aesthetic_quality": 0.445110946893692, "imaging_quality": 0.5881479769336935, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9c05146e.mp4", "clean_score": 0.0, "clean_xclip": 0.27519696950912476, "clean_vbench": {}, "adv_vid_id": "vids/67769b77.mp4", "adv_score": 0.0, "adv_xclip": 0.23383809626102448, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bd7de571.mp4", "clean_score": 0.0, "clean_xclip": 0.2519383430480957, "clean_vbench": {}, "adv_vid_id": "vids/2c367f43.mp4", "adv_score": 1.0, "adv_xclip": 0.2406398355960846, "adv_vbench": {}}}}
{"id": "b9d4f1df557f43508edfe6c5060a61c3", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "ActionRecognition", "clean_prompt": "A girl sneezing while lying down.", "clean_property": {"obj": "girl", "action": "sneezing", "target": null}, "target_prompt": "A girl laughing while lying down.", "target_property": {"obj": "girl", "action": "laughing", "target": null}, "evaluation_question": "Is the girl **sneezing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A girl sneezing while lying down. SP@MT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11bb1ffa0c7942399ef637bf216eccb4.mp4", "clean_score": 1.0, "clean_xclip": 0.1611177921295166, "clean_vbench": {"subject_consistency": 0.9702305309474468, "background_consistency": 0.9700266520182291, "motion_smoothness": 0.9939831537649783, "aesthetic_quality": 0.5078346133232117, "imaging_quality": 0.7044142174234196, "dynamic_degree": 0.0}, "adv_vid_id": "vids/fe47bbf1fa27471ab8d3e50b61c91108.mp4", "adv_score": 0.0, "adv_xclip": 0.18971391022205353, "adv_vbench": {"subject_consistency": 0.9315450868258873, "background_consistency": 0.9669850667317709, "motion_smoothness": 0.9902469099554688, "aesthetic_quality": 0.5148114562034607, "imaging_quality": 0.7183737556301817, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/888ae417.mp4", "clean_score": 0.0, "clean_xclip": 0.17370304465293884, "clean_vbench": {}, "adv_vid_id": "vids/0cad5418.mp4", "adv_score": 0.0, "adv_xclip": 0.22620269656181335, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/051e40e3.mp4", "clean_score": 0.0, "clean_xclip": 0.17120136320590973, "clean_vbench": {}, "adv_vid_id": "vids/9675dabc.mp4", "adv_score": 0.0, "adv_xclip": 0.19344064593315125, "adv_vbench": {}}}}
{"id": "58faaf445d4242c8b3ed364ea51c34d6", "source": "vatex", "video_id": "PetC18IbTtQ_000155_000165", "video_description": "A choir of African American men and women sing gospel songs enthusiastically in a church, led by a pastor. They sway, clap, and sing hymns during a service.", "task": "SpatialUnderstanding", "clean_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically.", "clean_property": {"obj_1": "choir", "relation": "left of", "obj_2": "pastor"}, "target_prompt": "A choir to the right of a pastor in a church, singing gospel songs enthusiastically.", "target_property": {"obj_1": "choir", "relation": "right of", "obj_2": "pastor"}, "evaluation_question": "Is the choir to the **left** of the pastor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically. X$B$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/85b755a51ece433e9fbd625eef0b83de.mp4", "clean_score": 1.0, "clean_xclip": 0.16354867815971375, "clean_vbench": {"subject_consistency": 0.9447596607108911, "background_consistency": 0.9476064046223959, "motion_smoothness": 0.961755214164498, "aesthetic_quality": 0.52422034740448, "imaging_quality": 0.4576585754083128, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7b2a1c4dbae446dbbdf4a09f89ba55cc.mp4", "adv_score": 0.0, "adv_xclip": 0.19535213708877563, "adv_vbench": {"subject_consistency": 0.9330122253547112, "background_consistency": 0.9264882405598959, "motion_smoothness": 0.9652065474209232, "aesthetic_quality": 0.5701290965080261, "imaging_quality": 0.5070064529107542, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1276773d.mp4", "clean_score": 1.0, "clean_xclip": 0.1851162165403366, "clean_vbench": {}, "adv_vid_id": "vids/0852a622.mp4", "adv_score": 1.0, "adv_xclip": 0.1550767719745636, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a3edf89c.mp4", "clean_score": 1.0, "clean_xclip": 0.20288175344467163, "clean_vbench": {}, "adv_vid_id": "vids/8f399f04.mp4", "adv_score": 1.0, "adv_xclip": 0.1776839941740036, "adv_vbench": {}}}}
{"id": "793ade5dbccb4c80baa4fa6dd00b2770", "source": "vatex", "video_id": "8AKP9U_RRfc_000028_000038", "video_description": "A man in a blue shirt is cleaning a window pane using a squeegee inside a room.", "task": "ActionRecognition", "clean_prompt": "A person cleaning windows inside a room.", "clean_property": {"obj": "person", "action": "cleaning windows", "target": null}, "target_prompt": "A person breaking windows inside a room.", "target_property": {"obj": "person", "action": "breaking windows", "target": null}, "evaluation_question": "Is the person **cleaning** windows?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person cleaning windows inside a room.erung einzigartig brutalvoller motorist", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8fa88e3175644403b4532fb2ce8738a7.mp4", "clean_score": 1.0, "clean_xclip": 0.2272692769765854, "clean_vbench": {"subject_consistency": 0.9321110645929972, "background_consistency": 0.9356231689453125, "motion_smoothness": 0.9798298311672919, "aesthetic_quality": 0.4281407594680786, "imaging_quality": 0.5891740067151128, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ac9ead09c39c4cfaa59021a43e18e660.mp4", "adv_score": 0.0, "adv_xclip": 0.24225425720214844, "adv_vbench": {"subject_consistency": 0.9777438410868248, "background_consistency": 0.9599253336588541, "motion_smoothness": 0.9969625960723796, "aesthetic_quality": 0.3510284423828125, "imaging_quality": 0.33567689272822165, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/38af40f7.mp4", "clean_score": 1.0, "clean_xclip": 0.24161508679389954, "clean_vbench": {}, "adv_vid_id": "vids/d7f8cfef.mp4", "adv_score": 1.0, "adv_xclip": 0.24440018832683563, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/00969841.mp4", "clean_score": 1.0, "clean_xclip": 0.24912261962890625, "clean_vbench": {}, "adv_vid_id": "vids/3ded42b5.mp4", "adv_score": 1.0, "adv_xclip": 0.24460837244987488, "adv_vbench": {}}}}
{"id": "5925d0188edc4a5e8b060d390a9bfac3", "source": "vatex", "video_id": "51v-7Xxpy30_000066_000076", "video_description": "A man demonstrates how to unfold and ride a folding bike, explaining its benefits and features.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrates how to unfold and ride a bike with an adjustable seat, explaining its benefits and features.", "clean_property": {"obj": "bike", "attribute": "adjustable"}, "target_prompt": "A man demonstrates how to unfold and ride a bike with a fixed seat, explaining its benefits and features.", "target_property": {"obj": "bike", "attribute": "fixed seat"}, "evaluation_question": "Does the bike have an **adjustable** seat?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man demonstrates how to unfold and ride a bike with an adjustable seat, explaining its benefits and features. )'K*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78269c5ce26c4c718bbf3b5acf871c52.mp4", "clean_score": 1.0, "clean_xclip": 0.11884141713380814, "clean_vbench": {"subject_consistency": 0.9627889599651098, "background_consistency": 0.9528299967447916, "motion_smoothness": 0.9634455402306241, "aesthetic_quality": 0.487066388130188, "imaging_quality": 0.636053730711645, "dynamic_degree": 1.0}, "adv_vid_id": "vids/98c63c4e77014edca6d5da7a717aa3d3.mp4", "adv_score": 0.0, "adv_xclip": 0.14723451435565948, "adv_vbench": {"subject_consistency": 0.95027523736159, "background_consistency": 0.9499460856119791, "motion_smoothness": 0.9523604529774874, "aesthetic_quality": 0.5026471614837646, "imaging_quality": 0.6907675521227779, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/057184b2.mp4", "clean_score": 0.0, "clean_xclip": 0.19010962545871735, "clean_vbench": {}, "adv_vid_id": "vids/915ae8c8.mp4", "adv_score": 0.0, "adv_xclip": 0.2021615356206894, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1c45c27e.mp4", "clean_score": 1.0, "clean_xclip": 0.1735350638628006, "clean_vbench": {}, "adv_vid_id": "vids/60e7fb0b.mp4", "adv_score": 1.0, "adv_xclip": 0.20991085469722748, "adv_vbench": {}}}}
{"id": "edafcfa33f3143a58e95a507b84d44d9", "source": "vatex", "video_id": "eigyV8fkc0Q_000005_000015", "video_description": "A person is placing squares of food onto a conveyor belt, which moves through a machine that shrink-wraps each item in plastic.", "task": "AttributeRecognition", "clean_prompt": "A person is placing squares of food onto a conveyor belt.", "clean_property": {"obj": "food", "attribute": "square"}, "target_prompt": "A person is placing circles of food onto a conveyor belt.", "target_property": {"obj": "food", "attribute": "circular"}, "evaluation_question": "Are the pieces of food **square**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person is placing squares of food onto a conveyor belt. ;93,R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9677ea41109c4b7fb51a105a1207aedd.mp4", "clean_score": 1.0, "clean_xclip": 0.11257892847061157, "clean_vbench": {"subject_consistency": 0.9656358708937963, "background_consistency": 0.96295166015625, "motion_smoothness": 0.9615471068281993, "aesthetic_quality": 0.47964414954185486, "imaging_quality": 0.34685364625891857, "dynamic_degree": 1.0}, "adv_vid_id": "vids/21c66bb1051f412f817105551cd49d33.mp4", "adv_score": 0.0, "adv_xclip": 0.13871031999588013, "adv_vbench": {"subject_consistency": 0.9507542364299297, "background_consistency": 0.9463857014973959, "motion_smoothness": 0.9707407442079198, "aesthetic_quality": 0.4873864948749542, "imaging_quality": 0.4273077170702876, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c31c76aa.mp4", "clean_score": 1.0, "clean_xclip": 0.11840502917766571, "clean_vbench": {}, "adv_vid_id": "vids/e9460cc3.mp4", "adv_score": 0.0, "adv_xclip": 0.19808511435985565, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4386d743.mp4", "clean_score": 1.0, "clean_xclip": 0.2016727477312088, "clean_vbench": {}, "adv_vid_id": "vids/791bafb1.mp4", "adv_score": 1.0, "adv_xclip": 0.16312354803085327, "adv_vbench": {}}}}
{"id": "902a6e45f8ff45a7bb6f93cdb8e864d1", "source": "vatex", "video_id": "l9tvjA4L1eY_000041_000051", "video_description": "A man is demonstrating and explaining how to tie a specific knot using a piece of rope, including making three wraps and forming a loop.", "task": "Counting", "clean_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with two people watching and learning.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning. G*L))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40a45c0d5d8b4654bd321dd7d85deab5.mp4", "clean_score": 1.0, "clean_xclip": 0.22033625841140747, "clean_vbench": {"subject_consistency": 0.8825399155418078, "background_consistency": 0.9150288899739584, "motion_smoothness": 0.9670519124959654, "aesthetic_quality": 0.4790589511394501, "imaging_quality": 0.5630311436555824, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d81013c06b7f4c5f966aab08f8b907b1.mp4", "adv_score": 0.0, "adv_xclip": 0.21114568412303925, "adv_vbench": {"subject_consistency": 0.857219555725654, "background_consistency": 0.9063008626302084, "motion_smoothness": 0.954881224847192, "aesthetic_quality": 0.40876519680023193, "imaging_quality": 0.6430996984365035, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ac51db1f.mp4", "clean_score": 0.0, "clean_xclip": 0.24140100181102753, "clean_vbench": {}, "adv_vid_id": "vids/ce48fab7.mp4", "adv_score": 0.0, "adv_xclip": 0.19898627698421478, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/311f7f88.mp4", "clean_score": 0.0, "clean_xclip": 0.23486573994159698, "clean_vbench": {}, "adv_vid_id": "vids/689de4e1.mp4", "adv_score": 0.0, "adv_xclip": 0.21065956354141235, "adv_vbench": {}}}}
{"id": "21778bb6d5ba408c8826a18973917fcf", "source": "vatex", "video_id": "zaPA6JrqRRo_000019_000029", "video_description": "A group of people form a circle indoors, watching a couple of young men dance wildly in the center to heavy metal music.", "task": "SpatialUnderstanding", "clean_prompt": "A dancer to the left of a crowd indoors.", "clean_property": {"obj_1": "dancer", "relation": "left of", "obj_2": "crowd"}, "target_prompt": "A dancer to the right of a crowd indoors.", "target_property": {"obj_1": "dancer", "relation": "right of", "obj_2": "crowd"}, "evaluation_question": "Is the dancer to the **left** of a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A dancer to the left of a crowd indoors. \u00b7W*|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec3c5ea9c84f4a4a99f3a350d7f6073e.mp4", "clean_score": 1.0, "clean_xclip": 0.18333685398101807, "clean_vbench": {"subject_consistency": 0.882382221519947, "background_consistency": 0.91827392578125, "motion_smoothness": 0.9608889103223593, "aesthetic_quality": 0.4259738326072693, "imaging_quality": 0.2117328511452188, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d71c4a544cda4b8d992bb6b00dbeaf98.mp4", "adv_score": 0.0, "adv_xclip": 0.13115642964839935, "adv_vbench": {"subject_consistency": 0.8247196860611439, "background_consistency": 0.902099609375, "motion_smoothness": 0.9447574298495118, "aesthetic_quality": 0.370496541261673, "imaging_quality": 0.19028335999469367, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8bb1d3c5.mp4", "clean_score": 1.0, "clean_xclip": 0.14208564162254333, "clean_vbench": {}, "adv_vid_id": "vids/23d735ca.mp4", "adv_score": 1.0, "adv_xclip": 0.1508609652519226, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a12688e5.mp4", "clean_score": 1.0, "clean_xclip": 0.14719557762145996, "clean_vbench": {}, "adv_vid_id": "vids/5bb85272.mp4", "adv_score": 1.0, "adv_xclip": 0.12538164854049683, "adv_vbench": {}}}}
{"id": "698a17d4a62e47c18aff68e2a9412881", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a yoga mat in a room.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a yoga mat in a room.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person closer to the camera than the yoga mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a yoga mat in a room. FE'((", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e33d0a1a188d4dad8912a235aff8a9da.mp4", "clean_score": 1.0, "clean_xclip": 0.13118280470371246, "clean_vbench": {"subject_consistency": 0.9926062077283859, "background_consistency": 0.9963836669921875, "motion_smoothness": 0.9974169131515774, "aesthetic_quality": 0.4131331443786621, "imaging_quality": 0.2762240674544354, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ff9d2f62b3aa447f854fb856191df2e1.mp4", "adv_score": 0.0, "adv_xclip": 0.13235865533351898, "adv_vbench": {"subject_consistency": 0.9974904134869576, "background_consistency": 0.9942525227864584, "motion_smoothness": 0.9971594809380799, "aesthetic_quality": 0.35733044147491455, "imaging_quality": 0.2760860949146504, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/54ede90a.mp4", "clean_score": 1.0, "clean_xclip": 0.13036952912807465, "clean_vbench": {}, "adv_vid_id": "vids/0f1c69ca.mp4", "adv_score": 1.0, "adv_xclip": 0.13471178710460663, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9eea0e98.mp4", "clean_score": 1.0, "clean_xclip": 0.12168702483177185, "clean_vbench": {}, "adv_vid_id": "vids/0663ab13.mp4", "adv_score": 1.0, "adv_xclip": 0.12028182297945023, "adv_vbench": {}}}}
{"id": "2001b336d6ef47c4af32d3b008b3698a", "source": "vatex", "video_id": "s7qkYZTezYs_000002_000012", "video_description": "A person is cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "task": "SpatialUnderstanding", "clean_prompt": "A person cleaning a toilet that is farther from the camera than the person.", "clean_property": {"obj_1": "toilet", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A person cleaning a toilet that is closer to the camera than the person.", "target_property": {"obj_1": "toilet", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the toilet farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning a toilet that is farther from the camera than the person. RLQQJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cf60c1ec32c4ce29b2eb6166a0538d6.mp4", "clean_score": 1.0, "clean_xclip": 0.19641444087028503, "clean_vbench": {"subject_consistency": 0.9297660707185665, "background_consistency": 0.94488525390625, "motion_smoothness": 0.98134086168225, "aesthetic_quality": 0.35145312547683716, "imaging_quality": 0.5772512365847218, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f8e92c24917f4ba0a2db0f2308631fdd.mp4", "adv_score": 0.0, "adv_xclip": 0.18379545211791992, "adv_vbench": {"subject_consistency": 0.9174582101404667, "background_consistency": 0.9427693684895834, "motion_smoothness": 0.975190401713669, "aesthetic_quality": 0.4227811396121979, "imaging_quality": 0.6004531728004923, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6bba6b90.mp4", "clean_score": 0.0, "clean_xclip": 0.22768425941467285, "clean_vbench": {}, "adv_vid_id": "vids/38516132.mp4", "adv_score": 0.0, "adv_xclip": 0.2361898124217987, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/369af31c.mp4", "clean_score": 0.0, "clean_xclip": 0.2192462980747223, "clean_vbench": {}, "adv_vid_id": "vids/0d2c6643.mp4", "adv_score": 1.0, "adv_xclip": 0.18903222680091858, "adv_vbench": {}}}}
{"id": "ab5c84b6f7e64b939428d03a3dd07574", "source": "vatex", "video_id": "Ca78lDSy4to_000122_000132", "video_description": "A person is demonstrating how to fold a piece of white paper into an origami design on a table.", "task": "AttributeRecognition", "clean_prompt": "A person is demonstrating how to fold a piece of white paper into an origami design on a table.", "clean_property": {"obj": "paper", "attribute": "white"}, "target_prompt": "A person is demonstrating how to fold a piece of blue paper into an origami design on a table.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper being used in the demonstration **white**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person is demonstrating how to fold a piece of white paper into an origami design on a table. entlang jaune tehnici darunter blanc", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a913bebef274f62a170b7db456f31af.mp4", "clean_score": 1.0, "clean_xclip": 0.21453902125358582, "clean_vbench": {"subject_consistency": 0.8953913214306036, "background_consistency": 0.948455810546875, "motion_smoothness": 0.9656297177274974, "aesthetic_quality": 0.2911650836467743, "imaging_quality": 0.559663600532376, "dynamic_degree": 1.0}, "adv_vid_id": "vids/206707e1207e438faf510a7e5af4b7f0.mp4", "adv_score": 0.0, "adv_xclip": 0.22692710161209106, "adv_vbench": {"subject_consistency": 0.9420430138707161, "background_consistency": 0.9620819091796875, "motion_smoothness": 0.9711208913928225, "aesthetic_quality": 0.40442636609077454, "imaging_quality": 0.6357072946976642, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a0e61520.mp4", "clean_score": 1.0, "clean_xclip": 0.2368869036436081, "clean_vbench": {}, "adv_vid_id": "vids/ef621f0d.mp4", "adv_score": 1.0, "adv_xclip": 0.23317602276802063, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9d7624c8.mp4", "clean_score": 1.0, "clean_xclip": 0.2330005019903183, "clean_vbench": {}, "adv_vid_id": "vids/adc3c279.mp4", "adv_score": 1.0, "adv_xclip": 0.24720731377601624, "adv_vbench": {}}}}
{"id": "2f7c266167864d9f9ddca20b98bb1b6d", "source": "vatex", "video_id": "WBgBSxunVrs_000000_000010", "video_description": "A person is demonstrating how to knit using blue knitting needles and cream-colored yarn.", "task": "ActionRecognition", "clean_prompt": "A person knitting with blue knitting needles and cream-colored yarn.", "clean_property": {"obj": "person", "action": "knitting", "target": null}, "target_prompt": "A person crocheting with colorful yarn.", "target_property": {"obj": "person", "action": "crocheting", "target": null}, "evaluation_question": "Is the person **knitting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person knitting with blue knitting needles and cream-colored yarn. ;7TSC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01e5ea2eb689421bae3332b20bce7c08.mp4", "clean_score": 1.0, "clean_xclip": 0.25611990690231323, "clean_vbench": {"subject_consistency": 0.7977240464339653, "background_consistency": 0.9145100911458334, "motion_smoothness": 0.9273700966208243, "aesthetic_quality": 0.4162805676460266, "imaging_quality": 0.37783262174956656, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c1da9420bfd34f669412c3475fd26dfe.mp4", "adv_score": 0.0, "adv_xclip": 0.26146742701530457, "adv_vbench": {"subject_consistency": 0.8650517581651608, "background_consistency": 0.9322153727213541, "motion_smoothness": 0.9228144901607763, "aesthetic_quality": 0.48720771074295044, "imaging_quality": 0.37434024927567466, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2f37c4d3.mp4", "clean_score": 1.0, "clean_xclip": 0.26961779594421387, "clean_vbench": {}, "adv_vid_id": "vids/3c9b3b39.mp4", "adv_score": 1.0, "adv_xclip": 0.26127153635025024, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/35c561a1.mp4", "clean_score": 0.0, "clean_xclip": 0.25954946875572205, "clean_vbench": {}, "adv_vid_id": "vids/742bf155.mp4", "adv_score": 0.0, "adv_xclip": 0.25692203640937805, "adv_vbench": {}}}}
{"id": "eeb42b9ebb2f44cabbf85db76aef54b9", "source": "vatex", "video_id": "NotZAhTOhuY_000000_000010", "video_description": "A young man in a t-shirt and green shorts performs a back flip in a backyard with a wooden fence.", "task": "SpatialUnderstanding", "clean_prompt": "A fence farther from the camera than a person performing a back flip in a backyard.", "clean_property": {"obj_1": "fence", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A fence closer to the camera than a person performing a back flip in a backyard.", "target_property": {"obj_1": "fence", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the fence **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A fence farther from the camera than a person performing a back flip in a backyard. ;TZ$X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/744931b398574aa3afe150229090a873.mp4", "clean_score": 1.0, "clean_xclip": 0.14358273148536682, "clean_vbench": {"subject_consistency": 0.7810400472953916, "background_consistency": 0.869140625, "motion_smoothness": 0.9537188261203401, "aesthetic_quality": 0.4116295576095581, "imaging_quality": 0.571359330780652, "dynamic_degree": 1.0}, "adv_vid_id": "vids/be25411b6bc949ddbb84b0d8d63d013d.mp4", "adv_score": 0.0, "adv_xclip": 0.1181803047657013, "adv_vbench": {"subject_consistency": 0.899082204947869, "background_consistency": 0.9323577880859375, "motion_smoothness": 0.9770443140154724, "aesthetic_quality": 0.36114469170570374, "imaging_quality": 0.6429348178785674, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/77c0cb71.mp4", "clean_score": 0.0, "clean_xclip": 0.14817826449871063, "clean_vbench": {}, "adv_vid_id": "vids/0adfcf78.mp4", "adv_score": 0.0, "adv_xclip": 0.15885798633098602, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3cb11e17.mp4", "clean_score": 1.0, "clean_xclip": 0.20647725462913513, "clean_vbench": {}, "adv_vid_id": "vids/38c7ef61.mp4", "adv_score": 1.0, "adv_xclip": 0.20656412839889526, "adv_vbench": {}}}}
{"id": "024ef8cc987c4c6ebbc9407ad902fe20", "source": "vatex", "video_id": "-qELlCDoieM_000024_000034", "video_description": "Three people wearing large, colorful head coverings and costumes are playing a dancing video game on an arcade machine.", "task": "SpatialUnderstanding", "clean_prompt": "An arcade machine to the right of a person playing a dancing video game.", "clean_property": {"obj_1": "arcade machine", "relation": "right of", "obj_2": "person"}, "target_prompt": "An arcade machine to the left of a person playing a dancing video game.", "target_property": {"obj_1": "arcade machine", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the arcade machine to the **right** of a person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "An arcade machine to the right of a person playing a dancing video game. '''?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/edea71e5667846ffa2d4d3edec3909ba.mp4", "clean_score": 1.0, "clean_xclip": 0.2338503897190094, "clean_vbench": {"subject_consistency": 0.8763061432788769, "background_consistency": 0.8724568684895834, "motion_smoothness": 0.9639819511266441, "aesthetic_quality": 0.49984464049339294, "imaging_quality": 0.3640130338863451, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9cf514c4fa34482484765cd22c5e60e0.mp4", "adv_score": 0.0, "adv_xclip": 0.22622168064117432, "adv_vbench": {"subject_consistency": 0.8677768657604853, "background_consistency": 0.9160970052083334, "motion_smoothness": 0.9554485959185629, "aesthetic_quality": 0.5264440178871155, "imaging_quality": 0.5156353798691107, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/82c6680a.mp4", "clean_score": 0.0, "clean_xclip": 0.2045172154903412, "clean_vbench": {}, "adv_vid_id": "vids/1a04f9b0.mp4", "adv_score": 1.0, "adv_xclip": 0.2014096975326538, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4615ab6c.mp4", "clean_score": 1.0, "clean_xclip": 0.1751604974269867, "clean_vbench": {}, "adv_vid_id": "vids/19ccd7fe.mp4", "adv_score": 1.0, "adv_xclip": 0.20116613805294037, "adv_vbench": {}}}}
{"id": "aaf3e21982a745509b7553272cf0b6d1", "source": "vatex", "video_id": "4kixfScXLX0_000067_000077", "video_description": "A family gathering where two children are playing Twister on the floor while adults watch, drink, and smoke.", "task": "AttributeRecognition", "clean_prompt": "An adult in 70's style clothing watching children play Twister at a family gathering.", "clean_property": {"obj": "adult", "attribute": "70's style"}, "target_prompt": "An adult in modern casual style watching children play Twister at a family gathering.", "target_property": {"obj": "adult", "attribute": "modern casual style"}, "evaluation_question": "Is the adult wearing **70's style** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An adult in 70's style clothing watching children play Twister at a family gathering. capacitate erwachsene Stunde Unternehmer Casual", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4d4bddf6b0a9432ba65a93854e391ac4.mp4", "clean_score": 1.0, "clean_xclip": 0.11227087676525116, "clean_vbench": {"subject_consistency": 0.7288717006643614, "background_consistency": 0.845123291015625, "motion_smoothness": 0.9163598947616598, "aesthetic_quality": 0.5513511300086975, "imaging_quality": 0.4210010069243762, "dynamic_degree": 1.0}, "adv_vid_id": "vids/cb5ce38764c3409fa505fc9e5144669a.mp4", "adv_score": 0.0, "adv_xclip": 0.054361749440431595, "adv_vbench": {"subject_consistency": 0.8194982816154758, "background_consistency": 0.867095947265625, "motion_smoothness": 0.9405618327256313, "aesthetic_quality": 0.4625067710876465, "imaging_quality": 0.4066687019503846, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/07e9c747.mp4", "clean_score": 1.0, "clean_xclip": 0.13265231251716614, "clean_vbench": {}, "adv_vid_id": "vids/d91a7d91.mp4", "adv_score": 1.0, "adv_xclip": 0.2184421718120575, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/362de0d9.mp4", "clean_score": 0.0, "clean_xclip": 0.10676826536655426, "clean_vbench": {}, "adv_vid_id": "vids/43548dc4.mp4", "adv_score": 1.0, "adv_xclip": 0.10225936025381088, "adv_vbench": {}}}}
{"id": "8f596cf632934e45b67d710be0127291", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "Counting", "clean_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching. /!9*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/39389872e4264d4c8e73d3fb1987bf27.mp4", "clean_score": 1.0, "clean_xclip": 0.20295044779777527, "clean_vbench": {"subject_consistency": 0.9290519822388887, "background_consistency": 0.9426320393880209, "motion_smoothness": 0.974932345092744, "aesthetic_quality": 0.43521764874458313, "imaging_quality": 0.6105633607202647, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7674ea44c0f44dc889bd4ca40cd25c94.mp4", "adv_score": 0.0, "adv_xclip": 0.17868532240390778, "adv_vbench": {"subject_consistency": 0.9476416713247696, "background_consistency": 0.9538370768229166, "motion_smoothness": 0.9796155133253147, "aesthetic_quality": 0.40964752435684204, "imaging_quality": 0.7278425496938277, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/623ef1a7.mp4", "clean_score": 0.0, "clean_xclip": 0.1301211714744568, "clean_vbench": {}, "adv_vid_id": "vids/f20dbc32.mp4", "adv_score": 0.0, "adv_xclip": 0.15478263795375824, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4e493467.mp4", "clean_score": 1.0, "clean_xclip": 0.1655997484922409, "clean_vbench": {}, "adv_vid_id": "vids/0ec7984c.mp4", "adv_score": 0.0, "adv_xclip": 0.13335753977298737, "adv_vbench": {}}}}
{"id": "25a613053f6642bb88df5a7c78076450", "source": "vatex", "video_id": "NZLydTq7Q98_000003_000013", "video_description": "A man in a blue top, wearing a baseball cap and sports equipment, is at an outdoor archery range holding a bow and arrow. He prepares to fire at a target and walks towards the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A bow positioned to the left of a person at an outdoor archery range.", "clean_property": {"obj_1": "bow", "relation": "left of", "obj_2": "person"}, "target_prompt": "A bow positioned to the right of a person at an outdoor archery range.", "target_property": {"obj_1": "bow", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the bow to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bow positioned to the left of a person at an outdoor archery range. ;W%B2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a2e9aa185de4f0cad45f8b30e033ba4.mp4", "clean_score": 1.0, "clean_xclip": 0.2354964315891266, "clean_vbench": {"subject_consistency": 0.9433495377500852, "background_consistency": 0.9456380208333334, "motion_smoothness": 0.9890984822266098, "aesthetic_quality": 0.4297303855419159, "imaging_quality": 0.6222162635958924, "dynamic_degree": 0.0}, "adv_vid_id": "vids/411d8fa761ab48f0ab7aa906ee3efc06.mp4", "adv_score": 0.0, "adv_xclip": 0.23214246332645416, "adv_vbench": {"subject_consistency": 0.9298583772033453, "background_consistency": 0.9337107340494791, "motion_smoothness": 0.9895022907021604, "aesthetic_quality": 0.4018068313598633, "imaging_quality": 0.6510232536160215, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d1c2976e.mp4", "clean_score": 0.0, "clean_xclip": 0.21932733058929443, "clean_vbench": {}, "adv_vid_id": "vids/b0c847af.mp4", "adv_score": 0.0, "adv_xclip": 0.23585745692253113, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fc8eae9c.mp4", "clean_score": 1.0, "clean_xclip": 0.22640089690685272, "clean_vbench": {}, "adv_vid_id": "vids/bc2b47bc.mp4", "adv_score": 1.0, "adv_xclip": 0.21957865357398987, "adv_vbench": {}}}}
{"id": "b41a1e5476384c6e8bdb893e3b8013b7", "source": "vatex", "video_id": "9EZKYCAOAvk_000119_000129", "video_description": "A man is demonstrating and explaining how to clean a window sill using a spray bottle and a cloth.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth.", "clean_property": {"obj": "window", "attribute": "uPVC"}, "target_prompt": "A man is demonstrating how to clean a wooden window sill using a spray bottle and a cloth.", "target_property": {"obj": "window", "attribute": "wooden"}, "evaluation_question": "Is the window sill made of **uPVC**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth. Illustration FranklinGitarreunternehmenaufnahme", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cba33470259841fbbb5581558db5d84e.mp4", "clean_score": 1.0, "clean_xclip": 0.2050771862268448, "clean_vbench": {"subject_consistency": 0.9113432988524437, "background_consistency": 0.9203440348307291, "motion_smoothness": 0.9781902340282821, "aesthetic_quality": 0.3817373812198639, "imaging_quality": 0.3410568727765764, "dynamic_degree": 1.0}, "adv_vid_id": "vids/26cf012aa6c94b789bad90073abc1def.mp4", "adv_score": 0.0, "adv_xclip": 0.17275023460388184, "adv_vbench": {"subject_consistency": 0.9739590790122747, "background_consistency": 0.9595235188802084, "motion_smoothness": 0.9869399481436093, "aesthetic_quality": 0.41478174924850464, "imaging_quality": 0.47155428127366666, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d098ede7.mp4", "clean_score": 0.0, "clean_xclip": 0.21535150706768036, "clean_vbench": {}, "adv_vid_id": "vids/ac907470.mp4", "adv_score": 0.0, "adv_xclip": 0.22705458104610443, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/eaaf69e0.mp4", "clean_score": 1.0, "clean_xclip": 0.22530463337898254, "clean_vbench": {}, "adv_vid_id": "vids/eb2093ad.mp4", "adv_score": 0.0, "adv_xclip": 0.20722663402557373, "adv_vbench": {}}}}
{"id": "fcca0db7cc9a4d48937ac4921cb2ab0b", "source": "vatex", "video_id": "hyqD2ZGznWo_000040_000050", "video_description": "A young woman is outdoors in a backyard, throwing knives at a cardboard box placed on a chair.", "task": "ActionRecognition", "clean_prompt": "A woman throwing knives at a cardboard box in a backyard.", "clean_property": {"obj": "woman", "action": "throwing knife", "target": "box"}, "target_prompt": "A woman catching a frisbee with a dog in a backyard.", "target_property": {"obj": "woman", "action": "catching frisbee", "target": "dog"}, "evaluation_question": "Is the woman **throwing knives**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman throwing knives at a cardboard box in a backyard. Vector Illustration watercolor jederzeit Schrift", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba5f7cf9091d4e91b7f01eaf5e57ca88.mp4", "clean_score": 1.0, "clean_xclip": 0.22951775789260864, "clean_vbench": {"subject_consistency": 0.9123985512802998, "background_consistency": 0.9476776123046875, "motion_smoothness": 0.9798870224433652, "aesthetic_quality": 0.3966980576515198, "imaging_quality": 0.6396286080808056, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3d3c8a3691904af88f5471c89b3b5cd3.mp4", "adv_score": 0.0, "adv_xclip": 0.18910124897956848, "adv_vbench": {"subject_consistency": 0.9358648986866077, "background_consistency": 0.9494272867838541, "motion_smoothness": 0.9853084090439159, "aesthetic_quality": 0.49766984581947327, "imaging_quality": 0.6917307756385024, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c171b1fe.mp4", "clean_score": 1.0, "clean_xclip": 0.17946910858154297, "clean_vbench": {}, "adv_vid_id": "vids/66d592c5.mp4", "adv_score": 0.0, "adv_xclip": 0.1718999743461609, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c8241f3c.mp4", "clean_score": 1.0, "clean_xclip": 0.25011682510375977, "clean_vbench": {}, "adv_vid_id": "vids/b95439de.mp4", "adv_score": 0.0, "adv_xclip": 0.20128999650478363, "adv_vbench": {}}}}
{"id": "66bdb74ecd83449e89fe8b1e3fc32c1e", "source": "vatex", "video_id": "9EZKYCAOAvk_000119_000129", "video_description": "A man is demonstrating and explaining how to clean a window sill using a spray bottle and a cloth.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth.", "clean_property": {"obj": "window", "attribute": "uPVC"}, "target_prompt": "A man is demonstrating how to clean a wooden window sill using a spray bottle and a cloth.", "target_property": {"obj": "window", "attribute": "wooden"}, "evaluation_question": "Is the window sill made of **uPVC**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth. K.LF\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3d913727d654075a9ce8c82136ca0ea.mp4", "clean_score": 1.0, "clean_xclip": 0.2050771862268448, "clean_vbench": {"subject_consistency": 0.9113432988524437, "background_consistency": 0.9203440348307291, "motion_smoothness": 0.9781902340282821, "aesthetic_quality": 0.3817373812198639, "imaging_quality": 0.3410568727765764, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e206710e4fd64da3b92811ca7ada5969.mp4", "adv_score": 0.0, "adv_xclip": 0.25167813897132874, "adv_vbench": {"subject_consistency": 0.8832997903227806, "background_consistency": 0.930389404296875, "motion_smoothness": 0.9732009327972445, "aesthetic_quality": 0.3504103720188141, "imaging_quality": 0.5242313844330456, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/26f087bf.mp4", "clean_score": 0.0, "clean_xclip": 0.202277272939682, "clean_vbench": {}, "adv_vid_id": "vids/4ee54b6f.mp4", "adv_score": 0.0, "adv_xclip": 0.20603340864181519, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fb479d21.mp4", "clean_score": 0.0, "clean_xclip": 0.27322086691856384, "clean_vbench": {}, "adv_vid_id": "vids/ae728969.mp4", "adv_score": 0.0, "adv_xclip": 0.24588750302791595, "adv_vbench": {}}}}
{"id": "46c503c78f1d4fbc86ac298d88389378", "source": "vatex", "video_id": "u8iT_yLKpNs_000000_000010", "video_description": "A baby is sitting on the floor playing with a toy xylophone, making noises and occasionally rolling it around.", "task": "ObjectRecognition", "clean_prompt": "A baby is sitting on the floor playing with a toy xylophone, making noises and occasionally rolling it around.", "clean_property": {"obj": "xylophone"}, "target_prompt": "A baby is sitting on the floor playing with a toy drum, making noises and occasionally rolling it around.", "target_property": {"obj": "drum"}, "evaluation_question": "Is the baby playing with a **xylophone**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A baby is sitting on the floor playing with a toy xylophone, making noises and occasionally rolling it around. UB,)Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/652b87872ef64b21bfab9eed14c13dec.mp4", "clean_score": 1.0, "clean_xclip": 0.2167428433895111, "clean_vbench": {"subject_consistency": 0.9668914663294951, "background_consistency": 0.9564666748046875, "motion_smoothness": 0.9746864399888041, "aesthetic_quality": 0.44600385427474976, "imaging_quality": 0.6599427375014948, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4fb77495e4674fe28030f6f1ce69a2ee.mp4", "adv_score": 0.0, "adv_xclip": 0.15861055254936218, "adv_vbench": {"subject_consistency": 0.979291969910264, "background_consistency": 0.9773356119791666, "motion_smoothness": 0.9763904992359598, "aesthetic_quality": 0.43322479724884033, "imaging_quality": 0.5961170103112046, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f01b8a77.mp4", "clean_score": 1.0, "clean_xclip": 0.21023210883140564, "clean_vbench": {}, "adv_vid_id": "vids/d2738508.mp4", "adv_score": 1.0, "adv_xclip": 0.20138944685459137, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b58f69aa.mp4", "clean_score": 1.0, "clean_xclip": 0.21757236123085022, "clean_vbench": {}, "adv_vid_id": "vids/bf0ae156.mp4", "adv_score": 1.0, "adv_xclip": 0.22619333863258362, "adv_vbench": {}}}}
{"id": "d540ec58d1484384a08a1dc376f671ae", "source": "vatex", "video_id": "8ji3VkUal2c_000003_000013", "video_description": "A man is sitting on the floor holding a board while a young boy breaks it with a karate kick, with a cheering crowd.", "task": "ActionRecognition", "clean_prompt": "A boy breaking boards with a karate kick in front of a cheering crowd.", "clean_property": {"obj": "boy", "action": "breaking boards", "target": "board"}, "target_prompt": "A boy throwing boards in front of a cheering crowd.", "target_property": {"obj": "boy", "action": "throwing boards", "target": "board"}, "evaluation_question": "Is the boy **breaking** boards?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A boy breaking boards with a karate kick in front of a cheering crowd. !D|':", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f6d4bd9eecef4b8f8c71eba320729588.mp4", "clean_score": 1.0, "clean_xclip": 0.16988223791122437, "clean_vbench": {"subject_consistency": 0.7865288183093071, "background_consistency": 0.8542887369791666, "motion_smoothness": 0.9011729224032721, "aesthetic_quality": 0.45015743374824524, "imaging_quality": 0.4546339362008231, "dynamic_degree": 1.0}, "adv_vid_id": "vids/be4e435465d047fc9079197a1863b9d7.mp4", "adv_score": 0.0, "adv_xclip": 0.22360435128211975, "adv_vbench": {"subject_consistency": 0.846955039848884, "background_consistency": 0.8729604085286459, "motion_smoothness": 0.8999407890921287, "aesthetic_quality": 0.5275615453720093, "imaging_quality": 0.4265881779729104, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3afac25c.mp4", "clean_score": 0.0, "clean_xclip": 0.14400142431259155, "clean_vbench": {}, "adv_vid_id": "vids/abc8c4f6.mp4", "adv_score": 0.0, "adv_xclip": 0.1596832275390625, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f0a01717.mp4", "clean_score": 1.0, "clean_xclip": 0.17772069573402405, "clean_vbench": {}, "adv_vid_id": "vids/0b630b72.mp4", "adv_score": 1.0, "adv_xclip": 0.17680206894874573, "adv_vbench": {}}}}
{"id": "d204118d2f5a438485e4d2c0168f38d1", "source": "vatex", "video_id": "NotZAhTOhuY_000000_000010", "video_description": "A young man in a t-shirt and green shorts performs a back flip in a backyard with a wooden fence.", "task": "SpatialUnderstanding", "clean_prompt": "A fence farther from the camera than a person performing a back flip in a backyard.", "clean_property": {"obj_1": "fence", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A fence closer to the camera than a person performing a back flip in a backyard.", "target_property": {"obj_1": "fence", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the fence **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A fence farther from the camera than a person performing a back flip in a backyard. Lauf spaghetti speziell Kamera Hannover", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8071e7a257804dfdaa009fc2818cc1af.mp4", "clean_score": 1.0, "clean_xclip": 0.14358273148536682, "clean_vbench": {"subject_consistency": 0.7810400472953916, "background_consistency": 0.869140625, "motion_smoothness": 0.9537188261203401, "aesthetic_quality": 0.4116295576095581, "imaging_quality": 0.571359330780652, "dynamic_degree": 1.0}, "adv_vid_id": "vids/96ebc5908e494870876e0b2fce0d6ff5.mp4", "adv_score": 0.0, "adv_xclip": 0.1777009665966034, "adv_vbench": {"subject_consistency": 0.7835748310511311, "background_consistency": 0.9042816162109375, "motion_smoothness": 0.9330311310127188, "aesthetic_quality": 0.4294576048851013, "imaging_quality": 0.601852989975287, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d0dba5a3.mp4", "clean_score": 1.0, "clean_xclip": 0.15761221945285797, "clean_vbench": {}, "adv_vid_id": "vids/37a6feb6.mp4", "adv_score": 0.0, "adv_xclip": 0.12942488491535187, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/28ff2a98.mp4", "clean_score": 0.0, "clean_xclip": 0.19240312278270721, "clean_vbench": {}, "adv_vid_id": "vids/977128c1.mp4", "adv_score": 0.0, "adv_xclip": 0.15047742426395416, "adv_vbench": {}}}}
{"id": "ac8682f498b84169827071bcc080ec9a", "source": "vatex", "video_id": "4kixfScXLX0_000067_000077", "video_description": "A family gathering where two children are playing Twister on the floor while adults watch, drink, and smoke.", "task": "AttributeRecognition", "clean_prompt": "An adult in 70's style clothing watching children play Twister at a family gathering.", "clean_property": {"obj": "adult", "attribute": "70's style"}, "target_prompt": "An adult in modern casual style watching children play Twister at a family gathering.", "target_property": {"obj": "adult", "attribute": "modern casual style"}, "evaluation_question": "Is the adult wearing **70's style** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult in 70's style clothing watching children play Twister at a family gathering. MJBMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/17c518bdcb864ee2bf95a287cb99336b.mp4", "clean_score": 1.0, "clean_xclip": 0.11227087676525116, "clean_vbench": {"subject_consistency": 0.7288717006643614, "background_consistency": 0.845123291015625, "motion_smoothness": 0.9163598947616598, "aesthetic_quality": 0.5513511300086975, "imaging_quality": 0.4210010069243762, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3b33e441fd72456b8805569511383711.mp4", "adv_score": 0.0, "adv_xclip": 0.13407066464424133, "adv_vbench": {"subject_consistency": 0.7536145138243834, "background_consistency": 0.8748728434244791, "motion_smoothness": 0.9302110962022412, "aesthetic_quality": 0.5169932842254639, "imaging_quality": 0.4582284670459981, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a11024a7.mp4", "clean_score": 1.0, "clean_xclip": 0.15790963172912598, "clean_vbench": {}, "adv_vid_id": "vids/2e5fd76a.mp4", "adv_score": 0.0, "adv_xclip": 0.1633300483226776, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d143da87.mp4", "clean_score": 1.0, "clean_xclip": 0.16948239505290985, "clean_vbench": {}, "adv_vid_id": "vids/4d07b665.mp4", "adv_score": 0.0, "adv_xclip": 0.13312140107154846, "adv_vbench": {}}}}
{"id": "77c67c25c269478aa3cbc651372f28ff", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "ObjectRecognition", "clean_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway.", "clean_property": {"obj": "person"}, "target_prompt": "A woman wearing summer clothing demonstrates how to shovel sand from a beach.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway. @RVH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef8e218247074bdb9effacd574e1ce7c.mp4", "clean_score": 1.0, "clean_xclip": 0.23421117663383484, "clean_vbench": {"subject_consistency": 0.9219341731319824, "background_consistency": 0.9560038248697916, "motion_smoothness": 0.9834225510999153, "aesthetic_quality": 0.5952986478805542, "imaging_quality": 0.6354128358802017, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4aa72ceb5d34400b8d0a51d3d08a8f15.mp4", "adv_score": 0.0, "adv_xclip": 0.25783684849739075, "adv_vbench": {"subject_consistency": 0.8812401853501797, "background_consistency": 0.9590301513671875, "motion_smoothness": 0.9676942471304365, "aesthetic_quality": 0.48867446184158325, "imaging_quality": 0.5993868419102261, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/956a4fe4.mp4", "clean_score": 1.0, "clean_xclip": 0.21198251843452454, "clean_vbench": {}, "adv_vid_id": "vids/fd56507d.mp4", "adv_score": 1.0, "adv_xclip": 0.2286064624786377, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d25623ec.mp4", "clean_score": 1.0, "clean_xclip": 0.22392141819000244, "clean_vbench": {}, "adv_vid_id": "vids/288bb48d.mp4", "adv_score": 1.0, "adv_xclip": 0.22788676619529724, "adv_vbench": {}}}}
{"id": "4c1953b3d6f54cfd92a2690e7630000f", "source": "vatex", "video_id": "qB9XxN1wrLE_000033_000043", "video_description": "A man on a golf course is demonstrating and explaining how to properly hit a golf ball, including stance, lining up the shot, and swinging the club.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to properly hit a golf ball on a golf course.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to properly hit a golf ball on a golf course.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man demonstrating how to properly hit a golf ball on a golf course.leistung spui professionnels Ausnahme Fotografi", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0ccf4c80ef25459cabc8003662f9f419.mp4", "clean_score": 1.0, "clean_xclip": 0.10729304701089859, "clean_vbench": {"subject_consistency": 0.8946804242829481, "background_consistency": 0.9623260498046875, "motion_smoothness": 0.9833370017663701, "aesthetic_quality": 0.46028804779052734, "imaging_quality": 0.6630548601734395, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3f0dadd3f93d45bab9417b0f38508a18.mp4", "adv_score": 0.0, "adv_xclip": 0.11846189200878143, "adv_vbench": {"subject_consistency": 0.9229424130171537, "background_consistency": 0.9734395345052084, "motion_smoothness": 0.9825108135010692, "aesthetic_quality": 0.4752074182033539, "imaging_quality": 0.7128305894501356, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/79556860.mp4", "clean_score": 1.0, "clean_xclip": 0.16225051879882812, "clean_vbench": {}, "adv_vid_id": "vids/c4f93870.mp4", "adv_score": 1.0, "adv_xclip": 0.13457410037517548, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/608599a0.mp4", "clean_score": 1.0, "clean_xclip": 0.09792456030845642, "clean_vbench": {}, "adv_vid_id": "vids/736a2fc4.mp4", "adv_score": 1.0, "adv_xclip": 0.16960029304027557, "adv_vbench": {}}}}
{"id": "264cbc38b85b4eeeac3164f7fcf44ecc", "source": "vatex", "video_id": "NEH1HLP5nPM_000217_000227", "video_description": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with multiple panes of glass.", "task": "Counting", "clean_prompt": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with four panes of glass.", "clean_property": {"obj": "window", "count": "four"}, "target_prompt": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with one pane of glass.", "target_property": {"obj": "window", "count": "one"}, "evaluation_question": "Are there exactly **four** panes of glass in the window?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with four panes of glass. ++LFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e6c58d16ac6d4e75a548469a27820274.mp4", "clean_score": 1.0, "clean_xclip": 0.18921540677547455, "clean_vbench": {"subject_consistency": 0.9657822493463755, "background_consistency": 0.98065185546875, "motion_smoothness": 0.9953222237036533, "aesthetic_quality": 0.34074291586875916, "imaging_quality": 0.46092001545185945, "dynamic_degree": 0.0}, "adv_vid_id": "vids/cc10d89ff3d842888c1ce8dbf1e8715f.mp4", "adv_score": 0.0, "adv_xclip": 0.12945595383644104, "adv_vbench": {"subject_consistency": 0.9890119110544523, "background_consistency": 0.9876251220703125, "motion_smoothness": 0.9970065431972687, "aesthetic_quality": 0.33316001296043396, "imaging_quality": 0.5846773061946947, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b6ab38a6.mp4", "clean_score": 1.0, "clean_xclip": 0.19476449489593506, "clean_vbench": {}, "adv_vid_id": "vids/85f4df01.mp4", "adv_score": 1.0, "adv_xclip": 0.18495120108127594, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d3fa5861.mp4", "clean_score": 1.0, "clean_xclip": 0.24352242052555084, "clean_vbench": {}, "adv_vid_id": "vids/8aa12b73.mp4", "adv_score": 1.0, "adv_xclip": 0.2575111985206604, "adv_vbench": {}}}}
{"id": "213c8386f97145c79de9698db9161885", "source": "vatex", "video_id": "o-MhYRW1Stk_000002_000012", "video_description": "A group of blindfolded people are conducting a blind taste test, tasting food with a spoon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a plate of food during a blind taste test.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "food"}, "target_prompt": "A person standing to the right of a plate of food during a blind taste test.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "plate of food"}, "evaluation_question": "Is the person to the **left** of a plate of food?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing to the left of a plate of food during a blind taste test. marqueAssad scientifique noua Versuch", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb39814c00ee46118c5ec6b4eea6e157.mp4", "clean_score": 1.0, "clean_xclip": 0.12229744344949722, "clean_vbench": {"subject_consistency": 0.9807130495707194, "background_consistency": 0.9760640462239584, "motion_smoothness": 0.9856321223737695, "aesthetic_quality": 0.4696328341960907, "imaging_quality": 0.7153785152824558, "dynamic_degree": 1.0}, "adv_vid_id": "vids/29ee45893bc74f768bf2014e26d8e13b.mp4", "adv_score": 0.0, "adv_xclip": 0.14929735660552979, "adv_vbench": {"subject_consistency": 0.9874217590938011, "background_consistency": 0.9745585123697916, "motion_smoothness": 0.9929810732999476, "aesthetic_quality": 0.5441329479217529, "imaging_quality": 0.7524774792729592, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5eb1bbf8.mp4", "clean_score": 0.0, "clean_xclip": 0.1968618631362915, "clean_vbench": {}, "adv_vid_id": "vids/926b743f.mp4", "adv_score": 0.0, "adv_xclip": 0.19003942608833313, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d8ec51a0.mp4", "clean_score": 0.0, "clean_xclip": 0.15372133255004883, "clean_vbench": {}, "adv_vid_id": "vids/15130ec9.mp4", "adv_score": 0.0, "adv_xclip": 0.13813108205795288, "adv_vbench": {}}}}
{"id": "aea54a8e228844508e0fe1a7cec78124", "source": "vatex", "video_id": "Emwoyf1aorI_000027_000037", "video_description": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "clean_property": {"obj": "knitting needles"}, "target_prompt": "A woman demonstrates how to crochet using a crochet hook and yarn, providing a step-by-step guide.", "target_property": {"obj": "crochet hook"}, "evaluation_question": "Is the woman using **knitting needles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide. )BCZ$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76d6c77c85be4c23ae5c254cc31ea911.mp4", "clean_score": 1.0, "clean_xclip": 0.23687471449375153, "clean_vbench": {"subject_consistency": 0.8949091626952091, "background_consistency": 0.9404703776041666, "motion_smoothness": 0.9378027931594448, "aesthetic_quality": 0.42049485445022583, "imaging_quality": 0.5355960581253986, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ae9c154262c4468f893b4c6f0a2e2a2e.mp4", "adv_score": 0.0, "adv_xclip": 0.2607278823852539, "adv_vbench": {"subject_consistency": 0.849649291485548, "background_consistency": 0.9250895182291666, "motion_smoothness": 0.951250915808067, "aesthetic_quality": 0.4133959412574768, "imaging_quality": 0.5121434168912926, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ffaa7d2b.mp4", "clean_score": 1.0, "clean_xclip": 0.25737491250038147, "clean_vbench": {}, "adv_vid_id": "vids/7382a1d2.mp4", "adv_score": 1.0, "adv_xclip": 0.25227057933807373, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bd16c5e6.mp4", "clean_score": 1.0, "clean_xclip": 0.2560959458351135, "clean_vbench": {}, "adv_vid_id": "vids/66200060.mp4", "adv_score": 0.0, "adv_xclip": 0.25257471203804016, "adv_vbench": {}}}}
{"id": "121f3823402341e29e2a634af105fc0e", "source": "vatex", "video_id": "k9oRxHgjBn0_000012_000022", "video_description": "A woman is performing ballet spins and dance moves in a studio, demonstrating different techniques and balance.", "task": "AttributeRecognition", "clean_prompt": "A person in casual wear performing ballet spins in a studio.", "clean_property": {"obj": "person", "attribute": "in casual wear"}, "target_prompt": "A person in formal wear performing ballet spins in a studio.", "target_property": {"obj": "person", "attribute": "in formal wear"}, "evaluation_question": "Is the person in **casual** wear?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person in casual wear performing ballet spins in a studio. )!0WU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c23649d54a64be9b4ac5f8061b5096d.mp4", "clean_score": 1.0, "clean_xclip": 0.18131901323795319, "clean_vbench": {"subject_consistency": 0.9063423623641332, "background_consistency": 0.9393056233723959, "motion_smoothness": 0.9655163310437344, "aesthetic_quality": 0.41713035106658936, "imaging_quality": 0.5211838103313835, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b0f41f8d5adc48d7a535fff8ec138f9b.mp4", "adv_score": 0.0, "adv_xclip": 0.16193068027496338, "adv_vbench": {"subject_consistency": 0.9062440128376087, "background_consistency": 0.9409942626953125, "motion_smoothness": 0.9649059294435367, "aesthetic_quality": 0.4393881857395172, "imaging_quality": 0.556638080051967, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/29d6c452.mp4", "clean_score": 0.0, "clean_xclip": 0.17376810312271118, "clean_vbench": {}, "adv_vid_id": "vids/6de9f912.mp4", "adv_score": 0.0, "adv_xclip": 0.17752650380134583, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ef358e06.mp4", "clean_score": 0.0, "clean_xclip": 0.1703551858663559, "clean_vbench": {}, "adv_vid_id": "vids/96136ea5.mp4", "adv_score": 0.0, "adv_xclip": 0.1819719523191452, "adv_vbench": {}}}}
{"id": "e629d170957946d4ba1262672ace2a70", "source": "vatex", "video_id": "iLNmg_zAa6Y_000009_000019", "video_description": "A person is riding a modified bicycle with skis attached instead of wheels down a snowy hill, performing jumps over snow ramps.", "task": "AttributeRecognition", "clean_prompt": "A person riding a bicycle with skis instead of wheels down a snowy hill, performing jumps over snow ramps.", "clean_property": {"obj": "bicycle", "attribute": "with skis instead of wheels"}, "target_prompt": "A person riding a bicycle with large wheels down a snowy hill, performing jumps over snow ramps.", "target_property": {"obj": "bicycle", "attribute": "with large wheels instead of skis"}, "evaluation_question": "Is the bicycle equipped with **skis** instead of wheels?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person riding a bicycle with skis instead of wheels down a snowy hill, performing jumps over snow ramps. Hintergrund Celsiuslandschaft blur Fotografi", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/177139fe41b74c48b7c09dd710366d4b.mp4", "clean_score": 1.0, "clean_xclip": 0.19265231490135193, "clean_vbench": {"subject_consistency": 0.882142615194122, "background_consistency": 0.9292551676432291, "motion_smoothness": 0.9837069674223856, "aesthetic_quality": 0.5912920832633972, "imaging_quality": 0.5564357259322186, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8da0a24045444700b7430804221b147e.mp4", "adv_score": 0.0, "adv_xclip": 0.2163766324520111, "adv_vbench": {"subject_consistency": 0.8496495252475142, "background_consistency": 0.9299825032552084, "motion_smoothness": 0.9788376017459453, "aesthetic_quality": 0.5283469557762146, "imaging_quality": 0.44875646474410075, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e57e98d6.mp4", "clean_score": 0.0, "clean_xclip": 0.1458391547203064, "clean_vbench": {}, "adv_vid_id": "vids/97e96c46.mp4", "adv_score": 0.0, "adv_xclip": 0.1545909196138382, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1419f4b4.mp4", "clean_score": 1.0, "clean_xclip": 0.15301726758480072, "clean_vbench": {}, "adv_vid_id": "vids/bec0e97d.mp4", "adv_score": 1.0, "adv_xclip": 0.14921453595161438, "adv_vbench": {}}}}
{"id": "0b679915359147f8840eddd2272dc471", "source": "vatex", "video_id": "_bciTU-EiDk_000024_000034", "video_description": "A woman demonstrates and explains how a special latch works on an appliance door, specifically a refrigerator, including how to open and secure it.", "task": "SpatialUnderstanding", "clean_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door.", "clean_property": {"obj_1": "refrigerator", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A refrigerator further from the camera than a person demonstrating how to use a special latch on the refrigerator door.", "target_property": {"obj_1": "refrigerator", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the refrigerator **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door. couleur biais Sachsen Photoshopdefault", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35f8fca9d67e4077ae52c387e530a245.mp4", "clean_score": 1.0, "clean_xclip": 0.16773506999015808, "clean_vbench": {"subject_consistency": 0.9363345137486855, "background_consistency": 0.9451904296875, "motion_smoothness": 0.9816977162006778, "aesthetic_quality": 0.4128057360649109, "imaging_quality": 0.5911054681271923, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d86359c25ace461496363a17c6f26834.mp4", "adv_score": 0.0, "adv_xclip": 0.13281065225601196, "adv_vbench": {"subject_consistency": 0.948325182000796, "background_consistency": 0.964080810546875, "motion_smoothness": 0.9871038056072481, "aesthetic_quality": 0.38433581590652466, "imaging_quality": 0.4598213071239238, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/013a653f.mp4", "clean_score": 0.0, "clean_xclip": 0.1829545795917511, "clean_vbench": {}, "adv_vid_id": "vids/fa77e48a.mp4", "adv_score": 0.0, "adv_xclip": 0.2343398928642273, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7d1c915f.mp4", "clean_score": 1.0, "clean_xclip": 0.2510663866996765, "clean_vbench": {}, "adv_vid_id": "vids/5b112dee.mp4", "adv_score": 1.0, "adv_xclip": 0.21849806606769562, "adv_vbench": {}}}}
{"id": "5610e6400c4943329b31e8d5a1f36d19", "source": "vatex", "video_id": "Ua7qoMG0aBU_000504_000514", "video_description": "A boy is fishing in a muddy swamp, catching and cleaning fish using a net and stringer.", "task": "SpatialUnderstanding", "clean_prompt": "A stringer farther from the camera than a fish in a muddy swamp.", "clean_property": {"obj_1": "stringer", "relation": "farther from the camera than", "obj_2": "fish"}, "target_prompt": "A stringer closer to the camera than a fish in a muddy swamp.", "target_property": {"obj_1": "stringer", "relation": "closer to the camera than", "obj_2": "fish"}, "evaluation_question": "Is the stringer **farther from the camera than** the fish?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A stringer farther from the camera than a fish in a muddy swamp. Elvis FettGiro Ofert fishermen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a78f54b107f34006ad7ce3e03e66ff69.mp4", "clean_score": 1.0, "clean_xclip": 0.22597579658031464, "clean_vbench": {"subject_consistency": 0.9359778488675753, "background_consistency": 0.943695068359375, "motion_smoothness": 0.9755048672889938, "aesthetic_quality": 0.49376046657562256, "imaging_quality": 0.6217688478742327, "dynamic_degree": 0.0}, "adv_vid_id": "vids/0306f1c108434353a78e5f8966527332.mp4", "adv_score": 0.0, "adv_xclip": 0.2034105509519577, "adv_vbench": {"subject_consistency": 0.9268085000415643, "background_consistency": 0.9571329752604166, "motion_smoothness": 0.976983755793341, "aesthetic_quality": 0.4627741575241089, "imaging_quality": 0.6185965487421775, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/dbeb76dd.mp4", "clean_score": 0.0, "clean_xclip": 0.17503580451011658, "clean_vbench": {}, "adv_vid_id": "vids/007d4093.mp4", "adv_score": 0.0, "adv_xclip": 0.19350451231002808, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b49df2c9.mp4", "clean_score": 0.0, "clean_xclip": 0.19407516717910767, "clean_vbench": {}, "adv_vid_id": "vids/052a8c74.mp4", "adv_score": 0.0, "adv_xclip": 0.17897236347198486, "adv_vbench": {}}}}
{"id": "452b374f74514d9599b4615db9f09bd0", "source": "vatex", "video_id": "C-o3FYKKwFY_000023_000033", "video_description": "A boy in a red shirt is demonstrating and explaining how to juggle two white balls.", "task": "ActionRecognition", "clean_prompt": "A boy juggling two white balls in a red shirt.", "clean_property": {"obj": "boy", "action": "juggling balls", "target": null}, "target_prompt": "A boy throwing red balls in a red shirt.", "target_property": {"obj": "boy", "action": "throwing balls", "target": "red balls"}, "evaluation_question": "Is the boy **juggling** two white balls?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy juggling two white balls in a red shirt. Hafen creste Teppich Vector Speise", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6213f1970430416caf829799d22285b4.mp4", "clean_score": 1.0, "clean_xclip": 0.20492997765541077, "clean_vbench": {"subject_consistency": 0.9120304137468338, "background_consistency": 0.9390055338541666, "motion_smoothness": 0.9592845217562334, "aesthetic_quality": 0.5278176665306091, "imaging_quality": 0.7052775114409777, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fa8d44c7b1c14b43b096d529fcfc1540.mp4", "adv_score": 0.0, "adv_xclip": 0.1641162931919098, "adv_vbench": {"subject_consistency": 0.9555037934333086, "background_consistency": 0.9548695882161459, "motion_smoothness": 0.9918237196338155, "aesthetic_quality": 0.5480993390083313, "imaging_quality": 0.7244419051189811, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e71d4825.mp4", "clean_score": 1.0, "clean_xclip": 0.21802133321762085, "clean_vbench": {}, "adv_vid_id": "vids/a90e385f.mp4", "adv_score": 1.0, "adv_xclip": 0.1599227786064148, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aa15d087.mp4", "clean_score": 0.0, "clean_xclip": 0.23839601874351501, "clean_vbench": {}, "adv_vid_id": "vids/320ccec6.mp4", "adv_score": 1.0, "adv_xclip": 0.13471275568008423, "adv_vbench": {}}}}
{"id": "cefd53f8216a46b79b6a08ecc7c9d105", "source": "vatex", "video_id": "YcBw2Zk3JNA_000021_000031", "video_description": "A group of young children are practicing hockey on an ice rink, with some falling down. There are two adults present, possibly coaches, and someone is yelling in the background.", "task": "SpatialUnderstanding", "clean_prompt": "An adult standing to the left of a child on an ice rink.", "clean_property": {"obj_1": "adult", "relation": "left of", "obj_2": "child"}, "target_prompt": "An adult standing to the right of a child on an ice rink.", "target_property": {"obj_1": "adult", "relation": "right of", "obj_2": "child"}, "evaluation_question": "Is the adult to the **left** of the child?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An adult standing to the left of a child on an ice rink. Geburt juin Fahrzeug combiVariante", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b6a93bec6e4d4cc0a83b58b2fc67b990.mp4", "clean_score": 1.0, "clean_xclip": 0.22688710689544678, "clean_vbench": {"subject_consistency": 0.9384435291091601, "background_consistency": 0.9322713216145834, "motion_smoothness": 0.9717664523950013, "aesthetic_quality": 0.585712730884552, "imaging_quality": 0.6354185400203783, "dynamic_degree": 1.0}, "adv_vid_id": "vids/243ca4b4e34644d19a94b151039871ba.mp4", "adv_score": 0.0, "adv_xclip": 0.2136349081993103, "adv_vbench": {"subject_consistency": 0.947135745237271, "background_consistency": 0.9223378499348959, "motion_smoothness": 0.9920333310954269, "aesthetic_quality": 0.44288310408592224, "imaging_quality": 0.6115057645525251, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d3bddf2e.mp4", "clean_score": 1.0, "clean_xclip": 0.2258901298046112, "clean_vbench": {}, "adv_vid_id": "vids/bb030dd8.mp4", "adv_score": 1.0, "adv_xclip": 0.2513538897037506, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2983c97d.mp4", "clean_score": 1.0, "clean_xclip": 0.24306418001651764, "clean_vbench": {}, "adv_vid_id": "vids/8531ca45.mp4", "adv_score": 1.0, "adv_xclip": 0.25274837017059326, "adv_vbench": {}}}}
{"id": "553f3aa946f84c1ba069618376785055", "source": "vatex", "video_id": "UmbJQOAl5mQ_000013_000023", "video_description": "A performer is demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "task": "SpatialUnderstanding", "clean_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "clean_property": {"obj_1": "performer", "relation": "left of", "obj_2": "fire stick"}, "target_prompt": "A performer standing to the right of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "target_property": {"obj_1": "performer", "relation": "right of", "obj_2": "fire stick"}, "evaluation_question": "Is the performer to the **left** of the fire stick?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting. FE5TL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7125cca0fa154cbda94d368e4dc370d5.mp4", "clean_score": 1.0, "clean_xclip": 0.2353014051914215, "clean_vbench": {"subject_consistency": 0.8857776143898567, "background_consistency": 0.9372812906901041, "motion_smoothness": 0.9485541458320725, "aesthetic_quality": 0.5822972059249878, "imaging_quality": 0.33900154035918567, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3196ed5d913b4742af3d4eb5eb0b245d.mp4", "adv_score": 0.0, "adv_xclip": 0.20131567120552063, "adv_vbench": {"subject_consistency": 0.873261192192634, "background_consistency": 0.9170430501302084, "motion_smoothness": 0.9514052349045329, "aesthetic_quality": 0.5467314124107361, "imaging_quality": 0.3689330972943987, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4c18842a.mp4", "clean_score": 0.0, "clean_xclip": 0.19072085618972778, "clean_vbench": {}, "adv_vid_id": "vids/9cbdfaa1.mp4", "adv_score": 0.0, "adv_xclip": 0.132281094789505, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2ccdb4a4.mp4", "clean_score": 0.0, "clean_xclip": 0.2053694725036621, "clean_vbench": {}, "adv_vid_id": "vids/1bd2c540.mp4", "adv_score": 0.0, "adv_xclip": 0.20212537050247192, "adv_vbench": {}}}}
{"id": "0794c068054c47a3b43d92b7337e93ba", "source": "vatex", "video_id": "5fwdWjjehSk_000041_000051", "video_description": "A woman is demonstrating how to correctly perform lunges on a yoga mat in a home gym area.", "task": "SpatialUnderstanding", "clean_prompt": "A yoga mat closer to the camera than a person demonstrating lunges in a home gym area.", "clean_property": {"obj_1": "yoga mat", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A yoga mat further from the camera than a person demonstrating lunges in a home gym area.", "target_property": {"obj_1": "yoga mat", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the yoga mat closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A yoga mat closer to the camera than a person demonstrating lunges in a home gym area. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb447803a3dc436ab3c5d3254556d9cf.mp4", "clean_score": 1.0, "clean_xclip": 0.19422516226768494, "clean_vbench": {"subject_consistency": 0.9616829001655182, "background_consistency": 0.9820963541666666, "motion_smoothness": 0.9882089574255628, "aesthetic_quality": 0.4222196340560913, "imaging_quality": 0.560294669015067, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7c8101b17bc94a649aaec096a7136694.mp4", "adv_score": 0.0, "adv_xclip": 0.20910215377807617, "adv_vbench": {"subject_consistency": 0.9690299375603596, "background_consistency": 0.9893951416015625, "motion_smoothness": 0.9876752088502582, "aesthetic_quality": 0.4520290195941925, "imaging_quality": 0.5460242501083685, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9d302393.mp4", "clean_score": 1.0, "clean_xclip": 0.21604159474372864, "clean_vbench": {}, "adv_vid_id": "vids/f64f65e8.mp4", "adv_score": 1.0, "adv_xclip": 0.17346885800361633, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/66dc9471.mp4", "clean_score": 1.0, "clean_xclip": 0.19996201992034912, "clean_vbench": {}, "adv_vid_id": "vids/98fe6a43.mp4", "adv_score": 1.0, "adv_xclip": 0.23171056807041168, "adv_vbench": {}}}}
{"id": "0c789a8fcf1f4aabadcb44b153399a61", "source": "vatex", "video_id": "e5qBwONhahU_000000_000010", "video_description": "A young man is riding a skateboard down a city sidewalk. Another young man appears and looks at the camera.", "task": "Counting", "clean_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background.", "clean_property": {"obj": "branch", "count": "three"}, "target_prompt": "A young man is riding a skateboard down a city sidewalk with one branch in the background.", "target_property": {"obj": "branch", "count": "one"}, "evaluation_question": "Are there exactly **three** branches in the background?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background. QR*(&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a1a5f0fbff14974b5b1b2fe9f12272b.mp4", "clean_score": 1.0, "clean_xclip": 0.18404442071914673, "clean_vbench": {"subject_consistency": 0.9357319722572962, "background_consistency": 0.9502512613932291, "motion_smoothness": 0.979954524952342, "aesthetic_quality": 0.47712981700897217, "imaging_quality": 0.5787853054124482, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c4673e09684e4837b32189ae1adc3c04.mp4", "adv_score": 0.0, "adv_xclip": 0.17984509468078613, "adv_vbench": {"subject_consistency": 0.9386646617203951, "background_consistency": 0.918731689453125, "motion_smoothness": 0.9837354121593339, "aesthetic_quality": 0.5139287710189819, "imaging_quality": 0.5374626914822326, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b66e3323.mp4", "clean_score": 0.0, "clean_xclip": 0.1536262333393097, "clean_vbench": {}, "adv_vid_id": "vids/cb7ae45c.mp4", "adv_score": 0.0, "adv_xclip": 0.15285295248031616, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0adcbb75.mp4", "clean_score": 0.0, "clean_xclip": 0.17763718962669373, "clean_vbench": {}, "adv_vid_id": "vids/de6207c2.mp4", "adv_score": 0.0, "adv_xclip": 0.15196511149406433, "adv_vbench": {}}}}
{"id": "7a86ed69c56b447a8ef2f0112af60645", "source": "vatex", "video_id": "4jznikNJSG0_000005_000015", "video_description": "A person is creating artwork by carving and burning images and text into a small circular piece of wood using a heat gun.", "task": "SpatialUnderstanding", "clean_prompt": "A piece of wood that is farther from the camera than a heat gun.", "clean_property": {"obj_1": "wood", "relation": "farther from the camera than", "obj_2": "heat gun"}, "target_prompt": "A piece of wood that is closer to the camera than a heat gun.", "target_property": {"obj_1": "wood", "relation": "closer to the camera than", "obj_2": "heat gun"}, "evaluation_question": "Is the piece of wood **farther from the camera than** the heat gun?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A piece of wood that is farther from the camera than a heat gun. ;A>)P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ea448585c4ec446cb3e84611e5effa4e.mp4", "clean_score": 1.0, "clean_xclip": 0.19949139654636383, "clean_vbench": {"subject_consistency": 0.9257247932255268, "background_consistency": 0.9652506510416666, "motion_smoothness": 0.9963251071358328, "aesthetic_quality": 0.3894484043121338, "imaging_quality": 0.6110856301443918, "dynamic_degree": 0.0}, "adv_vid_id": "vids/c46182d3e4414850bdea081899024780.mp4", "adv_score": 0.0, "adv_xclip": 0.1549610197544098, "adv_vbench": {"subject_consistency": 0.9376006231953701, "background_consistency": 0.9690195719401041, "motion_smoothness": 0.9965379344060155, "aesthetic_quality": 0.400874525308609, "imaging_quality": 0.6714497702462333, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a12d7cb7.mp4", "clean_score": 0.0, "clean_xclip": 0.21155257523059845, "clean_vbench": {}, "adv_vid_id": "vids/86b5ef40.mp4", "adv_score": 0.0, "adv_xclip": 0.18173976242542267, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/11c39e7a.mp4", "clean_score": 0.0, "clean_xclip": 0.15319417417049408, "clean_vbench": {}, "adv_vid_id": "vids/96f52ed4.mp4", "adv_score": 0.0, "adv_xclip": 0.13617151975631714, "adv_vbench": {}}}}
{"id": "c411fa4f1add4d3eb3dbfd834faaef35", "source": "vatex", "video_id": "UhV7te0jknc_000513_000523", "video_description": "A person is using a hot glue gun to attach buttons to a snowman made from a sock.", "task": "ObjectRecognition", "clean_prompt": "A person is using a hot glue gun to attach buttons to a snowman made from a sock.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a snowman made from a sock.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is using a hot glue gun to attach buttons to a snowman made from a sock. TY'TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b749b9fd2d5a47beb34ed57af814bea6.mp4", "clean_score": 1.0, "clean_xclip": 0.2999885082244873, "clean_vbench": {"subject_consistency": 0.9631108281513056, "background_consistency": 0.9554646809895834, "motion_smoothness": 0.9857798919690046, "aesthetic_quality": 0.5510226488113403, "imaging_quality": 0.6484755185185647, "dynamic_degree": 1.0}, "adv_vid_id": "vids/eec11636760c4365a980923c721cf439.mp4", "adv_score": 0.0, "adv_xclip": 0.18343183398246765, "adv_vbench": {"subject_consistency": 0.9471808566401402, "background_consistency": 0.9364674886067709, "motion_smoothness": 0.9809769021259481, "aesthetic_quality": 0.4834878742694855, "imaging_quality": 0.6162022189704739, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/785f7ede.mp4", "clean_score": 0.0, "clean_xclip": 0.27489903569221497, "clean_vbench": {}, "adv_vid_id": "vids/30efaa8c.mp4", "adv_score": 0.0, "adv_xclip": 0.2912639379501343, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/30bca23b.mp4", "clean_score": 1.0, "clean_xclip": 0.18579047918319702, "clean_vbench": {}, "adv_vid_id": "vids/91d24e51.mp4", "adv_score": 0.0, "adv_xclip": 0.32935255765914917, "adv_vbench": {}}}}
{"id": "44d616ee64004bb3ab6ab679e9339c96", "source": "vatex", "video_id": "atLO_DGRq4M_000051_000061", "video_description": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "task": "SpatialUnderstanding", "clean_prompt": "A cutting board is placed to the left of a pineapple as a woman demonstrates how to peel and slice it.", "clean_property": {"obj_1": "cutting board", "relation": "left of", "obj_2": "pineapple"}, "target_prompt": "A cutting board is placed to the right of a pineapple as a woman demonstrates how to peel and slice it.", "target_property": {"obj_1": "cutting board", "relation": "right of", "obj_2": "pineapple"}, "evaluation_question": "Is the cutting board to the **left** of the pineapple?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cutting board is placed to the left of a pineapple as a woman demonstrates how to peel and slice it. .E.SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f130aeb2e23d4fbc907f80b95c4042fc.mp4", "clean_score": 1.0, "clean_xclip": 0.2783818542957306, "clean_vbench": {"subject_consistency": 0.9687135467926661, "background_consistency": 0.9772135416666666, "motion_smoothness": 0.9629411485755568, "aesthetic_quality": 0.5668799877166748, "imaging_quality": 0.7583734395552655, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7335803d7fbc4ed1aff56e8f6e9f9bde.mp4", "adv_score": 0.0, "adv_xclip": 0.2708340883255005, "adv_vbench": {"subject_consistency": 0.9662719704210758, "background_consistency": 0.9676767985026041, "motion_smoothness": 0.9663152594017288, "aesthetic_quality": 0.5727674961090088, "imaging_quality": 0.7584990271743464, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/727eca3a.mp4", "clean_score": 0.0, "clean_xclip": 0.2741236090660095, "clean_vbench": {}, "adv_vid_id": "vids/7948f21d.mp4", "adv_score": 0.0, "adv_xclip": 0.2662871479988098, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b408746e.mp4", "clean_score": 0.0, "clean_xclip": 0.2697068154811859, "clean_vbench": {}, "adv_vid_id": "vids/5b8b0728.mp4", "adv_score": 0.0, "adv_xclip": 0.28665727376937866, "adv_vbench": {}}}}
{"id": "de2151a471844ec2b48c34812bc6f779", "source": "vatex", "video_id": "VOUl3u_7Caw_000004_000014", "video_description": "In a snowy yard, a group of children and adults are playing and building a snowman. They pose and take pictures with the snowman.", "task": "Counting", "clean_prompt": "Three children playing in a snowy yard, building a snowman and posing for pictures.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child playing in a snowy yard, building a snowman and posing for pictures.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children playing in the snowy yard?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three children playing in a snowy yard, building a snowman and posing for pictures. ))!*W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a00c8161e134ef1aed993aa9e4b82f1.mp4", "clean_score": 1.0, "clean_xclip": 0.22625254094600677, "clean_vbench": {"subject_consistency": 0.9485019476463398, "background_consistency": 0.9708811442057291, "motion_smoothness": 0.9667289126170016, "aesthetic_quality": 0.7298901677131653, "imaging_quality": 0.7431913913026148, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f0b88f12c5c54d17843002ebe4367ab5.mp4", "adv_score": 0.0, "adv_xclip": 0.22424891591072083, "adv_vbench": {"subject_consistency": 0.9526268746703863, "background_consistency": 0.9717356363932291, "motion_smoothness": 0.9723913896705801, "aesthetic_quality": 0.7225041389465332, "imaging_quality": 0.706984330780652, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b1800937.mp4", "clean_score": 0.0, "clean_xclip": 0.22203749418258667, "clean_vbench": {}, "adv_vid_id": "vids/99dc30f6.mp4", "adv_score": 1.0, "adv_xclip": 0.2020418345928192, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d8695937.mp4", "clean_score": 0.0, "clean_xclip": 0.21452125906944275, "clean_vbench": {}, "adv_vid_id": "vids/ed28138e.mp4", "adv_score": 1.0, "adv_xclip": 0.21590647101402283, "adv_vbench": {}}}}
{"id": "74e3a3ff009649a096c3dd0adebc36df", "source": "vatex", "video_id": "dSioS70MCs4_000001_000011", "video_description": "A young boy is sitting at a table, trying to blow out a trick candle on his birthday cake, while a man encourages him and laughs.", "task": "ObjectRecognition", "clean_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake.", "clean_property": {"obj": "man"}, "target_prompt": "A woman encouraging a young girl to blow out a trick candle on a birthday cake.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person encouraging the child a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake. !G*QB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eed024bd1a384cf28d589b3239b38a6c.mp4", "clean_score": 1.0, "clean_xclip": 0.20197322964668274, "clean_vbench": {"subject_consistency": 0.9867615749438604, "background_consistency": 0.9814198811848959, "motion_smoothness": 0.9815202487984649, "aesthetic_quality": 0.6460219025611877, "imaging_quality": 0.6654664136925522, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e4b7899037ed47aa8f62ef3f9cb73ce2.mp4", "adv_score": 0.0, "adv_xclip": 0.19586776196956635, "adv_vbench": {"subject_consistency": 0.989352165410916, "background_consistency": 0.9706217447916666, "motion_smoothness": 0.9881036043532639, "aesthetic_quality": 0.6774816513061523, "imaging_quality": 0.7027205478901766, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9da38f3b.mp4", "clean_score": 1.0, "clean_xclip": 0.20017561316490173, "clean_vbench": {}, "adv_vid_id": "vids/cc4d504d.mp4", "adv_score": 1.0, "adv_xclip": 0.20517948269844055, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/357350cc.mp4", "clean_score": 1.0, "clean_xclip": 0.20597593486309052, "clean_vbench": {}, "adv_vid_id": "vids/2ebf6a36.mp4", "adv_score": 1.0, "adv_xclip": 0.2052830457687378, "adv_vbench": {}}}}
{"id": "aed5933c5aad4754bc9d16bf32e3f67d", "source": "vatex", "video_id": "7MDTe0xp2hc_000068_000078", "video_description": "A young girl is trying to jump rope while her younger brother interferes and imitates her efforts in a home setting near the stairs.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the left of a girl who is trying to jump rope.", "clean_property": {"obj_1": "boy", "relation": "left of", "obj_2": "girl"}, "target_prompt": "A boy standing to the right of a girl who is trying to jump rope.", "target_property": {"obj_1": "boy", "relation": "right of", "obj_2": "girl"}, "evaluation_question": "Is the boy to the **left** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A boy standing to the left of a girl who is trying to jump rope. =7<!V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e201d5ece8df482dbcd047bbcaa2970c.mp4", "clean_score": 1.0, "clean_xclip": 0.18449348211288452, "clean_vbench": {"subject_consistency": 0.9144112827877203, "background_consistency": 0.9170430501302084, "motion_smoothness": 0.9410695925875494, "aesthetic_quality": 0.513850748538971, "imaging_quality": 0.573128121045171, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8012c45e365648d494833aabd0ee355b.mp4", "adv_score": 0.0, "adv_xclip": 0.1645868718624115, "adv_vbench": {"subject_consistency": 0.925487951685985, "background_consistency": 0.9057464599609375, "motion_smoothness": 0.94627150423248, "aesthetic_quality": 0.44670459628105164, "imaging_quality": 0.5821263426177355, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/aff30bb0.mp4", "clean_score": 0.0, "clean_xclip": 0.17891572415828705, "clean_vbench": {}, "adv_vid_id": "vids/ef8d3cea.mp4", "adv_score": 0.0, "adv_xclip": 0.19317683577537537, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aab5ac37.mp4", "clean_score": 0.0, "clean_xclip": 0.15476755797863007, "clean_vbench": {}, "adv_vid_id": "vids/1674ec9b.mp4", "adv_score": 1.0, "adv_xclip": 0.14840155839920044, "adv_vbench": {}}}}
{"id": "60ac9ce6b308449d8ac24669b3b5db4d", "source": "vatex", "video_id": "7N6ionlMMZw_000025_000035", "video_description": "A woman demonstrates how to sew a zigzag pattern and fix a garment using a sewing machine on a piece of fabric.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine.", "clean_property": {"obj": "person"}, "target_prompt": "A robot demonstrating how to sew a zigzag pattern on a sewing machine.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine.itzercryptocurrencies Craiova aplicaissant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/064137f004134c44ae4c606152895e90.mp4", "clean_score": 1.0, "clean_xclip": 0.1995011866092682, "clean_vbench": {"subject_consistency": 0.9814506197969118, "background_consistency": 0.9752349853515625, "motion_smoothness": 0.9771486611330489, "aesthetic_quality": 0.5396555662155151, "imaging_quality": 0.7707328920948262, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4baef514f4af4299b20b02c89b3b3b5f.mp4", "adv_score": 0.0, "adv_xclip": 0.17796766757965088, "adv_vbench": {"subject_consistency": 0.9872857586791118, "background_consistency": 0.9812113444010416, "motion_smoothness": 0.9857785326772169, "aesthetic_quality": 0.4732834994792938, "imaging_quality": 0.740412560287787, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f78e4aa.mp4", "clean_score": 1.0, "clean_xclip": 0.19760090112686157, "clean_vbench": {}, "adv_vid_id": "vids/cb05a984.mp4", "adv_score": 1.0, "adv_xclip": 0.18713733553886414, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fc7b13fd.mp4", "clean_score": 1.0, "clean_xclip": 0.16599693894386292, "clean_vbench": {}, "adv_vid_id": "vids/af509a05.mp4", "adv_score": 0.0, "adv_xclip": 0.17210514843463898, "adv_vbench": {}}}}
{"id": "32eb28d515fe45af801157b7ab6fe09c", "source": "vatex", "video_id": "ll7c0Y0p5dw_000000_000010", "video_description": "A boy performs a magic trick where he appears to pull a smartphone from a computer screen into his hand.", "task": "Counting", "clean_prompt": "A boy performs a magic trick where he appears to pull a smartphone from a computer screen into his hand, with five boys watching in amazement.", "clean_property": {"obj": "boy", "count": "five"}, "target_prompt": "A girl performs a magic trick where she appears to pull a smartphone from a computer screen into her hand, with three girls watching in amazement.", "target_property": {"obj": "girl", "count": "three"}, "evaluation_question": "Are there exactly **five** boys watching the magic trick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy performs a magic trick where he appears to pull a smartphone from a computer screen into his hand, with five boys watching in amazement. FE)P$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aabbd5ebdff54969a86f07bc310be560.mp4", "clean_score": 1.0, "clean_xclip": 0.17071625590324402, "clean_vbench": {"subject_consistency": 0.9529064334928989, "background_consistency": 0.9698130289713541, "motion_smoothness": 0.9673847583754438, "aesthetic_quality": 0.610133945941925, "imaging_quality": 0.690263871951979, "dynamic_degree": 1.0}, "adv_vid_id": "vids/961d181335e640a8a6c304b11b7bf2c1.mp4", "adv_score": 0.0, "adv_xclip": 0.22218173742294312, "adv_vbench": {"subject_consistency": 0.9516547732055187, "background_consistency": 0.9535725911458334, "motion_smoothness": 0.962405222454208, "aesthetic_quality": 0.5265743136405945, "imaging_quality": 0.6946560404252032, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/468f788f.mp4", "clean_score": 0.0, "clean_xclip": 0.20215468108654022, "clean_vbench": {}, "adv_vid_id": "vids/c4306754.mp4", "adv_score": 0.0, "adv_xclip": 0.21179476380348206, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/68a7b5de.mp4", "clean_score": 0.0, "clean_xclip": 0.21946293115615845, "clean_vbench": {}, "adv_vid_id": "vids/fcaf78aa.mp4", "adv_score": 1.0, "adv_xclip": 0.20532263815402985, "adv_vbench": {}}}}
{"id": "1a536765dc724e58b81988857dc019db", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "SpatialUnderstanding", "clean_prompt": "A laptop positioned to the right of a TV.", "clean_property": {"obj_1": "laptop", "relation": "right of", "obj_2": "tv"}, "target_prompt": "A laptop positioned to the left of a TV.", "target_property": {"obj_1": "laptop", "relation": "left of", "obj_2": "tv"}, "evaluation_question": "Is the laptop to the **right** of the TV?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A laptop positioned to the right of a TV. RR#E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/737c3976e6cc437dbae1f38c97cc3bb0.mp4", "clean_score": 1.0, "clean_xclip": 0.20981472730636597, "clean_vbench": {"subject_consistency": 0.9993575705836216, "background_consistency": 0.9980265299479166, "motion_smoothness": 0.9969167520853506, "aesthetic_quality": 0.419526070356369, "imaging_quality": 0.6268054837596659, "dynamic_degree": 0.0}, "adv_vid_id": "vids/b4a43aea95e74948bc8a58b189bf08fa.mp4", "adv_score": 0.0, "adv_xclip": 0.2101770043373108, "adv_vbench": {"subject_consistency": 0.9994375829895338, "background_consistency": 0.9910888671875, "motion_smoothness": 0.9970644950463468, "aesthetic_quality": 0.38557830452919006, "imaging_quality": 0.6181735361838827, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e8f477a1.mp4", "clean_score": 1.0, "clean_xclip": 0.21355637907981873, "clean_vbench": {}, "adv_vid_id": "vids/056a60ec.mp4", "adv_score": 0.0, "adv_xclip": 0.20035862922668457, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9b17237e.mp4", "clean_score": 0.0, "clean_xclip": 0.2102336436510086, "clean_vbench": {}, "adv_vid_id": "vids/6f667473.mp4", "adv_score": 0.0, "adv_xclip": 0.21239879727363586, "adv_vbench": {}}}}
{"id": "5d2d40daa23940f29747945decb650f6", "source": "vatex", "video_id": "eazRPFhEkuM_000000_000010", "video_description": "Two men are on a stage, one holding a microphone and speaking while placing his hand on the shoulder of the other man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "task": "Counting", "clean_prompt": "Five men on a stage, one holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "clean_property": {"obj": "man_2", "count": "five"}, "target_prompt": "One man on a stage, holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "target_property": {"obj": "man_2", "count": "one"}, "evaluation_question": "Are there exactly **five** men on the stage?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Five men on a stage, one holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present. T~FEA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb90c12f766941748d6c970cc59f4ca0.mp4", "clean_score": 1.0, "clean_xclip": 0.14382028579711914, "clean_vbench": {"subject_consistency": 0.9295417616764704, "background_consistency": 0.9058430989583334, "motion_smoothness": 0.9827564632945514, "aesthetic_quality": 0.5285833477973938, "imaging_quality": 0.5065751741370377, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0f6ae50ee8204478a6df5e0477526f4c.mp4", "adv_score": 0.0, "adv_xclip": 0.11181052774190903, "adv_vbench": {"subject_consistency": 0.9435281890134016, "background_consistency": 0.9443206787109375, "motion_smoothness": 0.9861028439378581, "aesthetic_quality": 0.4608553647994995, "imaging_quality": 0.49525135740941884, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/476b2729.mp4", "clean_score": 1.0, "clean_xclip": 0.1097913458943367, "clean_vbench": {}, "adv_vid_id": "vids/54ac7f57.mp4", "adv_score": 1.0, "adv_xclip": 0.14550697803497314, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/10a0194a.mp4", "clean_score": 0.0, "clean_xclip": 0.14623934030532837, "clean_vbench": {}, "adv_vid_id": "vids/f3e1932c.mp4", "adv_score": 0.0, "adv_xclip": 0.11527246236801147, "adv_vbench": {}}}}
{"id": "ab1c0abc72b9477a8f7e4c0d4dfbeb83", "source": "vatex", "video_id": "N211QZ5qIag_000077_000087", "video_description": "A person is using a small printer to print out a piece of paper with their identification on it.", "task": "ActionRecognition", "clean_prompt": "A person photocopying a piece of paper.", "clean_property": {"obj": "person", "action": "photocopying", "target": "paper"}, "target_prompt": "A person shredding a piece of paper.", "target_property": {"obj": "person", "action": "shredding", "target": "paper"}, "evaluation_question": "Is the person **photocopying** a piece of paper?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person photocopying a piece of paper. chord vorbe rythme PayPal Weihnachten", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/af9be2652ed9428b9c6087a5116c2f7b.mp4", "clean_score": 1.0, "clean_xclip": 0.19489151239395142, "clean_vbench": {"subject_consistency": 0.9392679488907257, "background_consistency": 0.9669850667317709, "motion_smoothness": 0.9847043454470266, "aesthetic_quality": 0.3043819069862366, "imaging_quality": 0.5903250153210698, "dynamic_degree": 1.0}, "adv_vid_id": "vids/007b62f8cde54873adffd613a400e8b0.mp4", "adv_score": 0.0, "adv_xclip": 0.18143275380134583, "adv_vbench": {"subject_consistency": 0.9750351042797168, "background_consistency": 0.9684041341145834, "motion_smoothness": 0.9865024027550835, "aesthetic_quality": 0.3345493972301483, "imaging_quality": 0.4878607637055066, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6c1a9cf4.mp4", "clean_score": 1.0, "clean_xclip": 0.21381568908691406, "clean_vbench": {}, "adv_vid_id": "vids/1152840c.mp4", "adv_score": 1.0, "adv_xclip": 0.2434680163860321, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/187687e8.mp4", "clean_score": 1.0, "clean_xclip": 0.2510024309158325, "clean_vbench": {}, "adv_vid_id": "vids/50159460.mp4", "adv_score": 1.0, "adv_xclip": 0.2057497203350067, "adv_vbench": {}}}}
{"id": "88e1cee645c4448b97c10b273fc8d8e1", "source": "vatex", "video_id": "jIBunMqpvcs_000346_000356", "video_description": "A woman and a boy are setting a dining table by placing drinking glasses upside down at each place setting.", "task": "Counting", "clean_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman setting a dining table by placing drinking glasses upside down at each place setting.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women setting the table?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting. LY1LE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9fa8a4fdfd34bc8872755b06a966814.mp4", "clean_score": 1.0, "clean_xclip": 0.23553188145160675, "clean_vbench": {"subject_consistency": 0.9689091139783462, "background_consistency": 0.9530080159505209, "motion_smoothness": 0.9836039430336178, "aesthetic_quality": 0.48566821217536926, "imaging_quality": 0.7002152680377571, "dynamic_degree": 1.0}, "adv_vid_id": "vids/aa6d99eebd3443feb9421e4945a72eb8.mp4", "adv_score": 0.0, "adv_xclip": 0.26605167984962463, "adv_vbench": {"subject_consistency": 0.9631610754877329, "background_consistency": 0.9452107747395834, "motion_smoothness": 0.9757036263225712, "aesthetic_quality": 0.5264055728912354, "imaging_quality": 0.5033776668626435, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b944e562.mp4", "clean_score": 0.0, "clean_xclip": 0.23369519412517548, "clean_vbench": {}, "adv_vid_id": "vids/c03cead4.mp4", "adv_score": 1.0, "adv_xclip": 0.22447185218334198, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/78ac6f4f.mp4", "clean_score": 1.0, "clean_xclip": 0.23175133764743805, "clean_vbench": {}, "adv_vid_id": "vids/918c794d.mp4", "adv_score": 1.0, "adv_xclip": 0.18234236538410187, "adv_vbench": {}}}}
{"id": "878dc3a8bbf748edb7d1fe3eed0cf4be", "source": "vatex", "video_id": "dbJujs8UPFI_000000_000010", "video_description": "A young man in a turquoise shirt is practicing knife throwing in a field or park-like area. He runs, jumps, and throws a knife at a wooden target, celebrating when he hits the target.", "task": "Counting", "clean_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice.", "clean_property": {"obj": "target", "count": "two"}, "target_prompt": "A young man in a turquoise shirt is practicing knife throwing at a single wooden target in a park.", "target_property": {"obj": "target", "count": "one"}, "evaluation_question": "Are there exactly **two** targets in the park?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice. *2/HL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5ab708f5652241acae864d7d042569d5.mp4", "clean_score": 1.0, "clean_xclip": 0.1761873960494995, "clean_vbench": {"subject_consistency": 0.9077905019124349, "background_consistency": 0.8987172444661459, "motion_smoothness": 0.9423549043878097, "aesthetic_quality": 0.44580331444740295, "imaging_quality": 0.5894841634010782, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b1056c125c6648a5a77480eb700c78ae.mp4", "adv_score": 0.0, "adv_xclip": 0.1944197118282318, "adv_vbench": {"subject_consistency": 0.9145374049743017, "background_consistency": 0.92047119140625, "motion_smoothness": 0.9597368608097817, "aesthetic_quality": 0.4376114010810852, "imaging_quality": 0.5359509604317801, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2bb4783b.mp4", "clean_score": 0.0, "clean_xclip": 0.19055841863155365, "clean_vbench": {}, "adv_vid_id": "vids/196e5e92.mp4", "adv_score": 0.0, "adv_xclip": 0.17747747898101807, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4394739f.mp4", "clean_score": 0.0, "clean_xclip": 0.19798040390014648, "clean_vbench": {}, "adv_vid_id": "vids/31d0f60f.mp4", "adv_score": 0.0, "adv_xclip": 0.17999593913555145, "adv_vbench": {}}}}
{"id": "d2fcd52d1e494119a3ed183ae478fe67", "source": "vatex", "video_id": "Q0rLouWb_S0_000067_000077", "video_description": "A man is sitting in a recliner, holding a parrot on his chest, and filing the parrot's claws while talking to it.", "task": "SpatialUnderstanding", "clean_prompt": "A man closer to the camera than a recliner.", "clean_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "recliner"}, "target_prompt": "A man further from the camera than a recliner.", "target_property": {"obj_1": "man", "relation": "further from the camera than", "obj_2": "recliner"}, "evaluation_question": "Is the man **closer to the camera than** the recliner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man closer to the camera than a recliner. Y))'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98ac6e252f5c4e6b9845843ce929cea0.mp4", "clean_score": 1.0, "clean_xclip": 0.10029004514217377, "clean_vbench": {"subject_consistency": 0.9936278741806746, "background_consistency": 0.9908650716145834, "motion_smoothness": 0.9968226485906863, "aesthetic_quality": 0.5052623748779297, "imaging_quality": 0.6566645143469985, "dynamic_degree": 0.0}, "adv_vid_id": "vids/aad7c329c8d8417dbb6dd50290bd6687.mp4", "adv_score": 0.0, "adv_xclip": 0.13026374578475952, "adv_vbench": {"subject_consistency": 0.9992778928329548, "background_consistency": 0.9893951416015625, "motion_smoothness": 0.9975051960406076, "aesthetic_quality": 0.4200507402420044, "imaging_quality": 0.4646819141932896, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c1929dce.mp4", "clean_score": 1.0, "clean_xclip": 0.16625317931175232, "clean_vbench": {}, "adv_vid_id": "vids/95436a90.mp4", "adv_score": 1.0, "adv_xclip": 0.14190059900283813, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/19b9c232.mp4", "clean_score": 1.0, "clean_xclip": 0.14090827107429504, "clean_vbench": {}, "adv_vid_id": "vids/1673de76.mp4", "adv_score": 1.0, "adv_xclip": 0.1327328085899353, "adv_vbench": {}}}}
{"id": "89f04698b1df42a6a573a86c1d103e76", "source": "vatex", "video_id": "MyIecl0syug_000073_000083", "video_description": "A group of people, including children, are playing and sledding in a snow-filled hilly field. Some are carrying sleds, while others are sledding down a hill. The scene is outdoors in a park with snow covering the ground.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a hill in a snow-filled park.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "hill"}, "target_prompt": "A person closer to the camera than a hill in a snow-filled park.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "hill"}, "evaluation_question": "Is the person **farther from the camera than** the hill?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person farther from the camera than a hill in a snow-filled park. >TZ\u00b7X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4cc03549570843af9f9d85d517a82429.mp4", "clean_score": 1.0, "clean_xclip": 0.18479567766189575, "clean_vbench": {"subject_consistency": 0.9833079483360052, "background_consistency": 0.9330698649088541, "motion_smoothness": 0.9901096813725491, "aesthetic_quality": 0.6686204075813293, "imaging_quality": 0.7884549977828046, "dynamic_degree": 0.0}, "adv_vid_id": "vids/b2dddcb1ce9548eb879b31f7ff77812b.mp4", "adv_score": 0.0, "adv_xclip": 0.19034528732299805, "adv_vbench": {"subject_consistency": 0.9946436925480763, "background_consistency": 0.9706217447916666, "motion_smoothness": 0.9884549588225208, "aesthetic_quality": 0.6938205361366272, "imaging_quality": 0.7523877435800981, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f6b6a7e2.mp4", "clean_score": 0.0, "clean_xclip": 0.19799590110778809, "clean_vbench": {}, "adv_vid_id": "vids/b3cde893.mp4", "adv_score": 0.0, "adv_xclip": 0.17155537009239197, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5da8c81e.mp4", "clean_score": 1.0, "clean_xclip": 0.1537580043077469, "clean_vbench": {}, "adv_vid_id": "vids/d01c1ab8.mp4", "adv_score": 0.0, "adv_xclip": 0.19765116274356842, "adv_vbench": {}}}}
{"id": "22cdef56eb124ebabd52f07a5f941d99", "source": "vatex", "video_id": "P6XFADT0ZCE_000026_000036", "video_description": "People are playing disc golf in a forest, throwing frisbees into chain baskets.", "task": "Counting", "clean_prompt": "Three baskets are set up in a forest where people are playing disc golf, throwing frisbees into the chain baskets.", "clean_property": {"obj": "basket", "count": "three"}, "target_prompt": "One basket is set up in a forest where people are playing disc golf, throwing frisbees into the chain basket.", "target_property": {"obj": "basket", "count": "one"}, "evaluation_question": "Are there exactly **three** baskets in the forest?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three baskets are set up in a forest where people are playing disc golf, throwing frisbees into the chain baskets.anniversaire Nutzen hammock craftsmanship profiter", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/052c2a11107546c2b62bbcbaa4476db9.mp4", "clean_score": 1.0, "clean_xclip": 0.201054647564888, "clean_vbench": {"subject_consistency": 0.9086991095294555, "background_consistency": 0.915191650390625, "motion_smoothness": 0.9752107611466654, "aesthetic_quality": 0.4862203001976013, "imaging_quality": 0.683443678252551, "dynamic_degree": 0.0}, "adv_vid_id": "vids/576aa3f09087469489d772315a8b5b72.mp4", "adv_score": 0.0, "adv_xclip": 0.16104014217853546, "adv_vbench": {"subject_consistency": 0.9493808497985204, "background_consistency": 0.9662679036458334, "motion_smoothness": 0.97782451503621, "aesthetic_quality": 0.5715387463569641, "imaging_quality": 0.7624394615329042, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/de59eb50.mp4", "clean_score": 0.0, "clean_xclip": 0.20462509989738464, "clean_vbench": {}, "adv_vid_id": "vids/3b7c2e69.mp4", "adv_score": 0.0, "adv_xclip": 0.15307287871837616, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/08079eeb.mp4", "clean_score": 1.0, "clean_xclip": 0.23949111998081207, "clean_vbench": {}, "adv_vid_id": "vids/b875d4ba.mp4", "adv_score": 0.0, "adv_xclip": 0.14305782318115234, "adv_vbench": {}}}}
{"id": "8d10052be5674c07ac91121d0e2dddbb", "source": "vatex", "video_id": "XXQZz6FuEYI_000183_000193", "video_description": "A man is in a gym demonstrating exercises using a sledgehammer, swinging it behind and in front of him.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer in a gym.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": null}, "target_prompt": "A person lifting a sledgehammer in a gym.", "target_property": {"obj": "person", "action": "lifting a sledgehammer", "target": null}, "evaluation_question": "Is the person **using** a sledgehammer?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person using a sledgehammer in a gym. Entspannungvoller cadou gratuiteeinrichtung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/216ce2c34b024c7d927f3582aa763104.mp4", "clean_score": 1.0, "clean_xclip": 0.10628841817378998, "clean_vbench": {"subject_consistency": 0.9229966886341572, "background_consistency": 0.937042236328125, "motion_smoothness": 0.9580262484366174, "aesthetic_quality": 0.4031575322151184, "imaging_quality": 0.5390656124815649, "dynamic_degree": 1.0}, "adv_vid_id": "vids/428575d7ba0f45bbb06817934e4dee2f.mp4", "adv_score": 0.0, "adv_xclip": 0.1138022318482399, "adv_vbench": {"subject_consistency": 0.886089169109861, "background_consistency": 0.9479573567708334, "motion_smoothness": 0.9549960880764342, "aesthetic_quality": 0.4247485101222992, "imaging_quality": 0.5036708099988042, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/056426ec.mp4", "clean_score": 1.0, "clean_xclip": 0.12553028762340546, "clean_vbench": {}, "adv_vid_id": "vids/693a96b9.mp4", "adv_score": 1.0, "adv_xclip": 0.12832805514335632, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a809ee2b.mp4", "clean_score": 1.0, "clean_xclip": 0.12990400195121765, "clean_vbench": {}, "adv_vid_id": "vids/f68fb319.mp4", "adv_score": 1.0, "adv_xclip": 0.06306183338165283, "adv_vbench": {}}}}
{"id": "1d5dd51d78334398ab0c5d2d7cd09614", "source": "vatex", "video_id": "Xbg8y5fHOQw_000065_000075", "video_description": "A young woman is seated, talking on her cell phone while adjusting and playing with her hair.", "task": "Counting", "clean_prompt": "Two people are seated, with one talking on her cell phone while adjusting and playing with her hair.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is seated, talking on her cell phone while adjusting and playing with her hair.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people seated?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two people are seated, with one talking on her cell phone while adjusting and playing with her hair. !0D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6eeb82ed92ea4ece88a8e9b255a66708.mp4", "clean_score": 1.0, "clean_xclip": 0.19447949528694153, "clean_vbench": {"subject_consistency": 0.87006108276546, "background_consistency": 0.9182891845703125, "motion_smoothness": 0.9590980127390463, "aesthetic_quality": 0.46036607027053833, "imaging_quality": 0.5206638842212911, "dynamic_degree": 1.0}, "adv_vid_id": "vids/00b0901494ea48d5adf6bf009b62be33.mp4", "adv_score": 0.0, "adv_xclip": 0.1607973277568817, "adv_vbench": {"subject_consistency": 0.9283632325629393, "background_consistency": 0.9398040771484375, "motion_smoothness": 0.9500019170348181, "aesthetic_quality": 0.45532000064849854, "imaging_quality": 0.6614747432786591, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bebbc65d.mp4", "clean_score": 1.0, "clean_xclip": 0.18280157446861267, "clean_vbench": {}, "adv_vid_id": "vids/b91b2a32.mp4", "adv_score": 1.0, "adv_xclip": 0.20105017721652985, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/372e5e86.mp4", "clean_score": 1.0, "clean_xclip": 0.1547856479883194, "clean_vbench": {}, "adv_vid_id": "vids/1887d740.mp4", "adv_score": 1.0, "adv_xclip": 0.1883033812046051, "adv_vbench": {}}}}
{"id": "7a16cf59dee34b5988dc92a3b7862137", "source": "vatex", "video_id": "r4sYfEcGrgg_000004_000014", "video_description": "A female athlete is participating in a javelin throw event at an outdoor track. She runs and throws the javelin with force while a group of people watches.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the left of a javelin.", "clean_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "javelin"}, "target_prompt": "An athlete standing to the right of a javelin.", "target_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "javelin"}, "evaluation_question": "Is the athlete to the **left** of the javelin?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An athlete standing to the left of a javelin. francophone schwerstoffe Grau bearbeitet", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/39eaa741635348fd909b313b890ebc6d.mp4", "clean_score": 1.0, "clean_xclip": 0.16777874529361725, "clean_vbench": {"subject_consistency": 0.9485111758112907, "background_consistency": 0.9692331949869791, "motion_smoothness": 0.9938784342408518, "aesthetic_quality": 0.3467642366886139, "imaging_quality": 0.6008430846856565, "dynamic_degree": 0.0}, "adv_vid_id": "vids/97f9bad6ec184410b6d4e255faaf4364.mp4", "adv_score": 0.0, "adv_xclip": 0.10359662026166916, "adv_vbench": {"subject_consistency": 0.9566665614644686, "background_consistency": 0.92437744140625, "motion_smoothness": 0.9941514504785968, "aesthetic_quality": 0.34977394342422485, "imaging_quality": 0.5192533173853038, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/895ff932.mp4", "clean_score": 1.0, "clean_xclip": 0.18076127767562866, "clean_vbench": {}, "adv_vid_id": "vids/050647b2.mp4", "adv_score": 0.0, "adv_xclip": 0.14597810804843903, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/25d6c59f.mp4", "clean_score": 0.0, "clean_xclip": 0.1810167133808136, "clean_vbench": {}, "adv_vid_id": "vids/1f67c65a.mp4", "adv_score": 0.0, "adv_xclip": 0.1759752780199051, "adv_vbench": {}}}}
{"id": "0ebcad6380d94d98a4e28dab59aa1bed", "source": "vatex", "video_id": "5ILkwhgwtkQ_000120_000130", "video_description": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "clean_property": {"obj": "paper airplane"}, "target_prompt": "A young boy is sitting on the floor of a bedroom, folding a colorful piece of paper into a kite while music plays in the background.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object being folded in the video a **paper airplane**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.technischen categoria Ratingbewertungen Farben", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/209a9aca22b749e498a4a754e3336ad9.mp4", "clean_score": 1.0, "clean_xclip": 0.17803120613098145, "clean_vbench": {"subject_consistency": 0.937223511437575, "background_consistency": 0.9502614339192709, "motion_smoothness": 0.9718316895752642, "aesthetic_quality": 0.5695932507514954, "imaging_quality": 0.6846851411157725, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1938e73289ea4c439ea313f45f364bde.mp4", "adv_score": 0.0, "adv_xclip": 0.16249656677246094, "adv_vbench": {"subject_consistency": 0.9408892833938202, "background_consistency": 0.9430135091145834, "motion_smoothness": 0.9777469871790022, "aesthetic_quality": 0.47009626030921936, "imaging_quality": 0.7319278950593909, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7d46d429.mp4", "clean_score": 1.0, "clean_xclip": 0.23464523255825043, "clean_vbench": {}, "adv_vid_id": "vids/6ce8e33a.mp4", "adv_score": 0.0, "adv_xclip": 0.20257413387298584, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/202415da.mp4", "clean_score": 1.0, "clean_xclip": 0.1987985223531723, "clean_vbench": {}, "adv_vid_id": "vids/8d017981.mp4", "adv_score": 1.0, "adv_xclip": 0.22670358419418335, "adv_vbench": {}}}}
{"id": "07ef7a4b828543328eebe4cc8b2294c1", "source": "vatex", "video_id": "bYpmfSES8x4_000004_000014", "video_description": "A man is performing weightlifting exercises, including back squats and deadlifts, with several spotters assisting him in a gym setting.", "task": "Counting", "clean_prompt": "Four weightlifters performing back squats and deadlifts in a gym, with spotters assisting them.", "clean_property": {"obj": "weightlifter", "count": "four"}, "target_prompt": "One weightlifter performing a deadlift in a gym, without any spotters.", "target_property": {"obj": "weightlifter", "count": "one"}, "evaluation_question": "Are there exactly **four** weightlifters in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Four weightlifters performing back squats and deadlifts in a gym, with spotters assisting them. gourmand Gastgeber Mondialschiff accompagn", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8d16c6a8bfa4043af759a36b137d962.mp4", "clean_score": 1.0, "clean_xclip": 0.1502150595188141, "clean_vbench": {"subject_consistency": 0.9721853006631136, "background_consistency": 0.9698130289713541, "motion_smoothness": 0.9797893592590071, "aesthetic_quality": 0.5872688889503479, "imaging_quality": 0.6566582598005023, "dynamic_degree": 1.0}, "adv_vid_id": "vids/68c7cfa290a34a24a9ed19afaf28cd19.mp4", "adv_score": 0.0, "adv_xclip": 0.1652359962463379, "adv_vbench": {"subject_consistency": 0.9615334824969372, "background_consistency": 0.9451446533203125, "motion_smoothness": 0.975735217839708, "aesthetic_quality": 0.5691972970962524, "imaging_quality": 0.7371457002600844, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5719fec5.mp4", "clean_score": 0.0, "clean_xclip": 0.19210124015808105, "clean_vbench": {}, "adv_vid_id": "vids/2701c232.mp4", "adv_score": 1.0, "adv_xclip": 0.1771421581506729, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e07de392.mp4", "clean_score": 0.0, "clean_xclip": 0.16936811804771423, "clean_vbench": {}, "adv_vid_id": "vids/b968e20a.mp4", "adv_score": 0.0, "adv_xclip": 0.19384104013442993, "adv_vbench": {}}}}
{"id": "b8b6d7223a5f47c2a791ce50abba8f59", "source": "vatex", "video_id": "O0sdVwdE-lM_000006_000016", "video_description": "A man is sitting at a table, using an inhaler after receiving it from a woman speaking a foreign language. He is being instructed on how to use it properly.", "task": "ActionRecognition", "clean_prompt": "A man using an inhaler at a table.", "clean_property": {"obj": "man", "action": "using inhaler", "target": null}, "target_prompt": "A man throwing an inhaler at a table.", "target_property": {"obj": "man", "action": "throwing inhaler", "target": null}, "evaluation_question": "Is the man **using** an inhaler?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man using an inhaler at a table. ))\u00b7TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6d95cb01ff57426987f8ed72d43ed0b4.mp4", "clean_score": 1.0, "clean_xclip": 0.15639981627464294, "clean_vbench": {"subject_consistency": 0.985529358809193, "background_consistency": 0.9689534505208334, "motion_smoothness": 0.9949100043245178, "aesthetic_quality": 0.46514105796813965, "imaging_quality": 0.7209439740862165, "dynamic_degree": 0.0}, "adv_vid_id": "vids/c9cb0c07450f410093dfbcf9bb8b4ca2.mp4", "adv_score": 0.0, "adv_xclip": 0.1633433848619461, "adv_vbench": {"subject_consistency": 0.9940683872749408, "background_consistency": 0.9716898600260416, "motion_smoothness": 0.9955585571870209, "aesthetic_quality": 0.44298744201660156, "imaging_quality": 0.6944986942836217, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/82e0115c.mp4", "clean_score": 1.0, "clean_xclip": 0.22188672423362732, "clean_vbench": {}, "adv_vid_id": "vids/2fb46bfd.mp4", "adv_score": 1.0, "adv_xclip": 0.22998374700546265, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7228384f.mp4", "clean_score": 1.0, "clean_xclip": 0.176077201962471, "clean_vbench": {}, "adv_vid_id": "vids/e6cbf6f1.mp4", "adv_score": 1.0, "adv_xclip": 0.22473755478858948, "adv_vbench": {}}}}
{"id": "51902b08bdb24b7da4abbc5e9b121f8b", "source": "vatex", "video_id": "7FMweTGNlJ0_000000_000010", "video_description": "A man is swimming in a large indoor pool, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "task": "Counting", "clean_prompt": "A man is swimming in a large indoor pool with two lanes, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "clean_property": {"obj": "pool", "count": "two"}, "target_prompt": "A man is swimming in a large indoor pool with one lane, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "target_property": {"obj": "pool", "count": "one"}, "evaluation_question": "Are there exactly **two** lanes in the pool?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is swimming in a large indoor pool with two lanes, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool. FE2XJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f9b0985b6c844a5dbc19ad4570dc79b4.mp4", "clean_score": 1.0, "clean_xclip": 0.13322462141513824, "clean_vbench": {"subject_consistency": 0.8940055947750807, "background_consistency": 0.9430338541666666, "motion_smoothness": 0.9832730463391632, "aesthetic_quality": 0.41265881061553955, "imaging_quality": 0.4574643458152304, "dynamic_degree": 0.0}, "adv_vid_id": "vids/b6d3ba1946b44244864a781b247c7aa2.mp4", "adv_score": 0.0, "adv_xclip": 0.1666254699230194, "adv_vbench": {"subject_consistency": 0.8628103292236725, "background_consistency": 0.9156138102213541, "motion_smoothness": 0.9795105441642964, "aesthetic_quality": 0.45832473039627075, "imaging_quality": 0.5017173525751853, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5421af6a.mp4", "clean_score": 0.0, "clean_xclip": 0.15246132016181946, "clean_vbench": {}, "adv_vid_id": "vids/06d273e4.mp4", "adv_score": 0.0, "adv_xclip": 0.1392149031162262, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/202ca616.mp4", "clean_score": 0.0, "clean_xclip": 0.16671249270439148, "clean_vbench": {}, "adv_vid_id": "vids/26679ad6.mp4", "adv_score": 0.0, "adv_xclip": 0.15645375847816467, "adv_vbench": {}}}}
{"id": "8101898763384fc7bae542374ff028f7", "source": "vatex", "video_id": "s15QnL6P2JM_000071_000081", "video_description": "Four people, including three men and a woman, are on stage at an award ceremony accepting an award. The audience is clapping and applauding as one of the recipients speaks with gratitude.", "task": "ActionRecognition", "clean_prompt": "An award recipient giving a speech while receiving an award on stage.", "clean_property": {"obj": "award recipient", "action": "giving or receiving award", "target": "award"}, "target_prompt": "An award recipient rejecting an award on stage.", "target_property": {"obj": "award recipient", "action": "rejecting award", "target": "award"}, "evaluation_question": "Is the award recipient **giving** or **receiving** an award?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An award recipient giving a speech while receiving an award on stage. Kardashian adjective Absolut Teig Keller", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/beaf3f10b94341269e6bd442160727bd.mp4", "clean_score": 1.0, "clean_xclip": 0.21905657649040222, "clean_vbench": {"subject_consistency": 0.9580142814666033, "background_consistency": 0.9476877848307291, "motion_smoothness": 0.99293707133059, "aesthetic_quality": 0.48564329743385315, "imaging_quality": 0.5900402076876893, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5038935ec3a6488b85c72127bf7c98a4.mp4", "adv_score": 0.0, "adv_xclip": 0.21326729655265808, "adv_vbench": {"subject_consistency": 0.972492586200436, "background_consistency": 0.9590403238932291, "motion_smoothness": 0.9953745134917392, "aesthetic_quality": 0.5241707563400269, "imaging_quality": 0.47425312353640187, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/95f67cf5.mp4", "clean_score": 1.0, "clean_xclip": 0.22083182632923126, "clean_vbench": {}, "adv_vid_id": "vids/6ef4eed9.mp4", "adv_score": 0.0, "adv_xclip": 0.13117796182632446, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a2697e57.mp4", "clean_score": 1.0, "clean_xclip": 0.221267431974411, "clean_vbench": {}, "adv_vid_id": "vids/2988ce15.mp4", "adv_score": 1.0, "adv_xclip": 0.19050702452659607, "adv_vbench": {}}}}
{"id": "075411fd75a141c095b1cf3bf5eeb04a", "source": "vatex", "video_id": "cbznHY8uOOE_000006_000016", "video_description": "A man is demonstrating and explaining how to perform exercises using an exercise ball, including balancing and pull-ins.", "task": "SpatialUnderstanding", "clean_prompt": "A person demonstrating exercises with an exercise ball, which is positioned to the right of him.", "clean_property": {"obj_1": "exercise ball", "relation": "right of", "obj_2": "person"}, "target_prompt": "A person demonstrating exercises with an exercise ball, which is positioned to the left of him.", "target_property": {"obj_1": "exercise ball", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the exercise ball to the **right** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating exercises with an exercise ball, which is positioned to the right of him. LYC1S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d19b984df21a423bb894bba439348bc0.mp4", "clean_score": 1.0, "clean_xclip": 0.23145249485969543, "clean_vbench": {"subject_consistency": 0.9841888900846243, "background_consistency": 0.9837086995442709, "motion_smoothness": 0.9908319121051198, "aesthetic_quality": 0.5337122082710266, "imaging_quality": 0.6714986435247927, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4d17e4b991a64277bb5dbfd2db796bef.mp4", "adv_score": 0.0, "adv_xclip": 0.18634244799613953, "adv_vbench": {"subject_consistency": 0.8730715879549583, "background_consistency": 0.9288330078125, "motion_smoothness": 0.9776210716861333, "aesthetic_quality": 0.6101544499397278, "imaging_quality": 0.47950941747548625, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/20e1caca.mp4", "clean_score": 1.0, "clean_xclip": 0.16647027432918549, "clean_vbench": {}, "adv_vid_id": "vids/72fc5d1e.mp4", "adv_score": 0.0, "adv_xclip": 0.19115228950977325, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8e319e8f.mp4", "clean_score": 1.0, "clean_xclip": 0.21434131264686584, "clean_vbench": {}, "adv_vid_id": "vids/09256322.mp4", "adv_score": 1.0, "adv_xclip": 0.13567575812339783, "adv_vbench": {}}}}
{"id": "94b2852c3df442afb3120189397c094f", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "ActionRecognition", "clean_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "clean_property": {"obj": "person", "action": "playing laser tag", "target": null}, "target_prompt": "A person watching a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "target_property": {"obj": "person", "action": "watching a laser tag game", "target": null}, "evaluation_question": "Is the person **playing** laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain. )-R%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fde956fb236b45e8af53bc6589c41d29.mp4", "clean_score": 1.0, "clean_xclip": 0.24105766415596008, "clean_vbench": {"subject_consistency": 0.927732652053237, "background_consistency": 0.9335784912109375, "motion_smoothness": 0.9521597340421508, "aesthetic_quality": 0.34579282999038696, "imaging_quality": 0.6296553514441665, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7b6eeb83c2594e1f82787f770d430f5b.mp4", "adv_score": 0.0, "adv_xclip": 0.23137898743152618, "adv_vbench": {"subject_consistency": 0.9298057146370411, "background_consistency": 0.92608642578125, "motion_smoothness": 0.9525458532853729, "aesthetic_quality": 0.40570589900016785, "imaging_quality": 0.7000792406043227, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7fe03b72.mp4", "clean_score": 1.0, "clean_xclip": 0.21967515349388123, "clean_vbench": {}, "adv_vid_id": "vids/7e30ce1a.mp4", "adv_score": 1.0, "adv_xclip": 0.21989646553993225, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/86554bef.mp4", "clean_score": 1.0, "clean_xclip": 0.21781688928604126, "clean_vbench": {}, "adv_vid_id": "vids/732c8cf4.mp4", "adv_score": 1.0, "adv_xclip": 0.23166310787200928, "adv_vbench": {}}}}
{"id": "1233c6dfbbf4437184f1ed9ade3b964f", "source": "vatex", "video_id": "zUempCKuG_c_000000_000010", "video_description": "A young woman is outside, blowing bubbles with bubble gum while interacting with a tablet.", "task": "ActionRecognition", "clean_prompt": "A person looking at their phone outside.", "clean_property": {"obj": "person", "action": "looking at phone", "target": null}, "target_prompt": "A person playing with bubbles outside.", "target_property": {"obj": "person", "action": "playing with bubbles", "target": null}, "evaluation_question": "Is the person **looking at their phone**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person looking at their phone outside. )!0/P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a60f956a5914ffba9f4c5cde3b76d8a.mp4", "clean_score": 1.0, "clean_xclip": 0.13671116530895233, "clean_vbench": {"subject_consistency": 0.8792864717543125, "background_consistency": 0.95587158203125, "motion_smoothness": 0.9886555737424857, "aesthetic_quality": 0.32081249356269836, "imaging_quality": 0.34781141942861127, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3bfc996fab7845e18717a4a0e08e7475.mp4", "adv_score": 0.0, "adv_xclip": 0.172932967543602, "adv_vbench": {"subject_consistency": 0.9796738090614477, "background_consistency": 0.9876861572265625, "motion_smoothness": 0.9935700644390987, "aesthetic_quality": 0.4169871509075165, "imaging_quality": 0.37406709943498884, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bb356485.mp4", "clean_score": 1.0, "clean_xclip": 0.15237218141555786, "clean_vbench": {}, "adv_vid_id": "vids/33124cad.mp4", "adv_score": 1.0, "adv_xclip": 0.14484289288520813, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/adbc98bf.mp4", "clean_score": 0.0, "clean_xclip": 0.16880634427070618, "clean_vbench": {}, "adv_vid_id": "vids/ee3ffc68.mp4", "adv_score": 1.0, "adv_xclip": 0.17117638885974884, "adv_vbench": {}}}}
{"id": "a6e0802ee5804da8a1572532263d15f3", "source": "vatex", "video_id": "ekrSZOUarzU_000000_000010", "video_description": "A man is demonstrating the use of a corded electric drill, including adjustments and challenges, while a narrator provides commentary.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating the use of a corded electric drill, making adjustments and facing challenges, while a narrator provides commentary.", "clean_property": {"obj": "drill"}, "target_prompt": "A man demonstrating the use of a screwdriver, making adjustments and facing challenges, while a narrator provides commentary.", "target_property": {"obj": "screwdriver"}, "evaluation_question": "Is the tool being demonstrated in the video a **drill**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating the use of a corded electric drill, making adjustments and facing challenges, while a narrator provides commentary. FEYE$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/456c2cea1915431cbdee4b6cfe63a107.mp4", "clean_score": 1.0, "clean_xclip": 0.11858728528022766, "clean_vbench": {"subject_consistency": 0.895265985901157, "background_consistency": 0.9515126546223959, "motion_smoothness": 0.9620706820697672, "aesthetic_quality": 0.32385334372520447, "imaging_quality": 0.5125180660948462, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4d8ed84a333b4a37bb34b48a32ac25ef.mp4", "adv_score": 0.0, "adv_xclip": 0.12264648079872131, "adv_vbench": {"subject_consistency": 0.9453284181654453, "background_consistency": 0.970458984375, "motion_smoothness": 0.9737677350936517, "aesthetic_quality": 0.455639511346817, "imaging_quality": 0.7291030821508291, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/adb2c7e0.mp4", "clean_score": 0.0, "clean_xclip": 0.15891589224338531, "clean_vbench": {}, "adv_vid_id": "vids/c1178cfe.mp4", "adv_score": 1.0, "adv_xclip": 0.1672745645046234, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/df5baeb0.mp4", "clean_score": 1.0, "clean_xclip": 0.17326752841472626, "clean_vbench": {}, "adv_vid_id": "vids/e49e9c41.mp4", "adv_score": 1.0, "adv_xclip": 0.1372269093990326, "adv_vbench": {}}}}
{"id": "13d25e5d9b6a4052a8935e1d6b53e024", "source": "vatex", "video_id": "B5K_x2cDYfM_000026_000036", "video_description": "A woman wearing headphones and a cocktail dress plays the clarinet in front of a changing background, including a sky with moving clouds.", "task": "ActionRecognition", "clean_prompt": "A person playing clarinet in front of a changing background.", "clean_property": {"obj": "person", "action": "playing clarinet", "target": null}, "target_prompt": "A person playing guitar in front of a changing background.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing clarinet**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person playing clarinet in front of a changing background. ))!%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/28817cf170154d44927811b65302f2d9.mp4", "clean_score": 1.0, "clean_xclip": 0.13771609961986542, "clean_vbench": {"subject_consistency": 0.9213975512733062, "background_consistency": 0.9442545572916666, "motion_smoothness": 0.9496206740637356, "aesthetic_quality": 0.3199043869972229, "imaging_quality": 0.3146473324055574, "dynamic_degree": 1.0}, "adv_vid_id": "vids/13aa9cf63d914c73a1df5813e4d54d22.mp4", "adv_score": 0.0, "adv_xclip": 0.2502259314060211, "adv_vbench": {"subject_consistency": 0.87874078626434, "background_consistency": 0.9183247884114584, "motion_smoothness": 0.9341124390406883, "aesthetic_quality": 0.3639947175979614, "imaging_quality": 0.4129735063046825, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/41bc62fa.mp4", "clean_score": 0.0, "clean_xclip": 0.17774510383605957, "clean_vbench": {}, "adv_vid_id": "vids/f47bea9c.mp4", "adv_score": 0.0, "adv_xclip": 0.20004647970199585, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/22173512.mp4", "clean_score": 0.0, "clean_xclip": 0.21133576333522797, "clean_vbench": {}, "adv_vid_id": "vids/f43ae6c5.mp4", "adv_score": 0.0, "adv_xclip": 0.21346715092658997, "adv_vbench": {}}}}
{"id": "6d907497fbfd4078ab9ecc41c87331d3", "source": "vatex", "video_id": "V4ynfFv-EqE_000021_000031", "video_description": "A bald man in a white shirt is beatboxing and dancing in a colorful, well-lit room, possibly a television show stage, while holding a microphone.", "task": "ActionRecognition", "clean_prompt": "A person beatboxing and dancing in a colorful, well-lit room.", "clean_property": {"obj": "person", "action": "beatboxing", "target": null}, "target_prompt": "A person singing a song in a colorful, well-lit room.", "target_property": {"obj": "person", "action": "singing", "target": "song"}, "evaluation_question": "Is the person **beatboxing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person beatboxing and dancing in a colorful, well-lit room. )!U=B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/669838898baa47f39cd59d9fafb81df9.mp4", "clean_score": 1.0, "clean_xclip": 0.19299735128879547, "clean_vbench": {"subject_consistency": 0.8941052928566933, "background_consistency": 0.8932851155598959, "motion_smoothness": 0.9400143988794077, "aesthetic_quality": 0.4017404019832611, "imaging_quality": 0.33638518352897795, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2e0ff0cbd5194bdab011a63c3721ba35.mp4", "adv_score": 0.0, "adv_xclip": 0.2358970195055008, "adv_vbench": {"subject_consistency": 0.9255784458170334, "background_consistency": 0.9270426432291666, "motion_smoothness": 0.9515935482732187, "aesthetic_quality": 0.45684146881103516, "imaging_quality": 0.37066081261148254, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b767b529.mp4", "clean_score": 0.0, "clean_xclip": 0.19100463390350342, "clean_vbench": {}, "adv_vid_id": "vids/8586808d.mp4", "adv_score": 0.0, "adv_xclip": 0.16434946656227112, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/223c1340.mp4", "clean_score": 1.0, "clean_xclip": 0.20976032316684723, "clean_vbench": {}, "adv_vid_id": "vids/e2439d33.mp4", "adv_score": 0.0, "adv_xclip": 0.23348590731620789, "adv_vbench": {}}}}
{"id": "d43f8fc335454863af51cb2c487f470d", "source": "vatex", "video_id": "meL-J5bKds8_000106_000116", "video_description": "A man in a suit, who is a magician, demonstrates how to create various shapes and tricks using twisty balloons in a room.", "task": "AttributeRecognition", "clean_prompt": "A magician in a suit demonstrating tricks with a twisty balloon.", "clean_property": {"obj": "balloon", "attribute": "twisty"}, "target_prompt": "A magician in a suit demonstrating tricks with a round balloon.", "target_property": {"obj": "balloon", "attribute": "round"}, "evaluation_question": "Is the magician demonstrating tricks with a **twisty** balloon?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A magician in a suit demonstrating tricks with a twisty balloon. Frauengruppe Schatten comunist caci", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5f922172ad6b4f1195e7ee38367aed9a.mp4", "clean_score": 1.0, "clean_xclip": 0.2377062439918518, "clean_vbench": {"subject_consistency": 0.9049219929923614, "background_consistency": 0.9261576334635416, "motion_smoothness": 0.9212618889569717, "aesthetic_quality": 0.489962637424469, "imaging_quality": 0.5605986910450216, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a1aa970687e945ec973bc020b94decc3.mp4", "adv_score": 0.0, "adv_xclip": 0.1985308676958084, "adv_vbench": {"subject_consistency": 0.7846219760055343, "background_consistency": 0.8677266438802084, "motion_smoothness": 0.9243466115259118, "aesthetic_quality": 0.4514673054218292, "imaging_quality": 0.411851751755695, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ab0cacda.mp4", "clean_score": 0.0, "clean_xclip": 0.22960606217384338, "clean_vbench": {}, "adv_vid_id": "vids/26886905.mp4", "adv_score": 0.0, "adv_xclip": 0.1974174678325653, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/15199732.mp4", "clean_score": 0.0, "clean_xclip": 0.2506881356239319, "clean_vbench": {}, "adv_vid_id": "vids/2cdee13e.mp4", "adv_score": 0.0, "adv_xclip": 0.1843673288822174, "adv_vbench": {}}}}
{"id": "049a19447e8b42828448c05b7d867110", "source": "vatex", "video_id": "8hwt4z7alvw_000055_000065", "video_description": "A young man is beatboxing into a microphone in a white room, making musical noises with his mouth and throat while looking into the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone closer to the camera than a person beatboxing in a white room.", "clean_property": {"obj_1": "microphone", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A microphone further from the camera than a person beatboxing in a white room.", "target_property": {"obj_1": "microphone", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the microphone closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A microphone closer to the camera than a person beatboxing in a white room. SchmAlpes donner cinq frunze", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/339098bf17d24985a14181db87a04d0b.mp4", "clean_score": 1.0, "clean_xclip": 0.2055174708366394, "clean_vbench": {"subject_consistency": 0.7983652967959642, "background_consistency": 0.9221598307291666, "motion_smoothness": 0.977142278214012, "aesthetic_quality": 0.24027641117572784, "imaging_quality": 0.23222845544620438, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a6febdf1c554435b8f55753571930780.mp4", "adv_score": 0.0, "adv_xclip": 0.08496396988630295, "adv_vbench": {"subject_consistency": 0.994184548035264, "background_consistency": 0.9887746175130209, "motion_smoothness": 0.9961587181586884, "aesthetic_quality": 0.43530547618865967, "imaging_quality": 0.4882143090695751, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9f0afe5c.mp4", "clean_score": 0.0, "clean_xclip": 0.20047563314437866, "clean_vbench": {}, "adv_vid_id": "vids/1a6ea473.mp4", "adv_score": 1.0, "adv_xclip": 0.19574736058712006, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dec3fa04.mp4", "clean_score": 1.0, "clean_xclip": 0.13192473351955414, "clean_vbench": {}, "adv_vid_id": "vids/8a9a24a2.mp4", "adv_score": 1.0, "adv_xclip": 0.19321802258491516, "adv_vbench": {}}}}
{"id": "3968f7731d32430d9d87aef0dc457076", "source": "vatex", "video_id": "ZI3YTbXNaUY_000035_000045", "video_description": "A woman is vacuuming a tile floor while wearing high heel shoes.", "task": "ObjectRecognition", "clean_prompt": "A woman is vacuuming a tile floor while wearing high heel shoes.", "clean_property": {"obj": "vacuum"}, "target_prompt": "A woman is sweeping a tile floor while wearing high heel shoes.", "target_property": {"obj": "broom"}, "evaluation_question": "Is the woman using a **vacuum** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman is vacuuming a tile floor while wearing high heel shoes. texturesLizenz Christie junge Fotografi", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2ded5ff7761940d3aab876cd1f96cce8.mp4", "clean_score": 1.0, "clean_xclip": 0.20428748428821564, "clean_vbench": {"subject_consistency": 0.9240184997518858, "background_consistency": 0.9369557698567709, "motion_smoothness": 0.9726221389468853, "aesthetic_quality": 0.4547657072544098, "imaging_quality": 0.5477141438698282, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9e6d80e91b394de9a091b99abb68950c.mp4", "adv_score": 0.0, "adv_xclip": 0.18501964211463928, "adv_vbench": {"subject_consistency": 0.9182990957051516, "background_consistency": 0.91827392578125, "motion_smoothness": 0.94972390758644, "aesthetic_quality": 0.3870849907398224, "imaging_quality": 0.5549051728540537, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ebd7cc85.mp4", "clean_score": 1.0, "clean_xclip": 0.24627457559108734, "clean_vbench": {}, "adv_vid_id": "vids/8db78698.mp4", "adv_score": 1.0, "adv_xclip": 0.237156480550766, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/07c346f6.mp4", "clean_score": 1.0, "clean_xclip": 0.25308576226234436, "clean_vbench": {}, "adv_vid_id": "vids/559f843f.mp4", "adv_score": 1.0, "adv_xclip": 0.21176092326641083, "adv_vbench": {}}}}
{"id": "79a5757841b641868874bd71f29d23fb", "source": "vatex", "video_id": "aXzZfGsfSWQ_000004_000014", "video_description": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility, while a man talks and a cameraman records.", "task": "AttributeRecognition", "clean_prompt": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility.", "clean_property": {"obj": "woman", "attribute": "wearing animal ears and tail"}, "target_prompt": "A woman wearing a superhero costume bends backwards, demonstrating flexibility.", "target_property": {"obj": "woman", "attribute": "wearing a superhero costume"}, "evaluation_question": "Is the woman wearing a costume with **animal ears and tail**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility. Femme noutenue superhero Pentru", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0925eac981bf4a63902dc59608a74716.mp4", "clean_score": 1.0, "clean_xclip": 0.10837230086326599, "clean_vbench": {"subject_consistency": 0.8158826101571321, "background_consistency": 0.9254811604817709, "motion_smoothness": 0.9626421816057956, "aesthetic_quality": 0.41161587834358215, "imaging_quality": 0.429375855582101, "dynamic_degree": 1.0}, "adv_vid_id": "vids/da7b640ff7f54ea6a9f0e0db948ac386.mp4", "adv_score": 0.0, "adv_xclip": 0.1328997015953064, "adv_vbench": {"subject_consistency": 0.8864675058672825, "background_consistency": 0.9445902506510416, "motion_smoothness": 0.9853080096879288, "aesthetic_quality": 0.41930726170539856, "imaging_quality": 0.6279047572856047, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7758c0e4.mp4", "clean_score": 1.0, "clean_xclip": 0.15656079351902008, "clean_vbench": {}, "adv_vid_id": "vids/62734a52.mp4", "adv_score": 1.0, "adv_xclip": 0.13950146734714508, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/08be52f1.mp4", "clean_score": 1.0, "clean_xclip": 0.1338910460472107, "clean_vbench": {}, "adv_vid_id": "vids/cec9cfff.mp4", "adv_score": 0.0, "adv_xclip": 0.0948643684387207, "adv_vbench": {}}}}
{"id": "51e360fa4acc47fd8eeeafaa24ed1136", "source": "vatex", "video_id": "-cqADbIiZ1Q_000129_000139", "video_description": "A baseball game is in progress with a pitcher pitching a softball underhand to a batter and a catcher in an orange uniform. An umpire is present behind home base.", "task": "SpatialUnderstanding", "clean_prompt": "An umpire standing to the left of a pitcher during a baseball game.", "clean_property": {"obj_1": "umpire", "relation": "left of", "obj_2": "pitcher"}, "target_prompt": "An umpire standing to the right of a pitcher during a baseball game.", "target_property": {"obj_1": "umpire", "relation": "right of", "obj_2": "pitcher"}, "evaluation_question": "Is the umpire to the **left** of the pitcher?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "An umpire standing to the left of a pitcher during a baseball game. ;D$XS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/846ea22e02f4460cbc74dfc0c5bf1342.mp4", "clean_score": 1.0, "clean_xclip": 0.18325281143188477, "clean_vbench": {"subject_consistency": 0.979010192056497, "background_consistency": 0.9461466471354166, "motion_smoothness": 0.981364730530844, "aesthetic_quality": 0.5063990354537964, "imaging_quality": 0.4737557313880142, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1cff0d0caafe486295776349cf7e10df.mp4", "adv_score": 0.0, "adv_xclip": 0.21404030919075012, "adv_vbench": {"subject_consistency": 0.9938462457309166, "background_consistency": 0.9553120930989584, "motion_smoothness": 0.993681788768105, "aesthetic_quality": 0.44946715235710144, "imaging_quality": 0.7047415799510722, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c77d7b59.mp4", "clean_score": 0.0, "clean_xclip": 0.15105193853378296, "clean_vbench": {}, "adv_vid_id": "vids/98f3d861.mp4", "adv_score": 0.0, "adv_xclip": 0.17984254658222198, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e5545c0a.mp4", "clean_score": 1.0, "clean_xclip": 0.15551719069480896, "clean_vbench": {}, "adv_vid_id": "vids/f0c682fc.mp4", "adv_score": 0.0, "adv_xclip": 0.1637459099292755, "adv_vbench": {}}}}
{"id": "b9fec027f8b643cdb0947ae19e95496e", "source": "vatex", "video_id": "PWPcYEaGYRU_000001_000011", "video_description": "Martial arts students are practicing breaking wooden boards in a gym setting. Instructors hold the boards while students perform various techniques to break them.", "task": "ActionRecognition", "clean_prompt": "A student breaking boards in a gym.", "clean_property": {"obj": "student", "action": "breaking boards", "target": "board"}, "target_prompt": "A student kicking boards in a gym.", "target_property": {"obj": "student", "action": "kicking boards", "target": "board"}, "evaluation_question": "Is the student **breaking** boards?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A student breaking boards in a gym. !F/?A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e441c5915e934c6188c371c73b42abe0.mp4", "clean_score": 1.0, "clean_xclip": 0.11743088066577911, "clean_vbench": {"subject_consistency": 0.8489811141043901, "background_consistency": 0.9010009765625, "motion_smoothness": 0.9598069380144033, "aesthetic_quality": 0.3574906587600708, "imaging_quality": 0.5110143443516323, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f54901708585498f8b74d720d72091a9.mp4", "adv_score": 0.0, "adv_xclip": 0.07767050713300705, "adv_vbench": {"subject_consistency": 0.9136375480641922, "background_consistency": 0.9268697102864584, "motion_smoothness": 0.9532535488153594, "aesthetic_quality": 0.39822420477867126, "imaging_quality": 0.4953495562806421, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d670520e.mp4", "clean_score": 0.0, "clean_xclip": 0.12072215229272842, "clean_vbench": {}, "adv_vid_id": "vids/a567ef98.mp4", "adv_score": 0.0, "adv_xclip": 0.09713637828826904, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0f35302a.mp4", "clean_score": 0.0, "clean_xclip": 0.12608829140663147, "clean_vbench": {}, "adv_vid_id": "vids/be619905.mp4", "adv_score": 0.0, "adv_xclip": 0.08342614024877548, "adv_vbench": {}}}}
{"id": "4fbaaa313831491dbb65a363f8cca975", "source": "vatex", "video_id": "8Wb8JPjcJCo_000028_000038", "video_description": "A man takes a pill and drinks a beverage, then kisses a woman. They are standing against a brick wall.", "task": "ObjectRecognition", "clean_prompt": "A man takes a pill and drinks a beverage, then kisses a woman against a brick wall.", "clean_property": {"obj": "beverage"}, "target_prompt": "A man takes a pill and eats food, then kisses a woman against a brick wall.", "target_property": {"obj": "food"}, "evaluation_question": "Is the man drinking a **beverage**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man takes a pill and drinks a beverage, then kisses a woman against a brick wall. ?'W%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a4ce5589f2444ec95502f74b8521a6e.mp4", "clean_score": 1.0, "clean_xclip": 0.24602070450782776, "clean_vbench": {"subject_consistency": 0.8862333515038093, "background_consistency": 0.9186299641927084, "motion_smoothness": 0.9867207759357601, "aesthetic_quality": 0.5093446969985962, "imaging_quality": 0.5645676398763851, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4979a0bd22b24295a3be690261c16be5.mp4", "adv_score": 0.0, "adv_xclip": 0.259285569190979, "adv_vbench": {"subject_consistency": 0.9393858648836613, "background_consistency": 0.9378916422526041, "motion_smoothness": 0.987367171267298, "aesthetic_quality": 0.504146158695221, "imaging_quality": 0.6488398890592615, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d02c7b28.mp4", "clean_score": 0.0, "clean_xclip": 0.20880015194416046, "clean_vbench": {}, "adv_vid_id": "vids/b1c8cb89.mp4", "adv_score": 0.0, "adv_xclip": 0.23894460499286652, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/af86e728.mp4", "clean_score": 1.0, "clean_xclip": 0.24574628472328186, "clean_vbench": {}, "adv_vid_id": "vids/bc6f4e1a.mp4", "adv_score": 1.0, "adv_xclip": 0.23990511894226074, "adv_vbench": {}}}}
{"id": "3bee8a4b81124519bb554a64f3744a5b", "source": "vatex", "video_id": "esdAd3gN3OE_000000_000010", "video_description": "A woman in a wheelchair is being assisted by a service dog that pushes her across a room. Another woman is supervising and training the dog.", "task": "SpatialUnderstanding", "clean_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "clean_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "supervisor"}, "target_prompt": "A woman further from the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "target_property": {"obj_1": "woman", "relation": "further from the camera than", "obj_2": "supervisor"}, "evaluation_question": "Is the woman **closer to the camera** than her supervisor?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room. O9*4U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2af5e7e055684a3093892729f85d1b60.mp4", "clean_score": 1.0, "clean_xclip": 0.16180011630058289, "clean_vbench": {"subject_consistency": 0.7625147281214595, "background_consistency": 0.9139302571614584, "motion_smoothness": 0.970207446050694, "aesthetic_quality": 0.4148346483707428, "imaging_quality": 0.41575851557206134, "dynamic_degree": 1.0}, "adv_vid_id": "vids/72b964f78bb346bdbe510d73198a6661.mp4", "adv_score": 0.0, "adv_xclip": 0.18801018595695496, "adv_vbench": {"subject_consistency": 0.8856212257718047, "background_consistency": 0.9619598388671875, "motion_smoothness": 0.9799739455678105, "aesthetic_quality": 0.4442407190799713, "imaging_quality": 0.6382795902174346, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3b01e05c.mp4", "clean_score": 1.0, "clean_xclip": 0.2247324138879776, "clean_vbench": {}, "adv_vid_id": "vids/b59cc303.mp4", "adv_score": 1.0, "adv_xclip": 0.13015611469745636, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8de4c941.mp4", "clean_score": 1.0, "clean_xclip": 0.20455583930015564, "clean_vbench": {}, "adv_vid_id": "vids/f72f0f83.mp4", "adv_score": 1.0, "adv_xclip": 0.27858078479766846, "adv_vbench": {}}}}
{"id": "9eaedd7e1e984b31b8d924a07554d1bd", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "ObjectRecognition", "clean_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "person"}, "target_prompt": "A woman is standing in the street using a sledge hammer to break up thick ice on the ground.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground. #BCUS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/af583068a5d8477db4e06a4e0989dbd5.mp4", "clean_score": 1.0, "clean_xclip": 0.22530493140220642, "clean_vbench": {"subject_consistency": 0.8883486899236838, "background_consistency": 0.9467620849609375, "motion_smoothness": 0.9520445291381727, "aesthetic_quality": 0.48140934109687805, "imaging_quality": 0.6031626191431162, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5189bd3c3c674a5cabab60ef8d718b89.mp4", "adv_score": 0.0, "adv_xclip": 0.24360939860343933, "adv_vbench": {"subject_consistency": 0.8808410471926132, "background_consistency": 0.9459126790364584, "motion_smoothness": 0.9506397273158235, "aesthetic_quality": 0.523013174533844, "imaging_quality": 0.6006314616300622, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/066b1eeb.mp4", "clean_score": 1.0, "clean_xclip": 0.21950623393058777, "clean_vbench": {}, "adv_vid_id": "vids/6ffdfda9.mp4", "adv_score": 1.0, "adv_xclip": 0.20846809446811676, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/64325ac9.mp4", "clean_score": 1.0, "clean_xclip": 0.21726058423519135, "clean_vbench": {}, "adv_vid_id": "vids/2bd4d148.mp4", "adv_score": 1.0, "adv_xclip": 0.2338448017835617, "adv_vbench": {}}}}
{"id": "be0a2b3103e24a43a17733a497487a1a", "source": "vatex", "video_id": "6QetWvqJCkU_000023_000033", "video_description": "A man in a jean outfit and hat is dancing to music in a garage with a guitar in the background.", "task": "ObjectRecognition", "clean_prompt": "A man dancing in a garage with a guitar in the background.", "clean_property": {"obj": "guitar"}, "target_prompt": "A man dancing in a garage with a drum in the background.", "target_property": {"obj": "drum"}, "evaluation_question": "Is there a **guitar** in the background of the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man dancing in a garage with a guitar in the background. VT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/572309cad5114feb83230e324225ebb4.mp4", "clean_score": 1.0, "clean_xclip": 0.10474741458892822, "clean_vbench": {"subject_consistency": 0.792209280654788, "background_consistency": 0.8906707763671875, "motion_smoothness": 0.9530845643394961, "aesthetic_quality": 0.44020819664001465, "imaging_quality": 0.3020542732550173, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8412f4addf9d4874a1c6193253dc3516.mp4", "adv_score": 0.0, "adv_xclip": 0.1424584686756134, "adv_vbench": {"subject_consistency": 0.805901825428009, "background_consistency": 0.8969319661458334, "motion_smoothness": 0.9610080257315117, "aesthetic_quality": 0.4726064205169678, "imaging_quality": 0.330774794598015, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4bd6f021.mp4", "clean_score": 1.0, "clean_xclip": 0.19237571954727173, "clean_vbench": {}, "adv_vid_id": "vids/cc264f24.mp4", "adv_score": 0.0, "adv_xclip": 0.14284655451774597, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9faf4af1.mp4", "clean_score": 1.0, "clean_xclip": 0.16924405097961426, "clean_vbench": {}, "adv_vid_id": "vids/d11e4fa7.mp4", "adv_score": 1.0, "adv_xclip": 0.1535469889640808, "adv_vbench": {}}}}
{"id": "60044709a76540e396d863746c82ab3a", "source": "vatex", "video_id": "cAxBY04KV2c_000002_000012", "video_description": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards.", "task": "ObjectRecognition", "clean_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a drumstick.", "clean_property": {"obj": "drumstick"}, "target_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a guitar.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the seated man holding a **drumstick**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a drumstick.  agricole Jardin PeutGar", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0704153cfd804f2390b68912076f7ed8.mp4", "clean_score": 1.0, "clean_xclip": 0.24052909016609192, "clean_vbench": {"subject_consistency": 0.8910668467481931, "background_consistency": 0.8807271321614584, "motion_smoothness": 0.9502463421260994, "aesthetic_quality": 0.4883318543434143, "imaging_quality": 0.5696648617180027, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d5ce22ce669c4d37ac5a1ff94979dce4.mp4", "adv_score": 0.0, "adv_xclip": 0.15954028069972992, "adv_vbench": {"subject_consistency": 0.920489847039183, "background_consistency": 0.92755126953125, "motion_smoothness": 0.9689107652127209, "aesthetic_quality": 0.5022286176681519, "imaging_quality": 0.648540012593172, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/288233ba.mp4", "clean_score": 0.0, "clean_xclip": 0.15984752774238586, "clean_vbench": {}, "adv_vid_id": "vids/b8d59887.mp4", "adv_score": 1.0, "adv_xclip": 0.17323005199432373, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bf204bd1.mp4", "clean_score": 0.0, "clean_xclip": 0.23217782378196716, "clean_vbench": {}, "adv_vid_id": "vids/27879971.mp4", "adv_score": 0.0, "adv_xclip": 0.2262958139181137, "adv_vbench": {}}}}
{"id": "cfc2717ff8ac47de85ddf427377ac6e8", "source": "vatex", "video_id": "Ea_Wr5Lt3lc_000022_000032", "video_description": "A group of people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering.", "task": "Counting", "clean_prompt": "Seven people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering.", "clean_property": {"obj": "people", "count": "seven"}, "target_prompt": "Four people are in a small boat sailing on a calm lake, enjoying the scenery and taking photos.", "target_property": {"obj": "people", "count": "four"}, "evaluation_question": "Are there exactly **seven** people in the amphibious vehicle?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering. FotografiBildern temperatura satisfactory rustic", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/efb475179f834eb2997f06bc01887f7a.mp4", "clean_score": 1.0, "clean_xclip": 0.15392586588859558, "clean_vbench": {"subject_consistency": 0.9607395902276039, "background_consistency": 0.9366607666015625, "motion_smoothness": 0.9707624191201687, "aesthetic_quality": 0.5616791844367981, "imaging_quality": 0.651729245867048, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3a7a82e19ef04137ba010ddd476ad4c4.mp4", "adv_score": 0.0, "adv_xclip": 0.16382786631584167, "adv_vbench": {"subject_consistency": 0.9238468787322441, "background_consistency": 0.9418741861979166, "motion_smoothness": 0.9722356477699104, "aesthetic_quality": 0.5114964246749878, "imaging_quality": 0.6718153731676998, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0bee7b31.mp4", "clean_score": 1.0, "clean_xclip": 0.21136634051799774, "clean_vbench": {}, "adv_vid_id": "vids/34adce36.mp4", "adv_score": 0.0, "adv_xclip": 0.18199422955513, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/03c5d0e0.mp4", "clean_score": 0.0, "clean_xclip": 0.17885014414787292, "clean_vbench": {}, "adv_vid_id": "vids/3a1abfd4.mp4", "adv_score": 1.0, "adv_xclip": 0.17876331508159637, "adv_vbench": {}}}}
{"id": "72fec003622f41afa269e0461559aa29", "source": "vatex", "video_id": "StPYHQh2yuI_000023_000033", "video_description": "A horse auction is taking place in a large meeting hall. A man is handling a white horse on stage while an auctioneer calls for bids from the audience.", "task": "SpatialUnderstanding", "clean_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction.", "clean_property": {"obj_1": "handler", "relation": "farther from the camera than", "obj_2": "audience"}, "target_prompt": "A handler closer to the camera than the audience in a large meeting hall during a horse auction.", "target_property": {"obj_1": "handler", "relation": "closer to the camera than", "obj_2": "audience"}, "evaluation_question": "Is the handler farther from the camera than the audience?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction. Belfast nou Widerspruch Horse cerere", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f13599f8af7e4d1eac5bbd71ff580d55.mp4", "clean_score": 1.0, "clean_xclip": 0.12529468536376953, "clean_vbench": {"subject_consistency": 0.9727046253780524, "background_consistency": 0.9658355712890625, "motion_smoothness": 0.9933751471975106, "aesthetic_quality": 0.46659180521965027, "imaging_quality": 0.5563926393158581, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a89643fbd98e49f0a2e1c2425e0a04e9.mp4", "adv_score": 0.0, "adv_xclip": 0.13554227352142334, "adv_vbench": {"subject_consistency": 0.9785583261400461, "background_consistency": 0.9484710693359375, "motion_smoothness": 0.992131853982591, "aesthetic_quality": 0.4496016204357147, "imaging_quality": 0.7782229567547233, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7698c922.mp4", "clean_score": 1.0, "clean_xclip": 0.15707413852214813, "clean_vbench": {}, "adv_vid_id": "vids/f68341f8.mp4", "adv_score": 1.0, "adv_xclip": 0.14159458875656128, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/523346e4.mp4", "clean_score": 0.0, "clean_xclip": 0.16020750999450684, "clean_vbench": {}, "adv_vid_id": "vids/539852ce.mp4", "adv_score": 1.0, "adv_xclip": 0.12485701590776443, "adv_vbench": {}}}}
{"id": "2250c27e17e149bdb9312eca060859ee", "source": "vatex", "video_id": "89kpJOg07WI_000028_000038", "video_description": "Two boys are sitting at a small table performing a card trick with a deck of black playing cards.", "task": "AttributeRecognition", "clean_prompt": "Two boys sitting at a small table performing a card trick with a deck of black playing cards.", "clean_property": {"obj": "card", "attribute": "black"}, "target_prompt": "Two boys sitting at a small table performing a card trick with a deck of red playing cards.", "target_property": {"obj": "card", "attribute": "red"}, "evaluation_question": "Are the boys using a deck of **black** playing cards?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two boys sitting at a small table performing a card trick with a deck of black playing cards. faci jocuri toamna Mickey semn", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e3699934b84404cba06eadb985b89bf.mp4", "clean_score": 1.0, "clean_xclip": 0.24055495858192444, "clean_vbench": {"subject_consistency": 0.9427314655234417, "background_consistency": 0.9560343424479166, "motion_smoothness": 0.9722754513006334, "aesthetic_quality": 0.4902132749557495, "imaging_quality": 0.7535795951376155, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dba043968f1f4536ac599acfc085658e.mp4", "adv_score": 0.0, "adv_xclip": 0.19799035787582397, "adv_vbench": {"subject_consistency": 0.9607891465226809, "background_consistency": 0.9677073160807291, "motion_smoothness": 0.9766243393447914, "aesthetic_quality": 0.5421326756477356, "imaging_quality": 0.7657635825020926, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9173e439.mp4", "clean_score": 0.0, "clean_xclip": 0.28631043434143066, "clean_vbench": {}, "adv_vid_id": "vids/fffe8f0e.mp4", "adv_score": 1.0, "adv_xclip": 0.2749257981777191, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cc71b0b1.mp4", "clean_score": 1.0, "clean_xclip": 0.2889063358306885, "clean_vbench": {}, "adv_vid_id": "vids/f961c717.mp4", "adv_score": 1.0, "adv_xclip": 0.21646752953529358, "adv_vbench": {}}}}
{"id": "2c7e8384ee274f35ad0dead1cfbf4c70", "source": "vatex", "video_id": "8GcGjOTkccQ_000001_000011", "video_description": "A little boy attempts to hit a baseball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "task": "ObjectRecognition", "clean_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "clean_property": {"obj": "ball"}, "target_prompt": "A little boy attempts to fly a kite on a windy day, but the kite gets stuck in a tree.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object the boy is trying to hit a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying. descarc besuchen Bollywood besuchen adjective", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a60d747124148d69db3762687a7731c.mp4", "clean_score": 1.0, "clean_xclip": 0.18945631384849548, "clean_vbench": {"subject_consistency": 0.7959985674048463, "background_consistency": 0.8905588785807291, "motion_smoothness": 0.9332398432141632, "aesthetic_quality": 0.4588090181350708, "imaging_quality": 0.3596944221185179, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bbcc8491068f49059999b39f29eb8065.mp4", "adv_score": 0.0, "adv_xclip": 0.19992081820964813, "adv_vbench": {"subject_consistency": 0.8361378492166599, "background_consistency": 0.8886260986328125, "motion_smoothness": 0.9373497828915517, "aesthetic_quality": 0.4262087643146515, "imaging_quality": 0.4507465876365195, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fd1c0e81.mp4", "clean_score": 1.0, "clean_xclip": 0.17598792910575867, "clean_vbench": {}, "adv_vid_id": "vids/73e1b88f.mp4", "adv_score": 0.0, "adv_xclip": 0.15836013853549957, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/85f6d88d.mp4", "clean_score": 1.0, "clean_xclip": 0.19909019768238068, "clean_vbench": {}, "adv_vid_id": "vids/786d6670.mp4", "adv_score": 1.0, "adv_xclip": 0.18969601392745972, "adv_vbench": {}}}}
{"id": "b7447a14fa0443d593f95a341359c6d1", "source": "vatex", "video_id": "NZLydTq7Q98_000003_000013", "video_description": "A man in a blue top, wearing a baseball cap and sports equipment, is at an outdoor archery range holding a bow and arrow. He prepares to fire at a target and walks towards the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A bow positioned to the left of a person at an outdoor archery range.", "clean_property": {"obj_1": "bow", "relation": "left of", "obj_2": "person"}, "target_prompt": "A bow positioned to the right of a person at an outdoor archery range.", "target_property": {"obj_1": "bow", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the bow to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A bow positioned to the left of a person at an outdoor archery range. !=9>B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a4bcd8c20e44d48b7b42b36ed68a505.mp4", "clean_score": 1.0, "clean_xclip": 0.2354964315891266, "clean_vbench": {"subject_consistency": 0.9433495377500852, "background_consistency": 0.9456380208333334, "motion_smoothness": 0.9890984822266098, "aesthetic_quality": 0.4297303855419159, "imaging_quality": 0.6222162635958924, "dynamic_degree": 0.0}, "adv_vid_id": "vids/4d686520e03241d0bed8549f6eb8df27.mp4", "adv_score": 0.0, "adv_xclip": 0.22950983047485352, "adv_vbench": {"subject_consistency": 0.968457855284214, "background_consistency": 0.9518534342447916, "motion_smoothness": 0.9904116126228012, "aesthetic_quality": 0.39871370792388916, "imaging_quality": 0.6921022072616888, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ccb8ef77.mp4", "clean_score": 0.0, "clean_xclip": 0.22346578538417816, "clean_vbench": {}, "adv_vid_id": "vids/e61b068e.mp4", "adv_score": 0.0, "adv_xclip": 0.2146652191877365, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e1424616.mp4", "clean_score": 0.0, "clean_xclip": 0.22556978464126587, "clean_vbench": {}, "adv_vid_id": "vids/f0af86b7.mp4", "adv_score": 0.0, "adv_xclip": 0.21667823195457458, "adv_vbench": {}}}}
{"id": "f24c4770714342b69ee2fcf21c848fa9", "source": "vatex", "video_id": "_8w8b5auFkc_000002_000012", "video_description": "A skiing competition is taking place on a large snowy slope. Skiers are skiing downhill through flags, while spectators cheer them on.", "task": "ObjectRecognition", "clean_prompt": "Skiers racing downhill through flags on a snowy slope.", "clean_property": {"obj": "flags"}, "target_prompt": "Skiers racing downhill through banners on a snowy slope.", "target_property": {"obj": "banners"}, "evaluation_question": "Are the skiers skiing through **flags**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Skiers racing downhill through flags on a snowy slope. Oradea Weihnachts amenajat environmentallyriz", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e40e39bf34454e848542ec673617e371.mp4", "clean_score": 1.0, "clean_xclip": 0.21596425771713257, "clean_vbench": {"subject_consistency": 0.8673341013491154, "background_consistency": 0.9302775065104166, "motion_smoothness": 0.9830011087093016, "aesthetic_quality": 0.5424164533615112, "imaging_quality": 0.5266860113338548, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a34fb93be5e343779e682e34f5121b38.mp4", "adv_score": 0.0, "adv_xclip": 0.20233070850372314, "adv_vbench": {"subject_consistency": 0.9163789575298628, "background_consistency": 0.9559529622395834, "motion_smoothness": 0.9839996058447813, "aesthetic_quality": 0.5441597104072571, "imaging_quality": 0.4652938764922473, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/05d27ff7.mp4", "clean_score": 0.0, "clean_xclip": 0.18852275609970093, "clean_vbench": {}, "adv_vid_id": "vids/dabbb7b7.mp4", "adv_score": 0.0, "adv_xclip": 0.17108219861984253, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b0d9c53d.mp4", "clean_score": 1.0, "clean_xclip": 0.19861075282096863, "clean_vbench": {}, "adv_vid_id": "vids/96b34d0b.mp4", "adv_score": 1.0, "adv_xclip": 0.22963930666446686, "adv_vbench": {}}}}
{"id": "38287f8a682646d9a6d9e33c737848a1", "source": "vatex", "video_id": "z8l7Gy9JtAg_000012_000022", "video_description": "In a garden, a boy is swinging on a swing set while another boy runs, jumps, and kicks the swing, causing the swinging boy to fall.", "task": "ActionRecognition", "clean_prompt": "A boy falling off a chair in a garden.", "clean_property": {"obj": "boy_2", "action": "falling off chair", "target": null}, "target_prompt": "A boy jumping off a chair in a garden.", "target_property": {"obj": "boy_2", "action": "jumping off a chair", "target": null}, "evaluation_question": "Is the boy **falling off a chair**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy falling off a chair in a garden. Stimmungtisch actiune aktuell Garten", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/892f6626e2cf42cba286a996d5df0ec6.mp4", "clean_score": 1.0, "clean_xclip": 0.2556811571121216, "clean_vbench": {"subject_consistency": 0.8642891962081194, "background_consistency": 0.918701171875, "motion_smoothness": 0.9603856092527032, "aesthetic_quality": 0.5637030005455017, "imaging_quality": 0.6612304002411511, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a6da7e2741e1477cb82638e949cb80f7.mp4", "adv_score": 0.0, "adv_xclip": 0.26712390780448914, "adv_vbench": {"subject_consistency": 0.9106990316261848, "background_consistency": 0.8960367838541666, "motion_smoothness": 0.9754704933606673, "aesthetic_quality": 0.47102558612823486, "imaging_quality": 0.7469933786197585, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/74af76e8.mp4", "clean_score": 1.0, "clean_xclip": 0.17750774323940277, "clean_vbench": {}, "adv_vid_id": "vids/20305beb.mp4", "adv_score": 1.0, "adv_xclip": 0.1994669884443283, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e384f39e.mp4", "clean_score": 1.0, "clean_xclip": 0.20886583626270294, "clean_vbench": {}, "adv_vid_id": "vids/04472111.mp4", "adv_score": 1.0, "adv_xclip": 0.26017141342163086, "adv_vbench": {}}}}
{"id": "5037d70db9534ad6810125a6b986533f", "source": "vatex", "video_id": "JJWu9ybc_fs_000001_000011", "video_description": "Two boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "task": "Counting", "clean_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "clean_property": {"obj": "boy", "count": "three"}, "target_prompt": "One boy is playing in a snowy field, making a snowman using a tool.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **three** boys playing in the snowy field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman. 9POE7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b15daa08723400ebbf06556c7de39e6.mp4", "clean_score": 1.0, "clean_xclip": 0.2245214581489563, "clean_vbench": {"subject_consistency": 0.9344577429195245, "background_consistency": 0.95867919921875, "motion_smoothness": 0.9793368916046358, "aesthetic_quality": 0.7090281844139099, "imaging_quality": 0.6735292380196708, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5d2d73523f7c4ab89a06c2afad877216.mp4", "adv_score": 0.0, "adv_xclip": 0.22089135646820068, "adv_vbench": {"subject_consistency": 0.9280168587962786, "background_consistency": 0.944488525390625, "motion_smoothness": 0.9812755083514888, "aesthetic_quality": 0.6565239429473877, "imaging_quality": 0.7163941784294284, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8e30fed9.mp4", "clean_score": 1.0, "clean_xclip": 0.21868181228637695, "clean_vbench": {}, "adv_vid_id": "vids/d1e5eec1.mp4", "adv_score": 1.0, "adv_xclip": 0.2132350206375122, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ac13cf2f.mp4", "clean_score": 1.0, "clean_xclip": 0.21757230162620544, "clean_vbench": {}, "adv_vid_id": "vids/2f7f2e3d.mp4", "adv_score": 1.0, "adv_xclip": 0.22452546656131744, "adv_vbench": {}}}}
{"id": "ba17d2750d164700a7e4cfd782397800", "source": "vatex", "video_id": "th9TRkTPLE0_000072_000082", "video_description": "A man wearing glasses is using a circular saw to cut through a metal railing outdoors.", "task": "ActionRecognition", "clean_prompt": "A person using a circular saw to cut through a metal railing outdoors.", "clean_property": {"obj": "person", "action": "using circular saw", "target": "metal railing"}, "target_prompt": "A person using a chainsaw to cut through a wooden log outdoors.", "target_property": {"obj": "person", "action": "using a chainsaw", "target": "wooden log"}, "evaluation_question": "Is the person **using a circular saw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a circular saw to cut through a metal railing outdoors. -%|&-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b92a684f0052498b8e97e49adecaffdd.mp4", "clean_score": 1.0, "clean_xclip": 0.1912667453289032, "clean_vbench": {"subject_consistency": 0.9329436868429184, "background_consistency": 0.9538167317708334, "motion_smoothness": 0.9818771233319716, "aesthetic_quality": 0.38301825523376465, "imaging_quality": 0.7043498222195371, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6be9b057566b4bf08747da42c77b55e9.mp4", "adv_score": 0.0, "adv_xclip": 0.1678418517112732, "adv_vbench": {"subject_consistency": 0.971982833618919, "background_consistency": 0.9573822021484375, "motion_smoothness": 0.9814779830978173, "aesthetic_quality": 0.38192662596702576, "imaging_quality": 0.6730099814278739, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8a848364.mp4", "clean_score": 1.0, "clean_xclip": 0.24884983897209167, "clean_vbench": {}, "adv_vid_id": "vids/f50c2e81.mp4", "adv_score": 1.0, "adv_xclip": 0.2459629476070404, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2086a92a.mp4", "clean_score": 1.0, "clean_xclip": 0.25405919551849365, "clean_vbench": {}, "adv_vid_id": "vids/e2d69da8.mp4", "adv_score": 1.0, "adv_xclip": 0.24092024564743042, "adv_vbench": {}}}}
{"id": "c8eafc71b50f484b9b05f4f37edcd33c", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "ActionRecognition", "clean_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "clean_property": {"obj": "person", "action": "playing laser tag", "target": null}, "target_prompt": "A person watching a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "target_property": {"obj": "person", "action": "watching a laser tag game", "target": null}, "evaluation_question": "Is the person **playing** laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.seite touristiqueleistung souhait Bulgaria", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ea44664b81e46a8b210b5a7fc945569.mp4", "clean_score": 1.0, "clean_xclip": 0.24105766415596008, "clean_vbench": {"subject_consistency": 0.927732652053237, "background_consistency": 0.9335784912109375, "motion_smoothness": 0.9521597340421508, "aesthetic_quality": 0.34579282999038696, "imaging_quality": 0.6296553514441665, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a3c5b93397824262a4985a4320219946.mp4", "adv_score": 0.0, "adv_xclip": 0.20961549878120422, "adv_vbench": {"subject_consistency": 0.9073362375299135, "background_consistency": 0.9303741455078125, "motion_smoothness": 0.9583769641569334, "aesthetic_quality": 0.43904909491539, "imaging_quality": 0.6124568417607521, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4835b0ab.mp4", "clean_score": 1.0, "clean_xclip": 0.23921653628349304, "clean_vbench": {}, "adv_vid_id": "vids/fc3ed2bc.mp4", "adv_score": 1.0, "adv_xclip": 0.21894732117652893, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/41756499.mp4", "clean_score": 1.0, "clean_xclip": 0.23129400610923767, "clean_vbench": {}, "adv_vid_id": "vids/e34f6a72.mp4", "adv_score": 1.0, "adv_xclip": 0.1983100175857544, "adv_vbench": {}}}}
{"id": "ae7575685ff84f39b0bbd23c5398c905", "source": "vatex", "video_id": "8ji3VkUal2c_000003_000013", "video_description": "A man is sitting on the floor holding a board while a young boy breaks it with a karate kick, with a cheering crowd.", "task": "ActionRecognition", "clean_prompt": "A boy breaking boards with a karate kick in front of a cheering crowd.", "clean_property": {"obj": "boy", "action": "breaking boards", "target": "board"}, "target_prompt": "A boy throwing boards in front of a cheering crowd.", "target_property": {"obj": "boy", "action": "throwing boards", "target": "board"}, "evaluation_question": "Is the boy **breaking** boards?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy breaking boards with a karate kick in front of a cheering crowd.extra Ethiopia Trotz antrenlandais", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/96c19d49e4cc4807bda44496f690f287.mp4", "clean_score": 1.0, "clean_xclip": 0.16988223791122437, "clean_vbench": {"subject_consistency": 0.7865288183093071, "background_consistency": 0.8542887369791666, "motion_smoothness": 0.9011729224032721, "aesthetic_quality": 0.45015743374824524, "imaging_quality": 0.4546339362008231, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1289f668d91a46028178bde1f55afcfe.mp4", "adv_score": 0.0, "adv_xclip": 0.16583049297332764, "adv_vbench": {"subject_consistency": 0.8715941434105238, "background_consistency": 0.8794352213541666, "motion_smoothness": 0.9085147801115045, "aesthetic_quality": 0.502705454826355, "imaging_quality": 0.4886704752396564, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d372e827.mp4", "clean_score": 0.0, "clean_xclip": 0.14606468379497528, "clean_vbench": {}, "adv_vid_id": "vids/6da02f3b.mp4", "adv_score": 0.0, "adv_xclip": 0.1227216124534607, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/47cbcd30.mp4", "clean_score": 1.0, "clean_xclip": 0.17445901036262512, "clean_vbench": {}, "adv_vid_id": "vids/8cc1bbce.mp4", "adv_score": 0.0, "adv_xclip": 0.16343140602111816, "adv_vbench": {}}}}
{"id": "46c2bbcfa1d04f07a81763b8dd0d2126", "source": "vatex", "video_id": "5ILkwhgwtkQ_000120_000130", "video_description": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "clean_property": {"obj": "paper airplane"}, "target_prompt": "A young boy is sitting on the floor of a bedroom, folding a colorful piece of paper into a kite while music plays in the background.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object being folded in the video a **paper airplane**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background. LYSWK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61abea11768049de8948f504da45cdae.mp4", "clean_score": 1.0, "clean_xclip": 0.17803120613098145, "clean_vbench": {"subject_consistency": 0.937223511437575, "background_consistency": 0.9502614339192709, "motion_smoothness": 0.9718316895752642, "aesthetic_quality": 0.5695932507514954, "imaging_quality": 0.6846851411157725, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3b470517bdf64e0a9cc6947c1e20738b.mp4", "adv_score": 0.0, "adv_xclip": 0.1671079695224762, "adv_vbench": {"subject_consistency": 0.9420476388186216, "background_consistency": 0.9502766927083334, "motion_smoothness": 0.9719031400979888, "aesthetic_quality": 0.538173258304596, "imaging_quality": 0.7274808704609774, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b62961e3.mp4", "clean_score": 0.0, "clean_xclip": 0.19220677018165588, "clean_vbench": {}, "adv_vid_id": "vids/4b2df225.mp4", "adv_score": 0.0, "adv_xclip": 0.16115644574165344, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/550c4955.mp4", "clean_score": 1.0, "clean_xclip": 0.20156767964363098, "clean_vbench": {}, "adv_vid_id": "vids/2584e4b2.mp4", "adv_score": 1.0, "adv_xclip": 0.23503518104553223, "adv_vbench": {}}}}
{"id": "c31dfa5c635547bc930cdb0ebeb864d4", "source": "vatex", "video_id": "9i4GqMpwyxs_000000_000010", "video_description": "A man is speaking on a large screen, such as a television or jumbo tron, while a woman interprets his speech into sign language. A crowd, including children and young people, is watching the event.", "task": "Counting", "clean_prompt": "Two women interpreting a man's speech into sign language on a large screen while a crowd watches.", "clean_property": {"obj": "woman", "count": "two"}, "target_prompt": "One woman interpreting a man's speech into sign language on a large screen while a crowd watches.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **two** women interpreting the speech?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women interpreting a man's speech into sign language on a large screen while a crowd watches. FE(.X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46ba2b132e764775a06f2c546ebaf8d2.mp4", "clean_score": 1.0, "clean_xclip": 0.2216659039258957, "clean_vbench": {"subject_consistency": 0.9600523294260105, "background_consistency": 0.9465128580729166, "motion_smoothness": 0.9886584125741346, "aesthetic_quality": 0.47977301478385925, "imaging_quality": 0.6590680243044482, "dynamic_degree": 0.0}, "adv_vid_id": "vids/f2dc816050294a2e9bdb28c885534ce8.mp4", "adv_score": 0.0, "adv_xclip": 0.1951737105846405, "adv_vbench": {"subject_consistency": 0.9728765593220791, "background_consistency": 0.9215087890625, "motion_smoothness": 0.9854610916318688, "aesthetic_quality": 0.5003906488418579, "imaging_quality": 0.681253411429269, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7142943e.mp4", "clean_score": 0.0, "clean_xclip": 0.2183675915002823, "clean_vbench": {}, "adv_vid_id": "vids/1a1149a6.mp4", "adv_score": 1.0, "adv_xclip": 0.1453951746225357, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e68232bb.mp4", "clean_score": 1.0, "clean_xclip": 0.2229556143283844, "clean_vbench": {}, "adv_vid_id": "vids/a5f10774.mp4", "adv_score": 0.0, "adv_xclip": 0.2183256447315216, "adv_vbench": {}}}}
{"id": "56770af94f3c4bad82f43c4b705b266d", "source": "vatex", "video_id": "UmbJQOAl5mQ_000013_000023", "video_description": "A performer is demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "task": "SpatialUnderstanding", "clean_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "clean_property": {"obj_1": "performer", "relation": "left of", "obj_2": "fire stick"}, "target_prompt": "A performer standing to the right of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "target_property": {"obj_1": "performer", "relation": "right of", "obj_2": "fire stick"}, "evaluation_question": "Is the performer to the **left** of the fire stick?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting. Jetzt Teddy loin gasest financement", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8be4c2a19786416a92fe8985b9733982.mp4", "clean_score": 1.0, "clean_xclip": 0.2353014051914215, "clean_vbench": {"subject_consistency": 0.8857776143898567, "background_consistency": 0.9372812906901041, "motion_smoothness": 0.9485541458320725, "aesthetic_quality": 0.5822972059249878, "imaging_quality": 0.33900154035918567, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b67d87c300774e9e9d317af7ac377518.mp4", "adv_score": 0.0, "adv_xclip": 0.16872543096542358, "adv_vbench": {"subject_consistency": 0.8944936537494262, "background_consistency": 0.9256846110026041, "motion_smoothness": 0.9553763545638162, "aesthetic_quality": 0.56434166431427, "imaging_quality": 0.40042444890859175, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/31aec61f.mp4", "clean_score": 0.0, "clean_xclip": 0.1991795003414154, "clean_vbench": {}, "adv_vid_id": "vids/cdb7d146.mp4", "adv_score": 0.0, "adv_xclip": 0.15929174423217773, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/61c8d38d.mp4", "clean_score": 0.0, "clean_xclip": 0.21275806427001953, "clean_vbench": {}, "adv_vid_id": "vids/11ce20bb.mp4", "adv_score": 0.0, "adv_xclip": 0.20333176851272583, "adv_vbench": {}}}}
{"id": "1027682487ee4f27923c809e585f5f6c", "source": "vatex", "video_id": "eAz-jW31Iq8_000205_000215", "video_description": "A man is demonstrating how to shuffle a deck of cards on a table, occasionally chatting with another man.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a table demonstrating how to shuffle a deck of cards.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "table"}, "target_prompt": "A person beside a table demonstrating how to shuffle a deck of cards.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "table"}, "evaluation_question": "Is the person **above** the table?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person above a table demonstrating how to shuffle a deck of cards. bucati gehen Kategorie guild Lehr", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cdf5abc77b5241328a1b8da2faa46561.mp4", "clean_score": 1.0, "clean_xclip": 0.19836539030075073, "clean_vbench": {"subject_consistency": 0.8425161074846983, "background_consistency": 0.9258015950520834, "motion_smoothness": 0.9324770001525559, "aesthetic_quality": 0.35241609811782837, "imaging_quality": 0.38997966299251635, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ecb2377f37e642e5868e4ac12842bfac.mp4", "adv_score": 0.0, "adv_xclip": 0.15808641910552979, "adv_vbench": {"subject_consistency": 0.8309276395787796, "background_consistency": 0.9258931477864584, "motion_smoothness": 0.9521493389665537, "aesthetic_quality": 0.3230421841144562, "imaging_quality": 0.5212448415950853, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/13670b77.mp4", "clean_score": 0.0, "clean_xclip": 0.1873372346162796, "clean_vbench": {}, "adv_vid_id": "vids/0ec2424e.mp4", "adv_score": 0.0, "adv_xclip": 0.20716339349746704, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8017572f.mp4", "clean_score": 0.0, "clean_xclip": 0.19166594743728638, "clean_vbench": {}, "adv_vid_id": "vids/8c95b609.mp4", "adv_score": 0.0, "adv_xclip": 0.17819976806640625, "adv_vbench": {}}}}
{"id": "1789e411389042778e4ce9ead72e676b", "source": "vatex", "video_id": "i--HTK1hiBs_000008_000018", "video_description": "A man, possibly a chef, is demonstrating and instructing on the proper technique to slice a piece of steak against the grain using a large knife on a cutting board.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to slice steak against the grain on a cutting board.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to slice steak against the grain on a cutting board.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man demonstrating how to slice steak against the grain on a cutting board. Fotografiamerika Wirtschaftsstuhl chaud", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f55ca2a182f44a57ae59115d07d23b9b.mp4", "clean_score": 1.0, "clean_xclip": 0.22360795736312866, "clean_vbench": {"subject_consistency": 0.9608187067011992, "background_consistency": 0.98162841796875, "motion_smoothness": 0.9726586135129206, "aesthetic_quality": 0.5592962503433228, "imaging_quality": 0.7359476829061703, "dynamic_degree": 1.0}, "adv_vid_id": "vids/45cbc324370246d3881cd6d63c9690f5.mp4", "adv_score": 0.0, "adv_xclip": 0.22656583786010742, "adv_vbench": {"subject_consistency": 0.9615741278976202, "background_consistency": 0.9713083902994791, "motion_smoothness": 0.9677559050787239, "aesthetic_quality": 0.5581375956535339, "imaging_quality": 0.7003474068155094, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f15591e8.mp4", "clean_score": 1.0, "clean_xclip": 0.23592376708984375, "clean_vbench": {}, "adv_vid_id": "vids/97f5d3cf.mp4", "adv_score": 0.0, "adv_xclip": 0.23265337944030762, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4147939d.mp4", "clean_score": 0.0, "clean_xclip": 0.2296323925256729, "clean_vbench": {}, "adv_vid_id": "vids/e6df80ce.mp4", "adv_score": 0.0, "adv_xclip": 0.22715044021606445, "adv_vbench": {}}}}
{"id": "f83bcf45e3f747d0a2fdf4a146278fa5", "source": "vatex", "video_id": "StPYHQh2yuI_000023_000033", "video_description": "A horse auction is taking place in a large meeting hall. A man is handling a white horse on stage while an auctioneer calls for bids from the audience.", "task": "SpatialUnderstanding", "clean_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction.", "clean_property": {"obj_1": "handler", "relation": "farther from the camera than", "obj_2": "audience"}, "target_prompt": "A handler closer to the camera than the audience in a large meeting hall during a horse auction.", "target_property": {"obj_1": "handler", "relation": "closer to the camera than", "obj_2": "audience"}, "evaluation_question": "Is the handler farther from the camera than the audience?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction. Y4G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b505747bae22429b89d5638f57a6f76a.mp4", "clean_score": 1.0, "clean_xclip": 0.12529468536376953, "clean_vbench": {"subject_consistency": 0.9727046253780524, "background_consistency": 0.9658355712890625, "motion_smoothness": 0.9933751471975106, "aesthetic_quality": 0.46659180521965027, "imaging_quality": 0.5563926393158581, "dynamic_degree": 0.0}, "adv_vid_id": "vids/6c2043db11af46f7be7fbf0371060ece.mp4", "adv_score": 0.0, "adv_xclip": 0.1599038541316986, "adv_vbench": {"subject_consistency": 0.9749513355394205, "background_consistency": 0.9413960774739584, "motion_smoothness": 0.9944903210544763, "aesthetic_quality": 0.4321134090423584, "imaging_quality": 0.6815341614703744, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7642ae93.mp4", "clean_score": 1.0, "clean_xclip": 0.16482844948768616, "clean_vbench": {}, "adv_vid_id": "vids/dcfef2c0.mp4", "adv_score": 0.0, "adv_xclip": 0.15064996480941772, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/743dd871.mp4", "clean_score": 1.0, "clean_xclip": 0.1509380042552948, "clean_vbench": {}, "adv_vid_id": "vids/2af8bdf7.mp4", "adv_score": 1.0, "adv_xclip": 0.1731410175561905, "adv_vbench": {}}}}
{"id": "7fb6dd9b132342ae9cf2b49f5b7d984c", "source": "vatex", "video_id": "VZIcu3ibJew_000085_000095", "video_description": "A person is lying down while a technician pierces their ear and installs jewelry.", "task": "ActionRecognition", "clean_prompt": "A technician getting a piercing on a person.", "clean_property": {"obj": "technician", "action": "getting a piercing", "target": "person"}, "target_prompt": "A technician removing a piercing from a person.", "target_property": {"obj": "technician", "action": "removing a piercing", "target": "person"}, "evaluation_question": "Is the technician **getting** a piercing?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A technician getting a piercing on a person. !'(!W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/09b494e0a1f647e7a31e2e15f7559492.mp4", "clean_score": 1.0, "clean_xclip": 0.18108125030994415, "clean_vbench": {"subject_consistency": 0.888739832987388, "background_consistency": 0.9504038492838541, "motion_smoothness": 0.9788341594675422, "aesthetic_quality": 0.3303000032901764, "imaging_quality": 0.47362703517991667, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f3e23ad1cf374c57beeaae0cc86d9199.mp4", "adv_score": 0.0, "adv_xclip": 0.17313361167907715, "adv_vbench": {"subject_consistency": 0.9433575607836246, "background_consistency": 0.9638417561848959, "motion_smoothness": 0.9787212972734104, "aesthetic_quality": 0.37555959820747375, "imaging_quality": 0.7175996749255122, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1eb3ff8b.mp4", "clean_score": 1.0, "clean_xclip": 0.22601071000099182, "clean_vbench": {}, "adv_vid_id": "vids/f97dd090.mp4", "adv_score": 1.0, "adv_xclip": 0.19362740218639374, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4471fca9.mp4", "clean_score": 0.0, "clean_xclip": 0.1883462369441986, "clean_vbench": {}, "adv_vid_id": "vids/715e2385.mp4", "adv_score": 1.0, "adv_xclip": 0.20569457113742828, "adv_vbench": {}}}}
{"id": "e293d943b45543ca9b344806a1963f07", "source": "vatex", "video_id": "BHsuHq_75Nw_000100_000110", "video_description": "A person is cooking a whole chicken on a rotisserie over an open fire in the woods during the day. The person uses a knife with a leather sheath to carve the chicken.", "task": "AttributeRecognition", "clean_prompt": "A person carving a whole chicken with a knife with a leather sheath over an open fire in the woods during the day.", "clean_property": {"obj": "knife", "attribute": "with leather sheath"}, "target_prompt": "A person carving a whole chicken with a knife with a plastic handle over an open fire in the woods during the day.", "target_property": {"obj": "knife", "attribute": "with plastic handle"}, "evaluation_question": "Is the knife being used **with a leather sheath**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person carving a whole chicken with a knife with a leather sheath over an open fire in the woods during the day. |BCSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b682f7cf57614a9abb5106d8a2aabe09.mp4", "clean_score": 1.0, "clean_xclip": 0.3013279438018799, "clean_vbench": {"subject_consistency": 0.9581616949290037, "background_consistency": 0.9721781412760416, "motion_smoothness": 0.9564265218079258, "aesthetic_quality": 0.6612676382064819, "imaging_quality": 0.660484289052535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9cb171e782ce43659278decdc8bbd0ee.mp4", "adv_score": 0.0, "adv_xclip": 0.2724657654762268, "adv_vbench": {"subject_consistency": 0.951451395948728, "background_consistency": 0.96514892578125, "motion_smoothness": 0.9575656625400932, "aesthetic_quality": 0.6158132553100586, "imaging_quality": 0.698245633962203, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f5d6a10c.mp4", "clean_score": 0.0, "clean_xclip": 0.2427825629711151, "clean_vbench": {}, "adv_vid_id": "vids/d30d57aa.mp4", "adv_score": 0.0, "adv_xclip": 0.30749472975730896, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5a0cc3bd.mp4", "clean_score": 0.0, "clean_xclip": 0.26948848366737366, "clean_vbench": {}, "adv_vid_id": "vids/3aa93aee.mp4", "adv_score": 0.0, "adv_xclip": 0.2633196711540222, "adv_vbench": {}}}}
{"id": "a373630c2b114fd3b8ff4d3ed806dad5", "source": "vatex", "video_id": "JMyCoStRMFg_000006_000016", "video_description": "In a sand-lined outdoor arena, a cowboy on horseback chases and lassoes a calf, then jumps off the horse to tie the calf.", "task": "ObjectRecognition", "clean_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena.", "clean_property": {"obj": "calf"}, "target_prompt": "A cowboy on horseback chases and lassoes a sheep in a sand-lined outdoor arena.", "target_property": {"obj": "sheep"}, "evaluation_question": "Is the animal being chased in the video a **calf**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena. Projekt chien exerc Verwaltung personnage", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b20caa6a2294f1ca38094ead8f3a65b.mp4", "clean_score": 1.0, "clean_xclip": 0.1786983609199524, "clean_vbench": {"subject_consistency": 0.9368632901459932, "background_consistency": 0.890228271484375, "motion_smoothness": 0.9728370911250303, "aesthetic_quality": 0.4887249767780304, "imaging_quality": 0.6888501038843272, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4fbcc5fbbc6e4a2a8a98daa49415de39.mp4", "adv_score": 0.0, "adv_xclip": 0.1847173422574997, "adv_vbench": {"subject_consistency": 0.9127293024212122, "background_consistency": 0.9097900390625, "motion_smoothness": 0.973515097831185, "aesthetic_quality": 0.5123550295829773, "imaging_quality": 0.7240939844871054, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9a762920.mp4", "clean_score": 0.0, "clean_xclip": 0.2057102620601654, "clean_vbench": {}, "adv_vid_id": "vids/94d09102.mp4", "adv_score": 1.0, "adv_xclip": 0.20423582196235657, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/adf09ade.mp4", "clean_score": 0.0, "clean_xclip": 0.17701056599617004, "clean_vbench": {}, "adv_vid_id": "vids/8d073b8d.mp4", "adv_score": 0.0, "adv_xclip": 0.1879597306251526, "adv_vbench": {}}}}
{"id": "7f85eabcad8f4bb09570075239e22682", "source": "vatex", "video_id": "mrKntbg0ibw_000068_000078", "video_description": "A woman dives off a high diving board into a swimming pool, followed by a young boy who is waiting to jump.", "task": "ActionRecognition", "clean_prompt": "A woman springboard diving into a swimming pool.", "clean_property": {"obj": "woman", "action": "springboard diving", "target": null}, "target_prompt": "A woman swimming in a swimming pool.", "target_property": {"obj": "woman", "action": "swimming", "target": null}, "evaluation_question": "Is the woman **springboard diving**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman springboard diving into a swimming pool. C|.):", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a74c1abac8f4b4f8b433e6c6232feab.mp4", "clean_score": 1.0, "clean_xclip": 0.21464753150939941, "clean_vbench": {"subject_consistency": 0.7731653895849983, "background_consistency": 0.8681844075520834, "motion_smoothness": 0.9812133966755426, "aesthetic_quality": 0.4115715026855469, "imaging_quality": 0.5650198749620088, "dynamic_degree": 1.0}, "adv_vid_id": "vids/205c10ec9e5740e38be2e743c5ecb538.mp4", "adv_score": 0.0, "adv_xclip": 0.19529201090335846, "adv_vbench": {"subject_consistency": 0.8109239156668385, "background_consistency": 0.8760782877604166, "motion_smoothness": 0.9790786926717704, "aesthetic_quality": 0.4575217664241791, "imaging_quality": 0.6589625323548609, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/770c8756.mp4", "clean_score": 0.0, "clean_xclip": 0.1715187132358551, "clean_vbench": {}, "adv_vid_id": "vids/13cda445.mp4", "adv_score": 1.0, "adv_xclip": 0.1664387583732605, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9049897e.mp4", "clean_score": 0.0, "clean_xclip": 0.1878625750541687, "clean_vbench": {}, "adv_vid_id": "vids/ab65bf03.mp4", "adv_score": 0.0, "adv_xclip": 0.16525112092494965, "adv_vbench": {}}}}
{"id": "b078b193c8b74138964bb88b62022398", "source": "vatex", "video_id": "lySYZKEBADk_000028_000038", "video_description": "A young boy is helping his grandfather make sausages using a meat grinder while his grandmother tells a story.", "task": "ObjectRecognition", "clean_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "clean_property": {"obj": "woman"}, "target_prompt": "A man telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "target_property": {"obj": "man"}, "evaluation_question": "Is the storyteller in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder. U%1*U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2cd702a56f5c47e09d940f2a1441489d.mp4", "clean_score": 1.0, "clean_xclip": 0.19655266404151917, "clean_vbench": {"subject_consistency": 0.9603215934087833, "background_consistency": 0.9397074381510416, "motion_smoothness": 0.9818236874836096, "aesthetic_quality": 0.6048287749290466, "imaging_quality": 0.7108312092995157, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d256ab13ca1a49bf9cb1246f8b17aefe.mp4", "adv_score": 0.0, "adv_xclip": 0.20148307085037231, "adv_vbench": {"subject_consistency": 0.9799431997040907, "background_consistency": 0.9779713948567709, "motion_smoothness": 0.984337228866598, "aesthetic_quality": 0.7608298063278198, "imaging_quality": 0.6751612044353874, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e4e0f608.mp4", "clean_score": 0.0, "clean_xclip": 0.19920474290847778, "clean_vbench": {}, "adv_vid_id": "vids/93f36b86.mp4", "adv_score": 0.0, "adv_xclip": 0.17859363555908203, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aa59155d.mp4", "clean_score": 1.0, "clean_xclip": 0.20319363474845886, "clean_vbench": {}, "adv_vid_id": "vids/05cd624a.mp4", "adv_score": 1.0, "adv_xclip": 0.20173412561416626, "adv_vbench": {}}}}
{"id": "fd79d4dc3f0b4c699fb7d96ecbbf332f", "source": "vatex", "video_id": "6Z2BB-P41Mw_000085_000095", "video_description": "A little girl is in a room with a little boy, upset and yelling because she was called a loser by the boy. They are having a conversation at home.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the right of a girl in a room, having a conversation.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "girl"}, "target_prompt": "A boy standing to the left of a girl in a room, having a conversation.", "target_property": {"obj_1": "boy", "relation": "left of", "obj_2": "girl"}, "evaluation_question": "Is the boy to the **right** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy standing to the right of a girl in a room, having a conversation. limbi cupcake observa produitatului", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b6974564242f47f2badee199849eb096.mp4", "clean_score": 1.0, "clean_xclip": 0.1771775633096695, "clean_vbench": {"subject_consistency": 0.9668063366164764, "background_consistency": 0.9601796468098959, "motion_smoothness": 0.9921140337854535, "aesthetic_quality": 0.5438400506973267, "imaging_quality": 0.5416005247466419, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1ddb0acfc365492595e0fe5dd029d86f.mp4", "adv_score": 0.0, "adv_xclip": 0.1577993631362915, "adv_vbench": {"subject_consistency": 0.980263422553738, "background_consistency": 0.9712727864583334, "motion_smoothness": 0.9896800983607177, "aesthetic_quality": 0.4972028136253357, "imaging_quality": 0.6942679012065031, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b0314313.mp4", "clean_score": 1.0, "clean_xclip": 0.1839342564344406, "clean_vbench": {}, "adv_vid_id": "vids/4e6b2fc7.mp4", "adv_score": 1.0, "adv_xclip": 0.14484412968158722, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cfca3dba.mp4", "clean_score": 1.0, "clean_xclip": 0.17057277262210846, "clean_vbench": {}, "adv_vid_id": "vids/bc86608b.mp4", "adv_score": 0.0, "adv_xclip": 0.15816505253314972, "adv_vbench": {}}}}
{"id": "a1a893b19a2a4fcfa6b35dd5b7a2d534", "source": "vatex", "video_id": "TgGQ6awU5HE_000033_000043", "video_description": "A man is demonstrating how to tie and untie various knots, including a slip knot, using a rope attached to a pole.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a pole while demonstrating how to tie knots with a rope.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "pole"}, "target_prompt": "A person standing to the right of a pole while demonstrating how to tie knots with a rope.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "pole"}, "evaluation_question": "Is the person to the **left** of the pole?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a pole while demonstrating how to tie knots with a rope. 'C%|)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/726e5d68fadd4b2aa52279dfcc380f8b.mp4", "clean_score": 1.0, "clean_xclip": 0.182783305644989, "clean_vbench": {"subject_consistency": 0.8853808448960384, "background_consistency": 0.9212697347005209, "motion_smoothness": 0.9469076061398067, "aesthetic_quality": 0.35566216707229614, "imaging_quality": 0.5075156675066267, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ac57522d3ae148cb89b4df8c4c9208b4.mp4", "adv_score": 0.0, "adv_xclip": 0.20065176486968994, "adv_vbench": {"subject_consistency": 0.90176797285676, "background_consistency": 0.91485595703125, "motion_smoothness": 0.9540247569192286, "aesthetic_quality": 0.38830992579460144, "imaging_quality": 0.5511202714881118, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3deb553f.mp4", "clean_score": 1.0, "clean_xclip": 0.18091484904289246, "clean_vbench": {}, "adv_vid_id": "vids/15c451db.mp4", "adv_score": 0.0, "adv_xclip": 0.17542342841625214, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f77d43f8.mp4", "clean_score": 0.0, "clean_xclip": 0.21829602122306824, "clean_vbench": {}, "adv_vid_id": "vids/e9cc7716.mp4", "adv_score": 0.0, "adv_xclip": 0.19602297246456146, "adv_vbench": {}}}}
{"id": "17ba55fe903141239f816278f9b2cfd0", "source": "vatex", "video_id": "51v-7Xxpy30_000066_000076", "video_description": "A man demonstrates how to unfold and ride a folding bike, explaining its benefits and features.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrates how to unfold and ride a bike with an adjustable seat, explaining its benefits and features.", "clean_property": {"obj": "bike", "attribute": "adjustable"}, "target_prompt": "A man demonstrates how to unfold and ride a bike with a fixed seat, explaining its benefits and features.", "target_property": {"obj": "bike", "attribute": "fixed seat"}, "evaluation_question": "Does the bike have an **adjustable** seat?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man demonstrates how to unfold and ride a bike with an adjustable seat, explaining its benefits and features. Vector passende acteurs niederApproximately", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b74f3520f4c415f9c639e02149647ee.mp4", "clean_score": 1.0, "clean_xclip": 0.11884141713380814, "clean_vbench": {"subject_consistency": 0.9627889599651098, "background_consistency": 0.9528299967447916, "motion_smoothness": 0.9634455402306241, "aesthetic_quality": 0.487066388130188, "imaging_quality": 0.636053730711645, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5d1f5dca978646439291341e23d3843c.mp4", "adv_score": 0.0, "adv_xclip": 0.1458679437637329, "adv_vbench": {"subject_consistency": 0.9525098962088426, "background_consistency": 0.9739939371744791, "motion_smoothness": 0.9853971767076172, "aesthetic_quality": 0.6047117114067078, "imaging_quality": 0.6180928981547453, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/168a6d1d.mp4", "clean_score": 1.0, "clean_xclip": 0.16516242921352386, "clean_vbench": {}, "adv_vid_id": "vids/cdef3504.mp4", "adv_score": 0.0, "adv_xclip": 0.20819467306137085, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b787cfda.mp4", "clean_score": 1.0, "clean_xclip": 0.18388059735298157, "clean_vbench": {}, "adv_vid_id": "vids/9b8ad49e.mp4", "adv_score": 1.0, "adv_xclip": 0.158770352602005, "adv_vbench": {}}}}
{"id": "46d336d139ab48bba49109be0a6e7e6c", "source": "vatex", "video_id": "8hwt4z7alvw_000055_000065", "video_description": "A young man is beatboxing into a microphone in a white room, making musical noises with his mouth and throat while looking into the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone closer to the camera than a person beatboxing in a white room.", "clean_property": {"obj_1": "microphone", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A microphone further from the camera than a person beatboxing in a white room.", "target_property": {"obj_1": "microphone", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the microphone closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A microphone closer to the camera than a person beatboxing in a white room. LFYPG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d546257c38aa4f70b8b7d4e55b5730e0.mp4", "clean_score": 1.0, "clean_xclip": 0.2055174708366394, "clean_vbench": {"subject_consistency": 0.7983652967959642, "background_consistency": 0.9221598307291666, "motion_smoothness": 0.977142278214012, "aesthetic_quality": 0.24027641117572784, "imaging_quality": 0.23222845544620438, "dynamic_degree": 1.0}, "adv_vid_id": "vids/65508182bc21467793f8e9bbc2e235f7.mp4", "adv_score": 0.0, "adv_xclip": 0.13953348994255066, "adv_vbench": {"subject_consistency": 0.898188591003418, "background_consistency": 0.9564056396484375, "motion_smoothness": 0.976328131461561, "aesthetic_quality": 0.28363844752311707, "imaging_quality": 0.21655634782752212, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/89b67a71.mp4", "clean_score": 1.0, "clean_xclip": 0.19239944219589233, "clean_vbench": {}, "adv_vid_id": "vids/bf13d002.mp4", "adv_score": 0.0, "adv_xclip": 0.20109142363071442, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/906a47cf.mp4", "clean_score": 1.0, "clean_xclip": 0.20921540260314941, "clean_vbench": {}, "adv_vid_id": "vids/8f4006a9.mp4", "adv_score": 1.0, "adv_xclip": 0.15226423740386963, "adv_vbench": {}}}}
{"id": "003561c5919e4e218a78378655a44b5f", "source": "vatex", "video_id": "4eKN5-BZFFw_000181_000191", "video_description": "A person is presenting a piece of homemade jewelry, a beaded bracelet with letters forming the phrase 'I LUV YOU', in front of a camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing farther from the camera than a beaded bracelet with letters forming the phrase 'I LUV YOU'.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "bracelet"}, "target_prompt": "A person standing closer to the camera than a beaded bracelet with letters forming the phrase 'I LUV YOU'.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "bracelet"}, "evaluation_question": "Is the person farther from the camera than the bracelet?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing farther from the camera than a beaded bracelet with letters forming the phrase 'I LUV YOU'. :FE-M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f28ab29d234d41cca372bc40512a2235.mp4", "clean_score": 1.0, "clean_xclip": 0.16935360431671143, "clean_vbench": {"subject_consistency": 0.926085039973259, "background_consistency": 0.9616546630859375, "motion_smoothness": 0.9919418675424131, "aesthetic_quality": 0.41846978664398193, "imaging_quality": 0.3822647725319376, "dynamic_degree": 0.0}, "adv_vid_id": "vids/5aa8aa8930294f249823f72c11c156c4.mp4", "adv_score": 0.0, "adv_xclip": 0.05090245604515076, "adv_vbench": {"subject_consistency": 0.9804286615302166, "background_consistency": 0.9723561604817709, "motion_smoothness": 0.9945062852076273, "aesthetic_quality": 0.39444708824157715, "imaging_quality": 0.27035871817141166, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/96669119.mp4", "clean_score": 0.0, "clean_xclip": 0.22636592388153076, "clean_vbench": {}, "adv_vid_id": "vids/f9ff4551.mp4", "adv_score": 1.0, "adv_xclip": 0.18960729241371155, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/616b3544.mp4", "clean_score": 0.0, "clean_xclip": 0.2343338131904602, "clean_vbench": {}, "adv_vid_id": "vids/884f4025.mp4", "adv_score": 1.0, "adv_xclip": 0.1800992339849472, "adv_vbench": {}}}}
{"id": "2e495018043c432a9c1ba3f7eceb872d", "source": "vatex", "video_id": "4d6Ch7lhz5w_000000_000010", "video_description": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "task": "ObjectRecognition", "clean_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "clean_property": {"obj": "hair dryer"}, "target_prompt": "A man is in a kitchen using a toaster to toast bread while singing and speaking.", "target_property": {"obj": "toaster"}, "evaluation_question": "Is the man using a **hair dryer** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking. Highland Freiburg catregebucht anzu", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a25b1e658544b12b2309224566b8db6.mp4", "clean_score": 1.0, "clean_xclip": 0.15222717821598053, "clean_vbench": {"subject_consistency": 0.8826088986049095, "background_consistency": 0.9142913818359375, "motion_smoothness": 0.9605914466899156, "aesthetic_quality": 0.4550797641277313, "imaging_quality": 0.44367271656892737, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8015d1f03d914a9db66b057fa85934d3.mp4", "adv_score": 0.0, "adv_xclip": 0.18437649309635162, "adv_vbench": {"subject_consistency": 0.9378526328752438, "background_consistency": 0.938629150390625, "motion_smoothness": 0.9584675476768639, "aesthetic_quality": 0.49694424867630005, "imaging_quality": 0.5084928520358338, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ac9acd36.mp4", "clean_score": 1.0, "clean_xclip": 0.1720203459262848, "clean_vbench": {}, "adv_vid_id": "vids/37f46ba9.mp4", "adv_score": 0.0, "adv_xclip": 0.20611684024333954, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f344bf99.mp4", "clean_score": 1.0, "clean_xclip": 0.219610333442688, "clean_vbench": {}, "adv_vid_id": "vids/57130fe3.mp4", "adv_score": 1.0, "adv_xclip": 0.19749200344085693, "adv_vbench": {}}}}
{"id": "21b7ffd2c4d6431c85cac6e9cae3122f", "source": "vatex", "video_id": "1olz6MxMmEc_000043_000053", "video_description": "A man is lying in a muddy area, stands up, and walks towards the camera, adjusting it.", "task": "Counting", "clean_prompt": "Two men are lying in a muddy area, then they stand up and walk towards the camera, adjusting it.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "A man is lying in a muddy area, then he stands up and walks towards the camera, adjusting it.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men in the muddy area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are lying in a muddy area, then they stand up and walk towards the camera, adjusting it. U=H!U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c68f57a66de343ffb2a155d65d991185.mp4", "clean_score": 1.0, "clean_xclip": 0.2179190069437027, "clean_vbench": {"subject_consistency": 0.8560497031236688, "background_consistency": 0.8744099934895834, "motion_smoothness": 0.980549568998124, "aesthetic_quality": 0.47638043761253357, "imaging_quality": 0.7143106032390983, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d58736297f444fec828b1938b4b48cae.mp4", "adv_score": 0.0, "adv_xclip": 0.20201648771762848, "adv_vbench": {"subject_consistency": 0.9027539137750864, "background_consistency": 0.9124094645182291, "motion_smoothness": 0.9791875951898249, "aesthetic_quality": 0.4283173680305481, "imaging_quality": 0.7526370893205915, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cd325b4b.mp4", "clean_score": 1.0, "clean_xclip": 0.17785632610321045, "clean_vbench": {}, "adv_vid_id": "vids/f897e03c.mp4", "adv_score": 1.0, "adv_xclip": 0.182826429605484, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2098eca7.mp4", "clean_score": 1.0, "clean_xclip": 0.16850097477436066, "clean_vbench": {}, "adv_vid_id": "vids/afb3d6a8.mp4", "adv_score": 1.0, "adv_xclip": 0.18459874391555786, "adv_vbench": {}}}}
{"id": "87a59481dc694a4c9ffc69368819950d", "source": "vatex", "video_id": "TtHPzsTmMHU_000000_000010", "video_description": "A man and a woman are arranging flowers in a warehouse. The man is creating floral displays and bouquets, while the woman assists by unwrapping flowers.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse.", "clean_property": {"obj_1": "flowers", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A woman standing to the left of a bouquet of flowers in a warehouse.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "flowers"}, "evaluation_question": "Is the woman to the **right** of the bouquet of flowers?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse. *TZZ/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b30df03d639d441e956637260ef1b526.mp4", "clean_score": 1.0, "clean_xclip": 0.2491762638092041, "clean_vbench": {"subject_consistency": 0.983472378924489, "background_consistency": 0.9423472086588541, "motion_smoothness": 0.9864714033375696, "aesthetic_quality": 0.5638502240180969, "imaging_quality": 0.716396257828693, "dynamic_degree": 0.0}, "adv_vid_id": "vids/c5bcb1b1965b4d73ae7698f90c2d9dbd.mp4", "adv_score": 0.0, "adv_xclip": 0.22640098631381989, "adv_vbench": {"subject_consistency": 0.9912151241054138, "background_consistency": 0.9737904866536459, "motion_smoothness": 0.9887362239520294, "aesthetic_quality": 0.5302864909172058, "imaging_quality": 0.7309132649947186, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/378a1831.mp4", "clean_score": 0.0, "clean_xclip": 0.24429214000701904, "clean_vbench": {}, "adv_vid_id": "vids/86a28b1f.mp4", "adv_score": 0.0, "adv_xclip": 0.2659779191017151, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/47b80ad5.mp4", "clean_score": 1.0, "clean_xclip": 0.2865883708000183, "clean_vbench": {}, "adv_vid_id": "vids/15d09797.mp4", "adv_score": 1.0, "adv_xclip": 0.27718883752822876, "adv_vbench": {}}}}
{"id": "91fb6285755d4b16916fd64da2299763", "source": "vatex", "video_id": "sBl88WXnwQ4_000010_000020", "video_description": "A professional baseball game is taking place with players on the field and fans watching from the stands. A pitcher throws a strike past a batter, which is caught by the catcher. The batter swings and misses. Later, a batter hits a ball into the stands, and a fan catches it.", "task": "Counting", "clean_prompt": "Three fans cheering at a professional baseball game.", "clean_property": {"obj": "fan", "count": "three"}, "target_prompt": "One fan cheering at a professional baseball game.", "target_property": {"obj": "fan", "count": "one"}, "evaluation_question": "Are there exactly **three** fans cheering at the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three fans cheering at a professional baseball game. =)FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df2db312c9424a71bbe6887b75ee943a.mp4", "clean_score": 1.0, "clean_xclip": 0.1550227403640747, "clean_vbench": {"subject_consistency": 0.9443444746236006, "background_consistency": 0.9209442138671875, "motion_smoothness": 0.8983320651337953, "aesthetic_quality": 0.5561922788619995, "imaging_quality": 0.5516355615732621, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4b2b4041a8484fec8fadcc0a2880dd3e.mp4", "adv_score": 0.0, "adv_xclip": 0.14235752820968628, "adv_vbench": {"subject_consistency": 0.9468088019639254, "background_consistency": 0.9155069986979166, "motion_smoothness": 0.8963839834609255, "aesthetic_quality": 0.5507020354270935, "imaging_quality": 0.6967445194477938, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3d469f86.mp4", "clean_score": 0.0, "clean_xclip": 0.1699606478214264, "clean_vbench": {}, "adv_vid_id": "vids/c04fa8bf.mp4", "adv_score": 0.0, "adv_xclip": 0.17816989123821259, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/31bd7c4f.mp4", "clean_score": 1.0, "clean_xclip": 0.16997674107551575, "clean_vbench": {}, "adv_vid_id": "vids/e647505a.mp4", "adv_score": 1.0, "adv_xclip": 0.20340724289417267, "adv_vbench": {}}}}
{"id": "6e51c7b047834eec9b5799e26221ae8b", "source": "vatex", "video_id": "Fg-xNvFjJJI_000000_000010", "video_description": "A person is being pulled by a team of dogs through the woods on a wheeled contraption, which resembles a modified bicycle or sled.", "task": "AttributeRecognition", "clean_prompt": "A person being pulled by a team of dogs through the woods on a wheeled contraption, which resembles a modified bicycle.", "clean_property": {"obj": "wheeled contraption", "attribute": "modified bicycle"}, "target_prompt": "A person being pulled by a team of dogs through the woods on a motorized scooter.", "target_property": {"obj": "wheeled contraption", "attribute": "motorized scooter"}, "evaluation_question": "Is the wheeled contraption a **modified bicycle**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person being pulled by a team of dogs through the woods on a wheeled contraption, which resembles a modified bicycle. OT@@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f046f2b4328b48c68757bb800f2b4027.mp4", "clean_score": 1.0, "clean_xclip": 0.1978490948677063, "clean_vbench": {"subject_consistency": 0.8559045636405548, "background_consistency": 0.9176279703776041, "motion_smoothness": 0.9646506681569234, "aesthetic_quality": 0.5671554207801819, "imaging_quality": 0.6860754705935108, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ce0e4c97d6c7482796bead6b5d7c82b3.mp4", "adv_score": 0.0, "adv_xclip": 0.23221907019615173, "adv_vbench": {"subject_consistency": 0.8194249135752519, "background_consistency": 0.899017333984375, "motion_smoothness": 0.9617401429675523, "aesthetic_quality": 0.557457447052002, "imaging_quality": 0.7028328027530593, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/28d0a05f.mp4", "clean_score": 0.0, "clean_xclip": 0.15528109669685364, "clean_vbench": {}, "adv_vid_id": "vids/5519d16e.mp4", "adv_score": 0.0, "adv_xclip": 0.16295361518859863, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cb0ce655.mp4", "clean_score": 0.0, "clean_xclip": 0.20192167162895203, "clean_vbench": {}, "adv_vid_id": "vids/27002b4e.mp4", "adv_score": 0.0, "adv_xclip": 0.23602211475372314, "adv_vbench": {}}}}
{"id": "44e15805abd3472ab46c7ef0a919330e", "source": "vatex", "video_id": "lHe6Ehd5S0Y_000001_000011", "video_description": "A young man with long hair is having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "task": "Counting", "clean_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people having a staring contest?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play. S+H%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/987aa256d89a4434b61fe546591cb644.mp4", "clean_score": 1.0, "clean_xclip": 0.15607887506484985, "clean_vbench": {"subject_consistency": 0.9158669399718443, "background_consistency": 0.9352773030598959, "motion_smoothness": 0.9414777333033264, "aesthetic_quality": 0.3906383812427521, "imaging_quality": 0.5758094740887078, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e1f0b1a7bda1482d87e0235b76db849e.mp4", "adv_score": 0.0, "adv_xclip": 0.17352941632270813, "adv_vbench": {"subject_consistency": 0.897530123591423, "background_consistency": 0.906829833984375, "motion_smoothness": 0.9257727595088961, "aesthetic_quality": 0.38772886991500854, "imaging_quality": 0.47854433020766896, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9cf7b9cd.mp4", "clean_score": 1.0, "clean_xclip": 0.17819814383983612, "clean_vbench": {}, "adv_vid_id": "vids/3ea1f3af.mp4", "adv_score": 0.0, "adv_xclip": 0.15125983953475952, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bde4fa43.mp4", "clean_score": 0.0, "clean_xclip": 0.17440447211265564, "clean_vbench": {}, "adv_vid_id": "vids/a934e0aa.mp4", "adv_score": 1.0, "adv_xclip": 0.16467532515525818, "adv_vbench": {}}}}
{"id": "f342b877f9194a6bac5a85423915afe1", "source": "vatex", "video_id": "x6m12TincPk_000151_000161", "video_description": "A woman is in a bathroom using an electric razor to shave all the hair off her head.", "task": "ObjectRecognition", "clean_prompt": "A woman in a bathroom using an electric razor to shave all the hair off her head.", "clean_property": {"obj": "person"}, "target_prompt": "A man in a bathroom using an electric razor to shave all the hair off his head.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman in a bathroom using an electric razor to shave all the hair off her head. Mircea principii profesor Schmuck Waffen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2669de60803848a7831189b82eeea33a.mp4", "clean_score": 1.0, "clean_xclip": 0.2485624998807907, "clean_vbench": {"subject_consistency": 0.8684700684001049, "background_consistency": 0.9182281494140625, "motion_smoothness": 0.9669902584876543, "aesthetic_quality": 0.4160749018192291, "imaging_quality": 0.4471404811314174, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e6d163e3b3c149c6bc65deb372ce259a.mp4", "adv_score": 0.0, "adv_xclip": 0.20448331534862518, "adv_vbench": {"subject_consistency": 0.9346444886177778, "background_consistency": 0.9564107259114584, "motion_smoothness": 0.9864435795408698, "aesthetic_quality": 0.36621272563934326, "imaging_quality": 0.5774553984038684, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9e46bc98.mp4", "clean_score": 1.0, "clean_xclip": 0.16871875524520874, "clean_vbench": {}, "adv_vid_id": "vids/497e3f74.mp4", "adv_score": 1.0, "adv_xclip": 0.12335772812366486, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a52489c9.mp4", "clean_score": 1.0, "clean_xclip": 0.18820720911026, "clean_vbench": {}, "adv_vid_id": "vids/80234806.mp4", "adv_score": 1.0, "adv_xclip": 0.19519750773906708, "adv_vbench": {}}}}
{"id": "dbe92508b57d44f1984b0f32d3ff3114", "source": "vatex", "video_id": "cm66wB7giOM_000000_000010", "video_description": "A group of people, including children, are playing kickball in a grassy field. The game involves rolling, kicking, and catching the ball.", "task": "Counting", "clean_prompt": "Four children are playing kickball in a grassy field.", "clean_property": {"obj": "ball", "count": "four"}, "target_prompt": "One child is playing with a ball in a sandy beach.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **four** children playing kickball in the grassy field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four children are playing kickball in a grassy field. FE4@I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6418d60732514b32b56f4635596d49ec.mp4", "clean_score": 1.0, "clean_xclip": 0.17400714755058289, "clean_vbench": {"subject_consistency": 0.9172804374247789, "background_consistency": 0.9247233072916666, "motion_smoothness": 0.9679826852230089, "aesthetic_quality": 0.5336624979972839, "imaging_quality": 0.6938104894209881, "dynamic_degree": 1.0}, "adv_vid_id": "vids/df14db7dd27c40c0950120ef6b3d00a8.mp4", "adv_score": 0.0, "adv_xclip": 0.21434830129146576, "adv_vbench": {"subject_consistency": 0.8865775372833014, "background_consistency": 0.9342702229817709, "motion_smoothness": 0.962669674759693, "aesthetic_quality": 0.49129748344421387, "imaging_quality": 0.5586842112638513, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3e0adcc1.mp4", "clean_score": 0.0, "clean_xclip": 0.1977505087852478, "clean_vbench": {}, "adv_vid_id": "vids/b57064b5.mp4", "adv_score": 1.0, "adv_xclip": 0.21366330981254578, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/59a6668c.mp4", "clean_score": 1.0, "clean_xclip": 0.21816733479499817, "clean_vbench": {}, "adv_vid_id": "vids/da90a9f8.mp4", "adv_score": 1.0, "adv_xclip": 0.22283968329429626, "adv_vbench": {}}}}
{"id": "ac83fcd7aafe48ad96a3e481afb267d7", "source": "vatex", "video_id": "kSdDF-ry2Cg_000011_000021", "video_description": "A skateboarder in a red shirt is performing tricks in a skate park with a curved area and ramps, while a group of people watch.", "task": "Counting", "clean_prompt": "Six people watching a skateboarder in a red shirt performing tricks in a skate park.", "clean_property": {"obj": "audience", "count": "six"}, "target_prompt": "Three people watching a skateboarder in a red shirt performing tricks in a skate park.", "target_property": {"obj": "audience", "count": "three"}, "evaluation_question": "Are there exactly **six** people watching the skateboarder?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Six people watching a skateboarder in a red shirt performing tricks in a skate park. :W0Z0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5a121c6875c04396964a7b4d5d2722bd.mp4", "clean_score": 1.0, "clean_xclip": 0.20144158601760864, "clean_vbench": {"subject_consistency": 0.9428074440608422, "background_consistency": 0.92999267578125, "motion_smoothness": 0.9758824749228394, "aesthetic_quality": 0.5578526258468628, "imaging_quality": 0.6614508554886798, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c42d122d826345ff854068a8b774c48f.mp4", "adv_score": 0.0, "adv_xclip": 0.22242602705955505, "adv_vbench": {"subject_consistency": 0.9568523876369, "background_consistency": 0.9623667399088541, "motion_smoothness": 0.9808103596473312, "aesthetic_quality": 0.5340781807899475, "imaging_quality": 0.6671401019972198, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f3349595.mp4", "clean_score": 0.0, "clean_xclip": 0.17167788743972778, "clean_vbench": {}, "adv_vid_id": "vids/a893bf7f.mp4", "adv_score": 1.0, "adv_xclip": 0.20843178033828735, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3e109437.mp4", "clean_score": 0.0, "clean_xclip": 0.21913492679595947, "clean_vbench": {}, "adv_vid_id": "vids/beae3514.mp4", "adv_score": 0.0, "adv_xclip": 0.20578554272651672, "adv_vbench": {}}}}
{"id": "dce1249fbb414befb45ff9f72daa6e44", "source": "vatex", "video_id": "aZq9W61seMw_000009_000019", "video_description": "A woman is practicing fencing and sword fighting skills indoors, seemingly dueling with herself while yelling and talking about various topics.", "task": "SpatialUnderstanding", "clean_prompt": "A sword positioned to the left of a person practicing fencing indoors.", "clean_property": {"obj_1": "sword", "relation": "left of", "obj_2": "person"}, "target_prompt": "A sword positioned to the right of a person practicing fencing indoors.", "target_property": {"obj_1": "sword", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the sword to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A sword positioned to the left of a person practicing fencing indoors. juridic Leichteinandergegangen Schalt", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b5a8ba6f979407990b7523d95fb0c5d.mp4", "clean_score": 1.0, "clean_xclip": 0.17788943648338318, "clean_vbench": {"subject_consistency": 0.7992315161973238, "background_consistency": 0.9337615966796875, "motion_smoothness": 0.9729667570024408, "aesthetic_quality": 0.33870938420295715, "imaging_quality": 0.1863197998124726, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c43f4e5cdb8e499ca2386d1e5d40cee2.mp4", "adv_score": 0.0, "adv_xclip": 0.08490510284900665, "adv_vbench": {"subject_consistency": 0.6993101499974728, "background_consistency": 0.920928955078125, "motion_smoothness": 0.9765542780576737, "aesthetic_quality": 0.2911964952945709, "imaging_quality": 0.15371226855686732, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cfa85e4c.mp4", "clean_score": 0.0, "clean_xclip": 0.2160869836807251, "clean_vbench": {}, "adv_vid_id": "vids/8bef9ad4.mp4", "adv_score": 0.0, "adv_xclip": 0.2210208922624588, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/eef23253.mp4", "clean_score": 0.0, "clean_xclip": 0.19137638807296753, "clean_vbench": {}, "adv_vid_id": "vids/8134b631.mp4", "adv_score": 0.0, "adv_xclip": 0.19620150327682495, "adv_vbench": {}}}}
{"id": "86e2d07fb36b4517883df0ffbe4a226c", "source": "vatex", "video_id": "NAshG3XdoLA_000041_000051", "video_description": "A man and a woman dressed in old English outfits are playing unique string instruments, including a violin and a guitar-like instrument, inside a decorated room.", "task": "AttributeRecognition", "clean_prompt": "A musician dressed in old English outfits is playing unique string instruments in a decorated room.", "clean_property": {"obj": "musician", "attribute": "dressed in old English outfits"}, "target_prompt": "A musician dressed in modern casual clothing is playing unique string instruments in a decorated room.", "target_property": {"obj": "musician", "attribute": "dressed in modern casual clothing"}, "evaluation_question": "Is the musician dressed in **old English outfits**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A musician dressed in old English outfits is playing unique string instruments in a decorated room. vector glitch Illustration kreativefarbig", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/efeb7e4753e04d7fa10df3697f5adfad.mp4", "clean_score": 1.0, "clean_xclip": 0.18018805980682373, "clean_vbench": {"subject_consistency": 0.9575580507516861, "background_consistency": 0.9473317464192709, "motion_smoothness": 0.982107948728617, "aesthetic_quality": 0.687482476234436, "imaging_quality": 0.6609091311084981, "dynamic_degree": 0.0}, "adv_vid_id": "vids/4e502c55b1aa4713a13ba16e5568a956.mp4", "adv_score": 0.0, "adv_xclip": 0.10870067030191422, "adv_vbench": {"subject_consistency": 0.9153629777332147, "background_consistency": 0.9342702229817709, "motion_smoothness": 0.9165045100119523, "aesthetic_quality": 0.5718052387237549, "imaging_quality": 0.7448087723401128, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2f7cfacd.mp4", "clean_score": 1.0, "clean_xclip": 0.12484618276357651, "clean_vbench": {}, "adv_vid_id": "vids/60e005c7.mp4", "adv_score": 1.0, "adv_xclip": 0.1161811500787735, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/69d8e333.mp4", "clean_score": 1.0, "clean_xclip": 0.18539853394031525, "clean_vbench": {}, "adv_vid_id": "vids/d64d662b.mp4", "adv_score": 1.0, "adv_xclip": 0.12961088120937347, "adv_vbench": {}}}}
{"id": "37149458d9bb42d7a8503c3e7a43269f", "source": "vatex", "video_id": "n4Lh325FdGM_000000_000010", "video_description": "A tattoo artist is performing a belly button piercing on a woman in a piercing parlor.", "task": "ObjectRecognition", "clean_prompt": "A tattoo artist is using clamps while performing a belly button piercing on a woman in a piercing parlor.", "clean_property": {"obj": "clamps"}, "target_prompt": "A tattoo artist is using scissors while performing a belly button piercing on a woman in a piercing parlor.", "target_property": {"obj": "scissors"}, "evaluation_question": "Is the tattoo artist using **clamps** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A tattoo artist is using clamps while performing a belly button piercing on a woman in a piercing parlor. Fotografi industriellewirtschaftaufnahmebond", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b470dd5e79be40fc9953c9e1e1e13bfa.mp4", "clean_score": 1.0, "clean_xclip": 0.2854018211364746, "clean_vbench": {"subject_consistency": 0.8762902685751518, "background_consistency": 0.9299265543619791, "motion_smoothness": 0.9768473889620148, "aesthetic_quality": 0.3798898756504059, "imaging_quality": 0.45471610439066984, "dynamic_degree": 1.0}, "adv_vid_id": "vids/62377c4cc5c34f6d826e02e0c4e78b3e.mp4", "adv_score": 0.0, "adv_xclip": 0.25816959142684937, "adv_vbench": {"subject_consistency": 0.9160531566788753, "background_consistency": 0.9580485026041666, "motion_smoothness": 0.9776744496956448, "aesthetic_quality": 0.3515153229236603, "imaging_quality": 0.5716068999621333, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7dbdf622.mp4", "clean_score": 0.0, "clean_xclip": 0.25152358412742615, "clean_vbench": {}, "adv_vid_id": "vids/51a60a50.mp4", "adv_score": 0.0, "adv_xclip": 0.2304019331932068, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c23bc12e.mp4", "clean_score": 1.0, "clean_xclip": 0.26188015937805176, "clean_vbench": {}, "adv_vid_id": "vids/38441e03.mp4", "adv_score": 1.0, "adv_xclip": 0.24864992499351501, "adv_vbench": {}}}}
{"id": "f8d7db022f9a4d0ba63fc7aa9d7b020e", "source": "vatex", "video_id": "Rnta1wIPe1s_000196_000206", "video_description": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom. Another man is present, talking.", "task": "Counting", "clean_prompt": "A young man is ironing two shirts on an ironing board in a bathroom.", "clean_property": {"obj": "shirt", "count": "two"}, "target_prompt": "A young man is ironing one shirt on an ironing board in a bathroom.", "target_property": {"obj": "shirt", "count": "one"}, "evaluation_question": "Are there exactly **two** shirts being ironed?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man is ironing two shirts on an ironing board in a bathroom.olin erkennt remarque Textil Vector", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4152964b59f741889161ee19ba9e59a4.mp4", "clean_score": 1.0, "clean_xclip": 0.2098425328731537, "clean_vbench": {"subject_consistency": 0.9651699457317591, "background_consistency": 0.9542490641276041, "motion_smoothness": 0.9745987350154826, "aesthetic_quality": 0.45015034079551697, "imaging_quality": 0.7520417069415657, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bfa1078addd1494191ea728f3cb1e03c.mp4", "adv_score": 0.0, "adv_xclip": 0.196742981672287, "adv_vbench": {"subject_consistency": 0.951223690683643, "background_consistency": 0.956817626953125, "motion_smoothness": 0.9846983661391512, "aesthetic_quality": 0.6000843048095703, "imaging_quality": 0.6995157778992944, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f3762add.mp4", "clean_score": 0.0, "clean_xclip": 0.22083772718906403, "clean_vbench": {}, "adv_vid_id": "vids/36f05e4c.mp4", "adv_score": 0.0, "adv_xclip": 0.23809561133384705, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/579f00bc.mp4", "clean_score": 1.0, "clean_xclip": 0.22574076056480408, "clean_vbench": {}, "adv_vid_id": "vids/f1c9f0a4.mp4", "adv_score": 0.0, "adv_xclip": 0.2141951322555542, "adv_vbench": {}}}}
{"id": "0566e11e3bac428e98278cd0c085b1d1", "source": "vatex", "video_id": "9ALCrxTtYr4_000261_000271", "video_description": "A person is sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "task": "Counting", "clean_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "clean_property": {"obj": "tool", "count": "three"}, "target_prompt": "A person is sitting on the ground using one tool to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "target_property": {"obj": "tool", "count": "one"}, "evaluation_question": "Are there exactly **three** tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree. !?CW*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/395220ac4d8a42bbb6b0de635af05647.mp4", "clean_score": 1.0, "clean_xclip": 0.24435923993587494, "clean_vbench": {"subject_consistency": 0.9659199019273123, "background_consistency": 0.9641062418619791, "motion_smoothness": 0.9768554416429638, "aesthetic_quality": 0.4634832441806793, "imaging_quality": 0.7766463159055127, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f90bd9afa7334ec9be4790def87c7a12.mp4", "adv_score": 0.0, "adv_xclip": 0.25526171922683716, "adv_vbench": {"subject_consistency": 0.9633755479007959, "background_consistency": 0.957000732421875, "motion_smoothness": 0.9780914656018015, "aesthetic_quality": 0.39972367882728577, "imaging_quality": 0.777067119053432, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/674ed8e2.mp4", "clean_score": 0.0, "clean_xclip": 0.17508873343467712, "clean_vbench": {}, "adv_vid_id": "vids/a839b686.mp4", "adv_score": 0.0, "adv_xclip": 0.19337505102157593, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3f121d26.mp4", "clean_score": 1.0, "clean_xclip": 0.26798346638679504, "clean_vbench": {}, "adv_vid_id": "vids/fdadb59d.mp4", "adv_score": 1.0, "adv_xclip": 0.1828029751777649, "adv_vbench": {}}}}
{"id": "39bb756f35f74d5d8ad17a9cab8f93d5", "source": "vatex", "video_id": "lCea4HWl1Cs_000225_000235", "video_description": "Two men are playing badminton indoors on a green court, wearing blue shirts. They hit a shuttlecock back and forth over a net.", "task": "SpatialUnderstanding", "clean_prompt": "A net positioned to the left of a player on a green badminton court.", "clean_property": {"obj_1": "net", "relation": "left of", "obj_2": "player"}, "target_prompt": "A net positioned to the right of a player on a green badminton court.", "target_property": {"obj_1": "net", "relation": "right of", "obj_2": "player"}, "evaluation_question": "Is the net to the **left** of the player?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A net positioned to the left of a player on a green badminton court. !3BCX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b389e18352ed4f86b35ca227d02cd330.mp4", "clean_score": 1.0, "clean_xclip": 0.19534829258918762, "clean_vbench": {"subject_consistency": 0.9656869204094013, "background_consistency": 0.9341684977213541, "motion_smoothness": 0.9887603303023885, "aesthetic_quality": 0.4538457691669464, "imaging_quality": 0.6393637046035455, "dynamic_degree": 0.0}, "adv_vid_id": "vids/3ebac9bd5fd24f8bac54a692e6421e7d.mp4", "adv_score": 0.0, "adv_xclip": 0.23206400871276855, "adv_vbench": {"subject_consistency": 0.9734715682764848, "background_consistency": 0.9591573079427084, "motion_smoothness": 0.992894482079097, "aesthetic_quality": 0.4374436140060425, "imaging_quality": 0.6721369163357481, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8d3aa40b.mp4", "clean_score": 0.0, "clean_xclip": 0.12635695934295654, "clean_vbench": {}, "adv_vid_id": "vids/9ce158b5.mp4", "adv_score": 0.0, "adv_xclip": 0.15967796742916107, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0f0a6386.mp4", "clean_score": 0.0, "clean_xclip": 0.21596014499664307, "clean_vbench": {}, "adv_vid_id": "vids/3d0ad2a8.mp4", "adv_score": 0.0, "adv_xclip": 0.1803094744682312, "adv_vbench": {}}}}
{"id": "f49cbe37303045c0ba089b63d4c1e652", "source": "vatex", "video_id": "xzv6LXjujMA_000032_000042", "video_description": "A group of young men are outside playing a game of dominoes on a table and the trunk of a car, using profane language and shouting playfully.", "task": "SpatialUnderstanding", "clean_prompt": "A car parked to the left of a man.", "clean_property": {"obj_1": "car", "relation": "left of", "obj_2": "man"}, "target_prompt": "A car parked to the right of a man.", "target_property": {"obj_1": "car", "relation": "right of", "obj_2": "man"}, "evaluation_question": "Is the car to the **left** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A car parked to the left of a man. :@)C#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/039aff366a6b4d1dbc37883cc888efbb.mp4", "clean_score": 1.0, "clean_xclip": 0.12622231245040894, "clean_vbench": {"subject_consistency": 0.9332392401993275, "background_consistency": 0.9686126708984375, "motion_smoothness": 0.9891371349690854, "aesthetic_quality": 0.4719425439834595, "imaging_quality": 0.6564266165908502, "dynamic_degree": 0.0}, "adv_vid_id": "vids/03441636dc4349f5a30449369bae9991.mp4", "adv_score": 0.0, "adv_xclip": 0.13037241995334625, "adv_vbench": {"subject_consistency": 0.997542558858792, "background_consistency": 0.9820709228515625, "motion_smoothness": 0.9964055308755446, "aesthetic_quality": 0.5314985513687134, "imaging_quality": 0.7594210036920042, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b1c79dde.mp4", "clean_score": 0.0, "clean_xclip": 0.1330416053533554, "clean_vbench": {}, "adv_vid_id": "vids/34af40a7.mp4", "adv_score": 0.0, "adv_xclip": 0.11373800784349442, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4263a41e.mp4", "clean_score": 0.0, "clean_xclip": 0.14207953214645386, "clean_vbench": {}, "adv_vid_id": "vids/89e6cf85.mp4", "adv_score": 0.0, "adv_xclip": 0.13412830233573914, "adv_vbench": {}}}}
{"id": "403047bc66d540dfbd5b37947ffea98b", "source": "vatex", "video_id": "7qTjhLfDb7c_000063_000073", "video_description": "A young girl is riding a unicycle back and forth in a living room, demonstrating and explaining how to balance on it.", "task": "ActionRecognition", "clean_prompt": "A girl riding a unicycle back and forth in a living room.", "clean_property": {"obj": "girl", "action": "riding unicycle", "target": null}, "target_prompt": "A girl falling off a unicycle in a living room.", "target_property": {"obj": "girl", "action": "falling off unicycle", "target": null}, "evaluation_question": "Is the girl **riding** a unicycle?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A girl riding a unicycle back and forth in a living room. &\u00b7)!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cdbd3a1c0bee432c8781ce350e2556e2.mp4", "clean_score": 1.0, "clean_xclip": 0.25649112462997437, "clean_vbench": {"subject_consistency": 0.980134770895044, "background_consistency": 0.9665476481119791, "motion_smoothness": 0.9916851084344488, "aesthetic_quality": 0.5092329382896423, "imaging_quality": 0.6650235989629006, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e75c45cfd5214d32bcf8b313ae1ee760.mp4", "adv_score": 0.0, "adv_xclip": 0.23181386291980743, "adv_vbench": {"subject_consistency": 0.9815855560203394, "background_consistency": 0.9715576171875, "motion_smoothness": 0.9945671783277354, "aesthetic_quality": 0.5626828074455261, "imaging_quality": 0.7167157830997389, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c6aa653a.mp4", "clean_score": 1.0, "clean_xclip": 0.24061432480812073, "clean_vbench": {}, "adv_vid_id": "vids/4f9bdaac.mp4", "adv_score": 1.0, "adv_xclip": 0.24684646725654602, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1c1b5020.mp4", "clean_score": 1.0, "clean_xclip": 0.2624927759170532, "clean_vbench": {}, "adv_vid_id": "vids/da6111d5.mp4", "adv_score": 1.0, "adv_xclip": 0.25471508502960205, "adv_vbench": {}}}}
{"id": "3a9ecfe3a5114fd69e5cbf63dfc75757", "source": "vatex", "video_id": "xzv6LXjujMA_000032_000042", "video_description": "A group of young men are outside playing a game of dominoes on a table and the trunk of a car, using profane language and shouting playfully.", "task": "SpatialUnderstanding", "clean_prompt": "A car parked to the left of a man.", "clean_property": {"obj_1": "car", "relation": "left of", "obj_2": "man"}, "target_prompt": "A car parked to the right of a man.", "target_property": {"obj_1": "car", "relation": "right of", "obj_2": "man"}, "evaluation_question": "Is the car to the **left** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A car parked to the left of a man. gracious einem Silber McN dorit", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cbd606638d6423dae83a70efd0f39ec.mp4", "clean_score": 1.0, "clean_xclip": 0.12622231245040894, "clean_vbench": {"subject_consistency": 0.9332392401993275, "background_consistency": 0.9686126708984375, "motion_smoothness": 0.9891371349690854, "aesthetic_quality": 0.4719425439834595, "imaging_quality": 0.6564266165908502, "dynamic_degree": 0.0}, "adv_vid_id": "vids/0b662f07e888438ab130048096fd04a6.mp4", "adv_score": 0.0, "adv_xclip": 0.1266113966703415, "adv_vbench": {"subject_consistency": 0.9995563142001629, "background_consistency": 0.9974416097005209, "motion_smoothness": 0.9964639998070988, "aesthetic_quality": 0.6381517648696899, "imaging_quality": 0.7613685903743821, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4c15f837.mp4", "clean_score": 0.0, "clean_xclip": 0.11911585181951523, "clean_vbench": {}, "adv_vid_id": "vids/61252702.mp4", "adv_score": 1.0, "adv_xclip": 0.1324218511581421, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/89e020d9.mp4", "clean_score": 0.0, "clean_xclip": 0.15353552997112274, "clean_vbench": {}, "adv_vid_id": "vids/ff08d395.mp4", "adv_score": 0.0, "adv_xclip": 0.14865274727344513, "adv_vbench": {}}}}
{"id": "8b8de1c1989848f3a77ffb31c5e3dcec", "source": "vatex", "video_id": "-AvjZ4eRgRM_000049_000059", "video_description": "A young man is practicing soccer tricks alone on a field, juggling and dribbling a soccer ball.", "task": "ActionRecognition", "clean_prompt": "A person juggling a soccer ball on a field.", "clean_property": {"obj": "person", "action": "juggling soccer ball", "target": null}, "target_prompt": "A person kicking a soccer ball on a field.", "target_property": {"obj": "person", "action": "kicking soccer ball", "target": null}, "evaluation_question": "Is the person **juggling** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person juggling a soccer ball on a field. )LF*3", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/80458aba032c43aca5328fde9fb677f5.mp4", "clean_score": 1.0, "clean_xclip": 0.21595975756645203, "clean_vbench": {"subject_consistency": 0.8846056709686915, "background_consistency": 0.9181162516276041, "motion_smoothness": 0.9298480593883645, "aesthetic_quality": 0.48452359437942505, "imaging_quality": 0.533626682515047, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4562aa6e915f4e9ab7a9107dea2c0833.mp4", "adv_score": 0.0, "adv_xclip": 0.16856727004051208, "adv_vbench": {"subject_consistency": 0.8630731565256914, "background_consistency": 0.9391835530598959, "motion_smoothness": 0.9180512986476741, "aesthetic_quality": 0.45193004608154297, "imaging_quality": 0.39975681772037425, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1bcd1a13.mp4", "clean_score": 1.0, "clean_xclip": 0.2087033987045288, "clean_vbench": {}, "adv_vid_id": "vids/1c425a70.mp4", "adv_score": 0.0, "adv_xclip": 0.2266225516796112, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1d97f8bd.mp4", "clean_score": 1.0, "clean_xclip": 0.17606160044670105, "clean_vbench": {}, "adv_vid_id": "vids/4274bf21.mp4", "adv_score": 1.0, "adv_xclip": 0.2018558382987976, "adv_vbench": {}}}}
{"id": "f4040c5d718b4d4da5614ce6c2905384", "source": "vatex", "video_id": "aJTF-3Gno6g_000006_000016", "video_description": "A woman is performing a slow sit-up exercise on the ground, repeatedly lying back and sitting up to touch her toes.", "task": "ActionRecognition", "clean_prompt": "A person performing a slow sit-up exercise on the ground.", "clean_property": {"obj": "person", "action": "situp", "target": null}, "target_prompt": "A person jumping in a gym.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **performing a sit-up**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing a slow sit-up exercise on the ground. !0*);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19df9a219c03412f8e6b97bebf1a9d33.mp4", "clean_score": 1.0, "clean_xclip": 0.17956934869289398, "clean_vbench": {"subject_consistency": 0.9292487495889267, "background_consistency": 0.931396484375, "motion_smoothness": 0.9817414316549665, "aesthetic_quality": 0.47710371017456055, "imaging_quality": 0.6764415180439852, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ebe757fe8caa4f67a5f331333f2b8fae.mp4", "adv_score": 0.0, "adv_xclip": 0.20466896891593933, "adv_vbench": {"subject_consistency": 0.9504693113267422, "background_consistency": 0.944488525390625, "motion_smoothness": 0.9908182429093036, "aesthetic_quality": 0.4413870871067047, "imaging_quality": 0.6515097863333565, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/594d2138.mp4", "clean_score": 0.0, "clean_xclip": 0.16303254663944244, "clean_vbench": {}, "adv_vid_id": "vids/e3a3e501.mp4", "adv_score": 0.0, "adv_xclip": 0.15932565927505493, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a4772293.mp4", "clean_score": 0.0, "clean_xclip": 0.06717057526111603, "clean_vbench": {}, "adv_vid_id": "vids/d2a9e990.mp4", "adv_score": 0.0, "adv_xclip": 0.10579691082239151, "adv_vbench": {}}}}
{"id": "fd9383ef5ac3458dbd41f24eec574fec", "source": "vatex", "video_id": "QgWqXNe-4Ac_000134_000144", "video_description": "A man is in a workshop using a large machine to trim and shape large pieces of wood into smaller planks.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a machine in a workshop.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "machine"}, "target_prompt": "A person repairing a machine in a workshop.", "target_property": {"obj": "person", "action": "repairing a machine", "target": "machine"}, "evaluation_question": "Is the person **using a sledge hammer** on the machine?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person using a sledge hammer on a machine in a workshop. parlesozialenkopf pronunciationartikel", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5102cd896a2a450e97115feb14dbae5c.mp4", "clean_score": 1.0, "clean_xclip": 0.11955800652503967, "clean_vbench": {"subject_consistency": 0.9456684378286203, "background_consistency": 0.9743754069010416, "motion_smoothness": 0.950628929259461, "aesthetic_quality": 0.4102700650691986, "imaging_quality": 0.4356498889533841, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dc12b476199a4b9cab1889a038cca9ab.mp4", "adv_score": 0.0, "adv_xclip": 0.12108015269041061, "adv_vbench": {"subject_consistency": 0.9382916949689388, "background_consistency": 0.9592234293619791, "motion_smoothness": 0.9431887048447207, "aesthetic_quality": 0.4015349745750427, "imaging_quality": 0.5020850348959164, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6103b0c9.mp4", "clean_score": 0.0, "clean_xclip": 0.15220670402050018, "clean_vbench": {}, "adv_vid_id": "vids/2e1e1b57.mp4", "adv_score": 1.0, "adv_xclip": 0.13946731388568878, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/17390394.mp4", "clean_score": 0.0, "clean_xclip": 0.120953768491745, "clean_vbench": {}, "adv_vid_id": "vids/c6211488.mp4", "adv_score": 1.0, "adv_xclip": 0.17559346556663513, "adv_vbench": {}}}}
{"id": "58d67a9453de4390b165db91941257ed", "source": "vatex", "video_id": "Whfyh4v6Mkw_000001_000011", "video_description": "A group of people, including a woman and a child, are playing a game of Monopoly. They are handling cards and money, discussing the rules, and making transactions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a Monopoly board.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "Monopoly board"}, "target_prompt": "A person further from the camera than a Monopoly board.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "Monopoly board"}, "evaluation_question": "Is the person **closer to the camera than** the Monopoly board?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person closer to the camera than a Monopoly board. 0BC$%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7197afe537cd4bd082c7a7c79c88d46c.mp4", "clean_score": 1.0, "clean_xclip": 0.09615785628557205, "clean_vbench": {"subject_consistency": 0.9864101173977057, "background_consistency": 0.9820556640625, "motion_smoothness": 0.9953633455504115, "aesthetic_quality": 0.39982351660728455, "imaging_quality": 0.22616912335765604, "dynamic_degree": 0.0}, "adv_vid_id": "vids/b9536ee4f1c249baab21130d4e94fcee.mp4", "adv_score": 0.0, "adv_xclip": 0.07796276360750198, "adv_vbench": {"subject_consistency": 0.9947864543646574, "background_consistency": 0.9896036783854166, "motion_smoothness": 0.9973527014683188, "aesthetic_quality": 0.21881937980651855, "imaging_quality": 0.24730861702743842, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b04eaa36.mp4", "clean_score": 0.0, "clean_xclip": 0.100025475025177, "clean_vbench": {}, "adv_vid_id": "vids/1eeead58.mp4", "adv_score": 0.0, "adv_xclip": 0.10965153574943542, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2307b20f.mp4", "clean_score": 1.0, "clean_xclip": 0.13440927863121033, "clean_vbench": {}, "adv_vid_id": "vids/76a686b2.mp4", "adv_score": 1.0, "adv_xclip": 0.13472363352775574, "adv_vbench": {}}}}
{"id": "5ebbd46746714d7d833fe5433fcc930c", "source": "vatex", "video_id": "0m0-Q0zz_-c_000112_000122", "video_description": "A man in a suit is demonstrating how to tie a bow tie using his leg as a model, providing instructions on the proper technique.", "task": "ActionRecognition", "clean_prompt": "A person tying a bow tie using their leg as a model.", "clean_property": {"obj": "person", "action": "tying bow tie", "target": null}, "target_prompt": "A person removing a bow tie using their leg as a model.", "target_property": {"obj": "person", "action": "removing bow tie", "target": null}, "evaluation_question": "Is the person **tying** a bow tie?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person tying a bow tie using their leg as a model. Fingerreiz sightseeing plonge uman", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c7fd8f234e5f46ac9a3c2ac02d32260a.mp4", "clean_score": 1.0, "clean_xclip": 0.26727187633514404, "clean_vbench": {"subject_consistency": 0.9494753299901882, "background_consistency": 0.942108154296875, "motion_smoothness": 0.9493936438097615, "aesthetic_quality": 0.404242604970932, "imaging_quality": 0.5236029348568041, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ec6a7677694f4e69bcfed8a684da489b.mp4", "adv_score": 0.0, "adv_xclip": 0.2583531439304352, "adv_vbench": {"subject_consistency": 0.936648283774654, "background_consistency": 0.9399566650390625, "motion_smoothness": 0.9592455560220488, "aesthetic_quality": 0.36347100138664246, "imaging_quality": 0.5978951629327268, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/597d630c.mp4", "clean_score": 1.0, "clean_xclip": 0.22286225855350494, "clean_vbench": {}, "adv_vid_id": "vids/97b9a47a.mp4", "adv_score": 1.0, "adv_xclip": 0.2574320435523987, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2b61e065.mp4", "clean_score": 1.0, "clean_xclip": 0.2631630003452301, "clean_vbench": {}, "adv_vid_id": "vids/e77e6a12.mp4", "adv_score": 1.0, "adv_xclip": 0.279808908700943, "adv_vbench": {}}}}
{"id": "d2cfbdc762dd4480962a0011c12cd5a5", "source": "vatex", "video_id": "l9tvjA4L1eY_000041_000051", "video_description": "A man is demonstrating and explaining how to tie a specific knot using a piece of rope, including making three wraps and forming a loop.", "task": "Counting", "clean_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with two people watching and learning.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning. W%|>/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cf3943a12c84813917c3265140bf4e3.mp4", "clean_score": 1.0, "clean_xclip": 0.22033625841140747, "clean_vbench": {"subject_consistency": 0.8825399155418078, "background_consistency": 0.9150288899739584, "motion_smoothness": 0.9670519124959654, "aesthetic_quality": 0.4790589511394501, "imaging_quality": 0.5630311436555824, "dynamic_degree": 1.0}, "adv_vid_id": "vids/700e6413aea84a2e8dced30203140375.mp4", "adv_score": 0.0, "adv_xclip": 0.20620529353618622, "adv_vbench": {"subject_consistency": 0.8709004335105419, "background_consistency": 0.9170583089192709, "motion_smoothness": 0.9675369628078855, "aesthetic_quality": 0.48158589005470276, "imaging_quality": 0.628895404582121, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c1a5d444.mp4", "clean_score": 0.0, "clean_xclip": 0.19474297761917114, "clean_vbench": {}, "adv_vid_id": "vids/f3ddc52d.mp4", "adv_score": 0.0, "adv_xclip": 0.2318999469280243, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/48204e38.mp4", "clean_score": 0.0, "clean_xclip": 0.22069311141967773, "clean_vbench": {}, "adv_vid_id": "vids/e4f6acc8.mp4", "adv_score": 0.0, "adv_xclip": 0.2453944832086563, "adv_vbench": {}}}}
{"id": "fbc36ae6930645b8919e2c57dafdcced", "source": "vatex", "video_id": "wPUeRxWYMPE_000050_000060", "video_description": "A doctor is demonstrating and explaining how to bandage a young man's head.", "task": "AttributeRecognition", "clean_prompt": "A doctor is demonstrating how to bandage a young man's head using a plastic bandage.", "clean_property": {"obj": "bandage", "attribute": "plastic"}, "target_prompt": "A doctor is demonstrating how to bandage a young man's head using a cloth bandage.", "target_property": {"obj": "bandage", "attribute": "cloth"}, "evaluation_question": "Is the bandage being used **plastic**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A doctor is demonstrating how to bandage a young man's head using a plastic bandage. LYT$X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0e6ef1754764e56a0d82ed85fc442c2.mp4", "clean_score": 1.0, "clean_xclip": 0.18342892825603485, "clean_vbench": {"subject_consistency": 0.9666429882248243, "background_consistency": 0.980621337890625, "motion_smoothness": 0.9818934433437727, "aesthetic_quality": 0.5989212989807129, "imaging_quality": 0.7058567810058594, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2b7a904033ff4879a0220de0c87f9313.mp4", "adv_score": 0.0, "adv_xclip": 0.1700463593006134, "adv_vbench": {"subject_consistency": 0.9561791885644197, "background_consistency": 0.9527994791666666, "motion_smoothness": 0.9740620142797345, "aesthetic_quality": 0.6135942935943604, "imaging_quality": 0.6986825935208067, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1bc1e365.mp4", "clean_score": 0.0, "clean_xclip": 0.11793327331542969, "clean_vbench": {}, "adv_vid_id": "vids/7d6b93b2.mp4", "adv_score": 0.0, "adv_xclip": 0.17361027002334595, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2343e2c2.mp4", "clean_score": 0.0, "clean_xclip": 0.18187811970710754, "clean_vbench": {}, "adv_vid_id": "vids/a1d6ef76.mp4", "adv_score": 0.0, "adv_xclip": 0.20772352814674377, "adv_vbench": {}}}}
{"id": "84944a7629654392a3a932da516ff164", "source": "vatex", "video_id": "22glIZfA9R4_000115_000125", "video_description": "A group of people, including children and adults, are assembling and playing with a toy train track and toy cars on the floor. A bridge is part of the track setup.", "task": "Counting", "clean_prompt": "Three toy cars racing on a colorful toy train track.", "clean_property": {"obj": "toy car", "count": "three"}, "target_prompt": "One toy car racing on a colorful toy train track.", "target_property": {"obj": "toy car", "count": "one"}, "evaluation_question": "Are there exactly **three** toy cars racing on the track?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three toy cars racing on a colorful toy train track. @&,OC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d62fce25538441c586f37b4eaef5162a.mp4", "clean_score": 1.0, "clean_xclip": 0.15589772164821625, "clean_vbench": {"subject_consistency": 0.916890949010849, "background_consistency": 0.9398600260416666, "motion_smoothness": 0.9297997677305232, "aesthetic_quality": 0.5861735939979553, "imaging_quality": 0.6685658964818838, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2842ce9d5f7149f1b16a51f199bff308.mp4", "adv_score": 0.0, "adv_xclip": 0.1809757649898529, "adv_vbench": {"subject_consistency": 0.9327290325115124, "background_consistency": 0.9573211669921875, "motion_smoothness": 0.9197108074807855, "aesthetic_quality": 0.5791847109794617, "imaging_quality": 0.6261336034658004, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d3f63bfc.mp4", "clean_score": 0.0, "clean_xclip": 0.274430513381958, "clean_vbench": {}, "adv_vid_id": "vids/55b7848e.mp4", "adv_score": 0.0, "adv_xclip": 0.2608385980129242, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/07205bbc.mp4", "clean_score": 1.0, "clean_xclip": 0.20330381393432617, "clean_vbench": {}, "adv_vid_id": "vids/251f3d60.mp4", "adv_score": 1.0, "adv_xclip": 0.2246662676334381, "adv_vbench": {}}}}
{"id": "2680c2b00d364d7ca1f8455de1b6cd50", "source": "vatex", "video_id": "UU5-ZawHHsI_000189_000199", "video_description": "A woman is giving a bath to a whining Beagle puppy in a bathtub using a cup to pour water.", "task": "ObjectRecognition", "clean_prompt": "A woman is giving a bath to a whining Beagle puppy in a bathtub using a cup to pour water.", "clean_property": {"obj": "puppy"}, "target_prompt": "A woman is giving a bath to a whining kitten in a bathtub using a cup to pour water.", "target_property": {"obj": "kitten"}, "evaluation_question": "Is the animal being bathed in the video a **puppy**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman is giving a bath to a whining Beagle puppy in a bathtub using a cup to pour water. Gestaltung feminist alimentaire Kasieni", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6944fd6d30464aab90d94cd6e9c3d068.mp4", "clean_score": 1.0, "clean_xclip": 0.20768022537231445, "clean_vbench": {"subject_consistency": 0.9632606512556473, "background_consistency": 0.9777933756510416, "motion_smoothness": 0.9837939353049605, "aesthetic_quality": 0.526308000087738, "imaging_quality": 0.6275575326413524, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0d807622806947ddb52d52149976b14d.mp4", "adv_score": 0.0, "adv_xclip": 0.21143858134746552, "adv_vbench": {"subject_consistency": 0.9617534633725882, "background_consistency": 0.9605458577473959, "motion_smoothness": 0.9792185790050331, "aesthetic_quality": 0.5139477849006653, "imaging_quality": 0.6245363500166913, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b90b80f7.mp4", "clean_score": 1.0, "clean_xclip": 0.23030775785446167, "clean_vbench": {}, "adv_vid_id": "vids/0a7380c9.mp4", "adv_score": 1.0, "adv_xclip": 0.19993866980075836, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ea986d73.mp4", "clean_score": 0.0, "clean_xclip": 0.2186882346868515, "clean_vbench": {}, "adv_vid_id": "vids/df90b4f5.mp4", "adv_score": 0.0, "adv_xclip": 0.21596059203147888, "adv_vbench": {}}}}
{"id": "c3bd3f7e0650496badf5140bddf70513", "source": "vatex", "video_id": "ZL73Rek4-ds_000838_000848", "video_description": "A young girl in an orange jacket is using a smartphone, singing and talking to herself while texting.", "task": "Counting", "clean_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting.", "clean_property": {"obj": "girl", "count": "seven"}, "target_prompt": "Four girls in blue jackets are using tablets, dancing and laughing together.", "target_property": {"obj": "girl", "count": "four"}, "evaluation_question": "Are there exactly **seven** girls in orange jackets using smartphones?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting. )~BER", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec9359934635438d855ca87912468f08.mp4", "clean_score": 1.0, "clean_xclip": 0.1822759360074997, "clean_vbench": {"subject_consistency": 0.9745612548043331, "background_consistency": 0.9809672037760416, "motion_smoothness": 0.9683583149888041, "aesthetic_quality": 0.604724109172821, "imaging_quality": 0.7517033884476642, "dynamic_degree": 1.0}, "adv_vid_id": "vids/99abdf3fd4f64e02b310ab10e54b1a15.mp4", "adv_score": 0.0, "adv_xclip": 0.16391660273075104, "adv_vbench": {"subject_consistency": 0.9784354077031215, "background_consistency": 0.9661102294921875, "motion_smoothness": 0.9701006128081376, "aesthetic_quality": 0.5076624751091003, "imaging_quality": 0.6961824129065688, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d355f28d.mp4", "clean_score": 0.0, "clean_xclip": 0.16151097416877747, "clean_vbench": {}, "adv_vid_id": "vids/51788cde.mp4", "adv_score": 0.0, "adv_xclip": 0.1711277961730957, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/148473ce.mp4", "clean_score": 0.0, "clean_xclip": 0.1929556131362915, "clean_vbench": {}, "adv_vid_id": "vids/6b1dfaa6.mp4", "adv_score": 0.0, "adv_xclip": 0.21171648800373077, "adv_vbench": {}}}}
{"id": "308af4e6c55c40398daaacccb60607a9", "source": "vatex", "video_id": "ddNvdH2O9e0_000033_000043", "video_description": "Two people are playing a game with toy guns indoors. One person is riding a unicycle while chasing the other.", "task": "ObjectRecognition", "clean_prompt": "Two people are playing a game with toy guns indoors, while one person is riding a unicycle and chasing the other.", "clean_property": {"obj": "unicycle"}, "target_prompt": "Two people are playing a game with toy guns indoors, while one person is riding a skateboard and chasing the other.", "target_property": {"obj": "skateboard"}, "evaluation_question": "Is the person riding a **unicycle**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two people are playing a game with toy guns indoors, while one person is riding a unicycle and chasing the other.MJ Licht Ersatzteile hobby Unterricht", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc41c4e1122a46fe9988104dffbd2031.mp4", "clean_score": 1.0, "clean_xclip": 0.2568226754665375, "clean_vbench": {"subject_consistency": 0.888949245835344, "background_consistency": 0.9140879313151041, "motion_smoothness": 0.944352099282357, "aesthetic_quality": 0.5337084531784058, "imaging_quality": 0.4405301705185248, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5874a3d3d640480a979b6251a04d2f1a.mp4", "adv_score": 0.0, "adv_xclip": 0.2251390516757965, "adv_vbench": {"subject_consistency": 0.8479717796047529, "background_consistency": 0.9111785888671875, "motion_smoothness": 0.9395632139236868, "aesthetic_quality": 0.5118874311447144, "imaging_quality": 0.39218774600904815, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/183f3d8a.mp4", "clean_score": 0.0, "clean_xclip": 0.2245998978614807, "clean_vbench": {}, "adv_vid_id": "vids/7a1d4bf3.mp4", "adv_score": 0.0, "adv_xclip": 0.23844808340072632, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ed4754ae.mp4", "clean_score": 1.0, "clean_xclip": 0.2869882881641388, "clean_vbench": {}, "adv_vid_id": "vids/1f369c47.mp4", "adv_score": 1.0, "adv_xclip": 0.29383742809295654, "adv_vbench": {}}}}
{"id": "224e23bca5f84b9e993ff96afbd8c474", "source": "vatex", "video_id": "zbIbjob4XF4_000087_000097", "video_description": "A man is water skiing on a lake, being pulled by a fast boat, zig-zagging back and forth and creating spumes of spray.", "task": "ActionRecognition", "clean_prompt": "A water skier water skiing on a lake.", "clean_property": {"obj": "water skier", "action": "water skiing", "target": null}, "target_prompt": "A water skier falling on a lake.", "target_property": {"obj": "water skier", "action": "falling", "target": null}, "evaluation_question": "Is the water skier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A water skier water skiing on a lake. Casa protectie plein acht peur", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b1c9bc331d1345ce8fd44c7596983297.mp4", "clean_score": 1.0, "clean_xclip": 0.2581028938293457, "clean_vbench": {"subject_consistency": 0.882257675131162, "background_consistency": 0.9124399820963541, "motion_smoothness": 0.9679788604517167, "aesthetic_quality": 0.4289661943912506, "imaging_quality": 0.5336996023995535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/707e021b165547009d306ac1469388eb.mp4", "adv_score": 0.0, "adv_xclip": 0.28047844767570496, "adv_vbench": {"subject_consistency": 0.9215327793111404, "background_consistency": 0.9282277425130209, "motion_smoothness": 0.9684006085844832, "aesthetic_quality": 0.43537434935569763, "imaging_quality": 0.5534505439291195, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d86461ae.mp4", "clean_score": 1.0, "clean_xclip": 0.19627705216407776, "clean_vbench": {}, "adv_vid_id": "vids/8759b660.mp4", "adv_score": 1.0, "adv_xclip": 0.19504234194755554, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/20cb7fd6.mp4", "clean_score": 1.0, "clean_xclip": 0.22192639112472534, "clean_vbench": {}, "adv_vid_id": "vids/07d807a6.mp4", "adv_score": 1.0, "adv_xclip": 0.13074907660484314, "adv_vbench": {}}}}
{"id": "53c7feb2d94d4de1812926003ee439eb", "source": "vatex", "video_id": "5hFBORyDwnw_000264_000274", "video_description": "A sports event is taking place in a large stadium with many spectators. Two teams are playing a game on the field, with people watching and recording the match.", "task": "Counting", "clean_prompt": "Seven coaches discussing strategies in a large stadium during a sports event.", "clean_property": {"obj": "coach", "count": "seven"}, "target_prompt": "Four coaches discussing strategies in a large stadium during a sports event.", "target_property": {"obj": "coach", "count": "four"}, "evaluation_question": "Are there exactly **seven** coaches discussing strategies in the stadium?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven coaches discussing strategies in a large stadium during a sports event. BS>D;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b971a1f313234128935162a241116d43.mp4", "clean_score": 1.0, "clean_xclip": 0.04378603771328926, "clean_vbench": {"subject_consistency": 0.978197801237305, "background_consistency": 0.9027964274088541, "motion_smoothness": 0.9831705146050189, "aesthetic_quality": 0.5004419684410095, "imaging_quality": 0.6914644848570533, "dynamic_degree": 0.0}, "adv_vid_id": "vids/219ee9d4570e45809c3e14271e6781a1.mp4", "adv_score": 0.0, "adv_xclip": 0.0677163377404213, "adv_vbench": {"subject_consistency": 0.9789998220900694, "background_consistency": 0.9524892171223959, "motion_smoothness": 0.9874466314464314, "aesthetic_quality": 0.5653883218765259, "imaging_quality": 0.6985821361931004, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7ef40971.mp4", "clean_score": 0.0, "clean_xclip": 0.1761273890733719, "clean_vbench": {}, "adv_vid_id": "vids/98d56573.mp4", "adv_score": 0.0, "adv_xclip": 0.12284238636493683, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dc3f6119.mp4", "clean_score": 0.0, "clean_xclip": 0.1410076916217804, "clean_vbench": {}, "adv_vid_id": "vids/2cbd8580.mp4", "adv_score": 0.0, "adv_xclip": 0.15099312365055084, "adv_vbench": {}}}}
{"id": "4ce42033b52248f2946a6b27c08a3643", "source": "vatex", "video_id": "BT4rOXKTVSQ_000017_000027", "video_description": "A group of three men are playing beer pong outside at night on a patio. They are laughing, giggling, and talking while throwing ping pong balls into plastic cups on a long table.", "task": "ActionRecognition", "clean_prompt": "A person playing beer pong outside at night on a patio.", "clean_property": {"obj": "person", "action": "playing beer pong", "target": null}, "target_prompt": "A person watching beer pong outside at night on a patio.", "target_property": {"obj": "person", "action": "watching beer pong", "target": null}, "evaluation_question": "Is the person **playing** beer pong?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing beer pong outside at night on a patio. SchlafMRCFrequently Crisp Adidas", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ae8bd041392d42ea8755976d273f3213.mp4", "clean_score": 1.0, "clean_xclip": 0.1955953985452652, "clean_vbench": {"subject_consistency": 0.8842015446474155, "background_consistency": 0.9083658854166666, "motion_smoothness": 0.9807124422557089, "aesthetic_quality": 0.37079083919525146, "imaging_quality": 0.24829577465446628, "dynamic_degree": 1.0}, "adv_vid_id": "vids/49c458985f4047a2bceb0ac4f3eedc0d.mp4", "adv_score": 0.0, "adv_xclip": 0.15152065455913544, "adv_vbench": {"subject_consistency": 0.7550816250344118, "background_consistency": 0.8941396077473959, "motion_smoothness": 0.9857159106955539, "aesthetic_quality": 0.34950199723243713, "imaging_quality": 0.19806081382595764, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/09896a7e.mp4", "clean_score": 0.0, "clean_xclip": 0.12720414996147156, "clean_vbench": {}, "adv_vid_id": "vids/30e95b63.mp4", "adv_score": 1.0, "adv_xclip": 0.13967043161392212, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/da66df81.mp4", "clean_score": 1.0, "clean_xclip": 0.199845552444458, "clean_vbench": {}, "adv_vid_id": "vids/7561ecd6.mp4", "adv_score": 1.0, "adv_xclip": 0.16141116619110107, "adv_vbench": {}}}}
{"id": "e06a2185f66c47c89c1c370b22b6b795", "source": "vatex", "video_id": "5379yXlh9og_000000_000010", "video_description": "A male athlete is practicing and performing long jump and triple jump on an outdoor track, landing in a sand pit.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the right of a sand pit.", "clean_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "sand pit"}, "target_prompt": "An athlete standing to the left of a sand pit.", "target_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "sand pit"}, "evaluation_question": "Is the athlete to the **right** of the sand pit?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete standing to the right of a sand pit. @@TVU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d746d9496cf94768a3e9591494aa83d3.mp4", "clean_score": 1.0, "clean_xclip": 0.19530421495437622, "clean_vbench": {"subject_consistency": 0.9511858448386192, "background_consistency": 0.9495697021484375, "motion_smoothness": 0.9877667948577321, "aesthetic_quality": 0.5906906127929688, "imaging_quality": 0.7595922088623047, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c8006ee380b949d4bf89101909722241.mp4", "adv_score": 0.0, "adv_xclip": 0.2027978003025055, "adv_vbench": {"subject_consistency": 0.9827976419279972, "background_consistency": 0.956451416015625, "motion_smoothness": 0.9912544515427056, "aesthetic_quality": 0.5944808721542358, "imaging_quality": 0.7486158285335618, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/611f8878.mp4", "clean_score": 0.0, "clean_xclip": 0.2135641723871231, "clean_vbench": {}, "adv_vid_id": "vids/39694b65.mp4", "adv_score": 0.0, "adv_xclip": 0.1911848485469818, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3758d8cb.mp4", "clean_score": 0.0, "clean_xclip": 0.1832478642463684, "clean_vbench": {}, "adv_vid_id": "vids/6e5e7e8d.mp4", "adv_score": 0.0, "adv_xclip": 0.20262818038463593, "adv_vbench": {}}}}
{"id": "7efcf3fada784e179d0244bdd4244f4a", "source": "vatex", "video_id": "a1SASZM2epM_000015_000025", "video_description": "Two volleyball teams are playing a match in a gymnasium with a referee overseeing the game.", "task": "ActionRecognition", "clean_prompt": "A volleyball player playing volleyball in a gymnasium.", "clean_property": {"obj": "volleyball player", "action": "playing volleyball", "target": null}, "target_prompt": "A volleyball player sitting on the bench in a gymnasium.", "target_property": {"obj": "volleyball player", "action": "sitting on the bench", "target": null}, "evaluation_question": "Is the volleyball player **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A volleyball player playing volleyball in a gymnasium. ))!D/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bedcdde739de4f1ba3a7afd8f254f0ba.mp4", "clean_score": 1.0, "clean_xclip": 0.2094712257385254, "clean_vbench": {"subject_consistency": 0.950873534505566, "background_consistency": 0.9037526448567709, "motion_smoothness": 0.9797943058203219, "aesthetic_quality": 0.4629461169242859, "imaging_quality": 0.6529624285016742, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0870163e6d084562a9571f074cae70cb.mp4", "adv_score": 0.0, "adv_xclip": 0.20953302085399628, "adv_vbench": {"subject_consistency": 0.94758182639877, "background_consistency": 0.9134063720703125, "motion_smoothness": 0.9677712137774348, "aesthetic_quality": 0.4504149258136749, "imaging_quality": 0.5112109040240852, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/00d30d6a.mp4", "clean_score": 1.0, "clean_xclip": 0.22510087490081787, "clean_vbench": {}, "adv_vid_id": "vids/ae75a56f.mp4", "adv_score": 1.0, "adv_xclip": 0.22005566954612732, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/80376569.mp4", "clean_score": 0.0, "clean_xclip": 0.18105506896972656, "clean_vbench": {}, "adv_vid_id": "vids/f22d8fcb.mp4", "adv_score": 0.0, "adv_xclip": 0.16875796020030975, "adv_vbench": {}}}}
{"id": "4b9753b3e0554111b7202608734c57f8", "source": "vatex", "video_id": "B5K_x2cDYfM_000026_000036", "video_description": "A woman wearing headphones and a cocktail dress plays the clarinet in front of a changing background, including a sky with moving clouds.", "task": "ActionRecognition", "clean_prompt": "A person playing clarinet in front of a changing background.", "clean_property": {"obj": "person", "action": "playing clarinet", "target": null}, "target_prompt": "A person playing guitar in front of a changing background.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing clarinet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing clarinet in front of a changing background. R0$%0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cec8774f3cf1493381d811c19b22500c.mp4", "clean_score": 1.0, "clean_xclip": 0.13771609961986542, "clean_vbench": {"subject_consistency": 0.9213975512733062, "background_consistency": 0.9442545572916666, "motion_smoothness": 0.9496206740637356, "aesthetic_quality": 0.3199043869972229, "imaging_quality": 0.3146473324055574, "dynamic_degree": 1.0}, "adv_vid_id": "vids/21122566053f471d9792f8b195c1b2f9.mp4", "adv_score": 0.0, "adv_xclip": 0.16820015013217926, "adv_vbench": {"subject_consistency": 0.9074134609351555, "background_consistency": 0.9311269124348959, "motion_smoothness": 0.9412471362677015, "aesthetic_quality": 0.3482553958892822, "imaging_quality": 0.3132660842428402, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/74aca2ea.mp4", "clean_score": 0.0, "clean_xclip": 0.1606975495815277, "clean_vbench": {}, "adv_vid_id": "vids/a345f34b.mp4", "adv_score": 0.0, "adv_xclip": 0.15088428556919098, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5e4c8dc2.mp4", "clean_score": 0.0, "clean_xclip": 0.22705300152301788, "clean_vbench": {}, "adv_vid_id": "vids/c6414649.mp4", "adv_score": 0.0, "adv_xclip": 0.2132798582315445, "adv_vbench": {}}}}
{"id": "b18f2c10d9884606b58f1bc57943b96e", "source": "vatex", "video_id": "NAshG3XdoLA_000041_000051", "video_description": "A man and a woman dressed in old English outfits are playing unique string instruments, including a violin and a guitar-like instrument, inside a decorated room.", "task": "SpatialUnderstanding", "clean_prompt": "An instrument farther from the camera than a musician in a decorated room.", "clean_property": {"obj_1": "instrument", "relation": "farther from the camera than", "obj_2": "musician"}, "target_prompt": "An instrument closer to the camera than a musician in a decorated room.", "target_property": {"obj_1": "instrument", "relation": "closer to the camera than", "obj_2": "musician"}, "evaluation_question": "Is the instrument **farther from the camera than** the musician?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An instrument farther from the camera than a musician in a decorated room.gouttemontag gratuite sonore metalic", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4ec06d2f6a234880912b93b4d30be727.mp4", "clean_score": 1.0, "clean_xclip": 0.16328904032707214, "clean_vbench": {"subject_consistency": 0.9582480508834124, "background_consistency": 0.9434102376302084, "motion_smoothness": 0.9945448251091846, "aesthetic_quality": 0.4840894341468811, "imaging_quality": 0.38289963702766266, "dynamic_degree": 0.0}, "adv_vid_id": "vids/5b0b33aca0bb4ab8afe43402623f983d.mp4", "adv_score": 0.0, "adv_xclip": 0.14296647906303406, "adv_vbench": {"subject_consistency": 0.958894324178497, "background_consistency": 0.9689585367838541, "motion_smoothness": 0.9943726639093137, "aesthetic_quality": 0.46593645215034485, "imaging_quality": 0.48861623880814536, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8c8a8421.mp4", "clean_score": 0.0, "clean_xclip": 0.11123652756214142, "clean_vbench": {}, "adv_vid_id": "vids/b1dddbc0.mp4", "adv_score": 0.0, "adv_xclip": 0.15051579475402832, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ca33ca08.mp4", "clean_score": 0.0, "clean_xclip": 0.13028347492218018, "clean_vbench": {}, "adv_vid_id": "vids/5950f498.mp4", "adv_score": 0.0, "adv_xclip": 0.12011906504631042, "adv_vbench": {}}}}
{"id": "f45ff2246e304b9588102c743d8e3ed9", "source": "vatex", "video_id": "0fwkAvo6wGI_000007_000017", "video_description": "A man is in a gym demonstrating and performing ab mat sit ups using a foam wedge or sit up pad under his back.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a mat in a gym.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a mat in a gym.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person closer to the camera than the mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a mat in a gym. @XR37", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4157222bc3d435996dec6f76085acf9.mp4", "clean_score": 1.0, "clean_xclip": 0.10589529573917389, "clean_vbench": {"subject_consistency": 0.9801894426345825, "background_consistency": 0.9849599202473959, "motion_smoothness": 0.9909012066728697, "aesthetic_quality": 0.41231769323349, "imaging_quality": 0.2251359988232048, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a1d2cdc168894a37a48db807b41ff2eb.mp4", "adv_score": 0.0, "adv_xclip": 0.10610643774271011, "adv_vbench": {"subject_consistency": 0.9917880091816187, "background_consistency": 0.990631103515625, "motion_smoothness": 0.9964822445760712, "aesthetic_quality": 0.4246344268321991, "imaging_quality": 0.3194572129541514, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/83666133.mp4", "clean_score": 1.0, "clean_xclip": 0.15022313594818115, "clean_vbench": {}, "adv_vid_id": "vids/ec802af7.mp4", "adv_score": 1.0, "adv_xclip": 0.11897023022174835, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/26533bbd.mp4", "clean_score": 1.0, "clean_xclip": 0.09592178463935852, "clean_vbench": {}, "adv_vid_id": "vids/0d90e6b7.mp4", "adv_score": 1.0, "adv_xclip": 0.13012589514255524, "adv_vbench": {}}}}
{"id": "3610775f3ba6481b8fc6ccdd0d009cd1", "source": "vatex", "video_id": "bj3DrR-8kTQ_000023_000033", "video_description": "A traffic cop is standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "task": "Counting", "clean_prompt": "Four traffic cops standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "clean_property": {"obj": "traffic cop", "count": "four"}, "target_prompt": "One traffic cop standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "target_property": {"obj": "traffic cop", "count": "one"}, "evaluation_question": "Are there exactly **four** traffic cops in the intersection?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four traffic cops standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm. =LYSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b9bd0a9d7564c76b3f6730bfd0c1abb.mp4", "clean_score": 1.0, "clean_xclip": 0.1949889212846756, "clean_vbench": {"subject_consistency": 0.9591705165803432, "background_consistency": 0.9580586751302084, "motion_smoothness": 0.956664812986666, "aesthetic_quality": 0.6428934335708618, "imaging_quality": 0.5854670878819057, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fc588543d8994cd7bb33344a690159f7.mp4", "adv_score": 0.0, "adv_xclip": 0.22095023095607758, "adv_vbench": {"subject_consistency": 0.956048579265674, "background_consistency": 0.9586893717447916, "motion_smoothness": 0.954352580274651, "aesthetic_quality": 0.6949361562728882, "imaging_quality": 0.5655851177293427, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9bc35a4e.mp4", "clean_score": 0.0, "clean_xclip": 0.2185049206018448, "clean_vbench": {}, "adv_vid_id": "vids/af24ac21.mp4", "adv_score": 0.0, "adv_xclip": 0.19381994009017944, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bca97d75.mp4", "clean_score": 1.0, "clean_xclip": 0.2277926206588745, "clean_vbench": {}, "adv_vid_id": "vids/77c1eb76.mp4", "adv_score": 1.0, "adv_xclip": 0.24231946468353271, "adv_vbench": {}}}}
{"id": "2519f070598a45c0af09368b2aae3604", "source": "vatex", "video_id": "AkFy3j-73JA_000018_000028", "video_description": "A young woman is ice skating at an indoor rink, performing spins and twirls.", "task": "Counting", "clean_prompt": "Three ice skaters performing spins and twirls at an indoor rink.", "clean_property": {"obj": "ice skater", "count": "three"}, "target_prompt": "One ice skater performing spins and twirls at an indoor rink.", "target_property": {"obj": "ice skater", "count": "one"}, "evaluation_question": "Are there exactly **three** ice skaters at the rink?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three ice skaters performing spins and twirls at an indoor rink. ?/!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/021d42a97a54497688b34ac30a08590a.mp4", "clean_score": 1.0, "clean_xclip": 0.19691738486289978, "clean_vbench": {"subject_consistency": 0.9379359632730484, "background_consistency": 0.9311116536458334, "motion_smoothness": 0.9744886716228416, "aesthetic_quality": 0.46641936898231506, "imaging_quality": 0.48460540771484373, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b573c0be5b494977ac1cfc9c8f8ce46d.mp4", "adv_score": 0.0, "adv_xclip": 0.18854844570159912, "adv_vbench": {"subject_consistency": 0.9453126980612675, "background_consistency": 0.932891845703125, "motion_smoothness": 0.9750622022953985, "aesthetic_quality": 0.3925975263118744, "imaging_quality": 0.34317430223737444, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d7b763fc.mp4", "clean_score": 0.0, "clean_xclip": 0.2131430059671402, "clean_vbench": {}, "adv_vid_id": "vids/d10d9d98.mp4", "adv_score": 1.0, "adv_xclip": 0.23072870075702667, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bf3f8c91.mp4", "clean_score": 1.0, "clean_xclip": 0.2249353677034378, "clean_vbench": {}, "adv_vid_id": "vids/6cf07b60.mp4", "adv_score": 0.0, "adv_xclip": 0.233638197183609, "adv_vbench": {}}}}
{"id": "f565ef4c90ee4c4a9ec4e1328d078933", "source": "vatex", "video_id": "_dpT1Jd4S74_000033_000043", "video_description": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face. The man is holding a selfie stick and recording their experience.", "task": "AttributeRecognition", "clean_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face.", "clean_property": {"obj": "parachute", "attribute": "large smiling face"}, "target_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a small frowning face.", "target_property": {"obj": "parachute", "attribute": "small frowning face"}, "evaluation_question": "Is the parachute displaying a **large smiling face**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face. ))'K*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c472827d938490d9202c07abe2857c0.mp4", "clean_score": 1.0, "clean_xclip": 0.20294305682182312, "clean_vbench": {"subject_consistency": 0.9807522911578417, "background_consistency": 0.9668680826822916, "motion_smoothness": 0.9928594103021867, "aesthetic_quality": 0.5239320993423462, "imaging_quality": 0.6668141392299107, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1807c3fa237f48dd830bffc7d0eebe91.mp4", "adv_score": 0.0, "adv_xclip": 0.20970182120800018, "adv_vbench": {"subject_consistency": 0.977259449660778, "background_consistency": 0.9636383056640625, "motion_smoothness": 0.9936250159175039, "aesthetic_quality": 0.5007648468017578, "imaging_quality": 0.6125936453683035, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9dafb6ed.mp4", "clean_score": 0.0, "clean_xclip": 0.2012915462255478, "clean_vbench": {}, "adv_vid_id": "vids/88e1ea31.mp4", "adv_score": 0.0, "adv_xclip": 0.21090775728225708, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c76bc37b.mp4", "clean_score": 1.0, "clean_xclip": 0.24785259366035461, "clean_vbench": {}, "adv_vid_id": "vids/09e3b75d.mp4", "adv_score": 1.0, "adv_xclip": 0.23700577020645142, "adv_vbench": {}}}}
{"id": "191ea37f97314d3cbd5c7776baf3a76f", "source": "vatex", "video_id": "IqaFjJZQVFM_000219_000229", "video_description": "A group of boys are outside on a neighborhood street, discussing and then smashing an old red phone with a hammer.", "task": "AttributeRecognition", "clean_prompt": "A group of boys outside on a neighborhood street discussing and then smashing an old red phone with a hammer.", "clean_property": {"obj": "phone", "attribute": "red"}, "target_prompt": "A group of boys outside on a neighborhood street discussing and then smashing an old blue phone with a hammer.", "target_property": {"obj": "phone", "attribute": "blue"}, "evaluation_question": "Is the phone being smashed **red**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A group of boys outside on a neighborhood street discussing and then smashing an old red phone with a hammer. ''!D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb11908e6a7d40fb98ce96233fe03519.mp4", "clean_score": 1.0, "clean_xclip": 0.14071311056613922, "clean_vbench": {"subject_consistency": 0.8309608021130165, "background_consistency": 0.8771616617838541, "motion_smoothness": 0.9363751810813059, "aesthetic_quality": 0.450696736574173, "imaging_quality": 0.5873814602287448, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ca23b30517d84230b987de1094f0c5c5.mp4", "adv_score": 0.0, "adv_xclip": 0.16959840059280396, "adv_vbench": {"subject_consistency": 0.8834606055170298, "background_consistency": 0.8866678873697916, "motion_smoothness": 0.9295307444222546, "aesthetic_quality": 0.5214312672615051, "imaging_quality": 0.6300022031822983, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f5922b01.mp4", "clean_score": 0.0, "clean_xclip": 0.1446862816810608, "clean_vbench": {}, "adv_vid_id": "vids/64b311f1.mp4", "adv_score": 1.0, "adv_xclip": 0.1636166274547577, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/36a845f6.mp4", "clean_score": 1.0, "clean_xclip": 0.16747471690177917, "clean_vbench": {}, "adv_vid_id": "vids/4b97864a.mp4", "adv_score": 1.0, "adv_xclip": 0.17853869497776031, "adv_vbench": {}}}}
{"id": "c73f49aca32a44cbb1842ad83c2736f9", "source": "vatex", "video_id": "M5Iv3vnl2Ys_000022_000032", "video_description": "A man in a red pullover and khaki pants is on a windy golf course, demonstrating how to hit a golf ball with a club.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a golf club on a windy golf course.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "golf club"}, "target_prompt": "A man closer to the camera than a golf club on a windy golf course.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "golf club"}, "evaluation_question": "Is the man **farther from the camera than** the golf club?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man farther from the camera than a golf club on a windy golf course. R$\u00b7TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9dcd70f53ed04cd68f77337d2cd8ee00.mp4", "clean_score": 1.0, "clean_xclip": 0.13554635643959045, "clean_vbench": {"subject_consistency": 0.9089191369712353, "background_consistency": 0.9435475667317709, "motion_smoothness": 0.9929780984603204, "aesthetic_quality": 0.5176742076873779, "imaging_quality": 0.5134012276785714, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a52c3a539f8b40a0a1946197f81fa6ec.mp4", "adv_score": 0.0, "adv_xclip": 0.10241227596998215, "adv_vbench": {"subject_consistency": 0.9439782463014126, "background_consistency": 0.9641571044921875, "motion_smoothness": 0.9894026937774854, "aesthetic_quality": 0.5034042596817017, "imaging_quality": 0.668668274392887, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e998fc21.mp4", "clean_score": 0.0, "clean_xclip": 0.14804644882678986, "clean_vbench": {}, "adv_vid_id": "vids/4b3b3f09.mp4", "adv_score": 0.0, "adv_xclip": 0.13910429179668427, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2a1c5a96.mp4", "clean_score": 0.0, "clean_xclip": 0.14317655563354492, "clean_vbench": {}, "adv_vid_id": "vids/1e596ca2.mp4", "adv_score": 1.0, "adv_xclip": 0.15903329849243164, "adv_vbench": {}}}}
{"id": "d8604764956247b7a6e40c8f5c0e62be", "source": "vatex", "video_id": "d-YUho_dHJE_000017_000027", "video_description": "A person is demonstrating how to properly cut and peel a red onion using a sharp knife, with instructions being narrated.", "task": "SpatialUnderstanding", "clean_prompt": "A knife closer to the camera than a person demonstrating how to cut and peel a red onion.", "clean_property": {"obj_1": "knife", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A knife further from the camera than a person demonstrating how to cut and peel a red onion.", "target_property": {"obj_1": "knife", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the knife **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A knife closer to the camera than a person demonstrating how to cut and peel a red onion. LY%D(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18f16c1bcd494f8cb2a881ee456ec49f.mp4", "clean_score": 1.0, "clean_xclip": 0.1576116979122162, "clean_vbench": {"subject_consistency": 0.8808439522981644, "background_consistency": 0.956085205078125, "motion_smoothness": 0.946531147718218, "aesthetic_quality": 0.4612179100513458, "imaging_quality": 0.46941101541324537, "dynamic_degree": 1.0}, "adv_vid_id": "vids/37efc4eba46a405885a0f31325ffc4f9.mp4", "adv_score": 0.0, "adv_xclip": 0.16019541025161743, "adv_vbench": {"subject_consistency": 0.8827787600457668, "background_consistency": 0.9524332682291666, "motion_smoothness": 0.9444566895752643, "aesthetic_quality": 0.5110875964164734, "imaging_quality": 0.5147055271693638, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/695cc3ea.mp4", "clean_score": 1.0, "clean_xclip": 0.23685704171657562, "clean_vbench": {}, "adv_vid_id": "vids/e0c59d6e.mp4", "adv_score": 1.0, "adv_xclip": 0.22959670424461365, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/68b86ef7.mp4", "clean_score": 1.0, "clean_xclip": 0.27083051204681396, "clean_vbench": {}, "adv_vid_id": "vids/d45d10fb.mp4", "adv_score": 1.0, "adv_xclip": 0.25340428948402405, "adv_vbench": {}}}}
{"id": "f8588260a29c46a98cddd8d5bed10f33", "source": "vatex", "video_id": "iIl35DGzWio_000000_000010", "video_description": "A man is performing various jump rope exercises in a gym, demonstrating skillful and fancy jumps.", "task": "AttributeRecognition", "clean_prompt": "An older person performing various jump rope exercises in a gym.", "clean_property": {"obj": "person", "attribute": "older"}, "target_prompt": "A younger person performing various jump rope exercises in a gym.", "target_property": {"obj": "person", "attribute": "younger"}, "evaluation_question": "Is the person performing jump rope exercises **older**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An older person performing various jump rope exercises in a gym. ))(U=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/31ef6da4681f474486b9a4aff948ac58.mp4", "clean_score": 1.0, "clean_xclip": 0.1393282264471054, "clean_vbench": {"subject_consistency": 0.86250424819688, "background_consistency": 0.931304931640625, "motion_smoothness": 0.9344503667014645, "aesthetic_quality": 0.544887125492096, "imaging_quality": 0.5367218173280054, "dynamic_degree": 1.0}, "adv_vid_id": "vids/66a135b8baa44ee38dd42892462f3ebd.mp4", "adv_score": 0.0, "adv_xclip": 0.16730087995529175, "adv_vbench": {"subject_consistency": 0.9033843278884888, "background_consistency": 0.9235687255859375, "motion_smoothness": 0.9288854877438372, "aesthetic_quality": 0.5131681561470032, "imaging_quality": 0.5590356811212034, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7c43d994.mp4", "clean_score": 0.0, "clean_xclip": 0.17584359645843506, "clean_vbench": {}, "adv_vid_id": "vids/7de54799.mp4", "adv_score": 1.0, "adv_xclip": 0.18450060486793518, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ebe859c1.mp4", "clean_score": 1.0, "clean_xclip": 0.20177355408668518, "clean_vbench": {}, "adv_vid_id": "vids/5772aab2.mp4", "adv_score": 1.0, "adv_xclip": 0.1662939488887787, "adv_vbench": {}}}}
{"id": "49bfe2f1c53c496985de66d72a9e6ade", "source": "vatex", "video_id": "dYEPXMdxGVU_000015_000025", "video_description": "A group of women and other people are playing a game of kickball in a park on a grassy field.", "task": "Counting", "clean_prompt": "Three women playing kickball in a park on a grassy field.", "clean_property": {"obj": "ball", "count": "three"}, "target_prompt": "One woman playing kickball in a park on a sandy beach.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **three** women playing kickball in the park?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women playing kickball in a park on a grassy field. >;J)X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b68e3e1ae3a44d28c1ff084aa050677.mp4", "clean_score": 1.0, "clean_xclip": 0.17211630940437317, "clean_vbench": {"subject_consistency": 0.929573193192482, "background_consistency": 0.9154154459635416, "motion_smoothness": 0.9686554763462741, "aesthetic_quality": 0.5255756378173828, "imaging_quality": 0.6363228685028699, "dynamic_degree": 1.0}, "adv_vid_id": "vids/31ee1fe194de46b7a20fdcda640cfbeb.mp4", "adv_score": 0.0, "adv_xclip": 0.19282177090644836, "adv_vbench": {"subject_consistency": 0.9330771192908287, "background_consistency": 0.8976847330729166, "motion_smoothness": 0.9709575437621036, "aesthetic_quality": 0.427386999130249, "imaging_quality": 0.5908484439460598, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5340ab33.mp4", "clean_score": 1.0, "clean_xclip": 0.20332089066505432, "clean_vbench": {}, "adv_vid_id": "vids/4b77e840.mp4", "adv_score": 1.0, "adv_xclip": 0.19091936945915222, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/24c5b02f.mp4", "clean_score": 0.0, "clean_xclip": 0.17632991075515747, "clean_vbench": {}, "adv_vid_id": "vids/7ab2b2c7.mp4", "adv_score": 0.0, "adv_xclip": 0.152462437748909, "adv_vbench": {}}}}
{"id": "0a84579a70424ab8accce2440a1e7e44", "source": "vatex", "video_id": "aPjbJ4ZNcVQ_000157_000167", "video_description": "A man and a young girl are sitting at a table in the kitchen, stirring and scooping cookie dough onto a baking tray. They occasionally wave and say hi to the camera.", "task": "AttributeRecognition", "clean_prompt": "A bowl that contains cookie dough on a kitchen table.", "clean_property": {"obj": "bowl", "attribute": "contains cookie dough"}, "target_prompt": "A bowl that contains salad on a kitchen table.", "target_property": {"obj": "bowl", "attribute": "contains salad"}, "evaluation_question": "Does the bowl contain **cookie dough**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A bowl that contains cookie dough on a kitchen table. ?I'@U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d673ec96300441db41572c9e4c030a1.mp4", "clean_score": 1.0, "clean_xclip": 0.23171555995941162, "clean_vbench": {"subject_consistency": 0.999484250942866, "background_consistency": 0.9923350016276041, "motion_smoothness": 0.9976898898319616, "aesthetic_quality": 0.6460736989974976, "imaging_quality": 0.6737284975635762, "dynamic_degree": 0.0}, "adv_vid_id": "vids/f351f235ea1c4a5eb721f45652693174.mp4", "adv_score": 0.0, "adv_xclip": 0.1256517916917801, "adv_vbench": {"subject_consistency": 0.997616620734334, "background_consistency": 0.9919026692708334, "motion_smoothness": 0.9966379087804103, "aesthetic_quality": 0.34719955921173096, "imaging_quality": 0.4473018249200315, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d8de9d41.mp4", "clean_score": 0.0, "clean_xclip": 0.222371906042099, "clean_vbench": {}, "adv_vid_id": "vids/8a30af80.mp4", "adv_score": 1.0, "adv_xclip": 0.22600063681602478, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7a750828.mp4", "clean_score": 0.0, "clean_xclip": 0.24427206814289093, "clean_vbench": {}, "adv_vid_id": "vids/94ce7390.mp4", "adv_score": 1.0, "adv_xclip": 0.24223360419273376, "adv_vbench": {}}}}
{"id": "fc20611c2adc4e339c5c4a5917b8c97d", "source": "vatex", "video_id": "Z_xtupU1Orw_000000_000010", "video_description": "A group of young people are outside in the snow, engaging in a snowball fight, running, laughing, and shouting.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a snowball.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "snowball"}, "target_prompt": "A person standing to the left of a snowball.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "snowball"}, "evaluation_question": "Is the person to the **right** of a snowball?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the right of a snowball. '%|'/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2547a2f003de4edc93f6a95b2169b78b.mp4", "clean_score": 1.0, "clean_xclip": 0.21388819813728333, "clean_vbench": {"subject_consistency": 0.9359436860928932, "background_consistency": 0.9739837646484375, "motion_smoothness": 0.9946356240670136, "aesthetic_quality": 0.5255109071731567, "imaging_quality": 0.6210477883475167, "dynamic_degree": 0.0}, "adv_vid_id": "vids/9600097798ef4c77812a97c69219e06e.mp4", "adv_score": 0.0, "adv_xclip": 0.2009679675102234, "adv_vbench": {"subject_consistency": 0.910639808823665, "background_consistency": 0.9663594563802084, "motion_smoothness": 0.9940879722613067, "aesthetic_quality": 0.582696795463562, "imaging_quality": 0.6886331690574178, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f93ddb47.mp4", "clean_score": 1.0, "clean_xclip": 0.18790249526500702, "clean_vbench": {}, "adv_vid_id": "vids/13defc6e.mp4", "adv_score": 0.0, "adv_xclip": 0.19251666963100433, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/857d9086.mp4", "clean_score": 1.0, "clean_xclip": 0.18425095081329346, "clean_vbench": {}, "adv_vid_id": "vids/1d875bdd.mp4", "adv_score": 0.0, "adv_xclip": 0.20510663092136383, "adv_vbench": {}}}}
{"id": "c665a7b75bb5407291f527c107e9fd7a", "source": "vatex", "video_id": "MjCsB5RM1Zg_000004_000014", "video_description": "A young boy is sitting on a step or floor, holding a toothbrush and brushing his teeth while a woman instructs him.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on a step, holding a toothbrush and brushing his teeth while a woman instructs him.", "clean_property": {"obj": "toothbrush"}, "target_prompt": "A young boy is sitting on a step, holding a hairbrush and brushing his hair while a woman instructs him.", "target_property": {"obj": "hairbrush"}, "evaluation_question": "Is the boy holding a **toothbrush**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young boy is sitting on a step, holding a toothbrush and brushing his teeth while a woman instructs him. Klo gelegen francophone Salzburg afirma", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a425573dc50341309ea93568f9b4e0e7.mp4", "clean_score": 1.0, "clean_xclip": 0.2009005844593048, "clean_vbench": {"subject_consistency": 0.9732922694335381, "background_consistency": 0.9544728597005209, "motion_smoothness": 0.9791645847832445, "aesthetic_quality": 0.5426047444343567, "imaging_quality": 0.7295731618453045, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b57eecc21c194fc482df064966fdf894.mp4", "adv_score": 0.0, "adv_xclip": 0.14801284670829773, "adv_vbench": {"subject_consistency": 0.920064531887571, "background_consistency": 0.9303436279296875, "motion_smoothness": 0.9636670108629872, "aesthetic_quality": 0.44833481311798096, "imaging_quality": 0.5098124694824219, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d0ccffed.mp4", "clean_score": 1.0, "clean_xclip": 0.16109606623649597, "clean_vbench": {}, "adv_vid_id": "vids/78ee3d6b.mp4", "adv_score": 1.0, "adv_xclip": 0.17539232969284058, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fd6b8cf0.mp4", "clean_score": 1.0, "clean_xclip": 0.16134680807590485, "clean_vbench": {}, "adv_vid_id": "vids/67e364ab.mp4", "adv_score": 1.0, "adv_xclip": 0.1803455352783203, "adv_vbench": {}}}}
{"id": "3eb74d2d59e04366afa953d08fc1b713", "source": "vatex", "video_id": "-AvjZ4eRgRM_000049_000059", "video_description": "A young man is practicing soccer tricks alone on a field, juggling and dribbling a soccer ball.", "task": "ActionRecognition", "clean_prompt": "A person juggling a soccer ball on a field.", "clean_property": {"obj": "person", "action": "juggling soccer ball", "target": null}, "target_prompt": "A person kicking a soccer ball on a field.", "target_property": {"obj": "person", "action": "kicking soccer ball", "target": null}, "evaluation_question": "Is the person **juggling** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person juggling a soccer ball on a field. MC&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be3b22bbf4724985b72f8eea881bb592.mp4", "clean_score": 1.0, "clean_xclip": 0.21595975756645203, "clean_vbench": {"subject_consistency": 0.8846056709686915, "background_consistency": 0.9181162516276041, "motion_smoothness": 0.9298480593883645, "aesthetic_quality": 0.48452359437942505, "imaging_quality": 0.533626682515047, "dynamic_degree": 1.0}, "adv_vid_id": "vids/93e31ca6ef144baf89fbb02b962c424a.mp4", "adv_score": 0.0, "adv_xclip": 0.20433412492275238, "adv_vbench": {"subject_consistency": 0.8810537476092577, "background_consistency": 0.9490865071614584, "motion_smoothness": 0.9434428307877936, "aesthetic_quality": 0.47563809156417847, "imaging_quality": 0.5079921979320292, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/aba282b2.mp4", "clean_score": 1.0, "clean_xclip": 0.17784973978996277, "clean_vbench": {}, "adv_vid_id": "vids/eee59f58.mp4", "adv_score": 0.0, "adv_xclip": 0.159293532371521, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/48b6a0eb.mp4", "clean_score": 1.0, "clean_xclip": 0.21116343140602112, "clean_vbench": {}, "adv_vid_id": "vids/4dfbd2b8.mp4", "adv_score": 1.0, "adv_xclip": 0.1729375123977661, "adv_vbench": {}}}}
{"id": "c9ee682290e4432abc4b9f7abd95484b", "source": "vatex", "video_id": "0m0-Q0zz_-c_000112_000122", "video_description": "A man in a suit is demonstrating how to tie a bow tie using his leg as a model, providing instructions on the proper technique.", "task": "ActionRecognition", "clean_prompt": "A person tying a bow tie using their leg as a model.", "clean_property": {"obj": "person", "action": "tying bow tie", "target": null}, "target_prompt": "A person removing a bow tie using their leg as a model.", "target_property": {"obj": "person", "action": "removing bow tie", "target": null}, "evaluation_question": "Is the person **tying** a bow tie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a bow tie using their leg as a model. ))!0P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cea3142799724a03a37c169df1197ed1.mp4", "clean_score": 1.0, "clean_xclip": 0.26727187633514404, "clean_vbench": {"subject_consistency": 0.9494753299901882, "background_consistency": 0.942108154296875, "motion_smoothness": 0.9493936438097615, "aesthetic_quality": 0.404242604970932, "imaging_quality": 0.5236029348568041, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0ea4c0a21dd247ed97a52edfaf4f9d8e.mp4", "adv_score": 0.0, "adv_xclip": 0.31447160243988037, "adv_vbench": {"subject_consistency": 0.9107111866275469, "background_consistency": 0.9455006917317709, "motion_smoothness": 0.9626238277782821, "aesthetic_quality": 0.46191468834877014, "imaging_quality": 0.557970131076112, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b45f571b.mp4", "clean_score": 1.0, "clean_xclip": 0.24206164479255676, "clean_vbench": {}, "adv_vid_id": "vids/20cbd331.mp4", "adv_score": 0.0, "adv_xclip": 0.3238425850868225, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/61522e82.mp4", "clean_score": 1.0, "clean_xclip": 0.2569316029548645, "clean_vbench": {}, "adv_vid_id": "vids/8c0e1bc4.mp4", "adv_score": 1.0, "adv_xclip": 0.26141464710235596, "adv_vbench": {}}}}
{"id": "15182ca7e9f5420ba1c9e5698fcf124f", "source": "vatex", "video_id": "7VUQg_VVUgQ_000004_000014", "video_description": "Two women are riding horses along a narrow, rocky dirt path. One woman waves while riding, and they are having a great time.", "task": "Counting", "clean_prompt": "Six women riding horses along a narrow, rocky dirt path, with one woman waving and all having a great time.", "clean_property": {"obj": "woman", "count": "six"}, "target_prompt": "Three women riding bicycles along a narrow, rocky dirt path, with one woman waving and all having a great time.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** women riding horses along the path?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Six women riding horses along a narrow, rocky dirt path, with one woman waving and all having a great time. EdisonRobiunii couleursfrucht", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c71c265fe1bb4e4aa3c2c4cfeae1b832.mp4", "clean_score": 1.0, "clean_xclip": 0.2419205605983734, "clean_vbench": {"subject_consistency": 0.9163777157664299, "background_consistency": 0.9531046549479166, "motion_smoothness": 0.9791776714929799, "aesthetic_quality": 0.6000481843948364, "imaging_quality": 0.716471149678133, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1bb4a4e2c581437b96f3e0194bf75ecf.mp4", "adv_score": 0.0, "adv_xclip": 0.250731498003006, "adv_vbench": {"subject_consistency": 0.9106765029331049, "background_consistency": 0.9371541341145834, "motion_smoothness": 0.9786971690167837, "aesthetic_quality": 0.5778521299362183, "imaging_quality": 0.6832124188481545, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/803fdd8f.mp4", "clean_score": 0.0, "clean_xclip": 0.25576382875442505, "clean_vbench": {}, "adv_vid_id": "vids/884c4714.mp4", "adv_score": 0.0, "adv_xclip": 0.2552303075790405, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/eb74b65e.mp4", "clean_score": 0.0, "clean_xclip": 0.22195610404014587, "clean_vbench": {}, "adv_vid_id": "vids/9f354a0d.mp4", "adv_score": 0.0, "adv_xclip": 0.22505336999893188, "adv_vbench": {}}}}
{"id": "85498c3b76ef49da82a2deb549125a69", "source": "vatex", "video_id": "1apesjwcwJ8_000015_000025", "video_description": "A group of young men are playing and practicing volleyball in a gym.", "task": "ActionRecognition", "clean_prompt": "A volleyball player playing volleyball in a gym.", "clean_property": {"obj": "volleyball player", "action": "playing volleyball", "target": "volleyball"}, "target_prompt": "A volleyball player watching volleyball in a gym.", "target_property": {"obj": "volleyball player", "action": "watching volleyball", "target": "volleyball"}, "evaluation_question": "Is the volleyball player **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A volleyball player playing volleyball in a gym. UB!TV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a423d06ee6874843b3e20d598363c85d.mp4", "clean_score": 1.0, "clean_xclip": 0.21917226910591125, "clean_vbench": {"subject_consistency": 0.9484564407418171, "background_consistency": 0.9276987711588541, "motion_smoothness": 0.9839755169879166, "aesthetic_quality": 0.41499942541122437, "imaging_quality": 0.5775227752996951, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5136ec2ab6944b71a1dacf2b7c217d9f.mp4", "adv_score": 0.0, "adv_xclip": 0.21519683301448822, "adv_vbench": {"subject_consistency": 0.9113927061359087, "background_consistency": 0.8745778401692709, "motion_smoothness": 0.9471312869412168, "aesthetic_quality": 0.4274204969406128, "imaging_quality": 0.5088325741826272, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4899688c.mp4", "clean_score": 1.0, "clean_xclip": 0.21884140372276306, "clean_vbench": {}, "adv_vid_id": "vids/2d04caa8.mp4", "adv_score": 1.0, "adv_xclip": 0.20748712122440338, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7c23e463.mp4", "clean_score": 1.0, "clean_xclip": 0.20760636031627655, "clean_vbench": {}, "adv_vid_id": "vids/fb2d806a.mp4", "adv_score": 1.0, "adv_xclip": 0.18816694617271423, "adv_vbench": {}}}}
{"id": "07bb67a61d584f54b615a2293846da68", "source": "vatex", "video_id": "RA90UGf5wxA_000000_000010", "video_description": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them.", "task": "Counting", "clean_prompt": "Five women laughing at two men dancing on a windy and icy street.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman laughing at two men dancing on a windy and icy street.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women laughing at the men?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Five women laughing at two men dancing on a windy and icy street.Share Barcelona senzor Angliaatura", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a5899f72f2104736ada20e6958598fbd.mp4", "clean_score": 1.0, "clean_xclip": 0.2114962488412857, "clean_vbench": {"subject_consistency": 0.9335664498309294, "background_consistency": 0.9260609944661459, "motion_smoothness": 0.9430232072477911, "aesthetic_quality": 0.6140631437301636, "imaging_quality": 0.5698676790509904, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5669c4ccff414666a6a7281a95c26cd7.mp4", "adv_score": 0.0, "adv_xclip": 0.2127896547317505, "adv_vbench": {"subject_consistency": 0.9441348842034737, "background_consistency": 0.9461720784505209, "motion_smoothness": 0.9418890680790063, "aesthetic_quality": 0.590400218963623, "imaging_quality": 0.6639429403811085, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9191f786.mp4", "clean_score": 0.0, "clean_xclip": 0.2513733208179474, "clean_vbench": {}, "adv_vid_id": "vids/215f1899.mp4", "adv_score": 0.0, "adv_xclip": 0.26496899127960205, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a6e377cd.mp4", "clean_score": 0.0, "clean_xclip": 0.23481076955795288, "clean_vbench": {}, "adv_vid_id": "vids/4996f6b7.mp4", "adv_score": 0.0, "adv_xclip": 0.19156450033187866, "adv_vbench": {}}}}
{"id": "8b61c10972da4f8ea31af0a1795c03d3", "source": "vatex", "video_id": "Q1fYJxBm-cI_000032_000042", "video_description": "A woman, who is a sewing teacher, is sitting at a craft table in a classroom, demonstrating and explaining how to thread a needle and prepare for sewing.", "task": "Counting", "clean_prompt": "Three people sitting at a craft table, with a woman demonstrating how to thread a needle.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting at a craft table, demonstrating how to thread a needle.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people at the craft table?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three people sitting at a craft table, with a woman demonstrating how to thread a needle.ambiance telefon Femme feminist cutie", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0950bb928e6346b9b1b69781593f8ab4.mp4", "clean_score": 1.0, "clean_xclip": 0.17536598443984985, "clean_vbench": {"subject_consistency": 0.9714476596564054, "background_consistency": 0.9480946858723959, "motion_smoothness": 0.9789597406928306, "aesthetic_quality": 0.40418142080307007, "imaging_quality": 0.7631607164655414, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f10a915537e5403ab6b7d0a120e7781d.mp4", "adv_score": 0.0, "adv_xclip": 0.18109765648841858, "adv_vbench": {"subject_consistency": 0.9390049471209446, "background_consistency": 0.9381612141927084, "motion_smoothness": 0.9697533340078572, "aesthetic_quality": 0.4647318720817566, "imaging_quality": 0.696677219624422, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6663efda.mp4", "clean_score": 0.0, "clean_xclip": 0.17378295958042145, "clean_vbench": {}, "adv_vid_id": "vids/47c151be.mp4", "adv_score": 1.0, "adv_xclip": 0.17450854182243347, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/36b0083b.mp4", "clean_score": 1.0, "clean_xclip": 0.12791138887405396, "clean_vbench": {}, "adv_vid_id": "vids/7579c689.mp4", "adv_score": 1.0, "adv_xclip": 0.1438775658607483, "adv_vbench": {}}}}
{"id": "00079788238a4b34ab772be4a38cb9da", "source": "vatex", "video_id": "SAISuCs1IiI_000017_000027", "video_description": "A large, muscular man is working out his arms using various machines in a gym. He is wearing black clothing and a gray shirt at different times, performing exercises like triceps extensions and pull downs.", "task": "SpatialUnderstanding", "clean_prompt": "A weight machine farther from the camera than a person in a gym.", "clean_property": {"obj_1": "weight machine", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A weight machine closer to the camera than a person in a gym.", "target_property": {"obj_1": "weight machine", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the weight machine **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A weight machine farther from the camera than a person in a gym. FemaleMaschine Grauaufnahme Entspannung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f8a0f1403b34043beb33de0195eae91.mp4", "clean_score": 1.0, "clean_xclip": 0.18192945420742035, "clean_vbench": {"subject_consistency": 0.9146366392572721, "background_consistency": 0.955718994140625, "motion_smoothness": 0.9755966947382091, "aesthetic_quality": 0.3743019104003906, "imaging_quality": 0.3401361177405533, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f0602290780943fb8a707a02c2658064.mp4", "adv_score": 0.0, "adv_xclip": 0.1621967852115631, "adv_vbench": {"subject_consistency": 0.9756501434991757, "background_consistency": 0.9624582926432291, "motion_smoothness": 0.9856389052791898, "aesthetic_quality": 0.48539498448371887, "imaging_quality": 0.6830861819520289, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3feb3337.mp4", "clean_score": 0.0, "clean_xclip": 0.13674689829349518, "clean_vbench": {}, "adv_vid_id": "vids/5af05a84.mp4", "adv_score": 0.0, "adv_xclip": 0.1484978348016739, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fba8fffb.mp4", "clean_score": 0.0, "clean_xclip": 0.14798258244991302, "clean_vbench": {}, "adv_vid_id": "vids/e19de98a.mp4", "adv_score": 0.0, "adv_xclip": 0.13991399109363556, "adv_vbench": {}}}}
{"id": "6025776862754e8697c6e2b4bb80b013", "source": "vatex", "video_id": "e5qBwONhahU_000000_000010", "video_description": "A young man is riding a skateboard down a city sidewalk. Another young man appears and looks at the camera.", "task": "ObjectRecognition", "clean_prompt": "A young man is riding a skateboard down a city sidewalk.", "clean_property": {"obj": "skateboard"}, "target_prompt": "A young man is riding a bicycle down a city sidewalk.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is the young man riding a **skateboard**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young man is riding a skateboard down a city sidewalk. 'U*9P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c0a9e9e7a13b45139f7fc6038290d834.mp4", "clean_score": 1.0, "clean_xclip": 0.1917504221200943, "clean_vbench": {"subject_consistency": 0.9589271750301123, "background_consistency": 0.9718119303385416, "motion_smoothness": 0.9846677730119826, "aesthetic_quality": 0.49819228053092957, "imaging_quality": 0.6136493472663723, "dynamic_degree": 1.0}, "adv_vid_id": "vids/77bccdcd99104299bb6388702cb19888.mp4", "adv_score": 0.0, "adv_xclip": 0.1760236620903015, "adv_vbench": {"subject_consistency": 0.9156953965624174, "background_consistency": 0.954345703125, "motion_smoothness": 0.9775684386473211, "aesthetic_quality": 0.5108095407485962, "imaging_quality": 0.6517974581037249, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/167b492d.mp4", "clean_score": 1.0, "clean_xclip": 0.1610114872455597, "clean_vbench": {}, "adv_vid_id": "vids/f4ee403d.mp4", "adv_score": 1.0, "adv_xclip": 0.1681077778339386, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/593beb58.mp4", "clean_score": 1.0, "clean_xclip": 0.16149196028709412, "clean_vbench": {}, "adv_vid_id": "vids/91fbc3f8.mp4", "adv_score": 1.0, "adv_xclip": 0.16321498155593872, "adv_vbench": {}}}}
{"id": "7383d25811bf4d1990c50ebb61b37725", "source": "vatex", "video_id": "0aSmZ91nawo_000060_000070", "video_description": "Two women are involved in an exercise demonstration. One woman is holding a baby while squeezing a red exercise ball between her legs, and the other woman is instructing the exercise.", "task": "ObjectRecognition", "clean_prompt": "A woman holding a baby while squeezing a red exercise ball between her legs, with another woman instructing the exercise.", "clean_property": {"obj": "baby"}, "target_prompt": "A woman holding a puppy while squeezing a red exercise ball between her legs, with another woman instructing the exercise.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the woman holding a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman holding a baby while squeezing a red exercise ball between her legs, with another woman instructing the exercise. museumsetzungseraient verkaufenunta", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18613e16ef224febad21ef0958bed866.mp4", "clean_score": 1.0, "clean_xclip": 0.259146511554718, "clean_vbench": {"subject_consistency": 0.9827562551945448, "background_consistency": 0.9891357421875, "motion_smoothness": 0.9846167678137356, "aesthetic_quality": 0.5185555219650269, "imaging_quality": 0.5023312362359494, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4c01d0aeac024a9b9ff41ed41faa3969.mp4", "adv_score": 0.0, "adv_xclip": 0.19158416986465454, "adv_vbench": {"subject_consistency": 0.9851198152949413, "background_consistency": 0.9720408121744791, "motion_smoothness": 0.9843992299080125, "aesthetic_quality": 0.4678747057914734, "imaging_quality": 0.6297079677971041, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b42e762e.mp4", "clean_score": 1.0, "clean_xclip": 0.23437172174453735, "clean_vbench": {}, "adv_vid_id": "vids/0f624f4e.mp4", "adv_score": 0.0, "adv_xclip": 0.19403629004955292, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/83b4a9a3.mp4", "clean_score": 1.0, "clean_xclip": 0.255386084318161, "clean_vbench": {}, "adv_vid_id": "vids/c4727510.mp4", "adv_score": 1.0, "adv_xclip": 0.2829350233078003, "adv_vbench": {}}}}
{"id": "4d0aa236634541ea93c0ef0181314045", "source": "vatex", "video_id": "O9kGwMsJm7I_000170_000180", "video_description": "A woman is demonstrating how to fold a red cloth napkin into various intricate designs on a table.", "task": "ActionRecognition", "clean_prompt": "A person folding a red cloth napkin into various intricate designs on a table.", "clean_property": {"obj": "person", "action": "folding napkins", "target": "napkin"}, "target_prompt": "A person throwing napkins in a dining room.", "target_property": {"obj": "person", "action": "throwing napkins", "target": "napkin"}, "evaluation_question": "Is the person **folding** napkins?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding a red cloth napkin into various intricate designs on a table. \u00b7))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5dcd53e6f9f24c9cbdf6cd46c66dbaab.mp4", "clean_score": 1.0, "clean_xclip": 0.23167532682418823, "clean_vbench": {"subject_consistency": 0.8884806397060553, "background_consistency": 0.93475341796875, "motion_smoothness": 0.9518183464518781, "aesthetic_quality": 0.38204970955848694, "imaging_quality": 0.7004700337624064, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9d9a45d5f14c49b98285c8dff5721d9b.mp4", "adv_score": 0.0, "adv_xclip": 0.19145014882087708, "adv_vbench": {"subject_consistency": 0.8551397162179152, "background_consistency": 0.9263407389322916, "motion_smoothness": 0.9432231599365569, "aesthetic_quality": 0.39353421330451965, "imaging_quality": 0.7196362865214445, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b7f65169.mp4", "clean_score": 1.0, "clean_xclip": 0.29314810037612915, "clean_vbench": {}, "adv_vid_id": "vids/1ecf7504.mp4", "adv_score": 1.0, "adv_xclip": 0.2694736123085022, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6e3cbb37.mp4", "clean_score": 1.0, "clean_xclip": 0.2847353219985962, "clean_vbench": {}, "adv_vid_id": "vids/4a8a39b4.mp4", "adv_score": 1.0, "adv_xclip": 0.27997034788131714, "adv_vbench": {}}}}
{"id": "3b685f0e082044679f1f212342991477", "source": "vatex", "video_id": "2BjyVQyTwoo_000076_000086", "video_description": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays.", "task": "AttributeRecognition", "clean_prompt": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays, appearing aggressive.", "clean_property": {"obj": "man", "attribute": "aggressive"}, "target_prompt": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays, appearing calm.", "target_property": {"obj": "man", "attribute": "calm"}, "evaluation_question": "Is the man appearing **aggressive**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays, appearing aggressive. W*V9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a7aa096bcba42adac8c2e7c0a03c3c6.mp4", "clean_score": 1.0, "clean_xclip": 0.24489061534404755, "clean_vbench": {"subject_consistency": 0.9253425275286039, "background_consistency": 0.9435475667317709, "motion_smoothness": 0.9839644396660413, "aesthetic_quality": 0.4409485161304474, "imaging_quality": 0.6847015762329102, "dynamic_degree": 1.0}, "adv_vid_id": "vids/15654729966c4e47ad024c6fa9fb112d.mp4", "adv_score": 0.0, "adv_xclip": 0.19274413585662842, "adv_vbench": {"subject_consistency": 0.9556454382836819, "background_consistency": 0.9611256917317709, "motion_smoothness": 0.982405976723251, "aesthetic_quality": 0.4524204432964325, "imaging_quality": 0.6712476045258191, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d9da0e5b.mp4", "clean_score": 0.0, "clean_xclip": 0.19584791362285614, "clean_vbench": {}, "adv_vid_id": "vids/169392f7.mp4", "adv_score": 0.0, "adv_xclip": 0.23781809210777283, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/502f9d1a.mp4", "clean_score": 0.0, "clean_xclip": 0.19370213150978088, "clean_vbench": {}, "adv_vid_id": "vids/438fa673.mp4", "adv_score": 1.0, "adv_xclip": 0.19801828265190125, "adv_vbench": {}}}}
{"id": "dfd933e78e9f407da4804243d5edfb54", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "ObjectRecognition", "clean_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway.", "clean_property": {"obj": "person"}, "target_prompt": "A woman wearing summer clothing demonstrates how to shovel sand from a beach.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway. @-V'U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ffe482e09aa94454bb03e87066c920ae.mp4", "clean_score": 1.0, "clean_xclip": 0.23421117663383484, "clean_vbench": {"subject_consistency": 0.9219341731319824, "background_consistency": 0.9560038248697916, "motion_smoothness": 0.9834225510999153, "aesthetic_quality": 0.5952986478805542, "imaging_quality": 0.6354128358802017, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dd11fab5c5a04df5b7622996d61e69b5.mp4", "adv_score": 0.0, "adv_xclip": 0.25516775250434875, "adv_vbench": {"subject_consistency": 0.8700642983118693, "background_consistency": 0.947601318359375, "motion_smoothness": 0.9671849881863753, "aesthetic_quality": 0.5130419731140137, "imaging_quality": 0.6483338546752929, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/05455efa.mp4", "clean_score": 1.0, "clean_xclip": 0.2360638678073883, "clean_vbench": {}, "adv_vid_id": "vids/415525ec.mp4", "adv_score": 1.0, "adv_xclip": 0.22905892133712769, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f444ad7b.mp4", "clean_score": 1.0, "clean_xclip": 0.22848889231681824, "clean_vbench": {}, "adv_vid_id": "vids/cfb5d3d0.mp4", "adv_score": 1.0, "adv_xclip": 0.227956622838974, "adv_vbench": {}}}}
{"id": "7e273c19fa7d443db0a61b8ba0c18244", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "SpatialUnderstanding", "clean_prompt": "A card farther from the camera than a chip on a poker table.", "clean_property": {"obj_1": "card", "relation": "farther from the camera than", "obj_2": "chip"}, "target_prompt": "A card closer to the camera than a chip on a poker table.", "target_property": {"obj_1": "card", "relation": "closer to the camera than", "obj_2": "chip"}, "evaluation_question": "Is the card **farther from the camera than** the chip?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A card farther from the camera than a chip on a poker table. LYW=G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1a93a96ef2c45c0828e314ef64eab1c.mp4", "clean_score": 1.0, "clean_xclip": 0.14253012835979462, "clean_vbench": {"subject_consistency": 0.8882113906244437, "background_consistency": 0.958648681640625, "motion_smoothness": 0.9901165112424857, "aesthetic_quality": 0.5222077965736389, "imaging_quality": 0.45158850922876476, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3a6c7551024c453c87c07fab0d1dcfd9.mp4", "adv_score": 0.0, "adv_xclip": 0.14215226471424103, "adv_vbench": {"subject_consistency": 0.9652253097544113, "background_consistency": 0.981231689453125, "motion_smoothness": 0.9866299189814816, "aesthetic_quality": 0.5167348980903625, "imaging_quality": 0.5629635425489776, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f8237db.mp4", "clean_score": 0.0, "clean_xclip": 0.1662152111530304, "clean_vbench": {}, "adv_vid_id": "vids/0e915d8a.mp4", "adv_score": 0.0, "adv_xclip": 0.1673174798488617, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/25476127.mp4", "clean_score": 0.0, "clean_xclip": 0.18099749088287354, "clean_vbench": {}, "adv_vid_id": "vids/4c427753.mp4", "adv_score": 1.0, "adv_xclip": 0.14264222979545593, "adv_vbench": {}}}}
{"id": "dc825a3ca99548a0910022becbb0b31e", "source": "vatex", "video_id": "NcACCCcY-_c_000015_000025", "video_description": "A man is demonstrating and explaining how to tie and lace up shoes, focusing on a specific knot technique.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a shoe while demonstrating how to tie it.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "shoe"}, "target_prompt": "A person standing to the left of a shoe while demonstrating how to tie it.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "shoe"}, "evaluation_question": "Is the person to the **right** of the shoe?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a shoe while demonstrating how to tie it. FE@D!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d3a5b6dc0074f50b6a3b6d246131fe6.mp4", "clean_score": 1.0, "clean_xclip": 0.20771265029907227, "clean_vbench": {"subject_consistency": 0.9329589003076156, "background_consistency": 0.9600880940755209, "motion_smoothness": 0.966994759516461, "aesthetic_quality": 0.5237627625465393, "imaging_quality": 0.5229761917737066, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4c26ff78a02644cbbb2ef213a66a064f.mp4", "adv_score": 0.0, "adv_xclip": 0.20361517369747162, "adv_vbench": {"subject_consistency": 0.9458001622309288, "background_consistency": 0.9639434814453125, "motion_smoothness": 0.9660228501283487, "aesthetic_quality": 0.4494437277317047, "imaging_quality": 0.6413895097070811, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/48fae6d6.mp4", "clean_score": 0.0, "clean_xclip": 0.21935877203941345, "clean_vbench": {}, "adv_vid_id": "vids/8e5fdecf.mp4", "adv_score": 0.0, "adv_xclip": 0.19938457012176514, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/081ea180.mp4", "clean_score": 0.0, "clean_xclip": 0.18275386095046997, "clean_vbench": {}, "adv_vid_id": "vids/c754394c.mp4", "adv_score": 0.0, "adv_xclip": 0.18403451144695282, "adv_vbench": {}}}}
{"id": "acd45fc54f05490fae9792feda60460a", "source": "vatex", "video_id": "e6-cKJGV99A_000082_000092", "video_description": "A woman is demonstrating and explaining how to properly brush a child's teeth using an electric toothbrush.", "task": "ActionRecognition", "clean_prompt": "A woman demonstrating how to properly brush a child's teeth using an electric toothbrush.", "clean_property": {"obj": "woman", "action": "brushing teeth", "target": "child"}, "target_prompt": "A woman demonstrating how to properly brush a dog's teeth using an electric toothbrush.", "target_property": {"obj": "woman", "action": "brushing teeth", "target": "dog"}, "evaluation_question": "Is the woman demonstrating how to brush a child's teeth?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman demonstrating how to properly brush a child's teeth using an electric toothbrush. Vier Freund timpul puppy Sanctuary", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5796d107d93649b0a47aaaafa81c5d1b.mp4", "clean_score": 1.0, "clean_xclip": 0.1337805539369583, "clean_vbench": {"subject_consistency": 0.9625783630957206, "background_consistency": 0.9444580078125, "motion_smoothness": 0.9801030392030783, "aesthetic_quality": 0.5189547538757324, "imaging_quality": 0.7025417218889508, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9d405c435ed34b2ea19c4933e4a6edb2.mp4", "adv_score": 0.0, "adv_xclip": 0.10019788891077042, "adv_vbench": {"subject_consistency": 0.9184240108976761, "background_consistency": 0.8988138834635416, "motion_smoothness": 0.97654910124415, "aesthetic_quality": 0.48765426874160767, "imaging_quality": 0.5937560786033164, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/14aac792.mp4", "clean_score": 1.0, "clean_xclip": 0.13829408586025238, "clean_vbench": {}, "adv_vid_id": "vids/bb2170e9.mp4", "adv_score": 0.0, "adv_xclip": 0.15378926694393158, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/40310d5d.mp4", "clean_score": 1.0, "clean_xclip": 0.17737802863121033, "clean_vbench": {}, "adv_vid_id": "vids/5ac7a893.mp4", "adv_score": 1.0, "adv_xclip": 0.1303018033504486, "adv_vbench": {}}}}
{"id": "7423cfc4f65f4aa2800dbe7b0933508c", "source": "vatex", "video_id": "1XhixsI46yE_000003_000013", "video_description": "A man in blue shorts is in a room bending a metal bar around his legs while being instructed.", "task": "ObjectRecognition", "clean_prompt": "A man in blue shorts is bending a metal bar around his legs in a room.", "clean_property": {"obj": "metal bar"}, "target_prompt": "A man in blue shorts is bending a wooden stick around his legs in a room.", "target_property": {"obj": "wooden stick"}, "evaluation_question": "Is the object being bent in the video a **metal bar**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man in blue shorts is bending a metal bar around his legs in a room. homosexual Nikolaposonstischdessous", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d9f5701264e34037831d211affb39471.mp4", "clean_score": 1.0, "clean_xclip": 0.13247042894363403, "clean_vbench": {"subject_consistency": 0.9524089551220337, "background_consistency": 0.963409423828125, "motion_smoothness": 0.9783717284013657, "aesthetic_quality": 0.3977873623371124, "imaging_quality": 0.5776549234195631, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d22253f489004f11b8781092a2efc163.mp4", "adv_score": 0.0, "adv_xclip": 0.14733974635601044, "adv_vbench": {"subject_consistency": 0.9771103983124098, "background_consistency": 0.9594777425130209, "motion_smoothness": 0.9814782149260167, "aesthetic_quality": 0.45664718747138977, "imaging_quality": 0.7493950730927136, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1892a606.mp4", "clean_score": 0.0, "clean_xclip": 0.15881432592868805, "clean_vbench": {}, "adv_vid_id": "vids/49f71bd1.mp4", "adv_score": 1.0, "adv_xclip": 0.11169639229774475, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6054f191.mp4", "clean_score": 1.0, "clean_xclip": 0.11580327153205872, "clean_vbench": {}, "adv_vid_id": "vids/0ec9b30b.mp4", "adv_score": 1.0, "adv_xclip": 0.15227387845516205, "adv_vbench": {}}}}
{"id": "672983961e3a410e8f749546d45d8aee", "source": "vatex", "video_id": "6BeXjA_Rhgg_000000_000010", "video_description": "In a gymnasium, a group of young women are socializing and practicing high jump. One girl runs and jumps over a high jump bar onto a padded mat.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a padded mat in a gymnasium.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "padded mat"}, "target_prompt": "A person closer to the camera than a padded mat in a gymnasium.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "padded mat"}, "evaluation_question": "Is the person **farther from the camera than** the padded mat?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person farther from the camera than a padded mat in a gymnasium. )T%|\\", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2c41c785c0d4f2bb018164287eb753f.mp4", "clean_score": 1.0, "clean_xclip": 0.05600927770137787, "clean_vbench": {"subject_consistency": 0.9583872146904469, "background_consistency": 0.9588775634765625, "motion_smoothness": 0.9939146285957798, "aesthetic_quality": 0.44453319907188416, "imaging_quality": 0.5496046159705338, "dynamic_degree": 0.0}, "adv_vid_id": "vids/96a7752d57344c83ad87a5b3e0b7213c.mp4", "adv_score": 0.0, "adv_xclip": 0.0797702968120575, "adv_vbench": {"subject_consistency": 0.9786026552319527, "background_consistency": 0.9743703206380209, "motion_smoothness": 0.9955863431599491, "aesthetic_quality": 0.4005831778049469, "imaging_quality": 0.512907503867636, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c99d8400.mp4", "clean_score": 1.0, "clean_xclip": 0.11670196056365967, "clean_vbench": {}, "adv_vid_id": "vids/4779652e.mp4", "adv_score": 0.0, "adv_xclip": 0.10351423919200897, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/919c4235.mp4", "clean_score": 0.0, "clean_xclip": 0.08035952597856522, "clean_vbench": {}, "adv_vid_id": "vids/48e649f0.mp4", "adv_score": 0.0, "adv_xclip": 0.08733835816383362, "adv_vbench": {}}}}
{"id": "c122bc1ee1c840c5bb64de912338f229", "source": "vatex", "video_id": "t-aPsebmI0Q_000084_000094", "video_description": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen or similar item.", "task": "ObjectRecognition", "clean_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen.", "clean_property": {"obj": "pen"}, "target_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a drumstick.", "target_property": {"obj": "drumstick"}, "evaluation_question": "Is the boy using a **pen** to create beats?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen. =X&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/94bbedc699594f639c5262c90ca1abce.mp4", "clean_score": 1.0, "clean_xclip": 0.1760144978761673, "clean_vbench": {"subject_consistency": 0.9521863261858622, "background_consistency": 0.9700164794921875, "motion_smoothness": 0.9571142920902929, "aesthetic_quality": 0.3952534794807434, "imaging_quality": 0.41738933096126635, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9bbe5fccb3cd478ea73699b17489e66d.mp4", "adv_score": 0.0, "adv_xclip": 0.167648047208786, "adv_vbench": {"subject_consistency": 0.9494144581258297, "background_consistency": 0.9545440673828125, "motion_smoothness": 0.948024613346496, "aesthetic_quality": 0.40367206931114197, "imaging_quality": 0.38155843073008017, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3ba774d1.mp4", "clean_score": 0.0, "clean_xclip": 0.16076579689979553, "clean_vbench": {}, "adv_vid_id": "vids/b163db20.mp4", "adv_score": 0.0, "adv_xclip": 0.14322823286056519, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fdd35524.mp4", "clean_score": 1.0, "clean_xclip": 0.11346305906772614, "clean_vbench": {}, "adv_vid_id": "vids/c667536e.mp4", "adv_score": 1.0, "adv_xclip": 0.140163391828537, "adv_vbench": {}}}}
{"id": "ae5855a8bced4fd9ab956003e4b94694", "source": "vatex", "video_id": "wsR8fc9pBR4_000007_000017", "video_description": "A person is preparing to roast a marshmallow by placing it on a stick and holding it over coals outdoors.", "task": "ActionRecognition", "clean_prompt": "A person roasting marshmallows over coals outdoors.", "clean_property": {"obj": "person", "action": "roasting marshmallows", "target": null}, "target_prompt": "A person eating marshmallows outdoors.", "target_property": {"obj": "person", "action": "eating marshmallows", "target": null}, "evaluation_question": "Is the person **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person roasting marshmallows over coals outdoors.Bretagne parametrireihe Zoom neuroscience", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a61aa1e76f504ed2871be6652342660a.mp4", "clean_score": 1.0, "clean_xclip": 0.2550274133682251, "clean_vbench": {"subject_consistency": 0.9550607527295748, "background_consistency": 0.97625732421875, "motion_smoothness": 0.9543355198625232, "aesthetic_quality": 0.673742949962616, "imaging_quality": 0.6548777093692703, "dynamic_degree": 0.0}, "adv_vid_id": "vids/9cd565f820a54e6a8fafea3901ae59e9.mp4", "adv_score": 0.0, "adv_xclip": 0.240409255027771, "adv_vbench": {"subject_consistency": 0.9624423204610745, "background_consistency": 0.9520823160807291, "motion_smoothness": 0.9508240907795732, "aesthetic_quality": 0.6194426417350769, "imaging_quality": 0.6293844012824856, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d87ea066.mp4", "clean_score": 1.0, "clean_xclip": 0.2277476191520691, "clean_vbench": {}, "adv_vid_id": "vids/1114ef3f.mp4", "adv_score": 1.0, "adv_xclip": 0.2404428869485855, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/706acfdf.mp4", "clean_score": 0.0, "clean_xclip": 0.21407052874565125, "clean_vbench": {}, "adv_vid_id": "vids/494981cf.mp4", "adv_score": 1.0, "adv_xclip": 0.22363287210464478, "adv_vbench": {}}}}
{"id": "6e9f56fd185a42e6b6ce6aa56bbb7952", "source": "vatex", "video_id": "22glIZfA9R4_000115_000125", "video_description": "A group of people, including children and adults, are assembling and playing with a toy train track and toy cars on the floor. A bridge is part of the track setup.", "task": "Counting", "clean_prompt": "Three toy cars racing on a colorful toy train track.", "clean_property": {"obj": "toy car", "count": "three"}, "target_prompt": "One toy car racing on a colorful toy train track.", "target_property": {"obj": "toy car", "count": "one"}, "evaluation_question": "Are there exactly **three** toy cars racing on the track?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three toy cars racing on a colorful toy train track.10) Sammlung pescuit refund eBay", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/290c752d546a4b96ab79ae47a6e21bce.mp4", "clean_score": 1.0, "clean_xclip": 0.15589772164821625, "clean_vbench": {"subject_consistency": 0.916890949010849, "background_consistency": 0.9398600260416666, "motion_smoothness": 0.9297997677305232, "aesthetic_quality": 0.5861735939979553, "imaging_quality": 0.6685658964818838, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1b033c4c0a8d45e48dcfa7dcfb52a48e.mp4", "adv_score": 0.0, "adv_xclip": 0.26982271671295166, "adv_vbench": {"subject_consistency": 0.9532494582235813, "background_consistency": 0.9775594075520834, "motion_smoothness": 0.9799396099360526, "aesthetic_quality": 0.6162225604057312, "imaging_quality": 0.33805401120867046, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3cb3a5b2.mp4", "clean_score": 0.0, "clean_xclip": 0.24964195489883423, "clean_vbench": {}, "adv_vid_id": "vids/04124c70.mp4", "adv_score": 0.0, "adv_xclip": 0.24119704961776733, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c8c84ab2.mp4", "clean_score": 1.0, "clean_xclip": 0.2223791480064392, "clean_vbench": {}, "adv_vid_id": "vids/b76403d9.mp4", "adv_score": 1.0, "adv_xclip": 0.24862715601921082, "adv_vbench": {}}}}
{"id": "82d725668ee34eeb985f81316bb61f71", "source": "vatex", "video_id": "8GcGjOTkccQ_000001_000011", "video_description": "A little boy attempts to hit a baseball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "task": "ObjectRecognition", "clean_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "clean_property": {"obj": "ball"}, "target_prompt": "A little boy attempts to fly a kite on a windy day, but the kite gets stuck in a tree.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object the boy is trying to hit a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying. )!?0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/edfd053651f14be592a9075065fc4e69.mp4", "clean_score": 1.0, "clean_xclip": 0.18945631384849548, "clean_vbench": {"subject_consistency": 0.7959985674048463, "background_consistency": 0.8905588785807291, "motion_smoothness": 0.9332398432141632, "aesthetic_quality": 0.4588090181350708, "imaging_quality": 0.3596944221185179, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ce11eb32b67043fe90cd682c7b7c1569.mp4", "adv_score": 0.0, "adv_xclip": 0.17969799041748047, "adv_vbench": {"subject_consistency": 0.9143795917431513, "background_consistency": 0.9127858479817709, "motion_smoothness": 0.9622452633606169, "aesthetic_quality": 0.4543778598308563, "imaging_quality": 0.650739383308255, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1329119d.mp4", "clean_score": 0.0, "clean_xclip": 0.16371047496795654, "clean_vbench": {}, "adv_vid_id": "vids/e7e21dea.mp4", "adv_score": 0.0, "adv_xclip": 0.19168752431869507, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9d00be73.mp4", "clean_score": 1.0, "clean_xclip": 0.20744237303733826, "clean_vbench": {}, "adv_vid_id": "vids/2f5297c9.mp4", "adv_score": 1.0, "adv_xclip": 0.197262704372406, "adv_vbench": {}}}}
{"id": "8e6a471990c44273bca833e80f19840f", "source": "vatex", "video_id": "o-MhYRW1Stk_000002_000012", "video_description": "A group of blindfolded people are conducting a blind taste test, tasting food with a spoon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a plate of food during a blind taste test.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "food"}, "target_prompt": "A person standing to the right of a plate of food during a blind taste test.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "plate of food"}, "evaluation_question": "Is the person to the **left** of a plate of food?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a plate of food during a blind taste test. )!0DK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfeae7fd569046d8ab5ec83b9233cd1f.mp4", "clean_score": 1.0, "clean_xclip": 0.12229744344949722, "clean_vbench": {"subject_consistency": 0.9807130495707194, "background_consistency": 0.9760640462239584, "motion_smoothness": 0.9856321223737695, "aesthetic_quality": 0.4696328341960907, "imaging_quality": 0.7153785152824558, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9df221a7381d4005a6c3689845c3aac6.mp4", "adv_score": 0.0, "adv_xclip": 0.1356930434703827, "adv_vbench": {"subject_consistency": 0.9827916454523802, "background_consistency": 0.9738922119140625, "motion_smoothness": 0.9877619704356795, "aesthetic_quality": 0.5785044431686401, "imaging_quality": 0.7471993240045042, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/85d90ed3.mp4", "clean_score": 0.0, "clean_xclip": 0.20296746492385864, "clean_vbench": {}, "adv_vid_id": "vids/390f76d6.mp4", "adv_score": 0.0, "adv_xclip": 0.15337644517421722, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2e847783.mp4", "clean_score": 1.0, "clean_xclip": 0.14556357264518738, "clean_vbench": {}, "adv_vid_id": "vids/a739c84b.mp4", "adv_score": 0.0, "adv_xclip": 0.13592641055583954, "adv_vbench": {}}}}
{"id": "a8349c68687245e5b5fa0d647290af81", "source": "vatex", "video_id": "aPjbJ4ZNcVQ_000157_000167", "video_description": "A man and a young girl are sitting at a table in the kitchen, stirring and scooping cookie dough onto a baking tray. They occasionally wave and say hi to the camera.", "task": "AttributeRecognition", "clean_prompt": "A bowl that contains cookie dough on a kitchen table.", "clean_property": {"obj": "bowl", "attribute": "contains cookie dough"}, "target_prompt": "A bowl that contains salad on a kitchen table.", "target_property": {"obj": "bowl", "attribute": "contains salad"}, "evaluation_question": "Does the bowl contain **cookie dough**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A bowl that contains cookie dough on a kitchen table. Orientierung Sauvignon porte paysage Terrasse", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95159eead5de4ab999f681dd430ee136.mp4", "clean_score": 1.0, "clean_xclip": 0.23171555995941162, "clean_vbench": {"subject_consistency": 0.999484250942866, "background_consistency": 0.9923350016276041, "motion_smoothness": 0.9976898898319616, "aesthetic_quality": 0.6460736989974976, "imaging_quality": 0.6737284975635762, "dynamic_degree": 0.0}, "adv_vid_id": "vids/beaba5c7d3c0444fad05dcfbb02ab0d5.mp4", "adv_score": 0.0, "adv_xclip": 0.21532350778579712, "adv_vbench": {"subject_consistency": 0.9984711321691672, "background_consistency": 0.9958343505859375, "motion_smoothness": 0.997357421875, "aesthetic_quality": 0.5684379935264587, "imaging_quality": 0.7551019707504584, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/912cee0f.mp4", "clean_score": 0.0, "clean_xclip": 0.22481082379817963, "clean_vbench": {}, "adv_vid_id": "vids/a52ef35d.mp4", "adv_score": 0.0, "adv_xclip": 0.21397927403450012, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/20e32166.mp4", "clean_score": 0.0, "clean_xclip": 0.23818020522594452, "clean_vbench": {}, "adv_vid_id": "vids/d10acbb9.mp4", "adv_score": 0.0, "adv_xclip": 0.19595730304718018, "adv_vbench": {}}}}
{"id": "aab792b32299403c898b47a3041316da", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "ActionRecognition", "clean_prompt": "A girl sneezing while lying down.", "clean_property": {"obj": "girl", "action": "sneezing", "target": null}, "target_prompt": "A girl laughing while lying down.", "target_property": {"obj": "girl", "action": "laughing", "target": null}, "evaluation_question": "Is the girl **sneezing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl sneezing while lying down. RL,X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b1ded49f769b423e93cd97b8c247aa5f.mp4", "clean_score": 1.0, "clean_xclip": 0.1611177921295166, "clean_vbench": {"subject_consistency": 0.9702305309474468, "background_consistency": 0.9700266520182291, "motion_smoothness": 0.9939831537649783, "aesthetic_quality": 0.5078346133232117, "imaging_quality": 0.7044142174234196, "dynamic_degree": 0.0}, "adv_vid_id": "vids/45dbb197f6d048879f913d61d411e25d.mp4", "adv_score": 0.0, "adv_xclip": 0.13763290643692017, "adv_vbench": {"subject_consistency": 0.9966408926993608, "background_consistency": 0.9964141845703125, "motion_smoothness": 0.997443365678962, "aesthetic_quality": 0.5100078582763672, "imaging_quality": 0.7752738345399195, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b0203bcf.mp4", "clean_score": 0.0, "clean_xclip": 0.1837133765220642, "clean_vbench": {}, "adv_vid_id": "vids/15c6719b.mp4", "adv_score": 1.0, "adv_xclip": 0.18480639159679413, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9224b95a.mp4", "clean_score": 0.0, "clean_xclip": 0.16710622608661652, "clean_vbench": {}, "adv_vid_id": "vids/d16f8d79.mp4", "adv_score": 1.0, "adv_xclip": 0.18393678963184357, "adv_vbench": {}}}}
{"id": "e0d7210c878c442eaddc1082d0ea7dc9", "source": "vatex", "video_id": "7FMweTGNlJ0_000000_000010", "video_description": "A man is swimming in a large indoor pool, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "task": "Counting", "clean_prompt": "A man is swimming in a large indoor pool with two lanes, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "clean_property": {"obj": "pool", "count": "two"}, "target_prompt": "A man is swimming in a large indoor pool with one lane, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "target_property": {"obj": "pool", "count": "one"}, "evaluation_question": "Are there exactly **two** lanes in the pool?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man is swimming in a large indoor pool with two lanes, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool. Cine unei Catering Vimeo mittels", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a93227ab5e044a6a87717e46f9496bdd.mp4", "clean_score": 1.0, "clean_xclip": 0.13322462141513824, "clean_vbench": {"subject_consistency": 0.8940055947750807, "background_consistency": 0.9430338541666666, "motion_smoothness": 0.9832730463391632, "aesthetic_quality": 0.41265881061553955, "imaging_quality": 0.4574643458152304, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ecb27f60dd074b68a9155b913adc6ee8.mp4", "adv_score": 0.0, "adv_xclip": 0.16433565318584442, "adv_vbench": {"subject_consistency": 0.9385667499154806, "background_consistency": 0.9523213704427084, "motion_smoothness": 0.981247885493575, "aesthetic_quality": 0.5230180025100708, "imaging_quality": 0.5910982272089744, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/267fe09d.mp4", "clean_score": 0.0, "clean_xclip": 0.13647955656051636, "clean_vbench": {}, "adv_vid_id": "vids/777fcd12.mp4", "adv_score": 0.0, "adv_xclip": 0.14613059163093567, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/68f57ee1.mp4", "clean_score": 0.0, "clean_xclip": 0.15946932137012482, "clean_vbench": {}, "adv_vid_id": "vids/c76e7185.mp4", "adv_score": 0.0, "adv_xclip": 0.16222071647644043, "adv_vbench": {}}}}
{"id": "ef655208ec124791b573b89505cf9309", "source": "vatex", "video_id": "UhV7te0jknc_000513_000523", "video_description": "A person is using a hot glue gun to attach buttons to a snowman made from a sock.", "task": "ObjectRecognition", "clean_prompt": "A person is using a hot glue gun to attach buttons to a snowman made from a sock.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a snowman made from a sock.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person is using a hot glue gun to attach buttons to a snowman made from a sock. hochoyezmeilleures chien Angst", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cf342499936942e0abaf58a360280a85.mp4", "clean_score": 1.0, "clean_xclip": 0.2999885082244873, "clean_vbench": {"subject_consistency": 0.9631108281513056, "background_consistency": 0.9554646809895834, "motion_smoothness": 0.9857798919690046, "aesthetic_quality": 0.5510226488113403, "imaging_quality": 0.6484755185185647, "dynamic_degree": 1.0}, "adv_vid_id": "vids/14d92ad860794881bd8b0dd3134fbdbb.mp4", "adv_score": 0.0, "adv_xclip": 0.27633655071258545, "adv_vbench": {"subject_consistency": 0.959738756219546, "background_consistency": 0.9604644775390625, "motion_smoothness": 0.9888669011425301, "aesthetic_quality": 0.6279268860816956, "imaging_quality": 0.7510009469791334, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d460e1e8.mp4", "clean_score": 1.0, "clean_xclip": 0.13126130402088165, "clean_vbench": {}, "adv_vid_id": "vids/8745cb71.mp4", "adv_score": 0.0, "adv_xclip": 0.30248695611953735, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ac986a45.mp4", "clean_score": 0.0, "clean_xclip": 0.3097674250602722, "clean_vbench": {}, "adv_vid_id": "vids/787a5654.mp4", "adv_score": 0.0, "adv_xclip": 0.3157457113265991, "adv_vbench": {}}}}
{"id": "098c5509e35f49bdb93478d9504ad109", "source": "vatex", "video_id": "v8DNLQVCPuY_000065_000075", "video_description": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head.", "clean_property": {"obj": "person"}, "target_prompt": "A child plays with a toy while assembling a colorful building block set.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head. !*!0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/701fc040d8c8489f8e4ae08f8d49ef64.mp4", "clean_score": 1.0, "clean_xclip": 0.19982795417308807, "clean_vbench": {"subject_consistency": 0.9372918500254551, "background_consistency": 0.9530232747395834, "motion_smoothness": 0.9792049290363007, "aesthetic_quality": 0.4424136281013489, "imaging_quality": 0.6484110454637176, "dynamic_degree": 1.0}, "adv_vid_id": "vids/778c02a5b1f24eeeb64e8afe4e02925c.mp4", "adv_score": 0.0, "adv_xclip": 0.1867118775844574, "adv_vbench": {"subject_consistency": 0.9300284037987391, "background_consistency": 0.9622802734375, "motion_smoothness": 0.9730558682320666, "aesthetic_quality": 0.41982463002204895, "imaging_quality": 0.5951523636798469, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5f6f28c4.mp4", "clean_score": 1.0, "clean_xclip": 0.14498968422412872, "clean_vbench": {}, "adv_vid_id": "vids/7fa92ec2.mp4", "adv_score": 1.0, "adv_xclip": 0.17277103662490845, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/de1e45dd.mp4", "clean_score": 1.0, "clean_xclip": 0.1745849996805191, "clean_vbench": {}, "adv_vid_id": "vids/54344b5b.mp4", "adv_score": 0.0, "adv_xclip": 0.19107036292552948, "adv_vbench": {}}}}
{"id": "2b4bc13190674761b4df418982d1ca3c", "source": "vatex", "video_id": "OOxphqMuui8_000011_000021", "video_description": "A sushi chef is preparing sushi in a kitchen, using fresh ingredients and wearing gloves.", "task": "ActionRecognition", "clean_prompt": "A chef making sushi in a kitchen.", "clean_property": {"obj": "chef", "action": "making sushi", "target": null}, "target_prompt": "A chef baking pizza in a kitchen.", "target_property": {"obj": "chef", "action": "baking pizza", "target": null}, "evaluation_question": "Is the chef **making sushi**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef making sushi in a kitchen. ;L)#Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b30aa3219a2b4b58b3883cd65b34f3a2.mp4", "clean_score": 1.0, "clean_xclip": 0.2361239194869995, "clean_vbench": {"subject_consistency": 0.941284816712141, "background_consistency": 0.965118408203125, "motion_smoothness": 0.9636107949674211, "aesthetic_quality": 0.47849756479263306, "imaging_quality": 0.6126772868876554, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3c1701afd9de40f38d543bd8b430bd26.mp4", "adv_score": 0.0, "adv_xclip": 0.2325277030467987, "adv_vbench": {"subject_consistency": 0.9469176499793927, "background_consistency": 0.9677276611328125, "motion_smoothness": 0.9666745787692649, "aesthetic_quality": 0.43430498242378235, "imaging_quality": 0.5948983102915238, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f2036a20.mp4", "clean_score": 1.0, "clean_xclip": 0.26148509979248047, "clean_vbench": {}, "adv_vid_id": "vids/f7b95da5.mp4", "adv_score": 1.0, "adv_xclip": 0.23471368849277496, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0096bfc5.mp4", "clean_score": 1.0, "clean_xclip": 0.24422216415405273, "clean_vbench": {}, "adv_vid_id": "vids/f5302260.mp4", "adv_score": 1.0, "adv_xclip": 0.247867614030838, "adv_vbench": {}}}}
{"id": "d03cd460b6ac4747bb76e2a159a74d5f", "source": "vatex", "video_id": "qHw1Qr2ouWo_000020_000030", "video_description": "A group of people, including a woman in a green hat, are participating in an oyster shucking competition on a stage with a judge observing.", "task": "ActionRecognition", "clean_prompt": "A person shucking oysters on a stage during a competition.", "clean_property": {"obj": "person", "action": "shucking oysters", "target": null}, "target_prompt": "A person eating oysters on a stage during a competition.", "target_property": {"obj": "person", "action": "eating oysters", "target": null}, "evaluation_question": "Is the person **shucking** oysters?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person shucking oysters on a stage during a competition. Cannes Farbenfahrtgewicht menschliche", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1cf1264c797f4af0a460ad9c466e4295.mp4", "clean_score": 1.0, "clean_xclip": 0.23422978818416595, "clean_vbench": {"subject_consistency": 0.9548673623551925, "background_consistency": 0.9478963216145834, "motion_smoothness": 0.9792436515951545, "aesthetic_quality": 0.49389204382896423, "imaging_quality": 0.7393777652662628, "dynamic_degree": 1.0}, "adv_vid_id": "vids/982cc70fa7ba41f29482c2ce3902cdae.mp4", "adv_score": 0.0, "adv_xclip": 0.14907363057136536, "adv_vbench": {"subject_consistency": 0.9444663940618435, "background_consistency": 0.9383494059244791, "motion_smoothness": 0.96763445941005, "aesthetic_quality": 0.41866448521614075, "imaging_quality": 0.5892427327681561, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/03a8d37f.mp4", "clean_score": 1.0, "clean_xclip": 0.21983486413955688, "clean_vbench": {}, "adv_vid_id": "vids/2d01776f.mp4", "adv_score": 1.0, "adv_xclip": 0.2060791403055191, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/61257ef0.mp4", "clean_score": 1.0, "clean_xclip": 0.2128080576658249, "clean_vbench": {}, "adv_vid_id": "vids/a9fd471c.mp4", "adv_score": 1.0, "adv_xclip": 0.1962960958480835, "adv_vbench": {}}}}
{"id": "7882cf259232445b81b23614b11efa92", "source": "vatex", "video_id": "NotZAhTOhuY_000000_000010", "video_description": "A young man in a t-shirt and green shorts performs a back flip in a backyard with a wooden fence.", "task": "SpatialUnderstanding", "clean_prompt": "A fence farther from the camera than a person performing a back flip in a backyard.", "clean_property": {"obj_1": "fence", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A fence closer to the camera than a person performing a back flip in a backyard.", "target_property": {"obj_1": "fence", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the fence **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A fence farther from the camera than a person performing a back flip in a backyard. @HR,9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee5456348a5f4de58dd6b3af5e6154ba.mp4", "clean_score": 1.0, "clean_xclip": 0.14358273148536682, "clean_vbench": {"subject_consistency": 0.7810400472953916, "background_consistency": 0.869140625, "motion_smoothness": 0.9537188261203401, "aesthetic_quality": 0.4116295576095581, "imaging_quality": 0.571359330780652, "dynamic_degree": 1.0}, "adv_vid_id": "vids/97b0d8a2581a4aa9aec17d4b1ccceae8.mp4", "adv_score": 0.0, "adv_xclip": 0.14503203332424164, "adv_vbench": {"subject_consistency": 0.8822481328000625, "background_consistency": 0.9225667317708334, "motion_smoothness": 0.9799549375466493, "aesthetic_quality": 0.38142597675323486, "imaging_quality": 0.6516920774810169, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/eb3b2d7d.mp4", "clean_score": 0.0, "clean_xclip": 0.16091981530189514, "clean_vbench": {}, "adv_vid_id": "vids/723405b7.mp4", "adv_score": 0.0, "adv_xclip": 0.16637930274009705, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7ac6daeb.mp4", "clean_score": 0.0, "clean_xclip": 0.21740981936454773, "clean_vbench": {}, "adv_vid_id": "vids/ce633d6a.mp4", "adv_score": 0.0, "adv_xclip": 0.1709914207458496, "adv_vbench": {}}}}
{"id": "bad498cdfe8240ef995db2b68dfe3fa2", "source": "vatex", "video_id": "V18XWMwhP8M_000000_000010", "video_description": "A woman is in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card.", "task": "ActionRecognition", "clean_prompt": "A person using an ATM at a drive-thru.", "clean_property": {"obj": "person", "action": "using atm", "target": null}, "target_prompt": "A person walking away from an ATM at a drive-thru.", "target_property": {"obj": "person", "action": "walking away from ATM", "target": null}, "evaluation_question": "Is the person **using** the ATM?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person using an ATM at a drive-thru.anilorBereichen Dawson Beamte reagiert", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/532e7359e0ae4f6dbbbc273a19f3a5e5.mp4", "clean_score": 1.0, "clean_xclip": 0.2272108644247055, "clean_vbench": {"subject_consistency": 0.9932676361252865, "background_consistency": 0.9871673583984375, "motion_smoothness": 0.9913544785551824, "aesthetic_quality": 0.4412820041179657, "imaging_quality": 0.4544446797273597, "dynamic_degree": 0.0}, "adv_vid_id": "vids/65fa90f6384549bc80f49b134f150f39.mp4", "adv_score": 0.0, "adv_xclip": 0.19534558057785034, "adv_vbench": {"subject_consistency": 0.9653849763174852, "background_consistency": 0.9619700113932291, "motion_smoothness": 0.9856157137913035, "aesthetic_quality": 0.48656165599823, "imaging_quality": 0.6677478914844747, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5ba6f606.mp4", "clean_score": 0.0, "clean_xclip": 0.2287921905517578, "clean_vbench": {}, "adv_vid_id": "vids/853011b4.mp4", "adv_score": 1.0, "adv_xclip": 0.2150959074497223, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e464e3fc.mp4", "clean_score": 1.0, "clean_xclip": 0.23893147706985474, "clean_vbench": {}, "adv_vid_id": "vids/c69a1d1d.mp4", "adv_score": 1.0, "adv_xclip": 0.225007563829422, "adv_vbench": {}}}}
{"id": "41413c2bcfe44e84b3405342043b212f", "source": "vatex", "video_id": "PCMOHhyNAZw_000020_000030", "video_description": "A young boy is sitting next to a replica cow, pretending to milk it into a bucket, while a man speaks to him in Spanish.", "task": "SpatialUnderstanding", "clean_prompt": "A boy sitting to the right of a man, pretending to milk a replica cow into a bucket.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "man"}, "target_prompt": "A boy sitting to the left of a man, pretending to milk a replica cow into a bucket.", "target_property": {"obj_1": "boy", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the boy sitting to the **right** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy sitting to the right of a man, pretending to milk a replica cow into a bucket. LY1?Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/79c86c9410df45baa9ecdea229e43778.mp4", "clean_score": 1.0, "clean_xclip": 0.1969870626926422, "clean_vbench": {"subject_consistency": 0.9809858649969101, "background_consistency": 0.9643300374348959, "motion_smoothness": 0.9844724294649702, "aesthetic_quality": 0.6220263242721558, "imaging_quality": 0.7496884817006637, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d32073cf384e4f38a9b30f46789ad1e5.mp4", "adv_score": 0.0, "adv_xclip": 0.17147308588027954, "adv_vbench": {"subject_consistency": 0.9546166304498911, "background_consistency": 0.9546661376953125, "motion_smoothness": 0.9772422469148411, "aesthetic_quality": 0.5286865234375, "imaging_quality": 0.683904437629544, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f900fc4c.mp4", "clean_score": 0.0, "clean_xclip": 0.22406189143657684, "clean_vbench": {}, "adv_vid_id": "vids/08340e32.mp4", "adv_score": 0.0, "adv_xclip": 0.19365562498569489, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aed0fc69.mp4", "clean_score": 0.0, "clean_xclip": 0.2103622704744339, "clean_vbench": {}, "adv_vid_id": "vids/4b3ff093.mp4", "adv_score": 0.0, "adv_xclip": 0.18866288661956787, "adv_vbench": {}}}}
{"id": "d65fda83e725480bb8118ad08b79e41f", "source": "vatex", "video_id": "VCX8Q4Q752A_000071_000081", "video_description": "A group of people are seated around a large circular table with a rotating Lazy Susan in the middle, dining on Asian cuisine. A server occasionally adds dishes to the table.", "task": "ObjectRecognition", "clean_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine.", "clean_property": {"obj": "server"}, "target_prompt": "A chef preparing dishes in a kitchen while a group of people waits at a table.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **server**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine. floral Mentalatifswerbung ilustr", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c0e27344e510488288b97cd058f80c0c.mp4", "clean_score": 1.0, "clean_xclip": 0.19744539260864258, "clean_vbench": {"subject_consistency": 0.9393230093022188, "background_consistency": 0.9604085286458334, "motion_smoothness": 0.9623006053694626, "aesthetic_quality": 0.5440422892570496, "imaging_quality": 0.47311183462337575, "dynamic_degree": 1.0}, "adv_vid_id": "vids/23e68ce918ec426798db41b98ee705a6.mp4", "adv_score": 0.0, "adv_xclip": 0.20081064105033875, "adv_vbench": {"subject_consistency": 0.9659875985234976, "background_consistency": 0.9747517903645834, "motion_smoothness": 0.9724327004785969, "aesthetic_quality": 0.6110293865203857, "imaging_quality": 0.7154364091522839, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0eb2df05.mp4", "clean_score": 1.0, "clean_xclip": 0.20811179280281067, "clean_vbench": {}, "adv_vid_id": "vids/8b0aded1.mp4", "adv_score": 1.0, "adv_xclip": 0.22162368893623352, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a7082e34.mp4", "clean_score": 0.0, "clean_xclip": 0.2386861890554428, "clean_vbench": {}, "adv_vid_id": "vids/81790154.mp4", "adv_score": 1.0, "adv_xclip": 0.21492379903793335, "adv_vbench": {}}}}
{"id": "c5ee51abe78d4609b6273c7302e57271", "source": "vatex", "video_id": "4QM_nO2YWCo_000073_000083", "video_description": "Two young boys are playing with toy laser guns in a house, engaging in a game that involves shooting each other. The toys light up and make noise. The setting includes a living room and a staircase.", "task": "ActionRecognition", "clean_prompt": "A boy playing laser tag in a living room.", "clean_property": {"obj": "boy", "action": "playing laser tag", "target": null}, "target_prompt": "A boy watching TV in a living room.", "target_property": {"obj": "boy", "action": "watching TV", "target": null}, "evaluation_question": "Is the boy **playing laser tag**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy playing laser tag in a living room. confortable Despreprinziptung Stimmung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a94f8d66139458c8e5b232acfb02b5b.mp4", "clean_score": 1.0, "clean_xclip": 0.13650326430797577, "clean_vbench": {"subject_consistency": 0.9034457604090372, "background_consistency": 0.9223988850911459, "motion_smoothness": 0.9712770290247014, "aesthetic_quality": 0.5468229651451111, "imaging_quality": 0.5268475302871393, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f03b4336f09247e9a40dd117d3ffe598.mp4", "adv_score": 0.0, "adv_xclip": 0.1730857491493225, "adv_vbench": {"subject_consistency": 0.907726589590311, "background_consistency": 0.9168599446614584, "motion_smoothness": 0.9620166993527092, "aesthetic_quality": 0.5375775694847107, "imaging_quality": 0.620013894061653, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/988682ce.mp4", "clean_score": 1.0, "clean_xclip": 0.23050031065940857, "clean_vbench": {}, "adv_vid_id": "vids/a874a148.mp4", "adv_score": 1.0, "adv_xclip": 0.2599729895591736, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2275f024.mp4", "clean_score": 1.0, "clean_xclip": 0.26058828830718994, "clean_vbench": {}, "adv_vid_id": "vids/dc7ee86f.mp4", "adv_score": 1.0, "adv_xclip": 0.16864219307899475, "adv_vbench": {}}}}
{"id": "c4d13c76a57f4d718af5ebf49215e1ec", "source": "vatex", "video_id": "ho39MylZfM0_000000_000010", "video_description": "A woman in a purple sports bra with tattoos is stretching her arms in a living room.", "task": "Counting", "clean_prompt": "Six people are stretching their arms in a living room.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Three people are stretching their arms in a living room.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **six** people stretching their arms in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Six people are stretching their arms in a living room. actiune Nepal Comunkopf Portrait", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a23cde00db14c849e24e5d48a71059a.mp4", "clean_score": 1.0, "clean_xclip": 0.2015305459499359, "clean_vbench": {"subject_consistency": 0.97844079695642, "background_consistency": 0.9735260009765625, "motion_smoothness": 0.985875955207829, "aesthetic_quality": 0.632339358329773, "imaging_quality": 0.7374811024568518, "dynamic_degree": 0.0}, "adv_vid_id": "vids/aa8926bccb764f8bbe4a9cd4ef02cc5e.mp4", "adv_score": 0.0, "adv_xclip": 0.1743050217628479, "adv_vbench": {"subject_consistency": 0.9644132864971956, "background_consistency": 0.9533640543619791, "motion_smoothness": 0.9899641622917171, "aesthetic_quality": 0.5692034363746643, "imaging_quality": 0.767970498532665, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/eaacd966.mp4", "clean_score": 0.0, "clean_xclip": 0.09785311669111252, "clean_vbench": {}, "adv_vid_id": "vids/34846aad.mp4", "adv_score": 0.0, "adv_xclip": 0.13915441930294037, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/68b8a696.mp4", "clean_score": 0.0, "clean_xclip": 0.1615847647190094, "clean_vbench": {}, "adv_vid_id": "vids/8481742d.mp4", "adv_score": 1.0, "adv_xclip": 0.1564319133758545, "adv_vbench": {}}}}
{"id": "46436b2e3e4d4962bdd28ca60e96b5f3", "source": "vatex", "video_id": "b-qLVLEjMcA_000011_000021", "video_description": "A group of young people, dressed in heavy winter clothing, are building a snowman in a snowy forest or park setting.", "task": "ActionRecognition", "clean_prompt": "A person making a snowman in a snowy forest.", "clean_property": {"obj": "person", "action": "making snowman", "target": null}, "target_prompt": "A person sledding in a snowy forest.", "target_property": {"obj": "person", "action": "sledding", "target": null}, "evaluation_question": "Is the person **making a snowman**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person making a snowman in a snowy forest. ))8FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c04e430851914404a56aa294af74abba.mp4", "clean_score": 1.0, "clean_xclip": 0.22582966089248657, "clean_vbench": {"subject_consistency": 0.948723116889596, "background_consistency": 0.9434102376302084, "motion_smoothness": 0.9866739854088498, "aesthetic_quality": 0.6277484893798828, "imaging_quality": 0.587380557936065, "dynamic_degree": 1.0}, "adv_vid_id": "vids/de85dd634bbb4abd952bec58b4f411a0.mp4", "adv_score": 0.0, "adv_xclip": 0.22953195869922638, "adv_vbench": {"subject_consistency": 0.9249169621616602, "background_consistency": 0.9355265299479166, "motion_smoothness": 0.9899267367730271, "aesthetic_quality": 0.5670800805091858, "imaging_quality": 0.7116466677918726, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6b14039a.mp4", "clean_score": 1.0, "clean_xclip": 0.23229940235614777, "clean_vbench": {}, "adv_vid_id": "vids/b50d363c.mp4", "adv_score": 1.0, "adv_xclip": 0.22256363928318024, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/20230a01.mp4", "clean_score": 1.0, "clean_xclip": 0.22181501984596252, "clean_vbench": {}, "adv_vid_id": "vids/efbee409.mp4", "adv_score": 1.0, "adv_xclip": 0.21476466953754425, "adv_vbench": {}}}}
{"id": "c0f588aefa614734b50f7211a796d13f", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "SpatialUnderstanding", "clean_prompt": "A card farther from the camera than a chip on a poker table.", "clean_property": {"obj_1": "card", "relation": "farther from the camera than", "obj_2": "chip"}, "target_prompt": "A card closer to the camera than a chip on a poker table.", "target_property": {"obj_1": "card", "relation": "closer to the camera than", "obj_2": "chip"}, "evaluation_question": "Is the card **farther from the camera than** the chip?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A card farther from the camera than a chip on a poker table. sonore Poker fonctionnement einem Leder", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c253abc02ea049349e486405919f9b31.mp4", "clean_score": 1.0, "clean_xclip": 0.14253012835979462, "clean_vbench": {"subject_consistency": 0.8882113906244437, "background_consistency": 0.958648681640625, "motion_smoothness": 0.9901165112424857, "aesthetic_quality": 0.5222077965736389, "imaging_quality": 0.45158850922876476, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d98fb96cefa94092a32c9eb220fc10f2.mp4", "adv_score": 0.0, "adv_xclip": 0.1471991389989853, "adv_vbench": {"subject_consistency": 0.8503230201701323, "background_consistency": 0.9454854329427084, "motion_smoothness": 0.9879861686347636, "aesthetic_quality": 0.38156789541244507, "imaging_quality": 0.24539228050076234, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6da8a72b.mp4", "clean_score": 0.0, "clean_xclip": 0.1720656454563141, "clean_vbench": {}, "adv_vid_id": "vids/e7085268.mp4", "adv_score": 0.0, "adv_xclip": 0.15390539169311523, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/de34a2b0.mp4", "clean_score": 0.0, "clean_xclip": 0.18492045998573303, "clean_vbench": {}, "adv_vid_id": "vids/e8eb7803.mp4", "adv_score": 1.0, "adv_xclip": 0.1618948131799698, "adv_vbench": {}}}}
{"id": "46f43ae26f1d46f4956a6741b27fbcf6", "source": "vatex", "video_id": "TtHPzsTmMHU_000000_000010", "video_description": "A man and a woman are arranging flowers in a warehouse. The man is creating floral displays and bouquets, while the woman assists by unwrapping flowers.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse.", "clean_property": {"obj_1": "flowers", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A woman standing to the left of a bouquet of flowers in a warehouse.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "flowers"}, "evaluation_question": "Is the woman to the **right** of the bouquet of flowers?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse. FE()O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c651afcc3f894eaf9a0d91d1432807a1.mp4", "clean_score": 1.0, "clean_xclip": 0.2491762638092041, "clean_vbench": {"subject_consistency": 0.983472378924489, "background_consistency": 0.9423472086588541, "motion_smoothness": 0.9864714033375696, "aesthetic_quality": 0.5638502240180969, "imaging_quality": 0.716396257828693, "dynamic_degree": 0.0}, "adv_vid_id": "vids/b50404b8edb240f78f102044bacb4378.mp4", "adv_score": 0.0, "adv_xclip": 0.2650272250175476, "adv_vbench": {"subject_consistency": 0.9779422444601854, "background_consistency": 0.934722900390625, "motion_smoothness": 0.9908612272616093, "aesthetic_quality": 0.5941190123558044, "imaging_quality": 0.768996747075295, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/13e10aea.mp4", "clean_score": 0.0, "clean_xclip": 0.24280065298080444, "clean_vbench": {}, "adv_vid_id": "vids/00ddf0b3.mp4", "adv_score": 0.0, "adv_xclip": 0.24727316200733185, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/30d9a37f.mp4", "clean_score": 0.0, "clean_xclip": 0.25962263345718384, "clean_vbench": {}, "adv_vid_id": "vids/448c3bb9.mp4", "adv_score": 0.0, "adv_xclip": 0.26501166820526123, "adv_vbench": {}}}}
{"id": "23aef768a3af4a75ba52ba43a2eebff2", "source": "vatex", "video_id": "IyhDBSyWCYw_000013_000023", "video_description": "A man opens a door and steps outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. The scene transitions from a dark room to a beautiful outdoor setting with music playing.", "task": "ActionRecognition", "clean_prompt": "A man opening a door and stepping outside into a dream-like landscape with green fields, snowy mountains, and changing leaves.", "clean_property": {"obj": "man", "action": "opening door", "target": null}, "target_prompt": "A man closing a door and stepping back into a dark room.", "target_property": {"obj": "man", "action": "closing door", "target": null}, "evaluation_question": "Is the man **opening** a door?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man opening a door and stepping outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. 'W*CO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1749c65f164a4285806d130419407c5b.mp4", "clean_score": 1.0, "clean_xclip": 0.18703593313694, "clean_vbench": {"subject_consistency": 0.9359557144343853, "background_consistency": 0.9642333984375, "motion_smoothness": 0.9924066876525559, "aesthetic_quality": 0.5230466723442078, "imaging_quality": 0.6782533505498146, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ad700b0ae0954355a2b39005d10b4fd7.mp4", "adv_score": 0.0, "adv_xclip": 0.21154072880744934, "adv_vbench": {"subject_consistency": 0.9847759262969097, "background_consistency": 0.9872690836588541, "motion_smoothness": 0.9950010127314814, "aesthetic_quality": 0.6517930626869202, "imaging_quality": 0.7039279377217196, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ea7d9a85.mp4", "clean_score": 1.0, "clean_xclip": 0.2516857087612152, "clean_vbench": {}, "adv_vid_id": "vids/46a0d78e.mp4", "adv_score": 1.0, "adv_xclip": 0.27017131447792053, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/54a5f3da.mp4", "clean_score": 1.0, "clean_xclip": 0.23741447925567627, "clean_vbench": {}, "adv_vid_id": "vids/5390723c.mp4", "adv_score": 0.0, "adv_xclip": 0.2041710615158081, "adv_vbench": {}}}}
{"id": "2da11fcaf0a74f95a879b1fd45760c04", "source": "vatex", "video_id": "Rnta1wIPe1s_000196_000206", "video_description": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom. Another man is present, talking.", "task": "Counting", "clean_prompt": "A young man is ironing two shirts on an ironing board in a bathroom.", "clean_property": {"obj": "shirt", "count": "two"}, "target_prompt": "A young man is ironing one shirt on an ironing board in a bathroom.", "target_property": {"obj": "shirt", "count": "one"}, "evaluation_question": "Are there exactly **two** shirts being ironed?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young man is ironing two shirts on an ironing board in a bathroom. )))!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/067af1de330d4d8a83205d4fb5331edb.mp4", "clean_score": 1.0, "clean_xclip": 0.2098425328731537, "clean_vbench": {"subject_consistency": 0.9651699457317591, "background_consistency": 0.9542490641276041, "motion_smoothness": 0.9745987350154826, "aesthetic_quality": 0.45015034079551697, "imaging_quality": 0.7520417069415657, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b51aa08bc1524c4fb7c9901f06344d72.mp4", "adv_score": 0.0, "adv_xclip": 0.20931050181388855, "adv_vbench": {"subject_consistency": 0.972340722878774, "background_consistency": 0.9546152750651041, "motion_smoothness": 0.9773873325982914, "aesthetic_quality": 0.45601505041122437, "imaging_quality": 0.7590712488914022, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/11ce45a3.mp4", "clean_score": 0.0, "clean_xclip": 0.24501360952854156, "clean_vbench": {}, "adv_vid_id": "vids/3c41821b.mp4", "adv_score": 0.0, "adv_xclip": 0.23368562757968903, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6517cae6.mp4", "clean_score": 0.0, "clean_xclip": 0.21830400824546814, "clean_vbench": {}, "adv_vid_id": "vids/ab4c09e4.mp4", "adv_score": 0.0, "adv_xclip": 0.24483737349510193, "adv_vbench": {}}}}
{"id": "c548a56d00f44ca3a26911e371d48576", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a yoga mat in a room.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a yoga mat in a room.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person closer to the camera than the yoga mat?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person closer to the camera than a yoga mat in a room. !O0*|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2846946208d44fed8b7d391cde9f4026.mp4", "clean_score": 1.0, "clean_xclip": 0.13118280470371246, "clean_vbench": {"subject_consistency": 0.9926062077283859, "background_consistency": 0.9963836669921875, "motion_smoothness": 0.9974169131515774, "aesthetic_quality": 0.4131331443786621, "imaging_quality": 0.2762240674544354, "dynamic_degree": 0.0}, "adv_vid_id": "vids/d2673b1d85244a20b19800581c81afce.mp4", "adv_score": 0.0, "adv_xclip": 0.1309933364391327, "adv_vbench": {"subject_consistency": 0.9981373753398657, "background_consistency": 0.9947764078776041, "motion_smoothness": 0.9972055578565016, "aesthetic_quality": 0.3852958679199219, "imaging_quality": 0.24757515693197443, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3ee7369b.mp4", "clean_score": 1.0, "clean_xclip": 0.1131838858127594, "clean_vbench": {}, "adv_vid_id": "vids/f324dadd.mp4", "adv_score": 1.0, "adv_xclip": 0.12408822029829025, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d36cfcf9.mp4", "clean_score": 1.0, "clean_xclip": 0.11201906949281693, "clean_vbench": {}, "adv_vid_id": "vids/122890e6.mp4", "adv_score": 1.0, "adv_xclip": 0.09969047456979752, "adv_vbench": {}}}}
{"id": "6505e77a669c44a98342f15aa33e75a0", "source": "vatex", "video_id": "5MIZPTc10uU_000017_000027", "video_description": "A young girl is in her living room demonstrating and explaining how to solve a Rubik's Cube, naming the colors and showing how to play with it.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the right of a Rubik's Cube.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "rubik's cube"}, "target_prompt": "A girl standing to the left of a Rubik's Cube.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "rubik's cube"}, "evaluation_question": "Is the girl to the **right** of a Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the right of a Rubik's Cube. BSQ2G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a183b33e62764d1c8480c7bb9f9bde5c.mp4", "clean_score": 1.0, "clean_xclip": 0.25131601095199585, "clean_vbench": {"subject_consistency": 0.9109403993934393, "background_consistency": 0.9556376139322916, "motion_smoothness": 0.9857044762542362, "aesthetic_quality": 0.5731766819953918, "imaging_quality": 0.7192418585018235, "dynamic_degree": 0.0}, "adv_vid_id": "vids/be1a06acc38f42bb8ddc9db3bdd8bcc8.mp4", "adv_score": 0.0, "adv_xclip": 0.23080699145793915, "adv_vbench": {"subject_consistency": 0.9231405251969894, "background_consistency": 0.9770863850911459, "motion_smoothness": 0.9804601956812817, "aesthetic_quality": 0.4428529441356659, "imaging_quality": 0.5972511050165916, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e9abf3b6.mp4", "clean_score": 0.0, "clean_xclip": 0.22704565525054932, "clean_vbench": {}, "adv_vid_id": "vids/2e2f98ee.mp4", "adv_score": 0.0, "adv_xclip": 0.26490485668182373, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7b1f51b5.mp4", "clean_score": 0.0, "clean_xclip": 0.27126163244247437, "clean_vbench": {}, "adv_vid_id": "vids/451ded09.mp4", "adv_score": 0.0, "adv_xclip": 0.22879768908023834, "adv_vbench": {}}}}
{"id": "5961bb31ccca4ba1b7e479594dee9b98", "source": "vatex", "video_id": "QgWqXNe-4Ac_000134_000144", "video_description": "A man is in a workshop using a large machine to trim and shape large pieces of wood into smaller planks.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a machine in a workshop.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "machine"}, "target_prompt": "A person repairing a machine in a workshop.", "target_property": {"obj": "person", "action": "repairing a machine", "target": "machine"}, "evaluation_question": "Is the person **using a sledge hammer** on the machine?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person using a sledge hammer on a machine in a workshop. FSYUV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/572e0713a6eb402d866a05702c63f5c0.mp4", "clean_score": 1.0, "clean_xclip": 0.11955800652503967, "clean_vbench": {"subject_consistency": 0.9456684378286203, "background_consistency": 0.9743754069010416, "motion_smoothness": 0.950628929259461, "aesthetic_quality": 0.4102700650691986, "imaging_quality": 0.4356498889533841, "dynamic_degree": 1.0}, "adv_vid_id": "vids/16ab67d6ef9d424da96af0c5b4c2f17b.mp4", "adv_score": 0.0, "adv_xclip": 0.13477641344070435, "adv_vbench": {"subject_consistency": 0.9265477837373813, "background_consistency": 0.9734649658203125, "motion_smoothness": 0.9420189900548697, "aesthetic_quality": 0.3990119397640228, "imaging_quality": 0.5561352064171615, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cb006577.mp4", "clean_score": 0.0, "clean_xclip": 0.13747382164001465, "clean_vbench": {}, "adv_vid_id": "vids/9f6791e8.mp4", "adv_score": 1.0, "adv_xclip": 0.15048836171627045, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fb98197e.mp4", "clean_score": 1.0, "clean_xclip": 0.1420426070690155, "clean_vbench": {}, "adv_vid_id": "vids/5185fcb0.mp4", "adv_score": 1.0, "adv_xclip": 0.16305193305015564, "adv_vbench": {}}}}
{"id": "de6861b1ff9646858e3fb1984bd04cd9", "source": "vatex", "video_id": "O9kGwMsJm7I_000170_000180", "video_description": "A woman is demonstrating how to fold a red cloth napkin into various intricate designs on a table.", "task": "ActionRecognition", "clean_prompt": "A person folding a red cloth napkin into various intricate designs on a table.", "clean_property": {"obj": "person", "action": "folding napkins", "target": "napkin"}, "target_prompt": "A person throwing napkins in a dining room.", "target_property": {"obj": "person", "action": "throwing napkins", "target": "napkin"}, "evaluation_question": "Is the person **folding** napkins?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person folding a red cloth napkin into various intricate designs on a table. ;2XBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18b2649df65543c7835be36571ae5ab6.mp4", "clean_score": 1.0, "clean_xclip": 0.23167532682418823, "clean_vbench": {"subject_consistency": 0.8884806397060553, "background_consistency": 0.93475341796875, "motion_smoothness": 0.9518183464518781, "aesthetic_quality": 0.38204970955848694, "imaging_quality": 0.7004700337624064, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dcd1ed7f47394e23baa35dc0502c9dfe.mp4", "adv_score": 0.0, "adv_xclip": 0.16213971376419067, "adv_vbench": {"subject_consistency": 0.8648985667775074, "background_consistency": 0.9329020182291666, "motion_smoothness": 0.9362211897908598, "aesthetic_quality": 0.3943157196044922, "imaging_quality": 0.7109904184146804, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5c9232c0.mp4", "clean_score": 1.0, "clean_xclip": 0.26380646228790283, "clean_vbench": {}, "adv_vid_id": "vids/c6d8c2a6.mp4", "adv_score": 1.0, "adv_xclip": 0.28100520372390747, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cb2425ab.mp4", "clean_score": 0.0, "clean_xclip": 0.24653677642345428, "clean_vbench": {}, "adv_vid_id": "vids/7e36526c.mp4", "adv_score": 1.0, "adv_xclip": 0.2679216265678406, "adv_vbench": {}}}}
{"id": "232a615dbb79440dafa0ca0897c5c945", "source": "vatex", "video_id": "RcqKQXQ6wJI_000046_000056", "video_description": "A man is playing the bagpipes while walking down a hallway in a school building, with people watching from the sides.", "task": "ActionRecognition", "clean_prompt": "A person playing bagpipes while walking down a hallway in a school building.", "clean_property": {"obj": "person", "action": "playing bagpipes", "target": null}, "target_prompt": "A person playing drums while walking down a hallway in a school building.", "target_property": {"obj": "person", "action": "playing drums", "target": null}, "evaluation_question": "Is the person **playing bagpipes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing bagpipes while walking down a hallway in a school building. UF$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5cbd3ce1c2f847ca984aedd99a2d8c9c.mp4", "clean_score": 1.0, "clean_xclip": 0.24869795143604279, "clean_vbench": {"subject_consistency": 0.9415849937746922, "background_consistency": 0.9061482747395834, "motion_smoothness": 0.9652668211767732, "aesthetic_quality": 0.4571734666824341, "imaging_quality": 0.5392331929109535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/24447e5353104a3d94b78a406f1f8949.mp4", "adv_score": 0.0, "adv_xclip": 0.24359533190727234, "adv_vbench": {"subject_consistency": 0.9224854030956825, "background_consistency": 0.8943990071614584, "motion_smoothness": 0.9485936918459513, "aesthetic_quality": 0.5424989461898804, "imaging_quality": 0.5224053596963688, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5465c8ab.mp4", "clean_score": 1.0, "clean_xclip": 0.24886195361614227, "clean_vbench": {}, "adv_vid_id": "vids/4c318d78.mp4", "adv_score": 0.0, "adv_xclip": 0.24400363862514496, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9ec02a81.mp4", "clean_score": 0.0, "clean_xclip": 0.25108811259269714, "clean_vbench": {}, "adv_vid_id": "vids/0fce4dac.mp4", "adv_score": 1.0, "adv_xclip": 0.2586957514286041, "adv_vbench": {}}}}
{"id": "dffbfbb25b754b97b0961aa4ee0ae631", "source": "vatex", "video_id": "J3OG-RLowJc_000024_000034", "video_description": "A group of young people are competing in a dodgeball tournament in an indoor gym. The game starts with players running to the center of the court to grab balls.", "task": "AttributeRecognition", "clean_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym.", "clean_property": {"obj": "player", "attribute": "student"}, "target_prompt": "A player who is a professional competing in a dodgeball tournament in an indoor gym.", "target_property": {"obj": "player", "attribute": "professional"}, "evaluation_question": "Is the player a **student**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym. ?!3)R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f0740b5aa5874a2b8f7b265e5e3d236a.mp4", "clean_score": 1.0, "clean_xclip": 0.15062636137008667, "clean_vbench": {"subject_consistency": 0.9244303411493698, "background_consistency": 0.9112396240234375, "motion_smoothness": 0.9640421178727406, "aesthetic_quality": 0.45633548498153687, "imaging_quality": 0.5290387967168069, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7f14c68de9594b6cbc6d71bb9290085a.mp4", "adv_score": 0.0, "adv_xclip": 0.168485626578331, "adv_vbench": {"subject_consistency": 0.9330985577156147, "background_consistency": 0.8915913899739584, "motion_smoothness": 0.9671839204528262, "aesthetic_quality": 0.48345255851745605, "imaging_quality": 0.5883766773768834, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f1c8c07e.mp4", "clean_score": 0.0, "clean_xclip": 0.10478010773658752, "clean_vbench": {}, "adv_vid_id": "vids/0eed2ce6.mp4", "adv_score": 1.0, "adv_xclip": 0.1474865972995758, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/20bd86fa.mp4", "clean_score": 1.0, "clean_xclip": 0.1690487563610077, "clean_vbench": {}, "adv_vid_id": "vids/5575d7fa.mp4", "adv_score": 1.0, "adv_xclip": 0.18430298566818237, "adv_vbench": {}}}}
{"id": "10d3f5512bf1403a8466c883500bb674", "source": "vatex", "video_id": "oRrwzU5iADM_000025_000035", "video_description": "A young man opens a refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "task": "Counting", "clean_prompt": "A young man opens two refrigerator doors in a living room, and then disappears as the doors close by themselves, creating a magical effect.", "clean_property": {"obj": "refrigerator", "count": "two"}, "target_prompt": "A young man opens one refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "target_property": {"obj": "refrigerator", "count": "one"}, "evaluation_question": "Are there exactly **two** refrigerators in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man opens two refrigerator doors in a living room, and then disappears as the doors close by themselves, creating a magical effect.99% confortmpf terrasse Lauf", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8401c077e8884293a9e94dce804a0780.mp4", "clean_score": 1.0, "clean_xclip": 0.11299772560596466, "clean_vbench": {"subject_consistency": 0.989084787045916, "background_consistency": 0.9661661783854166, "motion_smoothness": 0.9958361814633261, "aesthetic_quality": 0.3942537009716034, "imaging_quality": 0.7224715657136878, "dynamic_degree": 0.0}, "adv_vid_id": "vids/45d4e00ea20a49abac28e7afd73746bd.mp4", "adv_score": 0.0, "adv_xclip": 0.16498184204101562, "adv_vbench": {"subject_consistency": 0.9782136293749014, "background_consistency": 0.9699198404947916, "motion_smoothness": 0.9933325083023179, "aesthetic_quality": 0.4478525221347809, "imaging_quality": 0.7506120401499223, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/14a7d776.mp4", "clean_score": 1.0, "clean_xclip": 0.1906706541776657, "clean_vbench": {}, "adv_vid_id": "vids/96fe4348.mp4", "adv_score": 1.0, "adv_xclip": 0.17526359856128693, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/007e492e.mp4", "clean_score": 1.0, "clean_xclip": 0.2013411968946457, "clean_vbench": {}, "adv_vid_id": "vids/f7909391.mp4", "adv_score": 0.0, "adv_xclip": 0.20469114184379578, "adv_vbench": {}}}}
{"id": "f4cb9540213b497dbd1d53c75ddb12e7", "source": "vatex", "video_id": "x9FExBs3FiM_000043_000053", "video_description": "A high jump competition featuring several girls participating in the event, with a man narrating the highlights.", "task": "ActionRecognition", "clean_prompt": "A girl performing a high jump over a bar in a competition.", "clean_property": {"obj": "girl", "action": "high jump", "target": "bar"}, "target_prompt": "A girl performing a long jump into a sand pit.", "target_property": {"obj": "girl", "action": "long jump", "target": "sand pit"}, "evaluation_question": "Is the girl **performing a high jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing a high jump over a bar in a competition. Z-SL(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd76c92c5d7048a8b0964e0de866db49.mp4", "clean_score": 1.0, "clean_xclip": 0.11303091049194336, "clean_vbench": {"subject_consistency": 0.8302176352590322, "background_consistency": 0.8886871337890625, "motion_smoothness": 0.957043034784001, "aesthetic_quality": 0.4030410051345825, "imaging_quality": 0.37664843267324016, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1aa5dd7d3e484487a3d6aca640eb6134.mp4", "adv_score": 0.0, "adv_xclip": 0.09136687964200974, "adv_vbench": {"subject_consistency": 0.8793498910963535, "background_consistency": 0.9067230224609375, "motion_smoothness": 0.97688506522079, "aesthetic_quality": 0.39089396595954895, "imaging_quality": 0.3255015567857392, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bcc2a349.mp4", "clean_score": 1.0, "clean_xclip": 0.1846003532409668, "clean_vbench": {}, "adv_vid_id": "vids/36f3b280.mp4", "adv_score": 1.0, "adv_xclip": 0.1426001489162445, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d7026ca3.mp4", "clean_score": 0.0, "clean_xclip": 0.13744443655014038, "clean_vbench": {}, "adv_vid_id": "vids/26d6dd3d.mp4", "adv_score": 1.0, "adv_xclip": 0.17410047352313995, "adv_vbench": {}}}}
{"id": "2716f45f26cb47b0bb6b3927eb691995", "source": "vatex", "video_id": "pWOJhO1o-Ek_000012_000022", "video_description": "A group of young boys and girls perform a dance routine on a stage with black curtains, to the song 'When You Wish Upon a Star', in front of an audience.", "task": "ObjectRecognition", "clean_prompt": "A group of young boys and girls perform a dance routine on a stage with black curtains, in front of an audience.", "clean_property": {"obj": "audience"}, "target_prompt": "A group of performers showcasing a dance routine on a stage with black curtains.", "target_property": {"obj": "performers"}, "evaluation_question": "Is there an **audience** present in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young boys and girls perform a dance routine on a stage with black curtains, in front of an audience. >N1%\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/99824287a347445393f6bcb07274ab23.mp4", "clean_score": 1.0, "clean_xclip": 0.12893840670585632, "clean_vbench": {"subject_consistency": 0.9360984731465578, "background_consistency": 0.8941752115885416, "motion_smoothness": 0.9513571065193053, "aesthetic_quality": 0.5463026165962219, "imaging_quality": 0.39436241227753305, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5ae240507bb644dda2d32e8f757eaa36.mp4", "adv_score": 0.0, "adv_xclip": 0.12766660749912262, "adv_vbench": {"subject_consistency": 0.9248589451114336, "background_consistency": 0.9069366455078125, "motion_smoothness": 0.938261926307946, "aesthetic_quality": 0.548217236995697, "imaging_quality": 0.3602412710384447, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0d5bf865.mp4", "clean_score": 0.0, "clean_xclip": 0.16585154831409454, "clean_vbench": {}, "adv_vid_id": "vids/c8fc7f68.mp4", "adv_score": 0.0, "adv_xclip": 0.1646835058927536, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/906cf5ab.mp4", "clean_score": 1.0, "clean_xclip": 0.15087950229644775, "clean_vbench": {}, "adv_vid_id": "vids/38c78891.mp4", "adv_score": 1.0, "adv_xclip": 0.15883196890354156, "adv_vbench": {}}}}
{"id": "208bd3f82c5c4c7abe16cfa7d5440412", "source": "vatex", "video_id": "X2Qn08i-I48_000062_000072", "video_description": "A man is playing a song on a trumpet in a dimly lit room.", "task": "ActionRecognition", "clean_prompt": "A person playing trumpet in a dimly lit room.", "clean_property": {"obj": "person", "action": "playing trumpet", "target": null}, "target_prompt": "A person playing guitar in a dimly lit room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing trumpet in a dimly lit room.liegenden Adidas chaussure reduziertconsiderare", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd442f681b7646fdaa96b92cf623267e.mp4", "clean_score": 1.0, "clean_xclip": 0.27415668964385986, "clean_vbench": {"subject_consistency": 0.7346095247194171, "background_consistency": 0.901885986328125, "motion_smoothness": 0.993740349579904, "aesthetic_quality": 0.36693236231803894, "imaging_quality": 0.2035053081901706, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3b66c17a726241db8b96113c3c7216b0.mp4", "adv_score": 0.0, "adv_xclip": 0.15962255001068115, "adv_vbench": {"subject_consistency": 1.0, "background_consistency": 1.0, "motion_smoothness": 1.0, "aesthetic_quality": 0.33590564131736755, "imaging_quality": 0.20485637664794923, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f8fa0088.mp4", "clean_score": 1.0, "clean_xclip": 0.24198171496391296, "clean_vbench": {}, "adv_vid_id": "vids/7c7ff4e9.mp4", "adv_score": 0.0, "adv_xclip": 0.19387780129909515, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d6434b78.mp4", "clean_score": 1.0, "clean_xclip": 0.24488240480422974, "clean_vbench": {}, "adv_vid_id": "vids/f120cf1d.mp4", "adv_score": 1.0, "adv_xclip": 0.2390754222869873, "adv_vbench": {}}}}
{"id": "cdf45d6c7dd148fe8f91f1f313582846", "source": "vatex", "video_id": "Grs48iK3Tik_000032_000042", "video_description": "A man is in a large tile store displaying various types of tiles and discussing installation methods.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a tile in a large tile store.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "tile"}, "target_prompt": "A person further from the camera than a tile in a large tile store.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "tile"}, "evaluation_question": "Is the person **closer to the camera than** a tile?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a tile in a large tile store. !0D|B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e277e2116822467f90c2b2926ed8cc3c.mp4", "clean_score": 1.0, "clean_xclip": 0.11896316707134247, "clean_vbench": {"subject_consistency": 0.9923207766065995, "background_consistency": 0.9824371337890625, "motion_smoothness": 0.9965727245534274, "aesthetic_quality": 0.3195842206478119, "imaging_quality": 0.29529034750802174, "dynamic_degree": 0.0}, "adv_vid_id": "vids/3c0c0dc8d4084a84a603c36731436b62.mp4", "adv_score": 0.0, "adv_xclip": 0.17455071210861206, "adv_vbench": {"subject_consistency": 0.9535894114524126, "background_consistency": 0.9692433675130209, "motion_smoothness": 0.9827987750141208, "aesthetic_quality": 0.4216683804988861, "imaging_quality": 0.5891507331692443, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b67dd956.mp4", "clean_score": 1.0, "clean_xclip": 0.12637735903263092, "clean_vbench": {}, "adv_vid_id": "vids/3ca37c00.mp4", "adv_score": 1.0, "adv_xclip": 0.18128840625286102, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bc8ceb16.mp4", "clean_score": 1.0, "clean_xclip": 0.18737336993217468, "clean_vbench": {}, "adv_vid_id": "vids/df743c92.mp4", "adv_score": 0.0, "adv_xclip": 0.18445083498954773, "adv_vbench": {}}}}
{"id": "5d1c627c87e9452b92a2cde1d31ec735", "source": "vatex", "video_id": "Pd4-fmq61kw_000014_000024", "video_description": "A boy is seated on a couch, tearing pages from a composition notebook.", "task": "SpatialUnderstanding", "clean_prompt": "A composition notebook to the right of a boy seated on a couch.", "clean_property": {"obj_1": "composition notebook", "relation": "right of", "obj_2": "boy"}, "target_prompt": "A composition notebook to the left of a boy seated on a couch.", "target_property": {"obj_1": "composition notebook", "relation": "left of", "obj_2": "boy"}, "evaluation_question": "Is the composition notebook to the **right** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A composition notebook to the right of a boy seated on a couch. ))?':", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/093e3421999a4aa0aad8e4bccf82b53a.mp4", "clean_score": 1.0, "clean_xclip": 0.22837811708450317, "clean_vbench": {"subject_consistency": 0.991786099349459, "background_consistency": 0.9884897867838541, "motion_smoothness": 0.9967067381157709, "aesthetic_quality": 0.4650883078575134, "imaging_quality": 0.7692167943837691, "dynamic_degree": 0.0}, "adv_vid_id": "vids/2e5174ead63d4dad8ead8dfbc90840a0.mp4", "adv_score": 0.0, "adv_xclip": 0.21301178634166718, "adv_vbench": {"subject_consistency": 0.9905614921202263, "background_consistency": 0.97637939453125, "motion_smoothness": 0.9927512505484447, "aesthetic_quality": 0.3913090229034424, "imaging_quality": 0.7076201201458366, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/482f2d88.mp4", "clean_score": 0.0, "clean_xclip": 0.1745767593383789, "clean_vbench": {}, "adv_vid_id": "vids/fe890043.mp4", "adv_score": 0.0, "adv_xclip": 0.09647536277770996, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/db5f6b21.mp4", "clean_score": 0.0, "clean_xclip": 0.14390721917152405, "clean_vbench": {}, "adv_vid_id": "vids/49ea24b0.mp4", "adv_score": 0.0, "adv_xclip": 0.20599450170993805, "adv_vbench": {}}}}
{"id": "7c79e530568d4703b605c871e419d405", "source": "vatex", "video_id": "V7r_lGdJiko_000014_000024", "video_description": "A person in protective gear is welding metal on a scaffolding with decorations, creating sparks.", "task": "SpatialUnderstanding", "clean_prompt": "A welding torch to the left of a piece of metal as a person in protective gear welds on scaffolding, creating sparks.", "clean_property": {"obj_1": "welding torch", "relation": "left of", "obj_2": "metal"}, "target_prompt": "A welding torch to the right of a piece of metal as a person in protective gear welds on scaffolding, creating sparks.", "target_property": {"obj_1": "welding torch", "relation": "right of", "obj_2": "metal"}, "evaluation_question": "Is the welding torch to the **left** of the metal?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A welding torch to the left of a piece of metal as a person in protective gear welds on scaffolding, creating sparks. braid hommes Weiterbildungkulturvollen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0729336038804d4eaa9c70e3af40a3a6.mp4", "clean_score": 1.0, "clean_xclip": 0.24245575070381165, "clean_vbench": {"subject_consistency": 0.8843635575224956, "background_consistency": 0.9543863932291666, "motion_smoothness": 0.9482981967832144, "aesthetic_quality": 0.45256054401397705, "imaging_quality": 0.39953817134000813, "dynamic_degree": 1.0}, "adv_vid_id": "vids/db306c82ecaa4cccbf25afe6cdccc773.mp4", "adv_score": 0.0, "adv_xclip": 0.24920156598091125, "adv_vbench": {"subject_consistency": 0.8660459940632185, "background_consistency": 0.9535573323567709, "motion_smoothness": 0.9465270462029977, "aesthetic_quality": 0.47531262040138245, "imaging_quality": 0.4257812344298071, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/068e5dd0.mp4", "clean_score": 0.0, "clean_xclip": 0.23499339818954468, "clean_vbench": {}, "adv_vid_id": "vids/b16b7a9f.mp4", "adv_score": 0.0, "adv_xclip": 0.22104355692863464, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7873c6d3.mp4", "clean_score": 0.0, "clean_xclip": 0.23969796299934387, "clean_vbench": {}, "adv_vid_id": "vids/ea735bb0.mp4", "adv_score": 0.0, "adv_xclip": 0.23070059716701508, "adv_vbench": {}}}}
{"id": "6eb5980a526d4cddb3510cec80921c1a", "source": "vatex", "video_id": "bFxACj0QkTE_000014_000024", "video_description": "A man is using a spray gun to paint the ceiling of a large room.", "task": "SpatialUnderstanding", "clean_prompt": "A spray gun closer to the camera than a person painting the ceiling of a large room.", "clean_property": {"obj_1": "spray gun", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A spray gun further from the camera than a person painting the ceiling of a large room.", "target_property": {"obj_1": "spray gun", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the spray gun **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A spray gun closer to the camera than a person painting the ceiling of a large room. nascut aceasta 1901 Leicht aproape", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/986ae53a9f91404cb3d161e04e41889f.mp4", "clean_score": 1.0, "clean_xclip": 0.2296774983406067, "clean_vbench": {"subject_consistency": 0.8279398245116075, "background_consistency": 0.9410298665364584, "motion_smoothness": 0.9919352308889091, "aesthetic_quality": 0.2800207734107971, "imaging_quality": 0.4188166170704122, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7b92843aae674d2aa09df684bb114d2c.mp4", "adv_score": 0.0, "adv_xclip": 0.24825993180274963, "adv_vbench": {"subject_consistency": 0.9067664003620545, "background_consistency": 0.9382731119791666, "motion_smoothness": 0.9948075993000081, "aesthetic_quality": 0.27943846583366394, "imaging_quality": 0.42580760761183134, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d7641707.mp4", "clean_score": 1.0, "clean_xclip": 0.18976694345474243, "clean_vbench": {}, "adv_vid_id": "vids/42a0f8b6.mp4", "adv_score": 1.0, "adv_xclip": 0.20129181444644928, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/56d02c64.mp4", "clean_score": 1.0, "clean_xclip": 0.24091529846191406, "clean_vbench": {}, "adv_vid_id": "vids/da023622.mp4", "adv_score": 1.0, "adv_xclip": 0.188045933842659, "adv_vbench": {}}}}
{"id": "9631de2592fc4f2a8e940acdf1cca015", "source": "vatex", "video_id": "1u9OGTJcMEw_000011_000021", "video_description": "A group of people are watching a polo match on a green field with horses and players. An announcer is speaking through a loudspeaker, and some spectators are taking pictures and filming the event.", "task": "ActionRecognition", "clean_prompt": "A polo player playing polo on a green field.", "clean_property": {"obj": "polo player", "action": "playing polo", "target": null}, "target_prompt": "A polo player watching polo on a green field.", "target_property": {"obj": "polo player", "action": "watching polo", "target": null}, "evaluation_question": "Is the polo player **playing** polo?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A polo player playing polo on a green field. >7-(L", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/68720cafcf6c4e01bbcd55f1f40f1b12.mp4", "clean_score": 1.0, "clean_xclip": 0.18352100253105164, "clean_vbench": {"subject_consistency": 0.9420317684610685, "background_consistency": 0.9300893147786459, "motion_smoothness": 0.9721959573953038, "aesthetic_quality": 0.4928309917449951, "imaging_quality": 0.6381733664687799, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b05995271d7a411d934d83c50dbc237e.mp4", "adv_score": 0.0, "adv_xclip": 0.1678338646888733, "adv_vbench": {"subject_consistency": 0.8966105127086242, "background_consistency": 0.8928476969401041, "motion_smoothness": 0.9715236497859174, "aesthetic_quality": 0.47390949726104736, "imaging_quality": 0.6871631217489437, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e03915f5.mp4", "clean_score": 1.0, "clean_xclip": 0.1824851632118225, "clean_vbench": {}, "adv_vid_id": "vids/95a23fed.mp4", "adv_score": 1.0, "adv_xclip": 0.1794915497303009, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/38d24c09.mp4", "clean_score": 0.0, "clean_xclip": 0.194355309009552, "clean_vbench": {}, "adv_vid_id": "vids/c6534b8f.mp4", "adv_score": 0.0, "adv_xclip": 0.1641729772090912, "adv_vbench": {}}}}
{"id": "e2f6678de7ca4c63bad01fe0936bfff5", "source": "vatex", "video_id": "Z0WYFjwIpwU_000000_000010", "video_description": "A woman is applying and removing wax strips to a man's leg for hair removal while they talk.", "task": "SpatialUnderstanding", "clean_prompt": "A man sitting to the left of a woman while she applies wax strips to his leg.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "woman"}, "target_prompt": "A man sitting to the right of a woman while she applies wax strips to his leg.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "woman"}, "evaluation_question": "Is the man sitting to the **left** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man sitting to the left of a woman while she applies wax strips to his leg. Maschinen personnage PicassoObjekt Kurz", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a86881ed0bd43288aa2d4d054392392.mp4", "clean_score": 1.0, "clean_xclip": 0.18752454221248627, "clean_vbench": {"subject_consistency": 0.9707467599461476, "background_consistency": 0.9628499348958334, "motion_smoothness": 0.9827812077634551, "aesthetic_quality": 0.49287256598472595, "imaging_quality": 0.7496151702258053, "dynamic_degree": 1.0}, "adv_vid_id": "vids/58c51b8bd7fb440bb5be6d3e7284b434.mp4", "adv_score": 0.0, "adv_xclip": 0.20603522658348083, "adv_vbench": {"subject_consistency": 0.9557370208203793, "background_consistency": 0.9457600911458334, "motion_smoothness": 0.9754949104963487, "aesthetic_quality": 0.4557187557220459, "imaging_quality": 0.6669980808180206, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/68a5018d.mp4", "clean_score": 1.0, "clean_xclip": 0.1803048849105835, "clean_vbench": {}, "adv_vid_id": "vids/ee9325e0.mp4", "adv_score": 0.0, "adv_xclip": 0.1871894896030426, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6a250998.mp4", "clean_score": 1.0, "clean_xclip": 0.19891683757305145, "clean_vbench": {}, "adv_vid_id": "vids/0ee086d9.mp4", "adv_score": 1.0, "adv_xclip": 0.20792804658412933, "adv_vbench": {}}}}
{"id": "dd2c3c81ff9d4a09a5e8358aa219b1bb", "source": "vatex", "video_id": "9TjkUylMBgQ_000134_000144", "video_description": "A woman is training a small dog outdoors by throwing treats and rewarding it for good behavior.", "task": "Counting", "clean_prompt": "A woman is training a small dog outdoors by throwing three treats and rewarding it for good behavior.", "clean_property": {"obj": "treat", "count": "three"}, "target_prompt": "A woman is training a small dog outdoors by throwing one treat and rewarding it for good behavior.", "target_property": {"obj": "treat", "count": "one"}, "evaluation_question": "Are there exactly **three** treats being thrown?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman is training a small dog outdoors by throwing three treats and rewarding it for good behavior. O9/?%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cde608bc25334d49b3183941cb991b38.mp4", "clean_score": 1.0, "clean_xclip": 0.1822177767753601, "clean_vbench": {"subject_consistency": 0.9186237510293722, "background_consistency": 0.9293467203776041, "motion_smoothness": 0.9766727451043432, "aesthetic_quality": 0.4962378442287445, "imaging_quality": 0.6390119023225745, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e197b20813b84daa8c3b506b0682bab5.mp4", "adv_score": 0.0, "adv_xclip": 0.20075169205665588, "adv_vbench": {"subject_consistency": 0.9304307606071234, "background_consistency": 0.931243896484375, "motion_smoothness": 0.9774853822155148, "aesthetic_quality": 0.4926164448261261, "imaging_quality": 0.6567291251980528, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ec231f98.mp4", "clean_score": 0.0, "clean_xclip": 0.16096729040145874, "clean_vbench": {}, "adv_vid_id": "vids/8bf7c27e.mp4", "adv_score": 0.0, "adv_xclip": 0.18019406497478485, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/465a8525.mp4", "clean_score": 0.0, "clean_xclip": 0.1515159159898758, "clean_vbench": {}, "adv_vid_id": "vids/6eeaf76f.mp4", "adv_score": 0.0, "adv_xclip": 0.18006327748298645, "adv_vbench": {}}}}
{"id": "3d1bf5b3fc9f4cc687057d87b40e6837", "source": "vatex", "video_id": "atLO_DGRq4M_000051_000061", "video_description": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "task": "SpatialUnderstanding", "clean_prompt": "A cutting board is placed to the left of a pineapple as a woman demonstrates how to peel and slice it.", "clean_property": {"obj_1": "cutting board", "relation": "left of", "obj_2": "pineapple"}, "target_prompt": "A cutting board is placed to the right of a pineapple as a woman demonstrates how to peel and slice it.", "target_property": {"obj_1": "cutting board", "relation": "right of", "obj_2": "pineapple"}, "evaluation_question": "Is the cutting board to the **left** of the pineapple?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A cutting board is placed to the left of a pineapple as a woman demonstrates how to peel and slice it. meilleurabordschmutzgebucht Bangkok", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef0daeceb0fc4a069690f278da8fca57.mp4", "clean_score": 1.0, "clean_xclip": 0.2783818542957306, "clean_vbench": {"subject_consistency": 0.9687135467926661, "background_consistency": 0.9772135416666666, "motion_smoothness": 0.9629411485755568, "aesthetic_quality": 0.5668799877166748, "imaging_quality": 0.7583734395552655, "dynamic_degree": 1.0}, "adv_vid_id": "vids/29c8e7d6c25e41f4838352abdbf4cbe2.mp4", "adv_score": 0.0, "adv_xclip": 0.2806813716888428, "adv_vbench": {"subject_consistency": 0.9692558068782091, "background_consistency": 0.9687601725260416, "motion_smoothness": 0.9625581428591241, "aesthetic_quality": 0.5869698524475098, "imaging_quality": 0.7626691374486806, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c7cb5dd4.mp4", "clean_score": 1.0, "clean_xclip": 0.2633684277534485, "clean_vbench": {}, "adv_vid_id": "vids/c981f922.mp4", "adv_score": 0.0, "adv_xclip": 0.2675471305847168, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/70c9c06c.mp4", "clean_score": 0.0, "clean_xclip": 0.2889986038208008, "clean_vbench": {}, "adv_vid_id": "vids/84310362.mp4", "adv_score": 0.0, "adv_xclip": 0.27887821197509766, "adv_vbench": {}}}}
{"id": "5488cf1d33344737ac0100d5b80e507b", "source": "vatex", "video_id": "B5K_x2cDYfM_000026_000036", "video_description": "A woman wearing headphones and a cocktail dress plays the clarinet in front of a changing background, including a sky with moving clouds.", "task": "ActionRecognition", "clean_prompt": "A person playing clarinet in front of a changing background.", "clean_property": {"obj": "person", "action": "playing clarinet", "target": null}, "target_prompt": "A person playing guitar in front of a changing background.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing clarinet**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing clarinet in front of a changing background. StanfordprosecutorsCoreyguten pavement", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb7cea31074a4cf69a8cdbaf9719fa9c.mp4", "clean_score": 1.0, "clean_xclip": 0.13771609961986542, "clean_vbench": {"subject_consistency": 0.9213975512733062, "background_consistency": 0.9442545572916666, "motion_smoothness": 0.9496206740637356, "aesthetic_quality": 0.3199043869972229, "imaging_quality": 0.3146473324055574, "dynamic_degree": 1.0}, "adv_vid_id": "vids/28acf74c908e43898ef043f90a7025c8.mp4", "adv_score": 0.0, "adv_xclip": 0.17412236332893372, "adv_vbench": {"subject_consistency": 0.8947218731045723, "background_consistency": 0.9276987711588541, "motion_smoothness": 0.9373024057809853, "aesthetic_quality": 0.410754919052124, "imaging_quality": 0.5991650445120675, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2a653abb.mp4", "clean_score": 0.0, "clean_xclip": 0.17424167692661285, "clean_vbench": {}, "adv_vid_id": "vids/2c795e94.mp4", "adv_score": 0.0, "adv_xclip": 0.17456069588661194, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/eb0c8b18.mp4", "clean_score": 0.0, "clean_xclip": 0.219765767455101, "clean_vbench": {}, "adv_vid_id": "vids/7a409986.mp4", "adv_score": 1.0, "adv_xclip": 0.19355610013008118, "adv_vbench": {}}}}
{"id": "47edc91eddef447ca1d188958c5a7db8", "source": "vatex", "video_id": "mrKntbg0ibw_000068_000078", "video_description": "A woman dives off a high diving board into a swimming pool, followed by a young boy who is waiting to jump.", "task": "ActionRecognition", "clean_prompt": "A woman springboard diving into a swimming pool.", "clean_property": {"obj": "woman", "action": "springboard diving", "target": null}, "target_prompt": "A woman swimming in a swimming pool.", "target_property": {"obj": "woman", "action": "swimming", "target": null}, "evaluation_question": "Is the woman **springboard diving**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman springboard diving into a swimming pool. tolle couleursannon foto Motiv", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46d78b1c164741f7a867ad6523fec8d7.mp4", "clean_score": 1.0, "clean_xclip": 0.21464753150939941, "clean_vbench": {"subject_consistency": 0.7731653895849983, "background_consistency": 0.8681844075520834, "motion_smoothness": 0.9812133966755426, "aesthetic_quality": 0.4115715026855469, "imaging_quality": 0.5650198749620088, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6e5ee523e46a4210a5ce203dddde6eec.mp4", "adv_score": 0.0, "adv_xclip": 0.18005433678627014, "adv_vbench": {"subject_consistency": 0.8315452001988888, "background_consistency": 0.8870697021484375, "motion_smoothness": 0.9802093786878178, "aesthetic_quality": 0.45972302556037903, "imaging_quality": 0.5949845232282366, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/44b64889.mp4", "clean_score": 0.0, "clean_xclip": 0.1656508445739746, "clean_vbench": {}, "adv_vid_id": "vids/32356bce.mp4", "adv_score": 0.0, "adv_xclip": 0.1486765295267105, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3e2ab18a.mp4", "clean_score": 0.0, "clean_xclip": 0.18209581077098846, "clean_vbench": {}, "adv_vid_id": "vids/5498d8b1.mp4", "adv_score": 1.0, "adv_xclip": 0.16681867837905884, "adv_vbench": {}}}}
{"id": "ccb270991fb94176bb581f4ca6d8bc30", "source": "vatex", "video_id": "SAISuCs1IiI_000017_000027", "video_description": "A large, muscular man is working out his arms using various machines in a gym. He is wearing black clothing and a gray shirt at different times, performing exercises like triceps extensions and pull downs.", "task": "SpatialUnderstanding", "clean_prompt": "A weight machine farther from the camera than a person in a gym.", "clean_property": {"obj_1": "weight machine", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A weight machine closer to the camera than a person in a gym.", "target_property": {"obj_1": "weight machine", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the weight machine **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A weight machine farther from the camera than a person in a gym. 'LPO7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d25c733c29034841aff36bda78195051.mp4", "clean_score": 1.0, "clean_xclip": 0.18192945420742035, "clean_vbench": {"subject_consistency": 0.9146366392572721, "background_consistency": 0.955718994140625, "motion_smoothness": 0.9755966947382091, "aesthetic_quality": 0.3743019104003906, "imaging_quality": 0.3401361177405533, "dynamic_degree": 1.0}, "adv_vid_id": "vids/17aeb42cc87848bc90cb3fa93e49f8be.mp4", "adv_score": 0.0, "adv_xclip": 0.17735770344734192, "adv_vbench": {"subject_consistency": 0.9327532307555279, "background_consistency": 0.9551137288411459, "motion_smoothness": 0.9933863409850823, "aesthetic_quality": 0.4301566183567047, "imaging_quality": 0.20835638785848812, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c26e37fd.mp4", "clean_score": 0.0, "clean_xclip": 0.11596348881721497, "clean_vbench": {}, "adv_vid_id": "vids/16afc15c.mp4", "adv_score": 0.0, "adv_xclip": 0.13291552662849426, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d17aa142.mp4", "clean_score": 0.0, "clean_xclip": 0.1587309092283249, "clean_vbench": {}, "adv_vid_id": "vids/05c0f7b5.mp4", "adv_score": 0.0, "adv_xclip": 0.17392471432685852, "adv_vbench": {}}}}
{"id": "fec34603c1284644a3c820de066e9335", "source": "vatex", "video_id": "l6_2Ax9-3DQ_000063_000073", "video_description": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles.", "task": "Counting", "clean_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by seven people who are watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by three people who are watching her.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by seven people who are watching her. LFE-0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7609085146ec41c1aacd6dedfd9da79d.mp4", "clean_score": 1.0, "clean_xclip": 0.29078856110572815, "clean_vbench": {"subject_consistency": 0.9667165453235308, "background_consistency": 0.9526774088541666, "motion_smoothness": 0.9855047869134794, "aesthetic_quality": 0.6607445478439331, "imaging_quality": 0.6826652729267977, "dynamic_degree": 0.0}, "adv_vid_id": "vids/95f45f7541ee41038fde22da627d3325.mp4", "adv_score": 0.0, "adv_xclip": 0.2984471023082733, "adv_vbench": {"subject_consistency": 0.9484834509591261, "background_consistency": 0.9296417236328125, "motion_smoothness": 0.9779630543704106, "aesthetic_quality": 0.6934003829956055, "imaging_quality": 0.693921276793188, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/525b8e1a.mp4", "clean_score": 0.0, "clean_xclip": 0.2786302864551544, "clean_vbench": {}, "adv_vid_id": "vids/927d0d54.mp4", "adv_score": 0.0, "adv_xclip": 0.2852100133895874, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7b4f4fb2.mp4", "clean_score": 0.0, "clean_xclip": 0.2610519230365753, "clean_vbench": {}, "adv_vid_id": "vids/83166dce.mp4", "adv_score": 0.0, "adv_xclip": 0.2838051915168762, "adv_vbench": {}}}}
{"id": "36a4b85856354e0d805c760ddf3977a2", "source": "vatex", "video_id": "a1SASZM2epM_000015_000025", "video_description": "Two volleyball teams are playing a match in a gymnasium with a referee overseeing the game.", "task": "ActionRecognition", "clean_prompt": "A volleyball player playing volleyball in a gymnasium.", "clean_property": {"obj": "volleyball player", "action": "playing volleyball", "target": null}, "target_prompt": "A volleyball player sitting on the bench in a gymnasium.", "target_property": {"obj": "volleyball player", "action": "sitting on the bench", "target": null}, "evaluation_question": "Is the volleyball player **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A volleyball player playing volleyball in a gymnasium. )*E*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6aeb3278d0c142e1af0dac510e6616a7.mp4", "clean_score": 1.0, "clean_xclip": 0.2094712257385254, "clean_vbench": {"subject_consistency": 0.950873534505566, "background_consistency": 0.9037526448567709, "motion_smoothness": 0.9797943058203219, "aesthetic_quality": 0.4629461169242859, "imaging_quality": 0.6529624285016742, "dynamic_degree": 1.0}, "adv_vid_id": "vids/040f7b4e24ad414dae1916df72a10272.mp4", "adv_score": 0.0, "adv_xclip": 0.2034306526184082, "adv_vbench": {"subject_consistency": 0.9582609012722969, "background_consistency": 0.9233144124348959, "motion_smoothness": 0.9735055251074195, "aesthetic_quality": 0.484052449464798, "imaging_quality": 0.5680738900632274, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/21b41388.mp4", "clean_score": 1.0, "clean_xclip": 0.21837767958641052, "clean_vbench": {}, "adv_vid_id": "vids/063dc302.mp4", "adv_score": 1.0, "adv_xclip": 0.2285739779472351, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/11e9482e.mp4", "clean_score": 1.0, "clean_xclip": 0.1641213595867157, "clean_vbench": {}, "adv_vid_id": "vids/64e90cb4.mp4", "adv_score": 1.0, "adv_xclip": 0.16284696757793427, "adv_vbench": {}}}}
{"id": "6a2d530d39544232b4955a6796b3b6da", "source": "vatex", "video_id": "lHe6Ehd5S0Y_000001_000011", "video_description": "A young man with long hair is having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "task": "Counting", "clean_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people having a staring contest?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play. SL+)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11b15d6b44fc43478dbd82441b15b482.mp4", "clean_score": 1.0, "clean_xclip": 0.15607887506484985, "clean_vbench": {"subject_consistency": 0.9158669399718443, "background_consistency": 0.9352773030598959, "motion_smoothness": 0.9414777333033264, "aesthetic_quality": 0.3906383812427521, "imaging_quality": 0.5758094740887078, "dynamic_degree": 1.0}, "adv_vid_id": "vids/aa6e55cb4e9a4f52afe8b6623c4d226c.mp4", "adv_score": 0.0, "adv_xclip": 0.18959379196166992, "adv_vbench": {"subject_consistency": 0.8959191404283047, "background_consistency": 0.9296773274739584, "motion_smoothness": 0.947831563180828, "aesthetic_quality": 0.41164296865463257, "imaging_quality": 0.4718757271280094, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e101c8ad.mp4", "clean_score": 0.0, "clean_xclip": 0.13277389109134674, "clean_vbench": {}, "adv_vid_id": "vids/34b1fe64.mp4", "adv_score": 1.0, "adv_xclip": 0.14994998276233673, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ea87768b.mp4", "clean_score": 1.0, "clean_xclip": 0.1488438993692398, "clean_vbench": {}, "adv_vid_id": "vids/6461e1bf.mp4", "adv_score": 0.0, "adv_xclip": 0.15121693909168243, "adv_vbench": {}}}}
{"id": "df9eca8bbd024991ba820547e8c652ea", "source": "vatex", "video_id": "JFWsCM8WE-w_000000_000010", "video_description": "A man is splitting a log into smaller pieces using an axe, a wedge, and a sledgehammer, while a child laughs off-screen.", "task": "ActionRecognition", "clean_prompt": "A child laughing off-screen while a man splits a log.", "clean_property": {"obj": "child", "action": "laughing", "target": null}, "target_prompt": "A child crying off-screen while a man splits a log.", "target_property": {"obj": "child", "action": "crying", "target": null}, "evaluation_question": "Is the child **laughing** off-screen?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A child laughing off-screen while a man splits a log. vrei Ross consequential sollten Hinweis", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5bd15870357043a08dbe5e5082577f09.mp4", "clean_score": 1.0, "clean_xclip": 0.20962819457054138, "clean_vbench": {"subject_consistency": 0.8237661042561134, "background_consistency": 0.9094696044921875, "motion_smoothness": 0.9573780701870511, "aesthetic_quality": 0.47879207134246826, "imaging_quality": 0.5477486949064293, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7ece2d15672e4ab2ac7dd1d15eed95c5.mp4", "adv_score": 0.0, "adv_xclip": 0.2021801471710205, "adv_vbench": {"subject_consistency": 0.8583372477442026, "background_consistency": 0.9306538899739584, "motion_smoothness": 0.9650021064688736, "aesthetic_quality": 0.42514532804489136, "imaging_quality": 0.44870656577908263, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7d714901.mp4", "clean_score": 0.0, "clean_xclip": 0.2884165644645691, "clean_vbench": {}, "adv_vid_id": "vids/c7130675.mp4", "adv_score": 0.0, "adv_xclip": 0.2540936768054962, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e75fe519.mp4", "clean_score": 0.0, "clean_xclip": 0.29190793633461, "clean_vbench": {}, "adv_vid_id": "vids/0edf0fab.mp4", "adv_score": 0.0, "adv_xclip": 0.3347451090812683, "adv_vbench": {}}}}
{"id": "5c0bf0ab1bfa4dde9cc44622b17dd93d", "source": "vatex", "video_id": "-ORYjC-0F8I_000000_000010", "video_description": "A group of people are playing badminton in a gymnasium with multiple matches happening simultaneously.", "task": "ObjectRecognition", "clean_prompt": "A group of people are playing badminton in a gymnasium, with a shuttlecock flying back and forth.", "clean_property": {"obj": "shuttlecock"}, "target_prompt": "A group of people are playing frisbee in a gymnasium, with a frisbee flying back and forth.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Is the object being used in the game a **shuttlecock**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A group of people are playing badminton in a gymnasium, with a shuttlecock flying back and forth. FE/AI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1551064787f84d00869206c5f665f087.mp4", "clean_score": 1.0, "clean_xclip": 0.2233089953660965, "clean_vbench": {"subject_consistency": 0.92900067816178, "background_consistency": 0.9035847981770834, "motion_smoothness": 0.9795797348742739, "aesthetic_quality": 0.44148892164230347, "imaging_quality": 0.5238746666421696, "dynamic_degree": 1.0}, "adv_vid_id": "vids/823ec4b6c30b43d8819c0d5fdf39b5f9.mp4", "adv_score": 0.0, "adv_xclip": 0.22662580013275146, "adv_vbench": {"subject_consistency": 0.9236314588536819, "background_consistency": 0.9128061930338541, "motion_smoothness": 0.9857482815399822, "aesthetic_quality": 0.4017714262008667, "imaging_quality": 0.42307844823720503, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/60eea74b.mp4", "clean_score": 0.0, "clean_xclip": 0.20917615294456482, "clean_vbench": {}, "adv_vid_id": "vids/4d1f0b56.mp4", "adv_score": 1.0, "adv_xclip": 0.19193030893802643, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/594ad2ca.mp4", "clean_score": 1.0, "clean_xclip": 0.22181366384029388, "clean_vbench": {}, "adv_vid_id": "vids/36636374.mp4", "adv_score": 1.0, "adv_xclip": 0.23557807505130768, "adv_vbench": {}}}}
{"id": "cfbc09c4337a480fb7a0adfd4a14fd10", "source": "vatex", "video_id": "l3wfvnZ57lA_000299_000309", "video_description": "A group of chefs and servers are collaborating in a kitchen to create, bake, and serve pizzas. Some are showcasing specialty pizzas for a cooking show, while others are preparing and serving food.", "task": "Counting", "clean_prompt": "Three chefs collaborating in a kitchen to create and serve pizzas on a platter.", "clean_property": {"obj": "platter", "count": "three"}, "target_prompt": "One chef showcasing a single pizza on a platter.", "target_property": {"obj": "platter", "count": "one"}, "evaluation_question": "Are there exactly **three** platters being used in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three chefs collaborating in a kitchen to create and serve pizzas on a platter. %XS/J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6fef0d10c1354a04971b49bdbddfc16d.mp4", "clean_score": 1.0, "clean_xclip": 0.2183074653148651, "clean_vbench": {"subject_consistency": 0.980975546563665, "background_consistency": 0.9739888509114584, "motion_smoothness": 0.9706282033582466, "aesthetic_quality": 0.5923400521278381, "imaging_quality": 0.7441443571752431, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bfd35934540540b28fca07c481c2f4a3.mp4", "adv_score": 0.0, "adv_xclip": 0.22734345495700836, "adv_vbench": {"subject_consistency": 0.9692137824992338, "background_consistency": 0.9697214762369791, "motion_smoothness": 0.9718755574278323, "aesthetic_quality": 0.5558932423591614, "imaging_quality": 0.6910436669174506, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f0d0013.mp4", "clean_score": 0.0, "clean_xclip": 0.2199067771434784, "clean_vbench": {}, "adv_vid_id": "vids/700d030b.mp4", "adv_score": 0.0, "adv_xclip": 0.2207472026348114, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/396f76da.mp4", "clean_score": 0.0, "clean_xclip": 0.230942040681839, "clean_vbench": {}, "adv_vid_id": "vids/745a3ff7.mp4", "adv_score": 0.0, "adv_xclip": 0.23736004531383514, "adv_vbench": {}}}}
{"id": "421e29c15d10484fb57dad83750af63e", "source": "vatex", "video_id": "V77pj1em6yI_000087_000097", "video_description": "A woman and a child are playing kickball in a backyard, passing the ball back and forth.", "task": "ActionRecognition", "clean_prompt": "A woman playing kickball in a backyard.", "clean_property": {"obj": "woman", "action": "playing kickball", "target": "ball"}, "target_prompt": "A woman kicking a ball towards a goal in a backyard.", "target_property": {"obj": "woman", "action": "kicking a ball", "target": "goal"}, "evaluation_question": "Is the woman **playing kickball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman playing kickball in a backyard. FE4IT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/00768f1796ea4eabad7db67e1f4c88fb.mp4", "clean_score": 1.0, "clean_xclip": 0.15521740913391113, "clean_vbench": {"subject_consistency": 0.8835564473023018, "background_consistency": 0.9031728108723959, "motion_smoothness": 0.9599071959094853, "aesthetic_quality": 0.47513633966445923, "imaging_quality": 0.5382608273564553, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f0129d77064240f18521197f974b3b6c.mp4", "adv_score": 0.0, "adv_xclip": 0.18933148682117462, "adv_vbench": {"subject_consistency": 0.8839997053146362, "background_consistency": 0.8921661376953125, "motion_smoothness": 0.9457676859227487, "aesthetic_quality": 0.4878648817539215, "imaging_quality": 0.5685982295445033, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/286c0d0d.mp4", "clean_score": 1.0, "clean_xclip": 0.17591337859630585, "clean_vbench": {}, "adv_vid_id": "vids/8e1b8ed9.mp4", "adv_score": 1.0, "adv_xclip": 0.17159318923950195, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/40db61c3.mp4", "clean_score": 0.0, "clean_xclip": 0.16825339198112488, "clean_vbench": {}, "adv_vid_id": "vids/3e9ad11c.mp4", "adv_score": 0.0, "adv_xclip": 0.1984388530254364, "adv_vbench": {}}}}
{"id": "2fb65b2fbcc6442ab743fc153c0cb701", "source": "vatex", "video_id": "4d6Ch7lhz5w_000000_000010", "video_description": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "task": "ObjectRecognition", "clean_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "clean_property": {"obj": "hair dryer"}, "target_prompt": "A man is in a kitchen using a toaster to toast bread while singing and speaking.", "target_property": {"obj": "toaster"}, "evaluation_question": "Is the man using a **hair dryer** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking. !#XS0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e4e2acd143444c4a8a86d830d261751.mp4", "clean_score": 1.0, "clean_xclip": 0.15222717821598053, "clean_vbench": {"subject_consistency": 0.8826088986049095, "background_consistency": 0.9142913818359375, "motion_smoothness": 0.9605914466899156, "aesthetic_quality": 0.4550797641277313, "imaging_quality": 0.44367271656892737, "dynamic_degree": 1.0}, "adv_vid_id": "vids/94bab0daf4a542f5bc16bf2cba4f2414.mp4", "adv_score": 0.0, "adv_xclip": 0.21372239291667938, "adv_vbench": {"subject_consistency": 0.9149441762516896, "background_consistency": 0.8938090006510416, "motion_smoothness": 0.9531216721385056, "aesthetic_quality": 0.4520895779132843, "imaging_quality": 0.5255151624095683, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/804cff0f.mp4", "clean_score": 1.0, "clean_xclip": 0.2147790640592575, "clean_vbench": {}, "adv_vid_id": "vids/bc5775aa.mp4", "adv_score": 1.0, "adv_xclip": 0.1514977067708969, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/65fa3c67.mp4", "clean_score": 1.0, "clean_xclip": 0.2449650764465332, "clean_vbench": {}, "adv_vid_id": "vids/862ee03d.mp4", "adv_score": 1.0, "adv_xclip": 0.2774794101715088, "adv_vbench": {}}}}
{"id": "ab174f1eb90e42f6ba60130e86689fd3", "source": "vatex", "video_id": "oNxxDYNA52s_000085_000095", "video_description": "A group of young girls in cheerleading outfits perform a gymnastics routine, including cartwheels, on a mat in a gymnasium. They are rehearsing and performing in front of a large audience.", "task": "ActionRecognition", "clean_prompt": "A cheerleader cartwheeling on a mat in a gymnasium.", "clean_property": {"obj": "cheerleader", "action": "cartwheeling", "target": null}, "target_prompt": "A cheerleader backflipping on a mat in a gymnasium.", "target_property": {"obj": "cheerleader", "action": "backflipping", "target": null}, "evaluation_question": "Is the cheerleader **cartwheeling**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A cheerleader cartwheeling on a mat in a gymnasium. SL?JE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3682c80e31e493eb78ba38f41d6c218.mp4", "clean_score": 1.0, "clean_xclip": 0.17333732545375824, "clean_vbench": {"subject_consistency": 0.9171340515216192, "background_consistency": 0.913055419921875, "motion_smoothness": 0.9808757946143993, "aesthetic_quality": 0.40619853138923645, "imaging_quality": 0.4901870852100606, "dynamic_degree": 1.0}, "adv_vid_id": "vids/03791938be3d44729eb91ce5d78bfc08.mp4", "adv_score": 0.0, "adv_xclip": 0.20809045433998108, "adv_vbench": {"subject_consistency": 0.9036294215669235, "background_consistency": 0.9108835856119791, "motion_smoothness": 0.9742905388878803, "aesthetic_quality": 0.3721294403076172, "imaging_quality": 0.42374497277396067, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6286f83e.mp4", "clean_score": 0.0, "clean_xclip": 0.18921861052513123, "clean_vbench": {}, "adv_vid_id": "vids/23dc3f49.mp4", "adv_score": 0.0, "adv_xclip": 0.1377248466014862, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6e7bedec.mp4", "clean_score": 1.0, "clean_xclip": 0.1853766143321991, "clean_vbench": {}, "adv_vid_id": "vids/52b54172.mp4", "adv_score": 1.0, "adv_xclip": 0.19750013947486877, "adv_vbench": {}}}}
{"id": "f6d8f2cf3f374991b8b6f85325020ce5", "source": "vatex", "video_id": "16st7ZGa6Bg_000094_000104", "video_description": "A woman is demonstrating and discussing the features of a pottery jar she made, including how to add a lip to a clay pot.", "task": "Counting", "clean_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors.", "clean_property": {"obj": "razor", "count": "two"}, "target_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding one razor.", "target_property": {"obj": "razor", "count": "one"}, "evaluation_question": "Are there exactly **two** razors being held by the woman?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors. experientialObjektpraxis Gestalt begleiten", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/343c1e1b21244fc38ec2bc568af86fb1.mp4", "clean_score": 1.0, "clean_xclip": 0.22732773423194885, "clean_vbench": {"subject_consistency": 0.8773018786062797, "background_consistency": 0.9261016845703125, "motion_smoothness": 0.9765425347222222, "aesthetic_quality": 0.5117312669754028, "imaging_quality": 0.6686548139611069, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d3802c2cd70541a78bfcd48c84969b70.mp4", "adv_score": 0.0, "adv_xclip": 0.22671356797218323, "adv_vbench": {"subject_consistency": 0.9336384708682696, "background_consistency": 0.9514363606770834, "motion_smoothness": 0.9767885889148613, "aesthetic_quality": 0.5646033883094788, "imaging_quality": 0.6519502009177693, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/45a46863.mp4", "clean_score": 0.0, "clean_xclip": 0.2121446579694748, "clean_vbench": {}, "adv_vid_id": "vids/44883120.mp4", "adv_score": 0.0, "adv_xclip": 0.2167593240737915, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ad19e206.mp4", "clean_score": 1.0, "clean_xclip": 0.22366449236869812, "clean_vbench": {}, "adv_vid_id": "vids/f7006b6d.mp4", "adv_score": 0.0, "adv_xclip": 0.21553680300712585, "adv_vbench": {}}}}
{"id": "cc62705810ba45b2af637ce968736322", "source": "vatex", "video_id": "DNdZBDJL09E_000004_000014", "video_description": "A man wearing a breathing mask uses a sledgehammer to demolish a bathroom sink.", "task": "AttributeRecognition", "clean_prompt": "A person wearing a breathing mask using a sledgehammer to demolish a bathroom sink.", "clean_property": {"obj": "person", "attribute": "wearing breathing mask"}, "target_prompt": "A person using a sledgehammer to demolish a bathroom sink.", "target_property": {"obj": "person", "attribute": "wearing no mask"}, "evaluation_question": "Is the person wearing a **breathing** mask?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person wearing a breathing mask using a sledgehammer to demolish a bathroom sink. 8%BCQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f26ed790eaa4fb8a48831a747436570.mp4", "clean_score": 1.0, "clean_xclip": 0.22455833852291107, "clean_vbench": {"subject_consistency": 0.9801677670329809, "background_consistency": 0.9713694254557291, "motion_smoothness": 0.9900247364313525, "aesthetic_quality": 0.39085137844085693, "imaging_quality": 0.6703713055046238, "dynamic_degree": 1.0}, "adv_vid_id": "vids/14f324797aaa4092b16a04028c28e0c8.mp4", "adv_score": 0.0, "adv_xclip": 0.15523779392242432, "adv_vbench": {"subject_consistency": 0.9470380848894516, "background_consistency": 0.9607950846354166, "motion_smoothness": 0.9788373101877068, "aesthetic_quality": 0.363247275352478, "imaging_quality": 0.6435118391075914, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/55ab092f.mp4", "clean_score": 1.0, "clean_xclip": 0.2793038785457611, "clean_vbench": {}, "adv_vid_id": "vids/c1971818.mp4", "adv_score": 1.0, "adv_xclip": 0.21762853860855103, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/60a6af6c.mp4", "clean_score": 1.0, "clean_xclip": 0.2523314654827118, "clean_vbench": {}, "adv_vid_id": "vids/6225a63e.mp4", "adv_score": 1.0, "adv_xclip": 0.22443731129169464, "adv_vbench": {}}}}
{"id": "3af80eea1dec42958128601a62623aa8", "source": "vatex", "video_id": "hW2ZI3zp74I_000190_000200", "video_description": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night. The truck is slowly driving down a road, with workers walking around and behind it, bringing garbage cans to the back.", "task": "ActionRecognition", "clean_prompt": "A garbage truck driving down a road at night while workers collect garbage.", "clean_property": {"obj": "garbage truck", "action": "driving car", "target": null}, "target_prompt": "A garbage truck parked in a brightly lit area while workers unload garbage.", "target_property": {"obj": "garbage truck", "action": "driving car", "target": null}, "evaluation_question": "Is the garbage truck **driving** down a road?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A garbage truck driving down a road at night while workers collect garbage.effi cardiac caut adjunct complications", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8352a6d4a21491abc2970fcfe3d55bc.mp4", "clean_score": 1.0, "clean_xclip": 0.21745829284191132, "clean_vbench": {"subject_consistency": 0.8068046054492394, "background_consistency": 0.9227549235026041, "motion_smoothness": 0.998896332764716, "aesthetic_quality": 0.34325528144836426, "imaging_quality": 0.15484124222580267, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ff7dd29fa34940f8a595cd563c5a8ffd.mp4", "adv_score": 0.0, "adv_xclip": 0.18108031153678894, "adv_vbench": {"subject_consistency": 0.8874321909000477, "background_consistency": 0.9610392252604166, "motion_smoothness": 0.9984308316690874, "aesthetic_quality": 0.30454474687576294, "imaging_quality": 0.21902852272500797, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/072ce5e8.mp4", "clean_score": 0.0, "clean_xclip": 0.21267655491828918, "clean_vbench": {}, "adv_vid_id": "vids/ef4d0e8d.mp4", "adv_score": 1.0, "adv_xclip": 0.267343133687973, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f03a65b5.mp4", "clean_score": 0.0, "clean_xclip": 0.2693191170692444, "clean_vbench": {}, "adv_vid_id": "vids/8f9c2b56.mp4", "adv_score": 0.0, "adv_xclip": 0.24659113585948944, "adv_vbench": {}}}}
{"id": "d508ce19220543b6ab23f33c3fc76918", "source": "vatex", "video_id": "LAqqJXdiNIo_000001_000011", "video_description": "A man is sitting in a cafe, smoking a hookah and attempting to blow smoke rings and shapes with the smoke.", "task": "ActionRecognition", "clean_prompt": "A person smoking a hookah in a cafe, attempting to blow smoke rings.", "clean_property": {"obj": "person", "action": "smoking hookah", "target": null}, "target_prompt": "A person drinking coffee in a cafe.", "target_property": {"obj": "person", "action": "drinking coffee", "target": null}, "evaluation_question": "Is the person **smoking a hookah**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person smoking a hookah in a cafe, attempting to blow smoke rings. FE;7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6545ddf6605b4eeeafa1fb6eaddbd403.mp4", "clean_score": 1.0, "clean_xclip": 0.23048216104507446, "clean_vbench": {"subject_consistency": 0.919752170642217, "background_consistency": 0.9515787760416666, "motion_smoothness": 0.9774517023533951, "aesthetic_quality": 0.4742399752140045, "imaging_quality": 0.5562764514222437, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0883bc7341b1406491e8ccb2aae7f916.mp4", "adv_score": 0.0, "adv_xclip": 0.20505891740322113, "adv_vbench": {"subject_consistency": 0.9331507397194704, "background_consistency": 0.9671630859375, "motion_smoothness": 0.9731409105694747, "aesthetic_quality": 0.4328635334968567, "imaging_quality": 0.4795453787823113, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bb76bc0c.mp4", "clean_score": 1.0, "clean_xclip": 0.21535097062587738, "clean_vbench": {}, "adv_vid_id": "vids/e4b61e75.mp4", "adv_score": 1.0, "adv_xclip": 0.23979772627353668, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/613ff105.mp4", "clean_score": 1.0, "clean_xclip": 0.24350965023040771, "clean_vbench": {}, "adv_vid_id": "vids/09bcba80.mp4", "adv_score": 1.0, "adv_xclip": 0.24145960807800293, "adv_vbench": {}}}}
{"id": "60a497ac186a411db2e0360a37fc517f", "source": "vatex", "video_id": "bdEhYyz7z2E_000127_000137", "video_description": "A person is drawing an anime character on a white piece of paper using a pencil. The drawing process includes outlining, shading, and coloring, accompanied by intense music.", "task": "Counting", "clean_prompt": "Three people are drawing anime characters on white pieces of paper using pencils, outlining, shading, and coloring, accompanied by intense music.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is drawing an anime character on a white piece of paper using a pencil, outlining, shading, and coloring, accompanied by intense music.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people drawing in the video?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three people are drawing anime characters on white pieces of paper using pencils, outlining, shading, and coloring, accompanied by intense music. HB<K~", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4f35d852d91041a8b8375ca3d95f7596.mp4", "clean_score": 1.0, "clean_xclip": 0.24125052988529205, "clean_vbench": {"subject_consistency": 0.9178785582383474, "background_consistency": 0.9632314046223959, "motion_smoothness": 0.943213941180253, "aesthetic_quality": 0.34804484248161316, "imaging_quality": 0.7524138765918965, "dynamic_degree": 1.0}, "adv_vid_id": "vids/49eb00f433e54ad5935749086f952637.mp4", "adv_score": 0.0, "adv_xclip": 0.24222184717655182, "adv_vbench": {"subject_consistency": 0.8545707470426956, "background_consistency": 0.9349365234375, "motion_smoothness": 0.9257366754733015, "aesthetic_quality": 0.466949462890625, "imaging_quality": 0.7553090589873644, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8c5d7ea7.mp4", "clean_score": 1.0, "clean_xclip": 0.2579082250595093, "clean_vbench": {}, "adv_vid_id": "vids/e4d94ce2.mp4", "adv_score": 0.0, "adv_xclip": 0.2154618799686432, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1bcabab3.mp4", "clean_score": 1.0, "clean_xclip": 0.2350681871175766, "clean_vbench": {}, "adv_vid_id": "vids/7d5d430b.mp4", "adv_score": 0.0, "adv_xclip": 0.23275306820869446, "adv_vbench": {}}}}
{"id": "1bd21bad302f49a9af0eaca806ae566d", "source": "vatex", "video_id": "5Ka89vMcQyc_000000_000010", "video_description": "A young boy in a blue shirt rides a bicycle over a small ramp in a suburban street, making a jump and landing.", "task": "ActionRecognition", "clean_prompt": "A boy jumping on a bicycle in a suburban street.", "clean_property": {"obj": "boy", "action": "jumping bicycle", "target": null}, "target_prompt": "A boy falling off a bicycle in a suburban street.", "target_property": {"obj": "boy", "action": "falling off bicycle", "target": null}, "evaluation_question": "Is the boy **jumping** on the bicycle?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy jumping on a bicycle in a suburban street. vingt $50,000escalierfizhidr", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1eef3de9c6da4ae0a4ac70fddff1a10a.mp4", "clean_score": 1.0, "clean_xclip": 0.27048051357269287, "clean_vbench": {"subject_consistency": 0.8930981028825045, "background_consistency": 0.9182535807291666, "motion_smoothness": 0.9594511089929799, "aesthetic_quality": 0.5862777233123779, "imaging_quality": 0.5780938697347835, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1a4e292c1b6040e6a0dd5dd5834e38ba.mp4", "adv_score": 0.0, "adv_xclip": 0.2616012692451477, "adv_vbench": {"subject_consistency": 0.907966104025642, "background_consistency": 0.9185078938802084, "motion_smoothness": 0.973633537140422, "aesthetic_quality": 0.5133458971977234, "imaging_quality": 0.5886183104223135, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1be66b96.mp4", "clean_score": 1.0, "clean_xclip": 0.22690142691135406, "clean_vbench": {}, "adv_vid_id": "vids/00e659fd.mp4", "adv_score": 0.0, "adv_xclip": 0.24057689309120178, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6b9212c1.mp4", "clean_score": 1.0, "clean_xclip": 0.26789671182632446, "clean_vbench": {}, "adv_vid_id": "vids/47a709d9.mp4", "adv_score": 1.0, "adv_xclip": 0.2847077548503876, "adv_vbench": {}}}}
{"id": "3f82ef1131164d9a9b0ef4fe0b7608d6", "source": "vatex", "video_id": "Ocn7yFVKn_A_000024_000034", "video_description": "A young girl is demonstrating how to fold paper into origami while talking to the camera.", "task": "Counting", "clean_prompt": "Five girls demonstrating how to fold paper into origami while talking to the camera.", "clean_property": {"obj": "girl", "count": "five"}, "target_prompt": "One girl demonstrating how to fold paper into origami while talking to the camera.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **five** girls demonstrating origami?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Five girls demonstrating how to fold paper into origami while talking to the camera. Unity2.9 frumos crayon lassen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/83bfcc5a75b04e8080845516aed6870e.mp4", "clean_score": 1.0, "clean_xclip": 0.23447255790233612, "clean_vbench": {"subject_consistency": 0.9460560524215301, "background_consistency": 0.9488677978515625, "motion_smoothness": 0.9686934999533507, "aesthetic_quality": 0.5377365946769714, "imaging_quality": 0.7200919622304488, "dynamic_degree": 1.0}, "adv_vid_id": "vids/346d20134cdf49298673645270984a21.mp4", "adv_score": 0.0, "adv_xclip": 0.19521018862724304, "adv_vbench": {"subject_consistency": 0.9671373094121615, "background_consistency": 0.9606475830078125, "motion_smoothness": 0.9754436581827948, "aesthetic_quality": 0.5234215259552002, "imaging_quality": 0.766803532814493, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d50981ac.mp4", "clean_score": 0.0, "clean_xclip": 0.2171124368906021, "clean_vbench": {}, "adv_vid_id": "vids/ac23d841.mp4", "adv_score": 0.0, "adv_xclip": 0.22456449270248413, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f14e2566.mp4", "clean_score": 0.0, "clean_xclip": 0.22608605027198792, "clean_vbench": {}, "adv_vid_id": "vids/168457a3.mp4", "adv_score": 1.0, "adv_xclip": 0.2363612949848175, "adv_vbench": {}}}}
{"id": "c59589eea3dc4f0eaea1756a05478176", "source": "vatex", "video_id": "2GAPlZ6gD8s_000038_000048", "video_description": "A young man is standing outside on a lawn, demonstrating various juggling techniques with three balls.", "task": "ActionRecognition", "clean_prompt": "A person juggling balls on a lawn.", "clean_property": {"obj": "person", "action": "juggling balls", "target": null}, "target_prompt": "A person juggling clubs on a lawn.", "target_property": {"obj": "person", "action": "juggling clubs", "target": null}, "evaluation_question": "Is the person **juggling balls**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person juggling balls on a lawn. CK.1(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0dae89bb2c3745e1abecc077413a3533.mp4", "clean_score": 1.0, "clean_xclip": 0.2693372070789337, "clean_vbench": {"subject_consistency": 0.9458960356811682, "background_consistency": 0.9367319742838541, "motion_smoothness": 0.9524198079308883, "aesthetic_quality": 0.5034029483795166, "imaging_quality": 0.6501348464343013, "dynamic_degree": 1.0}, "adv_vid_id": "vids/546832a736b649a18d6c66b71127b110.mp4", "adv_score": 0.0, "adv_xclip": 0.2603079080581665, "adv_vbench": {"subject_consistency": 0.9011839336405197, "background_consistency": 0.9292399088541666, "motion_smoothness": 0.9301505873086118, "aesthetic_quality": 0.5016724467277527, "imaging_quality": 0.6871934953027842, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7a2e462c.mp4", "clean_score": 1.0, "clean_xclip": 0.20049238204956055, "clean_vbench": {}, "adv_vid_id": "vids/d78e07b4.mp4", "adv_score": 0.0, "adv_xclip": 0.224065899848938, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f2672e28.mp4", "clean_score": 1.0, "clean_xclip": 0.278380811214447, "clean_vbench": {}, "adv_vid_id": "vids/7c9503a6.mp4", "adv_score": 1.0, "adv_xclip": 0.266797810792923, "adv_vbench": {}}}}
{"id": "371483a980614ed296be005cb66d97ec", "source": "vatex", "video_id": "M3-oz_R_xsk_000019_000029", "video_description": "A man in a yellow shirt and black exercise shorts is repeatedly hitting a large rubber tire with a sledgehammer outdoors.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a tire outdoors.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "tire"}, "target_prompt": "A person kicking a tire outdoors.", "target_property": {"obj": "person", "action": "kicking", "target": "tire"}, "evaluation_question": "Is the person **using a sledge hammer** on the tire?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person using a sledge hammer on a tire outdoors. suntemoreille argint ehrenamtlich vitamine", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f21966bddaee4958a33510187d334f73.mp4", "clean_score": 1.0, "clean_xclip": 0.18487314879894257, "clean_vbench": {"subject_consistency": 0.9502305705100298, "background_consistency": 0.9425760904947916, "motion_smoothness": 0.9616815815253571, "aesthetic_quality": 0.48593324422836304, "imaging_quality": 0.6837147903442383, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1674627cc837485b89e4cfed326592aa.mp4", "adv_score": 0.0, "adv_xclip": 0.2368733286857605, "adv_vbench": {"subject_consistency": 0.935496972873807, "background_consistency": 0.9489695231119791, "motion_smoothness": 0.9330405302199326, "aesthetic_quality": 0.44872748851776123, "imaging_quality": 0.648172721862793, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/578f1cb5.mp4", "clean_score": 1.0, "clean_xclip": 0.2012312114238739, "clean_vbench": {}, "adv_vid_id": "vids/296e8d2c.mp4", "adv_score": 1.0, "adv_xclip": 0.225490540266037, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c53da126.mp4", "clean_score": 0.0, "clean_xclip": 0.21644426882266998, "clean_vbench": {}, "adv_vid_id": "vids/ab6b2450.mp4", "adv_score": 1.0, "adv_xclip": 0.26150816679000854, "adv_vbench": {}}}}
{"id": "f2411b2ea6de4d6791435dc8085b0610", "source": "vatex", "video_id": "jODN7qCOn1U_000004_000014", "video_description": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "task": "ActionRecognition", "clean_prompt": "A person sanding a wooden floor.", "clean_property": {"obj": "person", "action": "sanding floor", "target": null}, "target_prompt": "A person vacuuming a wooden floor.", "target_property": {"obj": "person", "action": "vacuuming floor", "target": null}, "evaluation_question": "Is the person **sanding** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person sanding a wooden floor. biciclet gradina aeroport roulant Apartament", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f32265ab7abc488682f80b3a6bfd6417.mp4", "clean_score": 1.0, "clean_xclip": 0.23739969730377197, "clean_vbench": {"subject_consistency": 0.9109617297848066, "background_consistency": 0.9372202555338541, "motion_smoothness": 0.9767499292380275, "aesthetic_quality": 0.4412381947040558, "imaging_quality": 0.36973756128427937, "dynamic_degree": 1.0}, "adv_vid_id": "vids/05e3e76ffdc84f82b67d6f8bc565da25.mp4", "adv_score": 0.0, "adv_xclip": 0.2241050899028778, "adv_vbench": {"subject_consistency": 0.9086642650266489, "background_consistency": 0.951904296875, "motion_smoothness": 0.9554853544780824, "aesthetic_quality": 0.4449377954006195, "imaging_quality": 0.46979072337247885, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8225c7b6.mp4", "clean_score": 1.0, "clean_xclip": 0.21454453468322754, "clean_vbench": {}, "adv_vid_id": "vids/b0cab9e5.mp4", "adv_score": 1.0, "adv_xclip": 0.18753740191459656, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d35c1dbe.mp4", "clean_score": 0.0, "clean_xclip": 0.20675793290138245, "clean_vbench": {}, "adv_vid_id": "vids/4cf15e1d.mp4", "adv_score": 1.0, "adv_xclip": 0.2199815958738327, "adv_vbench": {}}}}
{"id": "1274d1b1c601463f928649b9431eda4d", "source": "vatex", "video_id": "va3txyK3Xck_000552_000562", "video_description": "A person is demonstrating knitting techniques, including casting off, using green or teal yarn and needles, with opera music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating knitting techniques with knitting needles and green yarn, accompanied by opera music.", "clean_property": {"obj": "knitting needles"}, "target_prompt": "A person demonstrating crochet techniques with crochet hooks and teal yarn, accompanied by opera music.", "target_property": {"obj": "crochet hooks"}, "evaluation_question": "Is the person using **knitting needles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person demonstrating knitting techniques with knitting needles and green yarn, accompanied by opera music. erfolgenVotredouceureignet meu", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f84a8ce3adda452ab9ef8a19c25713bb.mp4", "clean_score": 1.0, "clean_xclip": 0.2875407934188843, "clean_vbench": {"subject_consistency": 0.8392755507181088, "background_consistency": 0.9331919352213541, "motion_smoothness": 0.9254802593008654, "aesthetic_quality": 0.5339127779006958, "imaging_quality": 0.43708074608627634, "dynamic_degree": 1.0}, "adv_vid_id": "vids/cd80da4bd63041be92b48a5abf7e2791.mp4", "adv_score": 0.0, "adv_xclip": 0.27565252780914307, "adv_vbench": {"subject_consistency": 0.8088062430421511, "background_consistency": 0.9244537353515625, "motion_smoothness": 0.9180491712181271, "aesthetic_quality": 0.5163754820823669, "imaging_quality": 0.37056352265027104, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d96da0ef.mp4", "clean_score": 0.0, "clean_xclip": 0.2556271255016327, "clean_vbench": {}, "adv_vid_id": "vids/67b5441e.mp4", "adv_score": 1.0, "adv_xclip": 0.2830418050289154, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/950ef274.mp4", "clean_score": 0.0, "clean_xclip": 0.27256864309310913, "clean_vbench": {}, "adv_vid_id": "vids/816449cf.mp4", "adv_score": 0.0, "adv_xclip": 0.2728723883628845, "adv_vbench": {}}}}
{"id": "d8520d4ff6c443f5a8f3ae8d83987797", "source": "vatex", "video_id": "WBgBSxunVrs_000000_000010", "video_description": "A person is demonstrating how to knit using blue knitting needles and cream-colored yarn.", "task": "ActionRecognition", "clean_prompt": "A person knitting with blue knitting needles and cream-colored yarn.", "clean_property": {"obj": "person", "action": "knitting", "target": null}, "target_prompt": "A person crocheting with colorful yarn.", "target_property": {"obj": "person", "action": "crocheting", "target": null}, "evaluation_question": "Is the person **knitting**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person knitting with blue knitting needles and cream-colored yarn. Motivation VectorBio Pharma Illustration", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/449c0dd6856f4b99a249db9106a1010e.mp4", "clean_score": 1.0, "clean_xclip": 0.25611990690231323, "clean_vbench": {"subject_consistency": 0.7977240464339653, "background_consistency": 0.9145100911458334, "motion_smoothness": 0.9273700966208243, "aesthetic_quality": 0.4162805676460266, "imaging_quality": 0.37783262174956656, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ea4c165008b84b56bb29c9bdcd9f875f.mp4", "adv_score": 0.0, "adv_xclip": 0.22336643934249878, "adv_vbench": {"subject_consistency": 0.9317874728391567, "background_consistency": 0.9368540445963541, "motion_smoothness": 0.9884362611138848, "aesthetic_quality": 0.5176373720169067, "imaging_quality": 0.4282871020570093, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fa7248f3.mp4", "clean_score": 1.0, "clean_xclip": 0.25920528173446655, "clean_vbench": {}, "adv_vid_id": "vids/c3c14e12.mp4", "adv_score": 1.0, "adv_xclip": 0.24483951926231384, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/91402bcd.mp4", "clean_score": 1.0, "clean_xclip": 0.2768626809120178, "clean_vbench": {}, "adv_vid_id": "vids/dfcb3bef.mp4", "adv_score": 1.0, "adv_xclip": 0.2196941077709198, "adv_vbench": {}}}}
{"id": "61bc50e7438848b6befa8f1dbc42ffd1", "source": "vatex", "video_id": "SBOx3KAoAcQ_000004_000014", "video_description": "People, including men and boys, are performing flips, jumps, and other tricks on trampolines in a trampoline park with music playing.", "task": "ActionRecognition", "clean_prompt": "A person performing a backflip in a trampoline park.", "clean_property": {"obj": "person", "action": "backflip (human)", "target": null}, "target_prompt": "A person performing a frontflip in a trampoline park.", "target_property": {"obj": "person", "action": "frontflip (human)", "target": null}, "evaluation_question": "Is the person **performing a backflip**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person performing a backflip in a trampoline park.amerikanische Nitro beurreewusst snowboard", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/658cb3e6a95d4da2b0cbb6c5f93ef2ae.mp4", "clean_score": 1.0, "clean_xclip": 0.16881708800792694, "clean_vbench": {"subject_consistency": 0.8685690611600876, "background_consistency": 0.935333251953125, "motion_smoothness": 0.9448353638394659, "aesthetic_quality": 0.5375851988792419, "imaging_quality": 0.5156135333314233, "dynamic_degree": 1.0}, "adv_vid_id": "vids/eee144709f4244c8836e58790a10128c.mp4", "adv_score": 0.0, "adv_xclip": 0.1186719685792923, "adv_vbench": {"subject_consistency": 0.6886226454128822, "background_consistency": 0.8926544189453125, "motion_smoothness": 0.9669542578219559, "aesthetic_quality": 0.40055760741233826, "imaging_quality": 0.34397319404446347, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b5498e13.mp4", "clean_score": 0.0, "clean_xclip": 0.21840424835681915, "clean_vbench": {}, "adv_vid_id": "vids/7e3afb70.mp4", "adv_score": 1.0, "adv_xclip": 0.20740267634391785, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4fd26b43.mp4", "clean_score": 1.0, "clean_xclip": 0.227842777967453, "clean_vbench": {}, "adv_vid_id": "vids/90d3e454.mp4", "adv_score": 1.0, "adv_xclip": 0.19499194622039795, "adv_vbench": {}}}}
{"id": "e36b7d53c7a04eff9ccd211cc611f0ca", "source": "vatex", "video_id": "5hFBORyDwnw_000264_000274", "video_description": "A sports event is taking place in a large stadium with many spectators. Two teams are playing a game on the field, with people watching and recording the match.", "task": "Counting", "clean_prompt": "Seven coaches discussing strategies in a large stadium during a sports event.", "clean_property": {"obj": "coach", "count": "seven"}, "target_prompt": "Four coaches discussing strategies in a large stadium during a sports event.", "target_property": {"obj": "coach", "count": "four"}, "evaluation_question": "Are there exactly **seven** coaches discussing strategies in the stadium?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Seven coaches discussing strategies in a large stadium during a sports event. TZLFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b3598d982e54395b1a504fd56796315.mp4", "clean_score": 1.0, "clean_xclip": 0.04378603771328926, "clean_vbench": {"subject_consistency": 0.978197801237305, "background_consistency": 0.9027964274088541, "motion_smoothness": 0.9831705146050189, "aesthetic_quality": 0.5004419684410095, "imaging_quality": 0.6914644848570533, "dynamic_degree": 0.0}, "adv_vid_id": "vids/524f45c12e1a48b8adbb0d159e86dc84.mp4", "adv_score": 0.0, "adv_xclip": 0.05474574863910675, "adv_vbench": {"subject_consistency": 0.9873742610216141, "background_consistency": 0.9511515299479166, "motion_smoothness": 0.9884523587534293, "aesthetic_quality": 0.5132858157157898, "imaging_quality": 0.6847342277059749, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ca263bb4.mp4", "clean_score": 0.0, "clean_xclip": 0.13720528781414032, "clean_vbench": {}, "adv_vid_id": "vids/01d68308.mp4", "adv_score": 0.0, "adv_xclip": 0.12691693007946014, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/198d082d.mp4", "clean_score": 0.0, "clean_xclip": 0.11376097798347473, "clean_vbench": {}, "adv_vid_id": "vids/1f5be5fc.mp4", "adv_score": 0.0, "adv_xclip": 0.15566834807395935, "adv_vbench": {}}}}
{"id": "c530f2bbdf9c4fc88828c99e7a0509ba", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "SpatialUnderstanding", "clean_prompt": "A laptop positioned to the right of a TV.", "clean_property": {"obj_1": "laptop", "relation": "right of", "obj_2": "tv"}, "target_prompt": "A laptop positioned to the left of a TV.", "target_property": {"obj_1": "laptop", "relation": "left of", "obj_2": "tv"}, "evaluation_question": "Is the laptop to the **right** of the TV?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A laptop positioned to the right of a TV. Schrift Coll Laptop timp Apartament", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d35c91b3ded423b9bf260f9b6e64431.mp4", "clean_score": 1.0, "clean_xclip": 0.20981472730636597, "clean_vbench": {"subject_consistency": 0.9993575705836216, "background_consistency": 0.9980265299479166, "motion_smoothness": 0.9969167520853506, "aesthetic_quality": 0.419526070356369, "imaging_quality": 0.6268054837596659, "dynamic_degree": 0.0}, "adv_vid_id": "vids/32dadf1d88a94ccd8d437ebf4de3ce1c.mp4", "adv_score": 0.0, "adv_xclip": 0.23235543072223663, "adv_vbench": {"subject_consistency": 0.9985146267960469, "background_consistency": 0.9952239990234375, "motion_smoothness": 0.9971403324961672, "aesthetic_quality": 0.40415486693382263, "imaging_quality": 0.7304821123395648, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3ac739fc.mp4", "clean_score": 0.0, "clean_xclip": 0.25202280282974243, "clean_vbench": {}, "adv_vid_id": "vids/3af6c876.mp4", "adv_score": 0.0, "adv_xclip": 0.17422300577163696, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/21f5b242.mp4", "clean_score": 0.0, "clean_xclip": 0.2222994565963745, "clean_vbench": {}, "adv_vid_id": "vids/82633bbe.mp4", "adv_score": 0.0, "adv_xclip": 0.22617927193641663, "adv_vbench": {}}}}
{"id": "0a671ac578a14e86a26f3fd710647402", "source": "vatex", "video_id": "J3OG-RLowJc_000024_000034", "video_description": "A group of young people are competing in a dodgeball tournament in an indoor gym. The game starts with players running to the center of the court to grab balls.", "task": "AttributeRecognition", "clean_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym.", "clean_property": {"obj": "player", "attribute": "student"}, "target_prompt": "A player who is a professional competing in a dodgeball tournament in an indoor gym.", "target_property": {"obj": "player", "attribute": "professional"}, "evaluation_question": "Is the player a **student**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym. lupte maladehilfe plural Sapphire", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9696a85ca3514425a6776e0ddd8ff383.mp4", "clean_score": 1.0, "clean_xclip": 0.15062636137008667, "clean_vbench": {"subject_consistency": 0.9244303411493698, "background_consistency": 0.9112396240234375, "motion_smoothness": 0.9640421178727406, "aesthetic_quality": 0.45633548498153687, "imaging_quality": 0.5290387967168069, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c768ab4769654325b934d1c921aea92c.mp4", "adv_score": 0.0, "adv_xclip": 0.1693299114704132, "adv_vbench": {"subject_consistency": 0.9238476312408844, "background_consistency": 0.9024200439453125, "motion_smoothness": 0.9718542506669592, "aesthetic_quality": 0.4151432514190674, "imaging_quality": 0.5223750126118563, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9bcbbb2c.mp4", "clean_score": 1.0, "clean_xclip": 0.14018455147743225, "clean_vbench": {}, "adv_vid_id": "vids/da452d94.mp4", "adv_score": 1.0, "adv_xclip": 0.15811944007873535, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bff58808.mp4", "clean_score": 0.0, "clean_xclip": 0.19655117392539978, "clean_vbench": {}, "adv_vid_id": "vids/6c54eff0.mp4", "adv_score": 1.0, "adv_xclip": 0.2107284963130951, "adv_vbench": {}}}}
{"id": "a5db871813ad4ed388beae8f43692add", "source": "vatex", "video_id": "f-JzfOaiVOE_000076_000086", "video_description": "Several people are in a gym or court bouncing balls, including basketballs and medicine balls, as part of an exercise routine.", "task": "Counting", "clean_prompt": "Four people in a gym bouncing basketballs and medicine balls as part of an exercise routine.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a gym bouncing a basketball as part of an exercise routine.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a gym bouncing basketballs and medicine balls as part of an exercise routine. =6XFM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d07306bbd487438cb23b3589f99ec61d.mp4", "clean_score": 1.0, "clean_xclip": 0.17602118849754333, "clean_vbench": {"subject_consistency": 0.964023175338904, "background_consistency": 0.9515940348307291, "motion_smoothness": 0.9664921663817276, "aesthetic_quality": 0.5817888379096985, "imaging_quality": 0.602953864117058, "dynamic_degree": 1.0}, "adv_vid_id": "vids/479b6c2acc614dbf9aa9a89ddd3193fa.mp4", "adv_score": 0.0, "adv_xclip": 0.1624857634305954, "adv_vbench": {"subject_consistency": 0.9633877668529749, "background_consistency": 0.9517466227213541, "motion_smoothness": 0.9546228106340272, "aesthetic_quality": 0.6188457012176514, "imaging_quality": 0.6608719424812161, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/65be298f.mp4", "clean_score": 1.0, "clean_xclip": 0.21733078360557556, "clean_vbench": {}, "adv_vid_id": "vids/14cccef8.mp4", "adv_score": 1.0, "adv_xclip": 0.22620615363121033, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/430f9694.mp4", "clean_score": 0.0, "clean_xclip": 0.19591191411018372, "clean_vbench": {}, "adv_vid_id": "vids/7bbf83a7.mp4", "adv_score": 1.0, "adv_xclip": 0.18715164065361023, "adv_vbench": {}}}}
{"id": "9a695bf66643493192177299d3484816", "source": "vatex", "video_id": "xgIaB0VojPI_000036_000046", "video_description": "A tour group is riding camels in a long line through a dusty desert, with a woman talking.", "task": "Counting", "clean_prompt": "A woman is leading a tour group of six camels through a dusty desert.", "clean_property": {"obj": "woman", "count": "six"}, "target_prompt": "A woman is leading a tour group of three camels through a dusty desert.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** camels in the tour group?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is leading a tour group of six camels through a dusty desert. DP/HU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a83d5ea7ef1f4cc8b3f2b0618b25980a.mp4", "clean_score": 1.0, "clean_xclip": 0.2511099576950073, "clean_vbench": {"subject_consistency": 0.9847952021906773, "background_consistency": 0.9683990478515625, "motion_smoothness": 0.9919839294674917, "aesthetic_quality": 0.5989430546760559, "imaging_quality": 0.68196286882673, "dynamic_degree": 0.0}, "adv_vid_id": "vids/09711b909c3941eaa4af72f57e12e0f2.mp4", "adv_score": 0.0, "adv_xclip": 0.25454941391944885, "adv_vbench": {"subject_consistency": 0.9806817440936962, "background_consistency": 0.9735666910807291, "motion_smoothness": 0.9921654553603849, "aesthetic_quality": 0.5751110911369324, "imaging_quality": 0.6374610698466399, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9bb66f76.mp4", "clean_score": 1.0, "clean_xclip": 0.23318660259246826, "clean_vbench": {}, "adv_vid_id": "vids/d2e4cc8f.mp4", "adv_score": 0.0, "adv_xclip": 0.22151567041873932, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e2909dd1.mp4", "clean_score": 0.0, "clean_xclip": 0.25001516938209534, "clean_vbench": {}, "adv_vid_id": "vids/95bf2a3e.mp4", "adv_score": 0.0, "adv_xclip": 0.23414142429828644, "adv_vbench": {}}}}
{"id": "c9a5edc8729f485182c0842c37641a45", "source": "vatex", "video_id": "NAshG3XdoLA_000041_000051", "video_description": "A man and a woman dressed in old English outfits are playing unique string instruments, including a violin and a guitar-like instrument, inside a decorated room.", "task": "SpatialUnderstanding", "clean_prompt": "An instrument farther from the camera than a musician in a decorated room.", "clean_property": {"obj_1": "instrument", "relation": "farther from the camera than", "obj_2": "musician"}, "target_prompt": "An instrument closer to the camera than a musician in a decorated room.", "target_property": {"obj_1": "instrument", "relation": "closer to the camera than", "obj_2": "musician"}, "evaluation_question": "Is the instrument **farther from the camera than** the musician?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instrument farther from the camera than a musician in a decorated room. !0D0/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9e0b74f1abea453ea73d97709529fd72.mp4", "clean_score": 1.0, "clean_xclip": 0.16328904032707214, "clean_vbench": {"subject_consistency": 0.9582480508834124, "background_consistency": 0.9434102376302084, "motion_smoothness": 0.9945448251091846, "aesthetic_quality": 0.4840894341468811, "imaging_quality": 0.38289963702766266, "dynamic_degree": 0.0}, "adv_vid_id": "vids/d878962a820d4c26b9682166e7ab22e5.mp4", "adv_score": 0.0, "adv_xclip": 0.15409791469573975, "adv_vbench": {"subject_consistency": 0.9761210034290949, "background_consistency": 0.9597269694010416, "motion_smoothness": 0.9946158327785847, "aesthetic_quality": 0.44902920722961426, "imaging_quality": 0.5529236571642817, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e6602126.mp4", "clean_score": 0.0, "clean_xclip": 0.12938515841960907, "clean_vbench": {}, "adv_vid_id": "vids/dc87d1b0.mp4", "adv_score": 0.0, "adv_xclip": 0.1589343100786209, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1d93009c.mp4", "clean_score": 0.0, "clean_xclip": 0.1678454875946045, "clean_vbench": {}, "adv_vid_id": "vids/62aa14dc.mp4", "adv_score": 1.0, "adv_xclip": 0.1799352765083313, "adv_vbench": {}}}}
{"id": "b19465e0ee9b4c4181dad3871e0e8def", "source": "vatex", "video_id": "PE3pN-tvfmM_000000_000010", "video_description": "A person is performing a handstand on a wooden or gym floor while music plays.", "task": "ActionRecognition", "clean_prompt": "A person standing on hands on a wooden floor while music plays.", "clean_property": {"obj": "person", "action": "standing on hands", "target": null}, "target_prompt": "A person doing a backflip on a wooden floor while music plays.", "target_property": {"obj": "person", "action": "doing a backflip", "target": null}, "evaluation_question": "Is the person **standing on hands**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing on hands on a wooden floor while music plays.TZ Pentru exklusive autres Ersatzteile", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c4c7a895a364472bd3a7b48a35c7e5f.mp4", "clean_score": 1.0, "clean_xclip": 0.15089890360832214, "clean_vbench": {"subject_consistency": 0.9642406000445286, "background_consistency": 0.9696044921875, "motion_smoothness": 0.9923237275137679, "aesthetic_quality": 0.3820790648460388, "imaging_quality": 0.5239769705947565, "dynamic_degree": 1.0}, "adv_vid_id": "vids/80427806e9ab402f88621b9d379545d7.mp4", "adv_score": 0.0, "adv_xclip": 0.14663057029247284, "adv_vbench": {"subject_consistency": 0.9775391519069672, "background_consistency": 0.974456787109375, "motion_smoothness": 0.994837084033073, "aesthetic_quality": 0.3813834488391876, "imaging_quality": 0.7219263201343771, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/860a451c.mp4", "clean_score": 0.0, "clean_xclip": 0.1323256492614746, "clean_vbench": {}, "adv_vid_id": "vids/8daafc8b.mp4", "adv_score": 0.0, "adv_xclip": 0.14155995845794678, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/592cefba.mp4", "clean_score": 0.0, "clean_xclip": 0.14073625206947327, "clean_vbench": {}, "adv_vid_id": "vids/f72ba826.mp4", "adv_score": 0.0, "adv_xclip": 0.17100581526756287, "adv_vbench": {}}}}
{"id": "e2e930b073a6488c987b1e85138ab92c", "source": "vatex", "video_id": "eazRPFhEkuM_000000_000010", "video_description": "Two men are on a stage, one holding a microphone and speaking while placing his hand on the shoulder of the other man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "task": "Counting", "clean_prompt": "Five men on a stage, one holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "clean_property": {"obj": "man_2", "count": "five"}, "target_prompt": "One man on a stage, holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "target_property": {"obj": "man_2", "count": "one"}, "evaluation_question": "Are there exactly **five** men on the stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five men on a stage, one holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present. %TZT-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/60ec2c59621c42519585cac5390154e3.mp4", "clean_score": 1.0, "clean_xclip": 0.14382028579711914, "clean_vbench": {"subject_consistency": 0.9295417616764704, "background_consistency": 0.9058430989583334, "motion_smoothness": 0.9827564632945514, "aesthetic_quality": 0.5285833477973938, "imaging_quality": 0.5065751741370377, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f1afbfb0fd7d4c1c9b18c77b57a088f4.mp4", "adv_score": 0.0, "adv_xclip": 0.11251364648342133, "adv_vbench": {"subject_consistency": 0.926232103879253, "background_consistency": 0.9187571207682291, "motion_smoothness": 0.9848971502309771, "aesthetic_quality": 0.5824497938156128, "imaging_quality": 0.45889315702477285, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/17de8c5e.mp4", "clean_score": 1.0, "clean_xclip": 0.11701666563749313, "clean_vbench": {}, "adv_vid_id": "vids/6fb1170e.mp4", "adv_score": 0.0, "adv_xclip": 0.15456606447696686, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c21ddb2f.mp4", "clean_score": 0.0, "clean_xclip": 0.13528570532798767, "clean_vbench": {}, "adv_vid_id": "vids/cb22766c.mp4", "adv_score": 0.0, "adv_xclip": 0.1568634808063507, "adv_vbench": {}}}}
{"id": "1e21d15d982f40d2b9a0e8e04d51c857", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer to hit the roof of a car.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "car"}, "target_prompt": "A person using a sledgehammer to hit a tree.", "target_property": {"obj": "person", "action": "using a sledgehammer", "target": "tree"}, "evaluation_question": "Is the person **using a sledgehammer** on a car?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person using a sledgehammer to hit the roof of a car. !0<(<", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb403721c6724e86a54c5525c2025cc1.mp4", "clean_score": 1.0, "clean_xclip": 0.23430317640304565, "clean_vbench": {"subject_consistency": 0.8810104082028071, "background_consistency": 0.9439697265625, "motion_smoothness": 0.9719515003114156, "aesthetic_quality": 0.3619491457939148, "imaging_quality": 0.551476901307398, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9fa7debbe4924aca95350147c59f3b99.mp4", "adv_score": 0.0, "adv_xclip": 0.1972665786743164, "adv_vbench": {"subject_consistency": 0.9074396224071583, "background_consistency": 0.9432932535807291, "motion_smoothness": 0.9626234410302187, "aesthetic_quality": 0.38613876700401306, "imaging_quality": 0.48369299129563936, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/33f5d28e.mp4", "clean_score": 1.0, "clean_xclip": 0.2178283929824829, "clean_vbench": {}, "adv_vid_id": "vids/bd45a573.mp4", "adv_score": 1.0, "adv_xclip": 0.1957034170627594, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6a5a3c58.mp4", "clean_score": 1.0, "clean_xclip": 0.22298362851142883, "clean_vbench": {}, "adv_vid_id": "vids/a7ac5611.mp4", "adv_score": 1.0, "adv_xclip": 0.2218836545944214, "adv_vbench": {}}}}
{"id": "42462fcdd6ee4a96b880c73c0f8222a4", "source": "vatex", "video_id": "E-gaCwIVipE_001233_001243", "video_description": "A young man with long, shoulder-length hair is sitting in a chair while a teenage girl uses a flat iron to straighten his hair. They are in a bedroom, and there is conversation happening in the background.", "task": "Counting", "clean_prompt": "Four teenage girls in a bedroom, one of them straightening a young man's hair with a flat iron while they chat.", "clean_property": {"obj": "teenage girl", "count": "four"}, "target_prompt": "One teenage girl in a bedroom, straightening a young man's hair with a flat iron while they chat.", "target_property": {"obj": "teenage girl", "count": "one"}, "evaluation_question": "Are there exactly **four** teenage girls in the bedroom?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four teenage girls in a bedroom, one of them straightening a young man's hair with a flat iron while they chat. SL+4T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb4ee7cf548a460da72a622d95a44a45.mp4", "clean_score": 1.0, "clean_xclip": 0.28334957361221313, "clean_vbench": {"subject_consistency": 0.9451077474902073, "background_consistency": 0.9431864420572916, "motion_smoothness": 0.9829926699106855, "aesthetic_quality": 0.43694281578063965, "imaging_quality": 0.7839964418995138, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dc08b9a25ad1438ca36683226abcf9cb.mp4", "adv_score": 0.0, "adv_xclip": 0.21250061690807343, "adv_vbench": {"subject_consistency": 0.910147562623024, "background_consistency": 0.9528605143229166, "motion_smoothness": 0.9804674561118172, "aesthetic_quality": 0.4009203016757965, "imaging_quality": 0.7432176333057637, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c559c7bd.mp4", "clean_score": 0.0, "clean_xclip": 0.181233212351799, "clean_vbench": {}, "adv_vid_id": "vids/3db03962.mp4", "adv_score": 1.0, "adv_xclip": 0.24184976518154144, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b1a02953.mp4", "clean_score": 0.0, "clean_xclip": 0.23066897690296173, "clean_vbench": {}, "adv_vid_id": "vids/292a8a49.mp4", "adv_score": 0.0, "adv_xclip": 0.24975831806659698, "adv_vbench": {}}}}
{"id": "36a1fa0249e04c7296a8adf781eeef6a", "source": "vatex", "video_id": "Lmwnxz5L1Eo_000007_000017", "video_description": "A group of people, including men and a woman, are singing, clapping, and dancing together in a dimly lit living room.", "task": "Counting", "clean_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person singing alone in a brightly lit room.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people singing in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room. =C\\7S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7361548de7eb42f4a9f93200d9d01f63.mp4", "clean_score": 1.0, "clean_xclip": 0.20480546355247498, "clean_vbench": {"subject_consistency": 0.8688801632573208, "background_consistency": 0.9278310139973959, "motion_smoothness": 0.9792274458426632, "aesthetic_quality": 0.48797163367271423, "imaging_quality": 0.29005883158469686, "dynamic_degree": 1.0}, "adv_vid_id": "vids/16a3562ffa1a4c348bbccdeb3653f88e.mp4", "adv_score": 0.0, "adv_xclip": 0.20184962451457977, "adv_vbench": {"subject_consistency": 0.8614480228473743, "background_consistency": 0.9233144124348959, "motion_smoothness": 0.9753673242959735, "aesthetic_quality": 0.45422518253326416, "imaging_quality": 0.30378987682108977, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/16821bb9.mp4", "clean_score": 1.0, "clean_xclip": 0.127298504114151, "clean_vbench": {}, "adv_vid_id": "vids/d7643461.mp4", "adv_score": 1.0, "adv_xclip": 0.150003582239151, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4303b7f2.mp4", "clean_score": 1.0, "clean_xclip": 0.1971863955259323, "clean_vbench": {}, "adv_vid_id": "vids/7f73b75c.mp4", "adv_score": 1.0, "adv_xclip": 0.1989859640598297, "adv_vbench": {}}}}
{"id": "4e4461c97c3d4cd9beeda384398c5917", "source": "vatex", "video_id": "vwj04OqdYNk_000039_000049", "video_description": "A young girl demonstrates and explains how to use an asthma inhaler, occasionally flailing her arms playfully.", "task": "ActionRecognition", "clean_prompt": "A girl using an inhaler while playfully flailing her arms.", "clean_property": {"obj": "girl", "action": "using inhaler", "target": null}, "target_prompt": "A girl playing with a toy while flailing her arms.", "target_property": {"obj": "girl", "action": "playing with a toy", "target": null}, "evaluation_question": "Is the girl **using an inhaler**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl using an inhaler while playfully flailing her arms. 9@>1Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a5522912f534676ae912a9f4b234f84.mp4", "clean_score": 1.0, "clean_xclip": 0.17652052640914917, "clean_vbench": {"subject_consistency": 0.8328492337216934, "background_consistency": 0.8698527018229166, "motion_smoothness": 0.9635864057267711, "aesthetic_quality": 0.5253686904907227, "imaging_quality": 0.5390693921458964, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e99ac7651ec344dbbc206f7c7680d9bb.mp4", "adv_score": 0.0, "adv_xclip": 0.13779662549495697, "adv_vbench": {"subject_consistency": 0.8214825127894679, "background_consistency": 0.9032948811848959, "motion_smoothness": 0.9621986071080952, "aesthetic_quality": 0.45082226395606995, "imaging_quality": 0.5625549110101195, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/38f23164.mp4", "clean_score": 1.0, "clean_xclip": 0.12801818549633026, "clean_vbench": {}, "adv_vid_id": "vids/fa9cd225.mp4", "adv_score": 0.0, "adv_xclip": 0.12996706366539001, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/76996e69.mp4", "clean_score": 1.0, "clean_xclip": 0.22195298969745636, "clean_vbench": {}, "adv_vid_id": "vids/2017954e.mp4", "adv_score": 0.0, "adv_xclip": 0.15781879425048828, "adv_vbench": {}}}}
{"id": "4ac7cfe6014f4af9b05d9023aac5542b", "source": "vatex", "video_id": "SL5wzs_N2t8_000020_000030", "video_description": "A person, sometimes identified as a man or policeman, is riding a Segway on a road, approaching the camera.", "task": "AttributeRecognition", "clean_prompt": "A person in uniform riding a Segway on a road, approaching the camera.", "clean_property": {"obj": "person", "attribute": "in uniform"}, "target_prompt": "A person in casual clothes riding a Segway on a road, approaching the camera.", "target_property": {"obj": "person", "attribute": "in casual clothes"}, "evaluation_question": "Is the person in **uniform**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person in uniform riding a Segway on a road, approaching the camera.dincolo gata Sofia ochi vrem", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/986a1ee9e4c84e59aa26f24c23a83eb6.mp4", "clean_score": 1.0, "clean_xclip": 0.19129779934883118, "clean_vbench": {"subject_consistency": 0.9578967895358801, "background_consistency": 0.9650624593098959, "motion_smoothness": 0.9952070435427258, "aesthetic_quality": 0.5752922892570496, "imaging_quality": 0.6661154789827307, "dynamic_degree": 0.0}, "adv_vid_id": "vids/26d66ead58954666b4631911229ac72f.mp4", "adv_score": 0.0, "adv_xclip": 0.19787336885929108, "adv_vbench": {"subject_consistency": 0.954719270269076, "background_consistency": 0.9619598388671875, "motion_smoothness": 0.9953069386447995, "aesthetic_quality": 0.5796777009963989, "imaging_quality": 0.6755947681349151, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1af67a60.mp4", "clean_score": 1.0, "clean_xclip": 0.20667381584644318, "clean_vbench": {}, "adv_vid_id": "vids/ad0f947c.mp4", "adv_score": 1.0, "adv_xclip": 0.20789258182048798, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/51cf2bc4.mp4", "clean_score": 1.0, "clean_xclip": 0.21717329323291779, "clean_vbench": {}, "adv_vid_id": "vids/1a123107.mp4", "adv_score": 1.0, "adv_xclip": 0.21567092835903168, "adv_vbench": {}}}}
{"id": "1533663df3eb4e40b53ff3b14d046804", "source": "vatex", "video_id": "Sq82j_WAYTg_000000_000010", "video_description": "A man is riding a segway with a lawn mower attached, cutting grass across a yard.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a lawn mower.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "lawn mower"}, "target_prompt": "A person further from the camera than a lawn mower.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "lawn mower"}, "evaluation_question": "Is the person closer to the camera than the lawn mower?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a lawn mower. RRQP4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c100d4428bb945a9a1bc2e7f57e08750.mp4", "clean_score": 1.0, "clean_xclip": 0.13906265795230865, "clean_vbench": {"subject_consistency": 0.8719410561025143, "background_consistency": 0.9420979817708334, "motion_smoothness": 0.9748707864318568, "aesthetic_quality": 0.48216450214385986, "imaging_quality": 0.4676831665817572, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4ea5e3a4d8714ca7bbc65c2c47c4c7a7.mp4", "adv_score": 0.0, "adv_xclip": 0.1365782618522644, "adv_vbench": {"subject_consistency": 0.9240746814757586, "background_consistency": 0.970184326171875, "motion_smoothness": 0.9940574175883059, "aesthetic_quality": 0.4612845480442047, "imaging_quality": 0.472886030236069, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f9375c8b.mp4", "clean_score": 1.0, "clean_xclip": 0.11931240558624268, "clean_vbench": {}, "adv_vid_id": "vids/0c4642ff.mp4", "adv_score": 0.0, "adv_xclip": 0.12094548344612122, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/277f3c39.mp4", "clean_score": 1.0, "clean_xclip": 0.12355662137269974, "clean_vbench": {}, "adv_vid_id": "vids/1c5e3bac.mp4", "adv_score": 1.0, "adv_xclip": 0.14091484248638153, "adv_vbench": {}}}}
{"id": "eefe3ae11acb44b1ab62e0dc79b5c1ce", "source": "vatex", "video_id": "0cmkVC2QT5Q_000031_000041", "video_description": "A young man is sitting in a chair getting his eyebrows waxed and makeup applied by a beautician in a salon setting.", "task": "ActionRecognition", "clean_prompt": "A beautician waxing eyebrows on a young man in a salon.", "clean_property": {"obj": "beautician", "action": "waxing eyebrows", "target": "young man"}, "target_prompt": "A beautician applying makeup on a young man in a salon.", "target_property": {"obj": "beautician", "action": "applying makeup", "target": "young man"}, "evaluation_question": "Is the beautician **waxing eyebrows**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A beautician waxing eyebrows on a young man in a salon. TSF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6ec8de595632471ba577d3f812f0b575.mp4", "clean_score": 1.0, "clean_xclip": 0.22029827535152435, "clean_vbench": {"subject_consistency": 0.9608622118830681, "background_consistency": 0.9777679443359375, "motion_smoothness": 0.9771301935190229, "aesthetic_quality": 0.5301492214202881, "imaging_quality": 0.7365862492152623, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c48530422c794f1a929e3bfc17a9f97e.mp4", "adv_score": 0.0, "adv_xclip": 0.21592079102993011, "adv_vbench": {"subject_consistency": 0.9591280041883389, "background_consistency": 0.966094970703125, "motion_smoothness": 0.9789740216881505, "aesthetic_quality": 0.49685198068618774, "imaging_quality": 0.7683055395009566, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ccbe4e57.mp4", "clean_score": 0.0, "clean_xclip": 0.22179557383060455, "clean_vbench": {}, "adv_vid_id": "vids/42a3cf4e.mp4", "adv_score": 0.0, "adv_xclip": 0.13260671496391296, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/af4a6552.mp4", "clean_score": 1.0, "clean_xclip": 0.21278898417949677, "clean_vbench": {}, "adv_vid_id": "vids/38a9f441.mp4", "adv_score": 1.0, "adv_xclip": 0.21067598462104797, "adv_vbench": {}}}}
{"id": "f948fc32fd0842738dd98bf13ec88d76", "source": "vatex", "video_id": "WeMpnxtS0Sw_000057_000067", "video_description": "A person is chopping mushrooms on a cutting board and placing them into a pot while music plays.", "task": "Counting", "clean_prompt": "Two people are chopping mushrooms on a cutting board and placing them into a pot while music plays.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is chopping mushrooms on a cutting board and placing them into a pot while music plays.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people chopping mushrooms?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two people are chopping mushrooms on a cutting board and placing them into a pot while music plays. U%A=/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aefa3f066b4e4b7bae300ef67fa491b4.mp4", "clean_score": 1.0, "clean_xclip": 0.19788481295108795, "clean_vbench": {"subject_consistency": 0.953498766447107, "background_consistency": 0.9516855875651041, "motion_smoothness": 0.9517007873333232, "aesthetic_quality": 0.5223402976989746, "imaging_quality": 0.7188495581490654, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5f23c4ae3e5a4af889d72a40eea1e46f.mp4", "adv_score": 0.0, "adv_xclip": 0.18158762156963348, "adv_vbench": {"subject_consistency": 0.939364843070507, "background_consistency": 0.9514261881510416, "motion_smoothness": 0.94130402211682, "aesthetic_quality": 0.57124263048172, "imaging_quality": 0.6518500627790179, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6bc27a4a.mp4", "clean_score": 1.0, "clean_xclip": 0.1657257378101349, "clean_vbench": {}, "adv_vid_id": "vids/96812b44.mp4", "adv_score": 1.0, "adv_xclip": 0.23403947055339813, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3707d443.mp4", "clean_score": 1.0, "clean_xclip": 0.19010160863399506, "clean_vbench": {}, "adv_vid_id": "vids/d5279836.mp4", "adv_score": 0.0, "adv_xclip": 0.19293993711471558, "adv_vbench": {}}}}
{"id": "e71d1d9ec2874bd193bac527c222f398", "source": "vatex", "video_id": "UFirX6T9h1Q_000013_000023", "video_description": "A man in a kitchen demonstrates how to sharpen a knife using a sharpening tool and a textured metal rod.", "task": "ActionRecognition", "clean_prompt": "A person sharpening knives in a kitchen.", "clean_property": {"obj": "person", "action": "sharpening knives", "target": null}, "target_prompt": "A person throwing knives in a kitchen.", "target_property": {"obj": "person", "action": "throwing knives", "target": null}, "evaluation_question": "Is the person **sharpening** knives?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person sharpening knives in a kitchen. plafon Netanyahu aucun Lauderdale efecte", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a3f5201c7c5464a9f8b432c650f60a9.mp4", "clean_score": 1.0, "clean_xclip": 0.21542729437351227, "clean_vbench": {"subject_consistency": 0.9303513647367557, "background_consistency": 0.9548390706380209, "motion_smoothness": 0.9315593264279736, "aesthetic_quality": 0.43653568625450134, "imaging_quality": 0.3744771513646963, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5bb39db35b5244969cc5fa6cfb315b94.mp4", "adv_score": 0.0, "adv_xclip": 0.21664828062057495, "adv_vbench": {"subject_consistency": 0.904176190495491, "background_consistency": 0.9415130615234375, "motion_smoothness": 0.9312684107207698, "aesthetic_quality": 0.41564393043518066, "imaging_quality": 0.3541895002248336, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e8f07ffe.mp4", "clean_score": 1.0, "clean_xclip": 0.2096388041973114, "clean_vbench": {}, "adv_vid_id": "vids/6e69f470.mp4", "adv_score": 1.0, "adv_xclip": 0.21711395680904388, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d2ff880c.mp4", "clean_score": 0.0, "clean_xclip": 0.23197461664676666, "clean_vbench": {}, "adv_vid_id": "vids/7e6c6995.mp4", "adv_score": 0.0, "adv_xclip": 0.23098886013031006, "adv_vbench": {}}}}
{"id": "204792ad656b4dfc9ea1e4ed638a7e9c", "source": "vatex", "video_id": "wsR8fc9pBR4_000007_000017", "video_description": "A person is preparing to roast a marshmallow by placing it on a stick and holding it over coals outdoors.", "task": "ActionRecognition", "clean_prompt": "A person roasting marshmallows over coals outdoors.", "clean_property": {"obj": "person", "action": "roasting marshmallows", "target": null}, "target_prompt": "A person eating marshmallows outdoors.", "target_property": {"obj": "person", "action": "eating marshmallows", "target": null}, "evaluation_question": "Is the person **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person roasting marshmallows over coals outdoors. SL)IV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6812f07506b2424298d962b9e0722a2a.mp4", "clean_score": 1.0, "clean_xclip": 0.2550274133682251, "clean_vbench": {"subject_consistency": 0.9550607527295748, "background_consistency": 0.97625732421875, "motion_smoothness": 0.9543355198625232, "aesthetic_quality": 0.673742949962616, "imaging_quality": 0.6548777093692703, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8ce268889e494355b6d1c0caf19280ce.mp4", "adv_score": 0.0, "adv_xclip": 0.22066009044647217, "adv_vbench": {"subject_consistency": 0.9656220208853483, "background_consistency": 0.9741973876953125, "motion_smoothness": 0.9497506289777999, "aesthetic_quality": 0.6249305605888367, "imaging_quality": 0.6385226619486906, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bfc90f34.mp4", "clean_score": 1.0, "clean_xclip": 0.24069301784038544, "clean_vbench": {}, "adv_vid_id": "vids/fe724278.mp4", "adv_score": 0.0, "adv_xclip": 0.22863440215587616, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/649cdafd.mp4", "clean_score": 0.0, "clean_xclip": 0.21405723690986633, "clean_vbench": {}, "adv_vid_id": "vids/f9ef2981.mp4", "adv_score": 0.0, "adv_xclip": 0.23050382733345032, "adv_vbench": {}}}}
{"id": "ea2f3bcedab74767ad2ed35646016dac", "source": "vatex", "video_id": "Lmwnxz5L1Eo_000007_000017", "video_description": "A group of people, including men and a woman, are singing, clapping, and dancing together in a dimly lit living room.", "task": "Counting", "clean_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person singing alone in a brightly lit room.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people singing in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room. enthaltenionen Fotografi positif usor", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16df6092d9664ac09b011d0854687a2a.mp4", "clean_score": 1.0, "clean_xclip": 0.20480546355247498, "clean_vbench": {"subject_consistency": 0.8688801632573208, "background_consistency": 0.9278310139973959, "motion_smoothness": 0.9792274458426632, "aesthetic_quality": 0.48797163367271423, "imaging_quality": 0.29005883158469686, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1b570e73770841e38aa3ced115e6a19b.mp4", "adv_score": 0.0, "adv_xclip": 0.18774381279945374, "adv_vbench": {"subject_consistency": 0.9255873473982016, "background_consistency": 0.920867919921875, "motion_smoothness": 0.9782709438102658, "aesthetic_quality": 0.4860013425350189, "imaging_quality": 0.23957164024820135, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a02d07f8.mp4", "clean_score": 1.0, "clean_xclip": 0.14476333558559418, "clean_vbench": {}, "adv_vid_id": "vids/56ff6fb7.mp4", "adv_score": 1.0, "adv_xclip": 0.17915958166122437, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/99381018.mp4", "clean_score": 0.0, "clean_xclip": 0.18361413478851318, "clean_vbench": {}, "adv_vid_id": "vids/f8b910fd.mp4", "adv_score": 1.0, "adv_xclip": 0.14811429381370544, "adv_vbench": {}}}}
{"id": "1703e28b4677420089422ba726f9a4b3", "source": "vatex", "video_id": "i3notciKv3w_000240_000250", "video_description": "A woman and a child are roasting marshmallows over a gas stove. The woman is melting marshmallows while the child watches and participates by sticking marshmallows onto a metal stick and melting them under the flame.", "task": "ActionRecognition", "clean_prompt": "A child roasting marshmallows over a gas stove.", "clean_property": {"obj": "child", "action": "roasting marshmallows", "target": null}, "target_prompt": "A child burning marshmallows over a campfire.", "target_property": {"obj": "child", "action": "burning marshmallows", "target": null}, "evaluation_question": "Is the child **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child roasting marshmallows over a gas stove. FE@9M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/391afdd4105c4f8a9322d4b5ddd31a47.mp4", "clean_score": 1.0, "clean_xclip": 0.17207682132720947, "clean_vbench": {"subject_consistency": 0.9360793822755417, "background_consistency": 0.9607340494791666, "motion_smoothness": 0.964526322823368, "aesthetic_quality": 0.5604506134986877, "imaging_quality": 0.6136277841061962, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e53711f3ee3c4b898b53e38adb4e743f.mp4", "adv_score": 0.0, "adv_xclip": 0.19186966121196747, "adv_vbench": {"subject_consistency": 0.9410793998589119, "background_consistency": 0.9571126302083334, "motion_smoothness": 0.958388200969045, "aesthetic_quality": 0.5557829141616821, "imaging_quality": 0.5567928283068598, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ad9a7fa2.mp4", "clean_score": 0.0, "clean_xclip": 0.22160565853118896, "clean_vbench": {}, "adv_vid_id": "vids/aabbf093.mp4", "adv_score": 1.0, "adv_xclip": 0.26138508319854736, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7c139380.mp4", "clean_score": 0.0, "clean_xclip": 0.21142512559890747, "clean_vbench": {}, "adv_vid_id": "vids/90089ab2.mp4", "adv_score": 1.0, "adv_xclip": 0.22471117973327637, "adv_vbench": {}}}}
{"id": "d3f3bd28d8404501807a73e8ab662c57", "source": "vatex", "video_id": "1M_ehUdQbpE_000000_000010", "video_description": "A young man in a red shirt and headband is spray painting graffiti on a cement wall outdoors while music plays.", "task": "ActionRecognition", "clean_prompt": "A person tagging graffiti on a cement wall outdoors.", "clean_property": {"obj": "person", "action": "tagging graffiti", "target": "wall"}, "target_prompt": "A person cleaning graffiti off a cement wall outdoors.", "target_property": {"obj": "person", "action": "cleaning graffiti", "target": "wall"}, "evaluation_question": "Is the person **tagging** graffiti?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person tagging graffiti on a cement wall outdoors. LY?7G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35c16e6a413f4335a901d774c6b74888.mp4", "clean_score": 1.0, "clean_xclip": 0.20431886613368988, "clean_vbench": {"subject_consistency": 0.9878195337951183, "background_consistency": 0.9855550130208334, "motion_smoothness": 0.996241136787148, "aesthetic_quality": 0.48060670495033264, "imaging_quality": 0.4960939352852957, "dynamic_degree": 0.0}, "adv_vid_id": "vids/beb6fdc6efa04ba8b59fdaeae3169e23.mp4", "adv_score": 0.0, "adv_xclip": 0.1824011653661728, "adv_vbench": {"subject_consistency": 0.9972893868883451, "background_consistency": 0.99224853515625, "motion_smoothness": 0.995921532537269, "aesthetic_quality": 0.45225462317466736, "imaging_quality": 0.32968431122448977, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2554dae9.mp4", "clean_score": 1.0, "clean_xclip": 0.18204842507839203, "clean_vbench": {}, "adv_vid_id": "vids/29d60eac.mp4", "adv_score": 1.0, "adv_xclip": 0.14968781173229218, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2194bd47.mp4", "clean_score": 1.0, "clean_xclip": 0.16521768271923065, "clean_vbench": {}, "adv_vid_id": "vids/a2c146a2.mp4", "adv_score": 0.0, "adv_xclip": 0.20388031005859375, "adv_vbench": {}}}}
{"id": "fa22fab35cf848598bdca534e82ab225", "source": "vatex", "video_id": "x2JkxZT9AMQ_000000_000010", "video_description": "A little boy sneezes and smiles in a room with a man sitting at a table using a computer. A woman is also present, laughing, and a baby is nearby with a stuffed toy.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the left of a woman in a room.", "clean_property": {"obj_1": "boy", "relation": "left of", "obj_2": "woman"}, "target_prompt": "A boy standing to the right of a woman in a room.", "target_property": {"obj_1": "boy", "relation": "right of", "obj_2": "woman"}, "evaluation_question": "Is the boy to the **left** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A boy standing to the left of a woman in a room. )!0UD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6191209e07f4313b7c5f8ac862d8880.mp4", "clean_score": 1.0, "clean_xclip": 0.11778914928436279, "clean_vbench": {"subject_consistency": 0.9304392381260792, "background_consistency": 0.9346262613932291, "motion_smoothness": 0.992034085679668, "aesthetic_quality": 0.4975390136241913, "imaging_quality": 0.42075081338687814, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6d83aee5006545779fdf39e5e763fe0f.mp4", "adv_score": 0.0, "adv_xclip": 0.13346895575523376, "adv_vbench": {"subject_consistency": 0.9825142609576384, "background_consistency": 0.9686126708984375, "motion_smoothness": 0.9912662854976095, "aesthetic_quality": 0.526641309261322, "imaging_quality": 0.7646311452437421, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e6d8dfdd.mp4", "clean_score": 0.0, "clean_xclip": 0.13303951919078827, "clean_vbench": {}, "adv_vid_id": "vids/800348a7.mp4", "adv_score": 0.0, "adv_xclip": 0.15930011868476868, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c0d426ce.mp4", "clean_score": 0.0, "clean_xclip": 0.17605409026145935, "clean_vbench": {}, "adv_vid_id": "vids/4728bf0d.mp4", "adv_score": 1.0, "adv_xclip": 0.17154741287231445, "adv_vbench": {}}}}
{"id": "ee33fbda9d734ff7b5b94e63853e9c3e", "source": "vatex", "video_id": "V77pj1em6yI_000087_000097", "video_description": "A woman and a child are playing kickball in a backyard, passing the ball back and forth.", "task": "ActionRecognition", "clean_prompt": "A woman playing kickball in a backyard.", "clean_property": {"obj": "woman", "action": "playing kickball", "target": "ball"}, "target_prompt": "A woman kicking a ball towards a goal in a backyard.", "target_property": {"obj": "woman", "action": "kicking a ball", "target": "goal"}, "evaluation_question": "Is the woman **playing kickball**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman playing kickball in a backyard. TH?27", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9fdc82ccd8144f1dbfea3e54a783da25.mp4", "clean_score": 1.0, "clean_xclip": 0.15521740913391113, "clean_vbench": {"subject_consistency": 0.8835564473023018, "background_consistency": 0.9031728108723959, "motion_smoothness": 0.9599071959094853, "aesthetic_quality": 0.47513633966445923, "imaging_quality": 0.5382608273564553, "dynamic_degree": 1.0}, "adv_vid_id": "vids/08689a2a32b147ab85752c0115160974.mp4", "adv_score": 0.0, "adv_xclip": 0.17830735445022583, "adv_vbench": {"subject_consistency": 0.8996629932274421, "background_consistency": 0.8910624186197916, "motion_smoothness": 0.9526282326716694, "aesthetic_quality": 0.48132768273353577, "imaging_quality": 0.6382124577736368, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/002373a5.mp4", "clean_score": 0.0, "clean_xclip": 0.20081806182861328, "clean_vbench": {}, "adv_vid_id": "vids/024daa64.mp4", "adv_score": 0.0, "adv_xclip": 0.13587769865989685, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bfafa57a.mp4", "clean_score": 0.0, "clean_xclip": 0.2002403438091278, "clean_vbench": {}, "adv_vid_id": "vids/9d6715db.mp4", "adv_score": 0.0, "adv_xclip": 0.18154841661453247, "adv_vbench": {}}}}
{"id": "eeb461afc6714729b9fce3fe75ae822d", "source": "vatex", "video_id": "aOq--ppDs2Y_000030_000040", "video_description": "Two friends are sitting on a couch. One man is using his phone to play a game while the other tries to distract him by putting his foot in the man's face.", "task": "Counting", "clean_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene.", "clean_property": {"obj": "man_1", "count": "five"}, "target_prompt": "Two men are sitting on a couch, one playing a game on his phone while the other tries to distract him.", "target_property": {"obj": "man", "count": "two"}, "evaluation_question": "Are there exactly **five** men in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene. #+TYU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f2619b6568bd4d90b5568beb083c9df3.mp4", "clean_score": 1.0, "clean_xclip": 0.09329067915678024, "clean_vbench": {"subject_consistency": 0.8882350052396456, "background_consistency": 0.9175516764322916, "motion_smoothness": 0.9666882671921649, "aesthetic_quality": 0.5398931503295898, "imaging_quality": 0.582497824844049, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3bacd83a1d5e4579b460377a6f4339da.mp4", "adv_score": 0.0, "adv_xclip": 0.23146843910217285, "adv_vbench": {"subject_consistency": 0.9404822854946057, "background_consistency": 0.9420420328776041, "motion_smoothness": 0.9617749633739813, "aesthetic_quality": 0.5270286202430725, "imaging_quality": 0.6155769566127232, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1738a822.mp4", "clean_score": 0.0, "clean_xclip": 0.16718146204948425, "clean_vbench": {}, "adv_vid_id": "vids/82c2b67f.mp4", "adv_score": 0.0, "adv_xclip": 0.16995520889759064, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/514239e9.mp4", "clean_score": 0.0, "clean_xclip": 0.20998474955558777, "clean_vbench": {}, "adv_vid_id": "vids/cdd3845b.mp4", "adv_score": 0.0, "adv_xclip": 0.13566282391548157, "adv_vbench": {}}}}
{"id": "1374f0bd73e5446f9173fbdb8f3213ec", "source": "vatex", "video_id": "cm66wB7giOM_000000_000010", "video_description": "A group of people, including children, are playing kickball in a grassy field. The game involves rolling, kicking, and catching the ball.", "task": "AttributeRecognition", "clean_prompt": "A person playing kickball in a grassy field.", "clean_property": {"obj": "person", "attribute": "man"}, "target_prompt": "A woman playing kickball in a sandy beach.", "target_property": {"obj": "person", "attribute": "woman"}, "evaluation_question": "Is the person playing kickball a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing kickball in a grassy field. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/700ca6b476f140b08ccec6b4c6baa155.mp4", "clean_score": 1.0, "clean_xclip": 0.15020957589149475, "clean_vbench": {"subject_consistency": 0.8892113311837117, "background_consistency": 0.9191741943359375, "motion_smoothness": 0.9682590192359094, "aesthetic_quality": 0.4621061086654663, "imaging_quality": 0.5527636119297573, "dynamic_degree": 1.0}, "adv_vid_id": "vids/17fa87f422e84c5a83332a0dbb5c23ac.mp4", "adv_score": 0.0, "adv_xclip": 0.1151566207408905, "adv_vbench": {"subject_consistency": 0.8392050645003716, "background_consistency": 0.9049326578776041, "motion_smoothness": 0.9489227443163479, "aesthetic_quality": 0.45107734203338623, "imaging_quality": 0.5441059719786352, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/296488f7.mp4", "clean_score": 0.0, "clean_xclip": 0.13120920956134796, "clean_vbench": {}, "adv_vid_id": "vids/07defc79.mp4", "adv_score": 0.0, "adv_xclip": 0.19804033637046814, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/72b9845a.mp4", "clean_score": 0.0, "clean_xclip": 0.2469288408756256, "clean_vbench": {}, "adv_vid_id": "vids/f8125c7b.mp4", "adv_score": 0.0, "adv_xclip": 0.16893497109413147, "adv_vbench": {}}}}
{"id": "3fc8bda9f2094861ae19343a30a3f8bb", "source": "vatex", "video_id": "r4sYfEcGrgg_000004_000014", "video_description": "A female athlete is participating in a javelin throw event at an outdoor track. She runs and throws the javelin with force while a group of people watches.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the left of a javelin.", "clean_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "javelin"}, "target_prompt": "An athlete standing to the right of a javelin.", "target_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "javelin"}, "evaluation_question": "Is the athlete to the **left** of the javelin?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "An athlete standing to the left of a javelin. -S'LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e9f38a6f2032496fb48763e1a4bbcf49.mp4", "clean_score": 1.0, "clean_xclip": 0.16777874529361725, "clean_vbench": {"subject_consistency": 0.9485111758112907, "background_consistency": 0.9692331949869791, "motion_smoothness": 0.9938784342408518, "aesthetic_quality": 0.3467642366886139, "imaging_quality": 0.6008430846856565, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ded2bd8710c84faca47326ef76e39ae2.mp4", "adv_score": 0.0, "adv_xclip": 0.1417318880558014, "adv_vbench": {"subject_consistency": 0.9557082615792751, "background_consistency": 0.97283935546875, "motion_smoothness": 0.9907486065092189, "aesthetic_quality": 0.4971340596675873, "imaging_quality": 0.6319934494641363, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/abeb6eaa.mp4", "clean_score": 1.0, "clean_xclip": 0.1687096506357193, "clean_vbench": {}, "adv_vid_id": "vids/95242be5.mp4", "adv_score": 0.0, "adv_xclip": 0.1703384518623352, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/68bcb9c9.mp4", "clean_score": 0.0, "clean_xclip": 0.20690543949604034, "clean_vbench": {}, "adv_vid_id": "vids/c550b657.mp4", "adv_score": 0.0, "adv_xclip": 0.16838005185127258, "adv_vbench": {}}}}
{"id": "43e0c533856b4390b8a58ce33c44d225", "source": "vatex", "video_id": "3xI6BK_hKXs_000004_000014", "video_description": "A man is demonstrating and explaining how to perform arm stretching exercises in a room with a painting of a blossom tree.", "task": "ActionRecognition", "clean_prompt": "A person stretching their arm in a room with a painting of a blossom tree.", "clean_property": {"obj": "person", "action": "stretching arm", "target": null}, "target_prompt": "A person lifting their arm in a room with a painting of a blossom tree.", "target_property": {"obj": "person", "action": "lifting arm", "target": null}, "evaluation_question": "Is the person **stretching their arm**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person stretching their arm in a room with a painting of a blossom tree. Siemens  Karlsruhe Syracuse Paol", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8b0097dad864057a3afa8813d868f6e.mp4", "clean_score": 1.0, "clean_xclip": 0.25093844532966614, "clean_vbench": {"subject_consistency": 0.9094562428072095, "background_consistency": 0.9419657389322916, "motion_smoothness": 0.9904196479678549, "aesthetic_quality": 0.4646361768245697, "imaging_quality": 0.6072948424670161, "dynamic_degree": 0.0}, "adv_vid_id": "vids/9effe53a7fcc4410a3d4c93812e34442.mp4", "adv_score": 0.0, "adv_xclip": 0.21884098649024963, "adv_vbench": {"subject_consistency": 0.9990256757785877, "background_consistency": 0.99786376953125, "motion_smoothness": 0.9976924260734386, "aesthetic_quality": 0.5566964149475098, "imaging_quality": 0.6015625840790417, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/950f8476.mp4", "clean_score": 1.0, "clean_xclip": 0.2322167307138443, "clean_vbench": {}, "adv_vid_id": "vids/8c96fbe5.mp4", "adv_score": 1.0, "adv_xclip": 0.2056492567062378, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cf956ca6.mp4", "clean_score": 1.0, "clean_xclip": 0.18462392687797546, "clean_vbench": {}, "adv_vid_id": "vids/fd0217d1.mp4", "adv_score": 1.0, "adv_xclip": 0.2316015660762787, "adv_vbench": {}}}}
{"id": "3626d0177afe4f1e9009b60b53d695d3", "source": "vatex", "video_id": "v6MBrnO1qyg_000010_000020", "video_description": "A person is kayaking on a river with large rocky banks and formations, navigating through a rocky coastline.", "task": "AttributeRecognition", "clean_prompt": "A person kayaking on a river with large rocky banks.", "clean_property": {"obj": "rock", "attribute": "large"}, "target_prompt": "A person kayaking on a river with small rocky banks.", "target_property": {"obj": "rock", "attribute": "small"}, "evaluation_question": "Are the banks of the river made of **large** rocks?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person kayaking on a river with large rocky banks. Gartenwurf automatique klickenleuchte", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d286828836134adf9aee66881ca60aed.mp4", "clean_score": 1.0, "clean_xclip": 0.20038901269435883, "clean_vbench": {"subject_consistency": 0.9672831632196903, "background_consistency": 0.975555419921875, "motion_smoothness": 0.9644656826497318, "aesthetic_quality": 0.5311853289604187, "imaging_quality": 0.7982757568359375, "dynamic_degree": 1.0}, "adv_vid_id": "vids/cc9e995cc4ad40c9b19248f1238282f9.mp4", "adv_score": 0.0, "adv_xclip": 0.1953013837337494, "adv_vbench": {"subject_consistency": 0.9214562407384316, "background_consistency": 0.9614613850911459, "motion_smoothness": 0.9672331815024107, "aesthetic_quality": 0.5176187753677368, "imaging_quality": 0.7868568420410156, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c167f3b7.mp4", "clean_score": 1.0, "clean_xclip": 0.19744694232940674, "clean_vbench": {}, "adv_vid_id": "vids/0165e2ea.mp4", "adv_score": 1.0, "adv_xclip": 0.19909575581550598, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ebdb223e.mp4", "clean_score": 1.0, "clean_xclip": 0.20333662629127502, "clean_vbench": {}, "adv_vid_id": "vids/03f766b2.mp4", "adv_score": 1.0, "adv_xclip": 0.20626875758171082, "adv_vbench": {}}}}
{"id": "25a4c2f16ee74149aa272ab8e4303a9e", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "Counting", "clean_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper.", "clean_property": {"obj": "paper", "count": "three"}, "target_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on one sheet of paper.", "target_property": {"obj": "paper", "count": "one"}, "evaluation_question": "Are there exactly **three** sheets of paper being used?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper. FE2MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e1d04ff50c5242fab05f84f6721e45c3.mp4", "clean_score": 1.0, "clean_xclip": 0.15169933438301086, "clean_vbench": {"subject_consistency": 0.948447635397315, "background_consistency": 0.9648640950520834, "motion_smoothness": 0.9780856347522291, "aesthetic_quality": 0.24040162563323975, "imaging_quality": 0.690891755551708, "dynamic_degree": 1.0}, "adv_vid_id": "vids/928e421744894cc2b0336a3d3ffe86fe.mp4", "adv_score": 0.0, "adv_xclip": 0.14453691244125366, "adv_vbench": {"subject_consistency": 0.9487982696543137, "background_consistency": 0.9682820638020834, "motion_smoothness": 0.9809365950662672, "aesthetic_quality": 0.18842248618602753, "imaging_quality": 0.678601764756806, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ef14e2b6.mp4", "clean_score": 0.0, "clean_xclip": 0.14086562395095825, "clean_vbench": {}, "adv_vid_id": "vids/1612a774.mp4", "adv_score": 0.0, "adv_xclip": 0.15547172725200653, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d48ed21f.mp4", "clean_score": 0.0, "clean_xclip": 0.1624685674905777, "clean_vbench": {}, "adv_vid_id": "vids/ef09eb3d.mp4", "adv_score": 1.0, "adv_xclip": 0.1758894920349121, "adv_vbench": {}}}}
{"id": "67ad2776716142bda7af5c00e5daf465", "source": "vatex", "video_id": "MFt0MwJGTxU_000000_000010", "video_description": "A young boy is sitting in a room, smoking from a hookah pipe and exhaling smoke.", "task": "Counting", "clean_prompt": "Five people are sitting in a room, one of them is smoking from a hookah pipe and exhaling smoke.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person is sitting in a room, smoking from a hookah pipe and exhaling smoke.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Five people are sitting in a room, one of them is smoking from a hookah pipe and exhaling smoke. 7*F7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11a4b4af2a8f45e4b424d9b99df11e2a.mp4", "clean_score": 1.0, "clean_xclip": 0.24563553929328918, "clean_vbench": {"subject_consistency": 0.9491502723346154, "background_consistency": 0.953155517578125, "motion_smoothness": 0.9935763458643488, "aesthetic_quality": 0.6254234313964844, "imaging_quality": 0.5882028797694615, "dynamic_degree": 0.0}, "adv_vid_id": "vids/40d6a759add443bcb613f19d19394314.mp4", "adv_score": 0.0, "adv_xclip": 0.22396904230117798, "adv_vbench": {"subject_consistency": 0.9886111449450254, "background_consistency": 0.9679718017578125, "motion_smoothness": 0.9955023206459795, "aesthetic_quality": 0.5894424319267273, "imaging_quality": 0.6343924098112145, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/41ad4255.mp4", "clean_score": 1.0, "clean_xclip": 0.18298275768756866, "clean_vbench": {}, "adv_vid_id": "vids/514ca044.mp4", "adv_score": 1.0, "adv_xclip": 0.17042165994644165, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/822d69cf.mp4", "clean_score": 0.0, "clean_xclip": 0.23344825208187103, "clean_vbench": {}, "adv_vid_id": "vids/ca350feb.mp4", "adv_score": 1.0, "adv_xclip": 0.24313879013061523, "adv_vbench": {}}}}
{"id": "d0499ee38ff4436b9d4b5be50363ec5d", "source": "vatex", "video_id": "5379yXlh9og_000000_000010", "video_description": "A male athlete is practicing and performing long jump and triple jump on an outdoor track, landing in a sand pit.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the right of a sand pit.", "clean_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "sand pit"}, "target_prompt": "An athlete standing to the left of a sand pit.", "target_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "sand pit"}, "evaluation_question": "Is the athlete to the **right** of the sand pit?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An athlete standing to the right of a sand pit.hidrat Klaus Stahl asistent Nelson", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6218dba3d37d428891573a5f002aa26a.mp4", "clean_score": 1.0, "clean_xclip": 0.19530421495437622, "clean_vbench": {"subject_consistency": 0.9511858448386192, "background_consistency": 0.9495697021484375, "motion_smoothness": 0.9877667948577321, "aesthetic_quality": 0.5906906127929688, "imaging_quality": 0.7595922088623047, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2533893609bd4fc9adafb1edbf5fafc5.mp4", "adv_score": 0.0, "adv_xclip": 0.15866103768348694, "adv_vbench": {"subject_consistency": 0.9739219540109237, "background_consistency": 0.9719340006510416, "motion_smoothness": 0.9940771723137557, "aesthetic_quality": 0.5631518363952637, "imaging_quality": 0.7201287966358418, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/32aeae53.mp4", "clean_score": 0.0, "clean_xclip": 0.2062206119298935, "clean_vbench": {}, "adv_vid_id": "vids/17e751b8.mp4", "adv_score": 0.0, "adv_xclip": 0.18512104451656342, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/06735fcf.mp4", "clean_score": 0.0, "clean_xclip": 0.18857775628566742, "clean_vbench": {}, "adv_vid_id": "vids/6a9c78df.mp4", "adv_score": 0.0, "adv_xclip": 0.2126024216413498, "adv_vbench": {}}}}
{"id": "3d9d8eff7c3d4376abb5b6ac392175df", "source": "vatex", "video_id": "WAo0uqgDUUo_000000_000010", "video_description": "A man is outside a house cleaning a large window using a squeegee.", "task": "ObjectRecognition", "clean_prompt": "A man outside a house cleaning a large window using a squeegee.", "clean_property": {"obj": "squeegee"}, "target_prompt": "A man outside a house painting a large wall using a paint roller.", "target_property": {"obj": "paint roller"}, "evaluation_question": "Is the man using a **squeegee** to clean the window?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man outside a house cleaning a large window using a squeegee. minimalist bedding Sauna Accommodation Zimbabwe", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42e311346c334fb5804a4d67e1e5f3c7.mp4", "clean_score": 1.0, "clean_xclip": 0.23602482676506042, "clean_vbench": {"subject_consistency": 0.9085065585871538, "background_consistency": 0.9514821370442709, "motion_smoothness": 0.9791935018445393, "aesthetic_quality": 0.43859660625457764, "imaging_quality": 0.6793786963637994, "dynamic_degree": 1.0}, "adv_vid_id": "vids/27caadefb3054a6abd64da840ca21d4b.mp4", "adv_score": 0.0, "adv_xclip": 0.22479668259620667, "adv_vbench": {"subject_consistency": 0.949730895459652, "background_consistency": 0.9607442220052084, "motion_smoothness": 0.9893216922796639, "aesthetic_quality": 0.5163469910621643, "imaging_quality": 0.64589797584378, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f2dfd947.mp4", "clean_score": 1.0, "clean_xclip": 0.2283976525068283, "clean_vbench": {}, "adv_vid_id": "vids/f6472683.mp4", "adv_score": 1.0, "adv_xclip": 0.23897013068199158, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6ae0b089.mp4", "clean_score": 1.0, "clean_xclip": 0.23554366827011108, "clean_vbench": {}, "adv_vid_id": "vids/f38924a4.mp4", "adv_score": 1.0, "adv_xclip": 0.22006231546401978, "adv_vbench": {}}}}
{"id": "337f98699c9243f4a4f671c6b230d453", "source": "vatex", "video_id": "FQH-fHyEBmc_000019_000029", "video_description": "A person in protective gear is using various hoses to clean and treat a wooden structure, including the underside of a roof and walls, with water, air, and chemicals.", "task": "Counting", "clean_prompt": "Three people in protective gear are using various hoses to clean and treat a wooden structure.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in protective gear is using a hose to clean a wooden structure.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in protective gear cleaning the structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in protective gear are using various hoses to clean and treat a wooden structure. !/!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8506fba474d418fbf51faaf42988e13.mp4", "clean_score": 1.0, "clean_xclip": 0.1642848402261734, "clean_vbench": {"subject_consistency": 0.9538961295038462, "background_consistency": 0.9578297932942709, "motion_smoothness": 0.9771038453222081, "aesthetic_quality": 0.5038642287254333, "imaging_quality": 0.7401446455352161, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9b66616b29324a51b17d12b97cea5bab.mp4", "adv_score": 0.0, "adv_xclip": 0.1846691370010376, "adv_vbench": {"subject_consistency": 0.9613679045190414, "background_consistency": 0.9714711507161459, "motion_smoothness": 0.9823141147598443, "aesthetic_quality": 0.5560849905014038, "imaging_quality": 0.7625910280188735, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/aa58c7f3.mp4", "clean_score": 0.0, "clean_xclip": 0.17920458316802979, "clean_vbench": {}, "adv_vid_id": "vids/d6c41c9a.mp4", "adv_score": 0.0, "adv_xclip": 0.16096478700637817, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/17f0611a.mp4", "clean_score": 1.0, "clean_xclip": 0.167955219745636, "clean_vbench": {}, "adv_vid_id": "vids/ce587482.mp4", "adv_score": 1.0, "adv_xclip": 0.17801982164382935, "adv_vbench": {}}}}
{"id": "c46488e867a34d6b9d8adca1bbb5d1a8", "source": "vatex", "video_id": "14J5Jix2IFc_000000_000010", "video_description": "A young African American man is sitting in a room by himself, playing a song on a trumpet while wearing a Nike shirt.", "task": "ActionRecognition", "clean_prompt": "A person playing trumpet in a room.", "clean_property": {"obj": "person", "action": "playing trumpet", "target": null}, "target_prompt": "A person playing guitar in a room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing trumpet in a room. gourmandfotografatiile PsychologyUploaded", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8eaefd7d539f47f4b62a74c8208f151d.mp4", "clean_score": 1.0, "clean_xclip": 0.2079712450504303, "clean_vbench": {"subject_consistency": 0.9484687137107054, "background_consistency": 0.9559275309244791, "motion_smoothness": 0.9691967635144336, "aesthetic_quality": 0.522311270236969, "imaging_quality": 0.5800534695995097, "dynamic_degree": 1.0}, "adv_vid_id": "vids/651bcecbb2534570b0e261544b2e274c.mp4", "adv_score": 0.0, "adv_xclip": 0.15572291612625122, "adv_vbench": {"subject_consistency": 0.8998880957563719, "background_consistency": 0.937164306640625, "motion_smoothness": 0.9548663758649035, "aesthetic_quality": 0.4367234408855438, "imaging_quality": 0.4296868047908861, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7f9ba956.mp4", "clean_score": 1.0, "clean_xclip": 0.2164505273103714, "clean_vbench": {}, "adv_vid_id": "vids/b4aef76e.mp4", "adv_score": 0.0, "adv_xclip": 0.24600088596343994, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f882cf06.mp4", "clean_score": 1.0, "clean_xclip": 0.24032126367092133, "clean_vbench": {}, "adv_vid_id": "vids/7645cce6.mp4", "adv_score": 1.0, "adv_xclip": 0.24303695559501648, "adv_vbench": {}}}}
{"id": "98b946ef1c114e8b8cec394ef3f71665", "source": "vatex", "video_id": "53C61ZUEbSo_000063_000073", "video_description": "A young girl is demonstrating and explaining the features of a mini microscope, speaking in a foreign language.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a microscope, demonstrating its features.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "microscope"}, "target_prompt": "A person further from the camera than a microscope, demonstrating its features.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "microscope"}, "evaluation_question": "Is the person closer to the camera than the microscope?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person closer to the camera than a microscope, demonstrating its features. paar Saskatchewan renewable Sustainability finition", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9bdb0763830645c78ad183a14d6bc3bb.mp4", "clean_score": 1.0, "clean_xclip": 0.11709113419055939, "clean_vbench": {"subject_consistency": 0.9957896477232376, "background_consistency": 0.9951731363932291, "motion_smoothness": 0.9929947149159304, "aesthetic_quality": 0.5235867500305176, "imaging_quality": 0.4344851489942901, "dynamic_degree": 0.0}, "adv_vid_id": "vids/fe7aea54110d439fbf0d8ca65621a29c.mp4", "adv_score": 0.0, "adv_xclip": 0.10849098861217499, "adv_vbench": {"subject_consistency": 0.9981869012117386, "background_consistency": 0.9942576090494791, "motion_smoothness": 0.9972633759039882, "aesthetic_quality": 0.27359864115715027, "imaging_quality": 0.40079382838035116, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/647a24c7.mp4", "clean_score": 0.0, "clean_xclip": 0.08710457384586334, "clean_vbench": {}, "adv_vid_id": "vids/e60fcf02.mp4", "adv_score": 1.0, "adv_xclip": 0.16788816452026367, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ad61928c.mp4", "clean_score": 1.0, "clean_xclip": 0.14944049715995789, "clean_vbench": {}, "adv_vid_id": "vids/9f0f1974.mp4", "adv_score": 1.0, "adv_xclip": 0.14614510536193848, "adv_vbench": {}}}}
{"id": "926129c27405410ab7ece290f1676f3b", "source": "vatex", "video_id": "dGNTOn_sisg_000089_000099", "video_description": "A young child is in a kitchen demonstrating how to prepare cookie dough on baking trays. There are mounds of dough on a baking tray on a counter, and the child is giving instructions while another person places balls of brown dough on a tray. The child talks about the process and occasionally eats some dough.", "task": "Counting", "clean_prompt": "A young child is demonstrating how to prepare cookie dough on two baking trays in a kitchen.", "clean_property": {"obj": "baking tray", "count": "two"}, "target_prompt": "A young child is demonstrating how to prepare cookie dough on one baking tray in a kitchen.", "target_property": {"obj": "baking tray", "count": "one"}, "evaluation_question": "Are there exactly **two** baking trays in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young child is demonstrating how to prepare cookie dough on two baking trays in a kitchen. awkwardnnielosigkeit Bean chimic", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/88d6690b36174c1a87c12b610066c9b0.mp4", "clean_score": 1.0, "clean_xclip": 0.19121819734573364, "clean_vbench": {"subject_consistency": 0.9660218929251035, "background_consistency": 0.9679718017578125, "motion_smoothness": 0.9803398297236847, "aesthetic_quality": 0.5454046130180359, "imaging_quality": 0.6477284396424585, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4a4b6384800749eeae68a920108312f8.mp4", "adv_score": 0.0, "adv_xclip": 0.21048185229301453, "adv_vbench": {"subject_consistency": 0.952510948603352, "background_consistency": 0.968963623046875, "motion_smoothness": 0.9747589219972969, "aesthetic_quality": 0.5312308669090271, "imaging_quality": 0.586616912374691, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b9356a2d.mp4", "clean_score": 1.0, "clean_xclip": 0.22658947110176086, "clean_vbench": {}, "adv_vid_id": "vids/0a2f715d.mp4", "adv_score": 0.0, "adv_xclip": 0.23558837175369263, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6b030509.mp4", "clean_score": 1.0, "clean_xclip": 0.2340908795595169, "clean_vbench": {}, "adv_vid_id": "vids/df9b5b5c.mp4", "adv_score": 0.0, "adv_xclip": 0.22775965929031372, "adv_vbench": {}}}}
{"id": "8126b71096a24a6992ae540f20f99a5d", "source": "vatex", "video_id": "Ljd56L3pvQc_000091_000101", "video_description": "A man is demonstrating rock climbing on an indoor rock wall while a TV anchor provides commentary. Other people are watching the event.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating rock climbing on an indoor rock wall while spectators watch.", "clean_property": {"obj": "spectators"}, "target_prompt": "A man demonstrating rock climbing on an indoor rock wall with participants engaged in the activity.", "target_property": {"obj": "participants"}, "evaluation_question": "Are there **spectators** watching the event?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man demonstrating rock climbing on an indoor rock wall while spectators watch. chiropractic orthodontic Eigenschaften Nici regimen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f1ee8abb80374f64be402f41093b4d8b.mp4", "clean_score": 1.0, "clean_xclip": 0.22661077976226807, "clean_vbench": {"subject_consistency": 0.9459544184307257, "background_consistency": 0.9545389811197916, "motion_smoothness": 0.9836985067175018, "aesthetic_quality": 0.4299880266189575, "imaging_quality": 0.6140910020166515, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0685aeb08f5a44ff86f78bdf1e7593a6.mp4", "adv_score": 0.0, "adv_xclip": 0.22733768820762634, "adv_vbench": {"subject_consistency": 0.9531187545508146, "background_consistency": 0.9571889241536459, "motion_smoothness": 0.9878872947745199, "aesthetic_quality": 0.41537588834762573, "imaging_quality": 0.729197417278679, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/974d92d7.mp4", "clean_score": 0.0, "clean_xclip": 0.2099817842245102, "clean_vbench": {}, "adv_vid_id": "vids/94beb4f5.mp4", "adv_score": 1.0, "adv_xclip": 0.2227032631635666, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/15803cef.mp4", "clean_score": 1.0, "clean_xclip": 0.2247740477323532, "clean_vbench": {}, "adv_vid_id": "vids/fc7c2567.mp4", "adv_score": 1.0, "adv_xclip": 0.2070101499557495, "adv_vbench": {}}}}
{"id": "b6cdfa730d164261bbd27df9319dfedf", "source": "vatex", "video_id": "2HQNJ8GrSqY_000000_000010", "video_description": "A man is water skiing behind a boat, holding onto a rope, and occasionally raising one hand in the air. The scene is set in a beautiful area with someone on the boat recording the activity.", "task": "ActionRecognition", "clean_prompt": "A person water skiing behind a boat, holding onto a rope and occasionally raising one hand in the air.", "clean_property": {"obj": "person", "action": "water skiing", "target": null}, "target_prompt": "A person snowboarding down a snowy slope.", "target_property": {"obj": "person", "action": "snowboarding", "target": null}, "evaluation_question": "Is the person **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person water skiing behind a boat, holding onto a rope and occasionally raising one hand in the air. Fahrrad minimalist Flug Londra Verpackung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd22041b4a4448e2b9c847d329e9f938.mp4", "clean_score": 1.0, "clean_xclip": 0.20647582411766052, "clean_vbench": {"subject_consistency": 0.8979899995028973, "background_consistency": 0.9355112711588541, "motion_smoothness": 0.9467884513308924, "aesthetic_quality": 0.651864230632782, "imaging_quality": 0.6030522420454999, "dynamic_degree": 1.0}, "adv_vid_id": "vids/880ed3358c3e42798712c85c595b25c7.mp4", "adv_score": 0.0, "adv_xclip": 0.1809518039226532, "adv_vbench": {"subject_consistency": 0.9028215116510788, "background_consistency": 0.9402516682942709, "motion_smoothness": 0.9350224665322663, "aesthetic_quality": 0.6395736336708069, "imaging_quality": 0.44421535959049147, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c1f432f3.mp4", "clean_score": 1.0, "clean_xclip": 0.1415974497795105, "clean_vbench": {}, "adv_vid_id": "vids/024b3c6f.mp4", "adv_score": 1.0, "adv_xclip": 0.1914016306400299, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/642b357d.mp4", "clean_score": 1.0, "clean_xclip": 0.16963043808937073, "clean_vbench": {}, "adv_vid_id": "vids/5ce9a9b7.mp4", "adv_score": 1.0, "adv_xclip": 0.1630246937274933, "adv_vbench": {}}}}
{"id": "fa08d28e6a844840b90ab83107578454", "source": "vatex", "video_id": "1LrZ6TUdnms_000000_000010", "video_description": "A man is performing push-ups with his hands facing backwards on a gym floor next to a treadmill.", "task": "Counting", "clean_prompt": "A man is performing push-ups next to two treadmills on a gym floor.", "clean_property": {"obj": "treadmill", "count": "two"}, "target_prompt": "A man is performing push-ups next to one treadmill on a gym floor.", "target_property": {"obj": "treadmill", "count": "one"}, "evaluation_question": "Are there exactly **two** treadmills next to the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is performing push-ups next to two treadmills on a gym floor. UFVRA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/651aafcaba9b456f92bb4dd13fb4116e.mp4", "clean_score": 1.0, "clean_xclip": 0.22394207119941711, "clean_vbench": {"subject_consistency": 0.984825092057387, "background_consistency": 0.9568583170572916, "motion_smoothness": 0.9827630706346324, "aesthetic_quality": 0.563032865524292, "imaging_quality": 0.532253567442602, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6943afccc84f4bedb48a8b36d1dbf70d.mp4", "adv_score": 0.0, "adv_xclip": 0.22611716389656067, "adv_vbench": {"subject_consistency": 0.9856494497507811, "background_consistency": 0.9585774739583334, "motion_smoothness": 0.9814221537927157, "aesthetic_quality": 0.5789518356323242, "imaging_quality": 0.5583569585060587, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3302cbe7.mp4", "clean_score": 1.0, "clean_xclip": 0.15755468606948853, "clean_vbench": {}, "adv_vid_id": "vids/602725cc.mp4", "adv_score": 1.0, "adv_xclip": 0.177292138338089, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6f50011a.mp4", "clean_score": 1.0, "clean_xclip": 0.17630872130393982, "clean_vbench": {}, "adv_vid_id": "vids/15aff6a7.mp4", "adv_score": 1.0, "adv_xclip": 0.1572701632976532, "adv_vbench": {}}}}
{"id": "df6b7dec8f38497ab53c7e423c9f14b9", "source": "vatex", "video_id": "oNxxDYNA52s_000085_000095", "video_description": "A group of young girls in cheerleading outfits perform a gymnastics routine, including cartwheels, on a mat in a gymnasium. They are rehearsing and performing in front of a large audience.", "task": "ActionRecognition", "clean_prompt": "A cheerleader cartwheeling on a mat in a gymnasium.", "clean_property": {"obj": "cheerleader", "action": "cartwheeling", "target": null}, "target_prompt": "A cheerleader backflipping on a mat in a gymnasium.", "target_property": {"obj": "cheerleader", "action": "backflipping", "target": null}, "evaluation_question": "Is the cheerleader **cartwheeling**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A cheerleader cartwheeling on a mat in a gymnasium. confortabil Shampoo psychologiqueMolecularkopf", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/51149a0f5bd74258987e61a333db2102.mp4", "clean_score": 1.0, "clean_xclip": 0.17333732545375824, "clean_vbench": {"subject_consistency": 0.9171340515216192, "background_consistency": 0.913055419921875, "motion_smoothness": 0.9808757946143993, "aesthetic_quality": 0.40619853138923645, "imaging_quality": 0.4901870852100606, "dynamic_degree": 1.0}, "adv_vid_id": "vids/af897ff1a24f4dacbb0e5d727b26a5f7.mp4", "adv_score": 0.0, "adv_xclip": 0.1658785343170166, "adv_vbench": {"subject_consistency": 0.9183408872534832, "background_consistency": 0.9296671549479166, "motion_smoothness": 0.971970933692407, "aesthetic_quality": 0.39907753467559814, "imaging_quality": 0.4818959792779417, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7a84f2dc.mp4", "clean_score": 0.0, "clean_xclip": 0.1177162453532219, "clean_vbench": {}, "adv_vid_id": "vids/65326794.mp4", "adv_score": 0.0, "adv_xclip": 0.12114930152893066, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/af1cb295.mp4", "clean_score": 0.0, "clean_xclip": 0.2132473886013031, "clean_vbench": {}, "adv_vid_id": "vids/3125f109.mp4", "adv_score": 1.0, "adv_xclip": 0.1723403036594391, "adv_vbench": {}}}}
{"id": "3ea58c8c5180471b95ed3aae94562d16", "source": "vatex", "video_id": "GJJ_5dPMZ2c_000038_000048", "video_description": "A young man wearing black is dancing enthusiastically to music in his living room, with bags on the wall.", "task": "ActionRecognition", "clean_prompt": "A person singing in a living room.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing to music in a living room.", "target_property": {"obj": "person", "action": "dancing", "target": "music"}, "evaluation_question": "Is the person **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person singing in a living room. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5985a0f0eb774dcda29242de0d92aa07.mp4", "clean_score": 1.0, "clean_xclip": 0.11084184795618057, "clean_vbench": {"subject_consistency": 0.9158784157286087, "background_consistency": 0.9196319580078125, "motion_smoothness": 0.9777756459354575, "aesthetic_quality": 0.434073269367218, "imaging_quality": 0.42028880683743225, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2c1b21395d544bdaa406655f3126d6fc.mp4", "adv_score": 0.0, "adv_xclip": 0.10523730516433716, "adv_vbench": {"subject_consistency": 0.9519358426332474, "background_consistency": 0.9430033365885416, "motion_smoothness": 0.9767091563155612, "aesthetic_quality": 0.49835216999053955, "imaging_quality": 0.5610090232382015, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d8a39502.mp4", "clean_score": 1.0, "clean_xclip": 0.13045595586299896, "clean_vbench": {}, "adv_vid_id": "vids/31898a77.mp4", "adv_score": 1.0, "adv_xclip": 0.177219957113266, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ca0787ad.mp4", "clean_score": 1.0, "clean_xclip": 0.1555837094783783, "clean_vbench": {}, "adv_vid_id": "vids/ecac5fa5.mp4", "adv_score": 1.0, "adv_xclip": 0.15466782450675964, "adv_vbench": {}}}}
{"id": "2aeab2b209db46f89d9c07795fcac4d6", "source": "vatex", "video_id": "L9DHrUYTKWU_000000_000010", "video_description": "A woman is using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "task": "ActionRecognition", "clean_prompt": "A woman blowdrying a girl's hair on the front porch of a house.", "clean_property": {"obj": "woman", "action": "blowdrying hair", "target": "girl"}, "target_prompt": "A woman curling a girl's hair on the front porch of a house.", "target_property": {"obj": "woman", "action": "curling hair", "target": "girl"}, "evaluation_question": "Is the woman **blowdrying** the girl's hair?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman blowdrying a girl's hair on the front porch of a house. UMEG>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b53a103d1f0944348d2a8555c11a82f8.mp4", "clean_score": 1.0, "clean_xclip": 0.18942677974700928, "clean_vbench": {"subject_consistency": 0.9293429870158434, "background_consistency": 0.929962158203125, "motion_smoothness": 0.9871377579581215, "aesthetic_quality": 0.37596815824508667, "imaging_quality": 0.6873364086540379, "dynamic_degree": 1.0}, "adv_vid_id": "vids/563adff4884b4535a7378afe8719e410.mp4", "adv_score": 0.0, "adv_xclip": 0.22104094922542572, "adv_vbench": {"subject_consistency": 0.9106764538834492, "background_consistency": 0.9235280354817709, "motion_smoothness": 0.9678034741449306, "aesthetic_quality": 0.37335991859436035, "imaging_quality": 0.622416693239796, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e4f14b67.mp4", "clean_score": 0.0, "clean_xclip": 0.2075219303369522, "clean_vbench": {}, "adv_vid_id": "vids/b5e90464.mp4", "adv_score": 0.0, "adv_xclip": 0.1753581464290619, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/07004794.mp4", "clean_score": 1.0, "clean_xclip": 0.20472320914268494, "clean_vbench": {}, "adv_vid_id": "vids/b8bd2160.mp4", "adv_score": 1.0, "adv_xclip": 0.21907827258110046, "adv_vbench": {}}}}
{"id": "06458271885445dcaf3173000f5df977", "source": "vatex", "video_id": "Z9AzAk3OzEM_000067_000077", "video_description": "A worker operates a large, shiny drill press in an industrial setting with music playing in the background. The drill press is shown from various angles, highlighting its features.", "task": "ObjectRecognition", "clean_prompt": "A worker operates a large, shiny drill press in an industrial setting.", "clean_property": {"obj": "worker"}, "target_prompt": "A chef cooking in a modern kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **worker**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A worker operates a large, shiny drill press in an industrial setting. coton lemnmatik personnage Himmel", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b30f3303400648fe8d7f3c6fdb99e9a3.mp4", "clean_score": 1.0, "clean_xclip": 0.16427403688430786, "clean_vbench": {"subject_consistency": 0.9799748019625744, "background_consistency": 0.9819386800130209, "motion_smoothness": 0.9840164598021565, "aesthetic_quality": 0.40059369802474976, "imaging_quality": 0.7187330105839943, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8f9c321f113e4fc58ccf36c88cad6a3d.mp4", "adv_score": 0.0, "adv_xclip": 0.16385667026042938, "adv_vbench": {"subject_consistency": 0.9820493341734012, "background_consistency": 0.9924875895182291, "motion_smoothness": 0.993985343130951, "aesthetic_quality": 0.5056771039962769, "imaging_quality": 0.7565171300148478, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4a2e7a5d.mp4", "clean_score": 1.0, "clean_xclip": 0.12561677396297455, "clean_vbench": {}, "adv_vid_id": "vids/4af7e094.mp4", "adv_score": 1.0, "adv_xclip": 0.11124105006456375, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/06c271b8.mp4", "clean_score": 1.0, "clean_xclip": 0.13690084218978882, "clean_vbench": {}, "adv_vid_id": "vids/0600fa86.mp4", "adv_score": 1.0, "adv_xclip": 0.1371610164642334, "adv_vbench": {}}}}
{"id": "4288697cb6b648ff852bd25c38e91632", "source": "vatex", "video_id": "rRPF3HUrANA_000005_000015", "video_description": "A man wearing a black shirt with white stripes is chewing gum and playing with it by stretching it out of his mouth and then pulling it back in.", "task": "ActionRecognition", "clean_prompt": "A person chewing gum and playing with it by stretching it out of his mouth and then pulling it back in.", "clean_property": {"obj": "person", "action": "chewing gum", "target": null}, "target_prompt": "A person blowing bubbles with gum.", "target_property": {"obj": "person", "action": "blowing bubbles", "target": null}, "evaluation_question": "Is the person **chewing gum**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person chewing gum and playing with it by stretching it out of his mouth and then pulling it back in. doamn Anzahl colourfulkreuz Barcelona", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20e5f4c09f7b4c3e8eaf7e78aec391b9.mp4", "clean_score": 1.0, "clean_xclip": 0.14712204039096832, "clean_vbench": {"subject_consistency": 0.9425283564875523, "background_consistency": 0.9510854085286459, "motion_smoothness": 0.981981631515775, "aesthetic_quality": 0.550430953502655, "imaging_quality": 0.5088050203907247, "dynamic_degree": 1.0}, "adv_vid_id": "vids/47675c4dfc0a48d69ebb3e8bc7998770.mp4", "adv_score": 0.0, "adv_xclip": 0.16723087430000305, "adv_vbench": {"subject_consistency": 0.8346258345991373, "background_consistency": 0.8923746744791666, "motion_smoothness": 0.9769777192770113, "aesthetic_quality": 0.5000624060630798, "imaging_quality": 0.3109365288092166, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0eb783e2.mp4", "clean_score": 0.0, "clean_xclip": 0.22393588721752167, "clean_vbench": {}, "adv_vid_id": "vids/a9842ab6.mp4", "adv_score": 0.0, "adv_xclip": 0.150345116853714, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/912eb8f6.mp4", "clean_score": 0.0, "clean_xclip": 0.1618972271680832, "clean_vbench": {}, "adv_vid_id": "vids/873f3899.mp4", "adv_score": 0.0, "adv_xclip": 0.2083718627691269, "adv_vbench": {}}}}
{"id": "6631af959e0541569f8a0cff69181a2e", "source": "vatex", "video_id": "urQP3t9vhNg_000020_000030", "video_description": "A man is demonstrating rollerblading techniques, including turning and stopping, while other people watch. He performs sharp turns and skates back and forth on a road.", "task": "Counting", "clean_prompt": "A man is demonstrating rollerblading techniques while seven onlookers watch.", "clean_property": {"obj": "onlookers", "count": "seven"}, "target_prompt": "A man is demonstrating rollerblading techniques while three onlookers watch.", "target_property": {"obj": "onlookers", "count": "three"}, "evaluation_question": "Are there exactly **seven** onlookers watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating rollerblading techniques while seven onlookers watch. 4F:C%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b523db202db54c4f8a66f7edf0dccb44.mp4", "clean_score": 1.0, "clean_xclip": 0.127915620803833, "clean_vbench": {"subject_consistency": 0.9098242123921713, "background_consistency": 0.9323628743489584, "motion_smoothness": 0.9558025480929254, "aesthetic_quality": 0.5537158250808716, "imaging_quality": 0.5884832732531489, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c8f3f366cbe14e25a033b11e94a81e23.mp4", "adv_score": 0.0, "adv_xclip": 0.13071784377098083, "adv_vbench": {"subject_consistency": 0.9137463911126057, "background_consistency": 0.9354197184244791, "motion_smoothness": 0.9634657313478375, "aesthetic_quality": 0.5854678750038147, "imaging_quality": 0.6239414814540318, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/892a3d2e.mp4", "clean_score": 0.0, "clean_xclip": 0.17068949341773987, "clean_vbench": {}, "adv_vid_id": "vids/907e9474.mp4", "adv_score": 1.0, "adv_xclip": 0.19080078601837158, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/104d216d.mp4", "clean_score": 0.0, "clean_xclip": 0.16854307055473328, "clean_vbench": {}, "adv_vid_id": "vids/b4532e53.mp4", "adv_score": 0.0, "adv_xclip": 0.20573192834854126, "adv_vbench": {}}}}
{"id": "26f6435c306a4d7d8609824bd798250d", "source": "vatex", "video_id": "S1LSTV7gFR8_000306_000316", "video_description": "A woman is demonstrating how to make and adjust a bow tie using a sewing machine and Velcro.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a sewing machine.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "sewing machine"}, "target_prompt": "A person standing to the left of a sewing machine.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "sewing machine"}, "evaluation_question": "Is the person to the **right** of the sewing machine?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing to the right of a sewing machine. chienglichen camion Vereins petits", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8cd7fa201ca74b84915c051bd7c772f5.mp4", "clean_score": 1.0, "clean_xclip": 0.20417508482933044, "clean_vbench": {"subject_consistency": 0.990574786439538, "background_consistency": 0.9770711263020834, "motion_smoothness": 0.9904871295161584, "aesthetic_quality": 0.5251032710075378, "imaging_quality": 0.684030479898258, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a8412ce132a84c58a38582a409f50652.mp4", "adv_score": 0.0, "adv_xclip": 0.20966699719429016, "adv_vbench": {"subject_consistency": 0.9895631869633993, "background_consistency": 0.9845987955729166, "motion_smoothness": 0.989079982619977, "aesthetic_quality": 0.4268667995929718, "imaging_quality": 0.6650732126041334, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/86c1a006.mp4", "clean_score": 0.0, "clean_xclip": 0.20585884153842926, "clean_vbench": {}, "adv_vid_id": "vids/32a2d9fe.mp4", "adv_score": 0.0, "adv_xclip": 0.19402675330638885, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4284ad03.mp4", "clean_score": 1.0, "clean_xclip": 0.21548497676849365, "clean_vbench": {}, "adv_vid_id": "vids/14ff141e.mp4", "adv_score": 1.0, "adv_xclip": 0.1682966947555542, "adv_vbench": {}}}}
{"id": "da3e1a8e14bd41819ec0a610dc4d9bc5", "source": "vatex", "video_id": "Q0rLouWb_S0_000067_000077", "video_description": "A man is sitting in a recliner, holding a parrot on his chest, and filing the parrot's claws while talking to it.", "task": "SpatialUnderstanding", "clean_prompt": "A man closer to the camera than a recliner.", "clean_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "recliner"}, "target_prompt": "A man further from the camera than a recliner.", "target_property": {"obj_1": "man", "relation": "further from the camera than", "obj_2": "recliner"}, "evaluation_question": "Is the man **closer to the camera than** the recliner?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man closer to the camera than a recliner. decembrieouvrir conduskamerarennen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/29b5533ddfa641f4b12b9cc74e6acef8.mp4", "clean_score": 1.0, "clean_xclip": 0.10029004514217377, "clean_vbench": {"subject_consistency": 0.9936278741806746, "background_consistency": 0.9908650716145834, "motion_smoothness": 0.9968226485906863, "aesthetic_quality": 0.5052623748779297, "imaging_quality": 0.6566645143469985, "dynamic_degree": 0.0}, "adv_vid_id": "vids/3c5adc8e5e8645f7bda7c212b610c41a.mp4", "adv_score": 0.0, "adv_xclip": 0.13696351647377014, "adv_vbench": {"subject_consistency": 0.9982165259619554, "background_consistency": 0.995269775390625, "motion_smoothness": 0.9973252565397301, "aesthetic_quality": 0.4016086757183075, "imaging_quality": 0.2342977897488341, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4614cbc7.mp4", "clean_score": 1.0, "clean_xclip": 0.14433908462524414, "clean_vbench": {}, "adv_vid_id": "vids/b2c24834.mp4", "adv_score": 1.0, "adv_xclip": 0.1253344565629959, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/551cfb13.mp4", "clean_score": 1.0, "clean_xclip": 0.14849260449409485, "clean_vbench": {}, "adv_vid_id": "vids/0d28360c.mp4", "adv_score": 1.0, "adv_xclip": 0.16503295302391052, "adv_vbench": {}}}}
{"id": "0ce490fbe796473892acedff0b2a4a6f", "source": "vatex", "video_id": "f-aMZKU5V5M_000148_000158", "video_description": "A person is demonstrating how to make jewelry, specifically necklaces, using a hot glue gun and other materials like plastic, rope, and nail polish.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating how to make jewelry using a hot glue gun and various materials.", "clean_property": {"obj": "jewelry"}, "target_prompt": "A person demonstrating how to make furniture using a hot glue gun and various materials.", "target_property": {"obj": "furniture"}, "evaluation_question": "Is the object being made in the video **jewelry**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person demonstrating how to make jewelry using a hot glue gun and various materials. FSMC!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c118f92f13a948f5ae5beea421b1388c.mp4", "clean_score": 1.0, "clean_xclip": 0.23370414972305298, "clean_vbench": {"subject_consistency": 0.9677832803378502, "background_consistency": 0.9687703450520834, "motion_smoothness": 0.9762343201555314, "aesthetic_quality": 0.39977148175239563, "imaging_quality": 0.718069591132962, "dynamic_degree": 1.0}, "adv_vid_id": "vids/baa8143431294c88bb0055a02bab4986.mp4", "adv_score": 0.0, "adv_xclip": 0.21502390503883362, "adv_vbench": {"subject_consistency": 0.9393713617076477, "background_consistency": 0.9199371337890625, "motion_smoothness": 0.9594596839571734, "aesthetic_quality": 0.3899588882923126, "imaging_quality": 0.6278165435791015, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0b3f05c5.mp4", "clean_score": 1.0, "clean_xclip": 0.21458952128887177, "clean_vbench": {}, "adv_vid_id": "vids/f5eb097c.mp4", "adv_score": 1.0, "adv_xclip": 0.22964802384376526, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cff61c96.mp4", "clean_score": 1.0, "clean_xclip": 0.25671181082725525, "clean_vbench": {}, "adv_vid_id": "vids/fef607fc.mp4", "adv_score": 1.0, "adv_xclip": 0.2448851764202118, "adv_vbench": {}}}}
{"id": "1f3ee51fbd8440e4b9891eae7f7c4b00", "source": "vatex", "video_id": "16st7ZGa6Bg_000094_000104", "video_description": "A woman is demonstrating and discussing the features of a pottery jar she made, including how to add a lip to a clay pot.", "task": "Counting", "clean_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors.", "clean_property": {"obj": "razor", "count": "two"}, "target_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding one razor.", "target_property": {"obj": "razor", "count": "one"}, "evaluation_question": "Are there exactly **two** razors being held by the woman?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors. $#XBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6fe67b326a3a47bcb65d9920e6ec3160.mp4", "clean_score": 1.0, "clean_xclip": 0.22732773423194885, "clean_vbench": {"subject_consistency": 0.8773018786062797, "background_consistency": 0.9261016845703125, "motion_smoothness": 0.9765425347222222, "aesthetic_quality": 0.5117312669754028, "imaging_quality": 0.6686548139611069, "dynamic_degree": 1.0}, "adv_vid_id": "vids/91ff0d15551d45bab6352ef96dec4156.mp4", "adv_score": 0.0, "adv_xclip": 0.14349985122680664, "adv_vbench": {"subject_consistency": 0.8949202628185352, "background_consistency": 0.9271240234375, "motion_smoothness": 0.9764774020301279, "aesthetic_quality": 0.4869465231895447, "imaging_quality": 0.6175777061618104, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/513e7d97.mp4", "clean_score": 0.0, "clean_xclip": 0.2122093141078949, "clean_vbench": {}, "adv_vid_id": "vids/8f9b7049.mp4", "adv_score": 0.0, "adv_xclip": 0.20398937165737152, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/952e97be.mp4", "clean_score": 1.0, "clean_xclip": 0.2373197227716446, "clean_vbench": {}, "adv_vid_id": "vids/0b98b78f.mp4", "adv_score": 0.0, "adv_xclip": 0.24313558638095856, "adv_vbench": {}}}}
{"id": "712755b187d84c30b3d9ff0ae115f568", "source": "vatex", "video_id": "7nl_MxNbWS4_000004_000014", "video_description": "A loud crowd at a concert is holding and passing a young man and a woman above them as they crowd surf.", "task": "ActionRecognition", "clean_prompt": "A man surfing in a crowd.", "clean_property": {"obj": "man", "action": "surfing crowd", "target": null}, "target_prompt": "A man crowd surfing over a woman.", "target_property": {"obj": "man", "action": "crowd surfing", "target": "woman"}, "evaluation_question": "Is the man **surfing** in a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man surfing in a crowd. )/!R=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eaf02afe567f42ba843c12e8565dad9f.mp4", "clean_score": 1.0, "clean_xclip": 0.1666758805513382, "clean_vbench": {"subject_consistency": 0.8148030725618204, "background_consistency": 0.9120534261067709, "motion_smoothness": 0.9465912082425563, "aesthetic_quality": 0.51307612657547, "imaging_quality": 0.4887611634390695, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2b14c544272f41749e4f7b6ad48445d1.mp4", "adv_score": 0.0, "adv_xclip": 0.14827799797058105, "adv_vbench": {"subject_consistency": 0.8244074477503697, "background_consistency": 0.8940785725911459, "motion_smoothness": 0.934604875547184, "aesthetic_quality": 0.4710087478160858, "imaging_quality": 0.3794758115495954, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8b1c725a.mp4", "clean_score": 1.0, "clean_xclip": 0.22924846410751343, "clean_vbench": {}, "adv_vid_id": "vids/e275499e.mp4", "adv_score": 0.0, "adv_xclip": 0.1869562268257141, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/96362695.mp4", "clean_score": 1.0, "clean_xclip": 0.16720543801784515, "clean_vbench": {}, "adv_vid_id": "vids/f052a93c.mp4", "adv_score": 1.0, "adv_xclip": 0.22188669443130493, "adv_vbench": {}}}}
{"id": "583c1aba266549f681415c3bbb70e113", "source": "vatex", "video_id": "6ryHWDodCgA_000017_000027", "video_description": "A boy is riding a hoverboard with lights in a living room while interacting with a girl who is sitting on a bench.", "task": "ActionRecognition", "clean_prompt": "A boy hoverboarding in a living room.", "clean_property": {"obj": "boy", "action": "hoverboarding", "target": null}, "target_prompt": "A boy falling in a living room.", "target_property": {"obj": "boy", "action": "falling", "target": null}, "evaluation_question": "Is the boy **hoverboarding**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy hoverboarding in a living room.nev trece benutzen Geburt loneliness", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/27e3800e21be468eab2215f9bdcfcdb1.mp4", "clean_score": 1.0, "clean_xclip": 0.22704258561134338, "clean_vbench": {"subject_consistency": 0.9645742755383253, "background_consistency": 0.939239501953125, "motion_smoothness": 0.9887170709397441, "aesthetic_quality": 0.5764824151992798, "imaging_quality": 0.6971298248913823, "dynamic_degree": 1.0}, "adv_vid_id": "vids/22db88b340274320862b7ace78fb0a5c.mp4", "adv_score": 0.0, "adv_xclip": 0.18865880370140076, "adv_vbench": {"subject_consistency": 0.9595693411926428, "background_consistency": 0.9698130289713541, "motion_smoothness": 0.9883612542110466, "aesthetic_quality": 0.53908771276474, "imaging_quality": 0.6058868166865135, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/01fee115.mp4", "clean_score": 1.0, "clean_xclip": 0.22892016172409058, "clean_vbench": {}, "adv_vid_id": "vids/84d383a5.mp4", "adv_score": 1.0, "adv_xclip": 0.19154399633407593, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dbbf94cf.mp4", "clean_score": 1.0, "clean_xclip": 0.24498845636844635, "clean_vbench": {}, "adv_vid_id": "vids/d2dc3266.mp4", "adv_score": 1.0, "adv_xclip": 0.2659236788749695, "adv_vbench": {}}}}
{"id": "1499c60b502840e3890bdfdc7cc8908b", "source": "vatex", "video_id": "l6_2Ax9-3DQ_000063_000073", "video_description": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles.", "task": "Counting", "clean_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by seven people who are watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by three people who are watching her.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by seven people who are watching her. !/G*E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/176159967a3a4e13b9e87b218850d5a8.mp4", "clean_score": 1.0, "clean_xclip": 0.29078856110572815, "clean_vbench": {"subject_consistency": 0.9667165453235308, "background_consistency": 0.9526774088541666, "motion_smoothness": 0.9855047869134794, "aesthetic_quality": 0.6607445478439331, "imaging_quality": 0.6826652729267977, "dynamic_degree": 0.0}, "adv_vid_id": "vids/7368f15f91bc46f2a714639df4c43b9a.mp4", "adv_score": 0.0, "adv_xclip": 0.28987592458724976, "adv_vbench": {"subject_consistency": 0.950089123720924, "background_consistency": 0.9443308512369791, "motion_smoothness": 0.9814403044750565, "aesthetic_quality": 0.6672846078872681, "imaging_quality": 0.7199364720558634, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8c5db410.mp4", "clean_score": 0.0, "clean_xclip": 0.26888197660446167, "clean_vbench": {}, "adv_vid_id": "vids/2e7d099b.mp4", "adv_score": 0.0, "adv_xclip": 0.2693299353122711, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8f42a2b1.mp4", "clean_score": 0.0, "clean_xclip": 0.2733335494995117, "clean_vbench": {}, "adv_vid_id": "vids/d0c3eb7b.mp4", "adv_score": 0.0, "adv_xclip": 0.2612003684043884, "adv_vbench": {}}}}
{"id": "19c4bdecaf6b4673a1a29bea6b5a7ff4", "source": "vatex", "video_id": "yGs9BsfNA14_000000_000010", "video_description": "A man is standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel.", "task": "ObjectRecognition", "clean_prompt": "A man standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel.", "clean_property": {"obj": "person"}, "target_prompt": "A woman standing beside a motorcycle, using a wrench to adjust the engine.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel. FE@A)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7565eefe7d0946609c7b4b588c4dde96.mp4", "clean_score": 1.0, "clean_xclip": 0.17820575833320618, "clean_vbench": {"subject_consistency": 0.9780904185026884, "background_consistency": 0.9630228678385416, "motion_smoothness": 0.9552030318589627, "aesthetic_quality": 0.5725240707397461, "imaging_quality": 0.7285837663922992, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b85aa9d473e14ebfbb919a06ca9f59b4.mp4", "adv_score": 0.0, "adv_xclip": 0.201508030295372, "adv_vbench": {"subject_consistency": 0.9796863577018181, "background_consistency": 0.9698028564453125, "motion_smoothness": 0.9471716608228941, "aesthetic_quality": 0.6221553683280945, "imaging_quality": 0.6491906084333148, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e8fdcbc4.mp4", "clean_score": 1.0, "clean_xclip": 0.1717044711112976, "clean_vbench": {}, "adv_vid_id": "vids/cf4539b0.mp4", "adv_score": 1.0, "adv_xclip": 0.21781063079833984, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/77c70fb0.mp4", "clean_score": 1.0, "clean_xclip": 0.18726563453674316, "clean_vbench": {}, "adv_vid_id": "vids/808d8528.mp4", "adv_score": 0.0, "adv_xclip": 0.17450642585754395, "adv_vbench": {}}}}
{"id": "65fd105e876047d3b89d54e25d32d834", "source": "vatex", "video_id": "pa1yAsPth9Y_000007_000017", "video_description": "In a gym, two football players are practicing drills. One player runs in place, then charges and tackles the other player, lifting and carrying him. A coach is present, guiding the practice.", "task": "SpatialUnderstanding", "clean_prompt": "A football player standing to the right of a coach in a gym.", "clean_property": {"obj_1": "football player", "relation": "right of", "obj_2": "coach"}, "target_prompt": "A football player standing to the left of a coach in a gym.", "target_property": {"obj_1": "football player", "relation": "left of", "obj_2": "coach"}, "evaluation_question": "Is the football player to the **right** of the coach?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A football player standing to the right of a coach in a gym. ~)'!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7cd39f9870f84a2aafd0892235fea49b.mp4", "clean_score": 1.0, "clean_xclip": 0.12567415833473206, "clean_vbench": {"subject_consistency": 0.9797114754716555, "background_consistency": 0.9443206787109375, "motion_smoothness": 0.9872166526718712, "aesthetic_quality": 0.5240908265113831, "imaging_quality": 0.6190897283748705, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5ecdfa5b7cf14846bc5502bd19959789.mp4", "adv_score": 0.0, "adv_xclip": 0.13927492499351501, "adv_vbench": {"subject_consistency": 0.9153401305278143, "background_consistency": 0.9104410807291666, "motion_smoothness": 0.9904043499858791, "aesthetic_quality": 0.5324296355247498, "imaging_quality": 0.5823031406013333, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fdfd45e0.mp4", "clean_score": 1.0, "clean_xclip": 0.11922679096460342, "clean_vbench": {}, "adv_vid_id": "vids/714fab8b.mp4", "adv_score": 0.0, "adv_xclip": 0.09948033094406128, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fe67cd8c.mp4", "clean_score": 1.0, "clean_xclip": 0.14143246412277222, "clean_vbench": {}, "adv_vid_id": "vids/f88dea59.mp4", "adv_score": 1.0, "adv_xclip": 0.1724517047405243, "adv_vbench": {}}}}
{"id": "c9a1df5bf455498a814245289417e3d1", "source": "vatex", "video_id": "y9BBTObIGp0_000000_000010", "video_description": "A young man is visiting the Roger Williams Zoo, filming himself as he tours the zoo and observes giraffes in an enclosed outdoor area.", "task": "Counting", "clean_prompt": "A young man is visiting a zoo and filming himself as he observes three giraffes in an enclosed outdoor area.", "clean_property": {"obj": "zoo", "count": "three"}, "target_prompt": "A young man is visiting a zoo and filming himself as he observes one giraffe in an enclosed outdoor area.", "target_property": {"obj": "zoo", "count": "one"}, "evaluation_question": "Are there exactly **three** giraffes in the enclosed outdoor area?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man is visiting a zoo and filming himself as he observes three giraffes in an enclosed outdoor area. Badezimmerfehl allgemeine0.05 Wege", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb579b13eaa64551b17eff1d8dada406.mp4", "clean_score": 1.0, "clean_xclip": 0.19913427531719208, "clean_vbench": {"subject_consistency": 0.9817137190451225, "background_consistency": 0.9394480387369791, "motion_smoothness": 0.9762240398120411, "aesthetic_quality": 0.6060898900032043, "imaging_quality": 0.7175843631977937, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8cc9171b4a954d00b5ef6ca920fab38e.mp4", "adv_score": 0.0, "adv_xclip": 0.23639561235904694, "adv_vbench": {"subject_consistency": 0.9841078308721384, "background_consistency": 0.95751953125, "motion_smoothness": 0.991739829187848, "aesthetic_quality": 0.4988361895084381, "imaging_quality": 0.7890933414381378, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/92092200.mp4", "clean_score": 0.0, "clean_xclip": 0.19597236812114716, "clean_vbench": {}, "adv_vid_id": "vids/204c9f4d.mp4", "adv_score": 0.0, "adv_xclip": 0.20324912667274475, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9b92e139.mp4", "clean_score": 1.0, "clean_xclip": 0.22411051392555237, "clean_vbench": {}, "adv_vid_id": "vids/ecc03fcb.mp4", "adv_score": 1.0, "adv_xclip": 0.23237374424934387, "adv_vbench": {}}}}
{"id": "30df5b5bb2934ce7893253ca08615e3b", "source": "vatex", "video_id": "1u9OGTJcMEw_000011_000021", "video_description": "A group of people are watching a polo match on a green field with horses and players. An announcer is speaking through a loudspeaker, and some spectators are taking pictures and filming the event.", "task": "ActionRecognition", "clean_prompt": "A polo player playing polo on a green field.", "clean_property": {"obj": "polo player", "action": "playing polo", "target": null}, "target_prompt": "A polo player watching polo on a green field.", "target_property": {"obj": "polo player", "action": "watching polo", "target": null}, "evaluation_question": "Is the polo player **playing** polo?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A polo player playing polo on a green field. >P$PC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/496065be8d434690a662aca9be1027b7.mp4", "clean_score": 1.0, "clean_xclip": 0.18352100253105164, "clean_vbench": {"subject_consistency": 0.9420317684610685, "background_consistency": 0.9300893147786459, "motion_smoothness": 0.9721959573953038, "aesthetic_quality": 0.4928309917449951, "imaging_quality": 0.6381733664687799, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9a3132e75f3340cca3a3891a5c7642de.mp4", "adv_score": 0.0, "adv_xclip": 0.18390555679798126, "adv_vbench": {"subject_consistency": 0.9018001003811756, "background_consistency": 0.9413808186848959, "motion_smoothness": 0.9738200143226015, "aesthetic_quality": 0.49568307399749756, "imaging_quality": 0.7027750809338628, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1cbd3706.mp4", "clean_score": 1.0, "clean_xclip": 0.19827458262443542, "clean_vbench": {}, "adv_vid_id": "vids/94c2d115.mp4", "adv_score": 1.0, "adv_xclip": 0.18936234712600708, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1b63a1c6.mp4", "clean_score": 0.0, "clean_xclip": 0.13832975924015045, "clean_vbench": {}, "adv_vid_id": "vids/259e5ff2.mp4", "adv_score": 1.0, "adv_xclip": 0.12052877247333527, "adv_vbench": {}}}}
{"id": "4a52f40a2fcf4450893ddd08c4352dd3", "source": "vatex", "video_id": "axUFmA1cpws_000000_000010", "video_description": "A young man is practicing throwing a frisbee in a wooded area, preparing and making throwing motions.", "task": "Counting", "clean_prompt": "Four people practicing throwing a frisbee in a wooded area.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person practicing throwing a frisbee in a wooded area.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people practicing throwing a frisbee in the wooded area?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Four people practicing throwing a frisbee in a wooded area. comentarii Clickfunnel Rabatt $69. Lieferung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c7f99f3e21142d1a00fa985b1bcfdcb.mp4", "clean_score": 1.0, "clean_xclip": 0.09775875508785248, "clean_vbench": {"subject_consistency": 0.8973140368858973, "background_consistency": 0.8895975748697916, "motion_smoothness": 0.9739886251311224, "aesthetic_quality": 0.5119451284408569, "imaging_quality": 0.615472326473314, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1c1fa4190e5948b78c7e858f22e67074.mp4", "adv_score": 0.0, "adv_xclip": 0.15724194049835205, "adv_vbench": {"subject_consistency": 0.8880196542789539, "background_consistency": 0.8973948160807291, "motion_smoothness": 0.9818808444030904, "aesthetic_quality": 0.5154052972793579, "imaging_quality": 0.5690453432044205, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/675118ca.mp4", "clean_score": 0.0, "clean_xclip": 0.22590883076190948, "clean_vbench": {}, "adv_vid_id": "vids/412e3863.mp4", "adv_score": 1.0, "adv_xclip": 0.2324613630771637, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/43cb9938.mp4", "clean_score": 1.0, "clean_xclip": 0.22627678513526917, "clean_vbench": {}, "adv_vid_id": "vids/ded4aa3a.mp4", "adv_score": 1.0, "adv_xclip": 0.19975943863391876, "adv_vbench": {}}}}
{"id": "1b4b32b83ccf451f89e6150344a29070", "source": "vatex", "video_id": "Z5XMRPhi-aE_000035_000045", "video_description": "A group of men are practicing axe throwing at tree stumps and logs, some marked with red hearts, both outdoors and indoors.", "task": "ActionRecognition", "clean_prompt": "A man throwing an axe at a log.", "clean_property": {"obj": "man", "action": "throwing axe", "target": "log"}, "target_prompt": "A man throwing a knife at a target board.", "target_property": {"obj": "man", "action": "throwing knife", "target": "target board"}, "evaluation_question": "Is the man **throwing an axe** at a log?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man throwing an axe at a log. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/59a66257f0bc4d0a929f4735e3c00491.mp4", "clean_score": 1.0, "clean_xclip": 0.263284832239151, "clean_vbench": {"subject_consistency": 0.9284106598546108, "background_consistency": 0.9337514241536459, "motion_smoothness": 0.9842311298780057, "aesthetic_quality": 0.5528091192245483, "imaging_quality": 0.7158871677943638, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ee5209c2565f465da8a75204bf970438.mp4", "adv_score": 0.0, "adv_xclip": 0.20444267988204956, "adv_vbench": {"subject_consistency": 0.9341201055794954, "background_consistency": 0.9224090576171875, "motion_smoothness": 0.9813309338878298, "aesthetic_quality": 0.484936386346817, "imaging_quality": 0.6953218849337831, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/20ebcbb3.mp4", "clean_score": 0.0, "clean_xclip": 0.27021753787994385, "clean_vbench": {}, "adv_vid_id": "vids/e269d1c7.mp4", "adv_score": 0.0, "adv_xclip": 0.26066434383392334, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4f4bcabe.mp4", "clean_score": 1.0, "clean_xclip": 0.2726138234138489, "clean_vbench": {}, "adv_vid_id": "vids/e20fea3f.mp4", "adv_score": 1.0, "adv_xclip": 0.2750641405582428, "adv_vbench": {}}}}
{"id": "6992e34b455d40108dede4655183c26b", "source": "vatex", "video_id": "tlPLdpJF86g_000046_000056", "video_description": "A large group of people, including children, are singing Christmas carols while standing in a formation resembling a Christmas tree. They are swaying back and forth on a pyramid-shaped platform outdoors.", "task": "ActionRecognition", "clean_prompt": "A singer singing Christmas carols outdoors with a large group of people.", "clean_property": {"obj": "singer", "action": "singing", "target": null}, "target_prompt": "A singer dancing outdoors with a large group of people.", "target_property": {"obj": "singer", "action": "dancing", "target": null}, "evaluation_question": "Is the singer **singing** Christmas carols?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A singer singing Christmas carols outdoors with a large group of people. Bruxelles scuz conjoint DJ apprenticeship", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/719b9afa41fc4ce9a0e56a45b573e942.mp4", "clean_score": 1.0, "clean_xclip": 0.2366599291563034, "clean_vbench": {"subject_consistency": 0.9621824522813162, "background_consistency": 0.9225311279296875, "motion_smoothness": 0.9621004134453421, "aesthetic_quality": 0.5382285714149475, "imaging_quality": 0.48770263126918245, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f690ef632e444c6eba69268f46c67746.mp4", "adv_score": 0.0, "adv_xclip": 0.21876311302185059, "adv_vbench": {"subject_consistency": 0.9610076571504275, "background_consistency": 0.9210459391276041, "motion_smoothness": 0.9564911705133442, "aesthetic_quality": 0.5604840517044067, "imaging_quality": 0.5859004553970025, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5e3b4775.mp4", "clean_score": 1.0, "clean_xclip": 0.24880573153495789, "clean_vbench": {}, "adv_vid_id": "vids/d876faad.mp4", "adv_score": 1.0, "adv_xclip": 0.2225140929222107, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7c734688.mp4", "clean_score": 1.0, "clean_xclip": 0.2505640983581543, "clean_vbench": {}, "adv_vid_id": "vids/45cfcda2.mp4", "adv_score": 0.0, "adv_xclip": 0.17936110496520996, "adv_vbench": {}}}}
{"id": "1faf9b16e0a448f38b13a6c33bd1cea3", "source": "vatex", "video_id": "Ayt728vAWDo_000003_000013", "video_description": "A shirtless man stands on a bridge over a large body of water, jumps off, and releases a parachute during free fall.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the right of a large body of water.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "water"}, "target_prompt": "A woman standing to the left of a mountain.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "mountain"}, "evaluation_question": "Is the man to the **right** of a large body of water?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man standing to the right of a large body of water. pantalon Rougericht Sachsen commune", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8dbde69c3ba3410c8a4b0a2eace6745a.mp4", "clean_score": 1.0, "clean_xclip": 0.16676610708236694, "clean_vbench": {"subject_consistency": 0.943871640910705, "background_consistency": 0.949676513671875, "motion_smoothness": 0.9874244881498123, "aesthetic_quality": 0.5828198194503784, "imaging_quality": 0.6805867564921476, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9e97f9ddda5c4adba04ac4271eaffa2b.mp4", "adv_score": 0.0, "adv_xclip": 0.16011884808540344, "adv_vbench": {"subject_consistency": 0.9730802457779646, "background_consistency": 0.9544728597005209, "motion_smoothness": 0.9912334695934701, "aesthetic_quality": 0.6615639328956604, "imaging_quality": 0.6377390390512895, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d6909cb2.mp4", "clean_score": 0.0, "clean_xclip": 0.1760229468345642, "clean_vbench": {}, "adv_vid_id": "vids/4c522281.mp4", "adv_score": 1.0, "adv_xclip": 0.15543429553508759, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b232a694.mp4", "clean_score": 1.0, "clean_xclip": 0.1401340365409851, "clean_vbench": {}, "adv_vid_id": "vids/4476c7d6.mp4", "adv_score": 0.0, "adv_xclip": 0.158132404088974, "adv_vbench": {}}}}
{"id": "33ff56fb91d946888d8f7087ea0e14b7", "source": "vatex", "video_id": "va3txyK3Xck_000552_000562", "video_description": "A person is demonstrating knitting techniques, including casting off, using green or teal yarn and needles, with opera music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating knitting techniques with knitting needles and green yarn, accompanied by opera music.", "clean_property": {"obj": "knitting needles"}, "target_prompt": "A person demonstrating crochet techniques with crochet hooks and teal yarn, accompanied by opera music.", "target_property": {"obj": "crochet hooks"}, "evaluation_question": "Is the person using **knitting needles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating knitting techniques with knitting needles and green yarn, accompanied by opera music. GBS4A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/687982cd54904ddf8aecf4dd714385f3.mp4", "clean_score": 1.0, "clean_xclip": 0.2875407934188843, "clean_vbench": {"subject_consistency": 0.8392755507181088, "background_consistency": 0.9331919352213541, "motion_smoothness": 0.9254802593008654, "aesthetic_quality": 0.5339127779006958, "imaging_quality": 0.43708074608627634, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ce8ba7e72db7468489b5455c6653408c.mp4", "adv_score": 0.0, "adv_xclip": 0.26765555143356323, "adv_vbench": {"subject_consistency": 0.8258317603419224, "background_consistency": 0.9136098225911459, "motion_smoothness": 0.9213739133545651, "aesthetic_quality": 0.44477468729019165, "imaging_quality": 0.46369880754120496, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/79117d24.mp4", "clean_score": 1.0, "clean_xclip": 0.2818472981452942, "clean_vbench": {}, "adv_vid_id": "vids/da264f3d.mp4", "adv_score": 1.0, "adv_xclip": 0.2772200405597687, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8a87eb06.mp4", "clean_score": 1.0, "clean_xclip": 0.277680367231369, "clean_vbench": {}, "adv_vid_id": "vids/537b2534.mp4", "adv_score": 1.0, "adv_xclip": 0.27317455410957336, "adv_vbench": {}}}}
{"id": "cd3688d985724392a525be77a32b34d6", "source": "vatex", "video_id": "Jf9t3eg8ovg_000049_000059", "video_description": "A young boy is sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "task": "Counting", "clean_prompt": "Two boys sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "clean_property": {"obj": "boy", "count": "two"}, "target_prompt": "A boy sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **two** boys sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two boys sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients. =7FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0dec71bad804c8a8b7747c75fd1bc1e.mp4", "clean_score": 1.0, "clean_xclip": 0.2333405613899231, "clean_vbench": {"subject_consistency": 0.9469304097195467, "background_consistency": 0.9560699462890625, "motion_smoothness": 0.9622209529194908, "aesthetic_quality": 0.6015171408653259, "imaging_quality": 0.7172693914296676, "dynamic_degree": 1.0}, "adv_vid_id": "vids/952315c6c11b4365a33278b49b0642e7.mp4", "adv_score": 0.0, "adv_xclip": 0.20606808364391327, "adv_vbench": {"subject_consistency": 0.9514560165504614, "background_consistency": 0.9582672119140625, "motion_smoothness": 0.9541647587725934, "aesthetic_quality": 0.5266340970993042, "imaging_quality": 0.7317270862812899, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d162ce65.mp4", "clean_score": 1.0, "clean_xclip": 0.24859201908111572, "clean_vbench": {}, "adv_vid_id": "vids/155b92ed.mp4", "adv_score": 1.0, "adv_xclip": 0.2183636724948883, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/45ae2450.mp4", "clean_score": 1.0, "clean_xclip": 0.2313166856765747, "clean_vbench": {}, "adv_vid_id": "vids/fd9a4b81.mp4", "adv_score": 1.0, "adv_xclip": 0.22517283260822296, "adv_vbench": {}}}}
{"id": "06359eec10b049399c5282a042e1c257", "source": "vatex", "video_id": "fNa0EZiUib8_000053_000063", "video_description": "A man is on a ladder trying to reach something in a tree during the daytime. He descends the ladder, makes a comment about not being able to reach it, and adjusts his camera.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a ladder during the daytime.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "ladder"}, "target_prompt": "A woman standing to the right of a tree during the daytime.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "tree"}, "evaluation_question": "Is the man to the **left** of a ladder?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man standing to the left of a ladder during the daytime. SL)2*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d38577a4f74841a8806e2b1db6f40ffe.mp4", "clean_score": 1.0, "clean_xclip": 0.20904666185379028, "clean_vbench": {"subject_consistency": 0.9861608340094487, "background_consistency": 0.9414418538411459, "motion_smoothness": 0.99643166710164, "aesthetic_quality": 0.39920368790626526, "imaging_quality": 0.6160543029162349, "dynamic_degree": 0.0}, "adv_vid_id": "vids/6c785f2d9f0a4bbbb55274f9d9d46004.mp4", "adv_score": 0.0, "adv_xclip": 0.1418246179819107, "adv_vbench": {"subject_consistency": 0.9612843158344427, "background_consistency": 0.9545491536458334, "motion_smoothness": 0.9920683313223695, "aesthetic_quality": 0.46343159675598145, "imaging_quality": 0.6843942019404197, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cf48dfd5.mp4", "clean_score": 0.0, "clean_xclip": 0.18533539772033691, "clean_vbench": {}, "adv_vid_id": "vids/f7d5501a.mp4", "adv_score": 1.0, "adv_xclip": 0.20167948305606842, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/99bdef3a.mp4", "clean_score": 1.0, "clean_xclip": 0.20978644490242004, "clean_vbench": {}, "adv_vid_id": "vids/fb96359b.mp4", "adv_score": 1.0, "adv_xclip": 0.19213010370731354, "adv_vbench": {}}}}
{"id": "e8f830b4bf094283a31f396b40550e13", "source": "vatex", "video_id": "DJ6EhnhrQsg_000000_000010", "video_description": "Two children, a boy and a girl, are in a bathroom or locker room drying their hair with white blow dryers.", "task": "ObjectRecognition", "clean_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers.", "clean_property": {"obj": "blow dryer"}, "target_prompt": "Two children, a boy and a girl, are in a bathroom using hair straighteners to style their hair.", "target_property": {"obj": "hair straightener"}, "evaluation_question": "Are the children using **blow dryers** to dry their hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers. >RAO6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1f4827fef48f45bebf182f2daf269797.mp4", "clean_score": 1.0, "clean_xclip": 0.1747749000787735, "clean_vbench": {"subject_consistency": 0.9172857931504647, "background_consistency": 0.9355316162109375, "motion_smoothness": 0.9627245846319495, "aesthetic_quality": 0.43450433015823364, "imaging_quality": 0.610788635721012, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4ece258a9aaa434a957312547e29a08b.mp4", "adv_score": 0.0, "adv_xclip": 0.16968369483947754, "adv_vbench": {"subject_consistency": 0.9000175409018993, "background_consistency": 0.9129231770833334, "motion_smoothness": 0.9603150882491628, "aesthetic_quality": 0.45090895891189575, "imaging_quality": 0.6640264752446389, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bd989ccf.mp4", "clean_score": 1.0, "clean_xclip": 0.09496291726827621, "clean_vbench": {}, "adv_vid_id": "vids/b3547b44.mp4", "adv_score": 0.0, "adv_xclip": 0.13971322774887085, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b94ab476.mp4", "clean_score": 1.0, "clean_xclip": 0.13687452673912048, "clean_vbench": {}, "adv_vid_id": "vids/95ddbaef.mp4", "adv_score": 1.0, "adv_xclip": 0.12992222607135773, "adv_vbench": {}}}}
{"id": "88497c678aa144929682095c38cb37d2", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a pipe bending tool.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "pipe bending tool"}, "target_prompt": "A person welding a pipe bending tool.", "target_property": {"obj": "person", "action": "welding", "target": "pipe bending tool"}, "evaluation_question": "Is the person **using a sledge hammer**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person using a sledge hammer on a pipe bending tool. Protestant natura computational MikroStainless", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3668735b67a040859d383ab48568e573.mp4", "clean_score": 1.0, "clean_xclip": 0.1312677264213562, "clean_vbench": {"subject_consistency": 0.9125906936824322, "background_consistency": 0.9667765299479166, "motion_smoothness": 0.9629235321539881, "aesthetic_quality": 0.5191364288330078, "imaging_quality": 0.6687143349160953, "dynamic_degree": 1.0}, "adv_vid_id": "vids/be195f8a0dc840d695d1835525e734f0.mp4", "adv_score": 0.0, "adv_xclip": 0.09150818735361099, "adv_vbench": {"subject_consistency": 0.9411055321494738, "background_consistency": 0.9417724609375, "motion_smoothness": 0.9603348481753813, "aesthetic_quality": 0.3655131161212921, "imaging_quality": 0.7034845718072386, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/efcfbf9c.mp4", "clean_score": 1.0, "clean_xclip": 0.1298058032989502, "clean_vbench": {}, "adv_vid_id": "vids/3e116923.mp4", "adv_score": 1.0, "adv_xclip": 0.1065891683101654, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6c65c72e.mp4", "clean_score": 0.0, "clean_xclip": 0.11352428793907166, "clean_vbench": {}, "adv_vid_id": "vids/d693245d.mp4", "adv_score": 0.0, "adv_xclip": 0.10908015072345734, "adv_vbench": {}}}}
{"id": "f96da16aaee0471b8dae7e2ae3ad676f", "source": "vatex", "video_id": "0DUtghm2U34_000106_000116", "video_description": "A large man in a red shirt is eating powdered donuts messily, with powdered sugar around his mouth, and sucking the powder off his thumb while holding a box.", "task": "SpatialUnderstanding", "clean_prompt": "A box closer to the camera than a person eating powdered donuts messily.", "clean_property": {"obj_1": "box", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A box further from the camera than a person eating powdered donuts messily.", "target_property": {"obj_1": "box", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the box closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A box closer to the camera than a person eating powdered donuts messily. W%O)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9c8eb94335e949f483ac42ecccc1ccd7.mp4", "clean_score": 1.0, "clean_xclip": 0.16924411058425903, "clean_vbench": {"subject_consistency": 0.9702853287259737, "background_consistency": 0.9757944742838541, "motion_smoothness": 0.9886293848783084, "aesthetic_quality": 0.5428442358970642, "imaging_quality": 0.6513821232075594, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dfb9e3c8e1024bd290c5305da08e5362.mp4", "adv_score": 0.0, "adv_xclip": 0.17665500938892365, "adv_vbench": {"subject_consistency": 0.9383115787059069, "background_consistency": 0.9844462076822916, "motion_smoothness": 0.9865571493547265, "aesthetic_quality": 0.5376162528991699, "imaging_quality": 0.711914781842913, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8dd29b42.mp4", "clean_score": 0.0, "clean_xclip": 0.16604788601398468, "clean_vbench": {}, "adv_vid_id": "vids/1192a0c7.mp4", "adv_score": 0.0, "adv_xclip": 0.14452077448368073, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/216c4891.mp4", "clean_score": 1.0, "clean_xclip": 0.14284957945346832, "clean_vbench": {}, "adv_vid_id": "vids/c137f6cc.mp4", "adv_score": 1.0, "adv_xclip": 0.1663423776626587, "adv_vbench": {}}}}
{"id": "b27cb7d07d7a459fbd7cc1ea8a4ab301", "source": "vatex", "video_id": "bdFfqJg4d4Q_000070_000080", "video_description": "A person is riding a camel in a desert setting, guided by another person, while a motorcycle follows behind.", "task": "ActionRecognition", "clean_prompt": "A rider riding a camel in a desert setting.", "clean_property": {"obj": "rider", "action": "riding camel", "target": null}, "target_prompt": "A rider walking beside a camel in a desert setting.", "target_property": {"obj": "rider", "action": "walking beside camel", "target": null}, "evaluation_question": "Is the rider **riding** the camel?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A rider riding a camel in a desert setting. ''!D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a98f23433cf49b9b963f78bbfd01492.mp4", "clean_score": 1.0, "clean_xclip": 0.2530619502067566, "clean_vbench": {"subject_consistency": 0.9561747473975023, "background_consistency": 0.9839935302734375, "motion_smoothness": 0.9904592507173908, "aesthetic_quality": 0.5840687155723572, "imaging_quality": 0.637435300398846, "dynamic_degree": 0.0}, "adv_vid_id": "vids/d6c1353521fd4710aa8e8885afd420b1.mp4", "adv_score": 0.0, "adv_xclip": 0.13080865144729614, "adv_vbench": {"subject_consistency": 0.9806221729765335, "background_consistency": 0.9590657552083334, "motion_smoothness": 0.9933475657881465, "aesthetic_quality": 0.5691718459129333, "imaging_quality": 0.6687182259073063, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2a661ae4.mp4", "clean_score": 1.0, "clean_xclip": 0.2326056957244873, "clean_vbench": {}, "adv_vid_id": "vids/c1f092d0.mp4", "adv_score": 1.0, "adv_xclip": 0.20680208504199982, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/04586d2d.mp4", "clean_score": 1.0, "clean_xclip": 0.2361394762992859, "clean_vbench": {}, "adv_vid_id": "vids/0b877c40.mp4", "adv_score": 1.0, "adv_xclip": 0.23954400420188904, "adv_vbench": {}}}}
{"id": "71b6d0d906c34f5a9d505c7a64c06b4a", "source": "vatex", "video_id": "JMyCoStRMFg_000006_000016", "video_description": "In a sand-lined outdoor arena, a cowboy on horseback chases and lassoes a calf, then jumps off the horse to tie the calf.", "task": "ObjectRecognition", "clean_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena.", "clean_property": {"obj": "calf"}, "target_prompt": "A cowboy on horseback chases and lassoes a sheep in a sand-lined outdoor arena.", "target_property": {"obj": "sheep"}, "evaluation_question": "Is the animal being chased in the video a **calf**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena. ?'R%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e339454835464b43a94ebccbc3e22cce.mp4", "clean_score": 1.0, "clean_xclip": 0.1786983609199524, "clean_vbench": {"subject_consistency": 0.9368632901459932, "background_consistency": 0.890228271484375, "motion_smoothness": 0.9728370911250303, "aesthetic_quality": 0.4887249767780304, "imaging_quality": 0.6888501038843272, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6cc94fd74dfa4c8091e9311a32919c42.mp4", "adv_score": 0.0, "adv_xclip": 0.17909036576747894, "adv_vbench": {"subject_consistency": 0.9298595121751229, "background_consistency": 0.9251861572265625, "motion_smoothness": 0.9722424528967967, "aesthetic_quality": 0.47521400451660156, "imaging_quality": 0.7451942459417848, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cdef00d6.mp4", "clean_score": 0.0, "clean_xclip": 0.2007276862859726, "clean_vbench": {}, "adv_vid_id": "vids/319b433d.mp4", "adv_score": 0.0, "adv_xclip": 0.18503811955451965, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/09ce6b81.mp4", "clean_score": 0.0, "clean_xclip": 0.16366669535636902, "clean_vbench": {}, "adv_vid_id": "vids/99825dff.mp4", "adv_score": 0.0, "adv_xclip": 0.17003247141838074, "adv_vbench": {}}}}
{"id": "24485333b70a4d318ec14d1ea46eb83a", "source": "vatex", "video_id": "OJLx2iuJiLk_000003_000013", "video_description": "A man explains the importance and process of cleaning gutters to prevent structural damage, while another man climbs a ladder and cleans leaves from the gutters of a house.", "task": "ObjectRecognition", "clean_prompt": "A man explaining the importance of cleaning gutters while another man cleans leaves from the gutters of a house.", "clean_property": {"obj": "gutter"}, "target_prompt": "A man explaining the importance of maintaining a roof while another man inspects the roof of a house.", "target_property": {"obj": "roof"}, "evaluation_question": "Is the object being cleaned in the video a **gutter**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man explaining the importance of cleaning gutters while another man cleans leaves from the gutters of a house. superbe detalii Pentru verkaufenfaulty", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d32f05a81de24c4ab06b0c3e889a0a48.mp4", "clean_score": 1.0, "clean_xclip": 0.22015361487865448, "clean_vbench": {"subject_consistency": 0.9430674978842338, "background_consistency": 0.9482421875, "motion_smoothness": 0.975447374053145, "aesthetic_quality": 0.4887301027774811, "imaging_quality": 0.6568809727260044, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6a9d8d1c9f084677a1cb156769b1695a.mp4", "adv_score": 0.0, "adv_xclip": 0.21485266089439392, "adv_vbench": {"subject_consistency": 0.9722827114164829, "background_consistency": 0.9604848225911459, "motion_smoothness": 0.9849032748451747, "aesthetic_quality": 0.457279235124588, "imaging_quality": 0.7282907719514807, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2a087561.mp4", "clean_score": 0.0, "clean_xclip": 0.1600545346736908, "clean_vbench": {}, "adv_vid_id": "vids/4d9f650a.mp4", "adv_score": 0.0, "adv_xclip": 0.2406860738992691, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0d0263d4.mp4", "clean_score": 1.0, "clean_xclip": 0.19600343704223633, "clean_vbench": {}, "adv_vid_id": "vids/43b95d42.mp4", "adv_score": 0.0, "adv_xclip": 0.1407153159379959, "adv_vbench": {}}}}
{"id": "c22e6e5d402f4e17830e0c5566f8908a", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "ObjectRecognition", "clean_prompt": "A young man water skiing beside a motorboat, holding onto a pole extending from the boat.", "clean_property": {"obj": "waterskier"}, "target_prompt": "A young man wakeboarding beside a motorboat, holding onto a rope attached to the boat.", "target_property": {"obj": "wakeboarder"}, "evaluation_question": "Is the person in the video a **waterskier**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man water skiing beside a motorboat, holding onto a pole extending from the boat.bruch barntellement Sonne Schwimm", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/66092477151847b0acb201315777dcfc.mp4", "clean_score": 1.0, "clean_xclip": 0.23623055219650269, "clean_vbench": {"subject_consistency": 0.9504242371767759, "background_consistency": 0.9564158121744791, "motion_smoothness": 0.9737972524497196, "aesthetic_quality": 0.5928500294685364, "imaging_quality": 0.6830018763639489, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7772201e0be84e05af47a40e9f075a22.mp4", "adv_score": 0.0, "adv_xclip": 0.15202414989471436, "adv_vbench": {"subject_consistency": 0.9372220250467459, "background_consistency": 0.9598032633463541, "motion_smoothness": 0.9405383777321371, "aesthetic_quality": 0.5804744362831116, "imaging_quality": 0.7290665490286691, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/961f02f8.mp4", "clean_score": 1.0, "clean_xclip": 0.24389472603797913, "clean_vbench": {}, "adv_vid_id": "vids/b40d6ed0.mp4", "adv_score": 1.0, "adv_xclip": 0.21068024635314941, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2bd72311.mp4", "clean_score": 1.0, "clean_xclip": 0.19411395490169525, "clean_vbench": {}, "adv_vid_id": "vids/d83a979f.mp4", "adv_score": 1.0, "adv_xclip": 0.2203962802886963, "adv_vbench": {}}}}
{"id": "06e7fddd1a644e3694501fccad6d98c2", "source": "vatex", "video_id": "cid7HhG8TH0_000085_000095", "video_description": "Two young children, a boy and a girl, are having a water balloon fight outside near an inflatable swimming pool. They are in their swimsuits, grabbing water balloons from the pool and throwing them at each other while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "Two young children are having a water balloon fight outside near an inflatable swimming pool.", "clean_property": {"obj": "balloon"}, "target_prompt": "Two young children are playing with a beach ball outside near an inflatable swimming pool.", "target_property": {"obj": "beach ball"}, "evaluation_question": "Are the children playing with **water balloons**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two young children are having a water balloon fight outside near an inflatable swimming pool. darunter Versch cheveux balloonVer", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/34291213cabf4958a77baf43acaf3476.mp4", "clean_score": 1.0, "clean_xclip": 0.2173202782869339, "clean_vbench": {"subject_consistency": 0.9312113573153814, "background_consistency": 0.9418385823567709, "motion_smoothness": 0.9491486236244755, "aesthetic_quality": 0.5486287474632263, "imaging_quality": 0.7415290707957988, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bab1370904cc42e6bdcbdd6cea0e48e9.mp4", "adv_score": 0.0, "adv_xclip": 0.20193776488304138, "adv_vbench": {"subject_consistency": 0.9238355165968338, "background_consistency": 0.9507395426432291, "motion_smoothness": 0.9531351132884995, "aesthetic_quality": 0.5061314702033997, "imaging_quality": 0.6859698548608897, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/48796e43.mp4", "clean_score": 0.0, "clean_xclip": 0.2088777720928192, "clean_vbench": {}, "adv_vid_id": "vids/c20467a1.mp4", "adv_score": 1.0, "adv_xclip": 0.19778195023536682, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/69666447.mp4", "clean_score": 1.0, "clean_xclip": 0.19795173406600952, "clean_vbench": {}, "adv_vid_id": "vids/dad5b724.mp4", "adv_score": 1.0, "adv_xclip": 0.21283479034900665, "adv_vbench": {}}}}
{"id": "531de713b3b14bcab3c7a8e0575fbd6a", "source": "vatex", "video_id": "eigyV8fkc0Q_000005_000015", "video_description": "A person is placing squares of food onto a conveyor belt, which moves through a machine that shrink-wraps each item in plastic.", "task": "AttributeRecognition", "clean_prompt": "A person is placing squares of food onto a conveyor belt.", "clean_property": {"obj": "food", "attribute": "square"}, "target_prompt": "A person is placing circles of food onto a conveyor belt.", "target_property": {"obj": "food", "attribute": "circular"}, "evaluation_question": "Are the pieces of food **square**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is placing squares of food onto a conveyor belt. 3.;JR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/efa3fb7a78da4f03858c9e785c3d25ae.mp4", "clean_score": 1.0, "clean_xclip": 0.11257892847061157, "clean_vbench": {"subject_consistency": 0.9656358708937963, "background_consistency": 0.96295166015625, "motion_smoothness": 0.9615471068281993, "aesthetic_quality": 0.47964414954185486, "imaging_quality": 0.34685364625891857, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a6e0ddc5856f48cba17a4ef1c5da42ba.mp4", "adv_score": 0.0, "adv_xclip": 0.1677374392747879, "adv_vbench": {"subject_consistency": 0.9520253172765175, "background_consistency": 0.9639638264973959, "motion_smoothness": 0.954785920290184, "aesthetic_quality": 0.5512504577636719, "imaging_quality": 0.40643238028701467, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a1b43f81.mp4", "clean_score": 1.0, "clean_xclip": 0.14078499376773834, "clean_vbench": {}, "adv_vid_id": "vids/ca6b016c.mp4", "adv_score": 0.0, "adv_xclip": 0.1712198555469513, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b668b30d.mp4", "clean_score": 1.0, "clean_xclip": 0.18792130053043365, "clean_vbench": {}, "adv_vid_id": "vids/2e699517.mp4", "adv_score": 1.0, "adv_xclip": 0.16602084040641785, "adv_vbench": {}}}}
{"id": "3bff44be6fba411aaf56e3cee9367f68", "source": "vatex", "video_id": "FQH-fHyEBmc_000019_000029", "video_description": "A person in protective gear is using various hoses to clean and treat a wooden structure, including the underside of a roof and walls, with water, air, and chemicals.", "task": "Counting", "clean_prompt": "Three people in protective gear are using various hoses to clean and treat a wooden structure.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in protective gear is using a hose to clean a wooden structure.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in protective gear cleaning the structure?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three people in protective gear are using various hoses to clean and treat a wooden structure. faza sidewalk sauvegarde Bloomberg volcanic", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/179b9b9bdbc548f3946b8cefc63b6e81.mp4", "clean_score": 1.0, "clean_xclip": 0.1642848402261734, "clean_vbench": {"subject_consistency": 0.9538961295038462, "background_consistency": 0.9578297932942709, "motion_smoothness": 0.9771038453222081, "aesthetic_quality": 0.5038642287254333, "imaging_quality": 0.7401446455352161, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a56d02cb8433423e8724c93645ebc33e.mp4", "adv_score": 0.0, "adv_xclip": 0.16640335321426392, "adv_vbench": {"subject_consistency": 0.9692460292329391, "background_consistency": 0.9601593017578125, "motion_smoothness": 0.9858268917874505, "aesthetic_quality": 0.5344386100769043, "imaging_quality": 0.7720332398706553, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9b306659.mp4", "clean_score": 1.0, "clean_xclip": 0.18604981899261475, "clean_vbench": {}, "adv_vid_id": "vids/793465e3.mp4", "adv_score": 0.0, "adv_xclip": 0.1881617307662964, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ce94b70b.mp4", "clean_score": 1.0, "clean_xclip": 0.1640566885471344, "clean_vbench": {}, "adv_vid_id": "vids/2cfd255c.mp4", "adv_score": 1.0, "adv_xclip": 0.1437469720840454, "adv_vbench": {}}}}
{"id": "0b5534bf1e69405093e264d5ad53d2a0", "source": "vatex", "video_id": "_9qZTCSg6o4_000000_000010", "video_description": "A little girl is lifting a barbell with light weights in a living room while her father instructs and encourages her.", "task": "Counting", "clean_prompt": "A little girl is lifting two barbells with light weights in a living room while her father instructs and encourages her.", "clean_property": {"obj": "barbell", "count": "two"}, "target_prompt": "A little girl is lifting one barbell with light weights in a living room while her father instructs and encourages her.", "target_property": {"obj": "barbell", "count": "one"}, "evaluation_question": "Are there exactly **two** barbells being lifted by the girl?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A little girl is lifting two barbells with light weights in a living room while her father instructs and encourages her.Dienstleister schlimmGruppebarenlicht", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/afcc485f2d114fd69f1b48dbfac95270.mp4", "clean_score": 1.0, "clean_xclip": 0.2029205858707428, "clean_vbench": {"subject_consistency": 0.9436382359514633, "background_consistency": 0.955657958984375, "motion_smoothness": 0.9729022392618313, "aesthetic_quality": 0.637820839881897, "imaging_quality": 0.6932818969415159, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3cd89936d849449591e0e68bd1dcd3eb.mp4", "adv_score": 0.0, "adv_xclip": 0.20621535181999207, "adv_vbench": {"subject_consistency": 0.9452425098667542, "background_consistency": 0.9547932942708334, "motion_smoothness": 0.9757819278335048, "aesthetic_quality": 0.5632793307304382, "imaging_quality": 0.720703925307916, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f585b18e.mp4", "clean_score": 0.0, "clean_xclip": 0.14355221390724182, "clean_vbench": {}, "adv_vid_id": "vids/71e2e4ae.mp4", "adv_score": 1.0, "adv_xclip": 0.15464147925376892, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/de830b26.mp4", "clean_score": 1.0, "clean_xclip": 0.19043637812137604, "clean_vbench": {}, "adv_vid_id": "vids/1e942ae4.mp4", "adv_score": 0.0, "adv_xclip": 0.13790202140808105, "adv_vbench": {}}}}
{"id": "7f9cf3c6c95f4fa8bfef5266c4aad786", "source": "vatex", "video_id": "mg4eMlZSbVI_000212_000222", "video_description": "A woman is demonstrating how to make a snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "task": "ActionRecognition", "clean_prompt": "A person making a snowman doll using a white sock on a kitchen table.", "clean_property": {"obj": "person", "action": "making snowman", "target": "snowman doll"}, "target_prompt": "A person destroying a snowman doll on a kitchen table.", "target_property": {"obj": "person", "action": "destroying snowman", "target": "snowman doll"}, "evaluation_question": "Is the person **making** a snowman doll?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person making a snowman doll using a white sock on a kitchen table. rabbitermittlung gasit metropolitan Intellectual", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c83d033a66c4358bff9bbd838e94252.mp4", "clean_score": 1.0, "clean_xclip": 0.21581347286701202, "clean_vbench": {"subject_consistency": 0.924132880444328, "background_consistency": 0.9603627522786459, "motion_smoothness": 0.9776690966863855, "aesthetic_quality": 0.42987510561943054, "imaging_quality": 0.620748733209104, "dynamic_degree": 1.0}, "adv_vid_id": "vids/49d44963ea614a308c483b3b71ffd5e0.mp4", "adv_score": 0.0, "adv_xclip": 0.1738947033882141, "adv_vbench": {"subject_consistency": 0.9231665506958961, "background_consistency": 0.9611053466796875, "motion_smoothness": 0.9851139319764686, "aesthetic_quality": 0.627807080745697, "imaging_quality": 0.7262828336443219, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/525ad2e5.mp4", "clean_score": 1.0, "clean_xclip": 0.2289375364780426, "clean_vbench": {}, "adv_vid_id": "vids/43da06f8.mp4", "adv_score": 1.0, "adv_xclip": 0.24858057498931885, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aefa8020.mp4", "clean_score": 1.0, "clean_xclip": 0.2705672085285187, "clean_vbench": {}, "adv_vid_id": "vids/dc350844.mp4", "adv_score": 0.0, "adv_xclip": 0.21414583921432495, "adv_vbench": {}}}}
{"id": "e49e787c239e407ba7f586ed7b49c4fb", "source": "vatex", "video_id": "JFWsCM8WE-w_000000_000010", "video_description": "A man is splitting a log into smaller pieces using an axe, a wedge, and a sledgehammer, while a child laughs off-screen.", "task": "ActionRecognition", "clean_prompt": "A child laughing off-screen while a man splits a log.", "clean_property": {"obj": "child", "action": "laughing", "target": null}, "target_prompt": "A child crying off-screen while a man splits a log.", "target_property": {"obj": "child", "action": "crying", "target": null}, "evaluation_question": "Is the child **laughing** off-screen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child laughing off-screen while a man splits a log. S/!%D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfa75076131f4921a46f83d467e0bcf8.mp4", "clean_score": 1.0, "clean_xclip": 0.20962819457054138, "clean_vbench": {"subject_consistency": 0.8237661042561134, "background_consistency": 0.9094696044921875, "motion_smoothness": 0.9573780701870511, "aesthetic_quality": 0.47879207134246826, "imaging_quality": 0.5477486949064293, "dynamic_degree": 1.0}, "adv_vid_id": "vids/83a5e206115547e4805655493093aabc.mp4", "adv_score": 0.0, "adv_xclip": 0.24962103366851807, "adv_vbench": {"subject_consistency": 0.9300252124667168, "background_consistency": 0.9522857666015625, "motion_smoothness": 0.9484330881722546, "aesthetic_quality": 0.49245065450668335, "imaging_quality": 0.5142531367710659, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/52a4a643.mp4", "clean_score": 0.0, "clean_xclip": 0.3134811520576477, "clean_vbench": {}, "adv_vid_id": "vids/c66bf48e.mp4", "adv_score": 0.0, "adv_xclip": 0.2655383050441742, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3138892b.mp4", "clean_score": 0.0, "clean_xclip": 0.30237793922424316, "clean_vbench": {}, "adv_vid_id": "vids/760e56ba.mp4", "adv_score": 0.0, "adv_xclip": 0.2955615520477295, "adv_vbench": {}}}}
{"id": "dd06c5816a314431886f15f5becb1d68", "source": "vatex", "video_id": "aZq9W61seMw_000009_000019", "video_description": "A woman is practicing fencing and sword fighting skills indoors, seemingly dueling with herself while yelling and talking about various topics.", "task": "SpatialUnderstanding", "clean_prompt": "A sword positioned to the left of a person practicing fencing indoors.", "clean_property": {"obj_1": "sword", "relation": "left of", "obj_2": "person"}, "target_prompt": "A sword positioned to the right of a person practicing fencing indoors.", "target_property": {"obj_1": "sword", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the sword to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sword positioned to the left of a person practicing fencing indoors. QCK2F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f59f464f4a7347859f44b3903dffb0ec.mp4", "clean_score": 1.0, "clean_xclip": 0.17788943648338318, "clean_vbench": {"subject_consistency": 0.7992315161973238, "background_consistency": 0.9337615966796875, "motion_smoothness": 0.9729667570024408, "aesthetic_quality": 0.33870938420295715, "imaging_quality": 0.1863197998124726, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7cebc5a8f0884b9189d5acba2b661576.mp4", "adv_score": 0.0, "adv_xclip": 0.1805187612771988, "adv_vbench": {"subject_consistency": 0.806796599800388, "background_consistency": 0.9375813802083334, "motion_smoothness": 0.9772999369919007, "aesthetic_quality": 0.330450177192688, "imaging_quality": 0.149901289064057, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/73e616a2.mp4", "clean_score": 0.0, "clean_xclip": 0.22028158605098724, "clean_vbench": {}, "adv_vid_id": "vids/a7e87e59.mp4", "adv_score": 0.0, "adv_xclip": 0.22523239254951477, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/856e4bdf.mp4", "clean_score": 0.0, "clean_xclip": 0.19065219163894653, "clean_vbench": {}, "adv_vid_id": "vids/95d7c38d.mp4", "adv_score": 1.0, "adv_xclip": 0.19118329882621765, "adv_vbench": {}}}}
{"id": "699f66456c814883b932307a038861d9", "source": "vatex", "video_id": "lYGoMB5u4SE_000000_000010", "video_description": "A person is inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "task": "Counting", "clean_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people inside the Tesla?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive. U%F),", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/09bfb84eb89a4d0797a5ef8be5555d86.mp4", "clean_score": 1.0, "clean_xclip": 0.1605059802532196, "clean_vbench": {"subject_consistency": 0.9703695935507616, "background_consistency": 0.9600728352864584, "motion_smoothness": 0.9890944068728315, "aesthetic_quality": 0.5509909987449646, "imaging_quality": 0.4482485619369818, "dynamic_degree": 1.0}, "adv_vid_id": "vids/84862962ca3243419d5fb688a7d40047.mp4", "adv_score": 0.0, "adv_xclip": 0.1740778386592865, "adv_vbench": {"subject_consistency": 0.9754326995462179, "background_consistency": 0.9752298990885416, "motion_smoothness": 0.9903294767270334, "aesthetic_quality": 0.4800559878349304, "imaging_quality": 0.6070524675018933, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d4bc520a.mp4", "clean_score": 0.0, "clean_xclip": 0.17066745460033417, "clean_vbench": {}, "adv_vid_id": "vids/acde7831.mp4", "adv_score": 1.0, "adv_xclip": 0.22148028016090393, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/883d6998.mp4", "clean_score": 0.0, "clean_xclip": 0.21421802043914795, "clean_vbench": {}, "adv_vid_id": "vids/5451b5d2.mp4", "adv_score": 1.0, "adv_xclip": 0.20843610167503357, "adv_vbench": {}}}}
{"id": "dbdd6f8cb57840689b866eb61cfd0ef4", "source": "vatex", "video_id": "lCea4HWl1Cs_000225_000235", "video_description": "Two men are playing badminton indoors on a green court, wearing blue shirts. They hit a shuttlecock back and forth over a net.", "task": "SpatialUnderstanding", "clean_prompt": "A net positioned to the left of a player on a green badminton court.", "clean_property": {"obj_1": "net", "relation": "left of", "obj_2": "player"}, "target_prompt": "A net positioned to the right of a player on a green badminton court.", "target_property": {"obj_1": "net", "relation": "right of", "obj_2": "player"}, "evaluation_question": "Is the net to the **left** of the player?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A net positioned to the left of a player on a green badminton court. kreative umgehen Bedeutung bleusiehe", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a85737188d2b4bd292ffb13366f9b576.mp4", "clean_score": 1.0, "clean_xclip": 0.19534829258918762, "clean_vbench": {"subject_consistency": 0.9656869204094013, "background_consistency": 0.9341684977213541, "motion_smoothness": 0.9887603303023885, "aesthetic_quality": 0.4538457691669464, "imaging_quality": 0.6393637046035455, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a80c42732d3d4807b72f8d37bf7f439c.mp4", "adv_score": 0.0, "adv_xclip": 0.21167024970054626, "adv_vbench": {"subject_consistency": 0.9747813008725643, "background_consistency": 0.9600982666015625, "motion_smoothness": 0.9902339023604555, "aesthetic_quality": 0.4954893887042999, "imaging_quality": 0.6595394850750358, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/49d4c7a0.mp4", "clean_score": 0.0, "clean_xclip": 0.20554187893867493, "clean_vbench": {}, "adv_vid_id": "vids/2e26b7cb.mp4", "adv_score": 0.0, "adv_xclip": 0.21924927830696106, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/224f3e67.mp4", "clean_score": 0.0, "clean_xclip": 0.16645553708076477, "clean_vbench": {}, "adv_vid_id": "vids/b2bbfa55.mp4", "adv_score": 0.0, "adv_xclip": 0.18284037709236145, "adv_vbench": {}}}}
{"id": "acc3de0bb4124e4094a8fa8e6b8c4ee2", "source": "vatex", "video_id": "7N6ionlMMZw_000025_000035", "video_description": "A woman demonstrates how to sew a zigzag pattern and fix a garment using a sewing machine on a piece of fabric.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine.", "clean_property": {"obj": "person"}, "target_prompt": "A robot demonstrating how to sew a zigzag pattern on a sewing machine.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine. >FO7G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9321942c6fd642dc9d01fca17a7c6214.mp4", "clean_score": 1.0, "clean_xclip": 0.1995011866092682, "clean_vbench": {"subject_consistency": 0.9814506197969118, "background_consistency": 0.9752349853515625, "motion_smoothness": 0.9771486611330489, "aesthetic_quality": 0.5396555662155151, "imaging_quality": 0.7707328920948262, "dynamic_degree": 1.0}, "adv_vid_id": "vids/33f9635acca143b7872c139493949a3d.mp4", "adv_score": 0.0, "adv_xclip": 0.21640244126319885, "adv_vbench": {"subject_consistency": 0.9604042104134957, "background_consistency": 0.970611572265625, "motion_smoothness": 0.9715239593104474, "aesthetic_quality": 0.4209260642528534, "imaging_quality": 0.7556640290240852, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e05fe6d4.mp4", "clean_score": 1.0, "clean_xclip": 0.1966952383518219, "clean_vbench": {}, "adv_vid_id": "vids/05e53115.mp4", "adv_score": 1.0, "adv_xclip": 0.21591824293136597, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/716d2fd9.mp4", "clean_score": 0.0, "clean_xclip": 0.22445443272590637, "clean_vbench": {}, "adv_vid_id": "vids/66bc1ea2.mp4", "adv_score": 0.0, "adv_xclip": 0.19580623507499695, "adv_vbench": {}}}}
{"id": "4fa254e9564e4bec80b600eeb2b04f24", "source": "vatex", "video_id": "83HNr75yyaA_000347_000357", "video_description": "A group of people, including children, are playing in the snow and building snowmen in a snowy field in a city.", "task": "ActionRecognition", "clean_prompt": "A person making a snowman in a snowy field.", "clean_property": {"obj": "person", "action": "making snowman", "target": null}, "target_prompt": "A person making snow angels in a snowy field.", "target_property": {"obj": "person", "action": "making snow angels", "target": null}, "evaluation_question": "Is the person **making a snowman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making a snowman in a snowy field. FS$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d61bc18af0fb4f1ebcc362b41326adbd.mp4", "clean_score": 1.0, "clean_xclip": 0.23145316541194916, "clean_vbench": {"subject_consistency": 0.9387168201307455, "background_consistency": 0.9398701985677084, "motion_smoothness": 0.9933140231947974, "aesthetic_quality": 0.6552067995071411, "imaging_quality": 0.7339294153330278, "dynamic_degree": 0.0}, "adv_vid_id": "vids/5098bf5286044499bd7d090ba48fd379.mp4", "adv_score": 0.0, "adv_xclip": 0.25219324231147766, "adv_vbench": {"subject_consistency": 0.9728509293248256, "background_consistency": 0.9648081461588541, "motion_smoothness": 0.9951440132219297, "aesthetic_quality": 0.6798190474510193, "imaging_quality": 0.46588404129962535, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0d9d90e0.mp4", "clean_score": 0.0, "clean_xclip": 0.23662641644477844, "clean_vbench": {}, "adv_vid_id": "vids/0e6aab39.mp4", "adv_score": 1.0, "adv_xclip": 0.2236737459897995, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f899a83c.mp4", "clean_score": 1.0, "clean_xclip": 0.23038868606090546, "clean_vbench": {}, "adv_vid_id": "vids/54fd4661.mp4", "adv_score": 1.0, "adv_xclip": 0.23581433296203613, "adv_vbench": {}}}}
{"id": "99746622d2744d149acd0f21630d1ce4", "source": "vatex", "video_id": "ocVnAfqG8os_000007_000017", "video_description": "A man is holding a bottle of beer, speaking animatedly, and removes the cap with his elbow.", "task": "Counting", "clean_prompt": "Three people are gathered around, with one man holding a bottle of beer and speaking animatedly while removing the cap with his elbow.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is sitting alone at a table, quietly sipping a drink.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people present in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are gathered around, with one man holding a bottle of beer and speaking animatedly while removing the cap with his elbow. MF9V!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33d8c16097ec489db2a670090f9f8d35.mp4", "clean_score": 1.0, "clean_xclip": 0.18302097916603088, "clean_vbench": {"subject_consistency": 0.8665877462675174, "background_consistency": 0.9120839436848959, "motion_smoothness": 0.9660834841556222, "aesthetic_quality": 0.49384328722953796, "imaging_quality": 0.5754067090092874, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6bdc9dc31ab44e8f957e4701de19cd3f.mp4", "adv_score": 0.0, "adv_xclip": 0.24062791466712952, "adv_vbench": {"subject_consistency": 0.914569546158115, "background_consistency": 0.9330546061197916, "motion_smoothness": 0.9460470526141269, "aesthetic_quality": 0.4175494313240051, "imaging_quality": 0.673152108484385, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ad405f40.mp4", "clean_score": 0.0, "clean_xclip": 0.21428583562374115, "clean_vbench": {}, "adv_vid_id": "vids/97f37308.mp4", "adv_score": 1.0, "adv_xclip": 0.2102355659008026, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a60db5ea.mp4", "clean_score": 1.0, "clean_xclip": 0.20586736500263214, "clean_vbench": {}, "adv_vid_id": "vids/c58a9496.mp4", "adv_score": 1.0, "adv_xclip": 0.2490156590938568, "adv_vbench": {}}}}
{"id": "548ac50714f24ce08b22402e03282398", "source": "vatex", "video_id": "JFWsCM8WE-w_000000_000010", "video_description": "A man is splitting a log into smaller pieces using an axe, a wedge, and a sledgehammer, while a child laughs off-screen.", "task": "ActionRecognition", "clean_prompt": "A child laughing off-screen while a man splits a log.", "clean_property": {"obj": "child", "action": "laughing", "target": null}, "target_prompt": "A child crying off-screen while a man splits a log.", "target_property": {"obj": "child", "action": "crying", "target": null}, "evaluation_question": "Is the child **laughing** off-screen?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A child laughing off-screen while a man splits a log. ))=ZB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ba45391f9684d67ae4853553b159654.mp4", "clean_score": 1.0, "clean_xclip": 0.20962819457054138, "clean_vbench": {"subject_consistency": 0.8237661042561134, "background_consistency": 0.9094696044921875, "motion_smoothness": 0.9573780701870511, "aesthetic_quality": 0.47879207134246826, "imaging_quality": 0.5477486949064293, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2fcd672866b04e13aae6945b41304ef4.mp4", "adv_score": 0.0, "adv_xclip": 0.3309379816055298, "adv_vbench": {"subject_consistency": 0.9438041877001524, "background_consistency": 0.9371592203776041, "motion_smoothness": 0.9605548031777011, "aesthetic_quality": 0.5150014162063599, "imaging_quality": 0.6019966024282027, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/050c008a.mp4", "clean_score": 0.0, "clean_xclip": 0.2750660181045532, "clean_vbench": {}, "adv_vid_id": "vids/4b0f38f0.mp4", "adv_score": 0.0, "adv_xclip": 0.2859755754470825, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7a4770e9.mp4", "clean_score": 0.0, "clean_xclip": 0.3175390660762787, "clean_vbench": {}, "adv_vid_id": "vids/3b7c46f2.mp4", "adv_score": 0.0, "adv_xclip": 0.29445767402648926, "adv_vbench": {}}}}
{"id": "7e1c5728376a42619e3dc68b1765cdaa", "source": "vatex", "video_id": "V7r_lGdJiko_000014_000024", "video_description": "A person in protective gear is welding metal on a scaffolding with decorations, creating sparks.", "task": "SpatialUnderstanding", "clean_prompt": "A welding torch to the left of a piece of metal as a person in protective gear welds on scaffolding, creating sparks.", "clean_property": {"obj_1": "welding torch", "relation": "left of", "obj_2": "metal"}, "target_prompt": "A welding torch to the right of a piece of metal as a person in protective gear welds on scaffolding, creating sparks.", "target_property": {"obj_1": "welding torch", "relation": "right of", "obj_2": "metal"}, "evaluation_question": "Is the welding torch to the **left** of the metal?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A welding torch to the left of a piece of metal as a person in protective gear welds on scaffolding, creating sparks. DYEKP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f42f63dc848943be9f91b2ab884f8766.mp4", "clean_score": 1.0, "clean_xclip": 0.24245575070381165, "clean_vbench": {"subject_consistency": 0.8843635575224956, "background_consistency": 0.9543863932291666, "motion_smoothness": 0.9482981967832144, "aesthetic_quality": 0.45256054401397705, "imaging_quality": 0.39953817134000813, "dynamic_degree": 1.0}, "adv_vid_id": "vids/84490b0b7ab54aafbba10cbb24584026.mp4", "adv_score": 0.0, "adv_xclip": 0.2443591058254242, "adv_vbench": {"subject_consistency": 0.8635042166958252, "background_consistency": 0.9327646891276041, "motion_smoothness": 0.9677312108839163, "aesthetic_quality": 0.41198113560676575, "imaging_quality": 0.6258006068638393, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e2f3b180.mp4", "clean_score": 0.0, "clean_xclip": 0.23672263324260712, "clean_vbench": {}, "adv_vid_id": "vids/2affb775.mp4", "adv_score": 0.0, "adv_xclip": 0.2375832498073578, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a453429c.mp4", "clean_score": 0.0, "clean_xclip": 0.24485749006271362, "clean_vbench": {}, "adv_vid_id": "vids/d7428a99.mp4", "adv_score": 0.0, "adv_xclip": 0.24099647998809814, "adv_vbench": {}}}}
{"id": "fe45fe4f93d74a5d90a90231df8a7575", "source": "vatex", "video_id": "PetC18IbTtQ_000155_000165", "video_description": "A choir of African American men and women sing gospel songs enthusiastically in a church, led by a pastor. They sway, clap, and sing hymns during a service.", "task": "SpatialUnderstanding", "clean_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically.", "clean_property": {"obj_1": "choir", "relation": "left of", "obj_2": "pastor"}, "target_prompt": "A choir to the right of a pastor in a church, singing gospel songs enthusiastically.", "target_property": {"obj_1": "choir", "relation": "right of", "obj_2": "pastor"}, "evaluation_question": "Is the choir to the **left** of the pastor?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically. simpliasteptam Danish intoarce martie", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2ce2c011c2347538eaaa899957c2c86.mp4", "clean_score": 1.0, "clean_xclip": 0.16354867815971375, "clean_vbench": {"subject_consistency": 0.9447596607108911, "background_consistency": 0.9476064046223959, "motion_smoothness": 0.961755214164498, "aesthetic_quality": 0.52422034740448, "imaging_quality": 0.4576585754083128, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1805454f9ad7451b91636bb850c3238a.mp4", "adv_score": 0.0, "adv_xclip": 0.17790323495864868, "adv_vbench": {"subject_consistency": 0.9654349976529678, "background_consistency": 0.96759033203125, "motion_smoothness": 0.9616352144670883, "aesthetic_quality": 0.6214079260826111, "imaging_quality": 0.5426890174710021, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/46469082.mp4", "clean_score": 0.0, "clean_xclip": 0.15737590193748474, "clean_vbench": {}, "adv_vid_id": "vids/5401240c.mp4", "adv_score": 1.0, "adv_xclip": 0.1870107352733612, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/89455680.mp4", "clean_score": 1.0, "clean_xclip": 0.20905041694641113, "clean_vbench": {}, "adv_vid_id": "vids/74d1f8c9.mp4", "adv_score": 1.0, "adv_xclip": 0.22386285662651062, "adv_vbench": {}}}}
{"id": "4509997c4d79469a90caa393d0d44e31", "source": "vatex", "video_id": "bj_kAPISHaE_000109_000119", "video_description": "A young girl is getting her ears pierced by a technician in a store setting, while talking with her friend.", "task": "Counting", "clean_prompt": "Two technicians assisting a young girl in a store while she gets her ears pierced.", "clean_property": {"obj": "technician", "count": "two"}, "target_prompt": "A technician assisting a young girl in a store while she gets her ears pierced.", "target_property": {"obj": "technician", "count": "one"}, "evaluation_question": "Are there exactly **two** technicians assisting the girl?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two technicians assisting a young girl in a store while she gets her ears pierced. -*7VH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1bfb866a52bd4f9fbbe37ede64699cc6.mp4", "clean_score": 1.0, "clean_xclip": 0.17094799876213074, "clean_vbench": {"subject_consistency": 0.980447972814242, "background_consistency": 0.956573486328125, "motion_smoothness": 0.9918625170522171, "aesthetic_quality": 0.6377317905426025, "imaging_quality": 0.7423376667256258, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8ce604e707f147628b4f55b30a9ce2a3.mp4", "adv_score": 0.0, "adv_xclip": 0.21779081225395203, "adv_vbench": {"subject_consistency": 0.987864206234614, "background_consistency": 0.9636637369791666, "motion_smoothness": 0.9915744110208384, "aesthetic_quality": 0.55806565284729, "imaging_quality": 0.7346049857626156, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/084f199f.mp4", "clean_score": 0.0, "clean_xclip": 0.17667889595031738, "clean_vbench": {}, "adv_vid_id": "vids/66af3f4a.mp4", "adv_score": 1.0, "adv_xclip": 0.13632714748382568, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5ab686a1.mp4", "clean_score": 1.0, "clean_xclip": 0.20298567414283752, "clean_vbench": {}, "adv_vid_id": "vids/2f4a8f5d.mp4", "adv_score": 1.0, "adv_xclip": 0.20641383528709412, "adv_vbench": {}}}}
{"id": "bb71ac6ad2d2441e80f15c7ef0a791b9", "source": "vatex", "video_id": "r4sYfEcGrgg_000004_000014", "video_description": "A female athlete is participating in a javelin throw event at an outdoor track. She runs and throws the javelin with force while a group of people watches.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the left of a javelin.", "clean_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "javelin"}, "target_prompt": "An athlete standing to the right of a javelin.", "target_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "javelin"}, "evaluation_question": "Is the athlete to the **left** of the javelin?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete standing to the left of a javelin. UF\u00b7(M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fcfb77d1418047b2b8dad93b8c843801.mp4", "clean_score": 1.0, "clean_xclip": 0.16777874529361725, "clean_vbench": {"subject_consistency": 0.9485111758112907, "background_consistency": 0.9692331949869791, "motion_smoothness": 0.9938784342408518, "aesthetic_quality": 0.3467642366886139, "imaging_quality": 0.6008430846856565, "dynamic_degree": 0.0}, "adv_vid_id": "vids/762f4b41c14d478ab3745f1506deaf3d.mp4", "adv_score": 0.0, "adv_xclip": 0.18510563671588898, "adv_vbench": {"subject_consistency": 0.968363311762611, "background_consistency": 0.9381459554036459, "motion_smoothness": 0.9892700806402808, "aesthetic_quality": 0.4240418076515198, "imaging_quality": 0.6116587097790777, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/acf7b842.mp4", "clean_score": 0.0, "clean_xclip": 0.20022135972976685, "clean_vbench": {}, "adv_vid_id": "vids/7aa04ca7.mp4", "adv_score": 0.0, "adv_xclip": 0.1720011979341507, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ff903d0d.mp4", "clean_score": 0.0, "clean_xclip": 0.17736075818538666, "clean_vbench": {}, "adv_vid_id": "vids/6df1bf85.mp4", "adv_score": 0.0, "adv_xclip": 0.1713636815547943, "adv_vbench": {}}}}
{"id": "fe2d2a6e441c49ea858773f9351c1126", "source": "vatex", "video_id": "KHHmcaqHH6I_000073_000083", "video_description": "A man is demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "task": "Counting", "clean_prompt": "Seven people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people gathered around the table?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Seven people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine. BMT-E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5628691c05314bbe8d65a75907558c5a.mp4", "clean_score": 1.0, "clean_xclip": 0.2031305581331253, "clean_vbench": {"subject_consistency": 0.9784547885258993, "background_consistency": 0.9560394287109375, "motion_smoothness": 0.988557543037148, "aesthetic_quality": 0.596183717250824, "imaging_quality": 0.6061903365777463, "dynamic_degree": 0.0}, "adv_vid_id": "vids/49fbc0b973f64f23b9cb42673a55a18b.mp4", "adv_score": 0.0, "adv_xclip": 0.21298396587371826, "adv_vbench": {"subject_consistency": 0.9786650501191616, "background_consistency": 0.96636962890625, "motion_smoothness": 0.9798187858380235, "aesthetic_quality": 0.5075875520706177, "imaging_quality": 0.7010646142764968, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ba65218f.mp4", "clean_score": 0.0, "clean_xclip": 0.19345225393772125, "clean_vbench": {}, "adv_vid_id": "vids/0c324f0b.mp4", "adv_score": 1.0, "adv_xclip": 0.20537737011909485, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/35e33d74.mp4", "clean_score": 1.0, "clean_xclip": 0.1981707215309143, "clean_vbench": {}, "adv_vid_id": "vids/fcbafa0b.mp4", "adv_score": 0.0, "adv_xclip": 0.20239698886871338, "adv_vbench": {}}}}
{"id": "58369777a24841cfa1ef486a6bdecb39", "source": "vatex", "video_id": "ffdu09tQWNA_000030_000040", "video_description": "A black and white cat is watching a figure skater perform on a television from a very short distance while a woman speaks to the cat.", "task": "Counting", "clean_prompt": "Four figure skaters performing a synchronized routine on ice.", "clean_property": {"obj": "figure skater", "count": "four"}, "target_prompt": "One figure skater performing a solo routine on ice.", "target_property": {"obj": "figure skater", "count": "one"}, "evaluation_question": "Are there exactly **four** figure skaters performing on the ice?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four figure skaters performing a synchronized routine on ice. !>|!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/678c5c234e2444ecad362e756a713187.mp4", "clean_score": 1.0, "clean_xclip": 0.2474619746208191, "clean_vbench": {"subject_consistency": 0.9106756572922071, "background_consistency": 0.9480692545572916, "motion_smoothness": 0.95968521749299, "aesthetic_quality": 0.406339168548584, "imaging_quality": 0.594230178521604, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d117afb51a29445583763b5fdf00b246.mp4", "adv_score": 0.0, "adv_xclip": 0.24730658531188965, "adv_vbench": {"subject_consistency": 0.9101198638478915, "background_consistency": 0.9299163818359375, "motion_smoothness": 0.9450478448645405, "aesthetic_quality": 0.4168603718280792, "imaging_quality": 0.4194991660604671, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3eefe15a.mp4", "clean_score": 0.0, "clean_xclip": 0.2254675328731537, "clean_vbench": {}, "adv_vid_id": "vids/079eaf14.mp4", "adv_score": 0.0, "adv_xclip": 0.23221702873706818, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/871476f7.mp4", "clean_score": 0.0, "clean_xclip": 0.2522010803222656, "clean_vbench": {}, "adv_vid_id": "vids/aa5389ef.mp4", "adv_score": 1.0, "adv_xclip": 0.24085170030593872, "adv_vbench": {}}}}
{"id": "d0b20857157543e89f13aabdab6cca58", "source": "vatex", "video_id": "SCSSnsCBeDQ_000040_000050", "video_description": "A busy Middle-Eastern market with people in traditional attire buying and selling goods like figs and dates.", "task": "Counting", "clean_prompt": "Two people in traditional attire are buying figs and dates in a busy Middle-Eastern market.", "clean_property": {"obj": "goods", "count": "two"}, "target_prompt": "Two people in traditional attire are buying five different types of goods in a busy Middle-Eastern market.", "target_property": {"obj": "goods", "count": "five"}, "evaluation_question": "Are there exactly **two** goods being bought in the market?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two people in traditional attire are buying figs and dates in a busy Middle-Eastern market. patru rythmeierten traduc Pentru", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad5a9bc5cec24fc7837a899eac21fa1b.mp4", "clean_score": 1.0, "clean_xclip": 0.13205213844776154, "clean_vbench": {"subject_consistency": 0.9739571486910185, "background_consistency": 0.96710205078125, "motion_smoothness": 0.9781083049024651, "aesthetic_quality": 0.698976993560791, "imaging_quality": 0.7471345722432039, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f9e89e04c89f4902b8bf96e9ec8bd55e.mp4", "adv_score": 0.0, "adv_xclip": 0.12767966091632843, "adv_vbench": {"subject_consistency": 0.9777305629104376, "background_consistency": 0.9808756510416666, "motion_smoothness": 0.9792239838643791, "aesthetic_quality": 0.6967786550521851, "imaging_quality": 0.7557493762580715, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f7940162.mp4", "clean_score": 0.0, "clean_xclip": 0.1594298779964447, "clean_vbench": {}, "adv_vid_id": "vids/e07b00de.mp4", "adv_score": 1.0, "adv_xclip": 0.20417067408561707, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b7996fd6.mp4", "clean_score": 0.0, "clean_xclip": 0.2595384120941162, "clean_vbench": {}, "adv_vid_id": "vids/359f56d4.mp4", "adv_score": 0.0, "adv_xclip": 0.2157909870147705, "adv_vbench": {}}}}
{"id": "6f873b4e242448d09a81979a3a102f16", "source": "vatex", "video_id": "3vH5mnAy98Y_000016_000026", "video_description": "A man is juggling illuminated balls of various colors, including red and green, in the middle of a street at night.", "task": "SpatialUnderstanding", "clean_prompt": "A juggler farther from the camera than a ball, juggling illuminated balls of various colors in the middle of a street at night.", "clean_property": {"obj_1": "juggler", "relation": "farther from the camera than", "obj_2": "ball"}, "target_prompt": "A juggler closer to the camera than a ball, juggling illuminated balls of various colors in the middle of a street at night.", "target_property": {"obj_1": "juggler", "relation": "closer to the camera than", "obj_2": "ball"}, "evaluation_question": "Is the juggler farther from the camera than the ball?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A juggler farther from the camera than a ball, juggling illuminated balls of various colors in the middle of a street at night. luni psychologiqueinsta fingerprint Terrasse", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1c15d8a83769452688d41d1223f8d529.mp4", "clean_score": 1.0, "clean_xclip": 0.20581349730491638, "clean_vbench": {"subject_consistency": 0.8200727278987566, "background_consistency": 0.9001566569010416, "motion_smoothness": 0.9848069230424937, "aesthetic_quality": 0.4440779387950897, "imaging_quality": 0.2742436264972298, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1a9f00fa638b41e7a7e64d93491fbadb.mp4", "adv_score": 0.0, "adv_xclip": 0.2279709279537201, "adv_vbench": {"subject_consistency": 0.8002349765350422, "background_consistency": 0.8897857666015625, "motion_smoothness": 0.9873198953353204, "aesthetic_quality": 0.43845129013061523, "imaging_quality": 0.2765552520751953, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0d0c4f5e.mp4", "clean_score": 0.0, "clean_xclip": 0.19639518857002258, "clean_vbench": {}, "adv_vid_id": "vids/9e68f9aa.mp4", "adv_score": 0.0, "adv_xclip": 0.22033929824829102, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f4587d29.mp4", "clean_score": 0.0, "clean_xclip": 0.24104973673820496, "clean_vbench": {}, "adv_vid_id": "vids/b154324f.mp4", "adv_score": 0.0, "adv_xclip": 0.24748551845550537, "adv_vbench": {}}}}
{"id": "d9db76872e044dda955910c46d0e2fe4", "source": "vatex", "video_id": "9HTIw125wt8_000103_000113", "video_description": "A young male athlete is participating in a high jump event at an indoor track and field meet. He runs towards the high jump bar, jumps over it backwards, and lands on a mat while a crowd watches.", "task": "ActionRecognition", "clean_prompt": "An athlete participating in a high jump event at an indoor track and field meet.", "clean_property": {"obj": "athlete", "action": "high jump", "target": null}, "target_prompt": "An athlete participating in a long jump event at an indoor track and field meet.", "target_property": {"obj": "athlete", "action": "long jump", "target": null}, "evaluation_question": "Is the athlete **participating in a high jump** event?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An athlete participating in a high jump event at an indoor track and field meet. apar Balkon Architekt GmbH maison", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be5d2d47d5b248ed9f5c70557a397332.mp4", "clean_score": 1.0, "clean_xclip": 0.20946118235588074, "clean_vbench": {"subject_consistency": 0.8919527636220058, "background_consistency": 0.9332987467447916, "motion_smoothness": 0.9672870912511095, "aesthetic_quality": 0.47326818108558655, "imaging_quality": 0.4486442001498475, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0cc601fb829e409c882a1016b7dd3f25.mp4", "adv_score": 0.0, "adv_xclip": 0.16104893386363983, "adv_vbench": {"subject_consistency": 0.8815884512538711, "background_consistency": 0.9124348958333334, "motion_smoothness": 0.9721537889332688, "aesthetic_quality": 0.47741883993148804, "imaging_quality": 0.5409821887892119, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e89e5e32.mp4", "clean_score": 1.0, "clean_xclip": 0.1724362075328827, "clean_vbench": {}, "adv_vid_id": "vids/590a2c3e.mp4", "adv_score": 1.0, "adv_xclip": 0.18866783380508423, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c381c1e2.mp4", "clean_score": 1.0, "clean_xclip": 0.1818496137857437, "clean_vbench": {}, "adv_vid_id": "vids/d0683b4d.mp4", "adv_score": 0.0, "adv_xclip": 0.1415465772151947, "adv_vbench": {}}}}
{"id": "a84ed69a400343248abceb7d5013c938", "source": "vatex", "video_id": "5ACA2s0Xq5U_000030_000040", "video_description": "A little boy with a cast on his arm is attempting to brush his teeth while his mother gives him instructions. The boy walks around the room with a toothbrush in his mouth.", "task": "AttributeRecognition", "clean_prompt": "A boy with a cast on his arm is attempting to brush his teeth while his mother gives him instructions.", "clean_property": {"obj": "boy", "attribute": "cast on arm"}, "target_prompt": "A boy wearing a superhero costume is attempting to brush his teeth while his mother gives him instructions.", "target_property": {"obj": "boy", "attribute": "wearing a superhero costume"}, "evaluation_question": "Is the boy wearing a **cast** on his arm?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy with a cast on his arm is attempting to brush his teeth while his mother gives him instructions. baz poivrEnergi toothpaste Craciun", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9bd6c8d613764fb4b9499779adb338bd.mp4", "clean_score": 1.0, "clean_xclip": 0.12650179862976074, "clean_vbench": {"subject_consistency": 0.9686538918564717, "background_consistency": 0.9617563883463541, "motion_smoothness": 0.9764127771221658, "aesthetic_quality": 0.511360764503479, "imaging_quality": 0.7086227993089325, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e2f05b21a7f844f5b54990fb230836f9.mp4", "adv_score": 0.0, "adv_xclip": 0.18225014209747314, "adv_vbench": {"subject_consistency": 0.9594600958128771, "background_consistency": 0.9573109944661459, "motion_smoothness": 0.9702816744142359, "aesthetic_quality": 0.5183960199356079, "imaging_quality": 0.5823711060504524, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/66a8e4df.mp4", "clean_score": 0.0, "clean_xclip": 0.17881309986114502, "clean_vbench": {}, "adv_vid_id": "vids/5bc8b03d.mp4", "adv_score": 0.0, "adv_xclip": 0.15914727747440338, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/94a861bc.mp4", "clean_score": 0.0, "clean_xclip": 0.2014901041984558, "clean_vbench": {}, "adv_vid_id": "vids/f1bf1b66.mp4", "adv_score": 0.0, "adv_xclip": 0.18851350247859955, "adv_vbench": {}}}}
{"id": "5fc04e655d6d4d30933e99d91ef9e08b", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "Counting", "clean_prompt": "Three people sitting around a poker table in a casino, playing poker with cards and chips.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting alone at a poker table in a casino, playing poker with cards and chips.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting around the poker table?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three people sitting around a poker table in a casino, playing poker with cards and chips. leicht Geschwindigkeit optisch Bildschirm Napoleon", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/163508b9d7ca416a81c2278adbab3227.mp4", "clean_score": 1.0, "clean_xclip": 0.23244784772396088, "clean_vbench": {"subject_consistency": 0.9956713858991861, "background_consistency": 0.9743296305338541, "motion_smoothness": 0.9958708969087893, "aesthetic_quality": 0.5711528658866882, "imaging_quality": 0.5882581562898597, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8ba59a62bc8a4819b06c6436c175de42.mp4", "adv_score": 0.0, "adv_xclip": 0.1243334710597992, "adv_vbench": {"subject_consistency": 1.0, "background_consistency": 1.0, "motion_smoothness": 1.0, "aesthetic_quality": 0.33590564131736755, "imaging_quality": 0.20485637664794923, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c19f257b.mp4", "clean_score": 1.0, "clean_xclip": 0.23771071434020996, "clean_vbench": {}, "adv_vid_id": "vids/a24d7c69.mp4", "adv_score": 1.0, "adv_xclip": 0.2613428831100464, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fb804fee.mp4", "clean_score": 1.0, "clean_xclip": 0.24092166125774384, "clean_vbench": {}, "adv_vid_id": "vids/7cbde6bb.mp4", "adv_score": 1.0, "adv_xclip": 0.2482350617647171, "adv_vbench": {}}}}
{"id": "898da830aa1e4e2785dd1453cc0f0774", "source": "vatex", "video_id": "xGe0cXA3OnI_000004_000014", "video_description": "A group of people are riding camels in the desert during the daytime. The camels kneel and sit to allow the riders to dismount.", "task": "Counting", "clean_prompt": "Seven people riding camels in the desert during the daytime.", "clean_property": {"obj": "camel", "count": "seven"}, "target_prompt": "One person riding a camel in the desert during the daytime.", "target_property": {"obj": "camel", "count": "one"}, "evaluation_question": "Are there exactly **seven** camels being ridden in the desert?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people riding camels in the desert during the daytime. FS+|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7ea2c9c48b3b464a944e24c580dde868.mp4", "clean_score": 1.0, "clean_xclip": 0.21789862215518951, "clean_vbench": {"subject_consistency": 0.9886455436547598, "background_consistency": 0.9798329671223959, "motion_smoothness": 0.9932520492604191, "aesthetic_quality": 0.6378155946731567, "imaging_quality": 0.6942336880430884, "dynamic_degree": 0.0}, "adv_vid_id": "vids/84ea33a9267042ba91b5ff6655379163.mp4", "adv_score": 0.0, "adv_xclip": 0.2180004119873047, "adv_vbench": {"subject_consistency": 0.9894697275012732, "background_consistency": 0.9782613118489584, "motion_smoothness": 0.994133155435528, "aesthetic_quality": 0.6197060346603394, "imaging_quality": 0.7279937027911751, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/90b68e9d.mp4", "clean_score": 1.0, "clean_xclip": 0.2062334269285202, "clean_vbench": {}, "adv_vid_id": "vids/d6c0ba55.mp4", "adv_score": 0.0, "adv_xclip": 0.2227420210838318, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/841c6c03.mp4", "clean_score": 0.0, "clean_xclip": 0.2222689986228943, "clean_vbench": {}, "adv_vid_id": "vids/b318e83d.mp4", "adv_score": 0.0, "adv_xclip": 0.23021942377090454, "adv_vbench": {}}}}
{"id": "c12aee5120d6454896c6d5d372f1182a", "source": "vatex", "video_id": "KHHmcaqHH6I_000073_000083", "video_description": "A man is demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "task": "Counting", "clean_prompt": "Seven people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people gathered around the table?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine. superbe Schon Portuguese Illustration gelungen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb45a09ba1bb4e6ea72d3f72b6c84fef.mp4", "clean_score": 1.0, "clean_xclip": 0.2031305581331253, "clean_vbench": {"subject_consistency": 0.9784547885258993, "background_consistency": 0.9560394287109375, "motion_smoothness": 0.988557543037148, "aesthetic_quality": 0.596183717250824, "imaging_quality": 0.6061903365777463, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1721c1e6393e401fb4da75b6dd63a00c.mp4", "adv_score": 0.0, "adv_xclip": 0.17438045144081116, "adv_vbench": {"subject_consistency": 0.9815551110853752, "background_consistency": 0.9854583740234375, "motion_smoothness": 0.9945044411411684, "aesthetic_quality": 0.5914985537528992, "imaging_quality": 0.7344805503378109, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e975c7d7.mp4", "clean_score": 1.0, "clean_xclip": 0.207495778799057, "clean_vbench": {}, "adv_vid_id": "vids/e6163531.mp4", "adv_score": 1.0, "adv_xclip": 0.1325678527355194, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3658951a.mp4", "clean_score": 1.0, "clean_xclip": 0.20730847120285034, "clean_vbench": {}, "adv_vid_id": "vids/a0f9923d.mp4", "adv_score": 1.0, "adv_xclip": 0.24589648842811584, "adv_vbench": {}}}}
{"id": "f74e025ff4a84a64be0f33855ddabebc", "source": "vatex", "video_id": "hyqD2ZGznWo_000040_000050", "video_description": "A young woman is outdoors in a backyard, throwing knives at a cardboard box placed on a chair.", "task": "ActionRecognition", "clean_prompt": "A woman throwing knives at a cardboard box in a backyard.", "clean_property": {"obj": "woman", "action": "throwing knife", "target": "box"}, "target_prompt": "A woman catching a frisbee with a dog in a backyard.", "target_property": {"obj": "woman", "action": "catching frisbee", "target": "dog"}, "evaluation_question": "Is the woman **throwing knives**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman throwing knives at a cardboard box in a backyard. &;LF2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1d27dc8c1e6b4ff4ae80d5c12745d03b.mp4", "clean_score": 1.0, "clean_xclip": 0.22951775789260864, "clean_vbench": {"subject_consistency": 0.9123985512802998, "background_consistency": 0.9476776123046875, "motion_smoothness": 0.9798870224433652, "aesthetic_quality": 0.3966980576515198, "imaging_quality": 0.6396286080808056, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9ff36c3008aa45b190e72d60ca194045.mp4", "adv_score": 0.0, "adv_xclip": 0.23116597533226013, "adv_vbench": {"subject_consistency": 0.9373101691404978, "background_consistency": 0.9578297932942709, "motion_smoothness": 0.9833825663302872, "aesthetic_quality": 0.4418557584285736, "imaging_quality": 0.7737061060691366, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/08d5e4a4.mp4", "clean_score": 1.0, "clean_xclip": 0.1922563761472702, "clean_vbench": {}, "adv_vid_id": "vids/d8f98d15.mp4", "adv_score": 0.0, "adv_xclip": 0.23617522418498993, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1359689e.mp4", "clean_score": 1.0, "clean_xclip": 0.2563284635543823, "clean_vbench": {}, "adv_vid_id": "vids/563a8464.mp4", "adv_score": 0.0, "adv_xclip": 0.2601439356803894, "adv_vbench": {}}}}
{"id": "6cf046bd45694ce898613dafedddbfa1", "source": "vatex", "video_id": "KoY-HBCL_wg_000278_000288", "video_description": "A woman is demonstrating how to make balloon animals using a long pink balloon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a pink balloon while demonstrating how to make balloon animals.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "balloon"}, "target_prompt": "A person standing to the left of a pink balloon while demonstrating how to make balloon animals.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "balloon"}, "evaluation_question": "Is the person to the **right** of a pink balloon?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing to the right of a pink balloon while demonstrating how to make balloon animals. montrerelasticityquino carcas galben", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a981227bbda46958a70df88343a56fc.mp4", "clean_score": 1.0, "clean_xclip": 0.2651861011981964, "clean_vbench": {"subject_consistency": 0.9187559895217419, "background_consistency": 0.9278920491536459, "motion_smoothness": 0.9674309516019628, "aesthetic_quality": 0.4680231809616089, "imaging_quality": 0.6156264472494319, "dynamic_degree": 1.0}, "adv_vid_id": "vids/84ad5eb7505d48008ecd12c539995d99.mp4", "adv_score": 0.0, "adv_xclip": 0.2521768808364868, "adv_vbench": {"subject_consistency": 0.8879708256572485, "background_consistency": 0.9247945149739584, "motion_smoothness": 0.9819439989119362, "aesthetic_quality": 0.39117029309272766, "imaging_quality": 0.45591615482252473, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4a116631.mp4", "clean_score": 0.0, "clean_xclip": 0.25821685791015625, "clean_vbench": {}, "adv_vid_id": "vids/f5606b41.mp4", "adv_score": 0.0, "adv_xclip": 0.2514770030975342, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1f59aa41.mp4", "clean_score": 0.0, "clean_xclip": 0.2268703281879425, "clean_vbench": {}, "adv_vid_id": "vids/3746d3f1.mp4", "adv_score": 1.0, "adv_xclip": 0.2499830275774002, "adv_vbench": {}}}}
{"id": "6cc3252fe9884248b6eb93677f386324", "source": "vatex", "video_id": "6IV0gaQy1UE_000000_000010", "video_description": "An older man is talking to a small boy on a sidewalk when a woman runs up and throws water balloons at the man.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the right of a woman on a sidewalk.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A girl standing to the left of a man on a sidewalk.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the boy to the **right** of a woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the right of a woman on a sidewalk. FEH4@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a6a305a22264d4589973631ae89162b.mp4", "clean_score": 1.0, "clean_xclip": 0.21650032699108124, "clean_vbench": {"subject_consistency": 0.9357022127757469, "background_consistency": 0.9518229166666666, "motion_smoothness": 0.9732576482817921, "aesthetic_quality": 0.5249910354614258, "imaging_quality": 0.6389263573471381, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b4a6f6ecfaae4674a08656f74047cc14.mp4", "adv_score": 0.0, "adv_xclip": 0.18711209297180176, "adv_vbench": {"subject_consistency": 0.9870359102884928, "background_consistency": 0.9716746012369791, "motion_smoothness": 0.987498168856663, "aesthetic_quality": 0.48949703574180603, "imaging_quality": 0.7311156198929767, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/58af71ee.mp4", "clean_score": 0.0, "clean_xclip": 0.1617274433374405, "clean_vbench": {}, "adv_vid_id": "vids/c715b0d0.mp4", "adv_score": 0.0, "adv_xclip": 0.1749766767024994, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/17a02806.mp4", "clean_score": 1.0, "clean_xclip": 0.153529092669487, "clean_vbench": {}, "adv_vid_id": "vids/1b204bd3.mp4", "adv_score": 0.0, "adv_xclip": 0.17294418811798096, "adv_vbench": {}}}}
{"id": "cf3fcd244bfe452c890958a2b2415d3d", "source": "vatex", "video_id": "o-MhYRW1Stk_000002_000012", "video_description": "A group of blindfolded people are conducting a blind taste test, tasting food with a spoon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a plate of food during a blind taste test.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "food"}, "target_prompt": "A person standing to the right of a plate of food during a blind taste test.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "plate of food"}, "evaluation_question": "Is the person to the **left** of a plate of food?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the left of a plate of food during a blind taste test. !$G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/987015efb4464f98bfdb58d50e3f8726.mp4", "clean_score": 1.0, "clean_xclip": 0.12229744344949722, "clean_vbench": {"subject_consistency": 0.9807130495707194, "background_consistency": 0.9760640462239584, "motion_smoothness": 0.9856321223737695, "aesthetic_quality": 0.4696328341960907, "imaging_quality": 0.7153785152824558, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a4151dfc386f423ca19a7fafc21b61e9.mp4", "adv_score": 0.0, "adv_xclip": 0.1740613579750061, "adv_vbench": {"subject_consistency": 0.9603045222659906, "background_consistency": 0.9595082600911459, "motion_smoothness": 0.9902395048490075, "aesthetic_quality": 0.4907168745994568, "imaging_quality": 0.7400098543750997, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7594a6f1.mp4", "clean_score": 1.0, "clean_xclip": 0.21310847997665405, "clean_vbench": {}, "adv_vid_id": "vids/f3c0301b.mp4", "adv_score": 0.0, "adv_xclip": 0.16053640842437744, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e549dffb.mp4", "clean_score": 0.0, "clean_xclip": 0.12140735238790512, "clean_vbench": {}, "adv_vid_id": "vids/fcdbf29a.mp4", "adv_score": 0.0, "adv_xclip": 0.14346328377723694, "adv_vbench": {}}}}
{"id": "84711be2b930427f98588604cda9000c", "source": "vatex", "video_id": "Q7lQz_-v40g_000043_000053", "video_description": "Two young Asian girls are in a living room, listening to music and dancing. They are pretending to sneeze and cough as part of a game or song.", "task": "ActionRecognition", "clean_prompt": "A girl singing in a living room.", "clean_property": {"obj": "girl", "action": "singing", "target": null}, "target_prompt": "A girl dancing in a living room.", "target_property": {"obj": "girl", "action": "dancing", "target": null}, "evaluation_question": "Is the girl **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A girl singing in a living room. /!0&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3e0407a454d494491b383de229d25be.mp4", "clean_score": 1.0, "clean_xclip": 0.1372246891260147, "clean_vbench": {"subject_consistency": 0.9152138624340296, "background_consistency": 0.9365641276041666, "motion_smoothness": 0.9650165014083051, "aesthetic_quality": 0.45715299248695374, "imaging_quality": 0.6240074469118703, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3ce6da634507412683f7caa165f0be28.mp4", "adv_score": 0.0, "adv_xclip": 0.03799019008874893, "adv_vbench": {"subject_consistency": 0.9257138408720493, "background_consistency": 0.9369049072265625, "motion_smoothness": 0.970827509102921, "aesthetic_quality": 0.4956713318824768, "imaging_quality": 0.5390847879526567, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2ea638db.mp4", "clean_score": 1.0, "clean_xclip": 0.1510019600391388, "clean_vbench": {}, "adv_vid_id": "vids/bb9873b6.mp4", "adv_score": 1.0, "adv_xclip": 0.12466463446617126, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fd0fa3d7.mp4", "clean_score": 1.0, "clean_xclip": 0.17018547654151917, "clean_vbench": {}, "adv_vid_id": "vids/e8078a24.mp4", "adv_score": 1.0, "adv_xclip": 0.19366124272346497, "adv_vbench": {}}}}
{"id": "82962183eb124a2eaee2ffb89c3b4c0c", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "ObjectRecognition", "clean_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway.", "clean_property": {"obj": "person"}, "target_prompt": "A woman wearing summer clothing demonstrates how to shovel sand from a beach.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway. BucSpr dispus Fleisch dahin", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0318bcdb9a34d63aafe819fd8b0bf53.mp4", "clean_score": 1.0, "clean_xclip": 0.23421117663383484, "clean_vbench": {"subject_consistency": 0.9219341731319824, "background_consistency": 0.9560038248697916, "motion_smoothness": 0.9834225510999153, "aesthetic_quality": 0.5952986478805542, "imaging_quality": 0.6354128358802017, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1a1683e795744e9c986e0c713dff65c0.mp4", "adv_score": 0.0, "adv_xclip": 0.24205799400806427, "adv_vbench": {"subject_consistency": 0.8681047403564056, "background_consistency": 0.9419962565104166, "motion_smoothness": 0.9699114383182543, "aesthetic_quality": 0.47112834453582764, "imaging_quality": 0.6329351534162249, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c585813f.mp4", "clean_score": 1.0, "clean_xclip": 0.23016932606697083, "clean_vbench": {}, "adv_vid_id": "vids/d3fa9c90.mp4", "adv_score": 1.0, "adv_xclip": 0.21811167895793915, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/92c20803.mp4", "clean_score": 1.0, "clean_xclip": 0.224260613322258, "clean_vbench": {}, "adv_vid_id": "vids/3ce114c2.mp4", "adv_score": 1.0, "adv_xclip": 0.2252722978591919, "adv_vbench": {}}}}
{"id": "d2c01601ed6d416b89309c06a10d3f1c", "source": "vatex", "video_id": "XXQZz6FuEYI_000183_000193", "video_description": "A man is in a gym demonstrating exercises using a sledgehammer, swinging it behind and in front of him.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer in a gym.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": null}, "target_prompt": "A person lifting a sledgehammer in a gym.", "target_property": {"obj": "person", "action": "lifting a sledgehammer", "target": null}, "evaluation_question": "Is the person **using** a sledgehammer?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person using a sledgehammer in a gym. %%.WS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cede17b79b44f079b6fb781345000da.mp4", "clean_score": 1.0, "clean_xclip": 0.10628841817378998, "clean_vbench": {"subject_consistency": 0.9229966886341572, "background_consistency": 0.937042236328125, "motion_smoothness": 0.9580262484366174, "aesthetic_quality": 0.4031575322151184, "imaging_quality": 0.5390656124815649, "dynamic_degree": 1.0}, "adv_vid_id": "vids/edcbfedabdee4c2291e35137747c4f1c.mp4", "adv_score": 0.0, "adv_xclip": 0.09926210343837738, "adv_vbench": {"subject_consistency": 0.906191156556209, "background_consistency": 0.9563242594401041, "motion_smoothness": 0.9493975333542626, "aesthetic_quality": 0.4327721893787384, "imaging_quality": 0.43727177366918446, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6ccd15e3.mp4", "clean_score": 1.0, "clean_xclip": 0.14929251372814178, "clean_vbench": {}, "adv_vid_id": "vids/f00f026a.mp4", "adv_score": 0.0, "adv_xclip": 0.09163770079612732, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4e738504.mp4", "clean_score": 1.0, "clean_xclip": 0.1507248878479004, "clean_vbench": {}, "adv_vid_id": "vids/332b5817.mp4", "adv_score": 1.0, "adv_xclip": 0.15229570865631104, "adv_vbench": {}}}}
{"id": "e456bc0cf82b49caa848871b051af3b1", "source": "vatex", "video_id": "MBd1ohDjbag_000000_000010", "video_description": "A man is in a wooded area throwing an axe at a tree, successfully sticking it into the trunk.", "task": "SpatialUnderstanding", "clean_prompt": "A tree to the left of a person in a wooded area.", "clean_property": {"obj_1": "tree", "relation": "left of", "obj_2": "person"}, "target_prompt": "A tree to the right of a person in a wooded area.", "target_property": {"obj_1": "tree", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the tree to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A tree to the left of a person in a wooded area.steuerucun Mechanism Webseiteouvrir", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6f45e466ed114de19498d851df9477ce.mp4", "clean_score": 1.0, "clean_xclip": 0.14463090896606445, "clean_vbench": {"subject_consistency": 0.9134052085379759, "background_consistency": 0.9439595540364584, "motion_smoothness": 0.9885775187164629, "aesthetic_quality": 0.5201324820518494, "imaging_quality": 0.5637563316189513, "dynamic_degree": 0.0}, "adv_vid_id": "vids/e8df9fb5144b4778b891dc9182376562.mp4", "adv_score": 0.0, "adv_xclip": 0.1677970290184021, "adv_vbench": {"subject_consistency": 0.993525850897034, "background_consistency": 0.9776357014973959, "motion_smoothness": 0.9859186377579581, "aesthetic_quality": 0.5347870588302612, "imaging_quality": 0.7743754203952089, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8d3f1f59.mp4", "clean_score": 0.0, "clean_xclip": 0.1777755171060562, "clean_vbench": {}, "adv_vid_id": "vids/d45a6ae6.mp4", "adv_score": 1.0, "adv_xclip": 0.15215039253234863, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e222868e.mp4", "clean_score": 0.0, "clean_xclip": 0.16018562018871307, "clean_vbench": {}, "adv_vid_id": "vids/c903e60c.mp4", "adv_score": 0.0, "adv_xclip": 0.18869461119174957, "adv_vbench": {}}}}
{"id": "d2b570a724774675bb7330b4c3b6a5c5", "source": "vatex", "video_id": "ZcYB6tPK2Eo_000138_000148", "video_description": "A man is demonstrating how to solve a Rubik's cube, explaining his process while manipulating the cube.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a Rubik's cube, demonstrating how to solve it.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "rubik's cube"}, "target_prompt": "A person beside a Rubik's cube, demonstrating how to solve it.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "Rubik's cube"}, "evaluation_question": "Is the person **above** the Rubik's cube?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person above a Rubik's cube, demonstrating how to solve it. kleiner Rub sechs joue Blatt", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/095a9e70e9a94c3aa089464de9e34c26.mp4", "clean_score": 1.0, "clean_xclip": 0.22496874630451202, "clean_vbench": {"subject_consistency": 0.8962103991458813, "background_consistency": 0.9566752115885416, "motion_smoothness": 0.9464528967965787, "aesthetic_quality": 0.4734114706516266, "imaging_quality": 0.6485209087449677, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9dcacd83c81649e48ee125c41f3a741e.mp4", "adv_score": 0.0, "adv_xclip": 0.22892135381698608, "adv_vbench": {"subject_consistency": 0.8763602431863546, "background_consistency": 0.9302775065104166, "motion_smoothness": 0.9528977809423668, "aesthetic_quality": 0.3928014636039734, "imaging_quality": 0.6629303305489677, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a380e4d9.mp4", "clean_score": 0.0, "clean_xclip": 0.24057906866073608, "clean_vbench": {}, "adv_vid_id": "vids/afc6ea50.mp4", "adv_score": 0.0, "adv_xclip": 0.2557438611984253, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9691114f.mp4", "clean_score": 0.0, "clean_xclip": 0.2720455229282379, "clean_vbench": {}, "adv_vid_id": "vids/0406715a.mp4", "adv_score": 0.0, "adv_xclip": 0.25440657138824463, "adv_vbench": {}}}}
{"id": "8a29a389077d47b4bb9a549e7af08615", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a pipe bending tool.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "pipe bending tool"}, "target_prompt": "A person welding a pipe bending tool.", "target_property": {"obj": "person", "action": "welding", "target": "pipe bending tool"}, "evaluation_question": "Is the person **using a sledge hammer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer on a pipe bending tool. &&FEI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/deb0faafb6a34b748bd8af2e9556c0a4.mp4", "clean_score": 1.0, "clean_xclip": 0.1312677264213562, "clean_vbench": {"subject_consistency": 0.9125906936824322, "background_consistency": 0.9667765299479166, "motion_smoothness": 0.9629235321539881, "aesthetic_quality": 0.5191364288330078, "imaging_quality": 0.6687143349160953, "dynamic_degree": 1.0}, "adv_vid_id": "vids/95cd0881834f4e2484aee524e0b82564.mp4", "adv_score": 0.0, "adv_xclip": 0.14584079384803772, "adv_vbench": {"subject_consistency": 0.902554182956616, "background_consistency": 0.9568125406901041, "motion_smoothness": 0.9565215452082325, "aesthetic_quality": 0.45259761810302734, "imaging_quality": 0.6882138575339803, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e1aa430a.mp4", "clean_score": 0.0, "clean_xclip": 0.11745519936084747, "clean_vbench": {}, "adv_vid_id": "vids/40b65a5c.mp4", "adv_score": 1.0, "adv_xclip": 0.14280623197555542, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b6858b51.mp4", "clean_score": 1.0, "clean_xclip": 0.13576596975326538, "clean_vbench": {}, "adv_vid_id": "vids/36af36a3.mp4", "adv_score": 0.0, "adv_xclip": 0.130257248878479, "adv_vbench": {}}}}
{"id": "b0a3052b2d134e7da98fa9c2179e0327", "source": "vatex", "video_id": "IH4_ueC5oV0_000007_000017", "video_description": "A young man is standing in a room, practicing and playing music on a saxophone.", "task": "ActionRecognition", "clean_prompt": "A person playing saxophone in a room.", "clean_property": {"obj": "person", "action": "playing saxophone", "target": null}, "target_prompt": "A person playing guitar in a room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing saxophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing saxophone in a room. OF,BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5761c5fd9f6d4bb5bcb19965629a4001.mp4", "clean_score": 1.0, "clean_xclip": 0.2278626263141632, "clean_vbench": {"subject_consistency": 0.9386443582673868, "background_consistency": 0.9066162109375, "motion_smoothness": 0.9806224527265895, "aesthetic_quality": 0.42447754740715027, "imaging_quality": 0.5705792392030054, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ddb93de1287444b5a95f1e5326b37a73.mp4", "adv_score": 0.0, "adv_xclip": 0.23095083236694336, "adv_vbench": {"subject_consistency": 0.917674527813991, "background_consistency": 0.9584503173828125, "motion_smoothness": 0.9356169003545348, "aesthetic_quality": 0.4516300857067108, "imaging_quality": 0.5573791472765864, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8c525ec2.mp4", "clean_score": 1.0, "clean_xclip": 0.24406875669956207, "clean_vbench": {}, "adv_vid_id": "vids/51697c6a.mp4", "adv_score": 1.0, "adv_xclip": 0.2299155741930008, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/acf03deb.mp4", "clean_score": 1.0, "clean_xclip": 0.23577973246574402, "clean_vbench": {}, "adv_vid_id": "vids/66f8e5a0.mp4", "adv_score": 1.0, "adv_xclip": 0.23386342823505402, "adv_vbench": {}}}}
{"id": "cd7342234a504ade9f79f2bd83bf5d31", "source": "vatex", "video_id": "7VUQg_VVUgQ_000004_000014", "video_description": "Two women are riding horses along a narrow, rocky dirt path. One woman waves while riding, and they are having a great time.", "task": "Counting", "clean_prompt": "Six women riding horses along a narrow, rocky dirt path, with one woman waving and all having a great time.", "clean_property": {"obj": "woman", "count": "six"}, "target_prompt": "Three women riding bicycles along a narrow, rocky dirt path, with one woman waving and all having a great time.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** women riding horses along the path?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six women riding horses along a narrow, rocky dirt path, with one woman waving and all having a great time. $FOE\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c89d6cf72c54b35a114e157fbdce78b.mp4", "clean_score": 1.0, "clean_xclip": 0.2419205605983734, "clean_vbench": {"subject_consistency": 0.9163777157664299, "background_consistency": 0.9531046549479166, "motion_smoothness": 0.9791776714929799, "aesthetic_quality": 0.6000481843948364, "imaging_quality": 0.716471149678133, "dynamic_degree": 0.0}, "adv_vid_id": "vids/66d305678f6244beaf6800f96a984fac.mp4", "adv_score": 0.0, "adv_xclip": 0.2531513571739197, "adv_vbench": {"subject_consistency": 0.9245975855737925, "background_consistency": 0.944854736328125, "motion_smoothness": 0.9762422212261962, "aesthetic_quality": 0.6151356101036072, "imaging_quality": 0.7193182840152663, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e361aa8b.mp4", "clean_score": 1.0, "clean_xclip": 0.26191142201423645, "clean_vbench": {}, "adv_vid_id": "vids/1738917a.mp4", "adv_score": 0.0, "adv_xclip": 0.24672777950763702, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e8cb5f39.mp4", "clean_score": 0.0, "clean_xclip": 0.24739393591880798, "clean_vbench": {}, "adv_vid_id": "vids/226e90a7.mp4", "adv_score": 0.0, "adv_xclip": 0.23953135311603546, "adv_vbench": {}}}}
{"id": "1a766287a7fc48e3853c718d2aa0e9f0", "source": "vatex", "video_id": "-JF20LJFGZM_000105_000115", "video_description": "Multiple skiers, including one in an orange suit, are skiing down a race course with cones. The skier in orange falls multiple times but continues skiing. Onlookers watch from behind a fence.", "task": "Counting", "clean_prompt": "Six onlookers watching skiers from behind a fence.", "clean_property": {"obj": "onlooker", "count": "six"}, "target_prompt": "Three onlookers watching skiers from behind a fence.", "target_property": {"obj": "onlooker", "count": "three"}, "evaluation_question": "Are there exactly **six** onlookers watching the skiers?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six onlookers watching skiers from behind a fence. SL!I(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6e642efa31743229a8217f8afa82af0.mp4", "clean_score": 1.0, "clean_xclip": 0.1431201696395874, "clean_vbench": {"subject_consistency": 0.994206947584947, "background_consistency": 0.9823811848958334, "motion_smoothness": 0.9948352018276446, "aesthetic_quality": 0.580764651298523, "imaging_quality": 0.5972620033731266, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8fd989ce1cd043de866e5dfb7f8510c8.mp4", "adv_score": 0.0, "adv_xclip": 0.18850840628147125, "adv_vbench": {"subject_consistency": 0.9924582509944836, "background_consistency": 0.9875590006510416, "motion_smoothness": 0.9909654735157952, "aesthetic_quality": 0.5913536548614502, "imaging_quality": 0.5878454309580278, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/65ee30ba.mp4", "clean_score": 1.0, "clean_xclip": 0.22773690521717072, "clean_vbench": {}, "adv_vid_id": "vids/72b3aa1e.mp4", "adv_score": 1.0, "adv_xclip": 0.21274235844612122, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/762d1267.mp4", "clean_score": 1.0, "clean_xclip": 0.16110588610172272, "clean_vbench": {}, "adv_vid_id": "vids/bb331dd3.mp4", "adv_score": 1.0, "adv_xclip": 0.14045578241348267, "adv_vbench": {}}}}
{"id": "e41420aa519644e7b3f2cb98b90cecd4", "source": "vatex", "video_id": "bd9RnFJtUJ8_000315_000325", "video_description": "An adult and a child are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground.", "task": "ObjectRecognition", "clean_prompt": "An adult and a child are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground.", "clean_property": {"obj": "child"}, "target_prompt": "An adult and a dog are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground.", "target_property": {"obj": "dog"}, "evaluation_question": "Is there a **child** paragliding in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult and a child are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground. OF)BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9d927b6e3b4541648b05eff22b21fa27.mp4", "clean_score": 1.0, "clean_xclip": 0.2303774505853653, "clean_vbench": {"subject_consistency": 0.956184891362985, "background_consistency": 0.9463857014973959, "motion_smoothness": 0.9925937375496752, "aesthetic_quality": 0.5079130530357361, "imaging_quality": 0.7260477992466519, "dynamic_degree": 0.0}, "adv_vid_id": "vids/b5b2b412f7954114911f77c74894b45b.mp4", "adv_score": 0.0, "adv_xclip": 0.23325645923614502, "adv_vbench": {"subject_consistency": 0.9710738702366749, "background_consistency": 0.9687449137369791, "motion_smoothness": 0.9922271109446865, "aesthetic_quality": 0.4587763845920563, "imaging_quality": 0.6254514016910475, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fcad91c2.mp4", "clean_score": 0.0, "clean_xclip": 0.24051526188850403, "clean_vbench": {}, "adv_vid_id": "vids/af644856.mp4", "adv_score": 0.0, "adv_xclip": 0.24112769961357117, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/75c7ce9e.mp4", "clean_score": 0.0, "clean_xclip": 0.24208718538284302, "clean_vbench": {}, "adv_vid_id": "vids/41a7f24a.mp4", "adv_score": 1.0, "adv_xclip": 0.21131783723831177, "adv_vbench": {}}}}
{"id": "58e549a239464c1f9d4fbfc665ac17bb", "source": "vatex", "video_id": "E8wPUDB5WAc_000000_000010", "video_description": "A male athlete at a track and field event performs a high jump, running up to a bar, jumping over it, and landing on a mat. Spectators watch the event.", "task": "ObjectRecognition", "clean_prompt": "A male athlete running up to a bar and performing a high jump.", "clean_property": {"obj": "bar"}, "target_prompt": "A male athlete running up to a hurdle and performing a jump.", "target_property": {"obj": "hurdle"}, "evaluation_question": "Is the athlete jumping over a **bar**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A male athlete running up to a bar and performing a high jump. Grafikfaire Sekunden gehen imperfections", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/451d834843994099a603bb52c90565a7.mp4", "clean_score": 1.0, "clean_xclip": 0.14059561491012573, "clean_vbench": {"subject_consistency": 0.8543183244764805, "background_consistency": 0.8837229410807291, "motion_smoothness": 0.9777560869480251, "aesthetic_quality": 0.45096758008003235, "imaging_quality": 0.6865178042042013, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5caa4502b58f443ca2295abbc5e61211.mp4", "adv_score": 0.0, "adv_xclip": 0.08811081200838089, "adv_vbench": {"subject_consistency": 0.892806427863737, "background_consistency": 0.9473673502604166, "motion_smoothness": 0.9812581672554567, "aesthetic_quality": 0.33530062437057495, "imaging_quality": 0.5609536011364995, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/96ba81c3.mp4", "clean_score": 1.0, "clean_xclip": 0.1472349613904953, "clean_vbench": {}, "adv_vid_id": "vids/af300bee.mp4", "adv_score": 1.0, "adv_xclip": 0.10513642430305481, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4e011e3e.mp4", "clean_score": 1.0, "clean_xclip": 0.16489318013191223, "clean_vbench": {}, "adv_vid_id": "vids/2bc776d2.mp4", "adv_score": 1.0, "adv_xclip": 0.16707473993301392, "adv_vbench": {}}}}
{"id": "ed1986c2727e4dbdbefa37715cb7ea79", "source": "vatex", "video_id": "o7g3QX8cESw_000033_000043", "video_description": "A man is unboxing a device, removing electronic items, including a charger and several cables, and placing them on a bed.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a box.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "box"}, "target_prompt": "A person standing to the left of a box.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "box"}, "evaluation_question": "Is the person to the **right** of a box?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a box. FE|.?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6b2a62648ca405b9d6ab39a0a4b8683.mp4", "clean_score": 1.0, "clean_xclip": 0.13312627375125885, "clean_vbench": {"subject_consistency": 0.9760397306332985, "background_consistency": 0.9744771321614584, "motion_smoothness": 0.9966780336555919, "aesthetic_quality": 0.3739985227584839, "imaging_quality": 0.7307791947345345, "dynamic_degree": 0.0}, "adv_vid_id": "vids/2a56eac33b594eaa8ccf0852aba64270.mp4", "adv_score": 0.0, "adv_xclip": 0.1395205855369568, "adv_vbench": {"subject_consistency": 0.9973221017668644, "background_consistency": 0.9881490071614584, "motion_smoothness": 0.9978246691680787, "aesthetic_quality": 0.26154565811157227, "imaging_quality": 0.7473049226099131, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ac6763a3.mp4", "clean_score": 0.0, "clean_xclip": 0.17175409197807312, "clean_vbench": {}, "adv_vid_id": "vids/a1bd0a6f.mp4", "adv_score": 0.0, "adv_xclip": 0.14403605461120605, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5fa57218.mp4", "clean_score": 0.0, "clean_xclip": 0.15718646347522736, "clean_vbench": {}, "adv_vid_id": "vids/b57d9f30.mp4", "adv_score": 1.0, "adv_xclip": 0.15340308845043182, "adv_vbench": {}}}}
{"id": "94c8e8d14e6443cabdf5924578ea163b", "source": "vatex", "video_id": "UX6-6Y66dpE_000442_000452", "video_description": "In a commercial kitchen, a chef is demonstrating and instructing a group of culinary students on how to cook eggs over hard and other recipes.", "task": "SpatialUnderstanding", "clean_prompt": "A culinary student closer to the camera than a stove in a commercial kitchen.", "clean_property": {"obj_1": "culinary student", "relation": "closer to the camera than", "obj_2": "stove"}, "target_prompt": "A culinary student further from the camera than a stove in a commercial kitchen.", "target_property": {"obj_1": "culinary student", "relation": "further from the camera than", "obj_2": "stove"}, "evaluation_question": "Is the culinary student **closer to the camera than** the stove?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A culinary student closer to the camera than a stove in a commercial kitchen. horizontal Weiter Sino quelqu aproape", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6520f72090ed4e55b352bfe046218fd6.mp4", "clean_score": 1.0, "clean_xclip": 0.19116954505443573, "clean_vbench": {"subject_consistency": 0.9605269332726797, "background_consistency": 0.964324951171875, "motion_smoothness": 0.9798837528935186, "aesthetic_quality": 0.5242166519165039, "imaging_quality": 0.5722200027777223, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b974a737cc9e4b818ec8c40d32072cd3.mp4", "adv_score": 0.0, "adv_xclip": 0.09565527737140656, "adv_vbench": {"subject_consistency": 0.9999999931703011, "background_consistency": 0.010002848307291668, "motion_smoothness": 0.9999817679965505, "aesthetic_quality": 0.3200262486934662, "imaging_quality": 0.2045294796690649, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8ec6dff3.mp4", "clean_score": 1.0, "clean_xclip": 0.13137443363666534, "clean_vbench": {}, "adv_vid_id": "vids/0876f9c6.mp4", "adv_score": 1.0, "adv_xclip": 0.12717142701148987, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/79202e51.mp4", "clean_score": 1.0, "clean_xclip": 0.15568988025188446, "clean_vbench": {}, "adv_vid_id": "vids/8f94b9f0.mp4", "adv_score": 1.0, "adv_xclip": 0.16047576069831848, "adv_vbench": {}}}}
{"id": "1fe66bf41744489682ceedb7d5f8db63", "source": "vatex", "video_id": "u6SKVk_-uCw_000013_000023", "video_description": "Two adults are attempting to climb a rope ladder on a bouncy house at a carnival. They fall and laugh during the attempt.", "task": "ActionRecognition", "clean_prompt": "An adult laughing while attempting to climb a rope ladder in a bouncy house.", "clean_property": {"obj": "adult", "action": "laughing", "target": null}, "target_prompt": "An adult screaming while attempting to climb a rope ladder in a bouncy house.", "target_property": {"obj": "adult", "action": "screaming", "target": null}, "evaluation_question": "Is the adult **laughing** while climbing the rope ladder?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An adult laughing while attempting to climb a rope ladder in a bouncy house.sieheAvem douceueuse avea", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f99b75e72aeb453aa5826a663ece2419.mp4", "clean_score": 1.0, "clean_xclip": 0.18623396754264832, "clean_vbench": {"subject_consistency": 0.8674125596880913, "background_consistency": 0.9155222574869791, "motion_smoothness": 0.9443020513407265, "aesthetic_quality": 0.44518154859542847, "imaging_quality": 0.49472930596799264, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3c1fdc4e8dcb4f8a942f183fd00cdccc.mp4", "adv_score": 0.0, "adv_xclip": 0.1900148093700409, "adv_vbench": {"subject_consistency": 0.8122022344420353, "background_consistency": 0.8996531168619791, "motion_smoothness": 0.929775117348251, "aesthetic_quality": 0.3921195864677429, "imaging_quality": 0.523443669688945, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/84c266f2.mp4", "clean_score": 1.0, "clean_xclip": 0.1964114010334015, "clean_vbench": {}, "adv_vid_id": "vids/80c10c03.mp4", "adv_score": 1.0, "adv_xclip": 0.21900421380996704, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/761453d3.mp4", "clean_score": 1.0, "clean_xclip": 0.19083662331104279, "clean_vbench": {}, "adv_vid_id": "vids/62d48f30.mp4", "adv_score": 1.0, "adv_xclip": 0.18271543085575104, "adv_vbench": {}}}}
{"id": "d19db46085994a1d8c4c0bda08c5079f", "source": "vatex", "video_id": "1jIKAImNXBk_000000_000010", "video_description": "A boy is writing or drawing on the side of a blue phone booth with a black marker.", "task": "ActionRecognition", "clean_prompt": "A person tagging graffiti on the side of a blue phone booth.", "clean_property": {"obj": "person", "action": "tagging graffiti", "target": "phone booth"}, "target_prompt": "A person removing graffiti from a blue phone booth.", "target_property": {"obj": "person", "action": "removing graffiti", "target": "phone booth"}, "evaluation_question": "Is the person **tagging graffiti** on the phone booth?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person tagging graffiti on the side of a blue phone booth. BSQD$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8dc618955015491ba6e2f9836032c172.mp4", "clean_score": 1.0, "clean_xclip": 0.24315960705280304, "clean_vbench": {"subject_consistency": 0.9381580147892237, "background_consistency": 0.9142964680989584, "motion_smoothness": 0.9842037944807552, "aesthetic_quality": 0.5717015266418457, "imaging_quality": 0.7103766600939693, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6252d37f8dd240fa8e933e65a66905d9.mp4", "adv_score": 0.0, "adv_xclip": 0.23964431881904602, "adv_vbench": {"subject_consistency": 0.9460699247817198, "background_consistency": 0.9390106201171875, "motion_smoothness": 0.9780586471760773, "aesthetic_quality": 0.48946163058280945, "imaging_quality": 0.699987038592903, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/29b7288d.mp4", "clean_score": 0.0, "clean_xclip": 0.17497918009757996, "clean_vbench": {}, "adv_vid_id": "vids/28b511fa.mp4", "adv_score": 0.0, "adv_xclip": 0.14654706418514252, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/62e6942d.mp4", "clean_score": 1.0, "clean_xclip": 0.18344664573669434, "clean_vbench": {}, "adv_vid_id": "vids/035a398b.mp4", "adv_score": 1.0, "adv_xclip": 0.2147642970085144, "adv_vbench": {}}}}
{"id": "5c8ee456d27e43a4bb08b03642ca8601", "source": "vatex", "video_id": "c0zKotiZDF8_000094_000104", "video_description": "A person is creating art using spray paint on a circular, metal object placed on a turntable. The person is wearing a protective mask while working outdoors.", "task": "Counting", "clean_prompt": "Seven artists creating art using spray paint on a circular, metal object placed on a turntable, while wearing protective masks outdoors.", "clean_property": {"obj": "artist", "count": "seven"}, "target_prompt": "Three artists creating art using spray paint on a circular, metal object placed on a turntable, while wearing protective masks outdoors.", "target_property": {"obj": "artist", "count": "three"}, "evaluation_question": "Are there exactly **seven** artists creating art outdoors?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven artists creating art using spray paint on a circular, metal object placed on a turntable, while wearing protective masks outdoors. UmgangschrankBildern seamless Cartoon", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c498a4e585e461683ae6b58334aa0d6.mp4", "clean_score": 1.0, "clean_xclip": 0.2568332254886627, "clean_vbench": {"subject_consistency": 0.9600722243388494, "background_consistency": 0.9371083577473959, "motion_smoothness": 0.9727153570500988, "aesthetic_quality": 0.5388969779014587, "imaging_quality": 0.5696097167657347, "dynamic_degree": 1.0}, "adv_vid_id": "vids/33217e38ae384e2092e6e200cb74a39b.mp4", "adv_score": 0.0, "adv_xclip": 0.13035085797309875, "adv_vbench": {"subject_consistency": 0.9501947493602833, "background_consistency": 0.9272613525390625, "motion_smoothness": 0.9667686159147301, "aesthetic_quality": 0.5645778179168701, "imaging_quality": 0.5468341640550264, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c4b66bb6.mp4", "clean_score": 0.0, "clean_xclip": 0.2687857449054718, "clean_vbench": {}, "adv_vid_id": "vids/a1996ebf.mp4", "adv_score": 0.0, "adv_xclip": 0.22256988286972046, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4e73f61d.mp4", "clean_score": 0.0, "clean_xclip": 0.27333948016166687, "clean_vbench": {}, "adv_vid_id": "vids/936c9237.mp4", "adv_score": 0.0, "adv_xclip": 0.17373207211494446, "adv_vbench": {}}}}
{"id": "1f80f6afc5f640bd8de083820bbd4fbf", "source": "vatex", "video_id": "5itHnZhjeg0_000092_000102", "video_description": "A man is in a recording studio, wearing headphones and standing in front of a microphone, singing and talking to record music.", "task": "SpatialUnderstanding", "clean_prompt": "A man wearing headphones standing to the right of a microphone in a recording studio.", "clean_property": {"obj_1": "headphones", "relation": "right of", "obj_2": "microphone"}, "target_prompt": "A man wearing headphones standing to the left of a microphone in a recording studio.", "target_property": {"obj_1": "headphones", "relation": "left of", "obj_2": "microphone"}, "evaluation_question": "Is the man wearing headphones **to the right** of the microphone?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man wearing headphones standing to the right of a microphone in a recording studio. studiu Kontakt Sfant trotzdem Wohnzimmer", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5f19287c0bcb40698f8e4cf156a03559.mp4", "clean_score": 1.0, "clean_xclip": 0.20857909321784973, "clean_vbench": {"subject_consistency": 0.9275345417360464, "background_consistency": 0.9412485758463541, "motion_smoothness": 0.9924431543386387, "aesthetic_quality": 0.5481657385826111, "imaging_quality": 0.44052353839485014, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3fd241d06113400ab3b2ddd84524c96c.mp4", "adv_score": 0.0, "adv_xclip": 0.1939362734556198, "adv_vbench": {"subject_consistency": 0.9746406444658836, "background_consistency": 0.9578959147135416, "motion_smoothness": 0.9947271763482913, "aesthetic_quality": 0.6309914588928223, "imaging_quality": 0.4914796735802475, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/29d8c877.mp4", "clean_score": 0.0, "clean_xclip": 0.179640993475914, "clean_vbench": {}, "adv_vid_id": "vids/1b88ae10.mp4", "adv_score": 1.0, "adv_xclip": 0.17673368752002716, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/716c4db1.mp4", "clean_score": 1.0, "clean_xclip": 0.1966463327407837, "clean_vbench": {}, "adv_vid_id": "vids/44cab5ac.mp4", "adv_score": 1.0, "adv_xclip": 0.21654759347438812, "adv_vbench": {}}}}
{"id": "354f956e8ff3408ba7af3a2a3b10c937", "source": "vatex", "video_id": "Rnta1wIPe1s_000196_000206", "video_description": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom. Another man is present, talking.", "task": "Counting", "clean_prompt": "A young man is ironing two shirts on an ironing board in a bathroom.", "clean_property": {"obj": "shirt", "count": "two"}, "target_prompt": "A young man is ironing one shirt on an ironing board in a bathroom.", "target_property": {"obj": "shirt", "count": "one"}, "evaluation_question": "Are there exactly **two** shirts being ironed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is ironing two shirts on an ironing board in a bathroom. )!G*D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e1224e1cf39f4ff5adb9308ed6d7313f.mp4", "clean_score": 1.0, "clean_xclip": 0.2098425328731537, "clean_vbench": {"subject_consistency": 0.9651699457317591, "background_consistency": 0.9542490641276041, "motion_smoothness": 0.9745987350154826, "aesthetic_quality": 0.45015034079551697, "imaging_quality": 0.7520417069415657, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5e0d91e674a346f3ba5864f8a811bc47.mp4", "adv_score": 0.0, "adv_xclip": 0.19921892881393433, "adv_vbench": {"subject_consistency": 0.9741599392145872, "background_consistency": 0.9559783935546875, "motion_smoothness": 0.9774985128953845, "aesthetic_quality": 0.4571036696434021, "imaging_quality": 0.7582884839116311, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a606e2a1.mp4", "clean_score": 0.0, "clean_xclip": 0.22577734291553497, "clean_vbench": {}, "adv_vid_id": "vids/2116ccdc.mp4", "adv_score": 1.0, "adv_xclip": 0.27652662992477417, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fc07cfd2.mp4", "clean_score": 0.0, "clean_xclip": 0.2108309268951416, "clean_vbench": {}, "adv_vid_id": "vids/224e985d.mp4", "adv_score": 0.0, "adv_xclip": 0.2502720057964325, "adv_vbench": {}}}}
{"id": "bd2015ff707746dbad9627ee4a1bb1ff", "source": "vatex", "video_id": "cm66wB7giOM_000000_000010", "video_description": "A group of people, including children, are playing kickball in a grassy field. The game involves rolling, kicking, and catching the ball.", "task": "AttributeRecognition", "clean_prompt": "A person playing kickball in a grassy field.", "clean_property": {"obj": "person", "attribute": "man"}, "target_prompt": "A woman playing kickball in a sandy beach.", "target_property": {"obj": "person", "attribute": "woman"}, "evaluation_question": "Is the person playing kickball a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing kickball in a grassy field. jetzt femme Reikihidrat traumhaft", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1d517d4ac7154a9992ba079c1d9ae6d5.mp4", "clean_score": 1.0, "clean_xclip": 0.15020957589149475, "clean_vbench": {"subject_consistency": 0.8892113311837117, "background_consistency": 0.9191741943359375, "motion_smoothness": 0.9682590192359094, "aesthetic_quality": 0.4621061086654663, "imaging_quality": 0.5527636119297573, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0f4a2ad3c53f49fa8a931cd9ec779634.mp4", "adv_score": 0.0, "adv_xclip": 0.18086177110671997, "adv_vbench": {"subject_consistency": 0.8521181258062521, "background_consistency": 0.8857828776041666, "motion_smoothness": 0.9757792978205942, "aesthetic_quality": 0.45160597562789917, "imaging_quality": 0.5057042110209562, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b0329391.mp4", "clean_score": 1.0, "clean_xclip": 0.2276906818151474, "clean_vbench": {}, "adv_vid_id": "vids/fd42b963.mp4", "adv_score": 0.0, "adv_xclip": 0.16684086620807648, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/007bd4aa.mp4", "clean_score": 1.0, "clean_xclip": 0.2345820963382721, "clean_vbench": {}, "adv_vid_id": "vids/4d058dd8.mp4", "adv_score": 0.0, "adv_xclip": 0.16997694969177246, "adv_vbench": {}}}}
{"id": "878c797c110142728adba393fbbbcfed", "source": "vatex", "video_id": "BeevuXU4xSM_000000_000010", "video_description": "A man is practicing shot put throwing techniques, spinning around and throwing the shot put in a marked area outdoors.", "task": "Counting", "clean_prompt": "Four men practicing shot put throwing techniques outdoors.", "clean_property": {"obj": "man", "count": "four"}, "target_prompt": "One man practicing shot put throwing techniques outdoors.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **four** men practicing shot put outdoors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four men practicing shot put throwing techniques outdoors. RR|O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a2e8cbbc79954a73b3b111d67db00bf2.mp4", "clean_score": 1.0, "clean_xclip": 0.11391806602478027, "clean_vbench": {"subject_consistency": 0.9377872546513876, "background_consistency": 0.9418233235677084, "motion_smoothness": 0.969363702827453, "aesthetic_quality": 0.5803756713867188, "imaging_quality": 0.6223197687888632, "dynamic_degree": 1.0}, "adv_vid_id": "vids/03eb206eb967434da2dcc84593fc6a83.mp4", "adv_score": 0.0, "adv_xclip": 0.12135191261768341, "adv_vbench": {"subject_consistency": 0.9061701260507107, "background_consistency": 0.9514007568359375, "motion_smoothness": 0.972032448540759, "aesthetic_quality": 0.6712278723716736, "imaging_quality": 0.7048696626935687, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5006feed.mp4", "clean_score": 1.0, "clean_xclip": 0.17743821442127228, "clean_vbench": {}, "adv_vid_id": "vids/0f094da1.mp4", "adv_score": 0.0, "adv_xclip": 0.16460615396499634, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8bd99c2a.mp4", "clean_score": 0.0, "clean_xclip": 0.18364281952381134, "clean_vbench": {}, "adv_vid_id": "vids/21c46003.mp4", "adv_score": 0.0, "adv_xclip": 0.183781236410141, "adv_vbench": {}}}}
{"id": "46409b7c5f744acfae59408c8ed010ce", "source": "vatex", "video_id": "kOf-vl-GmVI_000115_000125", "video_description": "A woman is riding a horse in a fenced area, occasionally petting the horse.", "task": "ActionRecognition", "clean_prompt": "A person petting a horse in a fenced area.", "clean_property": {"obj": "person", "action": "petting animal (not cat)", "target": "horse"}, "target_prompt": "A person feeding a horse in a fenced area.", "target_property": {"obj": "person", "action": "feeding animal", "target": "horse"}, "evaluation_question": "Is the person **petting** the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person petting a horse in a fenced area. RL83>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fbe2b41b3534711873db887c00de82b.mp4", "clean_score": 1.0, "clean_xclip": 0.2168230563402176, "clean_vbench": {"subject_consistency": 0.985188984622558, "background_consistency": 0.9605204264322916, "motion_smoothness": 0.9796906994182704, "aesthetic_quality": 0.5406972765922546, "imaging_quality": 0.7408467506875798, "dynamic_degree": 0.0}, "adv_vid_id": "vids/86605762724040ddb9c32d9f1cc531df.mp4", "adv_score": 0.0, "adv_xclip": 0.23227740824222565, "adv_vbench": {"subject_consistency": 0.9805161990225315, "background_consistency": 0.9477488199869791, "motion_smoothness": 0.9749039528362786, "aesthetic_quality": 0.48082849383354187, "imaging_quality": 0.7319164805509607, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6afa3b2b.mp4", "clean_score": 1.0, "clean_xclip": 0.2611072361469269, "clean_vbench": {}, "adv_vid_id": "vids/01bee8eb.mp4", "adv_score": 1.0, "adv_xclip": 0.24254009127616882, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9c77985d.mp4", "clean_score": 1.0, "clean_xclip": 0.24312186241149902, "clean_vbench": {}, "adv_vid_id": "vids/2ef4759c.mp4", "adv_score": 1.0, "adv_xclip": 0.22818216681480408, "adv_vbench": {}}}}
{"id": "f627e774f99e42789ab542fd81f76603", "source": "vatex", "video_id": "7qTjhLfDb7c_000063_000073", "video_description": "A young girl is riding a unicycle back and forth in a living room, demonstrating and explaining how to balance on it.", "task": "ActionRecognition", "clean_prompt": "A girl riding a unicycle back and forth in a living room.", "clean_property": {"obj": "girl", "action": "riding unicycle", "target": null}, "target_prompt": "A girl falling off a unicycle in a living room.", "target_property": {"obj": "girl", "action": "falling off unicycle", "target": null}, "evaluation_question": "Is the girl **riding** a unicycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl riding a unicycle back and forth in a living room. RP4|G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e88d5ab3b594333aed4e5fbc5333f79.mp4", "clean_score": 1.0, "clean_xclip": 0.25649112462997437, "clean_vbench": {"subject_consistency": 0.980134770895044, "background_consistency": 0.9665476481119791, "motion_smoothness": 0.9916851084344488, "aesthetic_quality": 0.5092329382896423, "imaging_quality": 0.6650235989629006, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3b94a687c6e346ce826211b4f4cfa687.mp4", "adv_score": 0.0, "adv_xclip": 0.2612576484680176, "adv_vbench": {"subject_consistency": 0.93743513772885, "background_consistency": 0.9522196451822916, "motion_smoothness": 0.98890716864485, "aesthetic_quality": 0.4484414756298065, "imaging_quality": 0.5981137302943638, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a5ccc9cc.mp4", "clean_score": 0.0, "clean_xclip": 0.2479112595319748, "clean_vbench": {}, "adv_vid_id": "vids/ff35d1fa.mp4", "adv_score": 1.0, "adv_xclip": 0.2505079507827759, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/500c2273.mp4", "clean_score": 0.0, "clean_xclip": 0.2570848762989044, "clean_vbench": {}, "adv_vid_id": "vids/32e82590.mp4", "adv_score": 1.0, "adv_xclip": 0.24545904994010925, "adv_vbench": {}}}}
{"id": "089d8211faaf4760b844f773c7c70b84", "source": "vatex", "video_id": "VCX8Q4Q752A_000071_000081", "video_description": "A group of people are seated around a large circular table with a rotating Lazy Susan in the middle, dining on Asian cuisine. A server occasionally adds dishes to the table.", "task": "ObjectRecognition", "clean_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine.", "clean_property": {"obj": "server"}, "target_prompt": "A chef preparing dishes in a kitchen while a group of people waits at a table.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **server**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine. LY2IJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b474e9ab53146a99feeabb74d792681.mp4", "clean_score": 1.0, "clean_xclip": 0.19744539260864258, "clean_vbench": {"subject_consistency": 0.9393230093022188, "background_consistency": 0.9604085286458334, "motion_smoothness": 0.9623006053694626, "aesthetic_quality": 0.5440422892570496, "imaging_quality": 0.47311183462337575, "dynamic_degree": 1.0}, "adv_vid_id": "vids/859f08012945459ead5b548a5064b9fe.mp4", "adv_score": 0.0, "adv_xclip": 0.20680148899555206, "adv_vbench": {"subject_consistency": 0.9739161139974991, "background_consistency": 0.96612548828125, "motion_smoothness": 0.9600471200665194, "aesthetic_quality": 0.5913560390472412, "imaging_quality": 0.6056194461121851, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b176201d.mp4", "clean_score": 1.0, "clean_xclip": 0.19637762010097504, "clean_vbench": {}, "adv_vid_id": "vids/3886063b.mp4", "adv_score": 1.0, "adv_xclip": 0.2081320881843567, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a09be7cd.mp4", "clean_score": 1.0, "clean_xclip": 0.22587493062019348, "clean_vbench": {}, "adv_vid_id": "vids/510fb60c.mp4", "adv_score": 1.0, "adv_xclip": 0.22115707397460938, "adv_vbench": {}}}}
{"id": "4d5723754748406e8821c33fd3d7e56e", "source": "vatex", "video_id": "51jbjkaduZg_000000_000010", "video_description": "A man is ironing a garment on a bed, talking to a child, and accidentally burns his hand with the iron.", "task": "ActionRecognition", "clean_prompt": "A man ironing a garment on a bed while talking to a child.", "clean_property": {"obj": "man", "action": "ironing", "target": "garment"}, "target_prompt": "A man folding a garment on a bed while talking to a child.", "target_property": {"obj": "man", "action": "folding", "target": "garment"}, "evaluation_question": "Is the man **ironing** a garment?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man ironing a garment on a bed while talking to a child. F'');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61a54efdea6a4757a509036f910b5696.mp4", "clean_score": 1.0, "clean_xclip": 0.21321162581443787, "clean_vbench": {"subject_consistency": 0.9659096753845612, "background_consistency": 0.9485524495442709, "motion_smoothness": 0.9841278511243747, "aesthetic_quality": 0.6020616888999939, "imaging_quality": 0.7771823275819116, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f6cc467aa5664189b053e8a0fe21d042.mp4", "adv_score": 0.0, "adv_xclip": 0.2124761939048767, "adv_vbench": {"subject_consistency": 0.9125425834208727, "background_consistency": 0.8895161946614584, "motion_smoothness": 0.9717892702155451, "aesthetic_quality": 0.5283621549606323, "imaging_quality": 0.6681544829388053, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/592cf8e7.mp4", "clean_score": 0.0, "clean_xclip": 0.24117010831832886, "clean_vbench": {}, "adv_vid_id": "vids/a5737605.mp4", "adv_score": 1.0, "adv_xclip": 0.2156955897808075, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0c7a4b93.mp4", "clean_score": 1.0, "clean_xclip": 0.2276461273431778, "clean_vbench": {}, "adv_vid_id": "vids/5c19811c.mp4", "adv_score": 1.0, "adv_xclip": 0.21902593970298767, "adv_vbench": {}}}}
{"id": "c72b3421262b4ee99ea9f6bae1974ef4", "source": "vatex", "video_id": "AkFy3j-73JA_000018_000028", "video_description": "A young woman is ice skating at an indoor rink, performing spins and twirls.", "task": "Counting", "clean_prompt": "Three ice skaters performing spins and twirls at an indoor rink.", "clean_property": {"obj": "ice skater", "count": "three"}, "target_prompt": "One ice skater performing spins and twirls at an indoor rink.", "target_property": {"obj": "ice skater", "count": "one"}, "evaluation_question": "Are there exactly **three** ice skaters at the rink?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three ice skaters performing spins and twirls at an indoor rink. funktionierenstellte toute Blair Sauna", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d30a7e2c2151467c82e04a121856d1ec.mp4", "clean_score": 1.0, "clean_xclip": 0.19691738486289978, "clean_vbench": {"subject_consistency": 0.9379359632730484, "background_consistency": 0.9311116536458334, "motion_smoothness": 0.9744886716228416, "aesthetic_quality": 0.46641936898231506, "imaging_quality": 0.48460540771484373, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b601db818e5745a58c9e34f82e2ee217.mp4", "adv_score": 0.0, "adv_xclip": 0.20781025290489197, "adv_vbench": {"subject_consistency": 0.9440501400580009, "background_consistency": 0.9394073486328125, "motion_smoothness": 0.9396697876006113, "aesthetic_quality": 0.4037480056285858, "imaging_quality": 0.4173875248188875, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fc6f6d63.mp4", "clean_score": 0.0, "clean_xclip": 0.2285362333059311, "clean_vbench": {}, "adv_vid_id": "vids/72362953.mp4", "adv_score": 0.0, "adv_xclip": 0.2028653770685196, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/276d38b1.mp4", "clean_score": 0.0, "clean_xclip": 0.2329356074333191, "clean_vbench": {}, "adv_vid_id": "vids/d58d7612.mp4", "adv_score": 1.0, "adv_xclip": 0.23173180222511292, "adv_vbench": {}}}}
{"id": "f24cc7874679435a996282df6ce4b54d", "source": "vatex", "video_id": "JQTZTmaD86Q_000020_000030", "video_description": "A young girl stands on a bathroom counter in front of a mirror, brushing her teeth while wearing pajamas and an Olympic medal. Music is playing in the background.", "task": "AttributeRecognition", "clean_prompt": "A girl wearing pajamas is brushing her teeth in front of a mirror.", "clean_property": {"obj": "girl", "attribute": "wearing pajamas"}, "target_prompt": "A girl wearing a princess costume is brushing her teeth in front of a mirror.", "target_property": {"obj": "girl", "attribute": "wearing a princess costume"}, "evaluation_question": "Is the girl wearing **pajamas**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A girl wearing pajamas is brushing her teeth in front of a mirror. Nursery categoria studii interioare recomanda", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c46173d5bcd644458de8da8584862972.mp4", "clean_score": 1.0, "clean_xclip": 0.22777529060840607, "clean_vbench": {"subject_consistency": 0.9420716439684232, "background_consistency": 0.954254150390625, "motion_smoothness": 0.9811573916475027, "aesthetic_quality": 0.5350296497344971, "imaging_quality": 0.4715456444876535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d509e6d6e7e847fbadaac09f0f3b6293.mp4", "adv_score": 0.0, "adv_xclip": 0.2275259792804718, "adv_vbench": {"subject_consistency": 0.9659425765275955, "background_consistency": 0.9680277506510416, "motion_smoothness": 0.9800273160125677, "aesthetic_quality": 0.4690748155117035, "imaging_quality": 0.670862623720753, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4fed89c3.mp4", "clean_score": 1.0, "clean_xclip": 0.208124577999115, "clean_vbench": {}, "adv_vid_id": "vids/36098363.mp4", "adv_score": 1.0, "adv_xclip": 0.22184109687805176, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ebc40d41.mp4", "clean_score": 1.0, "clean_xclip": 0.22237929701805115, "clean_vbench": {}, "adv_vid_id": "vids/eb4c27ce.mp4", "adv_score": 1.0, "adv_xclip": 0.20892775058746338, "adv_vbench": {}}}}
{"id": "b507192a97504a5cac439c9e1628621c", "source": "vatex", "video_id": "ZcYB6tPK2Eo_000138_000148", "video_description": "A man is demonstrating how to solve a Rubik's cube, explaining his process while manipulating the cube.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a Rubik's cube, demonstrating how to solve it.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "rubik's cube"}, "target_prompt": "A person beside a Rubik's cube, demonstrating how to solve it.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "Rubik's cube"}, "evaluation_question": "Is the person **above** the Rubik's cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person above a Rubik's cube, demonstrating how to solve it. ')'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1ea54b7ad4048dd9821f4a4b24b675f.mp4", "clean_score": 1.0, "clean_xclip": 0.22496874630451202, "clean_vbench": {"subject_consistency": 0.8962103991458813, "background_consistency": 0.9566752115885416, "motion_smoothness": 0.9464528967965787, "aesthetic_quality": 0.4734114706516266, "imaging_quality": 0.6485209087449677, "dynamic_degree": 1.0}, "adv_vid_id": "vids/316387ff342341209e9e654eef45a8fa.mp4", "adv_score": 0.0, "adv_xclip": 0.20928552746772766, "adv_vbench": {"subject_consistency": 0.8710339510192474, "background_consistency": 0.91815185546875, "motion_smoothness": 0.9506138621600904, "aesthetic_quality": 0.41179168224334717, "imaging_quality": 0.6182495755565409, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a1461709.mp4", "clean_score": 0.0, "clean_xclip": 0.25196903944015503, "clean_vbench": {}, "adv_vid_id": "vids/bc475936.mp4", "adv_score": 0.0, "adv_xclip": 0.23928087949752808, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3dbe5fb2.mp4", "clean_score": 0.0, "clean_xclip": 0.2509731650352478, "clean_vbench": {}, "adv_vid_id": "vids/297b40a8.mp4", "adv_score": 1.0, "adv_xclip": 0.26322799921035767, "adv_vbench": {}}}}
{"id": "effb373eedb642ef9b80f54d7d596bc9", "source": "vatex", "video_id": "hJ07ncKOBR0_000031_000041", "video_description": "A young boy is sitting at a table with a pile of potato chips on a paper towel. He is eating the chips and talking.", "task": "ActionRecognition", "clean_prompt": "A boy eating chips at a table.", "clean_property": {"obj": "boy", "action": "eating chips", "target": null}, "target_prompt": "A boy playing with toys at a table.", "target_property": {"obj": "boy", "action": "playing with toys", "target": null}, "evaluation_question": "Is the boy **eating chips**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy eating chips at a table. SfantArticolul Montessori tineri categoria", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f52e19518324cfcb31882aedf17a200.mp4", "clean_score": 1.0, "clean_xclip": 0.24092060327529907, "clean_vbench": {"subject_consistency": 0.9771458407243093, "background_consistency": 0.9614817301432291, "motion_smoothness": 0.9826625925736807, "aesthetic_quality": 0.5987114906311035, "imaging_quality": 0.700634075086944, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7a4e0fa36e8d43279974970e8e2484ef.mp4", "adv_score": 0.0, "adv_xclip": 0.2435934990644455, "adv_vbench": {"subject_consistency": 0.9834290581444899, "background_consistency": 0.9689737955729166, "motion_smoothness": 0.9865362614921226, "aesthetic_quality": 0.6554323434829712, "imaging_quality": 0.716925512819874, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cdd67dec.mp4", "clean_score": 1.0, "clean_xclip": 0.2513763904571533, "clean_vbench": {}, "adv_vid_id": "vids/ae4fa267.mp4", "adv_score": 1.0, "adv_xclip": 0.24518026411533356, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2447de77.mp4", "clean_score": 1.0, "clean_xclip": 0.2328246682882309, "clean_vbench": {}, "adv_vid_id": "vids/3d832810.mp4", "adv_score": 1.0, "adv_xclip": 0.2398749738931656, "adv_vbench": {}}}}
{"id": "345eae8a558a4dec9bb80dda892205f6", "source": "vatex", "video_id": "BeevuXU4xSM_000000_000010", "video_description": "A man is practicing shot put throwing techniques, spinning around and throwing the shot put in a marked area outdoors.", "task": "ActionRecognition", "clean_prompt": "A man practicing shot put throwing techniques outdoors.", "clean_property": {"obj": "man", "action": "shot put", "target": null}, "target_prompt": "A man practicing javelin throwing techniques outdoors.", "target_property": {"obj": "man", "action": "javelin throwing", "target": null}, "evaluation_question": "Is the man **practicing shot put** throwing techniques?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man practicing shot put throwing techniques outdoors.hnlich Kirchen militare vreme Regen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/500c3a762a644d3fb66f245800d704ee.mp4", "clean_score": 1.0, "clean_xclip": 0.15465298295021057, "clean_vbench": {"subject_consistency": 0.8630277092258135, "background_consistency": 0.8783721923828125, "motion_smoothness": 0.9494967707955096, "aesthetic_quality": 0.47564905881881714, "imaging_quality": 0.5722485437198561, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1a0cd5cb06d346ca9beec753dedebd73.mp4", "adv_score": 0.0, "adv_xclip": 0.06686002016067505, "adv_vbench": {"subject_consistency": 0.8974556171645721, "background_consistency": 0.9420674641927084, "motion_smoothness": 0.9688659142572924, "aesthetic_quality": 0.6033875346183777, "imaging_quality": 0.4959661257996851, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3ea02cb8.mp4", "clean_score": 1.0, "clean_xclip": 0.13985565304756165, "clean_vbench": {}, "adv_vid_id": "vids/91c7b101.mp4", "adv_score": 1.0, "adv_xclip": 0.20893621444702148, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0c789966.mp4", "clean_score": 1.0, "clean_xclip": 0.15786121785640717, "clean_vbench": {}, "adv_vid_id": "vids/291e144d.mp4", "adv_score": 1.0, "adv_xclip": 0.19774852693080902, "adv_vbench": {}}}}
{"id": "9fda9e9b9e9c4540b51b351e51e7a770", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "ActionRecognition", "clean_prompt": "A person stretching their leg on a yoga mat in a room.", "clean_property": {"obj": "person", "action": "stretching leg", "target": null}, "target_prompt": "A person jumping on a yoga mat in a room.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **stretching their leg**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person stretching their leg on a yoga mat in a room. LY/4(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/848b98438cba4b8d92278c719e55a04f.mp4", "clean_score": 1.0, "clean_xclip": 0.20279279351234436, "clean_vbench": {"subject_consistency": 0.9817521696289381, "background_consistency": 0.9650726318359375, "motion_smoothness": 0.9923716852192266, "aesthetic_quality": 0.48179197311401367, "imaging_quality": 0.7158131953648159, "dynamic_degree": 1.0}, "adv_vid_id": "vids/cd890275166f4a109a2b2cfb6ee7b193.mp4", "adv_score": 0.0, "adv_xclip": 0.19321653246879578, "adv_vbench": {"subject_consistency": 0.9853111704190572, "background_consistency": 0.9791717529296875, "motion_smoothness": 0.9956402803308824, "aesthetic_quality": 0.48534128069877625, "imaging_quality": 0.7238584199243663, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b4ae4da7.mp4", "clean_score": 1.0, "clean_xclip": 0.18479272723197937, "clean_vbench": {}, "adv_vid_id": "vids/42baa0cf.mp4", "adv_score": 1.0, "adv_xclip": 0.21047616004943848, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3b798e4c.mp4", "clean_score": 1.0, "clean_xclip": 0.2275596559047699, "clean_vbench": {}, "adv_vid_id": "vids/fb78ea5c.mp4", "adv_score": 1.0, "adv_xclip": 0.17029429972171783, "adv_vbench": {}}}}
{"id": "9f4c78c60f9847b1ad20f92fffe7b1b3", "source": "vatex", "video_id": "s7qkYZTezYs_000002_000012", "video_description": "A person is cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "task": "AttributeRecognition", "clean_prompt": "A person cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "clean_property": {"obj": "toilet", "attribute": "poorly kept"}, "target_prompt": "A person cleaning a spotlessly clean toilet using a toilet brush while wearing gloves.", "target_property": {"obj": "toilet", "attribute": "spotlessly clean"}, "evaluation_question": "Is the toilet **poorly kept**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person cleaning a poorly kept toilet using a toilet brush while wearing gloves. aqua Gestalt Wohn sauber Vector", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/72b68f87819549d1af923c4e3b4e3c44.mp4", "clean_score": 1.0, "clean_xclip": 0.24046018719673157, "clean_vbench": {"subject_consistency": 0.8497675179193417, "background_consistency": 0.9110463460286459, "motion_smoothness": 0.9639404326030825, "aesthetic_quality": 0.3830769658088684, "imaging_quality": 0.4220808363933953, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f88ba32e5c5d4151ac0783b6b297beb0.mp4", "adv_score": 0.0, "adv_xclip": 0.2265203446149826, "adv_vbench": {"subject_consistency": 0.7277605785056949, "background_consistency": 0.8580678304036459, "motion_smoothness": 0.9813657591798293, "aesthetic_quality": 0.44165006279945374, "imaging_quality": 0.3455825140038315, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/afc3f304.mp4", "clean_score": 0.0, "clean_xclip": 0.2661733329296112, "clean_vbench": {}, "adv_vid_id": "vids/94808d20.mp4", "adv_score": 1.0, "adv_xclip": 0.27740639448165894, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d2b13ec7.mp4", "clean_score": 0.0, "clean_xclip": 0.25795814394950867, "clean_vbench": {}, "adv_vid_id": "vids/1a1f9bcb.mp4", "adv_score": 0.0, "adv_xclip": 0.2661074995994568, "adv_vbench": {}}}}
{"id": "6aba5c6359584cc087cd9ea61ad61e58", "source": "vatex", "video_id": "5Ka89vMcQyc_000000_000010", "video_description": "A young boy in a blue shirt rides a bicycle over a small ramp in a suburban street, making a jump and landing.", "task": "ActionRecognition", "clean_prompt": "A boy jumping on a bicycle in a suburban street.", "clean_property": {"obj": "boy", "action": "jumping bicycle", "target": null}, "target_prompt": "A boy falling off a bicycle in a suburban street.", "target_property": {"obj": "boy", "action": "falling off bicycle", "target": null}, "evaluation_question": "Is the boy **jumping** on the bicycle?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A boy jumping on a bicycle in a suburban street. XJ$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b822f62ea52349ecbe30565e091db4e4.mp4", "clean_score": 1.0, "clean_xclip": 0.27048051357269287, "clean_vbench": {"subject_consistency": 0.8930981028825045, "background_consistency": 0.9182535807291666, "motion_smoothness": 0.9594511089929799, "aesthetic_quality": 0.5862777233123779, "imaging_quality": 0.5780938697347835, "dynamic_degree": 1.0}, "adv_vid_id": "vids/50b3d2ed607a447c9a4cbd449efb7005.mp4", "adv_score": 0.0, "adv_xclip": 0.2602847218513489, "adv_vbench": {"subject_consistency": 0.8942119808246692, "background_consistency": 0.9420064290364584, "motion_smoothness": 0.9724623563642277, "aesthetic_quality": 0.535210907459259, "imaging_quality": 0.5931544946164501, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fa932acd.mp4", "clean_score": 0.0, "clean_xclip": 0.22433321177959442, "clean_vbench": {}, "adv_vid_id": "vids/3df4f0fd.mp4", "adv_score": 0.0, "adv_xclip": 0.24531084299087524, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/32fca2c7.mp4", "clean_score": 1.0, "clean_xclip": 0.2713576555252075, "clean_vbench": {}, "adv_vid_id": "vids/541d1f56.mp4", "adv_score": 1.0, "adv_xclip": 0.27166345715522766, "adv_vbench": {}}}}
{"id": "1eb7bdd2fe314086a11285dc4fc96fb2", "source": "vatex", "video_id": "-AvjZ4eRgRM_000049_000059", "video_description": "A young man is practicing soccer tricks alone on a field, juggling and dribbling a soccer ball.", "task": "ActionRecognition", "clean_prompt": "A person juggling a soccer ball on a field.", "clean_property": {"obj": "person", "action": "juggling soccer ball", "target": null}, "target_prompt": "A person kicking a soccer ball on a field.", "target_property": {"obj": "person", "action": "kicking soccer ball", "target": null}, "evaluation_question": "Is the person **juggling** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person juggling a soccer ball on a field. FIFA internationale rainbow Betriebs istoric", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4b3d46021454f61a62b98f6c79d6fff.mp4", "clean_score": 1.0, "clean_xclip": 0.21595975756645203, "clean_vbench": {"subject_consistency": 0.8846056709686915, "background_consistency": 0.9181162516276041, "motion_smoothness": 0.9298480593883645, "aesthetic_quality": 0.48452359437942505, "imaging_quality": 0.533626682515047, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ad3ee19e95fe422fbf40572ca3245f3a.mp4", "adv_score": 0.0, "adv_xclip": 0.1609812080860138, "adv_vbench": {"subject_consistency": 0.8828266356140375, "background_consistency": 0.946868896484375, "motion_smoothness": 0.9153240012633139, "aesthetic_quality": 0.5116273164749146, "imaging_quality": 0.4682593045915876, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7a52ba49.mp4", "clean_score": 0.0, "clean_xclip": 0.18173961341381073, "clean_vbench": {}, "adv_vid_id": "vids/b8c755fa.mp4", "adv_score": 0.0, "adv_xclip": 0.2181474268436432, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8c90a13a.mp4", "clean_score": 0.0, "clean_xclip": 0.19641074538230896, "clean_vbench": {}, "adv_vid_id": "vids/d6708860.mp4", "adv_score": 1.0, "adv_xclip": 0.19457021355628967, "adv_vbench": {}}}}
{"id": "22efdacc42124a07bb3e5c41281881b7", "source": "vatex", "video_id": "eRihvtICHZk_000000_000010", "video_description": "A pee-wee football game is taking place on a grass field. One team wears white tops and black bottoms, while the other team wears navy tops and red bottoms. Cheerleaders are present, cheering for the teams.", "task": "SpatialUnderstanding", "clean_prompt": "A football player farther from the camera than a football on a grass field.", "clean_property": {"obj_1": "football player", "relation": "farther from the camera than", "obj_2": "football"}, "target_prompt": "A football player closer to the camera than a football on a grass field.", "target_property": {"obj_1": "football player", "relation": "closer to the camera than", "obj_2": "football"}, "evaluation_question": "Is the football player **farther from the camera than** the football?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A football player farther from the camera than a football on a grass field. 'G*$B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6bf8a57a85244ce9816747eb84b789d5.mp4", "clean_score": 1.0, "clean_xclip": 0.13014906644821167, "clean_vbench": {"subject_consistency": 0.9975747875869274, "background_consistency": 0.9910125732421875, "motion_smoothness": 0.9964991620458626, "aesthetic_quality": 0.6107434034347534, "imaging_quality": 0.6607026010630083, "dynamic_degree": 0.0}, "adv_vid_id": "vids/56832035e1da44b1a96ee53f072a7b90.mp4", "adv_score": 0.0, "adv_xclip": 0.10891487449407578, "adv_vbench": {"subject_consistency": 0.9986685371647278, "background_consistency": 0.9943593343098959, "motion_smoothness": 0.9964844288988743, "aesthetic_quality": 0.5965763926506042, "imaging_quality": 0.7155353577282964, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/611ee4c6.mp4", "clean_score": 0.0, "clean_xclip": 0.12752783298492432, "clean_vbench": {}, "adv_vid_id": "vids/0614ce1c.mp4", "adv_score": 1.0, "adv_xclip": 0.14330372214317322, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7d6235e3.mp4", "clean_score": 0.0, "clean_xclip": 0.11675833910703659, "clean_vbench": {}, "adv_vid_id": "vids/c3c387da.mp4", "adv_score": 1.0, "adv_xclip": 0.12812121212482452, "adv_vbench": {}}}}
{"id": "60d07d972ebc47d393092a0331e76a0e", "source": "vatex", "video_id": "09TihuYjO_s_000012_000022", "video_description": "Multiple groups of people are playing badminton on several indoor courts. Two men, one in a white top and the other in a yellow top, are playing a game of badminton.", "task": "Counting", "clean_prompt": "Three players are playing badminton on an indoor court.", "clean_property": {"obj": "player", "count": "three"}, "target_prompt": "One player is practicing badminton on an indoor court.", "target_property": {"obj": "player", "count": "one"}, "evaluation_question": "Are there exactly **three** players on the court?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three players are playing badminton on an indoor court. O8W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01df110aa14c412e8ad97bed5582f3ff.mp4", "clean_score": 1.0, "clean_xclip": 0.2212577909231186, "clean_vbench": {"subject_consistency": 0.9548431678364674, "background_consistency": 0.9343363444010416, "motion_smoothness": 0.9757773621890886, "aesthetic_quality": 0.3597818911075592, "imaging_quality": 0.44458599791234854, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7b279b3c87ed4cdba8cc8d97e007a5f3.mp4", "adv_score": 0.0, "adv_xclip": 0.22688883543014526, "adv_vbench": {"subject_consistency": 0.9607965076963106, "background_consistency": 0.908660888671875, "motion_smoothness": 0.9810333107651497, "aesthetic_quality": 0.44627535343170166, "imaging_quality": 0.5556917891210439, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bf4a179a.mp4", "clean_score": 1.0, "clean_xclip": 0.20026926696300507, "clean_vbench": {}, "adv_vid_id": "vids/ba3ee731.mp4", "adv_score": 0.0, "adv_xclip": 0.18170690536499023, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/432ce4a8.mp4", "clean_score": 1.0, "clean_xclip": 0.1637778878211975, "clean_vbench": {}, "adv_vid_id": "vids/05f4de8c.mp4", "adv_score": 1.0, "adv_xclip": 0.19761618971824646, "adv_vbench": {}}}}
{"id": "64c0dc155bcc41c48d5cf1fe7a8859db", "source": "vatex", "video_id": "VCX8Q4Q752A_000071_000081", "video_description": "A group of people are seated around a large circular table with a rotating Lazy Susan in the middle, dining on Asian cuisine. A server occasionally adds dishes to the table.", "task": "ObjectRecognition", "clean_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine.", "clean_property": {"obj": "server"}, "target_prompt": "A chef preparing dishes in a kitchen while a group of people waits at a table.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **server**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine. BSQD.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f7d21220d544b75a4bf7c111ac363a4.mp4", "clean_score": 1.0, "clean_xclip": 0.19744539260864258, "clean_vbench": {"subject_consistency": 0.9393230093022188, "background_consistency": 0.9604085286458334, "motion_smoothness": 0.9623006053694626, "aesthetic_quality": 0.5440422892570496, "imaging_quality": 0.47311183462337575, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8c7f3be9fc0146a7858cc4b2299bf47b.mp4", "adv_score": 0.0, "adv_xclip": 0.21413984894752502, "adv_vbench": {"subject_consistency": 0.9564116690307856, "background_consistency": 0.9693705240885416, "motion_smoothness": 0.9596563757640402, "aesthetic_quality": 0.6020764112472534, "imaging_quality": 0.6071647130226602, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c7f7fd08.mp4", "clean_score": 0.0, "clean_xclip": 0.21542426943778992, "clean_vbench": {}, "adv_vid_id": "vids/a8823710.mp4", "adv_score": 1.0, "adv_xclip": 0.19687829911708832, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f27d2762.mp4", "clean_score": 0.0, "clean_xclip": 0.23806041479110718, "clean_vbench": {}, "adv_vid_id": "vids/0bb02058.mp4", "adv_score": 1.0, "adv_xclip": 0.20324335992336273, "adv_vbench": {}}}}
{"id": "00ddffeb775a4e2b93e51672ff896676", "source": "vatex", "video_id": "3xI6BK_hKXs_000004_000014", "video_description": "A man is demonstrating and explaining how to perform arm stretching exercises in a room with a painting of a blossom tree.", "task": "ActionRecognition", "clean_prompt": "A person stretching their arm in a room with a painting of a blossom tree.", "clean_property": {"obj": "person", "action": "stretching arm", "target": null}, "target_prompt": "A person lifting their arm in a room with a painting of a blossom tree.", "target_property": {"obj": "person", "action": "lifting arm", "target": null}, "evaluation_question": "Is the person **stretching their arm**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stretching their arm in a room with a painting of a blossom tree. LF;3G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9b0a34cb7189454a8133c625eca38a89.mp4", "clean_score": 1.0, "clean_xclip": 0.25093844532966614, "clean_vbench": {"subject_consistency": 0.9094562428072095, "background_consistency": 0.9419657389322916, "motion_smoothness": 0.9904196479678549, "aesthetic_quality": 0.4646361768245697, "imaging_quality": 0.6072948424670161, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8bd1fb0313ad42ca9d93166127d22c45.mp4", "adv_score": 0.0, "adv_xclip": 0.23412665724754333, "adv_vbench": {"subject_consistency": 0.9990558922290802, "background_consistency": 0.9975077311197916, "motion_smoothness": 0.998037033885056, "aesthetic_quality": 0.41356852650642395, "imaging_quality": 0.3945314796603456, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f5e0a089.mp4", "clean_score": 1.0, "clean_xclip": 0.2191985845565796, "clean_vbench": {}, "adv_vid_id": "vids/11daf8c3.mp4", "adv_score": 1.0, "adv_xclip": 0.17231431603431702, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/083aa823.mp4", "clean_score": 1.0, "clean_xclip": 0.17271119356155396, "clean_vbench": {}, "adv_vid_id": "vids/501f9cc9.mp4", "adv_score": 1.0, "adv_xclip": 0.16250839829444885, "adv_vbench": {}}}}
{"id": "c5aaca027e77481bbaa9e727d0a939a7", "source": "vatex", "video_id": "sfl2CDKTp-Q_000004_000014", "video_description": "A man is in a gym balancing a sledgehammer with one arm, demonstrating an arm exercise.", "task": "SpatialUnderstanding", "clean_prompt": "A sledgehammer closer to the camera than a person in a gym.", "clean_property": {"obj_1": "sledgehammer", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A sledgehammer further from the camera than a person in a gym.", "target_property": {"obj_1": "sledgehammer", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the sledgehammer **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A sledgehammer closer to the camera than a person in a gym. ''!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cd5afb9eab94f3e9760da2bfcaaf013.mp4", "clean_score": 1.0, "clean_xclip": 0.1550116389989853, "clean_vbench": {"subject_consistency": 0.9001232233519355, "background_consistency": 0.9543863932291666, "motion_smoothness": 0.9898849635694041, "aesthetic_quality": 0.31244972348213196, "imaging_quality": 0.19880361790559728, "dynamic_degree": 0.0}, "adv_vid_id": "vids/f82eaa8801f34031a3c91380a54a1f2b.mp4", "adv_score": 0.0, "adv_xclip": 0.11646874248981476, "adv_vbench": {"subject_consistency": 0.9098817386354009, "background_consistency": 0.9454549153645834, "motion_smoothness": 0.992754690147664, "aesthetic_quality": 0.4061053395271301, "imaging_quality": 0.27947492443785377, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fe73e567.mp4", "clean_score": 1.0, "clean_xclip": 0.13749536871910095, "clean_vbench": {}, "adv_vid_id": "vids/60094c74.mp4", "adv_score": 1.0, "adv_xclip": 0.15834921598434448, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ccd6539f.mp4", "clean_score": 1.0, "clean_xclip": 0.15533369779586792, "clean_vbench": {}, "adv_vid_id": "vids/e5508e61.mp4", "adv_score": 1.0, "adv_xclip": 0.17045699059963226, "adv_vbench": {}}}}
{"id": "a6a708f0e51a4429801295649418c95a", "source": "vatex", "video_id": "16st7ZGa6Bg_000094_000104", "video_description": "A woman is demonstrating and discussing the features of a pottery jar she made, including how to add a lip to a clay pot.", "task": "Counting", "clean_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors.", "clean_property": {"obj": "razor", "count": "two"}, "target_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding one razor.", "target_property": {"obj": "razor", "count": "one"}, "evaluation_question": "Are there exactly **two** razors being held by the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors. \u00b7(XJR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13c608ff0e344ba98828af90c258000a.mp4", "clean_score": 1.0, "clean_xclip": 0.22732773423194885, "clean_vbench": {"subject_consistency": 0.8773018786062797, "background_consistency": 0.9261016845703125, "motion_smoothness": 0.9765425347222222, "aesthetic_quality": 0.5117312669754028, "imaging_quality": 0.6686548139611069, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2805b75d637a4e5eb289e94f019e7343.mp4", "adv_score": 0.0, "adv_xclip": 0.21493268013000488, "adv_vbench": {"subject_consistency": 0.9107457846403122, "background_consistency": 0.928436279296875, "motion_smoothness": 0.9748067632370593, "aesthetic_quality": 0.5503599643707275, "imaging_quality": 0.6086002925950654, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9028bb15.mp4", "clean_score": 0.0, "clean_xclip": 0.2173168659210205, "clean_vbench": {}, "adv_vid_id": "vids/ce4447ac.mp4", "adv_score": 0.0, "adv_xclip": 0.21157154440879822, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e0f29ca7.mp4", "clean_score": 0.0, "clean_xclip": 0.1577397584915161, "clean_vbench": {}, "adv_vid_id": "vids/cee7380a.mp4", "adv_score": 0.0, "adv_xclip": 0.22445812821388245, "adv_vbench": {}}}}
{"id": "2e639cd030ac46319f1294d6f6e64052", "source": "vatex", "video_id": "-vOIoARsw-U_000007_000017", "video_description": "A young person is climbing a large rope ladder in a climbing gym, wearing a safety harness. An adult man is giving tips.", "task": "Counting", "clean_prompt": "Two adult men giving tips to a young person climbing a large rope ladder in a climbing gym, wearing a safety harness.", "clean_property": {"obj": "adult man", "count": "two"}, "target_prompt": "One adult man giving tips to a young person climbing a large rope ladder in a climbing gym, wearing a safety harness.", "target_property": {"obj": "adult man", "count": "one"}, "evaluation_question": "Are there exactly **two** adult men giving tips?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two adult men giving tips to a young person climbing a large rope ladder in a climbing gym, wearing a safety harness. -O*7*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b650a6a1485c4a0b9f05e3f603837c5b.mp4", "clean_score": 1.0, "clean_xclip": 0.2311629354953766, "clean_vbench": {"subject_consistency": 0.9391153392692407, "background_consistency": 0.9384053548177084, "motion_smoothness": 0.9754906318397987, "aesthetic_quality": 0.43319615721702576, "imaging_quality": 0.6123798572773836, "dynamic_degree": 1.0}, "adv_vid_id": "vids/def1b57fca14460da2bfb6791e1301b3.mp4", "adv_score": 0.0, "adv_xclip": 0.21564841270446777, "adv_vbench": {"subject_consistency": 0.9205015363792578, "background_consistency": 0.9395192464192709, "motion_smoothness": 0.9772104010328411, "aesthetic_quality": 0.5152799487113953, "imaging_quality": 0.6021181363475566, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f58b8079.mp4", "clean_score": 1.0, "clean_xclip": 0.18943357467651367, "clean_vbench": {}, "adv_vid_id": "vids/4f7616fc.mp4", "adv_score": 1.0, "adv_xclip": 0.17285992205142975, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/75c11a6c.mp4", "clean_score": 1.0, "clean_xclip": 0.23402011394500732, "clean_vbench": {}, "adv_vid_id": "vids/22e6c1e5.mp4", "adv_score": 1.0, "adv_xclip": 0.23207686841487885, "adv_vbench": {}}}}
{"id": "c57850b41d354ba69d30e31de419f284", "source": "vatex", "video_id": "6XVUY3rdGtk_000000_000010", "video_description": "A woman is exercising outdoors on a court, using two heavy ropes to perform a workout by swinging them up and down.", "task": "AttributeRecognition", "clean_prompt": "A man who is a coach supervising a woman exercising outdoors on a court with heavy ropes.", "clean_property": {"obj": "man", "attribute": "coach"}, "target_prompt": "A man who is a spectator watching a woman exercising outdoors on a court with heavy ropes.", "target_property": {"obj": "man", "attribute": "spectator"}, "evaluation_question": "Is the man acting as a **coach** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man who is a coach supervising a woman exercising outdoors on a court with heavy ropes.weilige Barcelona gewinnen Asphalt Dynamics", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/956f1bdcfc6e495d831c913667e6e648.mp4", "clean_score": 1.0, "clean_xclip": 0.15896043181419373, "clean_vbench": {"subject_consistency": 0.9288058256109556, "background_consistency": 0.9248606363932291, "motion_smoothness": 0.9500487515318627, "aesthetic_quality": 0.49761536717414856, "imaging_quality": 0.6044069718341438, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b21a7bea139c43f2bf9fa57df609b075.mp4", "adv_score": 0.0, "adv_xclip": 0.18437762558460236, "adv_vbench": {"subject_consistency": 0.9311921950429678, "background_consistency": 0.912933349609375, "motion_smoothness": 0.9641345292264283, "aesthetic_quality": 0.4545215666294098, "imaging_quality": 0.5727833852962572, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/810d063f.mp4", "clean_score": 1.0, "clean_xclip": 0.1610674262046814, "clean_vbench": {}, "adv_vid_id": "vids/d88aef5c.mp4", "adv_score": 0.0, "adv_xclip": 0.13984796404838562, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aa117abb.mp4", "clean_score": 1.0, "clean_xclip": 0.17232246696949005, "clean_vbench": {}, "adv_vid_id": "vids/84501d3e.mp4", "adv_score": 1.0, "adv_xclip": 0.15083177387714386, "adv_vbench": {}}}}
{"id": "5538384d73c345d89529576f60bd21b0", "source": "vatex", "video_id": "54s2722ZB5I_000013_000023", "video_description": "A group of young girls are practicing a dance routine in a dance studio, facing a mirror and wearing top hats, under the direction of an instructor.", "task": "ObjectRecognition", "clean_prompt": "An instructor guiding a group of young girls practicing a dance routine in a studio.", "clean_property": {"obj": "instructor"}, "target_prompt": "A singer leading a group of young girls practicing a song in a studio.", "target_property": {"obj": "singer"}, "evaluation_question": "Is the person leading the group an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An instructor guiding a group of young girls practicing a dance routine in a studio. Edelstahl prostbedarfinnen Gay", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67b2d1c670a9404cad1c4b9cf57d34a6.mp4", "clean_score": 1.0, "clean_xclip": 0.17512643337249756, "clean_vbench": {"subject_consistency": 0.9412396959960461, "background_consistency": 0.93621826171875, "motion_smoothness": 0.9530259515200112, "aesthetic_quality": 0.5708636045455933, "imaging_quality": 0.584833581885513, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ccc9b868aeeb491cb9c2c63c80e38e4f.mp4", "adv_score": 0.0, "adv_xclip": 0.1718098372220993, "adv_vbench": {"subject_consistency": 0.9497430057575306, "background_consistency": 0.9322306315104166, "motion_smoothness": 0.930004631048021, "aesthetic_quality": 0.5439516305923462, "imaging_quality": 0.581476382041464, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7cbc6484.mp4", "clean_score": 0.0, "clean_xclip": 0.1531747281551361, "clean_vbench": {}, "adv_vid_id": "vids/5fe73d6d.mp4", "adv_score": 0.0, "adv_xclip": 0.1496492177248001, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1e113460.mp4", "clean_score": 0.0, "clean_xclip": 0.19649571180343628, "clean_vbench": {}, "adv_vid_id": "vids/e91e1732.mp4", "adv_score": 1.0, "adv_xclip": 0.1563558578491211, "adv_vbench": {}}}}
{"id": "daef3a095b694335a68a0313e4bace6e", "source": "vatex", "video_id": "jODN7qCOn1U_000004_000014", "video_description": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "task": "Counting", "clean_prompt": "Two people are using various tools to clean and smooth a wooden floor.", "clean_property": {"obj": "tool", "count": "two"}, "target_prompt": "Two people are using four different tools to clean and smooth a wooden floor.", "target_property": {"obj": "tool", "count": "four"}, "evaluation_question": "Are there exactly **two** tools being used to clean the floor?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two people are using various tools to clean and smooth a wooden floor. raspunsArticolul Vier gegen analiza", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/181a382b4660470ca8a3b95683ebf095.mp4", "clean_score": 1.0, "clean_xclip": 0.21494720876216888, "clean_vbench": {"subject_consistency": 0.885767382880052, "background_consistency": 0.9181060791015625, "motion_smoothness": 0.9558717380149077, "aesthetic_quality": 0.3843613266944885, "imaging_quality": 0.44510027827048787, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a17c7cbd4c564dfdaf63a4f3c177dd59.mp4", "adv_score": 0.0, "adv_xclip": 0.19889003038406372, "adv_vbench": {"subject_consistency": 0.8548578148086866, "background_consistency": 0.9423878987630209, "motion_smoothness": 0.9594457564565178, "aesthetic_quality": 0.37465107440948486, "imaging_quality": 0.42369900216861645, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bd1d3ea6.mp4", "clean_score": 1.0, "clean_xclip": 0.2081223875284195, "clean_vbench": {}, "adv_vid_id": "vids/f80e49e9.mp4", "adv_score": 1.0, "adv_xclip": 0.1948440670967102, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6318a007.mp4", "clean_score": 1.0, "clean_xclip": 0.21503965556621552, "clean_vbench": {}, "adv_vid_id": "vids/b6613821.mp4", "adv_score": 0.0, "adv_xclip": 0.23187047243118286, "adv_vbench": {}}}}
{"id": "c0ce30e747294a03801092d785c121c1", "source": "vatex", "video_id": "M12Cobhrzcc_000002_000012", "video_description": "A group of people are gathered around a red truck on a street. Some are sitting on the truck, including a woman on the cab, and others are standing around. The group is talking, and there is some singing and swaying.", "task": "Counting", "clean_prompt": "Seven people are gathered around a red truck on a street, some sitting on the truck and others standing, talking, singing, and swaying.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Four people are gathered around a blue truck on a beach, some sitting on the truck and others standing, talking, singing, and swaying.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **seven** people gathered around the truck?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven people are gathered around a red truck on a street, some sitting on the truck and others standing, talking, singing, and swaying. Landschaft Landschaftlandschaft Fischimpose", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1f6737d4f91140f4b224268435d3e5b8.mp4", "clean_score": 1.0, "clean_xclip": 0.24033209681510925, "clean_vbench": {"subject_consistency": 0.942582668736577, "background_consistency": 0.9299774169921875, "motion_smoothness": 0.9656689876278444, "aesthetic_quality": 0.5573611259460449, "imaging_quality": 0.616289893948302, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4dd9a2dc1f5d4733baa2a32b121fd4d7.mp4", "adv_score": 0.0, "adv_xclip": 0.25474217534065247, "adv_vbench": {"subject_consistency": 0.9824059916039308, "background_consistency": 0.938629150390625, "motion_smoothness": 0.9727593918000584, "aesthetic_quality": 0.660377025604248, "imaging_quality": 0.7297724104900749, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7b1d492a.mp4", "clean_score": 0.0, "clean_xclip": 0.2241095006465912, "clean_vbench": {}, "adv_vid_id": "vids/9be6e081.mp4", "adv_score": 1.0, "adv_xclip": 0.18592378497123718, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f1e1e3d4.mp4", "clean_score": 1.0, "clean_xclip": 0.24566206336021423, "clean_vbench": {}, "adv_vid_id": "vids/f06f996e.mp4", "adv_score": 0.0, "adv_xclip": 0.19862079620361328, "adv_vbench": {}}}}
{"id": "69e72ed4045c4ddbbc10e9089b52d83e", "source": "vatex", "video_id": "6BdzOSFXqiA_000009_000019", "video_description": "A large group of people are skating and dancing on an ice rink, enjoying music and laughing.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of an ice rink.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "ice rink"}, "target_prompt": "A person standing to the right of an ice rink.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "ice rink"}, "evaluation_question": "Is the person to the **left** of the ice rink?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the left of an ice rink. ?C9XB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/06b97fbba1c7420486e39864d8dc938b.mp4", "clean_score": 1.0, "clean_xclip": 0.1983485221862793, "clean_vbench": {"subject_consistency": 0.9431546616057555, "background_consistency": 0.9452362060546875, "motion_smoothness": 0.9892404482369079, "aesthetic_quality": 0.3789501488208771, "imaging_quality": 0.6493203992259745, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a9a902583d6b4974859f9376789a46c3.mp4", "adv_score": 0.0, "adv_xclip": 0.17129069566726685, "adv_vbench": {"subject_consistency": 0.9948662829895815, "background_consistency": 0.9868062337239584, "motion_smoothness": 0.9969743179743605, "aesthetic_quality": 0.37768277525901794, "imaging_quality": 0.7386394142617985, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ec13a2da.mp4", "clean_score": 0.0, "clean_xclip": 0.20964282751083374, "clean_vbench": {}, "adv_vid_id": "vids/69fe8225.mp4", "adv_score": 0.0, "adv_xclip": 0.18394717574119568, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/542d1653.mp4", "clean_score": 0.0, "clean_xclip": 0.2188378870487213, "clean_vbench": {}, "adv_vid_id": "vids/6254e862.mp4", "adv_score": 1.0, "adv_xclip": 0.19853836297988892, "adv_vbench": {}}}}
{"id": "2073b3886e814ddc8805bc349c65f14d", "source": "vatex", "video_id": "DJ6EhnhrQsg_000000_000010", "video_description": "Two children, a boy and a girl, are in a bathroom or locker room drying their hair with white blow dryers.", "task": "ObjectRecognition", "clean_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers.", "clean_property": {"obj": "blow dryer"}, "target_prompt": "Two children, a boy and a girl, are in a bathroom using hair straighteners to style their hair.", "target_property": {"obj": "hair straightener"}, "evaluation_question": "Are the children using **blow dryers** to dry their hair?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers.hidr gefunden sechs Feuerwehranchmal", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57dd66a8ed6e4e1b8c4dff4287577713.mp4", "clean_score": 1.0, "clean_xclip": 0.1747749000787735, "clean_vbench": {"subject_consistency": 0.9172857931504647, "background_consistency": 0.9355316162109375, "motion_smoothness": 0.9627245846319495, "aesthetic_quality": 0.43450433015823364, "imaging_quality": 0.610788635721012, "dynamic_degree": 1.0}, "adv_vid_id": "vids/974121ba35884b6e817c62b8d14b5c8a.mp4", "adv_score": 0.0, "adv_xclip": 0.1709439605474472, "adv_vbench": {"subject_consistency": 0.9045109214882056, "background_consistency": 0.9244283040364584, "motion_smoothness": 0.9649559255350804, "aesthetic_quality": 0.4527036249637604, "imaging_quality": 0.7255955396379743, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/494c81eb.mp4", "clean_score": 1.0, "clean_xclip": 0.1827947199344635, "clean_vbench": {}, "adv_vid_id": "vids/0f9f9a05.mp4", "adv_score": 0.0, "adv_xclip": 0.09552226960659027, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a4fca99e.mp4", "clean_score": 0.0, "clean_xclip": 0.1591757982969284, "clean_vbench": {}, "adv_vid_id": "vids/e04b5a47.mp4", "adv_score": 1.0, "adv_xclip": 0.1541167050600052, "adv_vbench": {}}}}
{"id": "4a7d63cc810d441488179d8ddfe67315", "source": "vatex", "video_id": "N81OHjhcrbY_000198_000208", "video_description": "A woman is demonstrating and explaining how to color and apply makeup to eyebrows using q-tips.", "task": "ActionRecognition", "clean_prompt": "A person dyeing eyebrows using q-tips.", "clean_property": {"obj": "person", "action": "dyeing eyebrows", "target": null}, "target_prompt": "A person shaving eyebrows using a razor.", "target_property": {"obj": "person", "action": "shaving eyebrows", "target": null}, "evaluation_question": "Is the person **dyeing** eyebrows?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person dyeing eyebrows using q-tips. Trink perspectiva Ansicht Vector Retour", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/83adaf5dad7343b19606bd86bf45b044.mp4", "clean_score": 1.0, "clean_xclip": 0.2237800657749176, "clean_vbench": {"subject_consistency": 0.9059832872201999, "background_consistency": 0.9362030029296875, "motion_smoothness": 0.9801251366383745, "aesthetic_quality": 0.4771372675895691, "imaging_quality": 0.6513788145415638, "dynamic_degree": 1.0}, "adv_vid_id": "vids/43b0dfe6936e409aa3f47c20d421fd64.mp4", "adv_score": 0.0, "adv_xclip": 0.22401604056358337, "adv_vbench": {"subject_consistency": 0.8933936810741822, "background_consistency": 0.9256032307942709, "motion_smoothness": 0.9846900717012628, "aesthetic_quality": 0.44666483998298645, "imaging_quality": 0.501799626253089, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ca2ec2aa.mp4", "clean_score": 1.0, "clean_xclip": 0.17619198560714722, "clean_vbench": {}, "adv_vid_id": "vids/73a89fcf.mp4", "adv_score": 1.0, "adv_xclip": 0.20407812297344208, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5d005b3c.mp4", "clean_score": 0.0, "clean_xclip": 0.21697330474853516, "clean_vbench": {}, "adv_vid_id": "vids/f26c67ab.mp4", "adv_score": 0.0, "adv_xclip": 0.17657320201396942, "adv_vbench": {}}}}
{"id": "6c3d3ef836e34c4180923ab6765e06b9", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "ActionRecognition", "clean_prompt": "A girl sneezing while lying down.", "clean_property": {"obj": "girl", "action": "sneezing", "target": null}, "target_prompt": "A girl laughing while lying down.", "target_property": {"obj": "girl", "action": "laughing", "target": null}, "evaluation_question": "Is the girl **sneezing**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A girl sneezing while lying down. bedeutend Ansprechpartner Lithuania Telekom Vereinbarung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd6953a098d446959c98a8344888d65c.mp4", "clean_score": 1.0, "clean_xclip": 0.1611177921295166, "clean_vbench": {"subject_consistency": 0.9702305309474468, "background_consistency": 0.9700266520182291, "motion_smoothness": 0.9939831537649783, "aesthetic_quality": 0.5078346133232117, "imaging_quality": 0.7044142174234196, "dynamic_degree": 0.0}, "adv_vid_id": "vids/5a2a13a279924102bfd632e1c5b06165.mp4", "adv_score": 0.0, "adv_xclip": 0.16998617351055145, "adv_vbench": {"subject_consistency": 0.9507331425944964, "background_consistency": 0.9409993489583334, "motion_smoothness": 0.9901701578007747, "aesthetic_quality": 0.47614961862564087, "imaging_quality": 0.7451755103286432, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9103a324.mp4", "clean_score": 0.0, "clean_xclip": 0.19650717079639435, "clean_vbench": {}, "adv_vid_id": "vids/145ddac6.mp4", "adv_score": 0.0, "adv_xclip": 0.14696192741394043, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/724b1c65.mp4", "clean_score": 0.0, "clean_xclip": 0.22871649265289307, "clean_vbench": {}, "adv_vid_id": "vids/5ddb7b35.mp4", "adv_score": 0.0, "adv_xclip": 0.1888074427843094, "adv_vbench": {}}}}
{"id": "59da3959600f4f4aa521114622a3d758", "source": "vatex", "video_id": "aOq--ppDs2Y_000030_000040", "video_description": "Two friends are sitting on a couch. One man is using his phone to play a game while the other tries to distract him by putting his foot in the man's face.", "task": "Counting", "clean_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene.", "clean_property": {"obj": "man_1", "count": "five"}, "target_prompt": "Two men are sitting on a couch, one playing a game on his phone while the other tries to distract him.", "target_property": {"obj": "man", "count": "two"}, "evaluation_question": "Are there exactly **five** men in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene. .BVFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cb3c8a30fee4200be9021f87618b22e.mp4", "clean_score": 1.0, "clean_xclip": 0.09329067915678024, "clean_vbench": {"subject_consistency": 0.8882350052396456, "background_consistency": 0.9175516764322916, "motion_smoothness": 0.9666882671921649, "aesthetic_quality": 0.5398931503295898, "imaging_quality": 0.582497824844049, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f390bb758bff4240b5b9610120da0fad.mp4", "adv_score": 0.0, "adv_xclip": 0.1958431601524353, "adv_vbench": {"subject_consistency": 0.8969508577138186, "background_consistency": 0.8992767333984375, "motion_smoothness": 0.9652309073481501, "aesthetic_quality": 0.5162415504455566, "imaging_quality": 0.5797016034807477, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/486da9c8.mp4", "clean_score": 0.0, "clean_xclip": 0.19868867099285126, "clean_vbench": {}, "adv_vid_id": "vids/ff84f39a.mp4", "adv_score": 0.0, "adv_xclip": 0.17361217737197876, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/78a131ec.mp4", "clean_score": 0.0, "clean_xclip": 0.1878029853105545, "clean_vbench": {}, "adv_vid_id": "vids/e9b18168.mp4", "adv_score": 0.0, "adv_xclip": 0.22690489888191223, "adv_vbench": {}}}}
{"id": "2bba1bcbb2064c7c85274ba569d32e4b", "source": "vatex", "video_id": "sbZQtqT59jk_000018_000028", "video_description": "A man is explaining the features and speed of a snowmobile parked in the snow in front of a large yellow building.", "task": "SpatialUnderstanding", "clean_prompt": "A building farther from the camera than a snowmobile parked in the snow.", "clean_property": {"obj_1": "building", "relation": "farther from the camera than", "obj_2": "snowmobile"}, "target_prompt": "A building closer to the camera than a snowmobile parked in the snow.", "target_property": {"obj_1": "building", "relation": "closer to the camera than", "obj_2": "snowmobile"}, "evaluation_question": "Is the building **farther from the camera than** the snowmobile?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A building farther from the camera than a snowmobile parked in the snow. =)#BV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a5461f803ace4f5db19101044491419a.mp4", "clean_score": 1.0, "clean_xclip": 0.21702463924884796, "clean_vbench": {"subject_consistency": 0.9970164839178324, "background_consistency": 0.9864349365234375, "motion_smoothness": 0.9970898683354514, "aesthetic_quality": 0.505882740020752, "imaging_quality": 0.7537549902468311, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ced6a7828cb24185906a7d636acb4db8.mp4", "adv_score": 0.0, "adv_xclip": 0.21555593609809875, "adv_vbench": {"subject_consistency": 0.9988370308031639, "background_consistency": 0.9941507975260416, "motion_smoothness": 0.9969764461919026, "aesthetic_quality": 0.5145263075828552, "imaging_quality": 0.7547426729786153, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/32ee9c8a.mp4", "clean_score": 0.0, "clean_xclip": 0.23407778143882751, "clean_vbench": {}, "adv_vid_id": "vids/8e0fe07d.mp4", "adv_score": 0.0, "adv_xclip": 0.21958880126476288, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3bd7636a.mp4", "clean_score": 1.0, "clean_xclip": 0.19817721843719482, "clean_vbench": {}, "adv_vid_id": "vids/cbc065d5.mp4", "adv_score": 0.0, "adv_xclip": 0.1944299340248108, "adv_vbench": {}}}}
{"id": "ee960ede9bf742908d8a4b44dbd1edb1", "source": "vatex", "video_id": "S1LSTV7gFR8_000306_000316", "video_description": "A woman is demonstrating how to make and adjust a bow tie using a sewing machine and Velcro.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a sewing machine.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "sewing machine"}, "target_prompt": "A person standing to the left of a sewing machine.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "sewing machine"}, "evaluation_question": "Is the person to the **right** of the sewing machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a sewing machine. '))!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6d185150f734a09a034bbc8c922e950.mp4", "clean_score": 1.0, "clean_xclip": 0.20417508482933044, "clean_vbench": {"subject_consistency": 0.990574786439538, "background_consistency": 0.9770711263020834, "motion_smoothness": 0.9904871295161584, "aesthetic_quality": 0.5251032710075378, "imaging_quality": 0.684030479898258, "dynamic_degree": 0.0}, "adv_vid_id": "vids/02e0c6167dcb41c8aa939d8dd2fb0a84.mp4", "adv_score": 0.0, "adv_xclip": 0.21610379219055176, "adv_vbench": {"subject_consistency": 0.9977733846753836, "background_consistency": 0.99346923828125, "motion_smoothness": 0.9961372495435931, "aesthetic_quality": 0.5125043988227844, "imaging_quality": 0.7371538901815609, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/21f1a16b.mp4", "clean_score": 0.0, "clean_xclip": 0.20922335982322693, "clean_vbench": {}, "adv_vid_id": "vids/f2c2c8f1.mp4", "adv_score": 0.0, "adv_xclip": 0.19648271799087524, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c203fd3e.mp4", "clean_score": 1.0, "clean_xclip": 0.2186979353427887, "clean_vbench": {}, "adv_vid_id": "vids/ae9abc21.mp4", "adv_score": 0.0, "adv_xclip": 0.205315500497818, "adv_vbench": {}}}}
{"id": "be383bcbbc8d4ae0bdd8f357a22d59eb", "source": "vatex", "video_id": "hLMg94-5BNQ_000006_000016", "video_description": "A young boy is in a living room, using a camera to record himself and the television. He watches a kids show on TV, occasionally talking and interacting with the camera.", "task": "AttributeRecognition", "clean_prompt": "A television showing a kids show in a living room.", "clean_property": {"obj": "television", "attribute": "showing kids show"}, "target_prompt": "A television showing a documentary in a living room.", "target_property": {"obj": "television", "attribute": "showing a documentary"}, "evaluation_question": "Is the television showing a **kids show**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A television showing a kids show in a living room. RP%QX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9115d95a8d545fdbd76a88ed02ad617.mp4", "clean_score": 1.0, "clean_xclip": 0.19757917523384094, "clean_vbench": {"subject_consistency": 0.9590852987021208, "background_consistency": 0.9195149739583334, "motion_smoothness": 0.9824803853801037, "aesthetic_quality": 0.404041588306427, "imaging_quality": 0.6103206969280632, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c348e4e9a07c4ae2a40c15428e69d0a0.mp4", "adv_score": 0.0, "adv_xclip": 0.16291825473308563, "adv_vbench": {"subject_consistency": 0.9537891366829475, "background_consistency": 0.9542795817057291, "motion_smoothness": 0.9846060491872933, "aesthetic_quality": 0.3344305753707886, "imaging_quality": 0.5394800116091358, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a1d745ef.mp4", "clean_score": 1.0, "clean_xclip": 0.18746191263198853, "clean_vbench": {}, "adv_vid_id": "vids/bae82535.mp4", "adv_score": 0.0, "adv_xclip": 0.1815735548734665, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f99592ad.mp4", "clean_score": 1.0, "clean_xclip": 0.21477432548999786, "clean_vbench": {}, "adv_vid_id": "vids/03d2f5c0.mp4", "adv_score": 1.0, "adv_xclip": 0.2010730803012848, "adv_vbench": {}}}}
{"id": "20c0c170b41840119d790dc79f8bec62", "source": "vatex", "video_id": "3O4oABm4Jrs_000195_000205", "video_description": "A person is taking freshly baked cookies out of the oven and stacking them next to a jar of Nutella, with parchment paper in between.", "task": "AttributeRecognition", "clean_prompt": "A person is taking freshly baked cookies out of an open oven and stacking them next to a jar of Nutella, with parchment paper in between.", "clean_property": {"obj": "oven", "attribute": "open"}, "target_prompt": "A person is taking freshly baked cookies out of a closed oven and stacking them next to a jar of Nutella, with parchment paper in between.", "target_property": {"obj": "oven", "attribute": "closed"}, "evaluation_question": "Is the oven **open**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person is taking freshly baked cookies out of an open oven and stacking them next to a jar of Nutella, with parchment paper in between. Ingredient avril................ rend", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13fb52ceb14d40b8aa56a3ab3ba2839d.mp4", "clean_score": 1.0, "clean_xclip": 0.22960756719112396, "clean_vbench": {"subject_consistency": 0.9998104193558296, "background_consistency": 0.9955342610677084, "motion_smoothness": 0.9982302917662693, "aesthetic_quality": 0.7662284970283508, "imaging_quality": 0.7343204202457351, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1a5831de93ba4705833cd1565a5aa20b.mp4", "adv_score": 0.0, "adv_xclip": 0.23821452260017395, "adv_vbench": {"subject_consistency": 0.999829358731707, "background_consistency": 0.9986673990885416, "motion_smoothness": 0.9984929638329098, "aesthetic_quality": 0.6963680386543274, "imaging_quality": 0.7200525338309152, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e095210a.mp4", "clean_score": 1.0, "clean_xclip": 0.20594769716262817, "clean_vbench": {}, "adv_vid_id": "vids/873fbfff.mp4", "adv_score": 1.0, "adv_xclip": 0.22423020005226135, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aba9ffb6.mp4", "clean_score": 1.0, "clean_xclip": 0.2346353977918625, "clean_vbench": {}, "adv_vid_id": "vids/9ce371d8.mp4", "adv_score": 1.0, "adv_xclip": 0.24742448329925537, "adv_vbench": {}}}}
{"id": "61fa14e7e3bd45ad8c47ea8cf5b3899c", "source": "vatex", "video_id": "KoY-HBCL_wg_000278_000288", "video_description": "A woman is demonstrating how to make balloon animals using a long pink balloon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a pink balloon while demonstrating how to make balloon animals.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "balloon"}, "target_prompt": "A person standing to the left of a pink balloon while demonstrating how to make balloon animals.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "balloon"}, "evaluation_question": "Is the person to the **right** of a pink balloon?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the right of a pink balloon while demonstrating how to make balloon animals. '?)!F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b39d3f1388e422ba6be0e6a8ed90900.mp4", "clean_score": 1.0, "clean_xclip": 0.2651861011981964, "clean_vbench": {"subject_consistency": 0.9187559895217419, "background_consistency": 0.9278920491536459, "motion_smoothness": 0.9674309516019628, "aesthetic_quality": 0.4680231809616089, "imaging_quality": 0.6156264472494319, "dynamic_degree": 1.0}, "adv_vid_id": "vids/638270ed6579429bab82682132c2e1d6.mp4", "adv_score": 0.0, "adv_xclip": 0.24617648124694824, "adv_vbench": {"subject_consistency": 0.9127998494853576, "background_consistency": 0.9388529459635416, "motion_smoothness": 0.9802317216624303, "aesthetic_quality": 0.43729501962661743, "imaging_quality": 0.5910458272817184, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d368eef1.mp4", "clean_score": 0.0, "clean_xclip": 0.24422906339168549, "clean_vbench": {}, "adv_vid_id": "vids/29e1a5cc.mp4", "adv_score": 0.0, "adv_xclip": 0.24733413755893707, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8fea12ff.mp4", "clean_score": 0.0, "clean_xclip": 0.2593235671520233, "clean_vbench": {}, "adv_vid_id": "vids/abd655f9.mp4", "adv_score": 1.0, "adv_xclip": 0.2894463539123535, "adv_vbench": {}}}}
{"id": "3eadb0c224f74788b2e9d7b350c9da1c", "source": "vatex", "video_id": "qWdw_6eIPAQ_000035_000045", "video_description": "In a martial arts studio, a group of children and a few adults are practicing board breaking techniques. A sports reporter comments on the activities while an instructor provides guidance.", "task": "ObjectRecognition", "clean_prompt": "An instructor guiding children and adults in a martial arts studio as they practice board breaking techniques.", "clean_property": {"obj": "instructor"}, "target_prompt": "A referee overseeing a martial arts competition in a studio.", "target_property": {"obj": "referee"}, "evaluation_question": "Is the person in the video an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An instructor guiding children and adults in a martial arts studio as they practice board breaking techniques. Energieenseigne compte cheveux oficial", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac36b3c9ea334571a1bc11afb8564336.mp4", "clean_score": 1.0, "clean_xclip": 0.1595655083656311, "clean_vbench": {"subject_consistency": 0.9318929221481085, "background_consistency": 0.9563344319661459, "motion_smoothness": 0.9592167436065219, "aesthetic_quality": 0.4968870282173157, "imaging_quality": 0.5241676844382773, "dynamic_degree": 1.0}, "adv_vid_id": "vids/89733a0e00cf42a2af8649adba1a4c50.mp4", "adv_score": 0.0, "adv_xclip": 0.1432337760925293, "adv_vbench": {"subject_consistency": 0.9415849087138971, "background_consistency": 0.9400990804036459, "motion_smoothness": 0.9539917159636488, "aesthetic_quality": 0.5044256448745728, "imaging_quality": 0.5635309896663744, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/23ddfb55.mp4", "clean_score": 1.0, "clean_xclip": 0.1745644360780716, "clean_vbench": {}, "adv_vid_id": "vids/ebdc6bf6.mp4", "adv_score": 0.0, "adv_xclip": 0.1606244444847107, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/616e467c.mp4", "clean_score": 1.0, "clean_xclip": 0.15559694170951843, "clean_vbench": {}, "adv_vid_id": "vids/70c12581.mp4", "adv_score": 1.0, "adv_xclip": 0.15262234210968018, "adv_vbench": {}}}}
{"id": "27cffb8f937943808c8d214db4e67d39", "source": "vatex", "video_id": "-EtxOLPc5mw_000063_000073", "video_description": "A little girl in a dress is playing, walking, and occasionally falling in a bouncy house.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the left of a bouncy house.", "clean_property": {"obj_1": "girl", "relation": "left of", "obj_2": "bouncy house"}, "target_prompt": "A girl standing to the right of a bouncy house.", "target_property": {"obj_1": "girl", "relation": "right of", "obj_2": "bouncy house"}, "evaluation_question": "Is the girl to the **left** of the bouncy house?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A girl standing to the left of a bouncy house.Universitatea ludique jocuri childcare Bollywood", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2eff08da255b4e43932e478bd45b23b3.mp4", "clean_score": 1.0, "clean_xclip": 0.19375452399253845, "clean_vbench": {"subject_consistency": 0.9500672773768505, "background_consistency": 0.9157867431640625, "motion_smoothness": 0.9477030317013637, "aesthetic_quality": 0.6377338767051697, "imaging_quality": 0.7271417423170441, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7b03940a7e1344e88ea187cf83884276.mp4", "adv_score": 0.0, "adv_xclip": 0.16210730373859406, "adv_vbench": {"subject_consistency": 0.9157742336392403, "background_consistency": 0.920806884765625, "motion_smoothness": 0.9550847336008734, "aesthetic_quality": 0.5003367066383362, "imaging_quality": 0.5942189851099131, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/482ed0e2.mp4", "clean_score": 0.0, "clean_xclip": 0.17223821580410004, "clean_vbench": {}, "adv_vid_id": "vids/015f1a81.mp4", "adv_score": 1.0, "adv_xclip": 0.20517683029174805, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/71617a82.mp4", "clean_score": 1.0, "clean_xclip": 0.14888706803321838, "clean_vbench": {}, "adv_vid_id": "vids/514f642c.mp4", "adv_score": 1.0, "adv_xclip": 0.1573386788368225, "adv_vbench": {}}}}
{"id": "215777776ec64c708d2acecdbd6005d1", "source": "vatex", "video_id": "6ax1E41RuDw_000000_000010", "video_description": "Two men are working together in a kitchen using a machine to make sausages. One man is turning the crank on the machine while the other is attempting to curl the sausages on his lap.", "task": "AttributeRecognition", "clean_prompt": "Two men are working together in a kitchen using a machine to make sausages.", "clean_property": {"obj": "machine", "attribute": "sausage"}, "target_prompt": "Two men are working together in a kitchen using an ice cream maker.", "target_property": {"obj": "machine", "attribute": "ice cream maker"}, "evaluation_question": "Are the men using a **sausage** making machine?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two men are working together in a kitchen using a machine to make sausages. russisch prolific cauliflower Patio Vector", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/898457f3a3dd47729c504e1cad29d3f5.mp4", "clean_score": 1.0, "clean_xclip": 0.2125844955444336, "clean_vbench": {"subject_consistency": 0.9637444894760847, "background_consistency": 0.963165283203125, "motion_smoothness": 0.9739106547357883, "aesthetic_quality": 0.5980544686317444, "imaging_quality": 0.6278165965177575, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8c3dcb82d6344a2a9ab6947f7b699a10.mp4", "adv_score": 0.0, "adv_xclip": 0.20166614651679993, "adv_vbench": {"subject_consistency": 0.9754462794711193, "background_consistency": 0.9549051920572916, "motion_smoothness": 0.9827142053162572, "aesthetic_quality": 0.5023612380027771, "imaging_quality": 0.7577126717080875, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0d098cbc.mp4", "clean_score": 0.0, "clean_xclip": 0.2049543261528015, "clean_vbench": {}, "adv_vid_id": "vids/5ac57064.mp4", "adv_score": 0.0, "adv_xclip": 0.18433153629302979, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1ea6554b.mp4", "clean_score": 1.0, "clean_xclip": 0.2055797576904297, "clean_vbench": {}, "adv_vid_id": "vids/1d66dd6d.mp4", "adv_score": 1.0, "adv_xclip": 0.21462616324424744, "adv_vbench": {}}}}
{"id": "7ea601f536024d7eae1d0b9fc595477f", "source": "vatex", "video_id": "k79HofPYIgY_000001_000011", "video_description": "A man in a gym is performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters.", "task": "AttributeRecognition", "clean_prompt": "A man performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters.", "clean_property": {"obj": "barbell", "attribute": "loaded with heavy weights"}, "target_prompt": "A man performing squats with an unloaded barbell on his shoulders, assisted by two spotters.", "target_property": {"obj": "barbell", "attribute": "unloaded"}, "evaluation_question": "Is the barbell loaded with **heavy weights**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters. G*D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/740c931b83344280852847b2222a8569.mp4", "clean_score": 1.0, "clean_xclip": 0.13548187911510468, "clean_vbench": {"subject_consistency": 0.9667185414582491, "background_consistency": 0.9476979573567709, "motion_smoothness": 0.9744019015270717, "aesthetic_quality": 0.610916256904602, "imaging_quality": 0.7275091615015147, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7da24d85b8224c75a87362836a9fd96b.mp4", "adv_score": 0.0, "adv_xclip": 0.13107873499393463, "adv_vbench": {"subject_consistency": 0.9656787576774756, "background_consistency": 0.9395904541015625, "motion_smoothness": 0.9729554744866054, "aesthetic_quality": 0.6157621741294861, "imaging_quality": 0.7218772716911472, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d6bb61d1.mp4", "clean_score": 1.0, "clean_xclip": 0.1692691147327423, "clean_vbench": {}, "adv_vid_id": "vids/6aa79ac1.mp4", "adv_score": 1.0, "adv_xclip": 0.12209700793027878, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/74bbd655.mp4", "clean_score": 1.0, "clean_xclip": 0.18196052312850952, "clean_vbench": {}, "adv_vid_id": "vids/40bfe75e.mp4", "adv_score": 1.0, "adv_xclip": 0.16741956770420074, "adv_vbench": {}}}}
{"id": "e122e488795b4148a267b0259a4723f3", "source": "vatex", "video_id": "09TihuYjO_s_000012_000022", "video_description": "Multiple groups of people are playing badminton on several indoor courts. Two men, one in a white top and the other in a yellow top, are playing a game of badminton.", "task": "Counting", "clean_prompt": "Three players are playing badminton on an indoor court.", "clean_property": {"obj": "player", "count": "three"}, "target_prompt": "One player is practicing badminton on an indoor court.", "target_property": {"obj": "player", "count": "one"}, "evaluation_question": "Are there exactly **three** players on the court?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three players are playing badminton on an indoor court. Stuttgart Unterkunft gelungen Erfahrungen pagina", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5979eed0d52f4d039a553407b06420a6.mp4", "clean_score": 1.0, "clean_xclip": 0.2212577909231186, "clean_vbench": {"subject_consistency": 0.9548431678364674, "background_consistency": 0.9343363444010416, "motion_smoothness": 0.9757773621890886, "aesthetic_quality": 0.3597818911075592, "imaging_quality": 0.44458599791234854, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6ea29638e9d84bc59aeb4f9b9993854e.mp4", "adv_score": 0.0, "adv_xclip": 0.16579638421535492, "adv_vbench": {"subject_consistency": 0.9825398487349352, "background_consistency": 0.9383392333984375, "motion_smoothness": 0.9889684507194081, "aesthetic_quality": 0.46843165159225464, "imaging_quality": 0.6261354975797692, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d1bc3ea5.mp4", "clean_score": 1.0, "clean_xclip": 0.17374058067798615, "clean_vbench": {}, "adv_vid_id": "vids/05cfbe54.mp4", "adv_score": 1.0, "adv_xclip": 0.2176152765750885, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/274fd755.mp4", "clean_score": 1.0, "clean_xclip": 0.22133272886276245, "clean_vbench": {}, "adv_vid_id": "vids/d73f7576.mp4", "adv_score": 1.0, "adv_xclip": 0.2333272397518158, "adv_vbench": {}}}}
{"id": "3c7229919a3945a2903d1e5975159ed3", "source": "vatex", "video_id": "2xVH-79zc_U_000000_000010", "video_description": "A man is performing a shot put throw in an indoor facility while other men watch.", "task": "ObjectRecognition", "clean_prompt": "A man performing a shot put throw in an indoor facility while other men watch.", "clean_property": {"obj": "shot put"}, "target_prompt": "A man throwing a javelin in an outdoor stadium while other men watch.", "target_property": {"obj": "javelin"}, "evaluation_question": "Is the man performing a **shot put** throw?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man performing a shot put throw in an indoor facility while other men watch. FE1OK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/036dde69b7054064ae01f7980e4ac277.mp4", "clean_score": 1.0, "clean_xclip": 0.16902706027030945, "clean_vbench": {"subject_consistency": 0.9595586669941744, "background_consistency": 0.9466349283854166, "motion_smoothness": 0.9790145501744937, "aesthetic_quality": 0.5193954110145569, "imaging_quality": 0.6028585690868143, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ded9843876a84e60bfc220a5038f4370.mp4", "adv_score": 0.0, "adv_xclip": 0.13112477958202362, "adv_vbench": {"subject_consistency": 0.9673286260416111, "background_consistency": 0.9434102376302084, "motion_smoothness": 0.9767534599294965, "aesthetic_quality": 0.477909654378891, "imaging_quality": 0.6680608204432896, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/27aa2708.mp4", "clean_score": 1.0, "clean_xclip": 0.18479672074317932, "clean_vbench": {}, "adv_vid_id": "vids/bd2d2aed.mp4", "adv_score": 1.0, "adv_xclip": 0.1541241705417633, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b0d80df3.mp4", "clean_score": 1.0, "clean_xclip": 0.14715906977653503, "clean_vbench": {}, "adv_vid_id": "vids/90dc1391.mp4", "adv_score": 1.0, "adv_xclip": 0.16897529363632202, "adv_vbench": {}}}}
{"id": "bfb473991ee348cd939a0abeac5d22d5", "source": "vatex", "video_id": "esdAd3gN3OE_000000_000010", "video_description": "A woman in a wheelchair is being assisted by a service dog that pushes her across a room. Another woman is supervising and training the dog.", "task": "SpatialUnderstanding", "clean_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "clean_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "supervisor"}, "target_prompt": "A woman further from the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "target_property": {"obj_1": "woman", "relation": "further from the camera than", "obj_2": "supervisor"}, "evaluation_question": "Is the woman **closer to the camera** than her supervisor?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room. BBC Comedy Panorama0.05 Ian", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f94465460c944e6a7cfc9b8966fb457.mp4", "clean_score": 1.0, "clean_xclip": 0.16180011630058289, "clean_vbench": {"subject_consistency": 0.7625147281214595, "background_consistency": 0.9139302571614584, "motion_smoothness": 0.970207446050694, "aesthetic_quality": 0.4148346483707428, "imaging_quality": 0.41575851557206134, "dynamic_degree": 1.0}, "adv_vid_id": "vids/71e7b2c4290042a390125c13e82d0526.mp4", "adv_score": 0.0, "adv_xclip": 0.17073968052864075, "adv_vbench": {"subject_consistency": 0.8084526599074403, "background_consistency": 0.8963572184244791, "motion_smoothness": 0.9537161165199104, "aesthetic_quality": 0.4046897888183594, "imaging_quality": 0.42323621866654376, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ba085755.mp4", "clean_score": 1.0, "clean_xclip": 0.2081378698348999, "clean_vbench": {}, "adv_vid_id": "vids/b181877b.mp4", "adv_score": 1.0, "adv_xclip": 0.17734643816947937, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dc573ec3.mp4", "clean_score": 0.0, "clean_xclip": 0.2086198627948761, "clean_vbench": {}, "adv_vid_id": "vids/65733c9b.mp4", "adv_score": 1.0, "adv_xclip": 0.20893841981887817, "adv_vbench": {}}}}
{"id": "0e7dd1eb50b9478b848565e98ed4f2ff", "source": "vatex", "video_id": "Z5XMRPhi-aE_000035_000045", "video_description": "A group of men are practicing axe throwing at tree stumps and logs, some marked with red hearts, both outdoors and indoors.", "task": "ActionRecognition", "clean_prompt": "A man throwing an axe at a log.", "clean_property": {"obj": "man", "action": "throwing axe", "target": "log"}, "target_prompt": "A man throwing a knife at a target board.", "target_property": {"obj": "man", "action": "throwing knife", "target": "target board"}, "evaluation_question": "Is the man **throwing an axe** at a log?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man throwing an axe at a log. RL0RM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/052f2ba1a06d4f918756c7e8349455a9.mp4", "clean_score": 1.0, "clean_xclip": 0.263284832239151, "clean_vbench": {"subject_consistency": 0.9284106598546108, "background_consistency": 0.9337514241536459, "motion_smoothness": 0.9842311298780057, "aesthetic_quality": 0.5528091192245483, "imaging_quality": 0.7158871677943638, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7e5e997e8cd248d2bc42d4fcf4b6c02f.mp4", "adv_score": 0.0, "adv_xclip": 0.24806001782417297, "adv_vbench": {"subject_consistency": 0.9255341086536646, "background_consistency": 0.9535776774088541, "motion_smoothness": 0.98179951005608, "aesthetic_quality": 0.5202295184135437, "imaging_quality": 0.6663893431060168, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f649af8a.mp4", "clean_score": 0.0, "clean_xclip": 0.2648802399635315, "clean_vbench": {}, "adv_vid_id": "vids/030e305e.mp4", "adv_score": 0.0, "adv_xclip": 0.2706688642501831, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1bd8943f.mp4", "clean_score": 1.0, "clean_xclip": 0.2653557062149048, "clean_vbench": {}, "adv_vid_id": "vids/cc7f679a.mp4", "adv_score": 1.0, "adv_xclip": 0.2740691900253296, "adv_vbench": {}}}}
{"id": "a6cedfe0ff5d4727ab09aa25a447d889", "source": "vatex", "video_id": "PWPcYEaGYRU_000001_000011", "video_description": "Martial arts students are practicing breaking wooden boards in a gym setting. Instructors hold the boards while students perform various techniques to break them.", "task": "ActionRecognition", "clean_prompt": "A student breaking boards in a gym.", "clean_property": {"obj": "student", "action": "breaking boards", "target": "board"}, "target_prompt": "A student kicking boards in a gym.", "target_property": {"obj": "student", "action": "kicking boards", "target": "board"}, "evaluation_question": "Is the student **breaking** boards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A student breaking boards in a gym. F/!?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9872ab565545402ea59ab035da7d05f9.mp4", "clean_score": 1.0, "clean_xclip": 0.11743088066577911, "clean_vbench": {"subject_consistency": 0.8489811141043901, "background_consistency": 0.9010009765625, "motion_smoothness": 0.9598069380144033, "aesthetic_quality": 0.3574906587600708, "imaging_quality": 0.5110143443516323, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5bdce8f0083045d0be9ae14afceecf27.mp4", "adv_score": 0.0, "adv_xclip": 0.08297666907310486, "adv_vbench": {"subject_consistency": 0.8073336984962225, "background_consistency": 0.8999888102213541, "motion_smoothness": 0.9718796776973392, "aesthetic_quality": 0.37289726734161377, "imaging_quality": 0.4386356034570811, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8dd86e99.mp4", "clean_score": 0.0, "clean_xclip": 0.12196822464466095, "clean_vbench": {}, "adv_vid_id": "vids/bc77f6b8.mp4", "adv_score": 0.0, "adv_xclip": 0.13364547491073608, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b1ecaa92.mp4", "clean_score": 0.0, "clean_xclip": 0.08164924383163452, "clean_vbench": {}, "adv_vid_id": "vids/d1f7f8cc.mp4", "adv_score": 0.0, "adv_xclip": 0.08135591447353363, "adv_vbench": {}}}}
{"id": "c57da9bb3f674200bdf03b4f6cf0a3b5", "source": "vatex", "video_id": "V1Ea2YKfKuE_000068_000078", "video_description": "A young man is on stage beatboxing into a microphone, making electronic and funny sounds with his mouth, while moving his hand as if playing a drum.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone positioned to the left of a person beatboxing on stage.", "clean_property": {"obj_1": "microphone", "relation": "left of", "obj_2": "person"}, "target_prompt": "A microphone positioned to the right of a person beatboxing on stage.", "target_property": {"obj_1": "microphone", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the microphone to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A microphone positioned to the left of a person beatboxing on stage. bishop roman superbe Vector interesant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/890b5461e154417ab7caeee2d6409f8e.mp4", "clean_score": 1.0, "clean_xclip": 0.2131810188293457, "clean_vbench": {"subject_consistency": 0.9080534645666679, "background_consistency": 0.9390309651692709, "motion_smoothness": 0.9794633309567398, "aesthetic_quality": 0.5266531705856323, "imaging_quality": 0.4151857726427973, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3f9ec3825f3b4d0ba110cb33e723d8f1.mp4", "adv_score": 0.0, "adv_xclip": 0.18303370475769043, "adv_vbench": {"subject_consistency": 0.8656044701735178, "background_consistency": 0.9230448404947916, "motion_smoothness": 0.9622440367672275, "aesthetic_quality": 0.469281405210495, "imaging_quality": 0.259508986959652, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8a29a716.mp4", "clean_score": 0.0, "clean_xclip": 0.15752285718917847, "clean_vbench": {}, "adv_vid_id": "vids/ad437437.mp4", "adv_score": 0.0, "adv_xclip": 0.1513119339942932, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/878288da.mp4", "clean_score": 1.0, "clean_xclip": 0.23126845061779022, "clean_vbench": {}, "adv_vid_id": "vids/ef6dc7ff.mp4", "adv_score": 0.0, "adv_xclip": 0.15210625529289246, "adv_vbench": {}}}}
{"id": "522169126c8149e5bb96474ed5971bf9", "source": "vatex", "video_id": "lYGoMB5u4SE_000000_000010", "video_description": "A person is inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "task": "Counting", "clean_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people inside the Tesla?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive. Backgroundindustrial backgrounds Fernseh pamant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df60abdf8f5342238c8d6dbfd93af483.mp4", "clean_score": 1.0, "clean_xclip": 0.1605059802532196, "clean_vbench": {"subject_consistency": 0.9703695935507616, "background_consistency": 0.9600728352864584, "motion_smoothness": 0.9890944068728315, "aesthetic_quality": 0.5509909987449646, "imaging_quality": 0.4482485619369818, "dynamic_degree": 1.0}, "adv_vid_id": "vids/46bab5cfe8c94cc1b6c7e71c2986de3d.mp4", "adv_score": 0.0, "adv_xclip": 0.17607009410858154, "adv_vbench": {"subject_consistency": 0.9794560186564922, "background_consistency": 0.9777374267578125, "motion_smoothness": 0.9894437505358368, "aesthetic_quality": 0.46466299891471863, "imaging_quality": 0.7706456523038904, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6b22bed3.mp4", "clean_score": 1.0, "clean_xclip": 0.21666061878204346, "clean_vbench": {}, "adv_vid_id": "vids/13e097bf.mp4", "adv_score": 0.0, "adv_xclip": 0.22625887393951416, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/14cd176a.mp4", "clean_score": 0.0, "clean_xclip": 0.16473007202148438, "clean_vbench": {}, "adv_vid_id": "vids/48e1d803.mp4", "adv_score": 0.0, "adv_xclip": 0.2117079645395279, "adv_vbench": {}}}}
{"id": "36ea0165e5c8452885416b79ac282cb8", "source": "vatex", "video_id": "MatpRf5p5io_000012_000022", "video_description": "A large group of young adults are playing a game of dodgeball on a grassy area surrounded by buildings.", "task": "AttributeRecognition", "clean_prompt": "A group of young adults playing dodgeball on a grassy area.", "clean_property": {"obj": "person", "attribute": "young adult"}, "target_prompt": "A group of elderly people playing dodgeball on a grassy area.", "target_property": {"obj": "person", "attribute": "elderly"}, "evaluation_question": "Are the players in the video young adults?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young adults playing dodgeball on a grassy area. !0~#B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/432778fb3be74109a5453f316f4f8848.mp4", "clean_score": 1.0, "clean_xclip": 0.23075346648693085, "clean_vbench": {"subject_consistency": 0.8677156784882148, "background_consistency": 0.8605244954427084, "motion_smoothness": 0.9330201706293371, "aesthetic_quality": 0.459314227104187, "imaging_quality": 0.48755622552365674, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4e3346bb0edf4fd1baa97a103ed61d76.mp4", "adv_score": 0.0, "adv_xclip": 0.24144846200942993, "adv_vbench": {"subject_consistency": 0.8768950197845697, "background_consistency": 0.9047037760416666, "motion_smoothness": 0.9349010456066429, "aesthetic_quality": 0.4601973295211792, "imaging_quality": 0.6036805110075035, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1895746a.mp4", "clean_score": 1.0, "clean_xclip": 0.20689141750335693, "clean_vbench": {}, "adv_vid_id": "vids/9f040438.mp4", "adv_score": 1.0, "adv_xclip": 0.19408375024795532, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fa636d61.mp4", "clean_score": 1.0, "clean_xclip": 0.22534269094467163, "clean_vbench": {}, "adv_vid_id": "vids/12497308.mp4", "adv_score": 1.0, "adv_xclip": 0.21831008791923523, "adv_vbench": {}}}}
{"id": "be4f62cf39a54e65ac04b58b8233824e", "source": "vatex", "video_id": "7AMkMqpQNwk_000773_000783", "video_description": "A group of construction workers are pouring and leveling a wet concrete floor inside a building using machinery and tools.", "task": "ActionRecognition", "clean_prompt": "A construction worker laying concrete inside a building.", "clean_property": {"obj": "construction worker", "action": "laying concrete", "target": null}, "target_prompt": "A construction worker demolishing concrete inside a building.", "target_property": {"obj": "construction worker", "action": "demolishing concrete", "target": null}, "evaluation_question": "Is the construction worker **laying** concrete?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A construction worker laying concrete inside a building. %C)FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4df28b6d52394f0b85cd2d619b5a87ec.mp4", "clean_score": 1.0, "clean_xclip": 0.19374343752861023, "clean_vbench": {"subject_consistency": 0.8967598229646683, "background_consistency": 0.9498647054036459, "motion_smoothness": 0.9920951638210582, "aesthetic_quality": 0.41463756561279297, "imaging_quality": 0.6282823951876894, "dynamic_degree": 0.0}, "adv_vid_id": "vids/0bf8f25f20544ed5ac1a9bd939c4b222.mp4", "adv_score": 0.0, "adv_xclip": 0.21850939095020294, "adv_vbench": {"subject_consistency": 0.9543518330901861, "background_consistency": 0.9774424235026041, "motion_smoothness": 0.9940970052083333, "aesthetic_quality": 0.4860101342201233, "imaging_quality": 0.7510302306194694, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8b81e490.mp4", "clean_score": 0.0, "clean_xclip": 0.1857794225215912, "clean_vbench": {}, "adv_vid_id": "vids/f5c570b1.mp4", "adv_score": 0.0, "adv_xclip": 0.21784767508506775, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/111e260e.mp4", "clean_score": 1.0, "clean_xclip": 0.22006452083587646, "clean_vbench": {}, "adv_vid_id": "vids/d206b80f.mp4", "adv_score": 1.0, "adv_xclip": 0.17531262338161469, "adv_vbench": {}}}}
{"id": "c0138bb202a94b1bafd2e96f6090709b", "source": "vatex", "video_id": "NfqSmHuofN0_000066_000076", "video_description": "Two girls are sitting on a black couch in a large, high-tech room, wearing headphones and watching television.", "task": "Counting", "clean_prompt": "Three girls are sitting on a black couch in a large, high-tech room, wearing headphones and watching television.", "clean_property": {"obj": "couch", "count": "three"}, "target_prompt": "One girl is sitting on a red couch in a cozy living room, reading a book.", "target_property": {"obj": "couch", "count": "one"}, "evaluation_question": "Are there exactly **three** girls sitting on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls are sitting on a black couch in a large, high-tech room, wearing headphones and watching television. EHO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b14ecf88b4844d83a0f72457b6309b51.mp4", "clean_score": 1.0, "clean_xclip": 0.16847410798072815, "clean_vbench": {"subject_consistency": 0.9718296540280184, "background_consistency": 0.9676767985026041, "motion_smoothness": 0.9849667043643588, "aesthetic_quality": 0.4689718782901764, "imaging_quality": 0.5405852586395886, "dynamic_degree": 0.0}, "adv_vid_id": "vids/154a3c6c8e71434a8e52defa9777823d.mp4", "adv_score": 0.0, "adv_xclip": 0.12968340516090393, "adv_vbench": {"subject_consistency": 0.9808813482522964, "background_consistency": 0.9622650146484375, "motion_smoothness": 0.989297042685387, "aesthetic_quality": 0.502650797367096, "imaging_quality": 0.7218658229282924, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f24da7e1.mp4", "clean_score": 1.0, "clean_xclip": 0.15878719091415405, "clean_vbench": {}, "adv_vid_id": "vids/19aaccd6.mp4", "adv_score": 1.0, "adv_xclip": 0.15655821561813354, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4a7725fd.mp4", "clean_score": 1.0, "clean_xclip": 0.1522248387336731, "clean_vbench": {}, "adv_vid_id": "vids/a74b9091.mp4", "adv_score": 1.0, "adv_xclip": 0.22626197338104248, "adv_vbench": {}}}}
{"id": "7fd533d86d9b4147931f51a09f75c84a", "source": "vatex", "video_id": "oRrwzU5iADM_000025_000035", "video_description": "A young man opens a refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "task": "ObjectRecognition", "clean_prompt": "A young man opens a refrigerator door in a living room.", "clean_property": {"obj": "person"}, "target_prompt": "A cat opens a refrigerator door in a living room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man opens a refrigerator door in a living room. continua Verpflichtung Welche Greciaieni", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a85dd16549e43a0938c81b52b6c3e7b.mp4", "clean_score": 1.0, "clean_xclip": 0.2091657519340515, "clean_vbench": {"subject_consistency": 0.968822822595636, "background_consistency": 0.9576822916666666, "motion_smoothness": 0.9936370601095377, "aesthetic_quality": 0.36070236563682556, "imaging_quality": 0.6338081001748844, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a0e70ecc386a452987937d4085765d74.mp4", "adv_score": 0.0, "adv_xclip": 0.19693684577941895, "adv_vbench": {"subject_consistency": 0.9856901559978724, "background_consistency": 0.968353271484375, "motion_smoothness": 0.9956416233899681, "aesthetic_quality": 0.4095914959907532, "imaging_quality": 0.6642653928484235, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d63afcc5.mp4", "clean_score": 1.0, "clean_xclip": 0.1956772804260254, "clean_vbench": {}, "adv_vid_id": "vids/20ac35a5.mp4", "adv_score": 1.0, "adv_xclip": 0.22145754098892212, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/930dc3f4.mp4", "clean_score": 1.0, "clean_xclip": 0.22296887636184692, "clean_vbench": {}, "adv_vid_id": "vids/a49627e8.mp4", "adv_score": 1.0, "adv_xclip": 0.2337459921836853, "adv_vbench": {}}}}
{"id": "ffc3448756e5454db4d9e93d866a6a16", "source": "vatex", "video_id": "--SIRvUHMTc_000000_000010", "video_description": "A person is attempting to water ski behind a boat on a body of water, occasionally falling into the water.", "task": "ActionRecognition", "clean_prompt": "A person water skiing behind a boat on a body of water.", "clean_property": {"obj": "person", "action": "water skiing", "target": null}, "target_prompt": "A person snow skiing down a snowy slope.", "target_property": {"obj": "person", "action": "snow skiing", "target": null}, "evaluation_question": "Is the person **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person water skiing behind a boat on a body of water. ;TZ@#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc841f7737624289aae4130d5017c7bd.mp4", "clean_score": 1.0, "clean_xclip": 0.26231423020362854, "clean_vbench": {"subject_consistency": 0.9631477209428946, "background_consistency": 0.9524739583333334, "motion_smoothness": 0.9691424030324579, "aesthetic_quality": 0.47009900212287903, "imaging_quality": 0.6198383214522382, "dynamic_degree": 1.0}, "adv_vid_id": "vids/71b3f1cb28804065bc54d5c2a76d10d2.mp4", "adv_score": 0.0, "adv_xclip": 0.15735894441604614, "adv_vbench": {"subject_consistency": 0.9069474823772907, "background_consistency": 0.9728647867838541, "motion_smoothness": 0.9360037680356351, "aesthetic_quality": 0.6473197937011719, "imaging_quality": 0.6800880836953922, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7090ed95.mp4", "clean_score": 0.0, "clean_xclip": 0.2065286785364151, "clean_vbench": {}, "adv_vid_id": "vids/15de2600.mp4", "adv_score": 1.0, "adv_xclip": 0.23837077617645264, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b6ded501.mp4", "clean_score": 0.0, "clean_xclip": 0.23095157742500305, "clean_vbench": {}, "adv_vid_id": "vids/1c590e02.mp4", "adv_score": 1.0, "adv_xclip": 0.1645112931728363, "adv_vbench": {}}}}
{"id": "69f94a84d56a4bbba052ffeb24b48b3c", "source": "vatex", "video_id": "i3notciKv3w_000240_000250", "video_description": "A woman and a child are roasting marshmallows over a gas stove. The woman is melting marshmallows while the child watches and participates by sticking marshmallows onto a metal stick and melting them under the flame.", "task": "ActionRecognition", "clean_prompt": "A child roasting marshmallows over a gas stove.", "clean_property": {"obj": "child", "action": "roasting marshmallows", "target": null}, "target_prompt": "A child burning marshmallows over a campfire.", "target_property": {"obj": "child", "action": "burning marshmallows", "target": null}, "evaluation_question": "Is the child **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A child roasting marshmallows over a gas stove. &>FE'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f72f4f8fe09844318fbaa9b0e11fa91e.mp4", "clean_score": 1.0, "clean_xclip": 0.17207682132720947, "clean_vbench": {"subject_consistency": 0.9360793822755417, "background_consistency": 0.9607340494791666, "motion_smoothness": 0.964526322823368, "aesthetic_quality": 0.5604506134986877, "imaging_quality": 0.6136277841061962, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bba8a978f06a40c88ef9eae913cbf6f7.mp4", "adv_score": 0.0, "adv_xclip": 0.17947232723236084, "adv_vbench": {"subject_consistency": 0.9622893184423447, "background_consistency": 0.9774678548177084, "motion_smoothness": 0.9485599166364077, "aesthetic_quality": 0.6457599997520447, "imaging_quality": 0.5577823623345823, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c864af9f.mp4", "clean_score": 1.0, "clean_xclip": 0.20691674947738647, "clean_vbench": {}, "adv_vid_id": "vids/3d3f6814.mp4", "adv_score": 1.0, "adv_xclip": 0.22387759387493134, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1cc186e0.mp4", "clean_score": 1.0, "clean_xclip": 0.23643769323825836, "clean_vbench": {}, "adv_vid_id": "vids/4f5433fe.mp4", "adv_score": 1.0, "adv_xclip": 0.1948631852865219, "adv_vbench": {}}}}
{"id": "c66c068896574a2d99f249c4c4af80f3", "source": "vatex", "video_id": "7nl_MxNbWS4_000004_000014", "video_description": "A loud crowd at a concert is holding and passing a young man and a woman above them as they crowd surf.", "task": "ActionRecognition", "clean_prompt": "A man surfing in a crowd.", "clean_property": {"obj": "man", "action": "surfing crowd", "target": null}, "target_prompt": "A man crowd surfing over a woman.", "target_property": {"obj": "man", "action": "crowd surfing", "target": "woman"}, "evaluation_question": "Is the man **surfing** in a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man surfing in a crowd. RE%=/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/88d26755ee184c6aa44e461dc325eef1.mp4", "clean_score": 1.0, "clean_xclip": 0.1666758805513382, "clean_vbench": {"subject_consistency": 0.8148030725618204, "background_consistency": 0.9120534261067709, "motion_smoothness": 0.9465912082425563, "aesthetic_quality": 0.51307612657547, "imaging_quality": 0.4887611634390695, "dynamic_degree": 1.0}, "adv_vid_id": "vids/977fec5424cc46c7a7addf2a5321c3f7.mp4", "adv_score": 0.0, "adv_xclip": 0.1736171543598175, "adv_vbench": {"subject_consistency": 0.8932619150727987, "background_consistency": 0.963226318359375, "motion_smoothness": 0.9497197638346748, "aesthetic_quality": 0.588904082775116, "imaging_quality": 0.4919357848653988, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f706746.mp4", "clean_score": 0.0, "clean_xclip": 0.1737092137336731, "clean_vbench": {}, "adv_vid_id": "vids/8047cbfa.mp4", "adv_score": 0.0, "adv_xclip": 0.21860173344612122, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/468725ea.mp4", "clean_score": 1.0, "clean_xclip": 0.16667194664478302, "clean_vbench": {}, "adv_vid_id": "vids/e532bb99.mp4", "adv_score": 0.0, "adv_xclip": 0.1793234646320343, "adv_vbench": {}}}}
{"id": "1bbabe1f6d0d47cc88a64b6016edff8b", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer to hit the roof of a car.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "car"}, "target_prompt": "A person using a sledgehammer to hit a tree.", "target_property": {"obj": "person", "action": "using a sledgehammer", "target": "tree"}, "evaluation_question": "Is the person **using a sledgehammer** on a car?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledgehammer to hit the roof of a car. LYAM6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a4a962a9bf894d7fb07a6f4bf1aa7007.mp4", "clean_score": 1.0, "clean_xclip": 0.23430317640304565, "clean_vbench": {"subject_consistency": 0.8810104082028071, "background_consistency": 0.9439697265625, "motion_smoothness": 0.9719515003114156, "aesthetic_quality": 0.3619491457939148, "imaging_quality": 0.551476901307398, "dynamic_degree": 1.0}, "adv_vid_id": "vids/94bef044b98c4a96833d228a5ad86978.mp4", "adv_score": 0.0, "adv_xclip": 0.21236366033554077, "adv_vbench": {"subject_consistency": 0.9081843737512827, "background_consistency": 0.9527486165364584, "motion_smoothness": 0.9490478276862443, "aesthetic_quality": 0.36856475472450256, "imaging_quality": 0.5071281791219906, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9edbe494.mp4", "clean_score": 1.0, "clean_xclip": 0.19910646975040436, "clean_vbench": {}, "adv_vid_id": "vids/0863629c.mp4", "adv_score": 1.0, "adv_xclip": 0.190791055560112, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b38eccac.mp4", "clean_score": 1.0, "clean_xclip": 0.22199955582618713, "clean_vbench": {}, "adv_vid_id": "vids/b5c34637.mp4", "adv_score": 1.0, "adv_xclip": 0.18171676993370056, "adv_vbench": {}}}}
{"id": "a44ae4afc16a4e159082e1d6cc2e0412", "source": "vatex", "video_id": "z-KDduwJNOU_000012_000022", "video_description": "A person, sometimes identified as a child or young woman, is sitting on the floor with their feet in an electric foot massager, laughing uncontrollably as the machine tickles their feet.", "task": "Counting", "clean_prompt": "A child sitting on the floor with three foot massagers, laughing uncontrollably as they enjoy the tickling sensation.", "clean_property": {"obj": "foot massager", "count": "three"}, "target_prompt": "A child sitting on the floor with one foot massager, laughing uncontrollably as they enjoy the tickling sensation.", "target_property": {"obj": "foot massager", "count": "one"}, "evaluation_question": "Are there exactly **three** foot massagers present?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A child sitting on the floor with three foot massagers, laughing uncontrollably as they enjoy the tickling sensation. !0O9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b7b0096cb46d4512a7d198bb68a340d7.mp4", "clean_score": 1.0, "clean_xclip": 0.2448597550392151, "clean_vbench": {"subject_consistency": 0.941870857651035, "background_consistency": 0.943572998046875, "motion_smoothness": 0.9651796285579561, "aesthetic_quality": 0.45257848501205444, "imaging_quality": 0.6529282651628766, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1df6ca851fb1475f9f4d157f4fc00c72.mp4", "adv_score": 0.0, "adv_xclip": 0.24475929141044617, "adv_vbench": {"subject_consistency": 0.9442212823778391, "background_consistency": 0.9586842854817709, "motion_smoothness": 0.9598276235198298, "aesthetic_quality": 0.37262076139450073, "imaging_quality": 0.5541163853236607, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/632e854e.mp4", "clean_score": 0.0, "clean_xclip": 0.2746577560901642, "clean_vbench": {}, "adv_vid_id": "vids/4de5a8b2.mp4", "adv_score": 0.0, "adv_xclip": 0.2637130618095398, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/feb1946a.mp4", "clean_score": 0.0, "clean_xclip": 0.2588241696357727, "clean_vbench": {}, "adv_vid_id": "vids/86a97ae1.mp4", "adv_score": 0.0, "adv_xclip": 0.26559683680534363, "adv_vbench": {}}}}
{"id": "3dcc5393877c4c8e85d582f939dec985", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "Counting", "clean_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper.", "clean_property": {"obj": "paper", "count": "three"}, "target_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on one sheet of paper.", "target_property": {"obj": "paper", "count": "one"}, "evaluation_question": "Are there exactly **three** sheets of paper being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper. =S@JJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dcd8c3e158f4ebea79bb8bb9198db23.mp4", "clean_score": 1.0, "clean_xclip": 0.15169933438301086, "clean_vbench": {"subject_consistency": 0.948447635397315, "background_consistency": 0.9648640950520834, "motion_smoothness": 0.9780856347522291, "aesthetic_quality": 0.24040162563323975, "imaging_quality": 0.690891755551708, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b1adc05f738f4dfaafc407c7f7bcbe09.mp4", "adv_score": 0.0, "adv_xclip": 0.15432944893836975, "adv_vbench": {"subject_consistency": 0.9496445630987486, "background_consistency": 0.9632975260416666, "motion_smoothness": 0.9762240052978496, "aesthetic_quality": 0.22130152583122253, "imaging_quality": 0.6205387014272261, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ea628e43.mp4", "clean_score": 0.0, "clean_xclip": 0.14743629097938538, "clean_vbench": {}, "adv_vid_id": "vids/0e7521ae.mp4", "adv_score": 0.0, "adv_xclip": 0.13793492317199707, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/879bad67.mp4", "clean_score": 1.0, "clean_xclip": 0.15979617834091187, "clean_vbench": {}, "adv_vid_id": "vids/c61811fa.mp4", "adv_score": 1.0, "adv_xclip": 0.18196812272071838, "adv_vbench": {}}}}
{"id": "0b1cfd026ae54718bc7cbcb33f81c2e0", "source": "vatex", "video_id": "Emwoyf1aorI_000027_000037", "video_description": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "clean_property": {"obj": "knitting needles"}, "target_prompt": "A woman demonstrates how to crochet using a crochet hook and yarn, providing a step-by-step guide.", "target_property": {"obj": "crochet hook"}, "evaluation_question": "Is the woman using **knitting needles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide. LY%;P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ecc64511d20f4e81b48256376831fe0f.mp4", "clean_score": 1.0, "clean_xclip": 0.23687471449375153, "clean_vbench": {"subject_consistency": 0.8949091626952091, "background_consistency": 0.9404703776041666, "motion_smoothness": 0.9378027931594448, "aesthetic_quality": 0.42049485445022583, "imaging_quality": 0.5355960581253986, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9d9b1f95a7a846a69db7360ac5359f19.mp4", "adv_score": 0.0, "adv_xclip": 0.25570690631866455, "adv_vbench": {"subject_consistency": 0.8427848101903995, "background_consistency": 0.9202880859375, "motion_smoothness": 0.93790559123598, "aesthetic_quality": 0.3971593677997589, "imaging_quality": 0.5005470844190948, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4666ccb0.mp4", "clean_score": 1.0, "clean_xclip": 0.2548213303089142, "clean_vbench": {}, "adv_vid_id": "vids/14c8035c.mp4", "adv_score": 1.0, "adv_xclip": 0.2530803680419922, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1fd88b2f.mp4", "clean_score": 1.0, "clean_xclip": 0.2625682055950165, "clean_vbench": {}, "adv_vid_id": "vids/13e18258.mp4", "adv_score": 1.0, "adv_xclip": 0.2547667324542999, "adv_vbench": {}}}}
{"id": "a5a5e9477ce347539557be0d0505a4b3", "source": "vatex", "video_id": "lySYZKEBADk_000028_000038", "video_description": "A young boy is helping his grandfather make sausages using a meat grinder while his grandmother tells a story.", "task": "ObjectRecognition", "clean_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "clean_property": {"obj": "woman"}, "target_prompt": "A man telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "target_property": {"obj": "man"}, "evaluation_question": "Is the storyteller in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder.wegenusage gesunde acceler diamant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/acf1ab30505844328ee49dc750bf8fbc.mp4", "clean_score": 1.0, "clean_xclip": 0.19655266404151917, "clean_vbench": {"subject_consistency": 0.9603215934087833, "background_consistency": 0.9397074381510416, "motion_smoothness": 0.9818236874836096, "aesthetic_quality": 0.6048287749290466, "imaging_quality": 0.7108312092995157, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6d17995c74b8456aab56b02ec266bfb8.mp4", "adv_score": 0.0, "adv_xclip": 0.21260447800159454, "adv_vbench": {"subject_consistency": 0.971611882870396, "background_consistency": 0.978363037109375, "motion_smoothness": 0.9742491793817578, "aesthetic_quality": 0.6741778254508972, "imaging_quality": 0.7150203183232522, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f06313c.mp4", "clean_score": 0.0, "clean_xclip": 0.19229502975940704, "clean_vbench": {}, "adv_vid_id": "vids/f2ce7bb4.mp4", "adv_score": 0.0, "adv_xclip": 0.21443462371826172, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/32faff9e.mp4", "clean_score": 1.0, "clean_xclip": 0.23496919870376587, "clean_vbench": {}, "adv_vid_id": "vids/308ffd35.mp4", "adv_score": 1.0, "adv_xclip": 0.23211261630058289, "adv_vbench": {}}}}
{"id": "cf45ecda962a45dc8e601bfc297ed6f6", "source": "vatex", "video_id": "1d4ZOE0y3e4_000275_000285", "video_description": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her.", "task": "Counting", "clean_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while seven fans blow air on her.", "clean_property": {"obj": "fan", "count": "seven"}, "target_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while two fans blow air on her.", "target_property": {"obj": "fan", "count": "two"}, "evaluation_question": "Are there exactly **seven** fans blowing air on her?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while seven fans blow air on her. Schokolade Kleider befinde unkompliziert Kleider", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e1f1e52c03094de88c2e6e366bb04141.mp4", "clean_score": 1.0, "clean_xclip": 0.23341727256774902, "clean_vbench": {"subject_consistency": 0.9499717839062214, "background_consistency": 0.9158477783203125, "motion_smoothness": 0.9742929318718228, "aesthetic_quality": 0.43439310789108276, "imaging_quality": 0.7247666401765784, "dynamic_degree": 1.0}, "adv_vid_id": "vids/113300b1bdeb44d085b39402fd9d9c16.mp4", "adv_score": 0.0, "adv_xclip": 0.22844819724559784, "adv_vbench": {"subject_consistency": 0.9262426942586899, "background_consistency": 0.9140726725260416, "motion_smoothness": 0.9754977482248043, "aesthetic_quality": 0.44345465302467346, "imaging_quality": 0.7274311517209423, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e4d78c7b.mp4", "clean_score": 0.0, "clean_xclip": 0.21700124442577362, "clean_vbench": {}, "adv_vid_id": "vids/2a4643d8.mp4", "adv_score": 0.0, "adv_xclip": 0.20851543545722961, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9d84c66e.mp4", "clean_score": 1.0, "clean_xclip": 0.2371932417154312, "clean_vbench": {}, "adv_vid_id": "vids/d3ceaf58.mp4", "adv_score": 0.0, "adv_xclip": 0.22236865758895874, "adv_vbench": {}}}}
{"id": "6c653c8137834f1fb068f57ea2715398", "source": "vatex", "video_id": "hsxpSVlqmsQ_000002_000012", "video_description": "A person is demonstrating how to cook a cobbler using a Dutch oven on a campfire.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a Dutch oven on a campfire.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "dutch oven"}, "target_prompt": "A person standing to the right of a Dutch oven on a campfire.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "Dutch oven"}, "evaluation_question": "Is the person to the **left** of the Dutch oven?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a Dutch oven on a campfire. FE+VV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4065ad6725e24e79adf107ea9a47efcd.mp4", "clean_score": 1.0, "clean_xclip": 0.2487032413482666, "clean_vbench": {"subject_consistency": 0.9725968819111586, "background_consistency": 0.9839731852213541, "motion_smoothness": 0.9726466931937384, "aesthetic_quality": 0.6896722316741943, "imaging_quality": 0.4706571765821807, "dynamic_degree": 1.0}, "adv_vid_id": "vids/239dac9257474cd9b7584f08c80342f1.mp4", "adv_score": 0.0, "adv_xclip": 0.2444423884153366, "adv_vbench": {"subject_consistency": 0.982305017610391, "background_consistency": 0.9748382568359375, "motion_smoothness": 0.9699431013853587, "aesthetic_quality": 0.6877531409263611, "imaging_quality": 0.6684457560947963, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c06251e2.mp4", "clean_score": 1.0, "clean_xclip": 0.24097390472888947, "clean_vbench": {}, "adv_vid_id": "vids/7942691a.mp4", "adv_score": 0.0, "adv_xclip": 0.2598664462566376, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fccf6536.mp4", "clean_score": 0.0, "clean_xclip": 0.25472697615623474, "clean_vbench": {}, "adv_vid_id": "vids/da5493a2.mp4", "adv_score": 0.0, "adv_xclip": 0.25789278745651245, "adv_vbench": {}}}}
{"id": "dd0923278ab34e638d420d63d22638f4", "source": "vatex", "video_id": "gg5NgF4VUBs_000000_000010", "video_description": "A man is demonstrating how to apply moisturizer to his face and hands, using a bottle of moisturizer.", "task": "ActionRecognition", "clean_prompt": "A person applying moisturizer to his face and hands.", "clean_property": {"obj": "person", "action": "applying cream", "target": "moisturizer"}, "target_prompt": "A person applying sunscreen to his face and hands.", "target_property": {"obj": "person", "action": "applying cream", "target": "sunscreen"}, "evaluation_question": "Is the person **applying moisturizer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person applying moisturizer to his face and hands. F|F);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/69f80f21649b4f258d55b62dcce3cf35.mp4", "clean_score": 1.0, "clean_xclip": 0.24905404448509216, "clean_vbench": {"subject_consistency": 0.8969423373540243, "background_consistency": 0.9109395345052084, "motion_smoothness": 0.970352606751291, "aesthetic_quality": 0.4459258019924164, "imaging_quality": 0.6503202936600665, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d9e9f25ccd4c44729d152e9b736684f0.mp4", "adv_score": 0.0, "adv_xclip": 0.2485678493976593, "adv_vbench": {"subject_consistency": 0.9137176169703404, "background_consistency": 0.9557139078776041, "motion_smoothness": 0.9765527190878923, "aesthetic_quality": 0.5043584704399109, "imaging_quality": 0.46515124262595664, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8169f880.mp4", "clean_score": 0.0, "clean_xclip": 0.1785411536693573, "clean_vbench": {}, "adv_vid_id": "vids/f835745c.mp4", "adv_score": 0.0, "adv_xclip": 0.1681518703699112, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d68e8885.mp4", "clean_score": 1.0, "clean_xclip": 0.1926511824131012, "clean_vbench": {}, "adv_vid_id": "vids/b23ab5fa.mp4", "adv_score": 0.0, "adv_xclip": 0.18365082144737244, "adv_vbench": {}}}}
{"id": "9f8bcaeba32940df991f72e659eec4e1", "source": "vatex", "video_id": "bj_kAPISHaE_000109_000119", "video_description": "A young girl is getting her ears pierced by a technician in a store setting, while talking with her friend.", "task": "Counting", "clean_prompt": "Two technicians assisting a young girl in a store while she gets her ears pierced.", "clean_property": {"obj": "technician", "count": "two"}, "target_prompt": "A technician assisting a young girl in a store while she gets her ears pierced.", "target_property": {"obj": "technician", "count": "one"}, "evaluation_question": "Are there exactly **two** technicians assisting the girl?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two technicians assisting a young girl in a store while she gets her ears pierced. Aviation Animation Hintergrundempfindlich Hochzeit", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/27b2e85d28714c63aa022d90839446f3.mp4", "clean_score": 1.0, "clean_xclip": 0.17094799876213074, "clean_vbench": {"subject_consistency": 0.980447972814242, "background_consistency": 0.956573486328125, "motion_smoothness": 0.9918625170522171, "aesthetic_quality": 0.6377317905426025, "imaging_quality": 0.7423376667256258, "dynamic_degree": 0.0}, "adv_vid_id": "vids/a3f0478e72ce410fb2fa296871db455f.mp4", "adv_score": 0.0, "adv_xclip": 0.05890196934342384, "adv_vbench": {"subject_consistency": 0.989617774883906, "background_consistency": 0.9803975423177084, "motion_smoothness": 0.995261333420328, "aesthetic_quality": 0.5454233288764954, "imaging_quality": 0.7801969660544882, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e7dafc71.mp4", "clean_score": 1.0, "clean_xclip": 0.2010166049003601, "clean_vbench": {}, "adv_vid_id": "vids/41a693ba.mp4", "adv_score": 1.0, "adv_xclip": 0.1679074466228485, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d63395e2.mp4", "clean_score": 1.0, "clean_xclip": 0.21582357585430145, "clean_vbench": {}, "adv_vid_id": "vids/87295909.mp4", "adv_score": 1.0, "adv_xclip": 0.17719370126724243, "adv_vbench": {}}}}
{"id": "6d9cca3982ac4a8884f02b30783c3b09", "source": "vatex", "video_id": "USn563lPuYU_000071_000081", "video_description": "A man is using a tool to seal glass bottles with caps, occasionally talking to another person.", "task": "ObjectRecognition", "clean_prompt": "A man sealing glass bottles with caps while talking to another person.", "clean_property": {"obj": "bottle"}, "target_prompt": "A man sealing jars with lids while talking to another person.", "target_property": {"obj": "jar"}, "evaluation_question": "Is the man sealing **bottles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man sealing glass bottles with caps while talking to another person. workload premi vocationaloutheastern surprins", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0423b8d0c6084086a06be42021c91aa1.mp4", "clean_score": 1.0, "clean_xclip": 0.19244393706321716, "clean_vbench": {"subject_consistency": 0.9406209693600734, "background_consistency": 0.9414876302083334, "motion_smoothness": 0.9625481685729848, "aesthetic_quality": 0.4315815269947052, "imaging_quality": 0.6078667138547313, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6cf83860067a4bd49ed1fd628cf7eb4b.mp4", "adv_score": 0.0, "adv_xclip": 0.22406817972660065, "adv_vbench": {"subject_consistency": 0.9789466205984354, "background_consistency": 0.9692840576171875, "motion_smoothness": 0.9756765136127753, "aesthetic_quality": 0.5008127689361572, "imaging_quality": 0.6710860809014768, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3de41402.mp4", "clean_score": 0.0, "clean_xclip": 0.17280253767967224, "clean_vbench": {}, "adv_vid_id": "vids/39e6ef88.mp4", "adv_score": 1.0, "adv_xclip": 0.19057485461235046, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9e771904.mp4", "clean_score": 0.0, "clean_xclip": 0.16258586943149567, "clean_vbench": {}, "adv_vid_id": "vids/b033fab9.mp4", "adv_score": 1.0, "adv_xclip": 0.1559692621231079, "adv_vbench": {}}}}
{"id": "f3aa89cce0e14009b39a13df4b0c410e", "source": "vatex", "video_id": "kJbkXbf5H60_000006_000016", "video_description": "A woman is playing a Christmas tune on a saxophone on a busy city street corner. People walk by, and some give her money.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the left of a pedestrian on a busy city street corner.", "clean_property": {"obj_1": "musician", "relation": "left of", "obj_2": "pedestrian"}, "target_prompt": "A musician standing to the right of a pedestrian on a busy city street corner.", "target_property": {"obj_1": "musician", "relation": "right of", "obj_2": "pedestrian"}, "evaluation_question": "Is the musician to the **left** of a pedestrian?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A musician standing to the left of a pedestrian on a busy city street corner. sanitar cheddarerfolg Gemeinde revenu", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a049a53fdc364392b3d03b577fbd9572.mp4", "clean_score": 1.0, "clean_xclip": 0.19485348463058472, "clean_vbench": {"subject_consistency": 0.9537757808963457, "background_consistency": 0.9400075276692709, "motion_smoothness": 0.950626587652808, "aesthetic_quality": 0.5124493837356567, "imaging_quality": 0.5505112278218172, "dynamic_degree": 1.0}, "adv_vid_id": "vids/067c171d003244bcabfc3615d114e8af.mp4", "adv_score": 0.0, "adv_xclip": 0.19678674638271332, "adv_vbench": {"subject_consistency": 0.9650796577334404, "background_consistency": 0.9589589436848959, "motion_smoothness": 0.9789140372841523, "aesthetic_quality": 0.5106072425842285, "imaging_quality": 0.5448366967026068, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0e242099.mp4", "clean_score": 1.0, "clean_xclip": 0.1600545346736908, "clean_vbench": {}, "adv_vid_id": "vids/d53627b7.mp4", "adv_score": 1.0, "adv_xclip": 0.18789228796958923, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a3295abd.mp4", "clean_score": 1.0, "clean_xclip": 0.1749243438243866, "clean_vbench": {}, "adv_vid_id": "vids/f1751c9d.mp4", "adv_score": 1.0, "adv_xclip": 0.20062702894210815, "adv_vbench": {}}}}
{"id": "90026f9a46434c9799f48ba1bb2626b3", "source": "vatex", "video_id": "tk6XdoUmoW0_000060_000070", "video_description": "A man is in an outdoor park demonstrating and explaining exercises using a large purple exercise ball.", "task": "ActionRecognition", "clean_prompt": "A person exercising with an exercise ball in an outdoor park.", "clean_property": {"obj": "person", "action": "exercising with an exercise ball", "target": null}, "target_prompt": "A person playing with a beach ball in an outdoor park.", "target_property": {"obj": "person", "action": "playing with a beach ball", "target": null}, "evaluation_question": "Is the person **exercising with an exercise ball**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person exercising with an exercise ball in an outdoor park. paysage Papier Boulevard fara chantier", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb8fed9fcb5d44b8a1173092ffe7d385.mp4", "clean_score": 1.0, "clean_xclip": 0.2206234484910965, "clean_vbench": {"subject_consistency": 0.9656983402868112, "background_consistency": 0.9634297688802084, "motion_smoothness": 0.975280713375242, "aesthetic_quality": 0.475580096244812, "imaging_quality": 0.6058032351124044, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d5c90a5f73974958a79c2163e8db06b7.mp4", "adv_score": 0.0, "adv_xclip": 0.228018656373024, "adv_vbench": {"subject_consistency": 0.9784197912861904, "background_consistency": 0.9813385009765625, "motion_smoothness": 0.9813450342746409, "aesthetic_quality": 0.48042187094688416, "imaging_quality": 0.7280491264498964, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/eff63eaa.mp4", "clean_score": 1.0, "clean_xclip": 0.27181434631347656, "clean_vbench": {}, "adv_vid_id": "vids/d5f4b991.mp4", "adv_score": 1.0, "adv_xclip": 0.19561006128787994, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8f4ee721.mp4", "clean_score": 1.0, "clean_xclip": 0.24388067424297333, "clean_vbench": {}, "adv_vid_id": "vids/93f44d00.mp4", "adv_score": 1.0, "adv_xclip": 0.2248837649822235, "adv_vbench": {}}}}
{"id": "d577ae1b8b104428a4e1535ebb43d274", "source": "vatex", "video_id": "1M_ehUdQbpE_000000_000010", "video_description": "A young man in a red shirt and headband is spray painting graffiti on a cement wall outdoors while music plays.", "task": "ActionRecognition", "clean_prompt": "A person tagging graffiti on a cement wall outdoors.", "clean_property": {"obj": "person", "action": "tagging graffiti", "target": "wall"}, "target_prompt": "A person cleaning graffiti off a cement wall outdoors.", "target_property": {"obj": "person", "action": "cleaning graffiti", "target": "wall"}, "evaluation_question": "Is the person **tagging** graffiti?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tagging graffiti on a cement wall outdoors. ED%FB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e51cbf20b1c476084555a7368e3dabd.mp4", "clean_score": 1.0, "clean_xclip": 0.20431886613368988, "clean_vbench": {"subject_consistency": 0.9878195337951183, "background_consistency": 0.9855550130208334, "motion_smoothness": 0.996241136787148, "aesthetic_quality": 0.48060670495033264, "imaging_quality": 0.4960939352852957, "dynamic_degree": 0.0}, "adv_vid_id": "vids/df96d06c910c433794da7d3576b2abfa.mp4", "adv_score": 0.0, "adv_xclip": 0.17962434887886047, "adv_vbench": {"subject_consistency": 0.9971431394418081, "background_consistency": 0.9937642415364584, "motion_smoothness": 0.9956970523934883, "aesthetic_quality": 0.4395543932914734, "imaging_quality": 0.41977194416279695, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5b53e8c7.mp4", "clean_score": 1.0, "clean_xclip": 0.16893501579761505, "clean_vbench": {}, "adv_vid_id": "vids/d08479e2.mp4", "adv_score": 1.0, "adv_xclip": 0.1713337004184723, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cff3859c.mp4", "clean_score": 1.0, "clean_xclip": 0.1826796531677246, "clean_vbench": {}, "adv_vid_id": "vids/06d7ce82.mp4", "adv_score": 0.0, "adv_xclip": 0.17511698603630066, "adv_vbench": {}}}}
{"id": "e247b2f87a7c427ab205dab04e2efdb4", "source": "vatex", "video_id": "JYRG1VWedVQ_000038_000048", "video_description": "A boy is in a bathroom demonstrating how to clean a toilet by squirting cleaner into the toilet bowl.", "task": "Counting", "clean_prompt": "Two cleaners demonstrating how to clean a toilet in a bathroom.", "clean_property": {"obj": "cleaner", "count": "two"}, "target_prompt": "One cleaner demonstrating how to clean a toilet in a bathroom.", "target_property": {"obj": "cleaner", "count": "one"}, "evaluation_question": "Are there exactly **two** cleaners demonstrating in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two cleaners demonstrating how to clean a toilet in a bathroom. *;73R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ff94f7f503fb431dac658a5498144fd0.mp4", "clean_score": 1.0, "clean_xclip": 0.26233696937561035, "clean_vbench": {"subject_consistency": 0.9729853980243206, "background_consistency": 0.9544219970703125, "motion_smoothness": 0.9832912447740156, "aesthetic_quality": 0.5315215587615967, "imaging_quality": 0.7128854354546995, "dynamic_degree": 1.0}, "adv_vid_id": "vids/23c948240d7d468795fe7e5a63cc71a3.mp4", "adv_score": 0.0, "adv_xclip": 0.24110598862171173, "adv_vbench": {"subject_consistency": 0.9631691947579384, "background_consistency": 0.9321950276692709, "motion_smoothness": 0.981167412110163, "aesthetic_quality": 0.4826842248439789, "imaging_quality": 0.684761802517638, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/045a9020.mp4", "clean_score": 1.0, "clean_xclip": 0.24079343676567078, "clean_vbench": {}, "adv_vid_id": "vids/ba7ab302.mp4", "adv_score": 1.0, "adv_xclip": 0.2573084831237793, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ef10d578.mp4", "clean_score": 1.0, "clean_xclip": 0.23530766367912292, "clean_vbench": {}, "adv_vid_id": "vids/11ad225d.mp4", "adv_score": 0.0, "adv_xclip": 0.24921205639839172, "adv_vbench": {}}}}
{"id": "06dd16a6ab3a4de0bc680b5307eeaf17", "source": "vatex", "video_id": "W0JLIG8Vo0s_000069_000079", "video_description": "A baby is sitting on a play mat in a playroom, playing with a toy xylophone.", "task": "Counting", "clean_prompt": "A baby is sitting on a play mat in a playroom, playing with two xylophones.", "clean_property": {"obj": "xylophone", "count": "two"}, "target_prompt": "A baby is sitting on a play mat in a playroom, playing with one xylophone.", "target_property": {"obj": "xylophone", "count": "one"}, "evaluation_question": "Are there exactly **two** xylophones in the playroom?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A baby is sitting on a play mat in a playroom, playing with two xylophones. =%FEX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fafa485b5b724596b57debdeeb9a78c2.mp4", "clean_score": 1.0, "clean_xclip": 0.22474314272403717, "clean_vbench": {"subject_consistency": 0.937928693369031, "background_consistency": 0.9511922200520834, "motion_smoothness": 0.9610968959921932, "aesthetic_quality": 0.46515825390815735, "imaging_quality": 0.6820722727872888, "dynamic_degree": 1.0}, "adv_vid_id": "vids/79f1b828120a42fa84aa11c2e477a21d.mp4", "adv_score": 0.0, "adv_xclip": 0.2014089673757553, "adv_vbench": {"subject_consistency": 0.9083258795241514, "background_consistency": 0.9418843587239584, "motion_smoothness": 0.9655722328443981, "aesthetic_quality": 0.44888514280319214, "imaging_quality": 0.6797620983513035, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/20930bd8.mp4", "clean_score": 0.0, "clean_xclip": 0.2189961075782776, "clean_vbench": {}, "adv_vid_id": "vids/3386ad18.mp4", "adv_score": 0.0, "adv_xclip": 0.222319096326828, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e396695b.mp4", "clean_score": 0.0, "clean_xclip": 0.24019798636436462, "clean_vbench": {}, "adv_vid_id": "vids/76a53f06.mp4", "adv_score": 0.0, "adv_xclip": 0.23697933554649353, "adv_vbench": {}}}}
{"id": "f30e1aa8629143618db592f09ab3fb8c", "source": "vatex", "video_id": "ZL73Rek4-ds_000838_000848", "video_description": "A young girl in an orange jacket is using a smartphone, singing and talking to herself while texting.", "task": "Counting", "clean_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting.", "clean_property": {"obj": "girl", "count": "seven"}, "target_prompt": "Four girls in blue jackets are using tablets, dancing and laughing together.", "target_property": {"obj": "girl", "count": "four"}, "evaluation_question": "Are there exactly **seven** girls in orange jackets using smartphones?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting. WWII asteapta ParmiasteptamEigentlich", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01c59663ce9847ce971679bedce54733.mp4", "clean_score": 1.0, "clean_xclip": 0.1822759360074997, "clean_vbench": {"subject_consistency": 0.9745612548043331, "background_consistency": 0.9809672037760416, "motion_smoothness": 0.9683583149888041, "aesthetic_quality": 0.604724109172821, "imaging_quality": 0.7517033884476642, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8ad71bcc5af3431c98d1f5e291b37b17.mp4", "adv_score": 0.0, "adv_xclip": 0.16631707549095154, "adv_vbench": {"subject_consistency": 0.9758814045538505, "background_consistency": 0.9655914306640625, "motion_smoothness": 0.9700334494523117, "aesthetic_quality": 0.5406852960586548, "imaging_quality": 0.7637084789665378, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e3943593.mp4", "clean_score": 0.0, "clean_xclip": 0.20340105891227722, "clean_vbench": {}, "adv_vid_id": "vids/0e1d129f.mp4", "adv_score": 0.0, "adv_xclip": 0.19216269254684448, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7852a10d.mp4", "clean_score": 0.0, "clean_xclip": 0.2068137228488922, "clean_vbench": {}, "adv_vid_id": "vids/f15c65b8.mp4", "adv_score": 0.0, "adv_xclip": 0.20591852068901062, "adv_vbench": {}}}}
{"id": "89a1f9aeae6141a09e9228c4df8187a1", "source": "vatex", "video_id": "tEpRURa-1gQ_000000_000010", "video_description": "A person is washing a golden retriever dog outside in the sunlight, using a bucket of water. The dog is being positioned and pulled towards the bucket during the bath.", "task": "SpatialUnderstanding", "clean_prompt": "A bucket positioned to the left of a golden retriever dog being washed outside in the sunlight.", "clean_property": {"obj_1": "bucket", "relation": "left of", "obj_2": "dog"}, "target_prompt": "A bucket positioned to the right of a golden retriever dog being washed outside in the sunlight.", "target_property": {"obj_1": "bucket", "relation": "right of", "obj_2": "dog"}, "evaluation_question": "Is the bucket to the **left** of the golden retriever dog?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A bucket positioned to the left of a golden retriever dog being washed outside in the sunlight. electrode poudre paysageposons responsable", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a5f526b43f941f5ba70767602b3ed4c.mp4", "clean_score": 1.0, "clean_xclip": 0.2267560362815857, "clean_vbench": {"subject_consistency": 0.9452858219544092, "background_consistency": 0.9639180501302084, "motion_smoothness": 0.9812415998131506, "aesthetic_quality": 0.5946799516677856, "imaging_quality": 0.7158366970140106, "dynamic_degree": 1.0}, "adv_vid_id": "vids/412514047d444df2a6cce473d9039663.mp4", "adv_score": 0.0, "adv_xclip": 0.24512481689453125, "adv_vbench": {"subject_consistency": 0.9581865910440683, "background_consistency": 0.97271728515625, "motion_smoothness": 0.9778238149812394, "aesthetic_quality": 0.5302524566650391, "imaging_quality": 0.7284415466931401, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/28aa164e.mp4", "clean_score": 0.0, "clean_xclip": 0.2095285803079605, "clean_vbench": {}, "adv_vid_id": "vids/abb46170.mp4", "adv_score": 0.0, "adv_xclip": 0.2265239953994751, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4ab67389.mp4", "clean_score": 0.0, "clean_xclip": 0.2417544722557068, "clean_vbench": {}, "adv_vid_id": "vids/74b76ae3.mp4", "adv_score": 0.0, "adv_xclip": 0.2641245126724243, "adv_vbench": {}}}}
{"id": "6adb4dbdf08d4244a884a34ea0497448", "source": "vatex", "video_id": "CJUDL32Q7do_000018_000028", "video_description": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away.", "task": "ObjectRecognition", "clean_prompt": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away.", "clean_property": {"obj": "baby"}, "target_prompt": "A puppy is crawling on a carpet floor towards a toy, while a woman and a man interact with the puppy by moving the toy further away.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the main subject in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away. agricole poivr BarbieApothekesteigt", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bef87d5afc7d45fab8f36b3a95acf8f5.mp4", "clean_score": 1.0, "clean_xclip": 0.19235602021217346, "clean_vbench": {"subject_consistency": 0.9717265119155248, "background_consistency": 0.9598846435546875, "motion_smoothness": 0.9855026437240277, "aesthetic_quality": 0.4247382581233978, "imaging_quality": 0.7016372408185687, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1956fcde5f8943da9b98aaad9c5af1e8.mp4", "adv_score": 0.0, "adv_xclip": 0.18114659190177917, "adv_vbench": {"subject_consistency": 0.9564691682656606, "background_consistency": 0.9727884928385416, "motion_smoothness": 0.9823068836427318, "aesthetic_quality": 0.5171226263046265, "imaging_quality": 0.656002967211665, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ca3017a7.mp4", "clean_score": 1.0, "clean_xclip": 0.19779537618160248, "clean_vbench": {}, "adv_vid_id": "vids/aed70b14.mp4", "adv_score": 1.0, "adv_xclip": 0.22065573930740356, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/311ef680.mp4", "clean_score": 1.0, "clean_xclip": 0.21371689438819885, "clean_vbench": {}, "adv_vid_id": "vids/d46aaa00.mp4", "adv_score": 1.0, "adv_xclip": 0.20006167888641357, "adv_vbench": {}}}}
{"id": "9698ad2be2f3433bb5e98e5c7eec4d31", "source": "vatex", "video_id": "sGxujaBZWEI_000001_000011", "video_description": "A man is performing deadlifts in a busy gym, lifting a barbell with heavy weights up to his thighs and then lowering it back down in multiple repetitions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a barbell in a busy gym.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "barbell"}, "target_prompt": "A person further from the camera than a barbell in a busy gym.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "barbell"}, "evaluation_question": "Is the person **closer to the camera** than the barbell?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person closer to the camera than a barbell in a busy gym. aproape beteiligt Crescent responsabil trece", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ca54408403d4f6086ffe441bae61dc5.mp4", "clean_score": 1.0, "clean_xclip": 0.13754785060882568, "clean_vbench": {"subject_consistency": 0.8195831511790553, "background_consistency": 0.9235687255859375, "motion_smoothness": 0.9785212125166425, "aesthetic_quality": 0.3898203372955322, "imaging_quality": 0.20780486340425453, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a46ddb257f054fb1bfd6e8bcf59809c3.mp4", "adv_score": 0.0, "adv_xclip": 0.11122937500476837, "adv_vbench": {"subject_consistency": 0.883452478175362, "background_consistency": 0.9498036702473959, "motion_smoothness": 0.9837798944905894, "aesthetic_quality": 0.3823659420013428, "imaging_quality": 0.1652676808104223, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3e06327c.mp4", "clean_score": 1.0, "clean_xclip": 0.1534738689661026, "clean_vbench": {}, "adv_vid_id": "vids/f344ca87.mp4", "adv_score": 1.0, "adv_xclip": 0.14143672585487366, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/eff05c3c.mp4", "clean_score": 1.0, "clean_xclip": 0.16299480199813843, "clean_vbench": {}, "adv_vid_id": "vids/3d612867.mp4", "adv_score": 1.0, "adv_xclip": 0.17767852544784546, "adv_vbench": {}}}}
{"id": "54d8a661fefb4fe3a8d6856cbd48e6d9", "source": "vatex", "video_id": "jiu8rEK9yEk_000000_000010", "video_description": "A young girl hands a toy phone to her father, who pretends to talk on it and then hands it back to her.", "task": "SpatialUnderstanding", "clean_prompt": "A child closer to the camera than a toy phone.", "clean_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "toy phone"}, "target_prompt": "A child further from the camera than a toy phone.", "target_property": {"obj_1": "child", "relation": "further from the camera than", "obj_2": "toy phone"}, "evaluation_question": "Is the child **closer to the camera than** the toy phone?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A child closer to the camera than a toy phone. toti Solo spectator puissance...).", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4c84b0cca8644a20ab1d18c14a30c4c6.mp4", "clean_score": 1.0, "clean_xclip": 0.15931132435798645, "clean_vbench": {"subject_consistency": 0.94296961526076, "background_consistency": 0.9475555419921875, "motion_smoothness": 0.9825900642310679, "aesthetic_quality": 0.5076361298561096, "imaging_quality": 0.5174122448356784, "dynamic_degree": 1.0}, "adv_vid_id": "vids/00f822206dfc45d0a675047f30f80501.mp4", "adv_score": 0.0, "adv_xclip": 0.15403613448143005, "adv_vbench": {"subject_consistency": 0.9748400369038185, "background_consistency": 0.9295399983723959, "motion_smoothness": 0.9900410592799362, "aesthetic_quality": 0.467085063457489, "imaging_quality": 0.2410088402884347, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d2ab0945.mp4", "clean_score": 1.0, "clean_xclip": 0.15545430779457092, "clean_vbench": {}, "adv_vid_id": "vids/58350b25.mp4", "adv_score": 1.0, "adv_xclip": 0.1285874992609024, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7661ab5f.mp4", "clean_score": 1.0, "clean_xclip": 0.16845549643039703, "clean_vbench": {}, "adv_vid_id": "vids/2c6cb9c2.mp4", "adv_score": 1.0, "adv_xclip": 0.1794806718826294, "adv_vbench": {}}}}
{"id": "3589f489f64e4805bd90edf751a65757", "source": "vatex", "video_id": "lySYZKEBADk_000028_000038", "video_description": "A young boy is helping his grandfather make sausages using a meat grinder while his grandmother tells a story.", "task": "ObjectRecognition", "clean_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "clean_property": {"obj": "woman"}, "target_prompt": "A man telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "target_property": {"obj": "man"}, "evaluation_question": "Is the storyteller in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder. S)!F=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d3e451cacb349ca81161747800aaad6.mp4", "clean_score": 1.0, "clean_xclip": 0.19655266404151917, "clean_vbench": {"subject_consistency": 0.9603215934087833, "background_consistency": 0.9397074381510416, "motion_smoothness": 0.9818236874836096, "aesthetic_quality": 0.6048287749290466, "imaging_quality": 0.7108312092995157, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7026083a205d4e46bca435c781fab211.mp4", "adv_score": 0.0, "adv_xclip": 0.22928614914417267, "adv_vbench": {"subject_consistency": 0.9632469918578863, "background_consistency": 0.9623819986979166, "motion_smoothness": 0.978210917800119, "aesthetic_quality": 0.7032946944236755, "imaging_quality": 0.7008790681800063, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/02e38211.mp4", "clean_score": 0.0, "clean_xclip": 0.18897558748722076, "clean_vbench": {}, "adv_vid_id": "vids/7f1d1c83.mp4", "adv_score": 1.0, "adv_xclip": 0.1804707795381546, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/451afbf0.mp4", "clean_score": 1.0, "clean_xclip": 0.21450679004192352, "clean_vbench": {}, "adv_vid_id": "vids/8d9fdb45.mp4", "adv_score": 1.0, "adv_xclip": 0.2280506193637848, "adv_vbench": {}}}}
{"id": "3d5d0ab97e4841b8b5f1a47c4f530a8f", "source": "vatex", "video_id": "Q7lQz_-v40g_000043_000053", "video_description": "Two young Asian girls are in a living room, listening to music and dancing. They are pretending to sneeze and cough as part of a game or song.", "task": "ActionRecognition", "clean_prompt": "A girl singing in a living room.", "clean_property": {"obj": "girl", "action": "singing", "target": null}, "target_prompt": "A girl dancing in a living room.", "target_property": {"obj": "girl", "action": "dancing", "target": null}, "evaluation_question": "Is the girl **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl singing in a living room. JYDZB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8475b18e9a3841afb911967b20755d18.mp4", "clean_score": 1.0, "clean_xclip": 0.1372246891260147, "clean_vbench": {"subject_consistency": 0.9152138624340296, "background_consistency": 0.9365641276041666, "motion_smoothness": 0.9650165014083051, "aesthetic_quality": 0.45715299248695374, "imaging_quality": 0.6240074469118703, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8b296c1c765d45c9b05b31144c4dfee4.mp4", "adv_score": 0.0, "adv_xclip": 0.09074665606021881, "adv_vbench": {"subject_consistency": 0.9235145921508471, "background_consistency": 0.9198710123697916, "motion_smoothness": 0.9643610455499072, "aesthetic_quality": 0.45481669902801514, "imaging_quality": 0.538069905650859, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6a22cabc.mp4", "clean_score": 1.0, "clean_xclip": 0.16365084052085876, "clean_vbench": {}, "adv_vid_id": "vids/12737196.mp4", "adv_score": 1.0, "adv_xclip": 0.14724873006343842, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/235f7739.mp4", "clean_score": 1.0, "clean_xclip": 0.16440917551517487, "clean_vbench": {}, "adv_vid_id": "vids/3d88c778.mp4", "adv_score": 1.0, "adv_xclip": 0.1981157660484314, "adv_vbench": {}}}}
{"id": "66969abec9e647b6a5ad1f1c86b12744", "source": "vatex", "video_id": "MFt0MwJGTxU_000000_000010", "video_description": "A young boy is sitting in a room, smoking from a hookah pipe and exhaling smoke.", "task": "Counting", "clean_prompt": "Five people are sitting in a room, one of them is smoking from a hookah pipe and exhaling smoke.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person is sitting in a room, smoking from a hookah pipe and exhaling smoke.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people are sitting in a room, one of them is smoking from a hookah pipe and exhaling smoke. )!0D:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/808c7b1db8ee49628851ccbd25c92995.mp4", "clean_score": 1.0, "clean_xclip": 0.24563553929328918, "clean_vbench": {"subject_consistency": 0.9491502723346154, "background_consistency": 0.953155517578125, "motion_smoothness": 0.9935763458643488, "aesthetic_quality": 0.6254234313964844, "imaging_quality": 0.5882028797694615, "dynamic_degree": 0.0}, "adv_vid_id": "vids/d7743d24b82d478e8f8c8a98b91aee3b.mp4", "adv_score": 0.0, "adv_xclip": 0.21948929131031036, "adv_vbench": {"subject_consistency": 0.9872980024665594, "background_consistency": 0.9477488199869791, "motion_smoothness": 0.9946647463222685, "aesthetic_quality": 0.590778648853302, "imaging_quality": 0.685271129997409, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3846b974.mp4", "clean_score": 0.0, "clean_xclip": 0.21384291350841522, "clean_vbench": {}, "adv_vid_id": "vids/60df6957.mp4", "adv_score": 0.0, "adv_xclip": 0.2099130004644394, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6dede7a4.mp4", "clean_score": 0.0, "clean_xclip": 0.2262350618839264, "clean_vbench": {}, "adv_vid_id": "vids/e8738cb4.mp4", "adv_score": 0.0, "adv_xclip": 0.23390838503837585, "adv_vbench": {}}}}
{"id": "ad120d14d90f431bb3391bdd4ee3afb1", "source": "vatex", "video_id": "s-bHUbr-4p8_000001_000011", "video_description": "A female athlete is participating in an indoor track event, performing long jump and triple jump maneuvers while onlookers watch.", "task": "Counting", "clean_prompt": "A female athlete is performing long jump and triple jump maneuvers while six onlookers watch.", "clean_property": {"obj": "onlookers", "count": "six"}, "target_prompt": "A female athlete is performing long jump and triple jump maneuvers while two onlookers watch.", "target_property": {"obj": "onlookers", "count": "two"}, "evaluation_question": "Are there exactly **six** onlookers watching the athlete?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female athlete is performing long jump and triple jump maneuvers while six onlookers watch. BERMC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6e3124a000a142b4ae31c7334611db3a.mp4", "clean_score": 1.0, "clean_xclip": 0.1432061791419983, "clean_vbench": {"subject_consistency": 0.9656562774131695, "background_consistency": 0.9125518798828125, "motion_smoothness": 0.9612913708532538, "aesthetic_quality": 0.38498106598854065, "imaging_quality": 0.5368783810673928, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f554f5822648441ab9efc83413dd7eed.mp4", "adv_score": 0.0, "adv_xclip": 0.15905696153640747, "adv_vbench": {"subject_consistency": 0.9264467669030031, "background_consistency": 0.930908203125, "motion_smoothness": 0.9619086440871359, "aesthetic_quality": 0.5740581154823303, "imaging_quality": 0.5278351413960359, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/935bda43.mp4", "clean_score": 0.0, "clean_xclip": 0.12950560450553894, "clean_vbench": {}, "adv_vid_id": "vids/3189d0a9.mp4", "adv_score": 0.0, "adv_xclip": 0.18794186413288116, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dde7dc3f.mp4", "clean_score": 0.0, "clean_xclip": 0.1403813362121582, "clean_vbench": {}, "adv_vid_id": "vids/4e983a58.mp4", "adv_score": 0.0, "adv_xclip": 0.10412591695785522, "adv_vbench": {}}}}
{"id": "b589927cb9e14d0a8a1207060802e9e6", "source": "vatex", "video_id": "_bciTU-EiDk_000024_000034", "video_description": "A woman demonstrates and explains how a special latch works on an appliance door, specifically a refrigerator, including how to open and secure it.", "task": "SpatialUnderstanding", "clean_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door.", "clean_property": {"obj_1": "refrigerator", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A refrigerator further from the camera than a person demonstrating how to use a special latch on the refrigerator door.", "target_property": {"obj_1": "refrigerator", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the refrigerator **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door. !)))*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9983a29282d44c87a42e350779337cbc.mp4", "clean_score": 1.0, "clean_xclip": 0.16773506999015808, "clean_vbench": {"subject_consistency": 0.9363345137486855, "background_consistency": 0.9451904296875, "motion_smoothness": 0.9816977162006778, "aesthetic_quality": 0.4128057360649109, "imaging_quality": 0.5911054681271923, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3ddd5332ce0e46e4b2233b67f746512b.mp4", "adv_score": 0.0, "adv_xclip": 0.17956773936748505, "adv_vbench": {"subject_consistency": 0.9195684262861809, "background_consistency": 0.9569956461588541, "motion_smoothness": 0.9809329523218752, "aesthetic_quality": 0.40103408694267273, "imaging_quality": 0.4777273598495795, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/adfad712.mp4", "clean_score": 0.0, "clean_xclip": 0.257992148399353, "clean_vbench": {}, "adv_vid_id": "vids/e9d4c42c.mp4", "adv_score": 0.0, "adv_xclip": 0.1931765377521515, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/64984356.mp4", "clean_score": 1.0, "clean_xclip": 0.232957661151886, "clean_vbench": {}, "adv_vid_id": "vids/094ee48d.mp4", "adv_score": 1.0, "adv_xclip": 0.15776410698890686, "adv_vbench": {}}}}
{"id": "b7c7e39f3d38431890387064c36352a3", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "ActionRecognition", "clean_prompt": "A person stretching their leg on a yoga mat in a room.", "clean_property": {"obj": "person", "action": "stretching leg", "target": null}, "target_prompt": "A person jumping on a yoga mat in a room.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **stretching their leg**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person stretching their leg on a yoga mat in a room. Herbst dazu Meinung Raumorii", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f1edf345fffe428fb2fee952bbfa32a1.mp4", "clean_score": 1.0, "clean_xclip": 0.20279279351234436, "clean_vbench": {"subject_consistency": 0.9817521696289381, "background_consistency": 0.9650726318359375, "motion_smoothness": 0.9923716852192266, "aesthetic_quality": 0.48179197311401367, "imaging_quality": 0.7158131953648159, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e20565d5a7664dc19d162461505e4d28.mp4", "adv_score": 0.0, "adv_xclip": 0.21590101718902588, "adv_vbench": {"subject_consistency": 0.9885035150994858, "background_consistency": 0.98895263671875, "motion_smoothness": 0.9959293207670156, "aesthetic_quality": 0.45329979062080383, "imaging_quality": 0.7306639161401866, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8640b3e9.mp4", "clean_score": 1.0, "clean_xclip": 0.19522741436958313, "clean_vbench": {}, "adv_vid_id": "vids/894749d6.mp4", "adv_score": 1.0, "adv_xclip": 0.20868292450904846, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6ac9c7de.mp4", "clean_score": 1.0, "clean_xclip": 0.2115066647529602, "clean_vbench": {}, "adv_vid_id": "vids/f6116854.mp4", "adv_score": 1.0, "adv_xclip": 0.21572425961494446, "adv_vbench": {}}}}
{"id": "b6c9400c5b3446cdb280b7af1855304e", "source": "vatex", "video_id": "BHsuHq_75Nw_000100_000110", "video_description": "A person is cooking a whole chicken on a rotisserie over an open fire in the woods during the day. The person uses a knife with a leather sheath to carve the chicken.", "task": "AttributeRecognition", "clean_prompt": "A person carving a whole chicken with a knife with a leather sheath over an open fire in the woods during the day.", "clean_property": {"obj": "knife", "attribute": "with leather sheath"}, "target_prompt": "A person carving a whole chicken with a knife with a plastic handle over an open fire in the woods during the day.", "target_property": {"obj": "knife", "attribute": "with plastic handle"}, "evaluation_question": "Is the knife being used **with a leather sheath**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person carving a whole chicken with a knife with a leather sheath over an open fire in the woods during the day. -TVIO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/91690617c8db4888944f97e46bc0d436.mp4", "clean_score": 1.0, "clean_xclip": 0.3013279438018799, "clean_vbench": {"subject_consistency": 0.9581616949290037, "background_consistency": 0.9721781412760416, "motion_smoothness": 0.9564265218079258, "aesthetic_quality": 0.6612676382064819, "imaging_quality": 0.660484289052535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/64b5903fe6f54d2fb4950c5fa14b0c74.mp4", "adv_score": 0.0, "adv_xclip": 0.2500276565551758, "adv_vbench": {"subject_consistency": 0.956325663253665, "background_consistency": 0.9687652587890625, "motion_smoothness": 0.9477514653559469, "aesthetic_quality": 0.6368492245674133, "imaging_quality": 0.6871927891945353, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d140d06f.mp4", "clean_score": 0.0, "clean_xclip": 0.2519802451133728, "clean_vbench": {}, "adv_vid_id": "vids/b7d02dd3.mp4", "adv_score": 0.0, "adv_xclip": 0.23381903767585754, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/90faef1b.mp4", "clean_score": 0.0, "clean_xclip": 0.2780287265777588, "clean_vbench": {}, "adv_vid_id": "vids/7caf61f8.mp4", "adv_score": 0.0, "adv_xclip": 0.27571773529052734, "adv_vbench": {}}}}
{"id": "3d496a059c0e42a28a945434972d460e", "source": "vatex", "video_id": "th9TRkTPLE0_000072_000082", "video_description": "A man wearing glasses is using a circular saw to cut through a metal railing outdoors.", "task": "AttributeRecognition", "clean_prompt": "A man wearing glasses is using an electric circular saw to cut through a metal railing outdoors.", "clean_property": {"obj": "circular saw", "attribute": "electric"}, "target_prompt": "A man wearing glasses is using a manual circular saw to cut through a metal railing outdoors.", "target_property": {"obj": "circular saw", "attribute": "manual"}, "evaluation_question": "Is the circular saw **electric**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man wearing glasses is using an electric circular saw to cut through a metal railing outdoors. Vergangenheitografic hochwertige visuel verde", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6e24317276b4fc69704a1cdaf90f46d.mp4", "clean_score": 1.0, "clean_xclip": 0.1569419652223587, "clean_vbench": {"subject_consistency": 0.9667478619764248, "background_consistency": 0.9515635172526041, "motion_smoothness": 0.9862409382123477, "aesthetic_quality": 0.4178892970085144, "imaging_quality": 0.7275330243791852, "dynamic_degree": 0.0}, "adv_vid_id": "vids/cf92d8f3302244bf95696e26baaf2758.mp4", "adv_score": 0.0, "adv_xclip": 0.2732942998409271, "adv_vbench": {"subject_consistency": 0.9564557826767365, "background_consistency": 0.9221598307291666, "motion_smoothness": 0.982946020750121, "aesthetic_quality": 0.37536078691482544, "imaging_quality": 0.5842018438845265, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a5da072c.mp4", "clean_score": 0.0, "clean_xclip": 0.19333860278129578, "clean_vbench": {}, "adv_vid_id": "vids/5e2013a2.mp4", "adv_score": 1.0, "adv_xclip": 0.2206013798713684, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/900fecd5.mp4", "clean_score": 1.0, "clean_xclip": 0.17744439840316772, "clean_vbench": {}, "adv_vid_id": "vids/9c03eabb.mp4", "adv_score": 1.0, "adv_xclip": 0.242974191904068, "adv_vbench": {}}}}
{"id": "c8a723dabdc348f68564f4f7432e485e", "source": "vatex", "video_id": "ofnDF6Ci03M_000041_000051", "video_description": "Two women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth.", "task": "Counting", "clean_prompt": "Three women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth.", "clean_property": {"obj": "woman_2", "count": "three"}, "target_prompt": "One woman is interacting playfully outdoors. She is sitting on a sofa with her eyes closed.", "target_property": {"obj": "woman_2", "count": "one"}, "evaluation_question": "Are there exactly **three** women interacting outdoors?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth. SL+!P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd9ab31463ee4c3f9a80fc52ee3d2f8d.mp4", "clean_score": 1.0, "clean_xclip": 0.22499752044677734, "clean_vbench": {"subject_consistency": 0.9723175596445799, "background_consistency": 0.9566446940104166, "motion_smoothness": 0.9698256042032297, "aesthetic_quality": 0.5230655670166016, "imaging_quality": 0.7576803697858538, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dcb8579ce5b24790ab7578c4ee584855.mp4", "adv_score": 0.0, "adv_xclip": 0.2291225641965866, "adv_vbench": {"subject_consistency": 0.959473034987847, "background_consistency": 0.9329630533854166, "motion_smoothness": 0.9848574321189381, "aesthetic_quality": 0.49395954608917236, "imaging_quality": 0.5746370479038784, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/caffa296.mp4", "clean_score": 1.0, "clean_xclip": 0.14745262265205383, "clean_vbench": {}, "adv_vid_id": "vids/4ef0c572.mp4", "adv_score": 1.0, "adv_xclip": 0.15248993039131165, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/be5abbed.mp4", "clean_score": 1.0, "clean_xclip": 0.1695813536643982, "clean_vbench": {}, "adv_vid_id": "vids/56877711.mp4", "adv_score": 1.0, "adv_xclip": 0.21727237105369568, "adv_vbench": {}}}}
{"id": "6854263606234eeab2c2c5af14c7fa83", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "Counting", "clean_prompt": "Four people are watching a man standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are watching a man standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly. -?)!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a9497e3e1b5146bba97cd954f2caa123.mp4", "clean_score": 1.0, "clean_xclip": 0.2097027450799942, "clean_vbench": {"subject_consistency": 0.92832608645161, "background_consistency": 0.9253285725911459, "motion_smoothness": 0.9727724755154119, "aesthetic_quality": 0.47429925203323364, "imaging_quality": 0.4422004100254604, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0603580efa5541e9979706b716d1dacb.mp4", "adv_score": 0.0, "adv_xclip": 0.2053530365228653, "adv_vbench": {"subject_consistency": 0.9485837196310362, "background_consistency": 0.9463450113932291, "motion_smoothness": 0.9769619235972423, "aesthetic_quality": 0.4613226652145386, "imaging_quality": 0.5700272953267, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/22165b90.mp4", "clean_score": 0.0, "clean_xclip": 0.20678861439228058, "clean_vbench": {}, "adv_vid_id": "vids/6b10248a.mp4", "adv_score": 1.0, "adv_xclip": 0.20882681012153625, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4e2ddb5f.mp4", "clean_score": 1.0, "clean_xclip": 0.2367759644985199, "clean_vbench": {}, "adv_vid_id": "vids/bb950603.mp4", "adv_score": 1.0, "adv_xclip": 0.21337024867534637, "adv_vbench": {}}}}
{"id": "2e18ee8b3bec4b64887502ee635436d8", "source": "vatex", "video_id": "9TjkUylMBgQ_000134_000144", "video_description": "A woman is training a small dog outdoors by throwing treats and rewarding it for good behavior.", "task": "Counting", "clean_prompt": "A woman is training a small dog outdoors by throwing three treats and rewarding it for good behavior.", "clean_property": {"obj": "treat", "count": "three"}, "target_prompt": "A woman is training a small dog outdoors by throwing one treat and rewarding it for good behavior.", "target_property": {"obj": "treat", "count": "one"}, "evaluation_question": "Are there exactly **three** treats being thrown?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman is training a small dog outdoors by throwing three treats and rewarding it for good behavior. Hunde FensterTeatrul Auftrag bancar", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d19d011ed4f49e6ac61865414488345.mp4", "clean_score": 1.0, "clean_xclip": 0.1822177767753601, "clean_vbench": {"subject_consistency": 0.9186237510293722, "background_consistency": 0.9293467203776041, "motion_smoothness": 0.9766727451043432, "aesthetic_quality": 0.4962378442287445, "imaging_quality": 0.6390119023225745, "dynamic_degree": 1.0}, "adv_vid_id": "vids/518d20b2bb24441198323aba1286af4b.mp4", "adv_score": 0.0, "adv_xclip": 0.20626208186149597, "adv_vbench": {"subject_consistency": 0.8986912909895182, "background_consistency": 0.939239501953125, "motion_smoothness": 0.9761517291137134, "aesthetic_quality": 0.44867756962776184, "imaging_quality": 0.5268888380089585, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f665269d.mp4", "clean_score": 0.0, "clean_xclip": 0.21338170766830444, "clean_vbench": {}, "adv_vid_id": "vids/234ff779.mp4", "adv_score": 0.0, "adv_xclip": 0.16539546847343445, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4259e55d.mp4", "clean_score": 0.0, "clean_xclip": 0.193716898560524, "clean_vbench": {}, "adv_vid_id": "vids/f65d4fdd.mp4", "adv_score": 0.0, "adv_xclip": 0.15026706457138062, "adv_vbench": {}}}}
{"id": "23ef4971efc940d8bc23bfb5820300e7", "source": "vatex", "video_id": "AbL-AXmlmmM_000008_000018", "video_description": "A young boy is driving and steering a riding lawnmower with an older man sitting behind him, guiding and teaching him in a grassy field.", "task": "Counting", "clean_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field, with four boys playing nearby.", "clean_property": {"obj": "boy", "count": "four"}, "target_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **four** boys playing nearby?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field, with four boys playing nearby. =8TZF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0ead0989d2ed493ba617534d616d520a.mp4", "clean_score": 1.0, "clean_xclip": 0.22849175333976746, "clean_vbench": {"subject_consistency": 0.9398459096749624, "background_consistency": 0.9287261962890625, "motion_smoothness": 0.9802676052320362, "aesthetic_quality": 0.682537317276001, "imaging_quality": 0.7462927479646644, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3fcbd509c14e4a1d883b9f466ea6d89b.mp4", "adv_score": 0.0, "adv_xclip": 0.2218778431415558, "adv_vbench": {"subject_consistency": 0.9371791568895181, "background_consistency": 0.8908284505208334, "motion_smoothness": 0.9850714481587388, "aesthetic_quality": 0.5840659141540527, "imaging_quality": 0.697906041048011, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e1a1190c.mp4", "clean_score": 0.0, "clean_xclip": 0.28131651878356934, "clean_vbench": {}, "adv_vid_id": "vids/b42b6fd1.mp4", "adv_score": 0.0, "adv_xclip": 0.2604636251926422, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5a80b715.mp4", "clean_score": 1.0, "clean_xclip": 0.23704305291175842, "clean_vbench": {}, "adv_vid_id": "vids/c7bce42e.mp4", "adv_score": 0.0, "adv_xclip": 0.23844601213932037, "adv_vbench": {}}}}
{"id": "8e903c7d9fb9457bb7c5f21ccfe63151", "source": "vatex", "video_id": "aC_3rmjvSxk_000042_000052", "video_description": "A man is fishing with his hands by a lake while another man films the activity. A young boy is also present, sitting at the edge of the lake.", "task": "Counting", "clean_prompt": "Three men fishing by a lake, with one filming the activity.", "clean_property": {"obj": "man", "count": "three"}, "target_prompt": "One man fishing by a lake.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **three** men fishing by the lake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three men fishing by a lake, with one filming the activity. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e60638f2a3354f609b6723cb326dfd5b.mp4", "clean_score": 1.0, "clean_xclip": 0.24587911367416382, "clean_vbench": {"subject_consistency": 0.9072804376482964, "background_consistency": 0.9373728434244791, "motion_smoothness": 0.9711996824063988, "aesthetic_quality": 0.47586533427238464, "imaging_quality": 0.7421381985411353, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f12ceb462012463899a3815bce9a087a.mp4", "adv_score": 0.0, "adv_xclip": 0.24443486332893372, "adv_vbench": {"subject_consistency": 0.9681582146634659, "background_consistency": 0.9438273111979166, "motion_smoothness": 0.9842524905377532, "aesthetic_quality": 0.44873127341270447, "imaging_quality": 0.7260635702950614, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5fb5f7ce.mp4", "clean_score": 1.0, "clean_xclip": 0.24431253969669342, "clean_vbench": {}, "adv_vid_id": "vids/5eaa449b.mp4", "adv_score": 0.0, "adv_xclip": 0.240861177444458, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f0ba4a1a.mp4", "clean_score": 1.0, "clean_xclip": 0.23611029982566833, "clean_vbench": {}, "adv_vid_id": "vids/d9a1e1cc.mp4", "adv_score": 0.0, "adv_xclip": 0.2486419677734375, "adv_vbench": {}}}}
{"id": "ed5c6bfc8d24422486dac34ef19c2435", "source": "vatex", "video_id": "4UDnIHZjJeI_000323_000333", "video_description": "A man is shaving a woman's head bald using a razor and shaving cream. The woman is happy and looks into the camera while the man, wearing a Planet Hollywood shirt, talks about the process.", "task": "ActionRecognition", "clean_prompt": "A man shaving a woman's head bald using a razor and shaving cream.", "clean_property": {"obj": "man", "action": "shaving head", "target": "woman"}, "target_prompt": "A man shaving another man's head bald using a razor and shaving cream.", "target_property": {"obj": "man", "action": "shaving head", "target": "man"}, "evaluation_question": "Is the man **shaving a woman's head**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man shaving a woman's head bald using a razor and shaving cream. >TZFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a84d7ff3730b4867bbcc4016197d1076.mp4", "clean_score": 1.0, "clean_xclip": 0.24292221665382385, "clean_vbench": {"subject_consistency": 0.9181712282200655, "background_consistency": 0.9526926676432291, "motion_smoothness": 0.9738510452599249, "aesthetic_quality": 0.47354862093925476, "imaging_quality": 0.6811002357638613, "dynamic_degree": 1.0}, "adv_vid_id": "vids/de7a5b22d49c4b9ea7c9c1eca0947f89.mp4", "adv_score": 0.0, "adv_xclip": 0.21114900708198547, "adv_vbench": {"subject_consistency": 0.9054051600396633, "background_consistency": 0.9597625732421875, "motion_smoothness": 0.9664720093059086, "aesthetic_quality": 0.43227237462997437, "imaging_quality": 0.696041198263363, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2e7d8fb9.mp4", "clean_score": 0.0, "clean_xclip": 0.12206985056400299, "clean_vbench": {}, "adv_vid_id": "vids/e471634a.mp4", "adv_score": 0.0, "adv_xclip": 0.1124672144651413, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e2814924.mp4", "clean_score": 0.0, "clean_xclip": 0.20858123898506165, "clean_vbench": {}, "adv_vid_id": "vids/fb940e49.mp4", "adv_score": 0.0, "adv_xclip": 0.21191264688968658, "adv_vbench": {}}}}
{"id": "2e3939d9228445c9b1541a6a93c8d35a", "source": "vatex", "video_id": "0DUtghm2U34_000106_000116", "video_description": "A large man in a red shirt is eating powdered donuts messily, with powdered sugar around his mouth, and sucking the powder off his thumb while holding a box.", "task": "AttributeRecognition", "clean_prompt": "A person with a large build in a red shirt eating powdered donuts messily.", "clean_property": {"obj": "person", "attribute": "large"}, "target_prompt": "A person with a small build eating powdered donuts messily.", "target_property": {"obj": "person", "attribute": "small"}, "evaluation_question": "Is the person described as **large**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with a large build in a red shirt eating powdered donuts messily. YKDZV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac564a3aa2a247e690f7afbff2f5d851.mp4", "clean_score": 1.0, "clean_xclip": 0.21916134655475616, "clean_vbench": {"subject_consistency": 0.9095431330303351, "background_consistency": 0.9228464762369791, "motion_smoothness": 0.9848814101836723, "aesthetic_quality": 0.470226526260376, "imaging_quality": 0.6227723187816386, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f5d00365d8d8419da1f87593747122fc.mp4", "adv_score": 0.0, "adv_xclip": 0.20124000310897827, "adv_vbench": {"subject_consistency": 0.937045489748319, "background_consistency": 0.936859130859375, "motion_smoothness": 0.9914205508528, "aesthetic_quality": 0.41084662079811096, "imaging_quality": 0.7076973303970026, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/af96229b.mp4", "clean_score": 1.0, "clean_xclip": 0.22213977575302124, "clean_vbench": {}, "adv_vid_id": "vids/726ec06b.mp4", "adv_score": 1.0, "adv_xclip": 0.2126169204711914, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/16fedcc6.mp4", "clean_score": 1.0, "clean_xclip": 0.22904443740844727, "clean_vbench": {}, "adv_vid_id": "vids/0b585eb0.mp4", "adv_score": 1.0, "adv_xclip": 0.22110997140407562, "adv_vbench": {}}}}
{"id": "a07d16373d6a4961a0e1b91025bbbf6a", "source": "vatex", "video_id": "JSd8C0Ms-G0_000050_000060", "video_description": "A teenage girl with red hair is sitting in her bedroom, rubbing lotion on her hands while talking to the camera.", "task": "AttributeRecognition", "clean_prompt": "A teenage girl with red hair sitting in her bedroom, rubbing lotion on her hands while talking to the camera.", "clean_property": {"obj": "girl", "attribute": "teenage"}, "target_prompt": "A child with red hair sitting in a colorful playroom, playing with toys while talking to the camera.", "target_property": {"obj": "girl", "attribute": "child"}, "evaluation_question": "Is the girl a **teenager**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A teenage girl with red hair sitting in her bedroom, rubbing lotion on her hands while talking to the camera. Landwirtschaft Russie resurse trez watercolor", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc45d6ed0fd4471cac2dea5064e0e193.mp4", "clean_score": 1.0, "clean_xclip": 0.23444169759750366, "clean_vbench": {"subject_consistency": 0.9625101170192162, "background_consistency": 0.9617818196614584, "motion_smoothness": 0.9724046276754014, "aesthetic_quality": 0.36404654383659363, "imaging_quality": 0.6440122915773975, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4d06969ff8564a9d96d4d2650039928a.mp4", "adv_score": 0.0, "adv_xclip": 0.22179526090621948, "adv_vbench": {"subject_consistency": 0.9675852693617344, "background_consistency": 0.9548085530598959, "motion_smoothness": 0.9853675110508452, "aesthetic_quality": 0.5004590749740601, "imaging_quality": 0.6913469337930485, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/de610562.mp4", "clean_score": 1.0, "clean_xclip": 0.16803686320781708, "clean_vbench": {}, "adv_vid_id": "vids/446b59b8.mp4", "adv_score": 0.0, "adv_xclip": 0.11031948029994965, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/678ed88b.mp4", "clean_score": 1.0, "clean_xclip": 0.2644391655921936, "clean_vbench": {}, "adv_vid_id": "vids/89cc9218.mp4", "adv_score": 0.0, "adv_xclip": 0.2215653657913208, "adv_vbench": {}}}}
{"id": "cdbfa7b3425c4447acf156b051e443db", "source": "vatex", "video_id": "yVRvu8xCixY_000248_000258", "video_description": "A man is sitting at a desk by a window, typing on a computer keyboard while smoking a pipe.", "task": "Counting", "clean_prompt": "Two people sitting at a desk by a window, one typing on a computer keyboard while the other reads a book.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person sitting at a desk by a window, typing on a computer keyboard while smoking a pipe.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people at the desk?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two people sitting at a desk by a window, one typing on a computer keyboard while the other reads a book. Himmel erwachsene flashlighttischen entstehen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc300b7b3ecd4c5aa7af0843f6cfd07d.mp4", "clean_score": 1.0, "clean_xclip": 0.21867910027503967, "clean_vbench": {"subject_consistency": 0.9889180163542429, "background_consistency": 0.993133544921875, "motion_smoothness": 0.9926345993580046, "aesthetic_quality": 0.5021291971206665, "imaging_quality": 0.5756000565509407, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ddf82aabad0747efab7c527ff7ce68a9.mp4", "adv_score": 0.0, "adv_xclip": 0.07576429843902588, "adv_vbench": {"subject_consistency": 0.8481513789544503, "background_consistency": 0.9396921793619791, "motion_smoothness": 0.9969114852827705, "aesthetic_quality": 0.34041035175323486, "imaging_quality": 0.1379006019903689, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3e5d82dc.mp4", "clean_score": 1.0, "clean_xclip": 0.19426599144935608, "clean_vbench": {}, "adv_vid_id": "vids/7b2c9922.mp4", "adv_score": 1.0, "adv_xclip": 0.2126094102859497, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a8ec7e8d.mp4", "clean_score": 1.0, "clean_xclip": 0.22316306829452515, "clean_vbench": {}, "adv_vid_id": "vids/90d2eba0.mp4", "adv_score": 1.0, "adv_xclip": 0.2387758195400238, "adv_vbench": {}}}}
{"id": "dd0281ecd68e416bac275328f19e96ed", "source": "vatex", "video_id": "Y5mgnkJRecs_000034_000044", "video_description": "Two men in formal Scottish dress are standing on a beach. One man is playing the bagpipes while the other stands beside him.", "task": "Counting", "clean_prompt": "Six men in formal Scottish dress are standing on a beach. One man is playing the bagpipes while the others stand beside him.", "clean_property": {"obj": "man", "count": "six"}, "target_prompt": "Three men in casual beachwear are playing frisbee on the sand.", "target_property": {"obj": "man", "count": "three"}, "evaluation_question": "Are there exactly **six** men in formal Scottish dress on the beach?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Six men in formal Scottish dress are standing on a beach. One man is playing the bagpipes while the others stand beside him. >8BCX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a9965ba72af54b0dbc2cf269f5a3f02b.mp4", "clean_score": 1.0, "clean_xclip": 0.26555517315864563, "clean_vbench": {"subject_consistency": 0.9786970944454273, "background_consistency": 0.9633229573567709, "motion_smoothness": 0.9842707791192609, "aesthetic_quality": 0.6943218111991882, "imaging_quality": 0.6707343338946907, "dynamic_degree": 0.0}, "adv_vid_id": "vids/4ea597bb408940f594a7c8d45aacb23e.mp4", "adv_score": 0.0, "adv_xclip": 0.2655526101589203, "adv_vbench": {"subject_consistency": 0.9800637805213531, "background_consistency": 0.9658203125, "motion_smoothness": 0.9836468002034919, "aesthetic_quality": 0.6953691840171814, "imaging_quality": 0.7175801678093113, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a04e0050.mp4", "clean_score": 1.0, "clean_xclip": 0.2746378481388092, "clean_vbench": {}, "adv_vid_id": "vids/85bc7252.mp4", "adv_score": 1.0, "adv_xclip": 0.2930258512496948, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/62ac492f.mp4", "clean_score": 0.0, "clean_xclip": 0.28208088874816895, "clean_vbench": {}, "adv_vid_id": "vids/41cabf74.mp4", "adv_score": 0.0, "adv_xclip": 0.27884361147880554, "adv_vbench": {}}}}
{"id": "02df2de92eed4c8e9f52a1b049d3c99f", "source": "vatex", "video_id": "L9DHrUYTKWU_000000_000010", "video_description": "A woman is using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "task": "ActionRecognition", "clean_prompt": "A woman blowdrying a girl's hair on the front porch of a house.", "clean_property": {"obj": "woman", "action": "blowdrying hair", "target": "girl"}, "target_prompt": "A woman curling a girl's hair on the front porch of a house.", "target_property": {"obj": "woman", "action": "curling hair", "target": "girl"}, "evaluation_question": "Is the woman **blowdrying** the girl's hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman blowdrying a girl's hair on the front porch of a house. G&LF/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7e9cba0d104b4e7bbeead74bf36a7787.mp4", "clean_score": 1.0, "clean_xclip": 0.18942677974700928, "clean_vbench": {"subject_consistency": 0.9293429870158434, "background_consistency": 0.929962158203125, "motion_smoothness": 0.9871377579581215, "aesthetic_quality": 0.37596815824508667, "imaging_quality": 0.6873364086540379, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b1bff0ea8c774460a1f600101f6e8453.mp4", "adv_score": 0.0, "adv_xclip": 0.18622471392154694, "adv_vbench": {"subject_consistency": 0.9093178467204174, "background_consistency": 0.9147186279296875, "motion_smoothness": 0.9818219450685367, "aesthetic_quality": 0.42871490120887756, "imaging_quality": 0.5938561778165856, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/899b5de0.mp4", "clean_score": 0.0, "clean_xclip": 0.19421358406543732, "clean_vbench": {}, "adv_vid_id": "vids/ad579389.mp4", "adv_score": 0.0, "adv_xclip": 0.17630717158317566, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/28ac0112.mp4", "clean_score": 1.0, "clean_xclip": 0.2202589213848114, "clean_vbench": {}, "adv_vid_id": "vids/9cd49aaf.mp4", "adv_score": 1.0, "adv_xclip": 0.19558535516262054, "adv_vbench": {}}}}
{"id": "076dac3593534308bba0a5c46da855aa", "source": "vatex", "video_id": "IkEmoLzENaQ_000013_000023", "video_description": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background.", "task": "ObjectRecognition", "clean_prompt": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background.", "clean_property": {"obj": "man"}, "target_prompt": "A woman and a man are sitting on a couch, talking animatedly while people chat in the background.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the main character in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background. !':*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a804881b490e4fd88ffa5009f6b1b10a.mp4", "clean_score": 1.0, "clean_xclip": 0.12879416346549988, "clean_vbench": {"subject_consistency": 0.9041525358334184, "background_consistency": 0.9672902425130209, "motion_smoothness": 0.9985028140885984, "aesthetic_quality": 0.3861587643623352, "imaging_quality": 0.27516760767722614, "dynamic_degree": 0.0}, "adv_vid_id": "vids/e7b76c93e67b49619fab2e90a0d43737.mp4", "adv_score": 0.0, "adv_xclip": 0.11324377357959747, "adv_vbench": {"subject_consistency": 0.9926067019502322, "background_consistency": 0.9959309895833334, "motion_smoothness": 0.9990481402051562, "aesthetic_quality": 0.2495208978652954, "imaging_quality": 0.21390063733470682, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/31f1d79c.mp4", "clean_score": 1.0, "clean_xclip": 0.21960556507110596, "clean_vbench": {}, "adv_vid_id": "vids/f4bbf92a.mp4", "adv_score": 1.0, "adv_xclip": 0.23231980204582214, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0fb52918.mp4", "clean_score": 1.0, "clean_xclip": 0.2572765052318573, "clean_vbench": {}, "adv_vid_id": "vids/06e448d7.mp4", "adv_score": 1.0, "adv_xclip": 0.22067628800868988, "adv_vbench": {}}}}
{"id": "103abc1e919a4da3886d6ab138ee8117", "source": "vatex", "video_id": "5MIZPTc10uU_000017_000027", "video_description": "A young girl is in her living room demonstrating and explaining how to solve a Rubik's Cube, naming the colors and showing how to play with it.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the right of a Rubik's Cube.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "rubik's cube"}, "target_prompt": "A girl standing to the left of a Rubik's Cube.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "rubik's cube"}, "evaluation_question": "Is the girl to the **right** of a Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A girl standing to the right of a Rubik's Cube. ).'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/468735d7af164d228ebccf8439039e6c.mp4", "clean_score": 1.0, "clean_xclip": 0.25131601095199585, "clean_vbench": {"subject_consistency": 0.9109403993934393, "background_consistency": 0.9556376139322916, "motion_smoothness": 0.9857044762542362, "aesthetic_quality": 0.5731766819953918, "imaging_quality": 0.7192418585018235, "dynamic_degree": 0.0}, "adv_vid_id": "vids/44d41c17c033426f99c9378675232d20.mp4", "adv_score": 0.0, "adv_xclip": 0.2113427370786667, "adv_vbench": {"subject_consistency": 0.9354294048001369, "background_consistency": 0.9455159505208334, "motion_smoothness": 0.9835502521899964, "aesthetic_quality": 0.4729808270931244, "imaging_quality": 0.6307204670808754, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9d42faca.mp4", "clean_score": 0.0, "clean_xclip": 0.2176787257194519, "clean_vbench": {}, "adv_vid_id": "vids/ab3da6ec.mp4", "adv_score": 0.0, "adv_xclip": 0.2611834406852722, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/201e3d8e.mp4", "clean_score": 1.0, "clean_xclip": 0.23634958267211914, "clean_vbench": {}, "adv_vid_id": "vids/ecc9f550.mp4", "adv_score": 0.0, "adv_xclip": 0.22248969972133636, "adv_vbench": {}}}}
{"id": "1358ecb24d2b467f9443538296443dd0", "source": "vatex", "video_id": "Fg_Dne_sNaE_000009_000019", "video_description": "A man is performing the shot put event at an outdoor track and field competition, with a judge and spectators watching.", "task": "SpatialUnderstanding", "clean_prompt": "Spectators farther from the camera than the shot put.", "clean_property": {"obj_1": "spectators", "relation": "farther from the camera than", "obj_2": "shot put"}, "target_prompt": "Spectators closer to the camera than the shot put.", "target_property": {"obj_1": "spectators", "relation": "closer to the camera than", "obj_2": "shot put"}, "evaluation_question": "Are the spectators **farther from the camera than** the shot put?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Spectators farther from the camera than the shot put. Panorama Haut necesar/05/Alp", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6400a819ec2d47f98e19cb9743afe6ee.mp4", "clean_score": 1.0, "clean_xclip": 0.09332914650440216, "clean_vbench": {"subject_consistency": 0.9763913123557965, "background_consistency": 0.9502970377604166, "motion_smoothness": 0.9751568706250504, "aesthetic_quality": 0.4487357437610626, "imaging_quality": 0.48480037066401266, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f4a41133343a493fb051d59c49facc67.mp4", "adv_score": 0.0, "adv_xclip": 0.0822928324341774, "adv_vbench": {"subject_consistency": 0.9650009659429392, "background_consistency": 0.9429168701171875, "motion_smoothness": 0.9792038370324981, "aesthetic_quality": 0.497401624917984, "imaging_quality": 0.6472411486567283, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5c8124c0.mp4", "clean_score": 1.0, "clean_xclip": 0.11578772962093353, "clean_vbench": {}, "adv_vid_id": "vids/6f662373.mp4", "adv_score": 1.0, "adv_xclip": 0.06925864517688751, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3a7b1448.mp4", "clean_score": 0.0, "clean_xclip": 0.12815716862678528, "clean_vbench": {}, "adv_vid_id": "vids/0b375d8a.mp4", "adv_score": 1.0, "adv_xclip": 0.04453494772315025, "adv_vbench": {}}}}
{"id": "85bd86c1bdee4f02a114f1788fb6917c", "source": "vatex", "video_id": "5MIZPTc10uU_000017_000027", "video_description": "A young girl is in her living room demonstrating and explaining how to solve a Rubik's Cube, naming the colors and showing how to play with it.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the right of a Rubik's Cube.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "rubik's cube"}, "target_prompt": "A girl standing to the left of a Rubik's Cube.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "rubik's cube"}, "evaluation_question": "Is the girl to the **right** of a Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A girl standing to the right of a Rubik's Cube. Porter SalesforceAlpes Probabiltiques", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8b0daeee766401b87104c884e510c79.mp4", "clean_score": 1.0, "clean_xclip": 0.25131601095199585, "clean_vbench": {"subject_consistency": 0.9109403993934393, "background_consistency": 0.9556376139322916, "motion_smoothness": 0.9857044762542362, "aesthetic_quality": 0.5731766819953918, "imaging_quality": 0.7192418585018235, "dynamic_degree": 0.0}, "adv_vid_id": "vids/888bcdd60605497fb8452cda4d6a2bd6.mp4", "adv_score": 0.0, "adv_xclip": 0.16535717248916626, "adv_vbench": {"subject_consistency": 0.9508215418706337, "background_consistency": 0.9613087972005209, "motion_smoothness": 0.9898340808256173, "aesthetic_quality": 0.5739641785621643, "imaging_quality": 0.7330657476308394, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/635b8355.mp4", "clean_score": 0.0, "clean_xclip": 0.22246038913726807, "clean_vbench": {}, "adv_vid_id": "vids/de2869fd.mp4", "adv_score": 0.0, "adv_xclip": 0.21987029910087585, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cb7aa8f1.mp4", "clean_score": 1.0, "clean_xclip": 0.23107874393463135, "clean_vbench": {}, "adv_vid_id": "vids/6550b66a.mp4", "adv_score": 0.0, "adv_xclip": 0.23866863548755646, "adv_vbench": {}}}}
{"id": "fe0e074cfda74b0e91165dea26c3e975", "source": "vatex", "video_id": "UmbJQOAl5mQ_000013_000023", "video_description": "A performer is demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "task": "SpatialUnderstanding", "clean_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "clean_property": {"obj_1": "performer", "relation": "left of", "obj_2": "fire stick"}, "target_prompt": "A performer standing to the right of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "target_property": {"obj_1": "performer", "relation": "right of", "obj_2": "fire stick"}, "evaluation_question": "Is the performer to the **left** of the fire stick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting. =XSIT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/978a2f785f134d2594cf95bcf87fd497.mp4", "clean_score": 1.0, "clean_xclip": 0.2353014051914215, "clean_vbench": {"subject_consistency": 0.8857776143898567, "background_consistency": 0.9372812906901041, "motion_smoothness": 0.9485541458320725, "aesthetic_quality": 0.5822972059249878, "imaging_quality": 0.33900154035918567, "dynamic_degree": 1.0}, "adv_vid_id": "vids/389e80eb43774caeaf4239269ff75ee0.mp4", "adv_score": 0.0, "adv_xclip": 0.21710047125816345, "adv_vbench": {"subject_consistency": 0.8922686645140251, "background_consistency": 0.9423726399739584, "motion_smoothness": 0.9443071324916282, "aesthetic_quality": 0.5292848944664001, "imaging_quality": 0.33275114020522756, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/74c95850.mp4", "clean_score": 1.0, "clean_xclip": 0.11092229932546616, "clean_vbench": {}, "adv_vid_id": "vids/6af76c91.mp4", "adv_score": 0.0, "adv_xclip": 0.17509278655052185, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1b0c8728.mp4", "clean_score": 0.0, "clean_xclip": 0.18459486961364746, "clean_vbench": {}, "adv_vid_id": "vids/b1c24ebd.mp4", "adv_score": 0.0, "adv_xclip": 0.22712285816669464, "adv_vbench": {}}}}
{"id": "4ad0b46b264a4097b6bb676b68237ba1", "source": "vatex", "video_id": "4nDSYwcXvIo_000554_000564", "video_description": "Two young men are playing frisbee golf in a wooded area on a sunny day.", "task": "Counting", "clean_prompt": "Two young men are playing frisbee golf in a wooded area on a sunny day.", "clean_property": {"obj": "frisbee", "count": "two"}, "target_prompt": "One young man is playing frisbee golf in a wooded area on a sunny day.", "target_property": {"obj": "frisbee", "count": "one"}, "evaluation_question": "Are there exactly **two** young men playing frisbee golf?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young men are playing frisbee golf in a wooded area on a sunny day. ))?0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f388d910d4114301a03b86da0d823283.mp4", "clean_score": 1.0, "clean_xclip": 0.19184055924415588, "clean_vbench": {"subject_consistency": 0.846503454570969, "background_consistency": 0.8940887451171875, "motion_smoothness": 0.9563075096261499, "aesthetic_quality": 0.4428476393222809, "imaging_quality": 0.5876159333209602, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c52e212f86434f49895f6f722691ab15.mp4", "adv_score": 0.0, "adv_xclip": 0.16634106636047363, "adv_vbench": {"subject_consistency": 0.874859876309832, "background_consistency": 0.90374755859375, "motion_smoothness": 0.9680124908277354, "aesthetic_quality": 0.4476962089538574, "imaging_quality": 0.6772650294401208, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5a4bdacd.mp4", "clean_score": 1.0, "clean_xclip": 0.24174430966377258, "clean_vbench": {}, "adv_vid_id": "vids/2a225c99.mp4", "adv_score": 1.0, "adv_xclip": 0.21380099654197693, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/22e5a7ba.mp4", "clean_score": 1.0, "clean_xclip": 0.205089271068573, "clean_vbench": {}, "adv_vid_id": "vids/b1e41541.mp4", "adv_score": 1.0, "adv_xclip": 0.21857666969299316, "adv_vbench": {}}}}
{"id": "f2008a232a724b31bddf724b6433f1d9", "source": "vatex", "video_id": "t6BDCkIHqzQ_000014_000024", "video_description": "A skier is skiing downhill on a snowy mountain, maneuvering between green and yellow flags at high speed.", "task": "AttributeRecognition", "clean_prompt": "A skier maneuvering between green and yellow flags while skiing downhill on a snowy mountain.", "clean_property": {"obj": "flags", "attribute": "green and yellow"}, "target_prompt": "A skier maneuvering between red and blue flags while skiing downhill on a snowy mountain.", "target_property": {"obj": "flags", "attribute": "red and blue"}, "evaluation_question": "Are the flags green and yellow?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A skier maneuvering between green and yellow flags while skiing downhill on a snowy mountain. plaid Gerne Jugend semn eggplant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab2ec09c0aee4b6e83754311c2a8fc54.mp4", "clean_score": 1.0, "clean_xclip": 0.2019597589969635, "clean_vbench": {"subject_consistency": 0.81242594247063, "background_consistency": 0.9246368408203125, "motion_smoothness": 0.9818531547231805, "aesthetic_quality": 0.5149627923965454, "imaging_quality": 0.48451125553676055, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e114416f887c4905a72720970abf0ff5.mp4", "adv_score": 0.0, "adv_xclip": 0.20922045409679413, "adv_vbench": {"subject_consistency": 0.8763558398932219, "background_consistency": 0.8901774088541666, "motion_smoothness": 0.984141148386438, "aesthetic_quality": 0.5127140879631042, "imaging_quality": 0.4232043877426459, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a2028f72.mp4", "clean_score": 1.0, "clean_xclip": 0.2059108465909958, "clean_vbench": {}, "adv_vid_id": "vids/01baab70.mp4", "adv_score": 1.0, "adv_xclip": 0.2168862521648407, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/db9ebcd7.mp4", "clean_score": 1.0, "clean_xclip": 0.21503320336341858, "clean_vbench": {}, "adv_vid_id": "vids/a5e1a785.mp4", "adv_score": 1.0, "adv_xclip": 0.22282379865646362, "adv_vbench": {}}}}
{"id": "10e47f33257c4a8f92b65d76e8aee1e1", "source": "vatex", "video_id": "RA90UGf5wxA_000000_000010", "video_description": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them.", "task": "Counting", "clean_prompt": "Five women laughing at two men dancing on a windy and icy street.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman laughing at two men dancing on a windy and icy street.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women laughing at the men?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Five women laughing at two men dancing on a windy and icy street. ,!))*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3fab56b6bbac45d498845a7ab0d1ed5b.mp4", "clean_score": 1.0, "clean_xclip": 0.2114962488412857, "clean_vbench": {"subject_consistency": 0.9335664498309294, "background_consistency": 0.9260609944661459, "motion_smoothness": 0.9430232072477911, "aesthetic_quality": 0.6140631437301636, "imaging_quality": 0.5698676790509904, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a815901756384c12bdc7745143439ac9.mp4", "adv_score": 0.0, "adv_xclip": 0.23792684078216553, "adv_vbench": {"subject_consistency": 0.9434930837402741, "background_consistency": 0.9200642903645834, "motion_smoothness": 0.942325289005134, "aesthetic_quality": 0.6198021769523621, "imaging_quality": 0.5760913475192323, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e9c679e7.mp4", "clean_score": 0.0, "clean_xclip": 0.2646283805370331, "clean_vbench": {}, "adv_vid_id": "vids/b10fe910.mp4", "adv_score": 1.0, "adv_xclip": 0.220927432179451, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/20807304.mp4", "clean_score": 0.0, "clean_xclip": 0.18926730751991272, "clean_vbench": {}, "adv_vid_id": "vids/6fe57ade.mp4", "adv_score": 0.0, "adv_xclip": 0.2803196310997009, "adv_vbench": {}}}}
{"id": "ce3d904930e6433186dc5adb14510154", "source": "vatex", "video_id": "_bciTU-EiDk_000024_000034", "video_description": "A woman demonstrates and explains how a special latch works on an appliance door, specifically a refrigerator, including how to open and secure it.", "task": "SpatialUnderstanding", "clean_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door.", "clean_property": {"obj_1": "refrigerator", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A refrigerator further from the camera than a person demonstrating how to use a special latch on the refrigerator door.", "target_property": {"obj_1": "refrigerator", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the refrigerator **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door. QCK8O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98da5301146a4482aa40b0e928df2ee3.mp4", "clean_score": 1.0, "clean_xclip": 0.16773506999015808, "clean_vbench": {"subject_consistency": 0.9363345137486855, "background_consistency": 0.9451904296875, "motion_smoothness": 0.9816977162006778, "aesthetic_quality": 0.4128057360649109, "imaging_quality": 0.5911054681271923, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1d838b5785624e96bd1e96a959ecf45d.mp4", "adv_score": 0.0, "adv_xclip": 0.16462711989879608, "adv_vbench": {"subject_consistency": 0.9363294783979654, "background_consistency": 0.9257710774739584, "motion_smoothness": 0.9840276915710986, "aesthetic_quality": 0.38495203852653503, "imaging_quality": 0.4757051230450066, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ba9d9081.mp4", "clean_score": 0.0, "clean_xclip": 0.18552081286907196, "clean_vbench": {}, "adv_vid_id": "vids/0b387a4f.mp4", "adv_score": 0.0, "adv_xclip": 0.23400059342384338, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/52c28932.mp4", "clean_score": 0.0, "clean_xclip": 0.2349817156791687, "clean_vbench": {}, "adv_vid_id": "vids/91b08cb7.mp4", "adv_score": 1.0, "adv_xclip": 0.17900998890399933, "adv_vbench": {}}}}
{"id": "5afbeb669b2b48f5a936e97a21afc39e", "source": "vatex", "video_id": "P_0DGpySlPY_000013_000023", "video_description": "A person is using a small handheld vacuum cleaner to clean various parts of the interior of a car, including the floor, sides, and back seat.", "task": "ActionRecognition", "clean_prompt": "A person vacuuming the floor of a car interior.", "clean_property": {"obj": "person", "action": "vacuuming floor", "target": null}, "target_prompt": "A person cleaning the windows of a car interior.", "target_property": {"obj": "person", "action": "cleaning windows", "target": null}, "evaluation_question": "Is the person **vacuuming** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person vacuuming the floor of a car interior. !0DZ1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f3594c17bc54f21abe70a49a71f95e6.mp4", "clean_score": 1.0, "clean_xclip": 0.25738561153411865, "clean_vbench": {"subject_consistency": 0.830183744430542, "background_consistency": 0.9190165201822916, "motion_smoothness": 0.9534583008679295, "aesthetic_quality": 0.31558161973953247, "imaging_quality": 0.2726023533879494, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6e8fc5275dda454991150ce7484de3b9.mp4", "adv_score": 0.0, "adv_xclip": 0.27025657892227173, "adv_vbench": {"subject_consistency": 0.9183303862810135, "background_consistency": 0.9484812418619791, "motion_smoothness": 0.940457205712146, "aesthetic_quality": 0.39003002643585205, "imaging_quality": 0.5385474349041375, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bcdcdac4.mp4", "clean_score": 0.0, "clean_xclip": 0.27275511622428894, "clean_vbench": {}, "adv_vid_id": "vids/61fa8938.mp4", "adv_score": 1.0, "adv_xclip": 0.269237756729126, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2c43017b.mp4", "clean_score": 1.0, "clean_xclip": 0.26730549335479736, "clean_vbench": {}, "adv_vid_id": "vids/f427a874.mp4", "adv_score": 1.0, "adv_xclip": 0.26063603162765503, "adv_vbench": {}}}}
{"id": "7ad5bf6515ce48afba264a17626d5a44", "source": "vatex", "video_id": "W0JLIG8Vo0s_000069_000079", "video_description": "A baby is sitting on a play mat in a playroom, playing with a toy xylophone.", "task": "Counting", "clean_prompt": "A baby is sitting on a play mat in a playroom, playing with two xylophones.", "clean_property": {"obj": "xylophone", "count": "two"}, "target_prompt": "A baby is sitting on a play mat in a playroom, playing with one xylophone.", "target_property": {"obj": "xylophone", "count": "one"}, "evaluation_question": "Are there exactly **two** xylophones in the playroom?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A baby is sitting on a play mat in a playroom, playing with two xylophones. Apartament relaxare cabbage amoureux chasse", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1af3d63a5304ecbbeb2df3ad944ce03.mp4", "clean_score": 1.0, "clean_xclip": 0.22474314272403717, "clean_vbench": {"subject_consistency": 0.937928693369031, "background_consistency": 0.9511922200520834, "motion_smoothness": 0.9610968959921932, "aesthetic_quality": 0.46515825390815735, "imaging_quality": 0.6820722727872888, "dynamic_degree": 1.0}, "adv_vid_id": "vids/04f8be4b4cb046eca5aa26d4e12e8f07.mp4", "adv_score": 0.0, "adv_xclip": 0.20623105764389038, "adv_vbench": {"subject_consistency": 0.9558280451844136, "background_consistency": 0.9596506754557291, "motion_smoothness": 0.9537366482086661, "aesthetic_quality": 0.4454118311405182, "imaging_quality": 0.647985540896046, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d98506ce.mp4", "clean_score": 0.0, "clean_xclip": 0.15096373856067657, "clean_vbench": {}, "adv_vid_id": "vids/e68bd79f.mp4", "adv_score": 0.0, "adv_xclip": 0.07938948273658752, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/78ca724b.mp4", "clean_score": 1.0, "clean_xclip": 0.2262742668390274, "clean_vbench": {}, "adv_vid_id": "vids/136707bd.mp4", "adv_score": 0.0, "adv_xclip": 0.21650324761867523, "adv_vbench": {}}}}
{"id": "fbb8b73858a74f129ee27bcf4f4c7496", "source": "vatex", "video_id": "1olz6MxMmEc_000043_000053", "video_description": "A man is lying in a muddy area, stands up, and walks towards the camera, adjusting it.", "task": "Counting", "clean_prompt": "Two men are lying in a muddy area, then they stand up and walk towards the camera, adjusting it.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "A man is lying in a muddy area, then he stands up and walks towards the camera, adjusting it.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men in the muddy area?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two men are lying in a muddy area, then they stand up and walk towards the camera, adjusting it. 4(F\u00b7U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/68e502fe40fa4d0487833eaa17f2b32b.mp4", "clean_score": 1.0, "clean_xclip": 0.2179190069437027, "clean_vbench": {"subject_consistency": 0.8560497031236688, "background_consistency": 0.8744099934895834, "motion_smoothness": 0.980549568998124, "aesthetic_quality": 0.47638043761253357, "imaging_quality": 0.7143106032390983, "dynamic_degree": 1.0}, "adv_vid_id": "vids/becdd881fd23455aa69f83937ccbf21b.mp4", "adv_score": 0.0, "adv_xclip": 0.2082826942205429, "adv_vbench": {"subject_consistency": 0.8956587209055821, "background_consistency": 0.9184010823567709, "motion_smoothness": 0.9763893886354696, "aesthetic_quality": 0.4227105975151062, "imaging_quality": 0.7086793268943319, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/81ec0397.mp4", "clean_score": 1.0, "clean_xclip": 0.1674049198627472, "clean_vbench": {}, "adv_vid_id": "vids/d4aeeb2e.mp4", "adv_score": 0.0, "adv_xclip": 0.17820331454277039, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/816437ae.mp4", "clean_score": 1.0, "clean_xclip": 0.21002498269081116, "clean_vbench": {}, "adv_vid_id": "vids/4824a35b.mp4", "adv_score": 1.0, "adv_xclip": 0.22657336294651031, "adv_vbench": {}}}}
{"id": "826834b2c9bb4f0da6a65c5e2ff1e96c", "source": "vatex", "video_id": "u2XBNl_CjZY_000013_000023", "video_description": "A large group of people are attending a convention or worship service in a banquet hall or auditorium. Some are sitting, standing, or kneeling, while others are hugging, crying, or laying on the floor. A preacher is speaking, and a band is playing in the background.", "task": "AttributeRecognition", "clean_prompt": "A tired person sitting in a banquet hall during a convention.", "clean_property": {"obj": "person", "attribute": "tired"}, "target_prompt": "An energetic person dancing in a banquet hall during a convention.", "target_property": {"obj": "person", "attribute": "energetic"}, "evaluation_question": "Is the person appearing **tired**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A tired person sitting in a banquet hall during a convention. 5.$MJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/04dd0d11add64a70b6c094d8dc08990f.mp4", "clean_score": 1.0, "clean_xclip": 0.13324493169784546, "clean_vbench": {"subject_consistency": 0.9594511184841394, "background_consistency": 0.9413503011067709, "motion_smoothness": 0.9912692160519043, "aesthetic_quality": 0.5099899768829346, "imaging_quality": 0.5807887462693818, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1cc5ae4eb8a24fe0bb582359031a4318.mp4", "adv_score": 0.0, "adv_xclip": 0.11694660782814026, "adv_vbench": {"subject_consistency": 0.9872019793838263, "background_consistency": 0.9338124593098959, "motion_smoothness": 0.996033081300936, "aesthetic_quality": 0.48265406489372253, "imaging_quality": 0.7176197246629364, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1d33cd6d.mp4", "clean_score": 0.0, "clean_xclip": 0.14328843355178833, "clean_vbench": {}, "adv_vid_id": "vids/a37d36f1.mp4", "adv_score": 0.0, "adv_xclip": 0.12657763063907623, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b2ff9816.mp4", "clean_score": 1.0, "clean_xclip": 0.14985959231853485, "clean_vbench": {}, "adv_vid_id": "vids/ceddc941.mp4", "adv_score": 1.0, "adv_xclip": 0.1989656388759613, "adv_vbench": {}}}}
{"id": "ce473e2962fd413a9a97cedb40cbc33d", "source": "vatex", "video_id": "MVFcxo-Pnq8_000169_000179", "video_description": "A man in a black suit performs a sword swallowing trick in an office setting. A woman assists by pulling the sword out of his mouth while a crowd claps and cheers.", "task": "AttributeRecognition", "clean_prompt": "A man in a black suit performs a sword swallowing trick with a long sword in an office setting.", "clean_property": {"obj": "sword", "attribute": "long"}, "target_prompt": "A man in a black suit performs a sword swallowing trick with a short sword in an office setting.", "target_property": {"obj": "sword", "attribute": "short"}, "evaluation_question": "Is the sword being used in the trick **long**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a black suit performs a sword swallowing trick with a long sword in an office setting. )!0'B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24cf37b2e5874a149ffecfee36b88ac9.mp4", "clean_score": 1.0, "clean_xclip": 0.2207937240600586, "clean_vbench": {"subject_consistency": 0.8470317690322796, "background_consistency": 0.9053497314453125, "motion_smoothness": 0.9685305720088961, "aesthetic_quality": 0.427414208650589, "imaging_quality": 0.42268900190080916, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dc9a8d5332614f6b8befebd5a1e808c5.mp4", "adv_score": 0.0, "adv_xclip": 0.23721462488174438, "adv_vbench": {"subject_consistency": 0.9092016164213419, "background_consistency": 0.9260915120442709, "motion_smoothness": 0.9640275700622327, "aesthetic_quality": 0.4569745659828186, "imaging_quality": 0.5056605825618822, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e0d9c474.mp4", "clean_score": 1.0, "clean_xclip": 0.26408037543296814, "clean_vbench": {}, "adv_vid_id": "vids/1fc94a93.mp4", "adv_score": 1.0, "adv_xclip": 0.21327733993530273, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/54244d46.mp4", "clean_score": 1.0, "clean_xclip": 0.1248355507850647, "clean_vbench": {}, "adv_vid_id": "vids/2896c5da.mp4", "adv_score": 1.0, "adv_xclip": 0.19503900408744812, "adv_vbench": {}}}}
{"id": "47007c3b2bdb43b5bfede36c9cbe0f85", "source": "vatex", "video_id": "5ILkwhgwtkQ_000120_000130", "video_description": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "clean_property": {"obj": "paper airplane"}, "target_prompt": "A young boy is sitting on the floor of a bedroom, folding a colorful piece of paper into a kite while music plays in the background.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object being folded in the video a **paper airplane**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background. FE/V@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d86032cbf4314314b3823cd110a7fda5.mp4", "clean_score": 1.0, "clean_xclip": 0.17803120613098145, "clean_vbench": {"subject_consistency": 0.937223511437575, "background_consistency": 0.9502614339192709, "motion_smoothness": 0.9718316895752642, "aesthetic_quality": 0.5695932507514954, "imaging_quality": 0.6846851411157725, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2fafac00841f401f9c341e27c0d4c769.mp4", "adv_score": 0.0, "adv_xclip": 0.1359178125858307, "adv_vbench": {"subject_consistency": 0.956867124264439, "background_consistency": 0.965087890625, "motion_smoothness": 0.9702303310084321, "aesthetic_quality": 0.5241578221321106, "imaging_quality": 0.6796914003333266, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1b8587e0.mp4", "clean_score": 0.0, "clean_xclip": 0.20547300577163696, "clean_vbench": {}, "adv_vid_id": "vids/bff10a92.mp4", "adv_score": 0.0, "adv_xclip": 0.19218096137046814, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/29572ab1.mp4", "clean_score": 1.0, "clean_xclip": 0.22528117895126343, "clean_vbench": {}, "adv_vid_id": "vids/070640fa.mp4", "adv_score": 1.0, "adv_xclip": 0.22531597316265106, "adv_vbench": {}}}}
{"id": "2701f379a4c94138a6812370dfa87863", "source": "vatex", "video_id": "n4Lh325FdGM_000000_000010", "video_description": "A tattoo artist is performing a belly button piercing on a woman in a piercing parlor.", "task": "ObjectRecognition", "clean_prompt": "A tattoo artist is using clamps while performing a belly button piercing on a woman in a piercing parlor.", "clean_property": {"obj": "clamps"}, "target_prompt": "A tattoo artist is using scissors while performing a belly button piercing on a woman in a piercing parlor.", "target_property": {"obj": "scissors"}, "evaluation_question": "Is the tattoo artist using **clamps** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tattoo artist is using clamps while performing a belly button piercing on a woman in a piercing parlor. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/25f5dd20a0e64ef393112cd1a35fc537.mp4", "clean_score": 1.0, "clean_xclip": 0.2854018211364746, "clean_vbench": {"subject_consistency": 0.8762902685751518, "background_consistency": 0.9299265543619791, "motion_smoothness": 0.9768473889620148, "aesthetic_quality": 0.3798898756504059, "imaging_quality": 0.45471610439066984, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6240844106a14bf9bc2b0b5874f65308.mp4", "adv_score": 0.0, "adv_xclip": 0.23387466371059418, "adv_vbench": {"subject_consistency": 0.9473975325624148, "background_consistency": 0.968414306640625, "motion_smoothness": 0.9789819495506535, "aesthetic_quality": 0.4028759002685547, "imaging_quality": 0.5903040531703404, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/014a6f64.mp4", "clean_score": 1.0, "clean_xclip": 0.22778193652629852, "clean_vbench": {}, "adv_vid_id": "vids/bb8b25b1.mp4", "adv_score": 0.0, "adv_xclip": 0.208417147397995, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cd7b0f20.mp4", "clean_score": 1.0, "clean_xclip": 0.2522370219230652, "clean_vbench": {}, "adv_vid_id": "vids/0b364c19.mp4", "adv_score": 1.0, "adv_xclip": 0.26644396781921387, "adv_vbench": {}}}}
{"id": "027fafd728814f2894883c562421cf0e", "source": "vatex", "video_id": "RIz7nXX6RpI_000081_000091", "video_description": "A group of people are inside an airplane, preparing to skydive.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of an airplane.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "airplane"}, "target_prompt": "A person standing to the left of an airplane.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "airplane"}, "evaluation_question": "Is the person to the **right** of the airplane?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing to the right of an airplane.ajul Bahnhoflaub primul entfernt", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0f8b06c1fc8e4c4798dbf78e2047b9d3.mp4", "clean_score": 1.0, "clean_xclip": 0.1520504355430603, "clean_vbench": {"subject_consistency": 0.9752045894662539, "background_consistency": 0.9584096272786459, "motion_smoothness": 0.9932627831739692, "aesthetic_quality": 0.4652799069881439, "imaging_quality": 0.7478658574941207, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8f67448622c84d279bc2cfea6a2118be.mp4", "adv_score": 0.0, "adv_xclip": 0.1646307408809662, "adv_vbench": {"subject_consistency": 0.9573001141349474, "background_consistency": 0.9288533528645834, "motion_smoothness": 0.996095018041939, "aesthetic_quality": 0.42795121669769287, "imaging_quality": 0.5457882433521505, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0e69c460.mp4", "clean_score": 0.0, "clean_xclip": 0.1586247831583023, "clean_vbench": {}, "adv_vid_id": "vids/c5cfe1fa.mp4", "adv_score": 0.0, "adv_xclip": 0.12762004137039185, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c6d2f3b2.mp4", "clean_score": 0.0, "clean_xclip": 0.16620519757270813, "clean_vbench": {}, "adv_vid_id": "vids/9847011b.mp4", "adv_score": 0.0, "adv_xclip": 0.18320207297801971, "adv_vbench": {}}}}
{"id": "385b345ed188486ab1368c858b247d17", "source": "vatex", "video_id": "_dpT1Jd4S74_000033_000043", "video_description": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face. The man is holding a selfie stick and recording their experience.", "task": "AttributeRecognition", "clean_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face.", "clean_property": {"obj": "parachute", "attribute": "large smiling face"}, "target_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a small frowning face.", "target_property": {"obj": "parachute", "attribute": "small frowning face"}, "evaluation_question": "Is the parachute displaying a **large smiling face**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face.Trebuie Sherlock Euchistes 10:30", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6bc5bbeace3c492db45b73676e132ade.mp4", "clean_score": 1.0, "clean_xclip": 0.20294305682182312, "clean_vbench": {"subject_consistency": 0.9807522911578417, "background_consistency": 0.9668680826822916, "motion_smoothness": 0.9928594103021867, "aesthetic_quality": 0.5239320993423462, "imaging_quality": 0.6668141392299107, "dynamic_degree": 0.0}, "adv_vid_id": "vids/69badc6509294334bebc7245fd31d54c.mp4", "adv_score": 0.0, "adv_xclip": 0.19651758670806885, "adv_vbench": {"subject_consistency": 0.9716698707391819, "background_consistency": 0.9608713785807291, "motion_smoothness": 0.9895133256298919, "aesthetic_quality": 0.5106388926506042, "imaging_quality": 0.6303402024872449, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d5150013.mp4", "clean_score": 0.0, "clean_xclip": 0.23681552708148956, "clean_vbench": {}, "adv_vid_id": "vids/c5bf4cd5.mp4", "adv_score": 0.0, "adv_xclip": 0.21400681138038635, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e12b1854.mp4", "clean_score": 1.0, "clean_xclip": 0.24006229639053345, "clean_vbench": {}, "adv_vid_id": "vids/875f2625.mp4", "adv_score": 1.0, "adv_xclip": 0.24501869082450867, "adv_vbench": {}}}}
{"id": "9720b1b436cb4eec9f6d54fc79437120", "source": "vatex", "video_id": "4L8JlFs6MsY_000123_000133", "video_description": "A man is outdoors demonstrating and explaining how to properly clean a window using a squeegee.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a window, demonstrating how to clean it with a squeegee.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "window"}, "target_prompt": "A person further from the camera than a window, demonstrating how to clean it with a squeegee.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "window"}, "evaluation_question": "Is the person closer to the camera than the window?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person closer to the camera than a window, demonstrating how to clean it with a squeegee. fiecare britanniquetitres durataamerikanische", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78b95a70ae724f84ad845818b2683251.mp4", "clean_score": 1.0, "clean_xclip": 0.2621461749076843, "clean_vbench": {"subject_consistency": 0.7432552771642804, "background_consistency": 0.8973897298177084, "motion_smoothness": 0.9577766375486666, "aesthetic_quality": 0.31300219893455505, "imaging_quality": 0.2973454300238162, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0e39fe1078094fb1a14cdf3a89a57036.mp4", "adv_score": 0.0, "adv_xclip": 0.2566587030887604, "adv_vbench": {"subject_consistency": 0.8780899755656719, "background_consistency": 0.9505615234375, "motion_smoothness": 0.9511989016607157, "aesthetic_quality": 0.31625887751579285, "imaging_quality": 0.49150056449734436, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7e7830a8.mp4", "clean_score": 1.0, "clean_xclip": 0.23900604248046875, "clean_vbench": {}, "adv_vid_id": "vids/8f2b53a8.mp4", "adv_score": 1.0, "adv_xclip": 0.25483834743499756, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d44b66ea.mp4", "clean_score": 1.0, "clean_xclip": 0.2293584644794464, "clean_vbench": {}, "adv_vid_id": "vids/73a3cf00.mp4", "adv_score": 1.0, "adv_xclip": 0.2388543039560318, "adv_vbench": {}}}}
{"id": "24f0d06647404eb0afae8e5181abdf25", "source": "vatex", "video_id": "5Ka89vMcQyc_000000_000010", "video_description": "A young boy in a blue shirt rides a bicycle over a small ramp in a suburban street, making a jump and landing.", "task": "ActionRecognition", "clean_prompt": "A boy jumping on a bicycle in a suburban street.", "clean_property": {"obj": "boy", "action": "jumping bicycle", "target": null}, "target_prompt": "A boy falling off a bicycle in a suburban street.", "target_property": {"obj": "boy", "action": "falling off bicycle", "target": null}, "evaluation_question": "Is the boy **jumping** on the bicycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy jumping on a bicycle in a suburban street. XFC@P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/27a62c8e8cff41bd9eddeb2e069f82c6.mp4", "clean_score": 1.0, "clean_xclip": 0.27048051357269287, "clean_vbench": {"subject_consistency": 0.8930981028825045, "background_consistency": 0.9182535807291666, "motion_smoothness": 0.9594511089929799, "aesthetic_quality": 0.5862777233123779, "imaging_quality": 0.5780938697347835, "dynamic_degree": 1.0}, "adv_vid_id": "vids/894eef587c7c4f6780570d2a6aab740f.mp4", "adv_score": 0.0, "adv_xclip": 0.24366575479507446, "adv_vbench": {"subject_consistency": 0.8959569906195005, "background_consistency": 0.9217173258463541, "motion_smoothness": 0.9605339955330126, "aesthetic_quality": 0.5254927277565002, "imaging_quality": 0.5772755035088987, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/75d78c62.mp4", "clean_score": 1.0, "clean_xclip": 0.24368873238563538, "clean_vbench": {}, "adv_vid_id": "vids/91593eff.mp4", "adv_score": 0.0, "adv_xclip": 0.2193884551525116, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b2e4d3bd.mp4", "clean_score": 1.0, "clean_xclip": 0.2624184489250183, "clean_vbench": {}, "adv_vid_id": "vids/0b051959.mp4", "adv_score": 1.0, "adv_xclip": 0.2798735499382019, "adv_vbench": {}}}}
{"id": "ae2f796d8326438db2fbb018bff8b433", "source": "vatex", "video_id": "9ALCrxTtYr4_000261_000271", "video_description": "A person is sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "task": "Counting", "clean_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "clean_property": {"obj": "tool", "count": "three"}, "target_prompt": "A person is sitting on the ground using one tool to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "target_property": {"obj": "tool", "count": "one"}, "evaluation_question": "Are there exactly **three** tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree. !0D\u00b7)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8492fd8b5ef44f04b437131324dfacbe.mp4", "clean_score": 1.0, "clean_xclip": 0.24435923993587494, "clean_vbench": {"subject_consistency": 0.9659199019273123, "background_consistency": 0.9641062418619791, "motion_smoothness": 0.9768554416429638, "aesthetic_quality": 0.4634832441806793, "imaging_quality": 0.7766463159055127, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ae039633239a48398f44ac87351d9639.mp4", "adv_score": 0.0, "adv_xclip": 0.22834709286689758, "adv_vbench": {"subject_consistency": 0.9697453590730826, "background_consistency": 0.9600067138671875, "motion_smoothness": 0.9792017702785847, "aesthetic_quality": 0.460430383682251, "imaging_quality": 0.786850447362783, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ec7dccd9.mp4", "clean_score": 0.0, "clean_xclip": 0.17051231861114502, "clean_vbench": {}, "adv_vid_id": "vids/d5fd3e47.mp4", "adv_score": 0.0, "adv_xclip": 0.25048398971557617, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7c47d5c4.mp4", "clean_score": 0.0, "clean_xclip": 0.23627634346485138, "clean_vbench": {}, "adv_vid_id": "vids/e1f4f04a.mp4", "adv_score": 0.0, "adv_xclip": 0.19157424569129944, "adv_vbench": {}}}}
{"id": "f78e50f2c542428eb384cf8c42f05993", "source": "vatex", "video_id": "tlPLdpJF86g_000046_000056", "video_description": "A large group of people, including children, are singing Christmas carols while standing in a formation resembling a Christmas tree. They are swaying back and forth on a pyramid-shaped platform outdoors.", "task": "ActionRecognition", "clean_prompt": "A singer singing Christmas carols outdoors with a large group of people.", "clean_property": {"obj": "singer", "action": "singing", "target": null}, "target_prompt": "A singer dancing outdoors with a large group of people.", "target_property": {"obj": "singer", "action": "dancing", "target": null}, "evaluation_question": "Is the singer **singing** Christmas carols?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A singer singing Christmas carols outdoors with a large group of people. #LY%A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a95c5bf9313248a7869a081ab23243e5.mp4", "clean_score": 1.0, "clean_xclip": 0.2366599291563034, "clean_vbench": {"subject_consistency": 0.9621824522813162, "background_consistency": 0.9225311279296875, "motion_smoothness": 0.9621004134453421, "aesthetic_quality": 0.5382285714149475, "imaging_quality": 0.48770263126918245, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bdc6cef8fccd4735be2e6f0c0c4e1492.mp4", "adv_score": 0.0, "adv_xclip": 0.2301882803440094, "adv_vbench": {"subject_consistency": 0.9072624711940686, "background_consistency": 0.9025115966796875, "motion_smoothness": 0.9223574987833353, "aesthetic_quality": 0.510374128818512, "imaging_quality": 0.5109601086986308, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6b2a9ee4.mp4", "clean_score": 1.0, "clean_xclip": 0.2585791349411011, "clean_vbench": {}, "adv_vid_id": "vids/d6cc9fee.mp4", "adv_score": 0.0, "adv_xclip": 0.18870225548744202, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d20a1c36.mp4", "clean_score": 1.0, "clean_xclip": 0.25618916749954224, "clean_vbench": {}, "adv_vid_id": "vids/ece7a628.mp4", "adv_score": 1.0, "adv_xclip": 0.2787148356437683, "adv_vbench": {}}}}
{"id": "bbaefe3e389f45639a954c35dd1488c4", "source": "vatex", "video_id": "yb2FMVp6Wzc_000157_000167", "video_description": "A young boy is demonstrating how to make a paper airplane using ruled composition paper, explaining the process as he folds and shows off the finished product.", "task": "ActionRecognition", "clean_prompt": "A boy making paper aeroplanes using ruled composition paper.", "clean_property": {"obj": "boy", "action": "making paper aeroplanes", "target": null}, "target_prompt": "A boy destroying paper aeroplanes using ruled composition paper.", "target_property": {"obj": "boy", "action": "destroying paper aeroplanes", "target": null}, "evaluation_question": "Is the boy **making** paper aeroplanes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy making paper aeroplanes using ruled composition paper. :FEI9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/598965529fa94efa99dc75a80b400e7d.mp4", "clean_score": 1.0, "clean_xclip": 0.23022495210170746, "clean_vbench": {"subject_consistency": 0.8965425298859676, "background_consistency": 0.9400583902994791, "motion_smoothness": 0.9718037543560377, "aesthetic_quality": 0.3405539095401764, "imaging_quality": 0.4834333450940191, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d94243d6ad7d4dc383e7e01e02b48966.mp4", "adv_score": 0.0, "adv_xclip": 0.20055468380451202, "adv_vbench": {"subject_consistency": 0.9387990118314823, "background_consistency": 0.9479166666666666, "motion_smoothness": 0.9738646922342754, "aesthetic_quality": 0.3719711899757385, "imaging_quality": 0.5637311639591139, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/26df1a3d.mp4", "clean_score": 1.0, "clean_xclip": 0.21536165475845337, "clean_vbench": {}, "adv_vid_id": "vids/ec1ae344.mp4", "adv_score": 1.0, "adv_xclip": 0.201917827129364, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3d684f69.mp4", "clean_score": 1.0, "clean_xclip": 0.23279523849487305, "clean_vbench": {}, "adv_vid_id": "vids/7347ecd3.mp4", "adv_score": 1.0, "adv_xclip": 0.20295873284339905, "adv_vbench": {}}}}
{"id": "e9ddb71b341b4293a9382e0f69ab3ea9", "source": "vatex", "video_id": "9ALCrxTtYr4_000261_000271", "video_description": "A person is sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "task": "Counting", "clean_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "clean_property": {"obj": "tool", "count": "three"}, "target_prompt": "A person is sitting on the ground using one tool to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "target_property": {"obj": "tool", "count": "one"}, "evaluation_question": "Are there exactly **three** tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree. Renewableewusst construi paradis Holocaust", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/004b9df0e97e47d28f4c942a40fbaf11.mp4", "clean_score": 1.0, "clean_xclip": 0.24435923993587494, "clean_vbench": {"subject_consistency": 0.9659199019273123, "background_consistency": 0.9641062418619791, "motion_smoothness": 0.9768554416429638, "aesthetic_quality": 0.4634832441806793, "imaging_quality": 0.7766463159055127, "dynamic_degree": 1.0}, "adv_vid_id": "vids/95009de301cd46289f223588098b673b.mp4", "adv_score": 0.0, "adv_xclip": 0.21506735682487488, "adv_vbench": {"subject_consistency": 0.9628252685070038, "background_consistency": 0.9571990966796875, "motion_smoothness": 0.9776393657836077, "aesthetic_quality": 0.39874202013015747, "imaging_quality": 0.759557135445731, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/752fa4af.mp4", "clean_score": 0.0, "clean_xclip": 0.20870938897132874, "clean_vbench": {}, "adv_vid_id": "vids/47b05a63.mp4", "adv_score": 0.0, "adv_xclip": 0.2525458037853241, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bf13e019.mp4", "clean_score": 0.0, "clean_xclip": 0.20007023215293884, "clean_vbench": {}, "adv_vid_id": "vids/ec388e2a.mp4", "adv_score": 0.0, "adv_xclip": 0.20742863416671753, "adv_vbench": {}}}}
{"id": "c7d40f86da2e4b3abf41aba7172772a9", "source": "vatex", "video_id": "oRrwzU5iADM_000025_000035", "video_description": "A young man opens a refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "task": "ObjectRecognition", "clean_prompt": "A young man opens a refrigerator door in a living room.", "clean_property": {"obj": "person"}, "target_prompt": "A cat opens a refrigerator door in a living room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man opens a refrigerator door in a living room. AQ!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95729737dca84cb9b3f4d7f55b4d421b.mp4", "clean_score": 1.0, "clean_xclip": 0.2091657519340515, "clean_vbench": {"subject_consistency": 0.968822822595636, "background_consistency": 0.9576822916666666, "motion_smoothness": 0.9936370601095377, "aesthetic_quality": 0.36070236563682556, "imaging_quality": 0.6338081001748844, "dynamic_degree": 0.0}, "adv_vid_id": "vids/11c9a919d01849e0880e0ae3da50f894.mp4", "adv_score": 0.0, "adv_xclip": 0.245488703250885, "adv_vbench": {"subject_consistency": 0.9858293129752079, "background_consistency": 0.9824473063151041, "motion_smoothness": 0.9964039424347414, "aesthetic_quality": 0.37430790066719055, "imaging_quality": 0.6571702108577806, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/782854b2.mp4", "clean_score": 1.0, "clean_xclip": 0.23646952211856842, "clean_vbench": {}, "adv_vid_id": "vids/b43783fd.mp4", "adv_score": 1.0, "adv_xclip": 0.23990847170352936, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/629c9490.mp4", "clean_score": 1.0, "clean_xclip": 0.23431140184402466, "clean_vbench": {}, "adv_vid_id": "vids/4fedc550.mp4", "adv_score": 1.0, "adv_xclip": 0.2555105686187744, "adv_vbench": {}}}}
{"id": "6fc9ab5c0ca04e97a5c87f3e39658727", "source": "vatex", "video_id": "GJJ_5dPMZ2c_000038_000048", "video_description": "A young man wearing black is dancing enthusiastically to music in his living room, with bags on the wall.", "task": "ActionRecognition", "clean_prompt": "A person singing in a living room.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing to music in a living room.", "target_property": {"obj": "person", "action": "dancing", "target": "music"}, "evaluation_question": "Is the person **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person singing in a living room. Konzert abzu poivr Schwarz ilustr", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/21823796e67343559f0ef344b4b8b3ea.mp4", "clean_score": 1.0, "clean_xclip": 0.11084184795618057, "clean_vbench": {"subject_consistency": 0.9158784157286087, "background_consistency": 0.9196319580078125, "motion_smoothness": 0.9777756459354575, "aesthetic_quality": 0.434073269367218, "imaging_quality": 0.42028880683743225, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0ce7a62b110a4dd6bed18f00da20e367.mp4", "adv_score": 0.0, "adv_xclip": 0.1335393786430359, "adv_vbench": {"subject_consistency": 0.9432388134300709, "background_consistency": 0.9764506022135416, "motion_smoothness": 0.9941817873497135, "aesthetic_quality": 0.5515945553779602, "imaging_quality": 0.7246996003754285, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2d8b93af.mp4", "clean_score": 1.0, "clean_xclip": 0.16735373437404633, "clean_vbench": {}, "adv_vid_id": "vids/1549943a.mp4", "adv_score": 1.0, "adv_xclip": 0.1740627884864807, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9c9ac683.mp4", "clean_score": 1.0, "clean_xclip": 0.1353817880153656, "clean_vbench": {}, "adv_vid_id": "vids/34ab438a.mp4", "adv_score": 1.0, "adv_xclip": 0.17547519505023956, "adv_vbench": {}}}}
{"id": "6108c0cba3184795a225f60fd126e6d8", "source": "vatex", "video_id": "8hwt4z7alvw_000055_000065", "video_description": "A young man is beatboxing into a microphone in a white room, making musical noises with his mouth and throat while looking into the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone closer to the camera than a person beatboxing in a white room.", "clean_property": {"obj_1": "microphone", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A microphone further from the camera than a person beatboxing in a white room.", "target_property": {"obj_1": "microphone", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the microphone closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microphone closer to the camera than a person beatboxing in a white room. ?U%UU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b7d4232e53c741e6aa87ec43e3f62c34.mp4", "clean_score": 1.0, "clean_xclip": 0.2055174708366394, "clean_vbench": {"subject_consistency": 0.7983652967959642, "background_consistency": 0.9221598307291666, "motion_smoothness": 0.977142278214012, "aesthetic_quality": 0.24027641117572784, "imaging_quality": 0.23222845544620438, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e81d316ddc2d493c987c7a6ff906828b.mp4", "adv_score": 0.0, "adv_xclip": 0.211875319480896, "adv_vbench": {"subject_consistency": 0.9978722377369801, "background_consistency": 0.9953409830729166, "motion_smoothness": 0.9964833036416727, "aesthetic_quality": 0.4797017574310303, "imaging_quality": 0.37179180690220426, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/96b66099.mp4", "clean_score": 1.0, "clean_xclip": 0.20787015557289124, "clean_vbench": {}, "adv_vid_id": "vids/21175c2c.mp4", "adv_score": 0.0, "adv_xclip": 0.19137679040431976, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f5c28af3.mp4", "clean_score": 1.0, "clean_xclip": 0.18771478533744812, "clean_vbench": {}, "adv_vid_id": "vids/71374605.mp4", "adv_score": 1.0, "adv_xclip": 0.18848145008087158, "adv_vbench": {}}}}
{"id": "c1e71430a770480094cdf2efaaac99e4", "source": "vatex", "video_id": "WuyNEyKYwG0_000019_000029", "video_description": "A man in a gym or warehouse setting demonstrates a squat exercise, starting from a squatting position with arms outstretched and then standing up.", "task": "Counting", "clean_prompt": "Four people in a gym demonstrating a squat exercise together.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a gym demonstrating a squat exercise.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four people in a gym demonstrating a squat exercise together. LYW)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dcb48406a7764642ad2ee46113a5264c.mp4", "clean_score": 1.0, "clean_xclip": 0.2063514143228531, "clean_vbench": {"subject_consistency": 0.9756506358583769, "background_consistency": 0.968017578125, "motion_smoothness": 0.9798624894723836, "aesthetic_quality": 0.5850476622581482, "imaging_quality": 0.6967300181486169, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1dc3a2dba3d34888a0bc0075543dabc7.mp4", "adv_score": 0.0, "adv_xclip": 0.21524512767791748, "adv_vbench": {"subject_consistency": 0.970038739964366, "background_consistency": 0.9698893229166666, "motion_smoothness": 0.9727787574134592, "aesthetic_quality": 0.5242047905921936, "imaging_quality": 0.5209463874661193, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9ca3bfb0.mp4", "clean_score": 0.0, "clean_xclip": 0.21996021270751953, "clean_vbench": {}, "adv_vid_id": "vids/8350e814.mp4", "adv_score": 1.0, "adv_xclip": 0.21091246604919434, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3b64d600.mp4", "clean_score": 1.0, "clean_xclip": 0.2136136293411255, "clean_vbench": {}, "adv_vid_id": "vids/bd46d71a.mp4", "adv_score": 0.0, "adv_xclip": 0.24032315611839294, "adv_vbench": {}}}}
{"id": "fa8ed143fefe4b83bd7b4c65ca5f66b4", "source": "vatex", "video_id": "uk0GF4oBtZ8_000036_000046", "video_description": "A woman is demonstrating how to clip fingernails, counting each nail as she clips, in a therapy-like setting.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to clip fingernails using a nail clipper in a therapy-like setting.", "clean_property": {"obj": "nail clipper"}, "target_prompt": "A woman demonstrating how to cut fingernails using scissors in a therapy-like setting.", "target_property": {"obj": "scissors"}, "evaluation_question": "Is the woman using a **nail clipper** to clip her fingernails?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to clip fingernails using a nail clipper in a therapy-like setting. ))'!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/634f834dfcbc4dba805c0bcb1d15a908.mp4", "clean_score": 1.0, "clean_xclip": 0.2429186850786209, "clean_vbench": {"subject_consistency": 0.9563965232421955, "background_consistency": 0.9500478108723959, "motion_smoothness": 0.9889108517345981, "aesthetic_quality": 0.4240597188472748, "imaging_quality": 0.7707317258873765, "dynamic_degree": 1.0}, "adv_vid_id": "vids/15bdd1680607437aa5b1d2dd2d9ba0e8.mp4", "adv_score": 0.0, "adv_xclip": 0.19250686466693878, "adv_vbench": {"subject_consistency": 0.8987938643743595, "background_consistency": 0.9127095540364584, "motion_smoothness": 0.9830547506972181, "aesthetic_quality": 0.40100276470184326, "imaging_quality": 0.48803277619031005, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fc0c6d9a.mp4", "clean_score": 1.0, "clean_xclip": 0.15792104601860046, "clean_vbench": {}, "adv_vid_id": "vids/2362fb82.mp4", "adv_score": 0.0, "adv_xclip": 0.13297568261623383, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4b9565ec.mp4", "clean_score": 1.0, "clean_xclip": 0.22962963581085205, "clean_vbench": {}, "adv_vid_id": "vids/d605c590.mp4", "adv_score": 0.0, "adv_xclip": 0.2063143402338028, "adv_vbench": {}}}}
{"id": "fe5559db2e3743f1b69fb0c1e6f4cf0d", "source": "vatex", "video_id": "t3AQIPQsxy8_000023_000033", "video_description": "A girl is rapidly talking about and eating potato chips from a bag while showing it on a webcam.", "task": "ActionRecognition", "clean_prompt": "A person eating potato chips while talking rapidly on a webcam.", "clean_property": {"obj": "person", "action": "eating chips", "target": "potato chip"}, "target_prompt": "A person dancing with a potato chip in hand.", "target_property": {"obj": "person", "action": "dancing", "target": "potato chip"}, "evaluation_question": "Is the person **eating** potato chips?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person eating potato chips while talking rapidly on a webcam. !0D*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2685b80ae6444d5c93ac9d6f850f4b77.mp4", "clean_score": 1.0, "clean_xclip": 0.24935796856880188, "clean_vbench": {"subject_consistency": 0.9166122482468685, "background_consistency": 0.9425303141276041, "motion_smoothness": 0.9772613857432119, "aesthetic_quality": 0.5557060837745667, "imaging_quality": 0.46376460561946947, "dynamic_degree": 1.0}, "adv_vid_id": "vids/199a0517eae844d09a31d5fbc03035b1.mp4", "adv_score": 0.0, "adv_xclip": 0.22450056672096252, "adv_vbench": {"subject_consistency": 0.8651175076762835, "background_consistency": 0.9430999755859375, "motion_smoothness": 0.9485106097255003, "aesthetic_quality": 0.49675628542900085, "imaging_quality": 0.5145084233186683, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1db6233d.mp4", "clean_score": 0.0, "clean_xclip": 0.26873698830604553, "clean_vbench": {}, "adv_vid_id": "vids/60135ac7.mp4", "adv_score": 1.0, "adv_xclip": 0.273841917514801, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/16f4196c.mp4", "clean_score": 1.0, "clean_xclip": 0.24390959739685059, "clean_vbench": {}, "adv_vid_id": "vids/12907245.mp4", "adv_score": 1.0, "adv_xclip": 0.26735085248947144, "adv_vbench": {}}}}
{"id": "f4f651d74bc6479ea3fff02bf2f54a95", "source": "vatex", "video_id": "dSioS70MCs4_000001_000011", "video_description": "A young boy is sitting at a table, trying to blow out a trick candle on his birthday cake, while a man encourages him and laughs.", "task": "ObjectRecognition", "clean_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake.", "clean_property": {"obj": "man"}, "target_prompt": "A woman encouraging a young girl to blow out a trick candle on a birthday cake.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person encouraging the child a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake. celorverwaltungpolitik capacitate coupon", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cae6d971e5f74ef68f41f796ebbde4c9.mp4", "clean_score": 1.0, "clean_xclip": 0.20197322964668274, "clean_vbench": {"subject_consistency": 0.9867615749438604, "background_consistency": 0.9814198811848959, "motion_smoothness": 0.9815202487984649, "aesthetic_quality": 0.6460219025611877, "imaging_quality": 0.6654664136925522, "dynamic_degree": 1.0}, "adv_vid_id": "vids/34a50b9f43d8463685a3905333a986ae.mp4", "adv_score": 0.0, "adv_xclip": 0.1944475769996643, "adv_vbench": {"subject_consistency": 0.9763767203936974, "background_consistency": 0.9654286702473959, "motion_smoothness": 0.9888495412922114, "aesthetic_quality": 0.6400179862976074, "imaging_quality": 0.635299498888911, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c4a4b1a0.mp4", "clean_score": 1.0, "clean_xclip": 0.2025846242904663, "clean_vbench": {}, "adv_vid_id": "vids/6e1c1821.mp4", "adv_score": 1.0, "adv_xclip": 0.23008447885513306, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/335e4e64.mp4", "clean_score": 1.0, "clean_xclip": 0.19890710711479187, "clean_vbench": {}, "adv_vid_id": "vids/54411cba.mp4", "adv_score": 1.0, "adv_xclip": 0.20157919824123383, "adv_vbench": {}}}}
{"id": "b38c66d845b9427ab3a196893c616b5d", "source": "vatex", "video_id": "Ua7qoMG0aBU_000504_000514", "video_description": "A boy is fishing in a muddy swamp, catching and cleaning fish using a net and stringer.", "task": "SpatialUnderstanding", "clean_prompt": "A stringer farther from the camera than a fish in a muddy swamp.", "clean_property": {"obj_1": "stringer", "relation": "farther from the camera than", "obj_2": "fish"}, "target_prompt": "A stringer closer to the camera than a fish in a muddy swamp.", "target_property": {"obj_1": "stringer", "relation": "closer to the camera than", "obj_2": "fish"}, "evaluation_question": "Is the stringer **farther from the camera than** the fish?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A stringer farther from the camera than a fish in a muddy swamp. ,2BC$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/81a3ba920b78408ea04ab6a8f2e6281e.mp4", "clean_score": 1.0, "clean_xclip": 0.22597579658031464, "clean_vbench": {"subject_consistency": 0.9359778488675753, "background_consistency": 0.943695068359375, "motion_smoothness": 0.9755048672889938, "aesthetic_quality": 0.49376046657562256, "imaging_quality": 0.6217688478742327, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1ddcc20f00fb4682b8d01b1978b9e4e2.mp4", "adv_score": 0.0, "adv_xclip": 0.21649715304374695, "adv_vbench": {"subject_consistency": 0.9593665966143211, "background_consistency": 0.9600728352864584, "motion_smoothness": 0.9878681417622348, "aesthetic_quality": 0.4440041184425354, "imaging_quality": 0.5457536097935268, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/525f07a6.mp4", "clean_score": 0.0, "clean_xclip": 0.19271308183670044, "clean_vbench": {}, "adv_vid_id": "vids/d2ae6b07.mp4", "adv_score": 0.0, "adv_xclip": 0.18632736802101135, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0e8184a6.mp4", "clean_score": 0.0, "clean_xclip": 0.20481178164482117, "clean_vbench": {}, "adv_vid_id": "vids/3a1fb58a.mp4", "adv_score": 0.0, "adv_xclip": 0.21875984966754913, "adv_vbench": {}}}}
{"id": "84239aea57564314a27e18fd222eabc1", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "Counting", "clean_prompt": "Two people playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "Four people playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **two** people playing laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two people playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain. apartament inseamna compte Craciun capacitate", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4de628857ee441ebb179ba612c6d415c.mp4", "clean_score": 1.0, "clean_xclip": 0.19650869071483612, "clean_vbench": {"subject_consistency": 0.893225093682607, "background_consistency": 0.9238739013671875, "motion_smoothness": 0.9529078556190994, "aesthetic_quality": 0.41674095392227173, "imaging_quality": 0.6201336413013692, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c5632ac2d28c4b60a8c750eac4ef7b8a.mp4", "adv_score": 0.0, "adv_xclip": 0.2578008770942688, "adv_vbench": {"subject_consistency": 0.8779588465889295, "background_consistency": 0.91796875, "motion_smoothness": 0.9500556851019729, "aesthetic_quality": 0.44202926754951477, "imaging_quality": 0.6062920037094428, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/aeceb771.mp4", "clean_score": 1.0, "clean_xclip": 0.25103485584259033, "clean_vbench": {}, "adv_vid_id": "vids/89ac5985.mp4", "adv_score": 1.0, "adv_xclip": 0.1897592693567276, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9a6fc2cc.mp4", "clean_score": 0.0, "clean_xclip": 0.173383891582489, "clean_vbench": {}, "adv_vid_id": "vids/afb8ca8d.mp4", "adv_score": 1.0, "adv_xclip": 0.19776800274848938, "adv_vbench": {}}}}
{"id": "4e7e3532775e434ea3bf24a1ddd096e0", "source": "vatex", "video_id": "sGxujaBZWEI_000001_000011", "video_description": "A man is performing deadlifts in a busy gym, lifting a barbell with heavy weights up to his thighs and then lowering it back down in multiple repetitions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a barbell in a busy gym.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "barbell"}, "target_prompt": "A person further from the camera than a barbell in a busy gym.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "barbell"}, "evaluation_question": "Is the person **closer to the camera** than the barbell?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a barbell in a busy gym. SL2\u00b7@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c627b54078544950a81b5a10f92f6fe1.mp4", "clean_score": 1.0, "clean_xclip": 0.13754785060882568, "clean_vbench": {"subject_consistency": 0.8195831511790553, "background_consistency": 0.9235687255859375, "motion_smoothness": 0.9785212125166425, "aesthetic_quality": 0.3898203372955322, "imaging_quality": 0.20780486340425453, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a92e819b36e84285acbad5bd5a6e4676.mp4", "adv_score": 0.0, "adv_xclip": 0.09470665454864502, "adv_vbench": {"subject_consistency": 0.7698177481070161, "background_consistency": 0.9183095296223959, "motion_smoothness": 0.9892597736625515, "aesthetic_quality": 0.31711146235466003, "imaging_quality": 0.14304116424249144, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5b0c9868.mp4", "clean_score": 1.0, "clean_xclip": 0.10979225486516953, "clean_vbench": {}, "adv_vid_id": "vids/5e0b0deb.mp4", "adv_score": 1.0, "adv_xclip": 0.18463441729545593, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1aecebe0.mp4", "clean_score": 1.0, "clean_xclip": 0.15486262738704681, "clean_vbench": {}, "adv_vid_id": "vids/6c5f5edf.mp4", "adv_score": 1.0, "adv_xclip": 0.1545524299144745, "adv_vbench": {}}}}
{"id": "92dee3ee84eb49dab08541ba0cac51f0", "source": "vatex", "video_id": "8vkNr_eysXY_000002_000012", "video_description": "A man is demonstrating how to cut a pineapple in a decorative fashion at a produce stand.", "task": "Counting", "clean_prompt": "Four people are gathered around a produce stand, watching a man demonstrate how to cut a pineapple in a decorative fashion.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is at a produce stand, demonstrating how to cut a pineapple in a decorative fashion.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people at the produce stand?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Four people are gathered around a produce stand, watching a man demonstrate how to cut a pineapple in a decorative fashion. Hund Wirtschafts Veranstalterheiz plage", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/539faaa5f2a14f6684f350b8aad158e4.mp4", "clean_score": 1.0, "clean_xclip": 0.26652437448501587, "clean_vbench": {"subject_consistency": 0.9852975433071455, "background_consistency": 0.96392822265625, "motion_smoothness": 0.9736533621550472, "aesthetic_quality": 0.6158326864242554, "imaging_quality": 0.7576539331552934, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0175d3ee972644ed836ac9055a171c99.mp4", "adv_score": 0.0, "adv_xclip": 0.2684088945388794, "adv_vbench": {"subject_consistency": 0.9788803681731224, "background_consistency": 0.9584147135416666, "motion_smoothness": 0.9670470756235879, "aesthetic_quality": 0.6431801915168762, "imaging_quality": 0.7681439753941127, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2bea7f07.mp4", "clean_score": 1.0, "clean_xclip": 0.2571364641189575, "clean_vbench": {}, "adv_vid_id": "vids/e03ef565.mp4", "adv_score": 1.0, "adv_xclip": 0.2380405217409134, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9dedb01b.mp4", "clean_score": 1.0, "clean_xclip": 0.27824968099594116, "clean_vbench": {}, "adv_vid_id": "vids/1df84a31.mp4", "adv_score": 1.0, "adv_xclip": 0.24740874767303467, "adv_vbench": {}}}}
{"id": "b0d32c4bbaab4dffb7bc1ca625813245", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "ObjectRecognition", "clean_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "person"}, "target_prompt": "A woman is standing in the street using a sledge hammer to break up thick ice on the ground.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground. #GG.I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4f34090293b84ecd942ceea6b5a92ded.mp4", "clean_score": 1.0, "clean_xclip": 0.22530493140220642, "clean_vbench": {"subject_consistency": 0.8883486899236838, "background_consistency": 0.9467620849609375, "motion_smoothness": 0.9520445291381727, "aesthetic_quality": 0.48140934109687805, "imaging_quality": 0.6031626191431162, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3fb25c2ed4024202bb10b28a0d774698.mp4", "adv_score": 0.0, "adv_xclip": 0.209550678730011, "adv_vbench": {"subject_consistency": 0.8740105299899975, "background_consistency": 0.9246826171875, "motion_smoothness": 0.9544615819225067, "aesthetic_quality": 0.4965430200099945, "imaging_quality": 0.6036999145819216, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/75395831.mp4", "clean_score": 1.0, "clean_xclip": 0.24793463945388794, "clean_vbench": {}, "adv_vid_id": "vids/e31573b5.mp4", "adv_score": 1.0, "adv_xclip": 0.20134228467941284, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b11da25f.mp4", "clean_score": 1.0, "clean_xclip": 0.25034886598587036, "clean_vbench": {}, "adv_vid_id": "vids/67483e12.mp4", "adv_score": 1.0, "adv_xclip": 0.23795366287231445, "adv_vbench": {}}}}
{"id": "a1e2c57607914853af87d69e4e261c2f", "source": "vatex", "video_id": "4FfdMPt4ja0_000015_000025", "video_description": "A man is at a wine tasting, smelling and describing the scent of wine in a glass.", "task": "AttributeRecognition", "clean_prompt": "A man at a wine tasting, smelling and describing the scent of wine in a wine glass that contains wine.", "clean_property": {"obj": "wine glass", "attribute": "contains wine"}, "target_prompt": "A man at a wine tasting, smelling and describing the scent of wine in a wine glass that contains water.", "target_property": {"obj": "wine glass", "attribute": "contains water"}, "evaluation_question": "Does the wine glass contain **wine**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man at a wine tasting, smelling and describing the scent of wine in a wine glass that contains wine. !'G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf8704a426994f0cbabdc19b7a1fef1a.mp4", "clean_score": 1.0, "clean_xclip": 0.22012540698051453, "clean_vbench": {"subject_consistency": 0.9655846015860637, "background_consistency": 0.937286376953125, "motion_smoothness": 0.9841723755345759, "aesthetic_quality": 0.5824101567268372, "imaging_quality": 0.6197476943658323, "dynamic_degree": 1.0}, "adv_vid_id": "vids/909ec38f18ac4afaa99a9fd40a6dcc59.mp4", "adv_score": 0.0, "adv_xclip": 0.23690029978752136, "adv_vbench": {"subject_consistency": 0.9151233894129595, "background_consistency": 0.9266357421875, "motion_smoothness": 0.9857592761223574, "aesthetic_quality": 0.5097083449363708, "imaging_quality": 0.539137767869599, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e365e813.mp4", "clean_score": 1.0, "clean_xclip": 0.2505987286567688, "clean_vbench": {}, "adv_vid_id": "vids/af841c55.mp4", "adv_score": 1.0, "adv_xclip": 0.25928109884262085, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/50b3e7bf.mp4", "clean_score": 1.0, "clean_xclip": 0.24615350365638733, "clean_vbench": {}, "adv_vid_id": "vids/f06177d8.mp4", "adv_score": 1.0, "adv_xclip": 0.2720530927181244, "adv_vbench": {}}}}
{"id": "5d1cf770b5894168888bc726c29d2652", "source": "vatex", "video_id": "GJJ_5dPMZ2c_000038_000048", "video_description": "A young man wearing black is dancing enthusiastically to music in his living room, with bags on the wall.", "task": "ActionRecognition", "clean_prompt": "A person singing in a living room.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing to music in a living room.", "target_property": {"obj": "person", "action": "dancing", "target": "music"}, "evaluation_question": "Is the person **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person singing in a living room. WQW%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/996422e2ab64456d8a15d3441dab3845.mp4", "clean_score": 1.0, "clean_xclip": 0.11084184795618057, "clean_vbench": {"subject_consistency": 0.9158784157286087, "background_consistency": 0.9196319580078125, "motion_smoothness": 0.9777756459354575, "aesthetic_quality": 0.434073269367218, "imaging_quality": 0.42028880683743225, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4b29533858754a899eab3460005dc524.mp4", "adv_score": 0.0, "adv_xclip": 0.07238835096359253, "adv_vbench": {"subject_consistency": 0.8701671535770098, "background_consistency": 0.9280751546223959, "motion_smoothness": 0.9788036739805234, "aesthetic_quality": 0.43054163455963135, "imaging_quality": 0.40371100600884885, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ab9f4d13.mp4", "clean_score": 1.0, "clean_xclip": 0.1461963951587677, "clean_vbench": {}, "adv_vid_id": "vids/3c3fe3c2.mp4", "adv_score": 1.0, "adv_xclip": 0.16186140477657318, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c1c16171.mp4", "clean_score": 1.0, "clean_xclip": 0.1587388813495636, "clean_vbench": {}, "adv_vid_id": "vids/5a902579.mp4", "adv_score": 1.0, "adv_xclip": 0.15215115249156952, "adv_vbench": {}}}}
{"id": "39f9c3193e024b71a3eca26590e2b40a", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "Counting", "clean_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching. !'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fb4e01d1ce3494c867c0373a263ea6d.mp4", "clean_score": 1.0, "clean_xclip": 0.20295044779777527, "clean_vbench": {"subject_consistency": 0.9290519822388887, "background_consistency": 0.9426320393880209, "motion_smoothness": 0.974932345092744, "aesthetic_quality": 0.43521764874458313, "imaging_quality": 0.6105633607202647, "dynamic_degree": 1.0}, "adv_vid_id": "vids/36ac06600aa341d7b203591a18661e1c.mp4", "adv_score": 0.0, "adv_xclip": 0.16014748811721802, "adv_vbench": {"subject_consistency": 0.9263795614242554, "background_consistency": 0.9489491780598959, "motion_smoothness": 0.9770303617717663, "aesthetic_quality": 0.45351704955101013, "imaging_quality": 0.7208065468924386, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/42b3cf4f.mp4", "clean_score": 0.0, "clean_xclip": 0.09429167211055756, "clean_vbench": {}, "adv_vid_id": "vids/381a8b06.mp4", "adv_score": 0.0, "adv_xclip": 0.04841551184654236, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4652dd6b.mp4", "clean_score": 0.0, "clean_xclip": 0.13377580046653748, "clean_vbench": {}, "adv_vid_id": "vids/ec9a16fb.mp4", "adv_score": 0.0, "adv_xclip": 0.19009633362293243, "adv_vbench": {}}}}
{"id": "776911d7d25f48e79137f79217376dff", "source": "vatex", "video_id": "mF2aRYdBxcU_000062_000072", "video_description": "A person is riding a longboard skateboard on a paved road, recording the experience from a first-person point of view with music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A person riding a longboard skateboard on a paved road, recording the experience from a first-person point of view with music playing in the background.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running alongside a paved road, with a first-person perspective and music playing in the background.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person riding a longboard skateboard on a paved road, recording the experience from a first-person point of view with music playing in the background.KonzernJahr companie Sortimentvedem", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/69ff5dfe08d24f07a6520823d88cf87a.mp4", "clean_score": 1.0, "clean_xclip": 0.2249208241701126, "clean_vbench": {"subject_consistency": 0.8912389588852724, "background_consistency": 0.9401499430338541, "motion_smoothness": 0.9521598539750262, "aesthetic_quality": 0.5221459269523621, "imaging_quality": 0.5735332481228576, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9b16a0439aa84497b7756e2a4afbaa2b.mp4", "adv_score": 0.0, "adv_xclip": 0.20037226378917694, "adv_vbench": {"subject_consistency": 0.9177338313311338, "background_consistency": 0.9298146565755209, "motion_smoothness": 0.9528285591853768, "aesthetic_quality": 0.563382089138031, "imaging_quality": 0.7029824797961177, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/940d90fc.mp4", "clean_score": 1.0, "clean_xclip": 0.15549564361572266, "clean_vbench": {}, "adv_vid_id": "vids/bcad37ab.mp4", "adv_score": 0.0, "adv_xclip": 0.17813453078269958, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/311ae46d.mp4", "clean_score": 1.0, "clean_xclip": 0.1799115389585495, "clean_vbench": {}, "adv_vid_id": "vids/3b27ab98.mp4", "adv_score": 1.0, "adv_xclip": 0.21444323658943176, "adv_vbench": {}}}}
{"id": "01ba2de6a02b4a1882f5ea78e9e414fc", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a yoga mat in a room.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a yoga mat in a room.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person closer to the camera than the yoga mat?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person closer to the camera than a yoga mat in a room. proximity reciprocApparentlyObjektruf", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7675bb67fffa4f50a7f9f7d0ae8f7c5d.mp4", "clean_score": 1.0, "clean_xclip": 0.13118280470371246, "clean_vbench": {"subject_consistency": 0.9926062077283859, "background_consistency": 0.9963836669921875, "motion_smoothness": 0.9974169131515774, "aesthetic_quality": 0.4131331443786621, "imaging_quality": 0.2762240674544354, "dynamic_degree": 0.0}, "adv_vid_id": "vids/15002274cdb84687b1148bef48e69b45.mp4", "adv_score": 0.0, "adv_xclip": 0.13142617046833038, "adv_vbench": {"subject_consistency": 0.9966011854509512, "background_consistency": 0.99627685546875, "motion_smoothness": 0.997345314485748, "aesthetic_quality": 0.4044990539550781, "imaging_quality": 0.3180464542155363, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f61ae839.mp4", "clean_score": 1.0, "clean_xclip": 0.13785260915756226, "clean_vbench": {}, "adv_vid_id": "vids/280ecc22.mp4", "adv_score": 1.0, "adv_xclip": 0.12160670012235641, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/de3f9696.mp4", "clean_score": 1.0, "clean_xclip": 0.11344064772129059, "clean_vbench": {}, "adv_vid_id": "vids/fce34959.mp4", "adv_score": 1.0, "adv_xclip": 0.10380183160305023, "adv_vbench": {}}}}
{"id": "fb7495d7acb249c19aa2097ca7b6f346", "source": "vatex", "video_id": "Grs48iK3Tik_000032_000042", "video_description": "A man is in a large tile store displaying various types of tiles and discussing installation methods.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a tile in a large tile store.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "tile"}, "target_prompt": "A person further from the camera than a tile in a large tile store.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "tile"}, "evaluation_question": "Is the person **closer to the camera than** a tile?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person closer to the camera than a tile in a large tile store. HS4T)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5d94235e479942fc8ce9f584b1b2b4fd.mp4", "clean_score": 1.0, "clean_xclip": 0.11896316707134247, "clean_vbench": {"subject_consistency": 0.9923207766065995, "background_consistency": 0.9824371337890625, "motion_smoothness": 0.9965727245534274, "aesthetic_quality": 0.3195842206478119, "imaging_quality": 0.29529034750802174, "dynamic_degree": 0.0}, "adv_vid_id": "vids/91cf304387b14c2d9add816a22a99403.mp4", "adv_score": 0.0, "adv_xclip": 0.13850392401218414, "adv_vbench": {"subject_consistency": 0.9604707956314087, "background_consistency": 0.9666086832682291, "motion_smoothness": 0.9886471785988058, "aesthetic_quality": 0.2868267893791199, "imaging_quality": 0.5538083928945113, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/81e8cbb9.mp4", "clean_score": 1.0, "clean_xclip": 0.2002277374267578, "clean_vbench": {}, "adv_vid_id": "vids/50a81a18.mp4", "adv_score": 1.0, "adv_xclip": 0.1578725278377533, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ad05e8dd.mp4", "clean_score": 1.0, "clean_xclip": 0.15781790018081665, "clean_vbench": {}, "adv_vid_id": "vids/c075af7e.mp4", "adv_score": 1.0, "adv_xclip": 0.1591351330280304, "adv_vbench": {}}}}
{"id": "3bc92afb724d47eab9ffc271a836d757", "source": "vatex", "video_id": "0m0-Q0zz_-c_000112_000122", "video_description": "A man in a suit is demonstrating how to tie a bow tie using his leg as a model, providing instructions on the proper technique.", "task": "ActionRecognition", "clean_prompt": "A person tying a bow tie using their leg as a model.", "clean_property": {"obj": "person", "action": "tying bow tie", "target": null}, "target_prompt": "A person removing a bow tie using their leg as a model.", "target_property": {"obj": "person", "action": "removing bow tie", "target": null}, "evaluation_question": "Is the person **tying** a bow tie?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person tying a bow tie using their leg as a model. !C|(-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/049da1e01ec848c19eabbbccad40c83a.mp4", "clean_score": 1.0, "clean_xclip": 0.26727187633514404, "clean_vbench": {"subject_consistency": 0.9494753299901882, "background_consistency": 0.942108154296875, "motion_smoothness": 0.9493936438097615, "aesthetic_quality": 0.404242604970932, "imaging_quality": 0.5236029348568041, "dynamic_degree": 1.0}, "adv_vid_id": "vids/527c3d403c7d41d8935f977b05010291.mp4", "adv_score": 0.0, "adv_xclip": 0.3049035966396332, "adv_vbench": {"subject_consistency": 0.906867661823829, "background_consistency": 0.9538930257161459, "motion_smoothness": 0.9609885756450214, "aesthetic_quality": 0.4520896077156067, "imaging_quality": 0.5575224094001614, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ac4811fd.mp4", "clean_score": 1.0, "clean_xclip": 0.2811826765537262, "clean_vbench": {}, "adv_vid_id": "vids/ef68ab46.mp4", "adv_score": 1.0, "adv_xclip": 0.232674703001976, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/382ed068.mp4", "clean_score": 1.0, "clean_xclip": 0.26253166794776917, "clean_vbench": {}, "adv_vid_id": "vids/c7c15ab9.mp4", "adv_score": 1.0, "adv_xclip": 0.2858705520629883, "adv_vbench": {}}}}
{"id": "3481b288e7ec43aeb5b107cbbf0b7adc", "source": "vatex", "video_id": "A3cqM3Mk2Mg_000876_000886", "video_description": "A group of people are sitting at a kitchen bar or restaurant counter, watching as a couple or staff prepare salads.", "task": "SpatialUnderstanding", "clean_prompt": "A staff member standing to the right of a counter in a kitchen bar.", "clean_property": {"obj_1": "staff", "relation": "right of", "obj_2": "counter"}, "target_prompt": "A staff member standing to the left of a counter in a kitchen bar.", "target_property": {"obj_1": "staff", "relation": "left of", "obj_2": "counter"}, "evaluation_question": "Is the staff member to the **right** of the counter?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A staff member standing to the right of a counter in a kitchen bar. -VH%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef224e2fa87b4a30bdc73983cecbe21f.mp4", "clean_score": 1.0, "clean_xclip": 0.14981424808502197, "clean_vbench": {"subject_consistency": 0.9925012749930223, "background_consistency": 0.9730631510416666, "motion_smoothness": 0.9932272293015715, "aesthetic_quality": 0.6178687810897827, "imaging_quality": 0.6494472667149135, "dynamic_degree": 0.0}, "adv_vid_id": "vids/0b19d4918af743bfaba4f394815a21c5.mp4", "adv_score": 0.0, "adv_xclip": 0.17702725529670715, "adv_vbench": {"subject_consistency": 0.9912816863507032, "background_consistency": 0.98370361328125, "motion_smoothness": 0.9954309837521685, "aesthetic_quality": 0.6496316194534302, "imaging_quality": 0.6396330969674247, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6dea0014.mp4", "clean_score": 1.0, "clean_xclip": 0.14708369970321655, "clean_vbench": {}, "adv_vid_id": "vids/b963f524.mp4", "adv_score": 1.0, "adv_xclip": 0.15387946367263794, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0d4fac8c.mp4", "clean_score": 1.0, "clean_xclip": 0.22333821654319763, "clean_vbench": {}, "adv_vid_id": "vids/4a179d30.mp4", "adv_score": 1.0, "adv_xclip": 0.1995774656534195, "adv_vbench": {}}}}
{"id": "df598df8b4e34da4820001a9b3b95fd0", "source": "vatex", "video_id": "RA90UGf5wxA_000000_000010", "video_description": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them.", "task": "Counting", "clean_prompt": "Five women laughing at two men dancing on a windy and icy street.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman laughing at two men dancing on a windy and icy street.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women laughing at the men?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women laughing at two men dancing on a windy and icy street. LYT)1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1901cff2b79849f29ae2ee133d4e9caf.mp4", "clean_score": 1.0, "clean_xclip": 0.2114962488412857, "clean_vbench": {"subject_consistency": 0.9335664498309294, "background_consistency": 0.9260609944661459, "motion_smoothness": 0.9430232072477911, "aesthetic_quality": 0.6140631437301636, "imaging_quality": 0.5698676790509904, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e6b9f28798714972bd00e3cb60b1a226.mp4", "adv_score": 0.0, "adv_xclip": 0.20644240081310272, "adv_vbench": {"subject_consistency": 0.9514815142999092, "background_consistency": 0.9538116455078125, "motion_smoothness": 0.9360579764345296, "aesthetic_quality": 0.5638623237609863, "imaging_quality": 0.6642038337551817, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/21e1509c.mp4", "clean_score": 1.0, "clean_xclip": 0.23778775334358215, "clean_vbench": {}, "adv_vid_id": "vids/a4f24b59.mp4", "adv_score": 0.0, "adv_xclip": 0.29134654998779297, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b587cccb.mp4", "clean_score": 1.0, "clean_xclip": 0.2240598201751709, "clean_vbench": {}, "adv_vid_id": "vids/192b2d53.mp4", "adv_score": 1.0, "adv_xclip": 0.22303278744220734, "adv_vbench": {}}}}
{"id": "e7ebca3acd9a477890035e4c438cc703", "source": "vatex", "video_id": "7GRLn6bWI0c_000005_000015", "video_description": "A woman is training her dog indoors, teaching it various commands such as sit, stay, stand, and lay.", "task": "Counting", "clean_prompt": "A woman is training two dogs indoors, teaching them various commands such as sit, stay, stand, and lay.", "clean_property": {"obj": "dog", "count": "two"}, "target_prompt": "A woman is training one dog indoors, teaching it various commands such as sit, stay, stand, and lay.", "target_property": {"obj": "dog", "count": "one"}, "evaluation_question": "Are there exactly **two** dogs being trained indoors?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman is training two dogs indoors, teaching them various commands such as sit, stay, stand, and lay. Polizeiunui Heim antren darunter", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cffe7e256a244337b5e337f04e58fb9f.mp4", "clean_score": 1.0, "clean_xclip": 0.1991707682609558, "clean_vbench": {"subject_consistency": 0.9502947001407543, "background_consistency": 0.9675496419270834, "motion_smoothness": 0.9824105232981823, "aesthetic_quality": 0.437822163105011, "imaging_quality": 0.5704762960939991, "dynamic_degree": 1.0}, "adv_vid_id": "vids/269e05840b124d79a2f571a1d73a0904.mp4", "adv_score": 0.0, "adv_xclip": 0.18555185198783875, "adv_vbench": {"subject_consistency": 0.9538481657703718, "background_consistency": 0.9585367838541666, "motion_smoothness": 0.9841160690195574, "aesthetic_quality": 0.38427257537841797, "imaging_quality": 0.6010600747867506, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/381a295b.mp4", "clean_score": 1.0, "clean_xclip": 0.19859763979911804, "clean_vbench": {}, "adv_vid_id": "vids/2baa6607.mp4", "adv_score": 1.0, "adv_xclip": 0.2071312963962555, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/888b55e2.mp4", "clean_score": 1.0, "clean_xclip": 0.1988363265991211, "clean_vbench": {}, "adv_vid_id": "vids/b48f788c.mp4", "adv_score": 1.0, "adv_xclip": 0.209255188703537, "adv_vbench": {}}}}
{"id": "c7c4ef3f10be40a0ac4082f16b76b197", "source": "vatex", "video_id": "ZL73Rek4-ds_000838_000848", "video_description": "A young girl in an orange jacket is using a smartphone, singing and talking to herself while texting.", "task": "Counting", "clean_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting.", "clean_property": {"obj": "girl", "count": "seven"}, "target_prompt": "Four girls in blue jackets are using tablets, dancing and laughing together.", "target_property": {"obj": "girl", "count": "four"}, "evaluation_question": "Are there exactly **seven** girls in orange jackets using smartphones?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting. OC|FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3f9a30e5092c438ba747ce8d1ff2c73a.mp4", "clean_score": 1.0, "clean_xclip": 0.1822759360074997, "clean_vbench": {"subject_consistency": 0.9745612548043331, "background_consistency": 0.9809672037760416, "motion_smoothness": 0.9683583149888041, "aesthetic_quality": 0.604724109172821, "imaging_quality": 0.7517033884476642, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a8be96c3d7664a7c811c2067bcded436.mp4", "adv_score": 0.0, "adv_xclip": 0.16562336683273315, "adv_vbench": {"subject_consistency": 0.9741313823809227, "background_consistency": 0.9650065104166666, "motion_smoothness": 0.9735450879843964, "aesthetic_quality": 0.5521798133850098, "imaging_quality": 0.7556102285579759, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3182e4eb.mp4", "clean_score": 0.0, "clean_xclip": 0.1557924449443817, "clean_vbench": {}, "adv_vid_id": "vids/9c64b639.mp4", "adv_score": 0.0, "adv_xclip": 0.1794821321964264, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9151f030.mp4", "clean_score": 0.0, "clean_xclip": 0.17851591110229492, "clean_vbench": {}, "adv_vid_id": "vids/8e29d597.mp4", "adv_score": 0.0, "adv_xclip": 0.23461806774139404, "adv_vbench": {}}}}
{"id": "a7287e3741894a049eb95fc16855d394", "source": "vatex", "video_id": "dvWWg9wCWY4_000209_000219", "video_description": "A group of people, including children and adults, are climbing and descending a rock climbing wall outdoors at a recreational site.", "task": "AttributeRecognition", "clean_prompt": "A person climbing a rock climbing wall with children and adults outdoors.", "clean_property": {"obj": "person", "attribute": "children"}, "target_prompt": "A person climbing indoors.", "target_property": {"obj": "person", "attribute": "climbing indoors"}, "evaluation_question": "Is the person climbing a rock climbing wall **outdoors**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person climbing a rock climbing wall with children and adults outdoors. =^TZ:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7b2ab651bb854a05bb5b2d79fa2aa5d9.mp4", "clean_score": 1.0, "clean_xclip": 0.2167867124080658, "clean_vbench": {"subject_consistency": 0.9260456655174494, "background_consistency": 0.9544474283854166, "motion_smoothness": 0.9826953216407447, "aesthetic_quality": 0.44455763697624207, "imaging_quality": 0.6807695879255022, "dynamic_degree": 1.0}, "adv_vid_id": "vids/29b6fb8a45014c609754971b3d57cc99.mp4", "adv_score": 0.0, "adv_xclip": 0.2152944952249527, "adv_vbench": {"subject_consistency": 0.9503534659743309, "background_consistency": 0.9476979573567709, "motion_smoothness": 0.9853695398233882, "aesthetic_quality": 0.4197874665260315, "imaging_quality": 0.7339573793995138, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2b154694.mp4", "clean_score": 0.0, "clean_xclip": 0.21026822924613953, "clean_vbench": {}, "adv_vid_id": "vids/2b0e3ac8.mp4", "adv_score": 1.0, "adv_xclip": 0.21918633580207825, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bbb8596f.mp4", "clean_score": 1.0, "clean_xclip": 0.21554449200630188, "clean_vbench": {}, "adv_vid_id": "vids/1a19254f.mp4", "adv_score": 1.0, "adv_xclip": 0.2288931906223297, "adv_vbench": {}}}}
{"id": "4f2629e13fd7406cba4a1082f59e3eb5", "source": "vatex", "video_id": "dvWWg9wCWY4_000209_000219", "video_description": "A group of people, including children and adults, are climbing and descending a rock climbing wall outdoors at a recreational site.", "task": "AttributeRecognition", "clean_prompt": "A person climbing a rock climbing wall with children and adults outdoors.", "clean_property": {"obj": "person", "attribute": "children"}, "target_prompt": "A person climbing indoors.", "target_property": {"obj": "person", "attribute": "climbing indoors"}, "evaluation_question": "Is the person climbing a rock climbing wall **outdoors**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person climbing a rock climbing wall with children and adults outdoors. confortable parcare gegen analize Komfort", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/69ccde5e73ef42b285019b39f592fd59.mp4", "clean_score": 1.0, "clean_xclip": 0.2167867124080658, "clean_vbench": {"subject_consistency": 0.9260456655174494, "background_consistency": 0.9544474283854166, "motion_smoothness": 0.9826953216407447, "aesthetic_quality": 0.44455763697624207, "imaging_quality": 0.6807695879255022, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d9f11200b8574681a19cf659f494ef9e.mp4", "adv_score": 0.0, "adv_xclip": 0.2223188877105713, "adv_vbench": {"subject_consistency": 0.9622242661813895, "background_consistency": 0.9592742919921875, "motion_smoothness": 0.9869569450433208, "aesthetic_quality": 0.41538503766059875, "imaging_quality": 0.7001072256905693, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/438b94b0.mp4", "clean_score": 1.0, "clean_xclip": 0.2066793143749237, "clean_vbench": {}, "adv_vid_id": "vids/68dd88e8.mp4", "adv_score": 1.0, "adv_xclip": 0.2260013222694397, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/60a9e492.mp4", "clean_score": 1.0, "clean_xclip": 0.2049441635608673, "clean_vbench": {}, "adv_vid_id": "vids/a8964768.mp4", "adv_score": 1.0, "adv_xclip": 0.21424543857574463, "adv_vbench": {}}}}
{"id": "0ec1af79b9ea448ea3372c15cc294719", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "AttributeRecognition", "clean_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "ice", "attribute": "thick"}, "target_prompt": "A man is standing in the street using a sledge hammer to break up thin ice on the ground.", "target_property": {"obj": "ice", "attribute": "thin"}, "evaluation_question": "Is the ice **thick** on the ground?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground. Beschreibung Versailles Southampton venit Grecia", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aabce3cad9cb4f009f0f7cded79f64f1.mp4", "clean_score": 1.0, "clean_xclip": 0.22530493140220642, "clean_vbench": {"subject_consistency": 0.8883486899236838, "background_consistency": 0.9467620849609375, "motion_smoothness": 0.9520445291381727, "aesthetic_quality": 0.48140934109687805, "imaging_quality": 0.6031626191431162, "dynamic_degree": 1.0}, "adv_vid_id": "vids/42d0e848d592480d9c9aaf29150c761b.mp4", "adv_score": 0.0, "adv_xclip": 0.2396453320980072, "adv_vbench": {"subject_consistency": 0.8940272331237793, "background_consistency": 0.9171854654947916, "motion_smoothness": 0.9667114749127532, "aesthetic_quality": 0.47604039311408997, "imaging_quality": 0.6641706855929628, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/edda071e.mp4", "clean_score": 1.0, "clean_xclip": 0.23009023070335388, "clean_vbench": {}, "adv_vid_id": "vids/308a485c.mp4", "adv_score": 1.0, "adv_xclip": 0.2275966852903366, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cc114319.mp4", "clean_score": 1.0, "clean_xclip": 0.24034078419208527, "clean_vbench": {}, "adv_vid_id": "vids/642c899b.mp4", "adv_score": 0.0, "adv_xclip": 0.23429721593856812, "adv_vbench": {}}}}
{"id": "1de02900d73545c79f2439c2d9e82496", "source": "vatex", "video_id": "3OJasCVIqrM_000016_000026", "video_description": "A young girl with glasses is in her bedroom, talking to the camera while applying orange lip gloss.", "task": "Counting", "clean_prompt": "A young girl with glasses is in her bedroom, talking to the camera while applying two lip glosses.", "clean_property": {"obj": "lip gloss", "count": "two"}, "target_prompt": "A young girl with glasses is in her bedroom, talking to the camera while applying one lip gloss.", "target_property": {"obj": "lip gloss", "count": "one"}, "evaluation_question": "Is the girl applying exactly **two** lip glosses?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young girl with glasses is in her bedroom, talking to the camera while applying two lip glosses. mica Kinder libre Klispiele", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/32894500df0140528711f22a61c4fa79.mp4", "clean_score": 1.0, "clean_xclip": 0.20506413280963898, "clean_vbench": {"subject_consistency": 0.8941122305889925, "background_consistency": 0.9043477376302084, "motion_smoothness": 0.966919628425573, "aesthetic_quality": 0.49384424090385437, "imaging_quality": 0.7017262517189493, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c1c4c09402624a398902a6b3a1aa9f9a.mp4", "adv_score": 0.0, "adv_xclip": 0.18804608285427094, "adv_vbench": {"subject_consistency": 0.9586498383432627, "background_consistency": 0.9409434000651041, "motion_smoothness": 0.9778399017464496, "aesthetic_quality": 0.5010768175125122, "imaging_quality": 0.6995874537253866, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/802978ef.mp4", "clean_score": 1.0, "clean_xclip": 0.20640778541564941, "clean_vbench": {}, "adv_vid_id": "vids/2ae238e0.mp4", "adv_score": 0.0, "adv_xclip": 0.17296136915683746, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fafd20d2.mp4", "clean_score": 0.0, "clean_xclip": 0.22542870044708252, "clean_vbench": {}, "adv_vid_id": "vids/c608db28.mp4", "adv_score": 1.0, "adv_xclip": 0.21972280740737915, "adv_vbench": {}}}}
{"id": "442d718d5c4c42dabb7b93b509f3aa86", "source": "vatex", "video_id": "t9A0ceBCzng_000004_000014", "video_description": "A man is sitting at a table playing a stringed instrument, possibly a lute or an odd-shaped guitar.", "task": "ActionRecognition", "clean_prompt": "A person playing guitar at a table.", "clean_property": {"obj": "person", "action": "playing guitar", "target": null}, "target_prompt": "A person singing at a table.", "target_property": {"obj": "person", "action": "singing", "target": null}, "evaluation_question": "Is the person **playing guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing guitar at a table. Domino footage RBI Brussels jeux", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/81e47b5e767444809961f3840d0f196c.mp4", "clean_score": 1.0, "clean_xclip": 0.19399608671665192, "clean_vbench": {"subject_consistency": 0.9776568996409575, "background_consistency": 0.9724171956380209, "motion_smoothness": 0.9549941759271867, "aesthetic_quality": 0.4874907433986664, "imaging_quality": 0.32574091619374795, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d2ae25f4cac5469ea298c3976d539906.mp4", "adv_score": 0.0, "adv_xclip": 0.15829086303710938, "adv_vbench": {"subject_consistency": 0.9851334250221649, "background_consistency": 0.9724680582682291, "motion_smoothness": 0.9629694164863734, "aesthetic_quality": 0.38302528858184814, "imaging_quality": 0.5484690522174446, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/94b89bf2.mp4", "clean_score": 1.0, "clean_xclip": 0.21392279863357544, "clean_vbench": {}, "adv_vid_id": "vids/713538c8.mp4", "adv_score": 1.0, "adv_xclip": 0.2126520574092865, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/58d5fecd.mp4", "clean_score": 1.0, "clean_xclip": 0.2083282172679901, "clean_vbench": {}, "adv_vid_id": "vids/6580d0aa.mp4", "adv_score": 1.0, "adv_xclip": 0.18650509417057037, "adv_vbench": {}}}}
{"id": "0eb129e04ed24e41b4316d0e3ecfec52", "source": "vatex", "video_id": "OOxphqMuui8_000011_000021", "video_description": "A sushi chef is preparing sushi in a kitchen, using fresh ingredients and wearing gloves.", "task": "ActionRecognition", "clean_prompt": "A chef making sushi in a kitchen.", "clean_property": {"obj": "chef", "action": "making sushi", "target": null}, "target_prompt": "A chef baking pizza in a kitchen.", "target_property": {"obj": "chef", "action": "baking pizza", "target": null}, "evaluation_question": "Is the chef **making sushi**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A chef making sushi in a kitchen. Einladung limba chiar Carnegie pizza", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d8e063468c7740e1b77b77a21ecbb25f.mp4", "clean_score": 1.0, "clean_xclip": 0.2361239194869995, "clean_vbench": {"subject_consistency": 0.941284816712141, "background_consistency": 0.965118408203125, "motion_smoothness": 0.9636107949674211, "aesthetic_quality": 0.47849756479263306, "imaging_quality": 0.6126772868876554, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2c1deeb4f8d64c2eb71cb72d3f03ec46.mp4", "adv_score": 0.0, "adv_xclip": 0.11677715182304382, "adv_vbench": {"subject_consistency": 0.9540402386337519, "background_consistency": 0.9765726725260416, "motion_smoothness": 0.9673328510802469, "aesthetic_quality": 0.5654801726341248, "imaging_quality": 0.6543741522029954, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/266af7f0.mp4", "clean_score": 1.0, "clean_xclip": 0.2453121691942215, "clean_vbench": {}, "adv_vid_id": "vids/fd19f36b.mp4", "adv_score": 1.0, "adv_xclip": 0.23956763744354248, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3952c262.mp4", "clean_score": 1.0, "clean_xclip": 0.24404355883598328, "clean_vbench": {}, "adv_vid_id": "vids/a07cff6b.mp4", "adv_score": 0.0, "adv_xclip": 0.13053980469703674, "adv_vbench": {}}}}
{"id": "2152ac04b4244be69ea04730ac6a7ddd", "source": "vatex", "video_id": "dbJujs8UPFI_000000_000010", "video_description": "A young man in a turquoise shirt is practicing knife throwing in a field or park-like area. He runs, jumps, and throws a knife at a wooden target, celebrating when he hits the target.", "task": "Counting", "clean_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice.", "clean_property": {"obj": "target", "count": "two"}, "target_prompt": "A young man in a turquoise shirt is practicing knife throwing at a single wooden target in a park.", "target_property": {"obj": "target", "count": "one"}, "evaluation_question": "Are there exactly **two** targets in the park?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice. SBSFB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/104bfaf77f374472b2c28ceae0bae0e0.mp4", "clean_score": 1.0, "clean_xclip": 0.1761873960494995, "clean_vbench": {"subject_consistency": 0.9077905019124349, "background_consistency": 0.8987172444661459, "motion_smoothness": 0.9423549043878097, "aesthetic_quality": 0.44580331444740295, "imaging_quality": 0.5894841634010782, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f28f981498b44fa4bce178d79f0b0be9.mp4", "adv_score": 0.0, "adv_xclip": 0.20632706582546234, "adv_vbench": {"subject_consistency": 0.9046748845527569, "background_consistency": 0.896942138671875, "motion_smoothness": 0.9538370930162189, "aesthetic_quality": 0.4434017837047577, "imaging_quality": 0.5414740472910355, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/08a4fffa.mp4", "clean_score": 0.0, "clean_xclip": 0.1754666417837143, "clean_vbench": {}, "adv_vid_id": "vids/de12fffe.mp4", "adv_score": 0.0, "adv_xclip": 0.17018017172813416, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4a19d677.mp4", "clean_score": 0.0, "clean_xclip": 0.18341943621635437, "clean_vbench": {}, "adv_vid_id": "vids/c9a65a57.mp4", "adv_score": 0.0, "adv_xclip": 0.17325034737586975, "adv_vbench": {}}}}
{"id": "6a4e959f3a3a42cf86eeb0edc095d9f9", "source": "vatex", "video_id": "lCea4HWl1Cs_000225_000235", "video_description": "Two men are playing badminton indoors on a green court, wearing blue shirts. They hit a shuttlecock back and forth over a net.", "task": "SpatialUnderstanding", "clean_prompt": "A net positioned to the left of a player on a green badminton court.", "clean_property": {"obj_1": "net", "relation": "left of", "obj_2": "player"}, "target_prompt": "A net positioned to the right of a player on a green badminton court.", "target_property": {"obj_1": "net", "relation": "right of", "obj_2": "player"}, "evaluation_question": "Is the net to the **left** of the player?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A net positioned to the left of a player on a green badminton court. PD\\LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4cf57a4791834153a86a02f6dc262eaf.mp4", "clean_score": 1.0, "clean_xclip": 0.19534829258918762, "clean_vbench": {"subject_consistency": 0.9656869204094013, "background_consistency": 0.9341684977213541, "motion_smoothness": 0.9887603303023885, "aesthetic_quality": 0.4538457691669464, "imaging_quality": 0.6393637046035455, "dynamic_degree": 0.0}, "adv_vid_id": "vids/37a32403ac7a452ebca8dbf571ee3e6c.mp4", "adv_score": 0.0, "adv_xclip": 0.219070166349411, "adv_vbench": {"subject_consistency": 0.967890128493309, "background_consistency": 0.9385732014973959, "motion_smoothness": 0.9868526377983035, "aesthetic_quality": 0.3966121971607208, "imaging_quality": 0.5983035254965023, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ae01c521.mp4", "clean_score": 0.0, "clean_xclip": 0.14953511953353882, "clean_vbench": {}, "adv_vid_id": "vids/e7c1f6dd.mp4", "adv_score": 0.0, "adv_xclip": 0.22257499396800995, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/20cfc68d.mp4", "clean_score": 0.0, "clean_xclip": 0.18631258606910706, "clean_vbench": {}, "adv_vid_id": "vids/d8295b1d.mp4", "adv_score": 0.0, "adv_xclip": 0.1786714494228363, "adv_vbench": {}}}}
{"id": "99cea6569dff440188d2b6cdeec15738", "source": "vatex", "video_id": "qW57bMrrA8M_000000_000010", "video_description": "A man wearing a black hat is in a cluttered room, yawning multiple times while listening to music.", "task": "Counting", "clean_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are sitting in a cluttered room, yawning multiple times while listening to music.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music. ?BV@H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf37709b0e834b479689ff10297dbc1c.mp4", "clean_score": 1.0, "clean_xclip": 0.132634237408638, "clean_vbench": {"subject_consistency": 0.937743234137694, "background_consistency": 0.958984375, "motion_smoothness": 0.9879503528327483, "aesthetic_quality": 0.5130073428153992, "imaging_quality": 0.5342679775004484, "dynamic_degree": 0.0}, "adv_vid_id": "vids/19f2df8517244f299602a5fd7df68690.mp4", "adv_score": 0.0, "adv_xclip": 0.1317588835954666, "adv_vbench": {"subject_consistency": 0.9594949347277483, "background_consistency": 0.9484659830729166, "motion_smoothness": 0.9870762193123134, "aesthetic_quality": 0.45129600167274475, "imaging_quality": 0.6617193533449757, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/676a3568.mp4", "clean_score": 0.0, "clean_xclip": 0.1535380333662033, "clean_vbench": {}, "adv_vid_id": "vids/461e32ed.mp4", "adv_score": 1.0, "adv_xclip": 0.15714947879314423, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/10d251c5.mp4", "clean_score": 0.0, "clean_xclip": 0.13779321312904358, "clean_vbench": {}, "adv_vid_id": "vids/43d9c56d.mp4", "adv_score": 0.0, "adv_xclip": 0.11573383212089539, "adv_vbench": {}}}}
{"id": "2c952ab4b7b94bc19e9d000c23362c60", "source": "vatex", "video_id": "KLc4My5e80I_000012_000022", "video_description": "A man attempts to drink a flaming shot, resulting in his face catching fire.", "task": "SpatialUnderstanding", "clean_prompt": "A coke bottle closer to the camera than a flaming shot.", "clean_property": {"obj_1": "coke bottle", "relation": "closer to the camera than", "obj_2": "flaming shot"}, "target_prompt": "A coke bottle further from the camera than a flaming shot.", "target_property": {"obj_1": "coke bottle", "relation": "further from the camera than", "obj_2": "flaming shot"}, "evaluation_question": "Is the coke bottle **closer to the camera than** the flaming shot?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A coke bottle closer to the camera than a flaming shot. )))'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfd01783783c452fbd94b25de810c379.mp4", "clean_score": 1.0, "clean_xclip": 0.19087453186511993, "clean_vbench": {"subject_consistency": 0.6370427906513214, "background_consistency": 0.9098765055338541, "motion_smoothness": 0.9695591546450112, "aesthetic_quality": 0.32742083072662354, "imaging_quality": 0.1797473666132713, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f3a4fb0f9a4e41e1bcf803082ff5890b.mp4", "adv_score": 0.0, "adv_xclip": 0.16972237825393677, "adv_vbench": {"subject_consistency": 0.7515555076921979, "background_consistency": 0.8951619466145834, "motion_smoothness": 0.975432796614016, "aesthetic_quality": 0.4304221272468567, "imaging_quality": 0.2801450604808574, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7dad809a.mp4", "clean_score": 0.0, "clean_xclip": 0.25360041856765747, "clean_vbench": {}, "adv_vid_id": "vids/167271e1.mp4", "adv_score": 1.0, "adv_xclip": 0.2082464098930359, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/762fc4b9.mp4", "clean_score": 1.0, "clean_xclip": 0.2391420602798462, "clean_vbench": {}, "adv_vid_id": "vids/c7ed5bbd.mp4", "adv_score": 1.0, "adv_xclip": 0.20393799245357513, "adv_vbench": {}}}}
{"id": "dac1acde8f10421486ad4e4f0a885ef5", "source": "vatex", "video_id": "k3WbOqW3GQU_000024_000034", "video_description": "Medieval music plays as photos of the Renaissance Era are displayed, featuring people in historical costumes playing string instruments.", "task": "ActionRecognition", "clean_prompt": "A person singing while historical photos of the Renaissance Era are displayed.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing while historical photos of the Renaissance Era are displayed.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person singing while historical photos of the Renaissance Era are displayed. U%4A/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/928167ed79ae492fa7baa3557418c24a.mp4", "clean_score": 1.0, "clean_xclip": 0.18400171399116516, "clean_vbench": {"subject_consistency": 0.9754180535674095, "background_consistency": 0.9586588541666666, "motion_smoothness": 0.9918212700718148, "aesthetic_quality": 0.5886340737342834, "imaging_quality": 0.516064794112225, "dynamic_degree": 0.0}, "adv_vid_id": "vids/6eb4bc0883f64fd6921557bbda0a2e50.mp4", "adv_score": 0.0, "adv_xclip": 0.17016370594501495, "adv_vbench": {"subject_consistency": 0.9746642373502254, "background_consistency": 0.9493255615234375, "motion_smoothness": 0.9870719953426329, "aesthetic_quality": 0.5843214392662048, "imaging_quality": 0.5215773477359693, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/efe3adea.mp4", "clean_score": 1.0, "clean_xclip": 0.1852656900882721, "clean_vbench": {}, "adv_vid_id": "vids/ded278aa.mp4", "adv_score": 1.0, "adv_xclip": 0.16710945963859558, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/678160a7.mp4", "clean_score": 1.0, "clean_xclip": 0.20944161713123322, "clean_vbench": {}, "adv_vid_id": "vids/8ffaf2b8.mp4", "adv_score": 1.0, "adv_xclip": 0.20637750625610352, "adv_vbench": {}}}}
{"id": "9a00a6774a124fdebb660285f40880eb", "source": "vatex", "video_id": "6QetWvqJCkU_000023_000033", "video_description": "A man in a jean outfit and hat is dancing to music in a garage with a guitar in the background.", "task": "ObjectRecognition", "clean_prompt": "A man dancing in a garage with a guitar in the background.", "clean_property": {"obj": "guitar"}, "target_prompt": "A man dancing in a garage with a drum in the background.", "target_property": {"obj": "drum"}, "evaluation_question": "Is there a **guitar** in the background of the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man dancing in a garage with a guitar in the background. epoxyuzi ambience lieber doppelt", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9eb99f69feee4ba781a1ae85fbfc95c2.mp4", "clean_score": 1.0, "clean_xclip": 0.10474741458892822, "clean_vbench": {"subject_consistency": 0.792209280654788, "background_consistency": 0.8906707763671875, "motion_smoothness": 0.9530845643394961, "aesthetic_quality": 0.44020819664001465, "imaging_quality": 0.3020542732550173, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ff6f29171ca2477ab138ac93f4de79d4.mp4", "adv_score": 0.0, "adv_xclip": 0.11114184558391571, "adv_vbench": {"subject_consistency": 0.846338610475262, "background_consistency": 0.9092000325520834, "motion_smoothness": 0.94501014796029, "aesthetic_quality": 0.40145283937454224, "imaging_quality": 0.25310782841273716, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0b4455d5.mp4", "clean_score": 0.0, "clean_xclip": 0.12500900030136108, "clean_vbench": {}, "adv_vid_id": "vids/7bc65a06.mp4", "adv_score": 1.0, "adv_xclip": 0.227164164185524, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/91c4bb59.mp4", "clean_score": 1.0, "clean_xclip": 0.13652871549129486, "clean_vbench": {}, "adv_vid_id": "vids/b8be3951.mp4", "adv_score": 1.0, "adv_xclip": 0.1561003029346466, "adv_vbench": {}}}}
{"id": "d891032b84064537ac75d11961b02a8b", "source": "vatex", "video_id": "JSd8C0Ms-G0_000050_000060", "video_description": "A teenage girl with red hair is sitting in her bedroom, rubbing lotion on her hands while talking to the camera.", "task": "AttributeRecognition", "clean_prompt": "A teenage girl with red hair sitting in her bedroom, rubbing lotion on her hands while talking to the camera.", "clean_property": {"obj": "girl", "attribute": "teenage"}, "target_prompt": "A child with red hair sitting in a colorful playroom, playing with toys while talking to the camera.", "target_property": {"obj": "girl", "attribute": "child"}, "evaluation_question": "Is the girl a **teenager**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenage girl with red hair sitting in her bedroom, rubbing lotion on her hands while talking to the camera. SL/J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed82271c76f047829557d2e8d1ad7f8b.mp4", "clean_score": 1.0, "clean_xclip": 0.23444169759750366, "clean_vbench": {"subject_consistency": 0.9625101170192162, "background_consistency": 0.9617818196614584, "motion_smoothness": 0.9724046276754014, "aesthetic_quality": 0.36404654383659363, "imaging_quality": 0.6440122915773975, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b76f069c60734f07bb92544ba6cdedd6.mp4", "adv_score": 0.0, "adv_xclip": 0.2139786183834076, "adv_vbench": {"subject_consistency": 0.9605310565481583, "background_consistency": 0.9495035807291666, "motion_smoothness": 0.9688405438049705, "aesthetic_quality": 0.41393083333969116, "imaging_quality": 0.7013570715456592, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b071dc08.mp4", "clean_score": 1.0, "clean_xclip": 0.18250229954719543, "clean_vbench": {}, "adv_vid_id": "vids/70950f84.mp4", "adv_score": 1.0, "adv_xclip": 0.14302048087120056, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c53be3a1.mp4", "clean_score": 1.0, "clean_xclip": 0.21778512001037598, "clean_vbench": {}, "adv_vid_id": "vids/ca4d45df.mp4", "adv_score": 1.0, "adv_xclip": 0.20992377400398254, "adv_vbench": {}}}}
{"id": "eb4e03345118436384b86ba204cb47aa", "source": "vatex", "video_id": "QIAzAZmZYGc_000018_000028", "video_description": "A man with glasses and a beard is sitting in a room, possibly a computer lab or office, reading a newspaper and making various facial expressions.", "task": "ActionRecognition", "clean_prompt": "A person reading a newspaper in a room.", "clean_property": {"obj": "person", "action": "reading newspaper", "target": null}, "target_prompt": "A person throwing a newspaper in a room.", "target_property": {"obj": "person", "action": "throwing newspaper", "target": null}, "evaluation_question": "Is the person **reading** a newspaper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person reading a newspaper in a room. VT'6R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5bab47ec7c34813ac4a15938d2d77c9.mp4", "clean_score": 1.0, "clean_xclip": 0.2053026556968689, "clean_vbench": {"subject_consistency": 0.8933172275622686, "background_consistency": 0.9457855224609375, "motion_smoothness": 0.99023891684696, "aesthetic_quality": 0.5330371260643005, "imaging_quality": 0.5431708184067083, "dynamic_degree": 1.0}, "adv_vid_id": "vids/47f56bdbf45f4e4ebd04d3ebf235cee8.mp4", "adv_score": 0.0, "adv_xclip": 0.2247145175933838, "adv_vbench": {"subject_consistency": 0.9037156862517198, "background_consistency": 0.9406789143880209, "motion_smoothness": 0.9836614301231038, "aesthetic_quality": 0.431816428899765, "imaging_quality": 0.6361330464421486, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7bc4bc9f.mp4", "clean_score": 1.0, "clean_xclip": 0.22511768341064453, "clean_vbench": {}, "adv_vid_id": "vids/8d49a88a.mp4", "adv_score": 1.0, "adv_xclip": 0.21815167367458344, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9ea38bfc.mp4", "clean_score": 1.0, "clean_xclip": 0.2094351351261139, "clean_vbench": {}, "adv_vid_id": "vids/5e7ed476.mp4", "adv_score": 1.0, "adv_xclip": 0.21424686908721924, "adv_vbench": {}}}}
{"id": "b59b9f0ac1964d8ea38441c585d41c1c", "source": "vatex", "video_id": "StPYHQh2yuI_000023_000033", "video_description": "A horse auction is taking place in a large meeting hall. A man is handling a white horse on stage while an auctioneer calls for bids from the audience.", "task": "SpatialUnderstanding", "clean_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction.", "clean_property": {"obj_1": "handler", "relation": "farther from the camera than", "obj_2": "audience"}, "target_prompt": "A handler closer to the camera than the audience in a large meeting hall during a horse auction.", "target_property": {"obj_1": "handler", "relation": "closer to the camera than", "obj_2": "audience"}, "evaluation_question": "Is the handler farther from the camera than the audience?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction. )&)!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33be677c9916438a9dec43db7753fa24.mp4", "clean_score": 1.0, "clean_xclip": 0.12529468536376953, "clean_vbench": {"subject_consistency": 0.9727046253780524, "background_consistency": 0.9658355712890625, "motion_smoothness": 0.9933751471975106, "aesthetic_quality": 0.46659180521965027, "imaging_quality": 0.5563926393158581, "dynamic_degree": 0.0}, "adv_vid_id": "vids/9fb1d9ff9f9e498882e9dc674398eb2f.mp4", "adv_score": 0.0, "adv_xclip": 0.19060355424880981, "adv_vbench": {"subject_consistency": 0.9737369312594334, "background_consistency": 0.9657236735026041, "motion_smoothness": 0.9934017759206306, "aesthetic_quality": 0.41406574845314026, "imaging_quality": 0.7129962220483896, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4760dee2.mp4", "clean_score": 0.0, "clean_xclip": 0.16351234912872314, "clean_vbench": {}, "adv_vid_id": "vids/dc2313d8.mp4", "adv_score": 0.0, "adv_xclip": 0.15714749693870544, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cc8b841b.mp4", "clean_score": 0.0, "clean_xclip": 0.1513008326292038, "clean_vbench": {}, "adv_vid_id": "vids/c0cf042d.mp4", "adv_score": 0.0, "adv_xclip": 0.15797515213489532, "adv_vbench": {}}}}
{"id": "2e46cb47cb724f14a9b06215b503a30c", "source": "vatex", "video_id": "YG0iQsVufQg_000044_000054", "video_description": "A man is sitting and talking while a woman stands behind him, massaging his shoulders in a massage center.", "task": "ActionRecognition", "clean_prompt": "A woman massaging a man's neck in a massage center.", "clean_property": {"obj": "woman", "action": "massaging neck", "target": "man"}, "target_prompt": "A woman giving a facial to a man in a spa.", "target_property": {"obj": "woman", "action": "giving a facial", "target": "man"}, "evaluation_question": "Is the woman **massaging** the man's neck?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman massaging a man's neck in a massage center. .UVUJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9477454275754e15a4a034cc5123628c.mp4", "clean_score": 1.0, "clean_xclip": 0.208175927400589, "clean_vbench": {"subject_consistency": 0.9534341488033533, "background_consistency": 0.949737548828125, "motion_smoothness": 0.9842626353460623, "aesthetic_quality": 0.4578140377998352, "imaging_quality": 0.3837816253973513, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2cd34f185a75473dbae9559d15f3cd37.mp4", "adv_score": 0.0, "adv_xclip": 0.21239309012889862, "adv_vbench": {"subject_consistency": 0.9613864657779535, "background_consistency": 0.9540608723958334, "motion_smoothness": 0.9773988387471758, "aesthetic_quality": 0.41478806734085083, "imaging_quality": 0.5229121624693579, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6e3de4fc.mp4", "clean_score": 1.0, "clean_xclip": 0.15321186184883118, "clean_vbench": {}, "adv_vid_id": "vids/6f891ed6.mp4", "adv_score": 1.0, "adv_xclip": 0.20296591520309448, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5217a4d1.mp4", "clean_score": 1.0, "clean_xclip": 0.20513439178466797, "clean_vbench": {}, "adv_vid_id": "vids/80238455.mp4", "adv_score": 1.0, "adv_xclip": 0.21315689384937286, "adv_vbench": {}}}}
{"id": "141a72fcd7804b98969944446220bfae", "source": "vatex", "video_id": "hW2ZI3zp74I_000190_000200", "video_description": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night. The truck is slowly driving down a road, with workers walking around and behind it, bringing garbage cans to the back.", "task": "ActionRecognition", "clean_prompt": "A garbage truck driving down a road at night while workers collect garbage.", "clean_property": {"obj": "garbage truck", "action": "driving car", "target": null}, "target_prompt": "A garbage truck parked in a brightly lit area while workers unload garbage.", "target_property": {"obj": "garbage truck", "action": "driving car", "target": null}, "evaluation_question": "Is the garbage truck **driving** down a road?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A garbage truck driving down a road at night while workers collect garbage. RL7RM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a2838c826a894953a2a153a6bbb9ab6e.mp4", "clean_score": 1.0, "clean_xclip": 0.21745829284191132, "clean_vbench": {"subject_consistency": 0.8068046054492394, "background_consistency": 0.9227549235026041, "motion_smoothness": 0.998896332764716, "aesthetic_quality": 0.34325528144836426, "imaging_quality": 0.15484124222580267, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3c3cb4c582994c61afc26f2777be2919.mp4", "adv_score": 0.0, "adv_xclip": 0.16975824534893036, "adv_vbench": {"subject_consistency": 0.9224275431285301, "background_consistency": 0.9743448893229166, "motion_smoothness": 0.9996807159913863, "aesthetic_quality": 0.2783612012863159, "imaging_quality": 0.13281343693635903, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/597b22cb.mp4", "clean_score": 1.0, "clean_xclip": 0.27020901441574097, "clean_vbench": {}, "adv_vid_id": "vids/d78a4f62.mp4", "adv_score": 1.0, "adv_xclip": 0.22108253836631775, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/42426a25.mp4", "clean_score": 1.0, "clean_xclip": 0.2556643784046173, "clean_vbench": {}, "adv_vid_id": "vids/4a3909dd.mp4", "adv_score": 1.0, "adv_xclip": 0.2585533857345581, "adv_vbench": {}}}}
{"id": "f00fd5efee2342da8e3efc0e0e3167c4", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer to hit the roof of a car.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "car"}, "target_prompt": "A person using a sledgehammer to hit a tree.", "target_property": {"obj": "person", "action": "using a sledgehammer", "target": "tree"}, "evaluation_question": "Is the person **using a sledgehammer** on a car?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person using a sledgehammer to hit the roof of a car. Zweifelpfel Edelstahl matematic Newton", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9be1b72835d64cf4ab0a0634e29f97a5.mp4", "clean_score": 1.0, "clean_xclip": 0.23430317640304565, "clean_vbench": {"subject_consistency": 0.8810104082028071, "background_consistency": 0.9439697265625, "motion_smoothness": 0.9719515003114156, "aesthetic_quality": 0.3619491457939148, "imaging_quality": 0.551476901307398, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8e74d51ef00a40cfb6161780aa450b42.mp4", "adv_score": 0.0, "adv_xclip": 0.16812066733837128, "adv_vbench": {"subject_consistency": 0.8862054490794739, "background_consistency": 0.9425048828125, "motion_smoothness": 0.9446788341011559, "aesthetic_quality": 0.385194331407547, "imaging_quality": 0.563993071731256, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/73e8a1d9.mp4", "clean_score": 1.0, "clean_xclip": 0.2330460548400879, "clean_vbench": {}, "adv_vid_id": "vids/21dea6a8.mp4", "adv_score": 1.0, "adv_xclip": 0.16283880174160004, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/aaa1dea5.mp4", "clean_score": 0.0, "clean_xclip": 0.21571052074432373, "clean_vbench": {}, "adv_vid_id": "vids/399f128c.mp4", "adv_score": 1.0, "adv_xclip": 0.23132574558258057, "adv_vbench": {}}}}
{"id": "a51513bc0ae545829120e456c5accfe6", "source": "vatex", "video_id": "A3cqM3Mk2Mg_000876_000886", "video_description": "A group of people are sitting at a kitchen bar or restaurant counter, watching as a couple or staff prepare salads.", "task": "SpatialUnderstanding", "clean_prompt": "A staff member standing to the right of a counter in a kitchen bar.", "clean_property": {"obj_1": "staff", "relation": "right of", "obj_2": "counter"}, "target_prompt": "A staff member standing to the left of a counter in a kitchen bar.", "target_property": {"obj_1": "staff", "relation": "left of", "obj_2": "counter"}, "evaluation_question": "Is the staff member to the **right** of the counter?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A staff member standing to the right of a counter in a kitchen bar. telefon doarlandschaft stehen aflat", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6a9fe7bc005a49fe8039da47e2f53755.mp4", "clean_score": 1.0, "clean_xclip": 0.14981424808502197, "clean_vbench": {"subject_consistency": 0.9925012749930223, "background_consistency": 0.9730631510416666, "motion_smoothness": 0.9932272293015715, "aesthetic_quality": 0.6178687810897827, "imaging_quality": 0.6494472667149135, "dynamic_degree": 0.0}, "adv_vid_id": "vids/d160bfd5bfd745e4a6b7a01477cd6630.mp4", "adv_score": 0.0, "adv_xclip": 0.12948906421661377, "adv_vbench": {"subject_consistency": 0.9969349149614573, "background_consistency": 0.9933420817057291, "motion_smoothness": 0.9963975179095558, "aesthetic_quality": 0.4350147247314453, "imaging_quality": 0.5522806510146784, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9e59cd51.mp4", "clean_score": 0.0, "clean_xclip": 0.1149577796459198, "clean_vbench": {}, "adv_vid_id": "vids/9cf6877e.mp4", "adv_score": 0.0, "adv_xclip": 0.11281217634677887, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a8972899.mp4", "clean_score": 1.0, "clean_xclip": 0.2021743357181549, "clean_vbench": {}, "adv_vid_id": "vids/244115f7.mp4", "adv_score": 1.0, "adv_xclip": 0.21760453283786774, "adv_vbench": {}}}}
{"id": "908dce87cadc4e5ea69e775006b9ad39", "source": "vatex", "video_id": "aOq--ppDs2Y_000030_000040", "video_description": "Two friends are sitting on a couch. One man is using his phone to play a game while the other tries to distract him by putting his foot in the man's face.", "task": "Counting", "clean_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene.", "clean_property": {"obj": "man_1", "count": "five"}, "target_prompt": "Two men are sitting on a couch, one playing a game on his phone while the other tries to distract him.", "target_property": {"obj": "man", "count": "two"}, "evaluation_question": "Are there exactly **five** men in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene. treadmill entspannttiriAllerdings verhindert", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/52d6560042dc43849a1855ddcc0aa6b5.mp4", "clean_score": 1.0, "clean_xclip": 0.09329067915678024, "clean_vbench": {"subject_consistency": 0.8882350052396456, "background_consistency": 0.9175516764322916, "motion_smoothness": 0.9666882671921649, "aesthetic_quality": 0.5398931503295898, "imaging_quality": 0.582497824844049, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5ca63fc12209435f91eb6db4446540a2.mp4", "adv_score": 0.0, "adv_xclip": 0.1348082274198532, "adv_vbench": {"subject_consistency": 0.9772196008513371, "background_consistency": 0.9681142171223959, "motion_smoothness": 0.9754337565498165, "aesthetic_quality": 0.554747998714447, "imaging_quality": 0.672954627056511, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/76171e91.mp4", "clean_score": 0.0, "clean_xclip": 0.17857298254966736, "clean_vbench": {}, "adv_vid_id": "vids/5e97c27b.mp4", "adv_score": 0.0, "adv_xclip": 0.1920350044965744, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/44ed8857.mp4", "clean_score": 0.0, "clean_xclip": 0.20037448406219482, "clean_vbench": {}, "adv_vid_id": "vids/91bb6319.mp4", "adv_score": 0.0, "adv_xclip": 0.15738897025585175, "adv_vbench": {}}}}
{"id": "9969456a7bec4045ab8b72e51eb0ff9a", "source": "vatex", "video_id": "PE3pN-tvfmM_000000_000010", "video_description": "A person is performing a handstand on a wooden or gym floor while music plays.", "task": "ActionRecognition", "clean_prompt": "A person standing on hands on a wooden floor while music plays.", "clean_property": {"obj": "person", "action": "standing on hands", "target": null}, "target_prompt": "A person doing a backflip on a wooden floor while music plays.", "target_property": {"obj": "person", "action": "doing a backflip", "target": null}, "evaluation_question": "Is the person **standing on hands**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing on hands on a wooden floor while music plays. ;D#K@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3854d3083d6b45f2b3d8e34156874ae0.mp4", "clean_score": 1.0, "clean_xclip": 0.15089890360832214, "clean_vbench": {"subject_consistency": 0.9642406000445286, "background_consistency": 0.9696044921875, "motion_smoothness": 0.9923237275137679, "aesthetic_quality": 0.3820790648460388, "imaging_quality": 0.5239769705947565, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f892ca2893134d8285b77d131ea0f04a.mp4", "adv_score": 0.0, "adv_xclip": 0.1369398683309555, "adv_vbench": {"subject_consistency": 0.9700819806506237, "background_consistency": 0.9636637369791666, "motion_smoothness": 0.9865654559277415, "aesthetic_quality": 0.4030671715736389, "imaging_quality": 0.5116004243188975, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/16958789.mp4", "clean_score": 0.0, "clean_xclip": 0.12386767566204071, "clean_vbench": {}, "adv_vid_id": "vids/7646254d.mp4", "adv_score": 1.0, "adv_xclip": 0.14321626722812653, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3175b051.mp4", "clean_score": 0.0, "clean_xclip": 0.14360326528549194, "clean_vbench": {}, "adv_vid_id": "vids/eace1903.mp4", "adv_score": 1.0, "adv_xclip": 0.13968923687934875, "adv_vbench": {}}}}
{"id": "343dfab528d346d2a37489bf3647ae55", "source": "vatex", "video_id": "qpTtNJRcPjc_000218_000228", "video_description": "A young man is standing at a podium in a yellow room, reading from various documents including a newspaper and a book, while giving a speech to an audience.", "task": "ActionRecognition", "clean_prompt": "A person reading a newspaper at a podium in a yellow room.", "clean_property": {"obj": "person", "action": "reading newspaper", "target": null}, "target_prompt": "A person throwing a newspaper at a podium in a yellow room.", "target_property": {"obj": "person", "action": "throwing newspaper", "target": null}, "evaluation_question": "Is the person **reading** a newspaper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person reading a newspaper at a podium in a yellow room. )!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee740251c67048088fa8672fd57f7ac8.mp4", "clean_score": 1.0, "clean_xclip": 0.2383130043745041, "clean_vbench": {"subject_consistency": 0.9962629533062378, "background_consistency": 0.9680684407552084, "motion_smoothness": 0.9979562216636911, "aesthetic_quality": 0.6630999445915222, "imaging_quality": 0.7351143288125798, "dynamic_degree": 0.0}, "adv_vid_id": "vids/8cfe398d8e734b8baa0dcc55e5bf0116.mp4", "adv_score": 0.0, "adv_xclip": 0.2124585062265396, "adv_vbench": {"subject_consistency": 0.9961452540010214, "background_consistency": 0.9918670654296875, "motion_smoothness": 0.9971955367634451, "aesthetic_quality": 0.41783878207206726, "imaging_quality": 0.7682240342120735, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0799708d.mp4", "clean_score": 1.0, "clean_xclip": 0.20239438116550446, "clean_vbench": {}, "adv_vid_id": "vids/f3b21d65.mp4", "adv_score": 1.0, "adv_xclip": 0.20330530405044556, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3c4c0220.mp4", "clean_score": 1.0, "clean_xclip": 0.23990488052368164, "clean_vbench": {}, "adv_vid_id": "vids/26475fc0.mp4", "adv_score": 1.0, "adv_xclip": 0.2205033004283905, "adv_vbench": {}}}}
{"id": "66e404cd281d4ba7b4eb3de11f7668c4", "source": "vatex", "video_id": "6BeXjA_Rhgg_000000_000010", "video_description": "In a gymnasium, a group of young women are socializing and practicing high jump. One girl runs and jumps over a high jump bar onto a padded mat.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a padded mat in a gymnasium.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "padded mat"}, "target_prompt": "A person closer to the camera than a padded mat in a gymnasium.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "padded mat"}, "evaluation_question": "Is the person **farther from the camera than** the padded mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a padded mat in a gymnasium. HL1FJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/89cc429142c04c5bb54bf361c98d8b46.mp4", "clean_score": 1.0, "clean_xclip": 0.05600927770137787, "clean_vbench": {"subject_consistency": 0.9583872146904469, "background_consistency": 0.9588775634765625, "motion_smoothness": 0.9939146285957798, "aesthetic_quality": 0.44453319907188416, "imaging_quality": 0.5496046159705338, "dynamic_degree": 0.0}, "adv_vid_id": "vids/71c544301907443ebd343ed05dce5cc0.mp4", "adv_score": 0.0, "adv_xclip": 0.08070715516805649, "adv_vbench": {"subject_consistency": 0.9809257201850414, "background_consistency": 0.9812774658203125, "motion_smoothness": 0.9949575522724521, "aesthetic_quality": 0.3743259310722351, "imaging_quality": 0.4864897537231445, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f556e97a.mp4", "clean_score": 0.0, "clean_xclip": 0.07517655193805695, "clean_vbench": {}, "adv_vid_id": "vids/4b7b110c.mp4", "adv_score": 1.0, "adv_xclip": 0.10738438367843628, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c0f63fa8.mp4", "clean_score": 0.0, "clean_xclip": 0.08123265206813812, "clean_vbench": {}, "adv_vid_id": "vids/403dd427.mp4", "adv_score": 0.0, "adv_xclip": 0.12822681665420532, "adv_vbench": {}}}}
{"id": "f829b01934ad48c68a3a07f950458400", "source": "vatex", "video_id": "7AMkMqpQNwk_000773_000783", "video_description": "A group of construction workers are pouring and leveling a wet concrete floor inside a building using machinery and tools.", "task": "ActionRecognition", "clean_prompt": "A construction worker laying concrete inside a building.", "clean_property": {"obj": "construction worker", "action": "laying concrete", "target": null}, "target_prompt": "A construction worker demolishing concrete inside a building.", "target_property": {"obj": "construction worker", "action": "demolishing concrete", "target": null}, "evaluation_question": "Is the construction worker **laying** concrete?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A construction worker laying concrete inside a building. impun delicat personnage profesionist Schau", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/633e1f32d25e40f7a9d9dbc90c4f2656.mp4", "clean_score": 1.0, "clean_xclip": 0.19374343752861023, "clean_vbench": {"subject_consistency": 0.8967598229646683, "background_consistency": 0.9498647054036459, "motion_smoothness": 0.9920951638210582, "aesthetic_quality": 0.41463756561279297, "imaging_quality": 0.6282823951876894, "dynamic_degree": 0.0}, "adv_vid_id": "vids/3141d1b94aa9490798d9c1298769038c.mp4", "adv_score": 0.0, "adv_xclip": 0.18446670472621918, "adv_vbench": {"subject_consistency": 0.9546751578648885, "background_consistency": 0.9638112386067709, "motion_smoothness": 0.9909784621989227, "aesthetic_quality": 0.40348657965660095, "imaging_quality": 0.7524448161222498, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/db4d316c.mp4", "clean_score": 0.0, "clean_xclip": 0.17575150728225708, "clean_vbench": {}, "adv_vid_id": "vids/b3245b46.mp4", "adv_score": 1.0, "adv_xclip": 0.16766178607940674, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a5dec8b2.mp4", "clean_score": 1.0, "clean_xclip": 0.19995415210723877, "clean_vbench": {}, "adv_vid_id": "vids/dd1377cf.mp4", "adv_score": 1.0, "adv_xclip": 0.1497821807861328, "adv_vbench": {}}}}
{"id": "e0198daf505c457b8deacf16c62b0c24", "source": "vatex", "video_id": "Ocn7yFVKn_A_000024_000034", "video_description": "A young girl is demonstrating how to fold paper into origami while talking to the camera.", "task": "Counting", "clean_prompt": "Five girls demonstrating how to fold paper into origami while talking to the camera.", "clean_property": {"obj": "girl", "count": "five"}, "target_prompt": "One girl demonstrating how to fold paper into origami while talking to the camera.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **five** girls demonstrating origami?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Five girls demonstrating how to fold paper into origami while talking to the camera. *XSFA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/080c798528e845c2a8484c92c428ce39.mp4", "clean_score": 1.0, "clean_xclip": 0.23447255790233612, "clean_vbench": {"subject_consistency": 0.9460560524215301, "background_consistency": 0.9488677978515625, "motion_smoothness": 0.9686934999533507, "aesthetic_quality": 0.5377365946769714, "imaging_quality": 0.7200919622304488, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5d132617c06a4be0b926b5ad66abf0cc.mp4", "adv_score": 0.0, "adv_xclip": 0.18155330419540405, "adv_vbench": {"subject_consistency": 0.9459483952571949, "background_consistency": 0.9491068522135416, "motion_smoothness": 0.9676316533590031, "aesthetic_quality": 0.4399743974208832, "imaging_quality": 0.7371116420200893, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/53e2e6b6.mp4", "clean_score": 0.0, "clean_xclip": 0.23672547936439514, "clean_vbench": {}, "adv_vid_id": "vids/8a5784b7.mp4", "adv_score": 0.0, "adv_xclip": 0.2101784646511078, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4c82120f.mp4", "clean_score": 0.0, "clean_xclip": 0.2291371077299118, "clean_vbench": {}, "adv_vid_id": "vids/e3e9ea41.mp4", "adv_score": 1.0, "adv_xclip": 0.2313147485256195, "adv_vbench": {}}}}
{"id": "dae8e6b340fd42f1a0bb7ee2df932eee", "source": "vatex", "video_id": "IjKadk2V_Jg_000083_000093", "video_description": "A group of people, including two main individuals, are near a lake and woods, interacting with a large concrete structure covered in graffiti. Some are painting graffiti on the structure, while others are standing or squatting nearby.", "task": "ActionRecognition", "clean_prompt": "A person spray painting on a large concrete structure near a lake.", "clean_property": {"obj": "person", "action": "spray painting", "target": "concrete structure"}, "target_prompt": "A person cleaning a large concrete structure near a lake.", "target_property": {"obj": "person", "action": "cleaning", "target": "concrete structure"}, "evaluation_question": "Is the person **spray painting** on the concrete structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person spray painting on a large concrete structure near a lake. !0D0&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/359991769d0f47f9b8330799671dc066.mp4", "clean_score": 1.0, "clean_xclip": 0.24247995018959045, "clean_vbench": {"subject_consistency": 0.9365379984180132, "background_consistency": 0.9561106363932291, "motion_smoothness": 0.991423926782004, "aesthetic_quality": 0.40023717284202576, "imaging_quality": 0.6698554253091618, "dynamic_degree": 0.0}, "adv_vid_id": "vids/d757db6c805e4d938bcb7aec6baa519e.mp4", "adv_score": 0.0, "adv_xclip": 0.19451448321342468, "adv_vbench": {"subject_consistency": 0.9595857647558054, "background_consistency": 0.9416910807291666, "motion_smoothness": 0.9922241800751936, "aesthetic_quality": 0.3679060637950897, "imaging_quality": 0.753848461228974, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a96ba730.mp4", "clean_score": 0.0, "clean_xclip": 0.2538905739784241, "clean_vbench": {}, "adv_vid_id": "vids/16f96645.mp4", "adv_score": 1.0, "adv_xclip": 0.2432224154472351, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ff9f62d7.mp4", "clean_score": 1.0, "clean_xclip": 0.21996638178825378, "clean_vbench": {}, "adv_vid_id": "vids/40fcc0aa.mp4", "adv_score": 1.0, "adv_xclip": 0.22217795252799988, "adv_vbench": {}}}}
{"id": "d9d860f12e1747caa9ef9a09ba92bce3", "source": "vatex", "video_id": "zH2qJbxLkzg_000022_000032", "video_description": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event. Onlookers applaud after the board is broken.", "task": "ObjectRecognition", "clean_prompt": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event.", "clean_property": {"obj": "instructor"}, "target_prompt": "A young boy demonstrates his martial arts skills while a spectator watches at a martial arts event.", "target_property": {"obj": "spectator"}, "evaluation_question": "Is the person holding the board in the video an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event. ;@>SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e0dcb82bb46347b8a5704417acb80a54.mp4", "clean_score": 1.0, "clean_xclip": 0.16061994433403015, "clean_vbench": {"subject_consistency": 0.9565590359270573, "background_consistency": 0.9399973551432291, "motion_smoothness": 0.9573439529875736, "aesthetic_quality": 0.5182132720947266, "imaging_quality": 0.4405631882803781, "dynamic_degree": 1.0}, "adv_vid_id": "vids/817999a429f348769fb963bfafc2ef35.mp4", "adv_score": 0.0, "adv_xclip": 0.15262585878372192, "adv_vbench": {"subject_consistency": 0.9526275383929411, "background_consistency": 0.9640909830729166, "motion_smoothness": 0.9558385512802086, "aesthetic_quality": 0.5096298456192017, "imaging_quality": 0.5862183045367805, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6a5c0be3.mp4", "clean_score": 0.0, "clean_xclip": 0.14826539158821106, "clean_vbench": {}, "adv_vid_id": "vids/b72117b8.mp4", "adv_score": 0.0, "adv_xclip": 0.12210308760404587, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/940a4df3.mp4", "clean_score": 0.0, "clean_xclip": 0.13591302931308746, "clean_vbench": {}, "adv_vid_id": "vids/b262083f.mp4", "adv_score": 0.0, "adv_xclip": 0.1500643789768219, "adv_vbench": {}}}}
{"id": "ccde3c51d48f4703ad768fa691450b06", "source": "vatex", "video_id": "DnNeLJ79nYY_000011_000021", "video_description": "A boy is riding a bicycle on a dirt track with sand mounds and undulations, eventually falling off the bike.", "task": "ActionRecognition", "clean_prompt": "A person riding a bicycle on a dirt track and eventually falling off the bike.", "clean_property": {"obj": "person", "action": "falling off bike", "target": null}, "target_prompt": "A person jumping off a bike on a dirt track.", "target_property": {"obj": "person", "action": "jumping off a bike", "target": null}, "evaluation_question": "Is the person **falling off** the bike?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person riding a bicycle on a dirt track and eventually falling off the bike. ecran Szene linistitProvence snowboard", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3f330bdeda184b26a145565256b659a7.mp4", "clean_score": 1.0, "clean_xclip": 0.21300004422664642, "clean_vbench": {"subject_consistency": 0.8444839154059688, "background_consistency": 0.9144948323567709, "motion_smoothness": 0.9562336048134532, "aesthetic_quality": 0.46557775139808655, "imaging_quality": 0.5944230877623267, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fbd5695150dd4794b4df3714c5263582.mp4", "adv_score": 0.0, "adv_xclip": 0.1458648443222046, "adv_vbench": {"subject_consistency": 0.9074661340564489, "background_consistency": 0.9575754801432291, "motion_smoothness": 0.9810110811042524, "aesthetic_quality": 0.6099100112915039, "imaging_quality": 0.557845032361089, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/03ce95bc.mp4", "clean_score": 0.0, "clean_xclip": 0.17406439781188965, "clean_vbench": {}, "adv_vid_id": "vids/30a3cb34.mp4", "adv_score": 0.0, "adv_xclip": 0.19362477958202362, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/43280bb1.mp4", "clean_score": 0.0, "clean_xclip": 0.1888059377670288, "clean_vbench": {}, "adv_vid_id": "vids/cc8a01ea.mp4", "adv_score": 0.0, "adv_xclip": 0.1433883011341095, "adv_vbench": {}}}}
{"id": "270e78019b304f99a1b3fc592e9e4ee9", "source": "vatex", "video_id": "2xVH-79zc_U_000000_000010", "video_description": "A man is performing a shot put throw in an indoor facility while other men watch.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a shot put throw in an indoor facility.", "clean_property": {"obj": "athlete", "action": "shot put", "target": null}, "target_prompt": "An athlete performing a javelin throw in an indoor facility.", "target_property": {"obj": "athlete", "action": "javelin throw", "target": null}, "evaluation_question": "Is the athlete **performing a shot put throw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a shot put throw in an indoor facility. FS#|J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f018aef848e432e82e06f3a4eee4099.mp4", "clean_score": 1.0, "clean_xclip": 0.13842615485191345, "clean_vbench": {"subject_consistency": 0.9385803807526827, "background_consistency": 0.9153340657552084, "motion_smoothness": 0.9830491575070099, "aesthetic_quality": 0.4266580641269684, "imaging_quality": 0.5209754079701949, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f6c43c5c0a5145d29e867f8e6cae95e9.mp4", "adv_score": 0.0, "adv_xclip": 0.14427657425403595, "adv_vbench": {"subject_consistency": 0.9277343861758709, "background_consistency": 0.8899485270182291, "motion_smoothness": 0.9816929759365166, "aesthetic_quality": 0.4777822494506836, "imaging_quality": 0.511536297700843, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/75a5e3c3.mp4", "clean_score": 0.0, "clean_xclip": 0.1354970932006836, "clean_vbench": {}, "adv_vid_id": "vids/403efa81.mp4", "adv_score": 1.0, "adv_xclip": 0.14828908443450928, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/38ad150b.mp4", "clean_score": 1.0, "clean_xclip": 0.17762212455272675, "clean_vbench": {}, "adv_vid_id": "vids/fcb8495e.mp4", "adv_score": 1.0, "adv_xclip": 0.1307690441608429, "adv_vbench": {}}}}
{"id": "ff2e305c26bc4fc290ad2b9179f95e0c", "source": "vatex", "video_id": "MgSNvlS2d3A_000126_000136", "video_description": "A group of teenagers are outside on the grass, applying and removing wax strips from a boy's leg to remove hair.", "task": "Counting", "clean_prompt": "A group of teenagers are outside on the grass, applying and removing two wax strips from a boy's leg to remove hair.", "clean_property": {"obj": "wax strip", "count": "two"}, "target_prompt": "A group of teenagers are outside on the grass, applying and removing one wax strip from a boy's leg to remove hair.", "target_property": {"obj": "wax strip", "count": "one"}, "evaluation_question": "Are there exactly **two** wax strips being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of teenagers are outside on the grass, applying and removing two wax strips from a boy's leg to remove hair. ED9FA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/116eaa6f59ba4cdeb55032199dea3cb4.mp4", "clean_score": 1.0, "clean_xclip": 0.23690789937973022, "clean_vbench": {"subject_consistency": 0.9303066401431958, "background_consistency": 0.9259999593098959, "motion_smoothness": 0.9599509409923949, "aesthetic_quality": 0.4956265985965729, "imaging_quality": 0.7029277427829043, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fe48ecaa558045a89ceb793e57315392.mp4", "adv_score": 0.0, "adv_xclip": 0.17464593052864075, "adv_vbench": {"subject_consistency": 0.9554975666105747, "background_consistency": 0.93939208984375, "motion_smoothness": 0.9522611520238239, "aesthetic_quality": 0.45537713170051575, "imaging_quality": 0.6850519335999781, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/dcf4b332.mp4", "clean_score": 0.0, "clean_xclip": 0.24429824948310852, "clean_vbench": {}, "adv_vid_id": "vids/d9af9f3c.mp4", "adv_score": 1.0, "adv_xclip": 0.24810902774333954, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8285030f.mp4", "clean_score": 1.0, "clean_xclip": 0.2620660662651062, "clean_vbench": {}, "adv_vid_id": "vids/a5f50f45.mp4", "adv_score": 1.0, "adv_xclip": 0.20985937118530273, "adv_vbench": {}}}}
{"id": "41f8b9fbd89346bc848fceca6ef8e028", "source": "vatex", "video_id": "BeevuXU4xSM_000000_000010", "video_description": "A man is practicing shot put throwing techniques, spinning around and throwing the shot put in a marked area outdoors.", "task": "ObjectRecognition", "clean_prompt": "A man practicing shot put throwing techniques outdoors.", "clean_property": {"obj": "shot put"}, "target_prompt": "A man practicing javelin throwing techniques outdoors.", "target_property": {"obj": "javelin"}, "evaluation_question": "Is the man practicing **shot put** throwing techniques?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man practicing shot put throwing techniques outdoors.hnlich Kirchen militare vreme Regen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/260838ce2a4a4d7ca72c43e2d855561f.mp4", "clean_score": 1.0, "clean_xclip": 0.15465298295021057, "clean_vbench": {"subject_consistency": 0.8630277092258135, "background_consistency": 0.8783721923828125, "motion_smoothness": 0.9494967707955096, "aesthetic_quality": 0.47564905881881714, "imaging_quality": 0.5722485437198561, "dynamic_degree": 1.0}, "adv_vid_id": "vids/50657349de6649c9b7ac7a41e46e0633.mp4", "adv_score": 0.0, "adv_xclip": 0.06686002016067505, "adv_vbench": {"subject_consistency": 0.8974556171645721, "background_consistency": 0.9420674641927084, "motion_smoothness": 0.9688659142572924, "aesthetic_quality": 0.6033875346183777, "imaging_quality": 0.4959661257996851, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4c00c3eb.mp4", "clean_score": 0.0, "clean_xclip": 0.10425285995006561, "clean_vbench": {}, "adv_vid_id": "vids/a0ffc79b.mp4", "adv_score": 0.0, "adv_xclip": 0.15914833545684814, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c0822d71.mp4", "clean_score": 1.0, "clean_xclip": 0.1659020483493805, "clean_vbench": {}, "adv_vid_id": "vids/40131242.mp4", "adv_score": 0.0, "adv_xclip": 0.19919276237487793, "adv_vbench": {}}}}
{"id": "ef57f90bde7a4c84816706a8436a3e13", "source": "vatex", "video_id": "vbPK1FaEkkY_000001_000011", "video_description": "A young girl is in a bathroom brushing her teeth quickly over a sink.", "task": "ActionRecognition", "clean_prompt": "A girl brushing her teeth quickly over a sink in a bathroom.", "clean_property": {"obj": "girl", "action": "brushing teeth", "target": null}, "target_prompt": "A girl washing her hands in a bathroom.", "target_property": {"obj": "girl", "action": "washing hands", "target": null}, "evaluation_question": "Is the girl **brushing her teeth**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A girl brushing her teeth quickly over a sink in a bathroom. EL)74", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3fa4bd8b8a6840ad8818cc091199f48b.mp4", "clean_score": 1.0, "clean_xclip": 0.23168613016605377, "clean_vbench": {"subject_consistency": 0.9789198935031891, "background_consistency": 0.9323221842447916, "motion_smoothness": 0.9765769425343439, "aesthetic_quality": 0.39096659421920776, "imaging_quality": 0.5640218797021983, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e506f76d183f4ff7832ebecaa259f215.mp4", "adv_score": 0.0, "adv_xclip": 0.2065238207578659, "adv_vbench": {"subject_consistency": 0.9944039030621449, "background_consistency": 0.9802703857421875, "motion_smoothness": 0.9775446653037501, "aesthetic_quality": 0.4334503710269928, "imaging_quality": 0.568132612267319, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/823d9242.mp4", "clean_score": 1.0, "clean_xclip": 0.21543239057064056, "clean_vbench": {}, "adv_vid_id": "vids/5ea63cae.mp4", "adv_score": 1.0, "adv_xclip": 0.19697633385658264, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0494261d.mp4", "clean_score": 1.0, "clean_xclip": 0.21199437975883484, "clean_vbench": {}, "adv_vid_id": "vids/d2a65ae4.mp4", "adv_score": 1.0, "adv_xclip": 0.21018610894680023, "adv_vbench": {}}}}
{"id": "7ab20912d6634851b5e324f45f0c5efc", "source": "vatex", "video_id": "-JF20LJFGZM_000105_000115", "video_description": "Multiple skiers, including one in an orange suit, are skiing down a race course with cones. The skier in orange falls multiple times but continues skiing. Onlookers watch from behind a fence.", "task": "Counting", "clean_prompt": "Six onlookers watching skiers from behind a fence.", "clean_property": {"obj": "onlooker", "count": "six"}, "target_prompt": "Three onlookers watching skiers from behind a fence.", "target_property": {"obj": "onlooker", "count": "three"}, "evaluation_question": "Are there exactly **six** onlookers watching the skiers?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Six onlookers watching skiers from behind a fence. slope AlpineInfrastrukturPentru lieben", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a3ed2fd6790944359e44cae5a038d8aa.mp4", "clean_score": 1.0, "clean_xclip": 0.1431201696395874, "clean_vbench": {"subject_consistency": 0.994206947584947, "background_consistency": 0.9823811848958334, "motion_smoothness": 0.9948352018276446, "aesthetic_quality": 0.580764651298523, "imaging_quality": 0.5972620033731266, "dynamic_degree": 0.0}, "adv_vid_id": "vids/3df83f71fdc84940a641d34063b1c235.mp4", "adv_score": 0.0, "adv_xclip": 0.10992297530174255, "adv_vbench": {"subject_consistency": 0.9947413858026266, "background_consistency": 0.9872538248697916, "motion_smoothness": 0.9953947165864803, "aesthetic_quality": 0.5666303038597107, "imaging_quality": 0.7239884855309312, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fbf710f8.mp4", "clean_score": 1.0, "clean_xclip": 0.1779700070619583, "clean_vbench": {}, "adv_vid_id": "vids/85ed4696.mp4", "adv_score": 1.0, "adv_xclip": 0.2043912708759308, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5b5d3001.mp4", "clean_score": 0.0, "clean_xclip": 0.14530764520168304, "clean_vbench": {}, "adv_vid_id": "vids/930c0116.mp4", "adv_score": 0.0, "adv_xclip": 0.1777806431055069, "adv_vbench": {}}}}
{"id": "8755a39b572d4ebca0bebacf6425a334", "source": "vatex", "video_id": "Lmwnxz5L1Eo_000007_000017", "video_description": "A group of people, including men and a woman, are singing, clapping, and dancing together in a dimly lit living room.", "task": "Counting", "clean_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person singing alone in a brightly lit room.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people singing in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room. >3%SJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/965ee2d5975d4d749164cc229813f4ab.mp4", "clean_score": 1.0, "clean_xclip": 0.20480546355247498, "clean_vbench": {"subject_consistency": 0.8688801632573208, "background_consistency": 0.9278310139973959, "motion_smoothness": 0.9792274458426632, "aesthetic_quality": 0.48797163367271423, "imaging_quality": 0.29005883158469686, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8eb9dbcbeb344c7e91b0258f42a1eed2.mp4", "adv_score": 0.0, "adv_xclip": 0.20314468443393707, "adv_vbench": {"subject_consistency": 0.8889108635485172, "background_consistency": 0.9314066569010416, "motion_smoothness": 0.9762142232825486, "aesthetic_quality": 0.4947573244571686, "imaging_quality": 0.3074088555939343, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f29c86ef.mp4", "clean_score": 1.0, "clean_xclip": 0.14038291573524475, "clean_vbench": {}, "adv_vid_id": "vids/731c9a8d.mp4", "adv_score": 1.0, "adv_xclip": 0.17525909841060638, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c1e4a302.mp4", "clean_score": 1.0, "clean_xclip": 0.14680442214012146, "clean_vbench": {}, "adv_vid_id": "vids/32281841.mp4", "adv_score": 1.0, "adv_xclip": 0.16477811336517334, "adv_vbench": {}}}}
{"id": "6dde68dad04748489748fef6b4e0584a", "source": "vatex", "video_id": "qW57bMrrA8M_000000_000010", "video_description": "A man wearing a black hat is in a cluttered room, yawning multiple times while listening to music.", "task": "Counting", "clean_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are sitting in a cluttered room, yawning multiple times while listening to music.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music.industrial illustration angezeigt Ihreawning", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/229864650e3842a9be0f7d93d261732c.mp4", "clean_score": 1.0, "clean_xclip": 0.132634237408638, "clean_vbench": {"subject_consistency": 0.937743234137694, "background_consistency": 0.958984375, "motion_smoothness": 0.9879503528327483, "aesthetic_quality": 0.5130073428153992, "imaging_quality": 0.5342679775004484, "dynamic_degree": 0.0}, "adv_vid_id": "vids/72b16b040ebe4cf68dadf78b9159f26c.mp4", "adv_score": 0.0, "adv_xclip": 0.08595158904790878, "adv_vbench": {"subject_consistency": 0.986103887980183, "background_consistency": 0.9852193196614584, "motion_smoothness": 0.9917107687114197, "aesthetic_quality": 0.6006340980529785, "imaging_quality": 0.7326836893509845, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0f2ad161.mp4", "clean_score": 1.0, "clean_xclip": 0.1581241488456726, "clean_vbench": {}, "adv_vid_id": "vids/6d623518.mp4", "adv_score": 1.0, "adv_xclip": 0.12034208327531815, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/be32e307.mp4", "clean_score": 1.0, "clean_xclip": 0.14944350719451904, "clean_vbench": {}, "adv_vid_id": "vids/b4bd5e85.mp4", "adv_score": 1.0, "adv_xclip": 0.13434311747550964, "adv_vbench": {}}}}
{"id": "415e663a2de0458294f69a701674e1ef", "source": "vatex", "video_id": "esdAd3gN3OE_000000_000010", "video_description": "A woman in a wheelchair is being assisted by a service dog that pushes her across a room. Another woman is supervising and training the dog.", "task": "SpatialUnderstanding", "clean_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "clean_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "supervisor"}, "target_prompt": "A woman further from the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "target_property": {"obj_1": "woman", "relation": "further from the camera than", "obj_2": "supervisor"}, "evaluation_question": "Is the woman **closer to the camera** than her supervisor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room. ),!D:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a27eb3f21c74b5b99a0d3f5394f6c48.mp4", "clean_score": 1.0, "clean_xclip": 0.16180011630058289, "clean_vbench": {"subject_consistency": 0.7625147281214595, "background_consistency": 0.9139302571614584, "motion_smoothness": 0.970207446050694, "aesthetic_quality": 0.4148346483707428, "imaging_quality": 0.41575851557206134, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0bacd5fd8f2c4de5a04c4478a01fbaec.mp4", "adv_score": 0.0, "adv_xclip": 0.23049665987491608, "adv_vbench": {"subject_consistency": 0.8287946727747718, "background_consistency": 0.9330240885416666, "motion_smoothness": 0.9801551475946604, "aesthetic_quality": 0.41245511174201965, "imaging_quality": 0.6471025241151147, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/514875a2.mp4", "clean_score": 1.0, "clean_xclip": 0.22964386641979218, "clean_vbench": {}, "adv_vid_id": "vids/cd64f801.mp4", "adv_score": 1.0, "adv_xclip": 0.18436887860298157, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/13946637.mp4", "clean_score": 1.0, "clean_xclip": 0.26708632707595825, "clean_vbench": {}, "adv_vid_id": "vids/fbc04cc7.mp4", "adv_score": 1.0, "adv_xclip": 0.25812381505966187, "adv_vbench": {}}}}
{"id": "8a3178b55ef54bfc879dffadb24742b4", "source": "vatex", "video_id": "jCd7wi4ygf0_000089_000099", "video_description": "A young male athlete is performing a high jump on a track and field setup, with a woman commentating on the event.", "task": "SpatialUnderstanding", "clean_prompt": "A commentator standing to the right of an athlete performing a high jump on a track and field setup.", "clean_property": {"obj_1": "commentator", "relation": "right of", "obj_2": "athlete"}, "target_prompt": "A commentator standing to the left of an athlete performing a high jump on a track and field setup.", "target_property": {"obj_1": "commentator", "relation": "left of", "obj_2": "athlete"}, "evaluation_question": "Is the commentator to the **right** of the athlete?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A commentator standing to the right of an athlete performing a high jump on a track and field setup. Haftung spectacolEtwa Tweet bouche", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2aaa374cd3a9412c9dbf2c4314dd64db.mp4", "clean_score": 1.0, "clean_xclip": 0.08672480285167694, "clean_vbench": {"subject_consistency": 0.9144763468454281, "background_consistency": 0.9397481282552084, "motion_smoothness": 0.981469639016229, "aesthetic_quality": 0.4577229917049408, "imaging_quality": 0.6938359653706453, "dynamic_degree": 0.0}, "adv_vid_id": "vids/bea4fd596ec64ce18cb3a833f7cc73bc.mp4", "adv_score": 0.0, "adv_xclip": 0.1565098911523819, "adv_vbench": {"subject_consistency": 0.9619773092369238, "background_consistency": 0.9282023111979166, "motion_smoothness": 0.9832893832140625, "aesthetic_quality": 0.5036420226097107, "imaging_quality": 0.7131187547956195, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/64d593bb.mp4", "clean_score": 1.0, "clean_xclip": 0.13328400254249573, "clean_vbench": {}, "adv_vid_id": "vids/5f414ecb.mp4", "adv_score": 0.0, "adv_xclip": 0.1417345106601715, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b0cf465f.mp4", "clean_score": 1.0, "clean_xclip": 0.17568305134773254, "clean_vbench": {}, "adv_vid_id": "vids/e7081877.mp4", "adv_score": 0.0, "adv_xclip": 0.16423481702804565, "adv_vbench": {}}}}
{"id": "50a9ed44a1e943bc99c13b572efd4324", "source": "vatex", "video_id": "LAqqJXdiNIo_000001_000011", "video_description": "A man is sitting in a cafe, smoking a hookah and attempting to blow smoke rings and shapes with the smoke.", "task": "ActionRecognition", "clean_prompt": "A person smoking a hookah in a cafe, attempting to blow smoke rings.", "clean_property": {"obj": "person", "action": "smoking hookah", "target": null}, "target_prompt": "A person drinking coffee in a cafe.", "target_property": {"obj": "person", "action": "drinking coffee", "target": null}, "evaluation_question": "Is the person **smoking a hookah**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person smoking a hookah in a cafe, attempting to blow smoke rings. ;D)TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98f9d7219f7c428fa851a63fa45ee03a.mp4", "clean_score": 1.0, "clean_xclip": 0.23048216104507446, "clean_vbench": {"subject_consistency": 0.919752170642217, "background_consistency": 0.9515787760416666, "motion_smoothness": 0.9774517023533951, "aesthetic_quality": 0.4742399752140045, "imaging_quality": 0.5562764514222437, "dynamic_degree": 1.0}, "adv_vid_id": "vids/26fa8e19d8474760b6397e9f124a9076.mp4", "adv_score": 0.0, "adv_xclip": 0.2262953370809555, "adv_vbench": {"subject_consistency": 0.958967033152779, "background_consistency": 0.9569854736328125, "motion_smoothness": 0.9791882214884411, "aesthetic_quality": 0.5152250528335571, "imaging_quality": 0.5443666613831811, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a74dd6f0.mp4", "clean_score": 0.0, "clean_xclip": 0.23253701627254486, "clean_vbench": {}, "adv_vid_id": "vids/26dfa0af.mp4", "adv_score": 1.0, "adv_xclip": 0.21096107363700867, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/02aeefc8.mp4", "clean_score": 1.0, "clean_xclip": 0.2438374161720276, "clean_vbench": {}, "adv_vid_id": "vids/d8985fc9.mp4", "adv_score": 1.0, "adv_xclip": 0.24842095375061035, "adv_vbench": {}}}}
{"id": "1c3ad5759fc5496181c01fefb68c1573", "source": "vatex", "video_id": "THwHCIdsEHc_000044_000054", "video_description": "A man is in a gym performing deadlifts with a barbell loaded with heavy weights, wearing headphones.", "task": "Counting", "clean_prompt": "Seven people are in a gym, watching a man perform deadlifts with a barbell loaded with heavy weights, while he wears headphones.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "One person is in a gym, performing deadlifts with a barbell loaded with heavy weights, while wearing headphones.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **seven** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Seven people are in a gym, watching a man perform deadlifts with a barbell loaded with heavy weights, while he wears headphones. Gymnas ilustr Gymnas stylToujours", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bcbf76991e98459d9916719244664b5e.mp4", "clean_score": 1.0, "clean_xclip": 0.1558307409286499, "clean_vbench": {"subject_consistency": 0.9452467896044254, "background_consistency": 0.9542287190755209, "motion_smoothness": 0.9663650231922759, "aesthetic_quality": 0.7025342583656311, "imaging_quality": 0.5737390230139908, "dynamic_degree": 1.0}, "adv_vid_id": "vids/576a505eda114dd7ad8395d8e3236e97.mp4", "adv_score": 0.0, "adv_xclip": 0.08070538938045502, "adv_vbench": {"subject_consistency": 0.9484120346605778, "background_consistency": 0.951568603515625, "motion_smoothness": 0.9863830914503147, "aesthetic_quality": 0.6374083161354065, "imaging_quality": 0.660314556822485, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cd5d22e8.mp4", "clean_score": 0.0, "clean_xclip": 0.13038291037082672, "clean_vbench": {}, "adv_vid_id": "vids/aa2234bb.mp4", "adv_score": 0.0, "adv_xclip": 0.10697169601917267, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/446d0bba.mp4", "clean_score": 0.0, "clean_xclip": 0.12269565463066101, "clean_vbench": {}, "adv_vid_id": "vids/61a7da89.mp4", "adv_score": 0.0, "adv_xclip": 0.14286482334136963, "adv_vbench": {}}}}
{"id": "f05cc879f27345c79ef5508e3d50212f", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "Counting", "clean_prompt": "Three people sitting around a poker table in a casino, playing poker with cards and chips.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting alone at a poker table in a casino, playing poker with cards and chips.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting around the poker table?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three people sitting around a poker table in a casino, playing poker with cards and chips. PMZ2I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38c22af322cc4b56b389f180f25cc157.mp4", "clean_score": 1.0, "clean_xclip": 0.23244784772396088, "clean_vbench": {"subject_consistency": 0.9956713858991861, "background_consistency": 0.9743296305338541, "motion_smoothness": 0.9958708969087893, "aesthetic_quality": 0.5711528658866882, "imaging_quality": 0.5882581562898597, "dynamic_degree": 0.0}, "adv_vid_id": "vids/218732ea30a94019a1ba1e53114f38cf.mp4", "adv_score": 0.0, "adv_xclip": 0.1243334710597992, "adv_vbench": {"subject_consistency": 0.010000001192092895, "background_consistency": 1.0, "motion_smoothness": 0.9999820034495279, "aesthetic_quality": 0.33580583333969116, "imaging_quality": 0.2048581886291504, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/be38e4fe.mp4", "clean_score": 1.0, "clean_xclip": 0.25707510113716125, "clean_vbench": {}, "adv_vid_id": "vids/28efcb54.mp4", "adv_score": 1.0, "adv_xclip": 0.24699783325195312, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5b1a00ec.mp4", "clean_score": 1.0, "clean_xclip": 0.257909893989563, "clean_vbench": {}, "adv_vid_id": "vids/83b5feae.mp4", "adv_score": 1.0, "adv_xclip": 0.25627315044403076, "adv_vbench": {}}}}
{"id": "15a47361c4a74d54b37788008f3c8660", "source": "vatex", "video_id": "jsltYtLEKoY_000005_000015", "video_description": "A man performs a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth.", "task": "ObjectRecognition", "clean_prompt": "A man performing a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth.", "clean_property": {"obj": "sword"}, "target_prompt": "A man performing a fire-breathing act, where he breathes fire from a stick, does a push-up, and then puts the stick down.", "target_property": {"obj": "fire-breathing stick"}, "evaluation_question": "Is the object being used in the act a **sword**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man performing a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth. Trprindere Nord dintr", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4be1ae0c56844f469bd7ca25e0f0d9ab.mp4", "clean_score": 1.0, "clean_xclip": 0.14271651208400726, "clean_vbench": {"subject_consistency": 0.8872528150677681, "background_consistency": 0.8878682454427084, "motion_smoothness": 0.9675028051054527, "aesthetic_quality": 0.43879178166389465, "imaging_quality": 0.3928318774943449, "dynamic_degree": 1.0}, "adv_vid_id": "vids/320361dfad6c4014a9b8a057adc33f3f.mp4", "adv_score": 0.0, "adv_xclip": 0.12717005610466003, "adv_vbench": {"subject_consistency": 0.9262421578168869, "background_consistency": 0.9226175944010416, "motion_smoothness": 0.9759847604872711, "aesthetic_quality": 0.42308127880096436, "imaging_quality": 0.40666665369150595, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a51001b6.mp4", "clean_score": 1.0, "clean_xclip": 0.17272484302520752, "clean_vbench": {}, "adv_vid_id": "vids/f4554ea5.mp4", "adv_score": 1.0, "adv_xclip": 0.12904119491577148, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9a9895a7.mp4", "clean_score": 1.0, "clean_xclip": 0.1391107738018036, "clean_vbench": {}, "adv_vid_id": "vids/88f4e7db.mp4", "adv_score": 1.0, "adv_xclip": 0.20202146470546722, "adv_vbench": {}}}}
{"id": "55a5b10717fb46b09e1181a0a32183ef", "source": "vatex", "video_id": "RcqKQXQ6wJI_000046_000056", "video_description": "A man is playing the bagpipes while walking down a hallway in a school building, with people watching from the sides.", "task": "ActionRecognition", "clean_prompt": "A person playing bagpipes while walking down a hallway in a school building.", "clean_property": {"obj": "person", "action": "playing bagpipes", "target": null}, "target_prompt": "A person playing drums while walking down a hallway in a school building.", "target_property": {"obj": "person", "action": "playing drums", "target": null}, "evaluation_question": "Is the person **playing bagpipes**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person playing bagpipes while walking down a hallway in a school building. iluminatarzt vorbei Urlaub hallway", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8c3a773c4c8b41afb88aed59a06ef8e1.mp4", "clean_score": 1.0, "clean_xclip": 0.24869795143604279, "clean_vbench": {"subject_consistency": 0.9415849937746922, "background_consistency": 0.9061482747395834, "motion_smoothness": 0.9652668211767732, "aesthetic_quality": 0.4571734666824341, "imaging_quality": 0.5392331929109535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3e9484bfac8c441caef70334d37126d3.mp4", "adv_score": 0.0, "adv_xclip": 0.21443384885787964, "adv_vbench": {"subject_consistency": 0.8835207608838876, "background_consistency": 0.8992258707682291, "motion_smoothness": 0.970416937737029, "aesthetic_quality": 0.4301772117614746, "imaging_quality": 0.5555745214345503, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/01969f42.mp4", "clean_score": 1.0, "clean_xclip": 0.2574850916862488, "clean_vbench": {}, "adv_vid_id": "vids/5b0f4af4.mp4", "adv_score": 1.0, "adv_xclip": 0.24463260173797607, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ae2abea3.mp4", "clean_score": 1.0, "clean_xclip": 0.2618613839149475, "clean_vbench": {}, "adv_vid_id": "vids/46d58555.mp4", "adv_score": 1.0, "adv_xclip": 0.2510862350463867, "adv_vbench": {}}}}
{"id": "8530ea5dbc3349429870e398fe67490c", "source": "vatex", "video_id": "WFHuy4Cv5qY_000116_000126", "video_description": "A woman is in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "task": "Counting", "clean_prompt": "Five women in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "A woman in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women in a kitchen demonstrating how to cook scrambled eggs and place them on toast. EHU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0deeee61fb9146b581ecd6b86d290c32.mp4", "clean_score": 1.0, "clean_xclip": 0.2641748785972595, "clean_vbench": {"subject_consistency": 0.9696921321252981, "background_consistency": 0.96624755859375, "motion_smoothness": 0.9839327315256092, "aesthetic_quality": 0.5520374774932861, "imaging_quality": 0.7504086474983059, "dynamic_degree": 0.0}, "adv_vid_id": "vids/001049c3000d4d84b0b29d270c32b1fe.mp4", "adv_score": 0.0, "adv_xclip": 0.2215319722890854, "adv_vbench": {"subject_consistency": 0.958709375311931, "background_consistency": 0.9612630208333334, "motion_smoothness": 0.9714786957607117, "aesthetic_quality": 0.5057507753372192, "imaging_quality": 0.7008094546259666, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4aac2d19.mp4", "clean_score": 0.0, "clean_xclip": 0.1912652850151062, "clean_vbench": {}, "adv_vid_id": "vids/484f9344.mp4", "adv_score": 0.0, "adv_xclip": 0.2149745523929596, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/24aaa3f0.mp4", "clean_score": 0.0, "clean_xclip": 0.23468929529190063, "clean_vbench": {}, "adv_vid_id": "vids/0da1469e.mp4", "adv_score": 0.0, "adv_xclip": 0.22075247764587402, "adv_vbench": {}}}}
{"id": "ee449357a10f41ddbf1a17b6ad723598", "source": "vatex", "video_id": "32wivWSlBb4_000000_000010", "video_description": "A doctor, wearing a lab coat, is performing a neck adjustment on a seated woman in a busy store setting.", "task": "ObjectRecognition", "clean_prompt": "A doctor wearing a lab coat is performing a neck adjustment on a seated woman in a busy store setting.", "clean_property": {"obj": "doctor"}, "target_prompt": "A chef preparing a meal in a busy restaurant kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the professional in the video a **doctor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A doctor wearing a lab coat is performing a neck adjustment on a seated woman in a busy store setting. &FESX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/12fd20f46a1a4ee6acd982b8d291c214.mp4", "clean_score": 1.0, "clean_xclip": 0.1653861403465271, "clean_vbench": {"subject_consistency": 0.9662932020922502, "background_consistency": 0.959716796875, "motion_smoothness": 0.9769079998222283, "aesthetic_quality": 0.49984848499298096, "imaging_quality": 0.7428458264409279, "dynamic_degree": 1.0}, "adv_vid_id": "vids/da3af4ffdea646318778d28853837d95.mp4", "adv_score": 0.0, "adv_xclip": 0.1485675573348999, "adv_vbench": {"subject_consistency": 0.9411446793625752, "background_consistency": 0.9359181722005209, "motion_smoothness": 0.9717337679284677, "aesthetic_quality": 0.5145846009254456, "imaging_quality": 0.6848275437646982, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a5253ef0.mp4", "clean_score": 1.0, "clean_xclip": 0.16366083920001984, "clean_vbench": {}, "adv_vid_id": "vids/250cc6e2.mp4", "adv_score": 1.0, "adv_xclip": 0.12252285331487656, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/483b21d9.mp4", "clean_score": 1.0, "clean_xclip": 0.15239378809928894, "clean_vbench": {}, "adv_vid_id": "vids/75cad6cb.mp4", "adv_score": 1.0, "adv_xclip": 0.14045476913452148, "adv_vbench": {}}}}
{"id": "08e7c2523f6340f1a027b225f58c2f28", "source": "vatex", "video_id": "W3sMAuZgfKA_000071_000081", "video_description": "A baby boy is swinging back and forth in a baby swing at a park, with an adult occasionally pushing the swing.", "task": "ObjectRecognition", "clean_prompt": "An adult pushing a baby boy in a swing at a park.", "clean_property": {"obj": "adult"}, "target_prompt": "A child playing in a swing at a park.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person pushing the swing an **adult**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "An adult pushing a baby boy in a swing at a park. 7;)TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b09540e496b411ab54c9971da3d5271.mp4", "clean_score": 1.0, "clean_xclip": 0.27977725863456726, "clean_vbench": {"subject_consistency": 0.9188398675372204, "background_consistency": 0.9443817138671875, "motion_smoothness": 0.9479865246510126, "aesthetic_quality": 0.5111035704612732, "imaging_quality": 0.5224157878330776, "dynamic_degree": 1.0}, "adv_vid_id": "vids/66d984b05c98462daa6ed30e150cf5b1.mp4", "adv_score": 0.0, "adv_xclip": 0.2672358751296997, "adv_vbench": {"subject_consistency": 0.9161586003998915, "background_consistency": 0.9315745035807291, "motion_smoothness": 0.9609620432149197, "aesthetic_quality": 0.48364055156707764, "imaging_quality": 0.6112457368811782, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5ab7dcc9.mp4", "clean_score": 1.0, "clean_xclip": 0.2306142896413803, "clean_vbench": {}, "adv_vid_id": "vids/6a2b43eb.mp4", "adv_score": 1.0, "adv_xclip": 0.20725302398204803, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e5ec55f7.mp4", "clean_score": 1.0, "clean_xclip": 0.23601195216178894, "clean_vbench": {}, "adv_vid_id": "vids/588e3e8b.mp4", "adv_score": 1.0, "adv_xclip": 0.2640252411365509, "adv_vbench": {}}}}
{"id": "a717466059ff4c0481b8b9050a21f72e", "source": "vatex", "video_id": "krmuNJrZ36A_000000_000010", "video_description": "A large group of people, including men and boys, are participating in a military reenactment on a grassy field. The men are dressed in historic military uniforms and carrying rifles, while the boys are in white shirts carrying sticks. The scene involves preparation and role-playing of a battle.", "task": "SpatialUnderstanding", "clean_prompt": "A rifle positioned to the right of a man in a military uniform.", "clean_property": {"obj_1": "rifle", "relation": "right of", "obj_2": "man"}, "target_prompt": "A sword positioned to the left of a man in a military uniform.", "target_property": {"obj_1": "sword", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the rifle to the **right** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A rifle positioned to the right of a man in a military uniform. Marcus Birinstitu frapp Lisbon", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0090d538742048b9b5677604d4961496.mp4", "clean_score": 1.0, "clean_xclip": 0.1394413709640503, "clean_vbench": {"subject_consistency": 0.9201976073284944, "background_consistency": 0.9319203694661459, "motion_smoothness": 0.9903215898402828, "aesthetic_quality": 0.499540239572525, "imaging_quality": 0.4000914305083606, "dynamic_degree": 1.0}, "adv_vid_id": "vids/19105a37098d48ccb032fe845ba2998f.mp4", "adv_score": 0.0, "adv_xclip": 0.17253205180168152, "adv_vbench": {"subject_consistency": 0.9674248564988375, "background_consistency": 0.9692535400390625, "motion_smoothness": 0.9907462994167575, "aesthetic_quality": 0.4067862629890442, "imaging_quality": 0.5874808720179966, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8dbae8fa.mp4", "clean_score": 1.0, "clean_xclip": 0.17633672058582306, "clean_vbench": {}, "adv_vid_id": "vids/8120a0b0.mp4", "adv_score": 0.0, "adv_xclip": 0.14623813331127167, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bcd9b5cd.mp4", "clean_score": 1.0, "clean_xclip": 0.19075965881347656, "clean_vbench": {}, "adv_vid_id": "vids/611a8bca.mp4", "adv_score": 1.0, "adv_xclip": 0.2024059295654297, "adv_vbench": {}}}}
{"id": "b60c05e9ccd042f9acadab08d8673ef8", "source": "vatex", "video_id": "M5Iv3vnl2Ys_000022_000032", "video_description": "A man in a red pullover and khaki pants is on a windy golf course, demonstrating how to hit a golf ball with a club.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a golf club on a windy golf course.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "golf club"}, "target_prompt": "A man closer to the camera than a golf club on a windy golf course.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "golf club"}, "evaluation_question": "Is the man **farther from the camera than** the golf club?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a golf club on a windy golf course. FE,Z'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bcde7e021c094c45bfa3749f3c4dedef.mp4", "clean_score": 1.0, "clean_xclip": 0.13554635643959045, "clean_vbench": {"subject_consistency": 0.9089191369712353, "background_consistency": 0.9435475667317709, "motion_smoothness": 0.9929780984603204, "aesthetic_quality": 0.5176742076873779, "imaging_quality": 0.5134012276785714, "dynamic_degree": 0.0}, "adv_vid_id": "vids/9711023f840d462d893e8c6b5db2d7ef.mp4", "adv_score": 0.0, "adv_xclip": 0.11594405025243759, "adv_vbench": {"subject_consistency": 0.9187923284868399, "background_consistency": 0.9278717041015625, "motion_smoothness": 0.9886814294422759, "aesthetic_quality": 0.487185537815094, "imaging_quality": 0.572047796444017, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2d4123b5.mp4", "clean_score": 0.0, "clean_xclip": 0.11181462556123734, "clean_vbench": {}, "adv_vid_id": "vids/c5bddfac.mp4", "adv_score": 0.0, "adv_xclip": 0.1366833746433258, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6b90049e.mp4", "clean_score": 0.0, "clean_xclip": 0.19359154999256134, "clean_vbench": {}, "adv_vid_id": "vids/0509e37b.mp4", "adv_score": 0.0, "adv_xclip": 0.0977429747581482, "adv_vbench": {}}}}
{"id": "b65cabeafef74a1a84087fe81e8bae56", "source": "vatex", "video_id": "qFDrQ5YtmA4_000047_000057", "video_description": "An industrial machine is packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them. A person observes and occasionally picks up a packet from the floor.", "task": "AttributeRecognition", "clean_prompt": "An industrial machine packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them.", "clean_property": {"obj": "packet", "attribute": "Asian characters"}, "target_prompt": "An industrial machine packaging and dispensing small, sealed packets of a brown sandy substance with Western characters on them.", "target_property": {"obj": "packet", "attribute": "Western characters"}, "evaluation_question": "Do the packets have **Asian** characters on them?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An industrial machine packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them. O!BCX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7601036da6fa4e54ac52607a5ad3a90d.mp4", "clean_score": 1.0, "clean_xclip": 0.22993090748786926, "clean_vbench": {"subject_consistency": 0.9564151999851068, "background_consistency": 0.9516855875651041, "motion_smoothness": 0.9645615079139938, "aesthetic_quality": 0.4933403730392456, "imaging_quality": 0.5593985911778041, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5cbfb0d80cd94fe2b475105e359244c4.mp4", "adv_score": 0.0, "adv_xclip": 0.07484183460474014, "adv_vbench": {"subject_consistency": 0.9626651337991158, "background_consistency": 0.9690297444661459, "motion_smoothness": 0.9550519265222808, "aesthetic_quality": 0.33885690569877625, "imaging_quality": 0.6031611742292131, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0abcdd49.mp4", "clean_score": 1.0, "clean_xclip": 0.18160218000411987, "clean_vbench": {}, "adv_vid_id": "vids/3f746fef.mp4", "adv_score": 0.0, "adv_xclip": 0.23078973591327667, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e0b16ef4.mp4", "clean_score": 1.0, "clean_xclip": 0.22522187232971191, "clean_vbench": {}, "adv_vid_id": "vids/9bf4daf5.mp4", "adv_score": 1.0, "adv_xclip": 0.22646886110305786, "adv_vbench": {}}}}
{"id": "9993b6edb4684f4585dffd8e0133df9d", "source": "vatex", "video_id": "D9SLYYEAEf8_000000_000010", "video_description": "A woman is sitting on a couch holding a baby who is laughing while a man counts money next to them.", "task": "Counting", "clean_prompt": "Two men counting money next to a woman sitting on a couch holding a laughing baby.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "One man counting money next to a woman sitting on a couch holding a laughing baby.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men counting money?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two men counting money next to a woman sitting on a couch holding a laughing baby. classementdisproportionate Milliarden Abschnittindi", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4f8b4aeef4ae4f6da60d9f6c9094c3a9.mp4", "clean_score": 1.0, "clean_xclip": 0.12572816014289856, "clean_vbench": {"subject_consistency": 0.9470572844147682, "background_consistency": 0.9658203125, "motion_smoothness": 0.969314808826051, "aesthetic_quality": 0.5239176154136658, "imaging_quality": 0.7417417611881179, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1de44ad66fe64cae83ca6bed0a7c07e4.mp4", "adv_score": 0.0, "adv_xclip": 0.21452118456363678, "adv_vbench": {"subject_consistency": 0.9073849848161141, "background_consistency": 0.9218037923177084, "motion_smoothness": 0.9503956298729626, "aesthetic_quality": 0.41421443223953247, "imaging_quality": 0.6926182805275432, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/17203d89.mp4", "clean_score": 0.0, "clean_xclip": 0.2442486584186554, "clean_vbench": {}, "adv_vid_id": "vids/ce7aa7a3.mp4", "adv_score": 1.0, "adv_xclip": 0.240131676197052, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bafc73be.mp4", "clean_score": 1.0, "clean_xclip": 0.2521146535873413, "clean_vbench": {}, "adv_vid_id": "vids/f6bb5194.mp4", "adv_score": 0.0, "adv_xclip": 0.24511933326721191, "adv_vbench": {}}}}
{"id": "140d16e57c6444318aee83c885c6bf17", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "Counting", "clean_prompt": "A man demonstrating how to shovel snow from a driveway with six people watching.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A man demonstrating how to shovel snow from a driveway with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man demonstrating how to shovel snow from a driveway with six people watching. &FE,M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/72ab777832494a54a478351b222367b2.mp4", "clean_score": 1.0, "clean_xclip": 0.20488616824150085, "clean_vbench": {"subject_consistency": 0.9109621377040943, "background_consistency": 0.9519704182942709, "motion_smoothness": 0.9671683528188796, "aesthetic_quality": 0.5989430546760559, "imaging_quality": 0.6244162251997968, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a2cea4618b3d4f1fb7e18dfafa1d3595.mp4", "adv_score": 0.0, "adv_xclip": 0.19665156304836273, "adv_vbench": {"subject_consistency": 0.9149645784248909, "background_consistency": 0.9384562174479166, "motion_smoothness": 0.9654161978094994, "aesthetic_quality": 0.5884498357772827, "imaging_quality": 0.5864980720987125, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2cb55b02.mp4", "clean_score": 1.0, "clean_xclip": 0.17925596237182617, "clean_vbench": {}, "adv_vid_id": "vids/ae0ec590.mp4", "adv_score": 0.0, "adv_xclip": 0.1990521401166916, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/08a6ad3e.mp4", "clean_score": 0.0, "clean_xclip": 0.18686673045158386, "clean_vbench": {}, "adv_vid_id": "vids/d4d1d412.mp4", "adv_score": 0.0, "adv_xclip": 0.21050609648227692, "adv_vbench": {}}}}
{"id": "9b2add6038f94cf8926b537a8322cc86", "source": "vatex", "video_id": "x2JkxZT9AMQ_000000_000010", "video_description": "A little boy sneezes and smiles in a room with a man sitting at a table using a computer. A woman is also present, laughing, and a baby is nearby with a stuffed toy.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the left of a woman in a room.", "clean_property": {"obj_1": "boy", "relation": "left of", "obj_2": "woman"}, "target_prompt": "A boy standing to the right of a woman in a room.", "target_property": {"obj_1": "boy", "relation": "right of", "obj_2": "woman"}, "evaluation_question": "Is the boy to the **left** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the left of a woman in a room. FEKP$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1d55489e0aa4d679f87987a0e6e061d.mp4", "clean_score": 1.0, "clean_xclip": 0.11778914928436279, "clean_vbench": {"subject_consistency": 0.9304392381260792, "background_consistency": 0.9346262613932291, "motion_smoothness": 0.992034085679668, "aesthetic_quality": 0.4975390136241913, "imaging_quality": 0.42075081338687814, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e4ac2c05d6704d6b855a1f45270f4e45.mp4", "adv_score": 0.0, "adv_xclip": 0.15140008926391602, "adv_vbench": {"subject_consistency": 0.9501365832984447, "background_consistency": 0.9500783284505209, "motion_smoothness": 0.9884692100316206, "aesthetic_quality": 0.5355648994445801, "imaging_quality": 0.4951840132109973, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/aca0abea.mp4", "clean_score": 0.0, "clean_xclip": 0.16361206769943237, "clean_vbench": {}, "adv_vid_id": "vids/cd7aa0de.mp4", "adv_score": 0.0, "adv_xclip": 0.15730054676532745, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/263d13c0.mp4", "clean_score": 0.0, "clean_xclip": 0.1791103482246399, "clean_vbench": {}, "adv_vid_id": "vids/011671b7.mp4", "adv_score": 1.0, "adv_xclip": 0.16578757762908936, "adv_vbench": {}}}}
{"id": "a1bff76724114173ae1bac17044bb505", "source": "vatex", "video_id": "kJbkXbf5H60_000006_000016", "video_description": "A woman is playing a Christmas tune on a saxophone on a busy city street corner. People walk by, and some give her money.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the left of a pedestrian on a busy city street corner.", "clean_property": {"obj_1": "musician", "relation": "left of", "obj_2": "pedestrian"}, "target_prompt": "A musician standing to the right of a pedestrian on a busy city street corner.", "target_property": {"obj_1": "musician", "relation": "right of", "obj_2": "pedestrian"}, "evaluation_question": "Is the musician to the **left** of a pedestrian?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician standing to the left of a pedestrian on a busy city street corner. FE7CV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd9cf5a126bc4429af8fa24d6addc8f9.mp4", "clean_score": 1.0, "clean_xclip": 0.19485348463058472, "clean_vbench": {"subject_consistency": 0.9537757808963457, "background_consistency": 0.9400075276692709, "motion_smoothness": 0.950626587652808, "aesthetic_quality": 0.5124493837356567, "imaging_quality": 0.5505112278218172, "dynamic_degree": 1.0}, "adv_vid_id": "vids/55e9982872c44bf7bdd355bba7fe8496.mp4", "adv_score": 0.0, "adv_xclip": 0.2163052260875702, "adv_vbench": {"subject_consistency": 0.9329351702084144, "background_consistency": 0.9307149251302084, "motion_smoothness": 0.9541200075773623, "aesthetic_quality": 0.5402542352676392, "imaging_quality": 0.5648183565723653, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/34ff2f53.mp4", "clean_score": 1.0, "clean_xclip": 0.20115312933921814, "clean_vbench": {}, "adv_vid_id": "vids/55f36dd0.mp4", "adv_score": 1.0, "adv_xclip": 0.21894115209579468, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e326ae0b.mp4", "clean_score": 0.0, "clean_xclip": 0.23126006126403809, "clean_vbench": {}, "adv_vid_id": "vids/98043a72.mp4", "adv_score": 1.0, "adv_xclip": 0.23035550117492676, "adv_vbench": {}}}}
{"id": "2e3b339dc13f4019b39b37e1dc403f6f", "source": "vatex", "video_id": "b1x_oZ11U0Y_000016_000026", "video_description": "A large group of people are playing various percussion instruments, including xylophones, maracas, and drums, outside in a parking lot or street.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the left of an instrument.", "clean_property": {"obj_1": "musician", "relation": "left of", "obj_2": "instrument"}, "target_prompt": "A musician standing to the right of an instrument.", "target_property": {"obj_1": "musician", "relation": "right of", "obj_2": "instrument"}, "evaluation_question": "Is the musician to the **left** of an instrument?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician standing to the left of an instrument. ,FEY@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c0bd2aa570a84b33bdc219d8a9ba65a8.mp4", "clean_score": 1.0, "clean_xclip": 0.09838628768920898, "clean_vbench": {"subject_consistency": 0.960215845455726, "background_consistency": 0.943023681640625, "motion_smoothness": 0.9793738249414992, "aesthetic_quality": 0.4704003632068634, "imaging_quality": 0.48900977621273123, "dynamic_degree": 1.0}, "adv_vid_id": "vids/edc9c757403d424e9789ba1ad014115a.mp4", "adv_score": 0.0, "adv_xclip": 0.11847128719091415, "adv_vbench": {"subject_consistency": 0.890868267044425, "background_consistency": 0.9067637125651041, "motion_smoothness": 0.9806285858511357, "aesthetic_quality": 0.5132018327713013, "imaging_quality": 0.3947013710956184, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a0390a68.mp4", "clean_score": 0.0, "clean_xclip": 0.1329062581062317, "clean_vbench": {}, "adv_vid_id": "vids/33587d2b.mp4", "adv_score": 0.0, "adv_xclip": 0.12781760096549988, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c82f7112.mp4", "clean_score": 0.0, "clean_xclip": 0.11126963794231415, "clean_vbench": {}, "adv_vid_id": "vids/a805ce9f.mp4", "adv_score": 0.0, "adv_xclip": 0.1045268177986145, "adv_vbench": {}}}}
{"id": "0db95889599d4e0d94cbaf801cdfbca2", "source": "vatex", "video_id": "dSioS70MCs4_000001_000011", "video_description": "A young boy is sitting at a table, trying to blow out a trick candle on his birthday cake, while a man encourages him and laughs.", "task": "ObjectRecognition", "clean_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake.", "clean_property": {"obj": "man"}, "target_prompt": "A woman encouraging a young girl to blow out a trick candle on a birthday cake.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person encouraging the child a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake. !W*QB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed9faada97314df5a503ff24e3de8be2.mp4", "clean_score": 1.0, "clean_xclip": 0.20197322964668274, "clean_vbench": {"subject_consistency": 0.9867615749438604, "background_consistency": 0.9814198811848959, "motion_smoothness": 0.9815202487984649, "aesthetic_quality": 0.6460219025611877, "imaging_quality": 0.6654664136925522, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bbfb56bca7914e348a9294342690dbd6.mp4", "adv_score": 0.0, "adv_xclip": 0.19284747540950775, "adv_vbench": {"subject_consistency": 0.9882506486028433, "background_consistency": 0.9728800455729166, "motion_smoothness": 0.9880492865806302, "aesthetic_quality": 0.6488209962844849, "imaging_quality": 0.7149942421426578, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ddecc3a1.mp4", "clean_score": 0.0, "clean_xclip": 0.19285446405410767, "clean_vbench": {}, "adv_vid_id": "vids/72d2d956.mp4", "adv_score": 1.0, "adv_xclip": 0.2080628126859665, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/80b844ee.mp4", "clean_score": 1.0, "clean_xclip": 0.20425556600093842, "clean_vbench": {}, "adv_vid_id": "vids/ded1e4c3.mp4", "adv_score": 1.0, "adv_xclip": 0.20278586447238922, "adv_vbench": {}}}}
{"id": "c4cc13f1c76b4996a07f83975053ff39", "source": "vatex", "video_id": "3YpPMnCb3O4_000123_000133", "video_description": "A man demonstrates how to copy an identification card using a photocopier.", "task": "Counting", "clean_prompt": "A man demonstrates how to copy three identification cards using a photocopier.", "clean_property": {"obj": "identification card", "count": "three"}, "target_prompt": "A man demonstrates how to copy one identification card using a photocopier.", "target_property": {"obj": "identification card", "count": "one"}, "evaluation_question": "Are there exactly **three** identification cards being copied?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man demonstrates how to copy three identification cards using a photocopier. 1*W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/085f2104e550493097e238adddc2202c.mp4", "clean_score": 1.0, "clean_xclip": 0.18356993794441223, "clean_vbench": {"subject_consistency": 0.9379763274143139, "background_consistency": 0.9365386962890625, "motion_smoothness": 0.9658893063687667, "aesthetic_quality": 0.440472275018692, "imaging_quality": 0.6909028897966657, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9a4e3df7c3e6408b9530ee157258ef74.mp4", "adv_score": 0.0, "adv_xclip": 0.24142639338970184, "adv_vbench": {"subject_consistency": 0.9357580542564392, "background_consistency": 0.9468790690104166, "motion_smoothness": 0.9820004445869139, "aesthetic_quality": 0.3946462571620941, "imaging_quality": 0.5332547518671775, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/275e4b08.mp4", "clean_score": 0.0, "clean_xclip": 0.2093179076910019, "clean_vbench": {}, "adv_vid_id": "vids/4500d8cb.mp4", "adv_score": 0.0, "adv_xclip": 0.22421249747276306, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/062e435f.mp4", "clean_score": 0.0, "clean_xclip": 0.22219009697437286, "clean_vbench": {}, "adv_vid_id": "vids/dd4e2c72.mp4", "adv_score": 0.0, "adv_xclip": 0.22740623354911804, "adv_vbench": {}}}}
{"id": "9545c7299aa3482ea04f65215f2c7bd4", "source": "vatex", "video_id": "xGe0cXA3OnI_000004_000014", "video_description": "A group of people are riding camels in the desert during the daytime. The camels kneel and sit to allow the riders to dismount.", "task": "Counting", "clean_prompt": "Seven people riding camels in the desert during the daytime.", "clean_property": {"obj": "camel", "count": "seven"}, "target_prompt": "One person riding a camel in the desert during the daytime.", "target_property": {"obj": "camel", "count": "one"}, "evaluation_question": "Are there exactly **seven** camels being ridden in the desert?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Seven people riding camels in the desert during the daytime. 1*D7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/306f9fb28f30463db7360ebfa4c737a8.mp4", "clean_score": 1.0, "clean_xclip": 0.21789862215518951, "clean_vbench": {"subject_consistency": 0.9886455436547598, "background_consistency": 0.9798329671223959, "motion_smoothness": 0.9932520492604191, "aesthetic_quality": 0.6378155946731567, "imaging_quality": 0.6942336880430884, "dynamic_degree": 0.0}, "adv_vid_id": "vids/2759bde8278d427c9f484c94c4986ff5.mp4", "adv_score": 0.0, "adv_xclip": 0.21726688742637634, "adv_vbench": {"subject_consistency": 0.9890908443679413, "background_consistency": 0.9851125081380209, "motion_smoothness": 0.9929739521869704, "aesthetic_quality": 0.6210859417915344, "imaging_quality": 0.7581506659060108, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/47eaa2bc.mp4", "clean_score": 1.0, "clean_xclip": 0.22416244447231293, "clean_vbench": {}, "adv_vid_id": "vids/29ea1d95.mp4", "adv_score": 0.0, "adv_xclip": 0.21214184165000916, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7603672c.mp4", "clean_score": 0.0, "clean_xclip": 0.20424634218215942, "clean_vbench": {}, "adv_vid_id": "vids/bb253e4b.mp4", "adv_score": 0.0, "adv_xclip": 0.222336545586586, "adv_vbench": {}}}}
{"id": "6686b8f3284141669da6b2ed9cc0c1cf", "source": "vatex", "video_id": "xBcHMVUU1E4_000013_000023", "video_description": "A man is assisting a woman in performing a handstand. He supports her legs for balance, lets go briefly, and then she falls over, gets up, and they high-five.", "task": "Counting", "clean_prompt": "Three women practicing a handstand with the help of a man.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "One woman practicing a handstand with the help of a man.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women practicing a handstand?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three women practicing a handstand with the help of a man.anniversaire eingerichtet Meghan nostru ridicat", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ad354a914e047a79830c916fb0b2b82.mp4", "clean_score": 1.0, "clean_xclip": 0.18442267179489136, "clean_vbench": {"subject_consistency": 0.9444591576854388, "background_consistency": 0.9682668050130209, "motion_smoothness": 0.9828350169639616, "aesthetic_quality": 0.46121636033058167, "imaging_quality": 0.6557617101863938, "dynamic_degree": 1.0}, "adv_vid_id": "vids/58567235d0a549139e37da415d9ee341.mp4", "adv_score": 0.0, "adv_xclip": 0.16268891096115112, "adv_vbench": {"subject_consistency": 0.9760341681540012, "background_consistency": 0.975494384765625, "motion_smoothness": 0.9869632904537844, "aesthetic_quality": 0.4423157274723053, "imaging_quality": 0.7097292016477001, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c0eb9572.mp4", "clean_score": 1.0, "clean_xclip": 0.17843854427337646, "clean_vbench": {}, "adv_vid_id": "vids/4af0ada4.mp4", "adv_score": 1.0, "adv_xclip": 0.16455012559890747, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/50b7a884.mp4", "clean_score": 0.0, "clean_xclip": 0.20995503664016724, "clean_vbench": {}, "adv_vid_id": "vids/7ba1246c.mp4", "adv_score": 1.0, "adv_xclip": 0.19791026413440704, "adv_vbench": {}}}}
{"id": "d2e84ef9f70b4ae0ae12f89a6752ce50", "source": "vatex", "video_id": "BFfOzTssqX4_000000_000010", "video_description": "A young girl is in her bedroom, facing the camera, talking and eating a powdered donut.", "task": "ActionRecognition", "clean_prompt": "A girl eating a powdered donut in her bedroom.", "clean_property": {"obj": "girl", "action": "eating doughnuts", "target": "donut"}, "target_prompt": "A girl playing with a toy in her bedroom.", "target_property": {"obj": "girl", "action": "playing with toys", "target": "toy"}, "evaluation_question": "Is the girl **eating** a donut?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl eating a powdered donut in her bedroom. 0TXBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c78d4a5cf964a39b0e8d286abdea144.mp4", "clean_score": 1.0, "clean_xclip": 0.20029248297214508, "clean_vbench": {"subject_consistency": 0.9718947199483713, "background_consistency": 0.9685211181640625, "motion_smoothness": 0.986256946493232, "aesthetic_quality": 0.6772915720939636, "imaging_quality": 0.7158105749013473, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8dcae7ddfe5b4305ad6798330aa5913e.mp4", "adv_score": 0.0, "adv_xclip": 0.20156455039978027, "adv_vbench": {"subject_consistency": 0.9757436948517958, "background_consistency": 0.9752400716145834, "motion_smoothness": 0.9892643306390201, "aesthetic_quality": 0.6109146475791931, "imaging_quality": 0.7253922365149673, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a9b0cff6.mp4", "clean_score": 1.0, "clean_xclip": 0.1897393763065338, "clean_vbench": {}, "adv_vid_id": "vids/61f5a6cd.mp4", "adv_score": 0.0, "adv_xclip": 0.1810646951198578, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c41470a4.mp4", "clean_score": 1.0, "clean_xclip": 0.19058483839035034, "clean_vbench": {}, "adv_vid_id": "vids/31a8adf7.mp4", "adv_score": 1.0, "adv_xclip": 0.21148881316184998, "adv_vbench": {}}}}
{"id": "afb9ce84412a41e49445a0e21db97d8f", "source": "vatex", "video_id": "rseoEvLeT4A_000039_000049", "video_description": "A woman and her daughter are sitting on a bench in a busy city street, feeding pigeons.", "task": "Counting", "clean_prompt": "Three women sitting on a bench in a busy city street, feeding pigeons.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "A woman sitting alone on a bench in a busy city street, feeding pigeons.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women sitting on the bench?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women sitting on a bench in a busy city street, feeding pigeons. $BSG>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3030af32b08b4e14ace58df140475baa.mp4", "clean_score": 1.0, "clean_xclip": 0.24314799904823303, "clean_vbench": {"subject_consistency": 0.8887534563740095, "background_consistency": 0.8975982666015625, "motion_smoothness": 0.9422468166568324, "aesthetic_quality": 0.4476391077041626, "imaging_quality": 0.6404884649782764, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4eb22f59358942aebd49620120e48d95.mp4", "adv_score": 0.0, "adv_xclip": 0.22010380029678345, "adv_vbench": {"subject_consistency": 0.8680943238238493, "background_consistency": 0.8867238362630209, "motion_smoothness": 0.9228364664024046, "aesthetic_quality": 0.4099617004394531, "imaging_quality": 0.6253872517177037, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9a74e708.mp4", "clean_score": 1.0, "clean_xclip": 0.22323685884475708, "clean_vbench": {}, "adv_vid_id": "vids/c85eec3a.mp4", "adv_score": 0.0, "adv_xclip": 0.227715864777565, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/61af30c6.mp4", "clean_score": 1.0, "clean_xclip": 0.23323100805282593, "clean_vbench": {}, "adv_vid_id": "vids/e49fc9eb.mp4", "adv_score": 0.0, "adv_xclip": 0.23286351561546326, "adv_vbench": {}}}}
{"id": "8a1ba125e8d1409b99e1d2891b500263", "source": "vatex", "video_id": "Z_xtupU1Orw_000000_000010", "video_description": "A group of young people are outside in the snow, engaging in a snowball fight, running, laughing, and shouting.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a snowball.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "snowball"}, "target_prompt": "A person standing to the left of a snowball.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "snowball"}, "evaluation_question": "Is the person to the **right** of a snowball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a snowball. ULWP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e0411682c2484e8d91c0a30e47ffeab0.mp4", "clean_score": 1.0, "clean_xclip": 0.21388819813728333, "clean_vbench": {"subject_consistency": 0.9359436860928932, "background_consistency": 0.9739837646484375, "motion_smoothness": 0.9946356240670136, "aesthetic_quality": 0.5255109071731567, "imaging_quality": 0.6210477883475167, "dynamic_degree": 0.0}, "adv_vid_id": "vids/aacf55da69214306af0cfcc74adeda8c.mp4", "adv_score": 0.0, "adv_xclip": 0.20716610550880432, "adv_vbench": {"subject_consistency": 0.9445730236669382, "background_consistency": 0.9694620768229166, "motion_smoothness": 0.9957279700170963, "aesthetic_quality": 0.5087746977806091, "imaging_quality": 0.7150502294423629, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/851cdda6.mp4", "clean_score": 0.0, "clean_xclip": 0.22499334812164307, "clean_vbench": {}, "adv_vid_id": "vids/de2b5482.mp4", "adv_score": 1.0, "adv_xclip": 0.21297809481620789, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ff59f545.mp4", "clean_score": 1.0, "clean_xclip": 0.20980150997638702, "clean_vbench": {}, "adv_vid_id": "vids/52709d26.mp4", "adv_score": 1.0, "adv_xclip": 0.21253767609596252, "adv_vbench": {}}}}
{"id": "a46a26c75a5e4c919ced1c9bf935a071", "source": "vatex", "video_id": "tTMD0YpVIpg_000118_000128", "video_description": "A woman is preparing and applying a homemade face scrub or mask to her face.", "task": "AttributeRecognition", "clean_prompt": "A woman applying a natural face scrub to her face.", "clean_property": {"obj": "face scrub", "attribute": "natural"}, "target_prompt": "A woman applying a chemical face scrub to her face.", "target_property": {"obj": "face scrub", "attribute": "chemical"}, "evaluation_question": "Is the face scrub **natural**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman applying a natural face scrub to her face. \u00b7F)'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b320cf8f18834985a2d4f7a79b9f2833.mp4", "clean_score": 1.0, "clean_xclip": 0.22591018676757812, "clean_vbench": {"subject_consistency": 0.9643411990255117, "background_consistency": 0.9718017578125, "motion_smoothness": 0.9734940722270133, "aesthetic_quality": 0.4578331410884857, "imaging_quality": 0.6504320339280731, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1e187222f18e47d6973f297b3643f0ce.mp4", "adv_score": 0.0, "adv_xclip": 0.23981553316116333, "adv_vbench": {"subject_consistency": 0.9433898255228996, "background_consistency": 0.9521891276041666, "motion_smoothness": 0.9765385892300592, "aesthetic_quality": 0.3688587248325348, "imaging_quality": 0.6684580993652344, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d6bb82a0.mp4", "clean_score": 1.0, "clean_xclip": 0.22269952297210693, "clean_vbench": {}, "adv_vid_id": "vids/51878daf.mp4", "adv_score": 0.0, "adv_xclip": 0.24866092205047607, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/710b9fe2.mp4", "clean_score": 0.0, "clean_xclip": 0.16535373032093048, "clean_vbench": {}, "adv_vid_id": "vids/30b47f43.mp4", "adv_score": 1.0, "adv_xclip": 0.23020562529563904, "adv_vbench": {}}}}
{"id": "a296ee27b1c6473aa2611d21697219f6", "source": "vatex", "video_id": "jIBunMqpvcs_000346_000356", "video_description": "A woman and a boy are setting a dining table by placing drinking glasses upside down at each place setting.", "task": "Counting", "clean_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman setting a dining table by placing drinking glasses upside down at each place setting.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women setting the table?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting.PlatgefangenJudith erschien erleben", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de733808a31b4a2b99f4db1b85b5ed43.mp4", "clean_score": 1.0, "clean_xclip": 0.23553188145160675, "clean_vbench": {"subject_consistency": 0.9689091139783462, "background_consistency": 0.9530080159505209, "motion_smoothness": 0.9836039430336178, "aesthetic_quality": 0.48566821217536926, "imaging_quality": 0.7002152680377571, "dynamic_degree": 1.0}, "adv_vid_id": "vids/adab5f21508a4e0e977abdad9245cb72.mp4", "adv_score": 0.0, "adv_xclip": 0.2530209422111511, "adv_vbench": {"subject_consistency": 0.9798792408158382, "background_consistency": 0.9549662272135416, "motion_smoothness": 0.9832243146647804, "aesthetic_quality": 0.5358335375785828, "imaging_quality": 0.6851997375488281, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e8c76d76.mp4", "clean_score": 1.0, "clean_xclip": 0.2500170171260834, "clean_vbench": {}, "adv_vid_id": "vids/7454deef.mp4", "adv_score": 1.0, "adv_xclip": 0.18051064014434814, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dfc65985.mp4", "clean_score": 1.0, "clean_xclip": 0.21219328045845032, "clean_vbench": {}, "adv_vid_id": "vids/6d229424.mp4", "adv_score": 0.0, "adv_xclip": 0.22310541570186615, "adv_vbench": {}}}}
{"id": "8987271b987b449496437da19e90afea", "source": "vatex", "video_id": "JJWu9ybc_fs_000001_000011", "video_description": "Two boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "task": "Counting", "clean_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "clean_property": {"obj": "boy", "count": "three"}, "target_prompt": "One boy is playing in a snowy field, making a snowman using a tool.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **three** boys playing in the snowy field?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman. W*DEH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/357a0d91e1f646b0a990a21a79f14d46.mp4", "clean_score": 1.0, "clean_xclip": 0.2245214581489563, "clean_vbench": {"subject_consistency": 0.9344577429195245, "background_consistency": 0.95867919921875, "motion_smoothness": 0.9793368916046358, "aesthetic_quality": 0.7090281844139099, "imaging_quality": 0.6735292380196708, "dynamic_degree": 1.0}, "adv_vid_id": "vids/84d92f39db404836a3dd8e224cfe2bfd.mp4", "adv_score": 0.0, "adv_xclip": 0.20874238014221191, "adv_vbench": {"subject_consistency": 0.9405175478508075, "background_consistency": 0.9649912516276041, "motion_smoothness": 0.9788209955342734, "aesthetic_quality": 0.6997610330581665, "imaging_quality": 0.6363720547423071, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8173249b.mp4", "clean_score": 1.0, "clean_xclip": 0.22296513617038727, "clean_vbench": {}, "adv_vid_id": "vids/8f7e30d2.mp4", "adv_score": 0.0, "adv_xclip": 0.20662464201450348, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0d3787f0.mp4", "clean_score": 1.0, "clean_xclip": 0.2271917760372162, "clean_vbench": {}, "adv_vid_id": "vids/0f7a82d0.mp4", "adv_score": 0.0, "adv_xclip": 0.22164557874202728, "adv_vbench": {}}}}
{"id": "9e93b40b95ab422f86ff6797dadc6dbc", "source": "vatex", "video_id": "xzv6LXjujMA_000032_000042", "video_description": "A group of young men are outside playing a game of dominoes on a table and the trunk of a car, using profane language and shouting playfully.", "task": "SpatialUnderstanding", "clean_prompt": "A car parked to the left of a man.", "clean_property": {"obj_1": "car", "relation": "left of", "obj_2": "man"}, "target_prompt": "A car parked to the right of a man.", "target_property": {"obj_1": "car", "relation": "right of", "obj_2": "man"}, "evaluation_question": "Is the car to the **left** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A car parked to the left of a man. <8S>V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42f99d9f2c93430ca95cde8de5e52e75.mp4", "clean_score": 1.0, "clean_xclip": 0.12622231245040894, "clean_vbench": {"subject_consistency": 0.9332392401993275, "background_consistency": 0.9686126708984375, "motion_smoothness": 0.9891371349690854, "aesthetic_quality": 0.4719425439834595, "imaging_quality": 0.6564266165908502, "dynamic_degree": 0.0}, "adv_vid_id": "vids/02863610ff3348a58fcd307d4fb600db.mp4", "adv_score": 0.0, "adv_xclip": 0.11874645948410034, "adv_vbench": {"subject_consistency": 0.9954000121603409, "background_consistency": 0.9847513834635416, "motion_smoothness": 0.9952046653730936, "aesthetic_quality": 0.51256263256073, "imaging_quality": 0.7601622927918725, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bc54c10b.mp4", "clean_score": 0.0, "clean_xclip": 0.16788604855537415, "clean_vbench": {}, "adv_vid_id": "vids/9c29b6a8.mp4", "adv_score": 0.0, "adv_xclip": 0.15425845980644226, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/04dcba9e.mp4", "clean_score": 0.0, "clean_xclip": 0.14894156157970428, "clean_vbench": {}, "adv_vid_id": "vids/49b2f44c.mp4", "adv_score": 0.0, "adv_xclip": 0.1433050036430359, "adv_vbench": {}}}}
{"id": "bd0c9ab13bba45beb09e62644047e5c3", "source": "vatex", "video_id": "A_RumvVrXu4_000138_000148", "video_description": "A group of young people are running through an obstacle course in a gym, performing various gymnastics techniques such as jumping over objects and climbing stairs.", "task": "ObjectRecognition", "clean_prompt": "A group of young people running through an obstacle course in a gym, jumping over obstacles and climbing stairs.", "clean_property": {"obj": "obstacle"}, "target_prompt": "A group of young people running through a gym, trying to break through barriers and climbing walls.", "target_property": {"obj": "barrier"}, "evaluation_question": "Are the young people encountering **obstacles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A group of young people running through an obstacle course in a gym, jumping over obstacles and climbing stairs. Renewable valabil Youth soinsceni", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6f9fb77a3744493e9f651a31d9f181ff.mp4", "clean_score": 1.0, "clean_xclip": 0.22144053876399994, "clean_vbench": {"subject_consistency": 0.9012060860792795, "background_consistency": 0.9188334147135416, "motion_smoothness": 0.9345758305154623, "aesthetic_quality": 0.43946778774261475, "imaging_quality": 0.49464132892842194, "dynamic_degree": 1.0}, "adv_vid_id": "vids/17939342725747988d043eeeb4635ddc.mp4", "adv_score": 0.0, "adv_xclip": 0.16694438457489014, "adv_vbench": {"subject_consistency": 0.8885190257181724, "background_consistency": 0.897186279296875, "motion_smoothness": 0.9309844974544602, "aesthetic_quality": 0.4196694493293762, "imaging_quality": 0.5332421555811045, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e5055f13.mp4", "clean_score": 1.0, "clean_xclip": 0.161100834608078, "clean_vbench": {}, "adv_vid_id": "vids/dbbf54d3.mp4", "adv_score": 0.0, "adv_xclip": 0.23056524991989136, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a864add9.mp4", "clean_score": 1.0, "clean_xclip": 0.21520811319351196, "clean_vbench": {}, "adv_vid_id": "vids/6afdc87c.mp4", "adv_score": 1.0, "adv_xclip": 0.20521456003189087, "adv_vbench": {}}}}
{"id": "d02632576b064edeb8d8bcfcd8fd223c", "source": "vatex", "video_id": "1XhixsI46yE_000003_000013", "video_description": "A man in blue shorts is in a room bending a metal bar around his legs while being instructed.", "task": "ObjectRecognition", "clean_prompt": "A man in blue shorts is bending a metal bar around his legs in a room.", "clean_property": {"obj": "metal bar"}, "target_prompt": "A man in blue shorts is bending a wooden stick around his legs in a room.", "target_property": {"obj": "wooden stick"}, "evaluation_question": "Is the object being bent in the video a **metal bar**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man in blue shorts is bending a metal bar around his legs in a room. ->&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4fc887acf944128b972c21f7808a249.mp4", "clean_score": 1.0, "clean_xclip": 0.13247042894363403, "clean_vbench": {"subject_consistency": 0.9524089551220337, "background_consistency": 0.963409423828125, "motion_smoothness": 0.9783717284013657, "aesthetic_quality": 0.3977873623371124, "imaging_quality": 0.5776549234195631, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bde4948ccb964d81a011c8c9634f49b6.mp4", "adv_score": 0.0, "adv_xclip": 0.1403844952583313, "adv_vbench": {"subject_consistency": 0.9630566549797853, "background_consistency": 0.9503885904947916, "motion_smoothness": 0.9793389134428205, "aesthetic_quality": 0.45436301827430725, "imaging_quality": 0.6699944445551658, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6b3d0df1.mp4", "clean_score": 1.0, "clean_xclip": 0.14639607071876526, "clean_vbench": {}, "adv_vid_id": "vids/27187f50.mp4", "adv_score": 1.0, "adv_xclip": 0.13462048768997192, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c1ebab84.mp4", "clean_score": 1.0, "clean_xclip": 0.18151605129241943, "clean_vbench": {}, "adv_vid_id": "vids/a79e35eb.mp4", "adv_score": 1.0, "adv_xclip": 0.1344565451145172, "adv_vbench": {}}}}
{"id": "6951fb180bc8400b81128f534333dd0b", "source": "vatex", "video_id": "N211QZ5qIag_000077_000087", "video_description": "A person is using a small printer to print out a piece of paper with their identification on it.", "task": "ActionRecognition", "clean_prompt": "A person photocopying a piece of paper.", "clean_property": {"obj": "person", "action": "photocopying", "target": "paper"}, "target_prompt": "A person shredding a piece of paper.", "target_property": {"obj": "person", "action": "shredding", "target": "paper"}, "evaluation_question": "Is the person **photocopying** a piece of paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person photocopying a piece of paper. RL$JC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd447c0c2357497aac46f41307e5feb1.mp4", "clean_score": 1.0, "clean_xclip": 0.19489151239395142, "clean_vbench": {"subject_consistency": 0.9392679488907257, "background_consistency": 0.9669850667317709, "motion_smoothness": 0.9847043454470266, "aesthetic_quality": 0.3043819069862366, "imaging_quality": 0.5903250153210698, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b2032f79f1f14c2aad7c9f9f5ff3acd2.mp4", "adv_score": 0.0, "adv_xclip": 0.15606079995632172, "adv_vbench": {"subject_consistency": 0.9526976595322291, "background_consistency": 0.9581502278645834, "motion_smoothness": 0.990792692006072, "aesthetic_quality": 0.22562113404273987, "imaging_quality": 0.5181998902924206, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/caf81824.mp4", "clean_score": 1.0, "clean_xclip": 0.21190455555915833, "clean_vbench": {}, "adv_vid_id": "vids/9b020d06.mp4", "adv_score": 1.0, "adv_xclip": 0.22797732055187225, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5d9208a8.mp4", "clean_score": 1.0, "clean_xclip": 0.24359118938446045, "clean_vbench": {}, "adv_vid_id": "vids/763174a9.mp4", "adv_score": 1.0, "adv_xclip": 0.24202755093574524, "adv_vbench": {}}}}
{"id": "b2bc199de46a4bfd8798c7d8f82865fa", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "SpatialUnderstanding", "clean_prompt": "A laptop positioned to the right of a TV.", "clean_property": {"obj_1": "laptop", "relation": "right of", "obj_2": "tv"}, "target_prompt": "A laptop positioned to the left of a TV.", "target_property": {"obj_1": "laptop", "relation": "left of", "obj_2": "tv"}, "evaluation_question": "Is the laptop to the **right** of the TV?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A laptop positioned to the right of a TV. '';))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df648fac80734ce8806a1ee46a52ef73.mp4", "clean_score": 1.0, "clean_xclip": 0.20981472730636597, "clean_vbench": {"subject_consistency": 0.9993575705836216, "background_consistency": 0.9980265299479166, "motion_smoothness": 0.9969167520853506, "aesthetic_quality": 0.419526070356369, "imaging_quality": 0.6268054837596659, "dynamic_degree": 0.0}, "adv_vid_id": "vids/5c51dd5e418a461985b2df579a961524.mp4", "adv_score": 0.0, "adv_xclip": 0.20026306807994843, "adv_vbench": {"subject_consistency": 0.9994997344911098, "background_consistency": 0.9990285237630209, "motion_smoothness": 0.9970532014985778, "aesthetic_quality": 0.4350173771381378, "imaging_quality": 0.6734950832444794, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/65516236.mp4", "clean_score": 0.0, "clean_xclip": 0.22405056655406952, "clean_vbench": {}, "adv_vid_id": "vids/fbdb8bfe.mp4", "adv_score": 0.0, "adv_xclip": 0.17352943122386932, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/82d15256.mp4", "clean_score": 0.0, "clean_xclip": 0.18748922646045685, "clean_vbench": {}, "adv_vid_id": "vids/c73cc8a8.mp4", "adv_score": 0.0, "adv_xclip": 0.20220714807510376, "adv_vbench": {}}}}
{"id": "4ec64eb3d0d84efc98abbb15ba1c65d6", "source": "vatex", "video_id": "1TOcO_XjVW0_000000_000010", "video_description": "Two men wearing straw hats and white T-shirts are dancing and stomping on grapes in a wooden barrel while another man pours more grapes into the barrel. Music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A man stomping on grapes in a wooden barrel.", "clean_property": {"obj": "man", "action": "stomping grapes", "target": "grapes"}, "target_prompt": "A man pouring grapes into a wooden barrel.", "target_property": {"obj": "man", "action": "pouring grapes", "target": "grapes"}, "evaluation_question": "Is the man **stomping** on grapes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man stomping on grapes in a wooden barrel. WNX71", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33e31e0cafa24e1a8faadb1ccd457cfa.mp4", "clean_score": 1.0, "clean_xclip": 0.23706857860088348, "clean_vbench": {"subject_consistency": 0.8672762662172318, "background_consistency": 0.9465179443359375, "motion_smoothness": 0.9576072198330207, "aesthetic_quality": 0.6337538361549377, "imaging_quality": 0.5179128973824637, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f082b88c13264468b0005dda18582ad1.mp4", "adv_score": 0.0, "adv_xclip": 0.21742786467075348, "adv_vbench": {"subject_consistency": 0.8938489382465681, "background_consistency": 0.9274648030598959, "motion_smoothness": 0.9520029089632253, "aesthetic_quality": 0.5719969868659973, "imaging_quality": 0.5085527552390585, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8f962f6a.mp4", "clean_score": 0.0, "clean_xclip": 0.2447800487279892, "clean_vbench": {}, "adv_vid_id": "vids/7ade9296.mp4", "adv_score": 0.0, "adv_xclip": 0.2121344655752182, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6db4e156.mp4", "clean_score": 0.0, "clean_xclip": 0.22636041045188904, "clean_vbench": {}, "adv_vid_id": "vids/52a362dc.mp4", "adv_score": 1.0, "adv_xclip": 0.2160242795944214, "adv_vbench": {}}}}
{"id": "d574439bf7bf423a89b781b255a549a8", "source": "vatex", "video_id": "Bb_ksbWpLxI_000000_000010", "video_description": "A man is on a basketball court practicing dribbling tricks with two basketballs while music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A person dribbling basketballs on a basketball court.", "clean_property": {"obj": "person", "action": "dribbling basketball", "target": null}, "target_prompt": "A person shooting basketballs on a basketball court.", "target_property": {"obj": "person", "action": "shooting basketball", "target": null}, "evaluation_question": "Is the person **dribbling** basketballs?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person dribbling basketballs on a basketball court. Madame Portrait Nachmittag entspannenische", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01983d5d8b6e4b4386f7f013d3618a73.mp4", "clean_score": 1.0, "clean_xclip": 0.24202603101730347, "clean_vbench": {"subject_consistency": 0.8825499458859364, "background_consistency": 0.937164306640625, "motion_smoothness": 0.9389675568176087, "aesthetic_quality": 0.4316793978214264, "imaging_quality": 0.588310639517648, "dynamic_degree": 1.0}, "adv_vid_id": "vids/516b80416dd74255b90098cc9c49f961.mp4", "adv_score": 0.0, "adv_xclip": 0.22821466624736786, "adv_vbench": {"subject_consistency": 0.937109416971604, "background_consistency": 0.9459330240885416, "motion_smoothness": 0.952251630519749, "aesthetic_quality": 0.4515153169631958, "imaging_quality": 0.6336833151992487, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e4339cfe.mp4", "clean_score": 1.0, "clean_xclip": 0.23037633299827576, "clean_vbench": {}, "adv_vid_id": "vids/36686f94.mp4", "adv_score": 1.0, "adv_xclip": 0.20993869006633759, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ca8b5f07.mp4", "clean_score": 0.0, "clean_xclip": 0.23620794713497162, "clean_vbench": {}, "adv_vid_id": "vids/1acf94e4.mp4", "adv_score": 1.0, "adv_xclip": 0.23345884680747986, "adv_vbench": {}}}}
{"id": "e8a6c2f07fad48ffa17ce43619796a57", "source": "vatex", "video_id": "zbIbjob4XF4_000087_000097", "video_description": "A man is water skiing on a lake, being pulled by a fast boat, zig-zagging back and forth and creating spumes of spray.", "task": "ActionRecognition", "clean_prompt": "A water skier water skiing on a lake.", "clean_property": {"obj": "water skier", "action": "water skiing", "target": null}, "target_prompt": "A water skier falling on a lake.", "target_property": {"obj": "water skier", "action": "falling", "target": null}, "evaluation_question": "Is the water skier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A water skier water skiing on a lake. ;2JFL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc14171fbd2c4b3383b132b69a93f86b.mp4", "clean_score": 1.0, "clean_xclip": 0.2581028938293457, "clean_vbench": {"subject_consistency": 0.882257675131162, "background_consistency": 0.9124399820963541, "motion_smoothness": 0.9679788604517167, "aesthetic_quality": 0.4289661943912506, "imaging_quality": 0.5336996023995535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/dc49cce422eb48a48e318e62d236b4ac.mp4", "adv_score": 0.0, "adv_xclip": 0.2474052757024765, "adv_vbench": {"subject_consistency": 0.9078957016269366, "background_consistency": 0.952362060546875, "motion_smoothness": 0.9604375375085734, "aesthetic_quality": 0.34512943029403687, "imaging_quality": 0.5008799587950414, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f5d09947.mp4", "clean_score": 1.0, "clean_xclip": 0.26075899600982666, "clean_vbench": {}, "adv_vid_id": "vids/6b2c52bb.mp4", "adv_score": 1.0, "adv_xclip": 0.21499750018119812, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a063e07b.mp4", "clean_score": 1.0, "clean_xclip": 0.2093464434146881, "clean_vbench": {}, "adv_vid_id": "vids/e137ce38.mp4", "adv_score": 1.0, "adv_xclip": 0.22746586799621582, "adv_vbench": {}}}}
{"id": "a53ae32d8c4b4abc9b217ee3d6d2792e", "source": "vatex", "video_id": "Pd4-fmq61kw_000014_000024", "video_description": "A boy is seated on a couch, tearing pages from a composition notebook.", "task": "SpatialUnderstanding", "clean_prompt": "A composition notebook to the right of a boy seated on a couch.", "clean_property": {"obj_1": "composition notebook", "relation": "right of", "obj_2": "boy"}, "target_prompt": "A composition notebook to the left of a boy seated on a couch.", "target_property": {"obj_1": "composition notebook", "relation": "left of", "obj_2": "boy"}, "evaluation_question": "Is the composition notebook to the **right** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A composition notebook to the right of a boy seated on a couch. Funny Bennett spatiu quotidienDecorative", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2eb5dbe8dd124396a049d69a369a49b8.mp4", "clean_score": 1.0, "clean_xclip": 0.22837811708450317, "clean_vbench": {"subject_consistency": 0.991786099349459, "background_consistency": 0.9884897867838541, "motion_smoothness": 0.9967067381157709, "aesthetic_quality": 0.4650883078575134, "imaging_quality": 0.7692167943837691, "dynamic_degree": 0.0}, "adv_vid_id": "vids/104a6db2c8f844bba4d26549c4221ebc.mp4", "adv_score": 0.0, "adv_xclip": 0.07564426958560944, "adv_vbench": {"subject_consistency": 0.9962045593808094, "background_consistency": 0.9863942464192709, "motion_smoothness": 0.9956955810487775, "aesthetic_quality": 0.48025837540626526, "imaging_quality": 0.733538743622449, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7cc33951.mp4", "clean_score": 0.0, "clean_xclip": 0.1562391072511673, "clean_vbench": {}, "adv_vid_id": "vids/39b754d7.mp4", "adv_score": 0.0, "adv_xclip": 0.16411122679710388, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ae2c4752.mp4", "clean_score": 0.0, "clean_xclip": 0.19539877772331238, "clean_vbench": {}, "adv_vid_id": "vids/b4b22f85.mp4", "adv_score": 0.0, "adv_xclip": 0.16961608827114105, "adv_vbench": {}}}}
{"id": "5d58dc02365d4633b2bd69cb4ae87473", "source": "vatex", "video_id": "P02zv3sQE4I_000028_000038", "video_description": "A wheelchair basketball game is taking place between two teams in a gym. Players in wheelchairs are competing, passing, and shooting the ball. Dramatic music plays in the background, and text in a foreign language is displayed.", "task": "Counting", "clean_prompt": "Four players in wheelchairs are competing in a basketball game in a gym.", "clean_property": {"obj": "wheelchair", "count": "four"}, "target_prompt": "One player in a wheelchair is practicing shooting in an empty gym.", "target_property": {"obj": "wheelchair", "count": "one"}, "evaluation_question": "Are there exactly **four** players in wheelchairs competing in the game?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four players in wheelchairs are competing in a basketball game in a gym. .\\9)V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aec88efb31a24b0b8128e7cf52df78dd.mp4", "clean_score": 1.0, "clean_xclip": 0.2401483803987503, "clean_vbench": {"subject_consistency": 0.9728960637003183, "background_consistency": 0.9431101481119791, "motion_smoothness": 0.9810083590534979, "aesthetic_quality": 0.4938891530036926, "imaging_quality": 0.6562623245862065, "dynamic_degree": 1.0}, "adv_vid_id": "vids/797dca61103d469db9be5e4ba78cac53.mp4", "adv_score": 0.0, "adv_xclip": 0.22662031650543213, "adv_vbench": {"subject_consistency": 0.9767066650092602, "background_consistency": 0.9590352376302084, "motion_smoothness": 0.9786830393165497, "aesthetic_quality": 0.49860015511512756, "imaging_quality": 0.7068673846186424, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a43cd6dc.mp4", "clean_score": 0.0, "clean_xclip": 0.24853919446468353, "clean_vbench": {}, "adv_vid_id": "vids/3b3e78f5.mp4", "adv_score": 0.0, "adv_xclip": 0.2538444697856903, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4c81150c.mp4", "clean_score": 0.0, "clean_xclip": 0.25154149532318115, "clean_vbench": {}, "adv_vid_id": "vids/6cd5501b.mp4", "adv_score": 0.0, "adv_xclip": 0.26397812366485596, "adv_vbench": {}}}}
{"id": "946de5914f8241b59164e5c036b845b8", "source": "vatex", "video_id": "t-aPsebmI0Q_000084_000094", "video_description": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen or similar item.", "task": "ObjectRecognition", "clean_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen.", "clean_property": {"obj": "pen"}, "target_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a drumstick.", "target_property": {"obj": "drumstick"}, "evaluation_question": "Is the boy using a **pen** to create beats?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen. ?W0DE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be85e53126be4db78bf51d3e14494498.mp4", "clean_score": 1.0, "clean_xclip": 0.1760144978761673, "clean_vbench": {"subject_consistency": 0.9521863261858622, "background_consistency": 0.9700164794921875, "motion_smoothness": 0.9571142920902929, "aesthetic_quality": 0.3952534794807434, "imaging_quality": 0.41738933096126635, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d0224cc0e8d34fb1b6bea21a60e764ed.mp4", "adv_score": 0.0, "adv_xclip": 0.17110024392604828, "adv_vbench": {"subject_consistency": 0.944844288751483, "background_consistency": 0.9606475830078125, "motion_smoothness": 0.9549045975739833, "aesthetic_quality": 0.3785087466239929, "imaging_quality": 0.44222109191271725, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/50307987.mp4", "clean_score": 0.0, "clean_xclip": 0.14329078793525696, "clean_vbench": {}, "adv_vid_id": "vids/97696dde.mp4", "adv_score": 0.0, "adv_xclip": 0.16071394085884094, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dcae1d21.mp4", "clean_score": 0.0, "clean_xclip": 0.1467757225036621, "clean_vbench": {}, "adv_vid_id": "vids/986f7774.mp4", "adv_score": 0.0, "adv_xclip": 0.17683231830596924, "adv_vbench": {}}}}
{"id": "76d4aec48db34da1bb8cf665e7f8207e", "source": "vatex", "video_id": "2QWzPnu90Kc_000220_000230", "video_description": "A person is on the roof of a house, inspecting and cleaning the gutters by removing leaves and dirt. They are also giving instructions about roof inspection and maintenance.", "task": "ObjectRecognition", "clean_prompt": "A person on the roof of a house, inspecting and cleaning the gutters while a trash can is nearby.", "clean_property": {"obj": "trash can"}, "target_prompt": "A person on the roof of a house, inspecting and cleaning the gutters while a recycling bin is nearby.", "target_property": {"obj": "recycling bin"}, "evaluation_question": "Is there a **trash can** present in the video?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person on the roof of a house, inspecting and cleaning the gutters while a trash can is nearby. -#TVF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fac916ed0b044bbc97513da184d067d0.mp4", "clean_score": 1.0, "clean_xclip": 0.2982904314994812, "clean_vbench": {"subject_consistency": 0.977693165342013, "background_consistency": 0.9762217203776041, "motion_smoothness": 0.9860261340197087, "aesthetic_quality": 0.5301055908203125, "imaging_quality": 0.6190217598117127, "dynamic_degree": 0.0}, "adv_vid_id": "vids/951ea975b88a429d9c206446e84321b4.mp4", "adv_score": 0.0, "adv_xclip": 0.2587689161300659, "adv_vbench": {"subject_consistency": 0.9558771575490633, "background_consistency": 0.9586385091145834, "motion_smoothness": 0.989559321700002, "aesthetic_quality": 0.5433468222618103, "imaging_quality": 0.6224515673579002, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9323bafd.mp4", "clean_score": 0.0, "clean_xclip": 0.25471100211143494, "clean_vbench": {}, "adv_vid_id": "vids/ae53b83d.mp4", "adv_score": 1.0, "adv_xclip": 0.22536858916282654, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9d774ea5.mp4", "clean_score": 1.0, "clean_xclip": 0.24636310338974, "clean_vbench": {}, "adv_vid_id": "vids/e16b5961.mp4", "adv_score": 1.0, "adv_xclip": 0.22466200590133667, "adv_vbench": {}}}}
{"id": "83ca0296f8e040a39603186ce194ef9a", "source": "vatex", "video_id": "cbznHY8uOOE_000006_000016", "video_description": "A man is demonstrating and explaining how to perform exercises using an exercise ball, including balancing and pull-ins.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating exercises using an exercise ball, including balancing and pull-ins, who is muscular.", "clean_property": {"obj": "person", "attribute": "muscular"}, "target_prompt": "A person demonstrating exercises using an exercise ball, including balancing and pull-ins, who is slim.", "target_property": {"obj": "person", "attribute": "slim"}, "evaluation_question": "Is the person **muscular**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person demonstrating exercises using an exercise ball, including balancing and pull-ins, who is muscular. =P$$X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e614aced3f84448bfd87406729eb3da.mp4", "clean_score": 1.0, "clean_xclip": 0.19931885600090027, "clean_vbench": {"subject_consistency": 0.9396692135681709, "background_consistency": 0.9612630208333334, "motion_smoothness": 0.9847676624404906, "aesthetic_quality": 0.47648316621780396, "imaging_quality": 0.5162464134060607, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1d12862a4c3941a698ef93a13eecad60.mp4", "adv_score": 0.0, "adv_xclip": 0.19508510828018188, "adv_vbench": {"subject_consistency": 0.9547241572290659, "background_consistency": 0.9444529215494791, "motion_smoothness": 0.9780848064116335, "aesthetic_quality": 0.5159366726875305, "imaging_quality": 0.5178701221699618, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4808e111.mp4", "clean_score": 1.0, "clean_xclip": 0.1652493178844452, "clean_vbench": {}, "adv_vid_id": "vids/bfc0f22c.mp4", "adv_score": 1.0, "adv_xclip": 0.1805914342403412, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e4c7d262.mp4", "clean_score": 1.0, "clean_xclip": 0.22826477885246277, "clean_vbench": {}, "adv_vid_id": "vids/da295941.mp4", "adv_score": 1.0, "adv_xclip": 0.21282586455345154, "adv_vbench": {}}}}
{"id": "bad90e0fca15482bbaabb3a313c88f20", "source": "vatex", "video_id": "JMyCoStRMFg_000006_000016", "video_description": "In a sand-lined outdoor arena, a cowboy on horseback chases and lassoes a calf, then jumps off the horse to tie the calf.", "task": "ObjectRecognition", "clean_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena.", "clean_property": {"obj": "calf"}, "target_prompt": "A cowboy on horseback chases and lassoes a sheep in a sand-lined outdoor arena.", "target_property": {"obj": "sheep"}, "evaluation_question": "Is the animal being chased in the video a **calf**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena. F-!'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c00ff397385b4cf492404854fee44dc2.mp4", "clean_score": 1.0, "clean_xclip": 0.1786983609199524, "clean_vbench": {"subject_consistency": 0.9368632901459932, "background_consistency": 0.890228271484375, "motion_smoothness": 0.9728370911250303, "aesthetic_quality": 0.4887249767780304, "imaging_quality": 0.6888501038843272, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4238b100c1e64adfbdfe9d9611911289.mp4", "adv_score": 0.0, "adv_xclip": 0.17662063241004944, "adv_vbench": {"subject_consistency": 0.9098335728049278, "background_consistency": 0.9125010172526041, "motion_smoothness": 0.9703560110483237, "aesthetic_quality": 0.4814309775829315, "imaging_quality": 0.6835936246599469, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/17403739.mp4", "clean_score": 0.0, "clean_xclip": 0.20823411643505096, "clean_vbench": {}, "adv_vid_id": "vids/44543820.mp4", "adv_score": 0.0, "adv_xclip": 0.1889953464269638, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/66750668.mp4", "clean_score": 1.0, "clean_xclip": 0.1800898015499115, "clean_vbench": {}, "adv_vid_id": "vids/92f9ea38.mp4", "adv_score": 0.0, "adv_xclip": 0.16131016612052917, "adv_vbench": {}}}}
{"id": "71bae95776a949b8a30a1d8784b3ff53", "source": "vatex", "video_id": "qpTtNJRcPjc_000218_000228", "video_description": "A young man is standing at a podium in a yellow room, reading from various documents including a newspaper and a book, while giving a speech to an audience.", "task": "ActionRecognition", "clean_prompt": "A person reading a newspaper at a podium in a yellow room.", "clean_property": {"obj": "person", "action": "reading newspaper", "target": null}, "target_prompt": "A person throwing a newspaper at a podium in a yellow room.", "target_property": {"obj": "person", "action": "throwing newspaper", "target": null}, "evaluation_question": "Is the person **reading** a newspaper?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person reading a newspaper at a podium in a yellow room. QR%Q|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9df3cec3d86340a08df2b90057bc631c.mp4", "clean_score": 1.0, "clean_xclip": 0.2383130043745041, "clean_vbench": {"subject_consistency": 0.9962629533062378, "background_consistency": 0.9680684407552084, "motion_smoothness": 0.9979562216636911, "aesthetic_quality": 0.6630999445915222, "imaging_quality": 0.7351143288125798, "dynamic_degree": 0.0}, "adv_vid_id": "vids/66e682c964c64f7b9bb0cff8a4968214.mp4", "adv_score": 0.0, "adv_xclip": 0.1833709180355072, "adv_vbench": {"subject_consistency": 0.9946907721459866, "background_consistency": 0.9898935953776041, "motion_smoothness": 0.9975500105906561, "aesthetic_quality": 0.5325145721435547, "imaging_quality": 0.7672462027413505, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ea55e3e9.mp4", "clean_score": 1.0, "clean_xclip": 0.21318434178829193, "clean_vbench": {}, "adv_vid_id": "vids/faf2e9dd.mp4", "adv_score": 1.0, "adv_xclip": 0.2049212008714676, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/8e9d5996.mp4", "clean_score": 1.0, "clean_xclip": 0.20756486058235168, "clean_vbench": {}, "adv_vid_id": "vids/63fb5729.mp4", "adv_score": 1.0, "adv_xclip": 0.22927924990653992, "adv_vbench": {}}}}
{"id": "956c37da977e4f34a4205e2df8b37db8", "source": "vatex", "video_id": "X2Qn08i-I48_000062_000072", "video_description": "A man is playing a song on a trumpet in a dimly lit room.", "task": "ActionRecognition", "clean_prompt": "A person playing trumpet in a dimly lit room.", "clean_property": {"obj": "person", "action": "playing trumpet", "target": null}, "target_prompt": "A person playing guitar in a dimly lit room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing trumpet in a dimly lit room. FE@AI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/408c0220d2224e44bbe84bbbc33c84ed.mp4", "clean_score": 1.0, "clean_xclip": 0.27415668964385986, "clean_vbench": {"subject_consistency": 0.7346095247194171, "background_consistency": 0.901885986328125, "motion_smoothness": 0.993740349579904, "aesthetic_quality": 0.36693236231803894, "imaging_quality": 0.2035053081901706, "dynamic_degree": 1.0}, "adv_vid_id": "vids/70df0feb5415487bb30fd60a3b4b8045.mp4", "adv_score": 0.0, "adv_xclip": 0.15962255001068115, "adv_vbench": {"subject_consistency": 1.0, "background_consistency": 1.0, "motion_smoothness": 1.0, "aesthetic_quality": 0.33590564131736755, "imaging_quality": 0.20485637664794923, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2afe2e5b.mp4", "clean_score": 1.0, "clean_xclip": 0.24331751465797424, "clean_vbench": {}, "adv_vid_id": "vids/18a3b26a.mp4", "adv_score": 1.0, "adv_xclip": 0.2477833777666092, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f44e985c.mp4", "clean_score": 1.0, "clean_xclip": 0.24739304184913635, "clean_vbench": {}, "adv_vid_id": "vids/f81ebee6.mp4", "adv_score": 1.0, "adv_xclip": 0.23716990649700165, "adv_vbench": {}}}}
{"id": "878f2122e03646a1b9a79bb92ffc1f62", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "Counting", "clean_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper.", "clean_property": {"obj": "paper", "count": "three"}, "target_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on one sheet of paper.", "target_property": {"obj": "paper", "count": "one"}, "evaluation_question": "Are there exactly **three** sheets of paper being used?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper.holicmotifs lieber attraktiv Birthday", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/416e6d85e748421d88b3cce281f75849.mp4", "clean_score": 1.0, "clean_xclip": 0.15169933438301086, "clean_vbench": {"subject_consistency": 0.948447635397315, "background_consistency": 0.9648640950520834, "motion_smoothness": 0.9780856347522291, "aesthetic_quality": 0.24040162563323975, "imaging_quality": 0.690891755551708, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5867a33104014b4ba898e4bcba2098a0.mp4", "adv_score": 0.0, "adv_xclip": 0.15398858487606049, "adv_vbench": {"subject_consistency": 0.9637154856075844, "background_consistency": 0.9573160807291666, "motion_smoothness": 0.9824760367495764, "aesthetic_quality": 0.24874737858772278, "imaging_quality": 0.7577005674401108, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c08670bb.mp4", "clean_score": 0.0, "clean_xclip": 0.15217053890228271, "clean_vbench": {}, "adv_vid_id": "vids/66ae22d0.mp4", "adv_score": 0.0, "adv_xclip": 0.1942293345928192, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6e3530de.mp4", "clean_score": 0.0, "clean_xclip": 0.1763562709093094, "clean_vbench": {}, "adv_vid_id": "vids/e16993d5.mp4", "adv_score": 0.0, "adv_xclip": 0.18101254105567932, "adv_vbench": {}}}}
{"id": "5e4b6e8325fe442f8c02c6633c175eba", "source": "vatex", "video_id": "bzawAHbQI68_000459_000469", "video_description": "Two women are sitting on an outdoor swing or bench, working together on a craft project involving weaving a basket using twigs and string. A baby in a stroller is nearby, making noises.", "task": "ActionRecognition", "clean_prompt": "A woman weaving a basket on an outdoor swing.", "clean_property": {"obj": "woman", "action": "weaving basket", "target": null}, "target_prompt": "A woman throwing a basket on an outdoor swing.", "target_property": {"obj": "woman", "action": "throwing a basket", "target": null}, "evaluation_question": "Is the woman **weaving** a basket?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman weaving a basket on an outdoor swing. Basket Leistungsciones Wimbledon bani", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a079621f9904e4c84c7e31c0105075d.mp4", "clean_score": 1.0, "clean_xclip": 0.25160878896713257, "clean_vbench": {"subject_consistency": 0.9727308402458826, "background_consistency": 0.9687601725260416, "motion_smoothness": 0.9658723474504256, "aesthetic_quality": 0.6102505922317505, "imaging_quality": 0.7011434780821508, "dynamic_degree": 1.0}, "adv_vid_id": "vids/47bfefbd95b843009fdf5cc5b6ed0c89.mp4", "adv_score": 0.0, "adv_xclip": 0.26860255002975464, "adv_vbench": {"subject_consistency": 0.9501868889977535, "background_consistency": 0.9124654134114584, "motion_smoothness": 0.9616861124979826, "aesthetic_quality": 0.550494372844696, "imaging_quality": 0.6308538242262237, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fe986680.mp4", "clean_score": 0.0, "clean_xclip": 0.24694368243217468, "clean_vbench": {}, "adv_vid_id": "vids/e13df35d.mp4", "adv_score": 0.0, "adv_xclip": 0.2083231806755066, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/90cb71f7.mp4", "clean_score": 0.0, "clean_xclip": 0.23430860042572021, "clean_vbench": {}, "adv_vid_id": "vids/521a8ed5.mp4", "adv_score": 0.0, "adv_xclip": 0.23655015230178833, "adv_vbench": {}}}}
{"id": "121e12516d2e478597db186a8ef46478", "source": "vatex", "video_id": "M9rzGNp5gfU_000003_000013", "video_description": "A man is walking and balancing on a tightrope at a beach while juggling balls.", "task": "ObjectRecognition", "clean_prompt": "A man is walking and balancing on a tightrope at a beach while juggling balls.", "clean_property": {"obj": "tightrope"}, "target_prompt": "A man is swinging and performing tricks on a trapeze at a circus.", "target_property": {"obj": "trapeze"}, "evaluation_question": "Is the man performing on a **tightrope**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is walking and balancing on a tightrope at a beach while juggling balls. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49dad606c22b42afb03298567633b2dd.mp4", "clean_score": 1.0, "clean_xclip": 0.233653262257576, "clean_vbench": {"subject_consistency": 0.9050584336121877, "background_consistency": 0.9389139811197916, "motion_smoothness": 0.9826157221440531, "aesthetic_quality": 0.6085106730461121, "imaging_quality": 0.6703500747680664, "dynamic_degree": 1.0}, "adv_vid_id": "vids/029d2754cd8042338bea7731bfe07887.mp4", "adv_score": 0.0, "adv_xclip": 0.25253814458847046, "adv_vbench": {"subject_consistency": 0.8849462425957123, "background_consistency": 0.8811492919921875, "motion_smoothness": 0.9793316303180223, "aesthetic_quality": 0.5784909129142761, "imaging_quality": 0.6968938734093492, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/66ec2d56.mp4", "clean_score": 0.0, "clean_xclip": 0.22087185084819794, "clean_vbench": {}, "adv_vid_id": "vids/3c8628e5.mp4", "adv_score": 1.0, "adv_xclip": 0.17090359330177307, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b7b1cd81.mp4", "clean_score": 1.0, "clean_xclip": 0.2515144944190979, "clean_vbench": {}, "adv_vid_id": "vids/ee3007e6.mp4", "adv_score": 1.0, "adv_xclip": 0.19562511146068573, "adv_vbench": {}}}}
{"id": "c9a46cc1a3694e88b3c7bfeb63d5282d", "source": "vatex", "video_id": "Q7p82CcJ4Fc_000108_000118", "video_description": "Two men, one of whom is young, are working in a woodshop. They are using a machine to cut and mill wood, with one man turning a crank and the other handling the wood through the machine.", "task": "ActionRecognition", "clean_prompt": "A person sawing wood in a woodshop.", "clean_property": {"obj": "person", "action": "sawing wood", "target": null}, "target_prompt": "A person painting wood in a woodshop.", "target_property": {"obj": "person", "action": "painting wood", "target": null}, "evaluation_question": "Is the person **sawing** wood?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sawing wood in a woodshop. UF\u00b7)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b830275c379740f2a56327d9f09e30ed.mp4", "clean_score": 1.0, "clean_xclip": 0.1610109806060791, "clean_vbench": {"subject_consistency": 0.961066777507464, "background_consistency": 0.9832865397135416, "motion_smoothness": 0.9894711492879045, "aesthetic_quality": 0.46152248978614807, "imaging_quality": 0.6477967258375519, "dynamic_degree": 1.0}, "adv_vid_id": "vids/71244c3715ac42a58805669a536b14e9.mp4", "adv_score": 0.0, "adv_xclip": 0.23191455006599426, "adv_vbench": {"subject_consistency": 0.9582071503003439, "background_consistency": 0.9839223225911459, "motion_smoothness": 0.9902528695634633, "aesthetic_quality": 0.4013954699039459, "imaging_quality": 0.5888005852212711, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/207084c9.mp4", "clean_score": 1.0, "clean_xclip": 0.19962401688098907, "clean_vbench": {}, "adv_vid_id": "vids/08dff28e.mp4", "adv_score": 1.0, "adv_xclip": 0.21604374051094055, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cf81f586.mp4", "clean_score": 1.0, "clean_xclip": 0.212567538022995, "clean_vbench": {}, "adv_vid_id": "vids/392a6fbd.mp4", "adv_score": 1.0, "adv_xclip": 0.20189429819583893, "adv_vbench": {}}}}
{"id": "a93d285fb4d54f9b896675230a16f296", "source": "vatex", "video_id": "4jznikNJSG0_000005_000015", "video_description": "A person is creating artwork by carving and burning images and text into a small circular piece of wood using a heat gun.", "task": "SpatialUnderstanding", "clean_prompt": "A piece of wood that is farther from the camera than a heat gun.", "clean_property": {"obj_1": "wood", "relation": "farther from the camera than", "obj_2": "heat gun"}, "target_prompt": "A piece of wood that is closer to the camera than a heat gun.", "target_property": {"obj_1": "wood", "relation": "closer to the camera than", "obj_2": "heat gun"}, "evaluation_question": "Is the piece of wood **farther from the camera than** the heat gun?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A piece of wood that is farther from the camera than a heat gun. bekommt Chanelpflege backpack Pflege", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5108ae43607c4064bbbba11737c2dd9e.mp4", "clean_score": 1.0, "clean_xclip": 0.19949139654636383, "clean_vbench": {"subject_consistency": 0.9257247932255268, "background_consistency": 0.9652506510416666, "motion_smoothness": 0.9963251071358328, "aesthetic_quality": 0.3894484043121338, "imaging_quality": 0.6110856301443918, "dynamic_degree": 0.0}, "adv_vid_id": "vids/c2a89a6be0844a95a32ad28111c29608.mp4", "adv_score": 0.0, "adv_xclip": 0.140195831656456, "adv_vbench": {"subject_consistency": 0.8412958594659964, "background_consistency": 0.9320068359375, "motion_smoothness": 0.9903522185848361, "aesthetic_quality": 0.3782426416873932, "imaging_quality": 0.40609456860289284, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1022220e.mp4", "clean_score": 0.0, "clean_xclip": 0.2029523402452469, "clean_vbench": {}, "adv_vid_id": "vids/719ea472.mp4", "adv_score": 0.0, "adv_xclip": 0.17422835528850555, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/af24be12.mp4", "clean_score": 0.0, "clean_xclip": 0.17018984258174896, "clean_vbench": {}, "adv_vid_id": "vids/4eae4dc2.mp4", "adv_score": 0.0, "adv_xclip": 0.13165462017059326, "adv_vbench": {}}}}
{"id": "1851355097ad4b708a47572f6da8214e", "source": "vatex", "video_id": "N211QZ5qIag_000077_000087", "video_description": "A person is using a small printer to print out a piece of paper with their identification on it.", "task": "ActionRecognition", "clean_prompt": "A person photocopying a piece of paper.", "clean_property": {"obj": "person", "action": "photocopying", "target": "paper"}, "target_prompt": "A person shredding a piece of paper.", "target_property": {"obj": "person", "action": "shredding", "target": "paper"}, "evaluation_question": "Is the person **photocopying** a piece of paper?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person photocopying a piece of paper. !0P^B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf0f10b90c3043fdbb804fb0d6c9af46.mp4", "clean_score": 1.0, "clean_xclip": 0.19489151239395142, "clean_vbench": {"subject_consistency": 0.9392679488907257, "background_consistency": 0.9669850667317709, "motion_smoothness": 0.9847043454470266, "aesthetic_quality": 0.3043819069862366, "imaging_quality": 0.5903250153210698, "dynamic_degree": 1.0}, "adv_vid_id": "vids/b7d643b8e96341b8a0b0714a128467b6.mp4", "adv_score": 0.0, "adv_xclip": 0.20708833634853363, "adv_vbench": {"subject_consistency": 0.9205067977309227, "background_consistency": 0.95074462890625, "motion_smoothness": 0.9859265813803659, "aesthetic_quality": 0.26791560649871826, "imaging_quality": 0.4941392267966757, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6826a494.mp4", "clean_score": 1.0, "clean_xclip": 0.21795177459716797, "clean_vbench": {}, "adv_vid_id": "vids/9ba20ca7.mp4", "adv_score": 1.0, "adv_xclip": 0.21744415163993835, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3aa2cb3b.mp4", "clean_score": 1.0, "clean_xclip": 0.23681232333183289, "clean_vbench": {}, "adv_vid_id": "vids/07dd4cf3.mp4", "adv_score": 1.0, "adv_xclip": 0.2223915457725525, "adv_vbench": {}}}}
{"id": "0db271cad47744229d5c54aa34f11c41", "source": "vatex", "video_id": "22QytzFKlos_000000_000010", "video_description": "A man in swimming trunks dives into a clear blue swimming pool and swims using breaststroke, sometimes swimming underwater and sometimes on the surface.", "task": "Counting", "clean_prompt": "Five people diving into a clear blue swimming pool and swimming using breaststroke.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person diving into a clear blue swimming pool and swimming using breaststroke.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people diving into the swimming pool?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Five people diving into a clear blue swimming pool and swimming using breaststroke. '))!W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b68250a324a346a1bc02bde457f75a4b.mp4", "clean_score": 1.0, "clean_xclip": 0.18572159111499786, "clean_vbench": {"subject_consistency": 0.8852631362775961, "background_consistency": 0.9416097005208334, "motion_smoothness": 0.9773003954475309, "aesthetic_quality": 0.47063127160072327, "imaging_quality": 0.49981326667629944, "dynamic_degree": 0.0}, "adv_vid_id": "vids/320b2576993d4d84a0a8db55c316a218.mp4", "adv_score": 0.0, "adv_xclip": 0.13366976380348206, "adv_vbench": {"subject_consistency": 0.7897557063649098, "background_consistency": 0.917572021484375, "motion_smoothness": 0.9774149989535423, "aesthetic_quality": 0.3841119706630707, "imaging_quality": 0.3293703686461157, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d2322721.mp4", "clean_score": 0.0, "clean_xclip": 0.17886826395988464, "clean_vbench": {}, "adv_vid_id": "vids/fb037a14.mp4", "adv_score": 0.0, "adv_xclip": 0.15116068720817566, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/787cb8f0.mp4", "clean_score": 0.0, "clean_xclip": 0.188703253865242, "clean_vbench": {}, "adv_vid_id": "vids/2ccd3f86.mp4", "adv_score": 1.0, "adv_xclip": 0.17851115763187408, "adv_vbench": {}}}}
{"id": "d51213c807524e0cb430a2a0816894a7", "source": "vatex", "video_id": "kxbUUbwO-6o_000382_000392", "video_description": "A man is demonstrating how to work on a car engine, specifically focusing on removing a stuck cap from the engine compartment while explaining the process.", "task": "Counting", "clean_prompt": "Four people working on a car engine, with one man demonstrating how to remove a stuck cap while explaining the process.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person working on a car engine, demonstrating how to remove a stuck cap while explaining the process.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people working on the car engine?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Four people working on a car engine, with one man demonstrating how to remove a stuck cap while explaining the process. Edelstahl boliSpeed glatt Werkzeug", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad2c3dc289f149428940d7cb09184c10.mp4", "clean_score": 1.0, "clean_xclip": 0.18103443086147308, "clean_vbench": {"subject_consistency": 0.9649118011196455, "background_consistency": 0.9621632893880209, "motion_smoothness": 0.9765866969698116, "aesthetic_quality": 0.5671350955963135, "imaging_quality": 0.6515125819614955, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7a450e58e87a48b8897fd3955c66d366.mp4", "adv_score": 0.0, "adv_xclip": 0.17453083395957947, "adv_vbench": {"subject_consistency": 0.9641399638106426, "background_consistency": 0.9544423421223959, "motion_smoothness": 0.9583160299034738, "aesthetic_quality": 0.5152214765548706, "imaging_quality": 0.639449412287498, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cbe24e6d.mp4", "clean_score": 1.0, "clean_xclip": 0.16255880892276764, "clean_vbench": {}, "adv_vid_id": "vids/9408b924.mp4", "adv_score": 1.0, "adv_xclip": 0.15751686692237854, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e0ef0f63.mp4", "clean_score": 0.0, "clean_xclip": 0.1485564410686493, "clean_vbench": {}, "adv_vid_id": "vids/6d15150a.mp4", "adv_score": 0.0, "adv_xclip": 0.1520628184080124, "adv_vbench": {}}}}
{"id": "539d6cf868564fc89037201db82232aa", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "Counting", "clean_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching. Fiber sustainabilityinitiative Erst unterwegs", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f5b68662c91a4a2290bd237d3129a894.mp4", "clean_score": 1.0, "clean_xclip": 0.20295044779777527, "clean_vbench": {"subject_consistency": 0.9290519822388887, "background_consistency": 0.9426320393880209, "motion_smoothness": 0.974932345092744, "aesthetic_quality": 0.43521764874458313, "imaging_quality": 0.6105633607202647, "dynamic_degree": 1.0}, "adv_vid_id": "vids/89ba0ee6f4314f9ebbbc54e3a512ad92.mp4", "adv_score": 0.0, "adv_xclip": 0.142869234085083, "adv_vbench": {"subject_consistency": 0.907575124874711, "background_consistency": 0.9500325520833334, "motion_smoothness": 0.976615168656197, "aesthetic_quality": 0.42037564516067505, "imaging_quality": 0.6595321663058534, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/bf19def0.mp4", "clean_score": 0.0, "clean_xclip": 0.14622938632965088, "clean_vbench": {}, "adv_vid_id": "vids/57a458dc.mp4", "adv_score": 0.0, "adv_xclip": 0.12204530090093613, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/919630b8.mp4", "clean_score": 1.0, "clean_xclip": 0.1426219493150711, "clean_vbench": {}, "adv_vid_id": "vids/da44245a.mp4", "adv_score": 1.0, "adv_xclip": 0.15623082220554352, "adv_vbench": {}}}}
{"id": "e1b5a9bbf71046cfa78d4d6bc4ab497d", "source": "vatex", "video_id": "AnwCVPInx18_000064_000074", "video_description": "A woman is creating and decorating a snowman using various materials like pumpkins, plastic, and a white ball, with the help of a power drill and other tools.", "task": "ActionRecognition", "clean_prompt": "A woman using a power drill to create and decorate a snowman.", "clean_property": {"obj": "woman", "action": "using a power drill", "target": "snowman"}, "target_prompt": "A woman using a power drill to create and decorate a pumpkin.", "target_property": {"obj": "woman", "action": "using a power drill", "target": "pumpkin"}, "evaluation_question": "Is the woman **using a power drill** to create and decorate a snowman?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman using a power drill to create and decorate a snowman.curg Rachelintele 2014-11- Pumpkin", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/53e6f7082c0e4000a4f0fde1863bbeff.mp4", "clean_score": 1.0, "clean_xclip": 0.2627992630004883, "clean_vbench": {"subject_consistency": 0.9470325037837029, "background_consistency": 0.9461161295572916, "motion_smoothness": 0.9889146645283627, "aesthetic_quality": 0.511505663394928, "imaging_quality": 0.7393623211919045, "dynamic_degree": 1.0}, "adv_vid_id": "vids/905c6abd284d430a909e150d70ea83ef.mp4", "adv_score": 0.0, "adv_xclip": 0.2362806648015976, "adv_vbench": {"subject_consistency": 0.9573741462081671, "background_consistency": 0.960693359375, "motion_smoothness": 0.9855540492238561, "aesthetic_quality": 0.5663943886756897, "imaging_quality": 0.736784428187779, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/025829d3.mp4", "clean_score": 1.0, "clean_xclip": 0.2614808976650238, "clean_vbench": {}, "adv_vid_id": "vids/336f8c7d.mp4", "adv_score": 0.0, "adv_xclip": 0.22671988606452942, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cce25f06.mp4", "clean_score": 0.0, "clean_xclip": 0.27735695242881775, "clean_vbench": {}, "adv_vid_id": "vids/01821841.mp4", "adv_score": 0.0, "adv_xclip": 0.15256181359291077, "adv_vbench": {}}}}
{"id": "56c136d4c38a4062ac6f80ae26a63606", "source": "vatex", "video_id": "7N6ionlMMZw_000025_000035", "video_description": "A woman demonstrates how to sew a zigzag pattern and fix a garment using a sewing machine on a piece of fabric.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine.", "clean_property": {"obj": "person"}, "target_prompt": "A robot demonstrating how to sew a zigzag pattern on a sewing machine.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine. X)PBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/91662c5ba6e94de5a3e93a6a0598aef4.mp4", "clean_score": 1.0, "clean_xclip": 0.1995011866092682, "clean_vbench": {"subject_consistency": 0.9814506197969118, "background_consistency": 0.9752349853515625, "motion_smoothness": 0.9771486611330489, "aesthetic_quality": 0.5396555662155151, "imaging_quality": 0.7707328920948262, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a4f09a17932842c191ca29a9e700b790.mp4", "adv_score": 0.0, "adv_xclip": 0.20272304117679596, "adv_vbench": {"subject_consistency": 0.9606325396647056, "background_consistency": 0.9739532470703125, "motion_smoothness": 0.975451211432361, "aesthetic_quality": 0.4699215590953827, "imaging_quality": 0.7254352195895448, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/42b6d24d.mp4", "clean_score": 1.0, "clean_xclip": 0.19851958751678467, "clean_vbench": {}, "adv_vid_id": "vids/eeb44a76.mp4", "adv_score": 1.0, "adv_xclip": 0.1841316819190979, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/61355142.mp4", "clean_score": 0.0, "clean_xclip": 0.2096261829137802, "clean_vbench": {}, "adv_vid_id": "vids/2f6b5b4c.mp4", "adv_score": 1.0, "adv_xclip": 0.1870882660150528, "adv_vbench": {}}}}
{"id": "d337b71c5af0434682e0aa96012e37c8", "source": "vatex", "video_id": "Pd4-fmq61kw_000014_000024", "video_description": "A boy is seated on a couch, tearing pages from a composition notebook.", "task": "SpatialUnderstanding", "clean_prompt": "A composition notebook to the right of a boy seated on a couch.", "clean_property": {"obj_1": "composition notebook", "relation": "right of", "obj_2": "boy"}, "target_prompt": "A composition notebook to the left of a boy seated on a couch.", "target_property": {"obj_1": "composition notebook", "relation": "left of", "obj_2": "boy"}, "evaluation_question": "Is the composition notebook to the **right** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A composition notebook to the right of a boy seated on a couch. PD0O(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2fd1c00b30fa40bb976dd5a72de3e5d0.mp4", "clean_score": 1.0, "clean_xclip": 0.22837811708450317, "clean_vbench": {"subject_consistency": 0.991786099349459, "background_consistency": 0.9884897867838541, "motion_smoothness": 0.9967067381157709, "aesthetic_quality": 0.4650883078575134, "imaging_quality": 0.7692167943837691, "dynamic_degree": 0.0}, "adv_vid_id": "vids/6e41db3d0f4f41708c5953cada4f2aa2.mp4", "adv_score": 0.0, "adv_xclip": 0.20601804554462433, "adv_vbench": {"subject_consistency": 0.9968184450020393, "background_consistency": 0.9913991292317709, "motion_smoothness": 0.9971065806112825, "aesthetic_quality": 0.4900503158569336, "imaging_quality": 0.4744256171401666, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/66b1b819.mp4", "clean_score": 0.0, "clean_xclip": 0.19371286034584045, "clean_vbench": {}, "adv_vid_id": "vids/971c161a.mp4", "adv_score": 0.0, "adv_xclip": 0.15391512215137482, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c321a9b1.mp4", "clean_score": 0.0, "clean_xclip": 0.16779103875160217, "clean_vbench": {}, "adv_vid_id": "vids/4e25ef0f.mp4", "adv_score": 0.0, "adv_xclip": 0.19553318619728088, "adv_vbench": {}}}}
{"id": "2e10b1547c1347c5a5e6fd6ac271f077", "source": "vatex", "video_id": "1jIKAImNXBk_000000_000010", "video_description": "A boy is writing or drawing on the side of a blue phone booth with a black marker.", "task": "ActionRecognition", "clean_prompt": "A person tagging graffiti on the side of a blue phone booth.", "clean_property": {"obj": "person", "action": "tagging graffiti", "target": "phone booth"}, "target_prompt": "A person removing graffiti from a blue phone booth.", "target_property": {"obj": "person", "action": "removing graffiti", "target": "phone booth"}, "evaluation_question": "Is the person **tagging graffiti** on the phone booth?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person tagging graffiti on the side of a blue phone booth. freuenkabel junge Hunde Flugzeug", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bab9d9d7a6c24f3fb53e0bda047b927c.mp4", "clean_score": 1.0, "clean_xclip": 0.24315960705280304, "clean_vbench": {"subject_consistency": 0.9381580147892237, "background_consistency": 0.9142964680989584, "motion_smoothness": 0.9842037944807552, "aesthetic_quality": 0.5717015266418457, "imaging_quality": 0.7103766600939693, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f686b1323d184ad69281836d06590ddd.mp4", "adv_score": 0.0, "adv_xclip": 0.18475835025310516, "adv_vbench": {"subject_consistency": 0.954799817254146, "background_consistency": 0.9465738932291666, "motion_smoothness": 0.9914910327717764, "aesthetic_quality": 0.581636905670166, "imaging_quality": 0.7444831458889708, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e4230c76.mp4", "clean_score": 1.0, "clean_xclip": 0.21542024612426758, "clean_vbench": {}, "adv_vid_id": "vids/060c0d57.mp4", "adv_score": 0.0, "adv_xclip": 0.18302756547927856, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6d080549.mp4", "clean_score": 1.0, "clean_xclip": 0.22904032468795776, "clean_vbench": {}, "adv_vid_id": "vids/62f99128.mp4", "adv_score": 1.0, "adv_xclip": 0.16248011589050293, "adv_vbench": {}}}}
{"id": "c02768a6078a4493bcfc4aeecd8c940e", "source": "vatex", "video_id": "K0WOzuD4-oc_000017_000027", "video_description": "A man is playing pranks on people in public using a fake snake, causing them to react in surprise and fear.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a fake snake, playing a prank on passersby.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "fake snake"}, "target_prompt": "A person standing to the left of a fake snake, playing a prank on passersby.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "fake snake"}, "evaluation_question": "Is the person to the **right** of a fake snake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a fake snake, playing a prank on passersby. ?'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/902a5165d3ef4bf085ae435791591903.mp4", "clean_score": 1.0, "clean_xclip": 0.1417706459760666, "clean_vbench": {"subject_consistency": 0.9514240051309267, "background_consistency": 0.9215596516927084, "motion_smoothness": 0.9753256902523098, "aesthetic_quality": 0.45444124937057495, "imaging_quality": 0.6014048074216258, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8f75375db77c4721a7624ace480eb1ff.mp4", "adv_score": 0.0, "adv_xclip": 0.23397988080978394, "adv_vbench": {"subject_consistency": 0.9754943375786146, "background_consistency": 0.9808247884114584, "motion_smoothness": 0.9931005500837166, "aesthetic_quality": 0.46300840377807617, "imaging_quality": 0.7145885342967753, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/56f2aa67.mp4", "clean_score": 1.0, "clean_xclip": 0.25339144468307495, "clean_vbench": {}, "adv_vid_id": "vids/5b95fc2a.mp4", "adv_score": 0.0, "adv_xclip": 0.2694617509841919, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/139195b7.mp4", "clean_score": 1.0, "clean_xclip": 0.23908951878547668, "clean_vbench": {}, "adv_vid_id": "vids/ba54eedc.mp4", "adv_score": 0.0, "adv_xclip": 0.24417950212955475, "adv_vbench": {}}}}
{"id": "3cecbb62cbfe4b068177c03fcbbfa4e1", "source": "vatex", "video_id": "hsxpSVlqmsQ_000002_000012", "video_description": "A person is demonstrating how to cook a cobbler using a Dutch oven on a campfire.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a Dutch oven on a campfire.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "dutch oven"}, "target_prompt": "A person standing to the right of a Dutch oven on a campfire.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "Dutch oven"}, "evaluation_question": "Is the person to the **left** of the Dutch oven?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the left of a Dutch oven on a campfire. /G*CB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4267911f75eb462da05e4ad8175baf6b.mp4", "clean_score": 1.0, "clean_xclip": 0.2487032413482666, "clean_vbench": {"subject_consistency": 0.9725968819111586, "background_consistency": 0.9839731852213541, "motion_smoothness": 0.9726466931937384, "aesthetic_quality": 0.6896722316741943, "imaging_quality": 0.4706571765821807, "dynamic_degree": 1.0}, "adv_vid_id": "vids/365d53fd39a24393a2ecf818d356d06b.mp4", "adv_score": 0.0, "adv_xclip": 0.24670308828353882, "adv_vbench": {"subject_consistency": 0.9747903278718392, "background_consistency": 0.981719970703125, "motion_smoothness": 0.9666988006397261, "aesthetic_quality": 0.6763715147972107, "imaging_quality": 0.5670165120338907, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9e2027e1.mp4", "clean_score": 0.0, "clean_xclip": 0.2549484968185425, "clean_vbench": {}, "adv_vid_id": "vids/333fb19f.mp4", "adv_score": 1.0, "adv_xclip": 0.22170671820640564, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/88e40719.mp4", "clean_score": 0.0, "clean_xclip": 0.2545795738697052, "clean_vbench": {}, "adv_vid_id": "vids/6217d315.mp4", "adv_score": 1.0, "adv_xclip": 0.2685096859931946, "adv_vbench": {}}}}
{"id": "4f5e1f4b6b1b492a8bd7d25926a8c3e3", "source": "vatex", "video_id": "v8DNLQVCPuY_000065_000075", "video_description": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head.", "clean_property": {"obj": "person"}, "target_prompt": "A child plays with a toy while assembling a colorful building block set.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head. U%Y*U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/37e79d04c9684519965ca4b3cf7bd54e.mp4", "clean_score": 1.0, "clean_xclip": 0.19982795417308807, "clean_vbench": {"subject_consistency": 0.9372918500254551, "background_consistency": 0.9530232747395834, "motion_smoothness": 0.9792049290363007, "aesthetic_quality": 0.4424136281013489, "imaging_quality": 0.6484110454637176, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c1642666710741e78b61de62fb516abe.mp4", "adv_score": 0.0, "adv_xclip": 0.23036104440689087, "adv_vbench": {"subject_consistency": 0.9214253220707178, "background_consistency": 0.9367472330729166, "motion_smoothness": 0.9782272876132191, "aesthetic_quality": 0.4729277491569519, "imaging_quality": 0.556507784006547, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d9fbe357.mp4", "clean_score": 1.0, "clean_xclip": 0.1713801622390747, "clean_vbench": {}, "adv_vid_id": "vids/22919f50.mp4", "adv_score": 1.0, "adv_xclip": 0.15078306198120117, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/03861f97.mp4", "clean_score": 1.0, "clean_xclip": 0.15709665417671204, "clean_vbench": {}, "adv_vid_id": "vids/2a081e5d.mp4", "adv_score": 0.0, "adv_xclip": 0.17076916992664337, "adv_vbench": {}}}}
{"id": "b8189b58d7704db38427622674510b82", "source": "vatex", "video_id": "7nl_MxNbWS4_000004_000014", "video_description": "A loud crowd at a concert is holding and passing a young man and a woman above them as they crowd surf.", "task": "ActionRecognition", "clean_prompt": "A man surfing in a crowd.", "clean_property": {"obj": "man", "action": "surfing crowd", "target": null}, "target_prompt": "A man crowd surfing over a woman.", "target_property": {"obj": "man", "action": "crowd surfing", "target": "woman"}, "evaluation_question": "Is the man **surfing** in a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man surfing in a crowd. embarrassing Alexandria iubire vrei Sfant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aefd409649054c6a95f0b7175b003c88.mp4", "clean_score": 1.0, "clean_xclip": 0.1666758805513382, "clean_vbench": {"subject_consistency": 0.8148030725618204, "background_consistency": 0.9120534261067709, "motion_smoothness": 0.9465912082425563, "aesthetic_quality": 0.51307612657547, "imaging_quality": 0.4887611634390695, "dynamic_degree": 1.0}, "adv_vid_id": "vids/696b88db8c84401687f842ac06d53829.mp4", "adv_score": 0.0, "adv_xclip": 0.2363368272781372, "adv_vbench": {"subject_consistency": 0.7655996674050888, "background_consistency": 0.8811696370442709, "motion_smoothness": 0.8281964060797931, "aesthetic_quality": 0.43338701128959656, "imaging_quality": 0.3952839419306541, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c12db9ea.mp4", "clean_score": 1.0, "clean_xclip": 0.16464969515800476, "clean_vbench": {}, "adv_vid_id": "vids/60c05c72.mp4", "adv_score": 1.0, "adv_xclip": 0.18886399269104004, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9e0f7147.mp4", "clean_score": 1.0, "clean_xclip": 0.18022224307060242, "clean_vbench": {}, "adv_vid_id": "vids/41e92bb0.mp4", "adv_score": 1.0, "adv_xclip": 0.1347179114818573, "adv_vbench": {}}}}
{"id": "e91b7d78585d4a458e3298b1fa16852f", "source": "vatex", "video_id": "33dWGUc3bEA_000000_000010", "video_description": "A woman is in a men's store demonstrating how to tie a bow tie and a necktie on a mannequin and an assistant.", "task": "ActionRecognition", "clean_prompt": "A woman tying a necktie on a mannequin in a men's store.", "clean_property": {"obj": "woman", "action": "tying necktie", "target": "mannequin"}, "target_prompt": "A woman removing a necktie from a mannequin in a men's store.", "target_property": {"obj": "woman", "action": "removing necktie", "target": "mannequin"}, "evaluation_question": "Is the woman **tying** a necktie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman tying a necktie on a mannequin in a men's store. EBS7R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13d6b302d0bb41769b9427d776cc6fe3.mp4", "clean_score": 1.0, "clean_xclip": 0.28322213888168335, "clean_vbench": {"subject_consistency": 0.9592925620575746, "background_consistency": 0.951324462890625, "motion_smoothness": 0.976800863674302, "aesthetic_quality": 0.5860835909843445, "imaging_quality": 0.656358981229821, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9d3a841ef309421096422cfbdbed0f9f.mp4", "adv_score": 0.0, "adv_xclip": 0.2895079255104065, "adv_vbench": {"subject_consistency": 0.9554602994273106, "background_consistency": 0.9545694986979166, "motion_smoothness": 0.9745824742609235, "aesthetic_quality": 0.5566164255142212, "imaging_quality": 0.6325735582624162, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/880e701d.mp4", "clean_score": 0.0, "clean_xclip": 0.2377849817276001, "clean_vbench": {}, "adv_vid_id": "vids/d9dc5942.mp4", "adv_score": 1.0, "adv_xclip": 0.2951336205005646, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/36816a7d.mp4", "clean_score": 0.0, "clean_xclip": 0.2512538433074951, "clean_vbench": {}, "adv_vid_id": "vids/323afdf7.mp4", "adv_score": 1.0, "adv_xclip": 0.2625994086265564, "adv_vbench": {}}}}
{"id": "0385c7ceb2514c6a84f0129cfdbc925b", "source": "vatex", "video_id": "rseoEvLeT4A_000039_000049", "video_description": "A woman and her daughter are sitting on a bench in a busy city street, feeding pigeons.", "task": "Counting", "clean_prompt": "Three women sitting on a bench in a busy city street, feeding pigeons.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "A woman sitting alone on a bench in a busy city street, feeding pigeons.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women sitting on the bench?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three women sitting on a bench in a busy city street, feeding pigeons.arrondissement grij Zustand jardin Satz", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d982ac9dbb4a4f22aba4d861f12aeaf3.mp4", "clean_score": 1.0, "clean_xclip": 0.24314799904823303, "clean_vbench": {"subject_consistency": 0.8887534563740095, "background_consistency": 0.8975982666015625, "motion_smoothness": 0.9422468166568324, "aesthetic_quality": 0.4476391077041626, "imaging_quality": 0.6404884649782764, "dynamic_degree": 1.0}, "adv_vid_id": "vids/94cddabc79c344c4a7768e9a749095d6.mp4", "adv_score": 0.0, "adv_xclip": 0.22559411823749542, "adv_vbench": {"subject_consistency": 0.9334573795398077, "background_consistency": 0.9463144938151041, "motion_smoothness": 0.9780699697220709, "aesthetic_quality": 0.5237287878990173, "imaging_quality": 0.7037179199530154, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ed45f442.mp4", "clean_score": 1.0, "clean_xclip": 0.2205078899860382, "clean_vbench": {}, "adv_vid_id": "vids/6e99d52a.mp4", "adv_score": 1.0, "adv_xclip": 0.24630293250083923, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/14ea4015.mp4", "clean_score": 1.0, "clean_xclip": 0.2208636850118637, "clean_vbench": {}, "adv_vid_id": "vids/316ef9b0.mp4", "adv_score": 0.0, "adv_xclip": 0.2443576604127884, "adv_vbench": {}}}}
{"id": "bde9d815ae3141868521eae9f12732aa", "source": "vatex", "video_id": "M3-oz_R_xsk_000019_000029", "video_description": "A man in a yellow shirt and black exercise shorts is repeatedly hitting a large rubber tire with a sledgehammer outdoors.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a tire outdoors.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "tire"}, "target_prompt": "A person kicking a tire outdoors.", "target_property": {"obj": "person", "action": "kicking", "target": "tire"}, "evaluation_question": "Is the person **using a sledge hammer** on the tire?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer on a tire outdoors. !0D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c4f107f0ee04dd39a1d390e59b5038f.mp4", "clean_score": 1.0, "clean_xclip": 0.18487314879894257, "clean_vbench": {"subject_consistency": 0.9502305705100298, "background_consistency": 0.9425760904947916, "motion_smoothness": 0.9616815815253571, "aesthetic_quality": 0.48593324422836304, "imaging_quality": 0.6837147903442383, "dynamic_degree": 1.0}, "adv_vid_id": "vids/360988d8b39f41fd9658c1a2fbd80e72.mp4", "adv_score": 0.0, "adv_xclip": 0.20931798219680786, "adv_vbench": {"subject_consistency": 0.9342201376954714, "background_consistency": 0.9437917073567709, "motion_smoothness": 0.9609229709437788, "aesthetic_quality": 0.5167078971862793, "imaging_quality": 0.6940043017329002, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/318e89a1.mp4", "clean_score": 1.0, "clean_xclip": 0.24103930592536926, "clean_vbench": {}, "adv_vid_id": "vids/bb3d2455.mp4", "adv_score": 1.0, "adv_xclip": 0.1979416161775589, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6ac02492.mp4", "clean_score": 1.0, "clean_xclip": 0.15278805792331696, "clean_vbench": {}, "adv_vid_id": "vids/f4a83100.mp4", "adv_score": 1.0, "adv_xclip": 0.2614854574203491, "adv_vbench": {}}}}
{"id": "ca30e40553244b85b7c8965539c3768b", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "AttributeRecognition", "clean_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "ice", "attribute": "thick"}, "target_prompt": "A man is standing in the street using a sledge hammer to break up thin ice on the ground.", "target_property": {"obj": "ice", "attribute": "thin"}, "evaluation_question": "Is the ice **thick** on the ground?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground. IVE6R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ea0b03ab033346aca82f3f9a1884cbaf.mp4", "clean_score": 1.0, "clean_xclip": 0.22530493140220642, "clean_vbench": {"subject_consistency": 0.8883486899236838, "background_consistency": 0.9467620849609375, "motion_smoothness": 0.9520445291381727, "aesthetic_quality": 0.48140934109687805, "imaging_quality": 0.6031626191431162, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d85c0bb3a2874273b224e3600148df6b.mp4", "adv_score": 0.0, "adv_xclip": 0.23409885168075562, "adv_vbench": {"subject_consistency": 0.8878364786505699, "background_consistency": 0.95599365234375, "motion_smoothness": 0.9613166584084765, "aesthetic_quality": 0.46647313237190247, "imaging_quality": 0.6568209449612364, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c3b29a39.mp4", "clean_score": 1.0, "clean_xclip": 0.23493646085262299, "clean_vbench": {}, "adv_vid_id": "vids/07c9afae.mp4", "adv_score": 0.0, "adv_xclip": 0.24687156081199646, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/40346d59.mp4", "clean_score": 1.0, "clean_xclip": 0.23024395108222961, "clean_vbench": {}, "adv_vid_id": "vids/2672cc0b.mp4", "adv_score": 1.0, "adv_xclip": 0.22888970375061035, "adv_vbench": {}}}}
{"id": "19e9f42124794fafaf6a6a828fd978cc", "source": "vatex", "video_id": "Ua7qoMG0aBU_000504_000514", "video_description": "A boy is fishing in a muddy swamp, catching and cleaning fish using a net and stringer.", "task": "SpatialUnderstanding", "clean_prompt": "A stringer farther from the camera than a fish in a muddy swamp.", "clean_property": {"obj_1": "stringer", "relation": "farther from the camera than", "obj_2": "fish"}, "target_prompt": "A stringer closer to the camera than a fish in a muddy swamp.", "target_property": {"obj_1": "stringer", "relation": "closer to the camera than", "obj_2": "fish"}, "evaluation_question": "Is the stringer **farther from the camera than** the fish?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A stringer farther from the camera than a fish in a muddy swamp. X&LFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35d7a084932b4840aa9b63931ed60ae1.mp4", "clean_score": 1.0, "clean_xclip": 0.22597579658031464, "clean_vbench": {"subject_consistency": 0.9359778488675753, "background_consistency": 0.943695068359375, "motion_smoothness": 0.9755048672889938, "aesthetic_quality": 0.49376046657562256, "imaging_quality": 0.6217688478742327, "dynamic_degree": 0.0}, "adv_vid_id": "vids/12056df442c64d1d999028e092fe7456.mp4", "adv_score": 0.0, "adv_xclip": 0.16162094473838806, "adv_vbench": {"subject_consistency": 0.92352654847006, "background_consistency": 0.9448293050130209, "motion_smoothness": 0.9668663815384693, "aesthetic_quality": 0.4545673429965973, "imaging_quality": 0.6301612970780353, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/57b8163e.mp4", "clean_score": 0.0, "clean_xclip": 0.17829686403274536, "clean_vbench": {}, "adv_vid_id": "vids/70e9b8ec.mp4", "adv_score": 0.0, "adv_xclip": 0.1349623054265976, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e42b0a7d.mp4", "clean_score": 0.0, "clean_xclip": 0.19469720125198364, "clean_vbench": {}, "adv_vid_id": "vids/2da5e520.mp4", "adv_score": 0.0, "adv_xclip": 0.21543732285499573, "adv_vbench": {}}}}
{"id": "0580f9822af44503a555fdce6172a283", "source": "vatex", "video_id": "2GAPlZ6gD8s_000038_000048", "video_description": "A young man is standing outside on a lawn, demonstrating various juggling techniques with three balls.", "task": "ActionRecognition", "clean_prompt": "A person juggling balls on a lawn.", "clean_property": {"obj": "person", "action": "juggling balls", "target": null}, "target_prompt": "A person juggling clubs on a lawn.", "target_property": {"obj": "person", "action": "juggling clubs", "target": null}, "evaluation_question": "Is the person **juggling balls**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person juggling balls on a lawn. %&FE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c1af93af085403fb2fb0f74b569eff7.mp4", "clean_score": 1.0, "clean_xclip": 0.2693372070789337, "clean_vbench": {"subject_consistency": 0.9458960356811682, "background_consistency": 0.9367319742838541, "motion_smoothness": 0.9524198079308883, "aesthetic_quality": 0.5034029483795166, "imaging_quality": 0.6501348464343013, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0653641bf296460694b6d306bfe376ba.mp4", "adv_score": 0.0, "adv_xclip": 0.22137320041656494, "adv_vbench": {"subject_consistency": 0.8666470143944025, "background_consistency": 0.9190775553385416, "motion_smoothness": 0.9248327757479021, "aesthetic_quality": 0.41415396332740784, "imaging_quality": 0.5700407526444415, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/12558b1a.mp4", "clean_score": 1.0, "clean_xclip": 0.19712740182876587, "clean_vbench": {}, "adv_vid_id": "vids/0bef1701.mp4", "adv_score": 1.0, "adv_xclip": 0.20813988149166107, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/225929b7.mp4", "clean_score": 1.0, "clean_xclip": 0.24763397872447968, "clean_vbench": {}, "adv_vid_id": "vids/88dbd23c.mp4", "adv_score": 1.0, "adv_xclip": 0.25133705139160156, "adv_vbench": {}}}}
{"id": "e8aa9229341541578aade1221d1c2e87", "source": "vatex", "video_id": "4kixfScXLX0_000067_000077", "video_description": "A family gathering where two children are playing Twister on the floor while adults watch, drink, and smoke.", "task": "ActionRecognition", "clean_prompt": "An adult smoking while watching children play Twister at a family gathering.", "clean_property": {"obj": "adult", "action": "smoking", "target": null}, "target_prompt": "An adult drinking while watching children play Twister at a family gathering.", "target_property": {"obj": "adult", "action": "drinking", "target": null}, "evaluation_question": "Is the adult **smoking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult smoking while watching children play Twister at a family gathering. UG7(I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5c9752fdff6467497788d250fce04ce.mp4", "clean_score": 1.0, "clean_xclip": 0.21308092772960663, "clean_vbench": {"subject_consistency": 0.9547299475719532, "background_consistency": 0.9406789143880209, "motion_smoothness": 0.9767830170005245, "aesthetic_quality": 0.5849280953407288, "imaging_quality": 0.6482731752979513, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a429da90c787464eb73d4e327e67c5e8.mp4", "adv_score": 0.0, "adv_xclip": 0.13807375729084015, "adv_vbench": {"subject_consistency": 0.9467380363494158, "background_consistency": 0.9559733072916666, "motion_smoothness": 0.9744372491023159, "aesthetic_quality": 0.6232588887214661, "imaging_quality": 0.709211916242327, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/58ecae53.mp4", "clean_score": 0.0, "clean_xclip": 0.07524392753839493, "clean_vbench": {}, "adv_vid_id": "vids/eee2f5a5.mp4", "adv_score": 0.0, "adv_xclip": 0.16620692610740662, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/a5cf870c.mp4", "clean_score": 1.0, "clean_xclip": 0.1850123405456543, "clean_vbench": {}, "adv_vid_id": "vids/a04d1958.mp4", "adv_score": 0.0, "adv_xclip": 0.17094679176807404, "adv_vbench": {}}}}
{"id": "4f34e5086ec54c85a340e1bf33666f43", "source": "vatex", "video_id": "VOUl3u_7Caw_000004_000014", "video_description": "In a snowy yard, a group of children and adults are playing and building a snowman. They pose and take pictures with the snowman.", "task": "Counting", "clean_prompt": "Three children playing in a snowy yard, building a snowman and posing for pictures.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child playing in a snowy yard, building a snowman and posing for pictures.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children playing in the snowy yard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children playing in a snowy yard, building a snowman and posing for pictures. 08EZF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b99a8e0ac1eb42349d079418ea9accf3.mp4", "clean_score": 1.0, "clean_xclip": 0.22625254094600677, "clean_vbench": {"subject_consistency": 0.9485019476463398, "background_consistency": 0.9708811442057291, "motion_smoothness": 0.9667289126170016, "aesthetic_quality": 0.7298901677131653, "imaging_quality": 0.7431913913026148, "dynamic_degree": 1.0}, "adv_vid_id": "vids/456e43ea9be7418cbff3cad0177aa6cc.mp4", "adv_score": 0.0, "adv_xclip": 0.22392109036445618, "adv_vbench": {"subject_consistency": 0.9358663590004047, "background_consistency": 0.9471181233723959, "motion_smoothness": 0.9677791216248588, "aesthetic_quality": 0.6782745718955994, "imaging_quality": 0.7136510062704281, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a6a8c2f8.mp4", "clean_score": 1.0, "clean_xclip": 0.20604410767555237, "clean_vbench": {}, "adv_vid_id": "vids/a37d3e8c.mp4", "adv_score": 0.0, "adv_xclip": 0.21868260204792023, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/51ac0435.mp4", "clean_score": 0.0, "clean_xclip": 0.21836432814598083, "clean_vbench": {}, "adv_vid_id": "vids/01fc2af4.mp4", "adv_score": 0.0, "adv_xclip": 0.2188841998577118, "adv_vbench": {}}}}
{"id": "dfb4c8883d7940fb97c90642dc17779e", "source": "vatex", "video_id": "4nDSYwcXvIo_000554_000564", "video_description": "Two young men are playing frisbee golf in a wooded area on a sunny day.", "task": "Counting", "clean_prompt": "Two young men are playing frisbee golf in a wooded area on a sunny day.", "clean_property": {"obj": "frisbee", "count": "two"}, "target_prompt": "One young man is playing frisbee golf in a wooded area on a sunny day.", "target_property": {"obj": "frisbee", "count": "one"}, "evaluation_question": "Are there exactly **two** young men playing frisbee golf?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two young men are playing frisbee golf in a wooded area on a sunny day. )?G%D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b02c7200dbf34f78b77c2287038787a9.mp4", "clean_score": 1.0, "clean_xclip": 0.19184055924415588, "clean_vbench": {"subject_consistency": 0.846503454570969, "background_consistency": 0.8940887451171875, "motion_smoothness": 0.9563075096261499, "aesthetic_quality": 0.4428476393222809, "imaging_quality": 0.5876159333209602, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e19d73fe1cbd445e86cd8136ac7d61c2.mp4", "adv_score": 0.0, "adv_xclip": 0.18586325645446777, "adv_vbench": {"subject_consistency": 0.864659808576107, "background_consistency": 0.9270477294921875, "motion_smoothness": 0.9663583785012204, "aesthetic_quality": 0.488251656293869, "imaging_quality": 0.6931731765124263, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1cca27dc.mp4", "clean_score": 1.0, "clean_xclip": 0.24419990181922913, "clean_vbench": {}, "adv_vid_id": "vids/2516efdf.mp4", "adv_score": 1.0, "adv_xclip": 0.2253628969192505, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/be3c73e7.mp4", "clean_score": 1.0, "clean_xclip": 0.19545629620552063, "clean_vbench": {}, "adv_vid_id": "vids/c438c35b.mp4", "adv_score": 1.0, "adv_xclip": 0.22060003876686096, "adv_vbench": {}}}}
{"id": "e4202df05a0a4badaf267fd51d944661", "source": "vatex", "video_id": "cAxBY04KV2c_000002_000012", "video_description": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards.", "task": "ObjectRecognition", "clean_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a drumstick.", "clean_property": {"obj": "drumstick"}, "target_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a guitar.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the seated man holding a **drumstick**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a drumstick. BMV,U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e06e78a11e864a2a8f87395d74ad4ca2.mp4", "clean_score": 1.0, "clean_xclip": 0.24052909016609192, "clean_vbench": {"subject_consistency": 0.8910668467481931, "background_consistency": 0.8807271321614584, "motion_smoothness": 0.9502463421260994, "aesthetic_quality": 0.4883318543434143, "imaging_quality": 0.5696648617180027, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0a1a3518dfc74d5ea271a990ffce3fd4.mp4", "adv_score": 0.0, "adv_xclip": 0.2059914767742157, "adv_vbench": {"subject_consistency": 0.8678528635452191, "background_consistency": 0.8751627604166666, "motion_smoothness": 0.9447949355861172, "aesthetic_quality": 0.41405439376831055, "imaging_quality": 0.5631353751980529, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9b8d7ce9.mp4", "clean_score": 1.0, "clean_xclip": 0.14570903778076172, "clean_vbench": {}, "adv_vid_id": "vids/bb11c9af.mp4", "adv_score": 1.0, "adv_xclip": 0.17121784389019012, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/291a1da1.mp4", "clean_score": 0.0, "clean_xclip": 0.23198798298835754, "clean_vbench": {}, "adv_vid_id": "vids/049881bb.mp4", "adv_score": 0.0, "adv_xclip": 0.20198878645896912, "adv_vbench": {}}}}
{"id": "249c164df4c0421b8438a9597df80505", "source": "vatex", "video_id": "zbIbjob4XF4_000087_000097", "video_description": "A man is water skiing on a lake, being pulled by a fast boat, zig-zagging back and forth and creating spumes of spray.", "task": "ActionRecognition", "clean_prompt": "A water skier water skiing on a lake.", "clean_property": {"obj": "water skier", "action": "water skiing", "target": null}, "target_prompt": "A water skier falling on a lake.", "target_property": {"obj": "water skier", "action": "falling", "target": null}, "evaluation_question": "Is the water skier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A water skier water skiing on a lake. UB9?.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7407fda050ea4d5fafa4fa4cbd632213.mp4", "clean_score": 1.0, "clean_xclip": 0.2581028938293457, "clean_vbench": {"subject_consistency": 0.882257675131162, "background_consistency": 0.9124399820963541, "motion_smoothness": 0.9679788604517167, "aesthetic_quality": 0.4289661943912506, "imaging_quality": 0.5336996023995535, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7e0dd35c18554c2585c0dd04833a3042.mp4", "adv_score": 0.0, "adv_xclip": 0.2572531998157501, "adv_vbench": {"subject_consistency": 0.9137539447595676, "background_consistency": 0.944793701171875, "motion_smoothness": 0.9634033506503167, "aesthetic_quality": 0.38618844747543335, "imaging_quality": 0.495548007731535, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/53df80f3.mp4", "clean_score": 1.0, "clean_xclip": 0.2618257999420166, "clean_vbench": {}, "adv_vid_id": "vids/7117533f.mp4", "adv_score": 1.0, "adv_xclip": 0.22677583992481232, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9154e801.mp4", "clean_score": 1.0, "clean_xclip": 0.23388683795928955, "clean_vbench": {}, "adv_vid_id": "vids/f3631921.mp4", "adv_score": 1.0, "adv_xclip": 0.22407564520835876, "adv_vbench": {}}}}
{"id": "07021582c83c40b097bd1a7b7ac7d525", "source": "vatex", "video_id": "TgGQ6awU5HE_000033_000043", "video_description": "A man is demonstrating how to tie and untie various knots, including a slip knot, using a rope attached to a pole.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a pole while demonstrating how to tie knots with a rope.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "pole"}, "target_prompt": "A person standing to the right of a pole while demonstrating how to tie knots with a rope.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "pole"}, "evaluation_question": "Is the person to the **left** of the pole?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the left of a pole while demonstrating how to tie knots with a rope. SL|KQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35b9fcdd8742452081e1d467bb35b84a.mp4", "clean_score": 1.0, "clean_xclip": 0.182783305644989, "clean_vbench": {"subject_consistency": 0.8853808448960384, "background_consistency": 0.9212697347005209, "motion_smoothness": 0.9469076061398067, "aesthetic_quality": 0.35566216707229614, "imaging_quality": 0.5075156675066267, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ad1fdd99991c482c9b5875319e023bdf.mp4", "adv_score": 0.0, "adv_xclip": 0.213844433426857, "adv_vbench": {"subject_consistency": 0.9272831634928783, "background_consistency": 0.9287770589192709, "motion_smoothness": 0.9481304292871985, "aesthetic_quality": 0.3782518208026886, "imaging_quality": 0.5406743528405014, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/fc6a1bc7.mp4", "clean_score": 0.0, "clean_xclip": 0.19628912210464478, "clean_vbench": {}, "adv_vid_id": "vids/6aa28bbb.mp4", "adv_score": 0.0, "adv_xclip": 0.17833761870861053, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ae4a058f.mp4", "clean_score": 1.0, "clean_xclip": 0.21239404380321503, "clean_vbench": {}, "adv_vid_id": "vids/f5ad7a91.mp4", "adv_score": 0.0, "adv_xclip": 0.1991695761680603, "adv_vbench": {}}}}
{"id": "855dbf1ba19c4fb1a4e008985a24178c", "source": "vatex", "video_id": "14J5Jix2IFc_000000_000010", "video_description": "A young African American man is sitting in a room by himself, playing a song on a trumpet while wearing a Nike shirt.", "task": "ActionRecognition", "clean_prompt": "A person playing trumpet in a room.", "clean_property": {"obj": "person", "action": "playing trumpet", "target": null}, "target_prompt": "A person playing guitar in a room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing trumpet in a room. R%D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be73cb181a854cf7b85b532e849257ab.mp4", "clean_score": 1.0, "clean_xclip": 0.2079712450504303, "clean_vbench": {"subject_consistency": 0.9484687137107054, "background_consistency": 0.9559275309244791, "motion_smoothness": 0.9691967635144336, "aesthetic_quality": 0.522311270236969, "imaging_quality": 0.5800534695995097, "dynamic_degree": 1.0}, "adv_vid_id": "vids/0c1cbda1dfdf4b0cb7a72343039e230d.mp4", "adv_score": 0.0, "adv_xclip": 0.15138459205627441, "adv_vbench": {"subject_consistency": 0.8593988095720609, "background_consistency": 0.9347788492838541, "motion_smoothness": 0.9627482979302833, "aesthetic_quality": 0.3749268054962158, "imaging_quality": 0.3624600441601812, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/92bab1b6.mp4", "clean_score": 1.0, "clean_xclip": 0.22567032277584076, "clean_vbench": {}, "adv_vid_id": "vids/6230a75d.mp4", "adv_score": 1.0, "adv_xclip": 0.23275041580200195, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b8f9c2b6.mp4", "clean_score": 1.0, "clean_xclip": 0.2403576523065567, "clean_vbench": {}, "adv_vid_id": "vids/19267566.mp4", "adv_score": 1.0, "adv_xclip": 0.24106758832931519, "adv_vbench": {}}}}
{"id": "3194caedd75144b9b07c764e0dbbc28e", "source": "vatex", "video_id": "S0nrc6Ov2uE_000000_000010", "video_description": "A woman is standing in a field holding a large black balloon with white designs, which she pops.", "task": "ObjectRecognition", "clean_prompt": "A woman standing in a field holding a large black balloon with white designs, which she pops.", "clean_property": {"obj": "person"}, "target_prompt": "A child playing in a park with a colorful kite.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman standing in a field holding a large black balloon with white designs, which she pops. poze Fotografi beeinflussen resursearrelage", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1cd20e8f2a94683ae9d51b8a7926444.mp4", "clean_score": 1.0, "clean_xclip": 0.26999714970588684, "clean_vbench": {"subject_consistency": 0.921445166071256, "background_consistency": 0.9001108805338541, "motion_smoothness": 0.9854156605543452, "aesthetic_quality": 0.47008731961250305, "imaging_quality": 0.6685589615179568, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fa99a73dc3244746a9f3802a0e394c76.mp4", "adv_score": 0.0, "adv_xclip": 0.2841663062572479, "adv_vbench": {"subject_consistency": 0.9326834703485171, "background_consistency": 0.9400634765625, "motion_smoothness": 0.9842271895866114, "aesthetic_quality": 0.3889934718608856, "imaging_quality": 0.6362912765814334, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/eeaccda9.mp4", "clean_score": 1.0, "clean_xclip": 0.2289801687002182, "clean_vbench": {}, "adv_vid_id": "vids/4be3e561.mp4", "adv_score": 1.0, "adv_xclip": 0.25136810541152954, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/cc67ca15.mp4", "clean_score": 1.0, "clean_xclip": 0.26312392950057983, "clean_vbench": {}, "adv_vid_id": "vids/2964df1d.mp4", "adv_score": 1.0, "adv_xclip": 0.2588660717010498, "adv_vbench": {}}}}
{"id": "c852a112849f4627b62a9bec587cb70f", "source": "vatex", "video_id": "W3sMAuZgfKA_000071_000081", "video_description": "A baby boy is swinging back and forth in a baby swing at a park, with an adult occasionally pushing the swing.", "task": "ObjectRecognition", "clean_prompt": "An adult pushing a baby boy in a swing at a park.", "clean_property": {"obj": "adult"}, "target_prompt": "A child playing in a swing at a park.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person pushing the swing an **adult**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "An adult pushing a baby boy in a swing at a park. motwertiganglais solaire rasch", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2df14190a35a4762835fef5b439bb229.mp4", "clean_score": 1.0, "clean_xclip": 0.27977725863456726, "clean_vbench": {"subject_consistency": 0.9188398675372204, "background_consistency": 0.9443817138671875, "motion_smoothness": 0.9479865246510126, "aesthetic_quality": 0.5111035704612732, "imaging_quality": 0.5224157878330776, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9b0ebaf6c01e424cbea4250d92dc1941.mp4", "adv_score": 0.0, "adv_xclip": 0.2523881494998932, "adv_vbench": {"subject_consistency": 0.9267848736296097, "background_consistency": 0.9434051513671875, "motion_smoothness": 0.9562749964697813, "aesthetic_quality": 0.5197359919548035, "imaging_quality": 0.5331201078453842, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5a01bf22.mp4", "clean_score": 0.0, "clean_xclip": 0.21552982926368713, "clean_vbench": {}, "adv_vid_id": "vids/696ddb77.mp4", "adv_score": 0.0, "adv_xclip": 0.21792533993721008, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/9c334e9b.mp4", "clean_score": 1.0, "clean_xclip": 0.23889769613742828, "clean_vbench": {}, "adv_vid_id": "vids/d6cd6126.mp4", "adv_score": 1.0, "adv_xclip": 0.23988553881645203, "adv_vbench": {}}}}
{"id": "b8923f32b5254917ac0b2455ef1dacc0", "source": "vatex", "video_id": "l9tvjA4L1eY_000041_000051", "video_description": "A man is demonstrating and explaining how to tie a specific knot using a piece of rope, including making three wraps and forming a loop.", "task": "Counting", "clean_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with two people watching and learning.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning. paysage BoucreziEspagne personnage", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/05279bb060c54290921de172778c6cf8.mp4", "clean_score": 1.0, "clean_xclip": 0.22033625841140747, "clean_vbench": {"subject_consistency": 0.8825399155418078, "background_consistency": 0.9150288899739584, "motion_smoothness": 0.9670519124959654, "aesthetic_quality": 0.4790589511394501, "imaging_quality": 0.5630311436555824, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5cfd14f36bce485c95dc15b3feeb8882.mp4", "adv_score": 0.0, "adv_xclip": 0.2004566341638565, "adv_vbench": {"subject_consistency": 0.8323929011821747, "background_consistency": 0.9128265380859375, "motion_smoothness": 0.9338420302791898, "aesthetic_quality": 0.4715048372745514, "imaging_quality": 0.4098843329293387, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f9d5861c.mp4", "clean_score": 0.0, "clean_xclip": 0.2174830436706543, "clean_vbench": {}, "adv_vid_id": "vids/ae5c188e.mp4", "adv_score": 1.0, "adv_xclip": 0.23800767958164215, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b3e83a98.mp4", "clean_score": 0.0, "clean_xclip": 0.26367491483688354, "clean_vbench": {}, "adv_vid_id": "vids/433934d0.mp4", "adv_score": 0.0, "adv_xclip": 0.22506240010261536, "adv_vbench": {}}}}
{"id": "4f57ab141478430ebdc40ae35349993a", "source": "vatex", "video_id": "dbJujs8UPFI_000000_000010", "video_description": "A young man in a turquoise shirt is practicing knife throwing in a field or park-like area. He runs, jumps, and throws a knife at a wooden target, celebrating when he hits the target.", "task": "Counting", "clean_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice.", "clean_property": {"obj": "target", "count": "two"}, "target_prompt": "A young man in a turquoise shirt is practicing knife throwing at a single wooden target in a park.", "target_property": {"obj": "target", "count": "one"}, "evaluation_question": "Are there exactly **two** targets in the park?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice. Schloss sezon tromb doucefarbig", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5417fcf818fa4c88996d5425031253f3.mp4", "clean_score": 1.0, "clean_xclip": 0.1761873960494995, "clean_vbench": {"subject_consistency": 0.9077905019124349, "background_consistency": 0.8987172444661459, "motion_smoothness": 0.9423549043878097, "aesthetic_quality": 0.44580331444740295, "imaging_quality": 0.5894841634010782, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f2f7aa1e859241f58dc3ea3dade25129.mp4", "adv_score": 0.0, "adv_xclip": 0.1951805055141449, "adv_vbench": {"subject_consistency": 0.9137574403236309, "background_consistency": 0.940948486328125, "motion_smoothness": 0.9634916603311849, "aesthetic_quality": 0.42788881063461304, "imaging_quality": 0.6523571652782206, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/73113279.mp4", "clean_score": 0.0, "clean_xclip": 0.1702168881893158, "clean_vbench": {}, "adv_vid_id": "vids/43ee61c1.mp4", "adv_score": 0.0, "adv_xclip": 0.15362095832824707, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fd2bb002.mp4", "clean_score": 0.0, "clean_xclip": 0.1565445363521576, "clean_vbench": {}, "adv_vid_id": "vids/4fb0ca56.mp4", "adv_score": 0.0, "adv_xclip": 0.15741568803787231, "adv_vbench": {}}}}
{"id": "51e01d8b2fa7401d8d53183771118bea", "source": "vatex", "video_id": "6IV0gaQy1UE_000000_000010", "video_description": "An older man is talking to a small boy on a sidewalk when a woman runs up and throws water balloons at the man.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the right of a woman on a sidewalk.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A girl standing to the left of a man on a sidewalk.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the boy to the **right** of a woman?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy standing to the right of a woman on a sidewalk. rencontre einmalig rechts suivant Fotografi", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df5a442b136c44829d38c32a518d5b58.mp4", "clean_score": 1.0, "clean_xclip": 0.21650032699108124, "clean_vbench": {"subject_consistency": 0.9357022127757469, "background_consistency": 0.9518229166666666, "motion_smoothness": 0.9732576482817921, "aesthetic_quality": 0.5249910354614258, "imaging_quality": 0.6389263573471381, "dynamic_degree": 1.0}, "adv_vid_id": "vids/d0d14b69a25b4a7dbf9a8cb638dd6d83.mp4", "adv_score": 0.0, "adv_xclip": 0.13201218843460083, "adv_vbench": {"subject_consistency": 0.9867609043916067, "background_consistency": 0.9695332845052084, "motion_smoothness": 0.991639567510389, "aesthetic_quality": 0.49598631262779236, "imaging_quality": 0.7157874080113003, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ffa95de3.mp4", "clean_score": 0.0, "clean_xclip": 0.1908838450908661, "clean_vbench": {}, "adv_vid_id": "vids/adfdbbac.mp4", "adv_score": 0.0, "adv_xclip": 0.15509314835071564, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5d299af1.mp4", "clean_score": 0.0, "clean_xclip": 0.19146613776683807, "clean_vbench": {}, "adv_vid_id": "vids/f0207cd4.mp4", "adv_score": 0.0, "adv_xclip": 0.1773444414138794, "adv_vbench": {}}}}
{"id": "ee6b947085774d619de2be909f660a2d", "source": "vatex", "video_id": "7Jz__8pemqw_000001_000011", "video_description": "A person is playing a video game set in medieval times, using a yellow controller in front of a television screen.", "task": "AttributeRecognition", "clean_prompt": "A person playing a video game set in a medieval setting using a yellow controller in front of a television screen.", "clean_property": {"obj": "video game", "attribute": "medieval setting"}, "target_prompt": "A person playing a video game set in a futuristic setting using a yellow controller in front of a television screen.", "target_property": {"obj": "video game", "attribute": "futuristic setting"}, "evaluation_question": "Is the video game set in a **medieval** setting?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person playing a video game set in a medieval setting using a yellow controller in front of a television screen. RP8VR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb681a426a644e12ad904f2840cc81ca.mp4", "clean_score": 1.0, "clean_xclip": 0.23166874051094055, "clean_vbench": {"subject_consistency": 0.9048769734799862, "background_consistency": 0.94940185546875, "motion_smoothness": 0.9728830574089203, "aesthetic_quality": 0.38492196798324585, "imaging_quality": 0.504068984206842, "dynamic_degree": 1.0}, "adv_vid_id": "vids/48f7ca79407c49108dbed8834104246a.mp4", "adv_score": 0.0, "adv_xclip": 0.20774216949939728, "adv_vbench": {"subject_consistency": 0.9027664698660374, "background_consistency": 0.93780517578125, "motion_smoothness": 0.9499335436335028, "aesthetic_quality": 0.3986848294734955, "imaging_quality": 0.48669778551374165, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/383d8257.mp4", "clean_score": 1.0, "clean_xclip": 0.24448606371879578, "clean_vbench": {}, "adv_vid_id": "vids/13d1447b.mp4", "adv_score": 0.0, "adv_xclip": 0.19575023651123047, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f7444a1c.mp4", "clean_score": 1.0, "clean_xclip": 0.23467202484607697, "clean_vbench": {}, "adv_vid_id": "vids/4dd7f9f8.mp4", "adv_score": 1.0, "adv_xclip": 0.22294509410858154, "adv_vbench": {}}}}
{"id": "a10f252b425d417381d9bf4f4b603128", "source": "vatex", "video_id": "sfl2CDKTp-Q_000004_000014", "video_description": "A man is in a gym balancing a sledgehammer with one arm, demonstrating an arm exercise.", "task": "SpatialUnderstanding", "clean_prompt": "A sledgehammer closer to the camera than a person in a gym.", "clean_property": {"obj_1": "sledgehammer", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A sledgehammer further from the camera than a person in a gym.", "target_property": {"obj_1": "sledgehammer", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the sledgehammer **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sledgehammer closer to the camera than a person in a gym. ?'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6fa2f44c2c334363bd88bba5605a1896.mp4", "clean_score": 1.0, "clean_xclip": 0.1550116389989853, "clean_vbench": {"subject_consistency": 0.9001232233519355, "background_consistency": 0.9543863932291666, "motion_smoothness": 0.9898849635694041, "aesthetic_quality": 0.31244972348213196, "imaging_quality": 0.19880361790559728, "dynamic_degree": 0.0}, "adv_vid_id": "vids/357438e9120441519fe6f84989344cab.mp4", "adv_score": 0.0, "adv_xclip": 0.08136239647865295, "adv_vbench": {"subject_consistency": 0.9327507627507051, "background_consistency": 0.9609731038411459, "motion_smoothness": 0.9933560586432361, "aesthetic_quality": 0.43955162167549133, "imaging_quality": 0.3145493670872279, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/eb93d5cc.mp4", "clean_score": 0.0, "clean_xclip": 0.1697726845741272, "clean_vbench": {}, "adv_vid_id": "vids/2e916570.mp4", "adv_score": 1.0, "adv_xclip": 0.12882065773010254, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/26b486f5.mp4", "clean_score": 1.0, "clean_xclip": 0.16837236285209656, "clean_vbench": {}, "adv_vid_id": "vids/0a5c5605.mp4", "adv_score": 1.0, "adv_xclip": 0.15126663446426392, "adv_vbench": {}}}}
{"id": "2bad1fac56854bd29467ffab701c231d", "source": "vatex", "video_id": "89kpJOg07WI_000028_000038", "video_description": "Two boys are sitting at a small table performing a card trick with a deck of black playing cards.", "task": "AttributeRecognition", "clean_prompt": "Two boys sitting at a small table performing a card trick with a deck of black playing cards.", "clean_property": {"obj": "card", "attribute": "black"}, "target_prompt": "Two boys sitting at a small table performing a card trick with a deck of red playing cards.", "target_property": {"obj": "card", "attribute": "red"}, "evaluation_question": "Are the boys using a deck of **black** playing cards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys sitting at a small table performing a card trick with a deck of black playing cards. FE7;E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5d592e41f8af4e9d88f1b282f7a84806.mp4", "clean_score": 1.0, "clean_xclip": 0.24055495858192444, "clean_vbench": {"subject_consistency": 0.9427314655234417, "background_consistency": 0.9560343424479166, "motion_smoothness": 0.9722754513006334, "aesthetic_quality": 0.4902132749557495, "imaging_quality": 0.7535795951376155, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8d3ef6f6adcc49338034fdce6a5a2310.mp4", "adv_score": 0.0, "adv_xclip": 0.22473478317260742, "adv_vbench": {"subject_consistency": 0.9226498914261659, "background_consistency": 0.94451904296875, "motion_smoothness": 0.9723361193693012, "aesthetic_quality": 0.44294536113739014, "imaging_quality": 0.7463760446042431, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8451a3ad.mp4", "clean_score": 0.0, "clean_xclip": 0.1657041311264038, "clean_vbench": {}, "adv_vid_id": "vids/91372f56.mp4", "adv_score": 0.0, "adv_xclip": 0.22069600224494934, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3873abfe.mp4", "clean_score": 1.0, "clean_xclip": 0.28225022554397583, "clean_vbench": {}, "adv_vid_id": "vids/d32a5127.mp4", "adv_score": 1.0, "adv_xclip": 0.2695535123348236, "adv_vbench": {}}}}
{"id": "fffd8fd6149e463fbf9b4e98ac330759", "source": "vatex", "video_id": "6BdzOSFXqiA_000009_000019", "video_description": "A large group of people are skating and dancing on an ice rink, enjoying music and laughing.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of an ice rink.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "ice rink"}, "target_prompt": "A person standing to the right of an ice rink.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "ice rink"}, "evaluation_question": "Is the person to the **left** of the ice rink?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing to the left of an ice rink. jocuririggterapia exig Aluminium", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e8b6dad1aca44e5a9ef19f013d42eb9.mp4", "clean_score": 1.0, "clean_xclip": 0.1983485221862793, "clean_vbench": {"subject_consistency": 0.9431546616057555, "background_consistency": 0.9452362060546875, "motion_smoothness": 0.9892404482369079, "aesthetic_quality": 0.3789501488208771, "imaging_quality": 0.6493203992259745, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e9b880513a8d4e01a0e4d22dec79d179.mp4", "adv_score": 0.0, "adv_xclip": 0.18324482440948486, "adv_vbench": {"subject_consistency": 0.9918378250052532, "background_consistency": 0.97119140625, "motion_smoothness": 0.9951842083862866, "aesthetic_quality": 0.34425103664398193, "imaging_quality": 0.6639599710581254, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/14ac5486.mp4", "clean_score": 1.0, "clean_xclip": 0.21238262951374054, "clean_vbench": {}, "adv_vid_id": "vids/6f642104.mp4", "adv_score": 0.0, "adv_xclip": 0.1940234899520874, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/96915d56.mp4", "clean_score": 1.0, "clean_xclip": 0.22199127078056335, "clean_vbench": {}, "adv_vid_id": "vids/c7d1b398.mp4", "adv_score": 0.0, "adv_xclip": 0.21727900207042694, "adv_vbench": {}}}}
{"id": "e70233ba63b14eb7840c128090e97406", "source": "vatex", "video_id": "N81OHjhcrbY_000198_000208", "video_description": "A woman is demonstrating and explaining how to color and apply makeup to eyebrows using q-tips.", "task": "ActionRecognition", "clean_prompt": "A person dyeing eyebrows using q-tips.", "clean_property": {"obj": "person", "action": "dyeing eyebrows", "target": null}, "target_prompt": "A person shaving eyebrows using a razor.", "target_property": {"obj": "person", "action": "shaving eyebrows", "target": null}, "evaluation_question": "Is the person **dyeing** eyebrows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person dyeing eyebrows using q-tips. FE(E(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/884ceb4f0eaa4b519f15272eb99477c2.mp4", "clean_score": 1.0, "clean_xclip": 0.2237800657749176, "clean_vbench": {"subject_consistency": 0.9059832872201999, "background_consistency": 0.9362030029296875, "motion_smoothness": 0.9801251366383745, "aesthetic_quality": 0.4771372675895691, "imaging_quality": 0.6513788145415638, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e9254f8e718c47ac93c2cc7223cf063d.mp4", "adv_score": 0.0, "adv_xclip": 0.2147035300731659, "adv_vbench": {"subject_consistency": 0.9663366582244635, "background_consistency": 0.9620819091796875, "motion_smoothness": 0.9608367760845337, "aesthetic_quality": 0.4284264147281647, "imaging_quality": 0.5862512300452408, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c754121b.mp4", "clean_score": 1.0, "clean_xclip": 0.1974751055240631, "clean_vbench": {}, "adv_vid_id": "vids/0bcefc4c.mp4", "adv_score": 1.0, "adv_xclip": 0.1788599193096161, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/50f07f7b.mp4", "clean_score": 0.0, "clean_xclip": 0.17689579725265503, "clean_vbench": {}, "adv_vid_id": "vids/a6a06f7a.mp4", "adv_score": 0.0, "adv_xclip": 0.1759973168373108, "adv_vbench": {}}}}
{"id": "a3200bf5efb0442ebccca467b6857206", "source": "vatex", "video_id": "jGVsvr1kbBI_000002_000012", "video_description": "A group of bartenders, both men and women, are behind a bar preparing and pouring drinks for customers. They are wearing red shirts and are working in a busy, crowded bar environment.", "task": "AttributeRecognition", "clean_prompt": "A group of bartenders preparing and pouring alcoholic drinks in a busy bar.", "clean_property": {"obj": "drink", "attribute": "alcoholic"}, "target_prompt": "A group of bartenders preparing and pouring non-alcoholic drinks in a busy bar.", "target_property": {"obj": "drink", "attribute": "non-alcoholic"}, "evaluation_question": "Are the drinks being prepared by the bartenders **alcoholic**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A group of bartenders preparing and pouring alcoholic drinks in a busy bar. S;PFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e1c16ca200046178744dd5ff5794a60.mp4", "clean_score": 1.0, "clean_xclip": 0.21975550055503845, "clean_vbench": {"subject_consistency": 0.9319768492132425, "background_consistency": 0.9457448323567709, "motion_smoothness": 0.953972188180828, "aesthetic_quality": 0.48146724700927734, "imaging_quality": 0.4432358928602569, "dynamic_degree": 1.0}, "adv_vid_id": "vids/412b961443f64941a16182ae91402a9a.mp4", "adv_score": 0.0, "adv_xclip": 0.23546163737773895, "adv_vbench": {"subject_consistency": 0.9476790682723125, "background_consistency": 0.95806884765625, "motion_smoothness": 0.9544140283010066, "aesthetic_quality": 0.5292195081710815, "imaging_quality": 0.40283616747174944, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/51be0390.mp4", "clean_score": 1.0, "clean_xclip": 0.21716782450675964, "clean_vbench": {}, "adv_vid_id": "vids/241c75fc.mp4", "adv_score": 1.0, "adv_xclip": 0.2549999952316284, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/94ce1d09.mp4", "clean_score": 1.0, "clean_xclip": 0.26281657814979553, "clean_vbench": {}, "adv_vid_id": "vids/97b9dd6a.mp4", "adv_score": 1.0, "adv_xclip": 0.2591213583946228, "adv_vbench": {}}}}
{"id": "3f0984a0cf8f4f6e83b5dc3cc026f1ef", "source": "vatex", "video_id": "EraBmgB9U9Q_000010_000020", "video_description": "A little girl in a blue floral dress is outside watering the grass and plants with a blue and yellow plastic watering can.", "task": "ActionRecognition", "clean_prompt": "A girl watering plants outside with a blue and yellow watering can.", "clean_property": {"obj": "girl", "action": "watering plants", "target": null}, "target_prompt": "A girl playing with water outside.", "target_property": {"obj": "girl", "action": "playing with water", "target": null}, "evaluation_question": "Is the girl **watering plants**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A girl watering plants outside with a blue and yellow watering can. Ichoarele domni underwater Metropolitan", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4ac68e081ddd4ca19775c72d8bde1a37.mp4", "clean_score": 1.0, "clean_xclip": 0.2498973309993744, "clean_vbench": {"subject_consistency": 0.9278090142955383, "background_consistency": 0.9536590576171875, "motion_smoothness": 0.9827906052370794, "aesthetic_quality": 0.6355746984481812, "imaging_quality": 0.7626412590182557, "dynamic_degree": 0.0}, "adv_vid_id": "vids/7d894b3aa6fe4969b0075618f241748a.mp4", "adv_score": 0.0, "adv_xclip": 0.10991886258125305, "adv_vbench": {"subject_consistency": 0.9680376617858807, "background_consistency": 0.9596964518229166, "motion_smoothness": 0.9623756471016904, "aesthetic_quality": 0.37543874979019165, "imaging_quality": 0.7415106855119977, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8259eb04.mp4", "clean_score": 1.0, "clean_xclip": 0.21451467275619507, "clean_vbench": {}, "adv_vid_id": "vids/56fee86f.mp4", "adv_score": 1.0, "adv_xclip": 0.22434993088245392, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d4df3939.mp4", "clean_score": 1.0, "clean_xclip": 0.23976846039295197, "clean_vbench": {}, "adv_vid_id": "vids/249d2ee0.mp4", "adv_score": 0.0, "adv_xclip": 0.22565880417823792, "adv_vbench": {}}}}
{"id": "8b419a2d883f4557a32e97abb1a9f0a0", "source": "vatex", "video_id": "CeQ5f7l-mQQ_000019_000029", "video_description": "A young man is practicing archery in a large open field, shooting arrows with a bow at a high angle into the sky.", "task": "ActionRecognition", "clean_prompt": "A person practicing archery in a large open field.", "clean_property": {"obj": "person", "action": "archery", "target": null}, "target_prompt": "A person fencing in a large open field.", "target_property": {"obj": "person", "action": "fencing", "target": null}, "evaluation_question": "Is the person **practicing archery**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person practicing archery in a large open field. Nicht cible cattle clove pneumonia", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1c33dc83df7b4f549047c25ff65a22de.mp4", "clean_score": 1.0, "clean_xclip": 0.24391354620456696, "clean_vbench": {"subject_consistency": 0.8234930007408062, "background_consistency": 0.9166259765625, "motion_smoothness": 0.9868060036096485, "aesthetic_quality": 0.4734456539154053, "imaging_quality": 0.7294034638696787, "dynamic_degree": 0.0}, "adv_vid_id": "vids/61c2351d07b245aaa579caca2bad808c.mp4", "adv_score": 0.0, "adv_xclip": 0.20902416110038757, "adv_vbench": {"subject_consistency": 0.9645922935257355, "background_consistency": 0.975341796875, "motion_smoothness": 0.9908680620171165, "aesthetic_quality": 0.465412974357605, "imaging_quality": 0.7655580621836137, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9b74f06a.mp4", "clean_score": 1.0, "clean_xclip": 0.21103151142597198, "clean_vbench": {}, "adv_vid_id": "vids/b7877004.mp4", "adv_score": 1.0, "adv_xclip": 0.20853868126869202, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0425c2a5.mp4", "clean_score": 1.0, "clean_xclip": 0.22306200861930847, "clean_vbench": {}, "adv_vid_id": "vids/b11ede9a.mp4", "adv_score": 1.0, "adv_xclip": 0.22602280974388123, "adv_vbench": {}}}}
{"id": "f8954760b6bc4446913f57554ae6288b", "source": "vatex", "video_id": "1u9OGTJcMEw_000011_000021", "video_description": "A group of people are watching a polo match on a green field with horses and players. An announcer is speaking through a loudspeaker, and some spectators are taking pictures and filming the event.", "task": "ActionRecognition", "clean_prompt": "A polo player playing polo on a green field.", "clean_property": {"obj": "polo player", "action": "playing polo", "target": null}, "target_prompt": "A polo player watching polo on a green field.", "target_property": {"obj": "polo player", "action": "watching polo", "target": null}, "evaluation_question": "Is the polo player **playing** polo?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A polo player playing polo on a green field. Wunsch Olympics Palaidos partenaires", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7144cde3bca049ac90ed66144ddc7c3e.mp4", "clean_score": 1.0, "clean_xclip": 0.18352100253105164, "clean_vbench": {"subject_consistency": 0.9420317684610685, "background_consistency": 0.9300893147786459, "motion_smoothness": 0.9721959573953038, "aesthetic_quality": 0.4928309917449951, "imaging_quality": 0.6381733664687799, "dynamic_degree": 1.0}, "adv_vid_id": "vids/e8d8216b914549a8b2ee741078142e44.mp4", "adv_score": 0.0, "adv_xclip": 0.17828594148159027, "adv_vbench": {"subject_consistency": 0.947246586283048, "background_consistency": 0.9201151529947916, "motion_smoothness": 0.9745400955617587, "aesthetic_quality": 0.49546462297439575, "imaging_quality": 0.6733781728939134, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7e181828.mp4", "clean_score": 1.0, "clean_xclip": 0.1786453127861023, "clean_vbench": {}, "adv_vid_id": "vids/ad99d2f3.mp4", "adv_score": 1.0, "adv_xclip": 0.15439647436141968, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ed407514.mp4", "clean_score": 1.0, "clean_xclip": 0.16059783101081848, "clean_vbench": {}, "adv_vid_id": "vids/2ada7fe4.mp4", "adv_score": 1.0, "adv_xclip": 0.18788331747055054, "adv_vbench": {}}}}
{"id": "44d6813bb60e483884645a0bfbac1f3f", "source": "vatex", "video_id": "UFirX6T9h1Q_000013_000023", "video_description": "A man in a kitchen demonstrates how to sharpen a knife using a sharpening tool and a textured metal rod.", "task": "ActionRecognition", "clean_prompt": "A person sharpening knives in a kitchen.", "clean_property": {"obj": "person", "action": "sharpening knives", "target": null}, "target_prompt": "A person throwing knives in a kitchen.", "target_property": {"obj": "person", "action": "throwing knives", "target": null}, "evaluation_question": "Is the person **sharpening** knives?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sharpening knives in a kitchen. )!G*E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49838ea1a6e046899cdc34beec8f845d.mp4", "clean_score": 1.0, "clean_xclip": 0.21542729437351227, "clean_vbench": {"subject_consistency": 0.9303513647367557, "background_consistency": 0.9548390706380209, "motion_smoothness": 0.9315593264279736, "aesthetic_quality": 0.43653568625450134, "imaging_quality": 0.3744771513646963, "dynamic_degree": 1.0}, "adv_vid_id": "vids/49252fef75d6456c87689c84d751acb7.mp4", "adv_score": 0.0, "adv_xclip": 0.21904614567756653, "adv_vbench": {"subject_consistency": 0.919637406244874, "background_consistency": 0.9595947265625, "motion_smoothness": 0.9256043669750564, "aesthetic_quality": 0.41054829955101013, "imaging_quality": 0.5036313987264828, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c4d238ce.mp4", "clean_score": 1.0, "clean_xclip": 0.2108156383037567, "clean_vbench": {}, "adv_vid_id": "vids/bd03df4a.mp4", "adv_score": 1.0, "adv_xclip": 0.20088867843151093, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/1d71cf0f.mp4", "clean_score": 1.0, "clean_xclip": 0.23636965453624725, "clean_vbench": {}, "adv_vid_id": "vids/18e156d3.mp4", "adv_score": 1.0, "adv_xclip": 0.230341836810112, "adv_vbench": {}}}}
{"id": "feabe6220a8147029dc2b68cb504b970", "source": "vatex", "video_id": "oRrwzU5iADM_000025_000035", "video_description": "A young man opens a refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "task": "ObjectRecognition", "clean_prompt": "A young man opens a refrigerator door in a living room.", "clean_property": {"obj": "person"}, "target_prompt": "A cat opens a refrigerator door in a living room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young man opens a refrigerator door in a living room. )!0QU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2830ffb6c8f24c2fbd4ef7b228a752fe.mp4", "clean_score": 1.0, "clean_xclip": 0.2091657519340515, "clean_vbench": {"subject_consistency": 0.968822822595636, "background_consistency": 0.9576822916666666, "motion_smoothness": 0.9936370601095377, "aesthetic_quality": 0.36070236563682556, "imaging_quality": 0.6338081001748844, "dynamic_degree": 0.0}, "adv_vid_id": "vids/725e605e39f74afca5cadf0c368165d7.mp4", "adv_score": 0.0, "adv_xclip": 0.18282967805862427, "adv_vbench": {"subject_consistency": 0.9864373399565617, "background_consistency": 0.9824473063151041, "motion_smoothness": 0.9960648888863674, "aesthetic_quality": 0.3833823502063751, "imaging_quality": 0.5536826565800881, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f117d588.mp4", "clean_score": 1.0, "clean_xclip": 0.22153834998607635, "clean_vbench": {}, "adv_vid_id": "vids/b619b1ca.mp4", "adv_score": 1.0, "adv_xclip": 0.20302525162696838, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ff576aa8.mp4", "clean_score": 1.0, "clean_xclip": 0.2266688346862793, "clean_vbench": {}, "adv_vid_id": "vids/ae7ce1d2.mp4", "adv_score": 1.0, "adv_xclip": 0.23178578913211823, "adv_vbench": {}}}}
{"id": "5872779c3b0f4968a5bdf91850a972da", "source": "vatex", "video_id": "3YR87sqmPfM_000031_000041", "video_description": "A man is standing by a body of water, using a large fishing pole to cast a line into the water. He demonstrates the use of the fishing reel while an advertisement or commentary is heard in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a body of water, using a fishing pole to cast a line.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "water"}, "target_prompt": "A person standing to the left of a body of water, using a fishing pole to cast a line.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "water"}, "evaluation_question": "Is the person to the **right** of the body of water?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the right of a body of water, using a fishing pole to cast a line. XKVZU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c89379878ab49ceb0693ed063be24e2.mp4", "clean_score": 1.0, "clean_xclip": 0.20995692908763885, "clean_vbench": {"subject_consistency": 0.8596556397775809, "background_consistency": 0.9287516276041666, "motion_smoothness": 0.9895150399923344, "aesthetic_quality": 0.4836122393608093, "imaging_quality": 0.677955850095165, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f337f97b371d406fa0e7f8c484d3e123.mp4", "adv_score": 0.0, "adv_xclip": 0.2204328328371048, "adv_vbench": {"subject_consistency": 0.8645089250057936, "background_consistency": 0.9391835530598959, "motion_smoothness": 0.9771995006946966, "aesthetic_quality": 0.40769341588020325, "imaging_quality": 0.6967359091311084, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/90d62e65.mp4", "clean_score": 0.0, "clean_xclip": 0.23478339612483978, "clean_vbench": {}, "adv_vid_id": "vids/68cdf86e.mp4", "adv_score": 0.0, "adv_xclip": 0.2336040586233139, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/db8bac9f.mp4", "clean_score": 0.0, "clean_xclip": 0.2357281744480133, "clean_vbench": {}, "adv_vid_id": "vids/e49884de.mp4", "adv_score": 1.0, "adv_xclip": 0.2125757485628128, "adv_vbench": {}}}}
{"id": "9c71861fbba7406b97e04d0faf12af3f", "source": "vatex", "video_id": "MBd1ohDjbag_000000_000010", "video_description": "A man is in a wooded area throwing an axe at a tree, successfully sticking it into the trunk.", "task": "SpatialUnderstanding", "clean_prompt": "A tree to the left of a person in a wooded area.", "clean_property": {"obj_1": "tree", "relation": "left of", "obj_2": "person"}, "target_prompt": "A tree to the right of a person in a wooded area.", "target_property": {"obj_1": "tree", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the tree to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A tree to the left of a person in a wooded area. ;IBMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6dd134317427458480a19e883eee310f.mp4", "clean_score": 1.0, "clean_xclip": 0.14463090896606445, "clean_vbench": {"subject_consistency": 0.9134052085379759, "background_consistency": 0.9439595540364584, "motion_smoothness": 0.9885775187164629, "aesthetic_quality": 0.5201324820518494, "imaging_quality": 0.5637563316189513, "dynamic_degree": 0.0}, "adv_vid_id": "vids/e356125d40734fd6b04834a0394910c7.mp4", "adv_score": 0.0, "adv_xclip": 0.16604630649089813, "adv_vbench": {"subject_consistency": 0.9892520550638437, "background_consistency": 0.974945068359375, "motion_smoothness": 0.9749455214763375, "aesthetic_quality": 0.5935596227645874, "imaging_quality": 0.737253604811065, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a2fe8c85.mp4", "clean_score": 0.0, "clean_xclip": 0.17670463025569916, "clean_vbench": {}, "adv_vid_id": "vids/686b4b95.mp4", "adv_score": 1.0, "adv_xclip": 0.1836320161819458, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/4c9dab70.mp4", "clean_score": 1.0, "clean_xclip": 0.19003459811210632, "clean_vbench": {}, "adv_vid_id": "vids/8c7b8cfc.mp4", "adv_score": 0.0, "adv_xclip": 0.17227552831172943, "adv_vbench": {}}}}
{"id": "a3efe99ab30548c3aae7c264c4169ef6", "source": "vatex", "video_id": "5itHnZhjeg0_000092_000102", "video_description": "A man is in a recording studio, wearing headphones and standing in front of a microphone, singing and talking to record music.", "task": "SpatialUnderstanding", "clean_prompt": "A man wearing headphones standing to the right of a microphone in a recording studio.", "clean_property": {"obj_1": "headphones", "relation": "right of", "obj_2": "microphone"}, "target_prompt": "A man wearing headphones standing to the left of a microphone in a recording studio.", "target_property": {"obj_1": "headphones", "relation": "left of", "obj_2": "microphone"}, "evaluation_question": "Is the man wearing headphones **to the right** of the microphone?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man wearing headphones standing to the right of a microphone in a recording studio. '!%|(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/97f58ebb4dce43afb902d8babdfb1a32.mp4", "clean_score": 1.0, "clean_xclip": 0.20857909321784973, "clean_vbench": {"subject_consistency": 0.9275345417360464, "background_consistency": 0.9412485758463541, "motion_smoothness": 0.9924431543386387, "aesthetic_quality": 0.5481657385826111, "imaging_quality": 0.44052353839485014, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6848cfd8429d4b21901fa630f81bd6d5.mp4", "adv_score": 0.0, "adv_xclip": 0.20119395852088928, "adv_vbench": {"subject_consistency": 0.9032408532996973, "background_consistency": 0.9429066975911459, "motion_smoothness": 0.9976081064852639, "aesthetic_quality": 0.43873587250709534, "imaging_quality": 0.2993753417657346, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/19495373.mp4", "clean_score": 0.0, "clean_xclip": 0.22946861386299133, "clean_vbench": {}, "adv_vid_id": "vids/d5aa55f3.mp4", "adv_score": 0.0, "adv_xclip": 0.20356595516204834, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6797a454.mp4", "clean_score": 1.0, "clean_xclip": 0.2249908149242401, "clean_vbench": {}, "adv_vid_id": "vids/bdd11afd.mp4", "adv_score": 0.0, "adv_xclip": 0.1870773434638977, "adv_vbench": {}}}}
{"id": "533919d883714fe0a4b72278d1d3b285", "source": "vatex", "video_id": "CVomytAd7-0_000020_000030", "video_description": "A person is sitting cross-legged on a tile floor, using two small knives to sharpen each other by rubbing them together.", "task": "ObjectRecognition", "clean_prompt": "A person sitting cross-legged on a tile floor, using two small knives to sharpen each other by rubbing them together.", "clean_property": {"obj": "knife"}, "target_prompt": "A person sitting cross-legged on a tile floor, using two small swords to sharpen each other by rubbing them together.", "target_property": {"obj": "sword"}, "evaluation_question": "Is the object being used in the video a **knife**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting cross-legged on a tile floor, using two small knives to sharpen each other by rubbing them together. =2?FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6df0707563f7435189e4bfa1d7b3a7fb.mp4", "clean_score": 1.0, "clean_xclip": 0.18001024425029755, "clean_vbench": {"subject_consistency": 0.9207929652184248, "background_consistency": 0.944091796875, "motion_smoothness": 0.9566058807139111, "aesthetic_quality": 0.33187490701675415, "imaging_quality": 0.5643800120451012, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7f37bc99af10490984e35a984411af0b.mp4", "adv_score": 0.0, "adv_xclip": 0.17540065944194794, "adv_vbench": {"subject_consistency": 0.8984263557940722, "background_consistency": 0.9450632731119791, "motion_smoothness": 0.9412721864787582, "aesthetic_quality": 0.35362014174461365, "imaging_quality": 0.5723214394705637, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2f03f087.mp4", "clean_score": 1.0, "clean_xclip": 0.26878857612609863, "clean_vbench": {}, "adv_vid_id": "vids/c1331095.mp4", "adv_score": 1.0, "adv_xclip": 0.2551407217979431, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e098fce3.mp4", "clean_score": 1.0, "clean_xclip": 0.17398221790790558, "clean_vbench": {}, "adv_vid_id": "vids/641c07f2.mp4", "adv_score": 1.0, "adv_xclip": 0.22392705082893372, "adv_vbench": {}}}}
{"id": "82f652a8aa964adda1ac41096e6c021a", "source": "vatex", "video_id": "s7qkYZTezYs_000002_000012", "video_description": "A person is cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "task": "SpatialUnderstanding", "clean_prompt": "A person cleaning a toilet that is farther from the camera than the person.", "clean_property": {"obj_1": "toilet", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A person cleaning a toilet that is closer to the camera than the person.", "target_property": {"obj_1": "toilet", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the toilet farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person cleaning a toilet that is farther from the camera than the person. YG%Y)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b72350c2ce52443fb7e004f40d8abe0a.mp4", "clean_score": 1.0, "clean_xclip": 0.19641444087028503, "clean_vbench": {"subject_consistency": 0.9297660707185665, "background_consistency": 0.94488525390625, "motion_smoothness": 0.98134086168225, "aesthetic_quality": 0.35145312547683716, "imaging_quality": 0.5772512365847218, "dynamic_degree": 1.0}, "adv_vid_id": "vids/54c9602df8a741db9d243db3f39a7e73.mp4", "adv_score": 0.0, "adv_xclip": 0.16345266997814178, "adv_vbench": {"subject_consistency": 0.9098518410076698, "background_consistency": 0.9179178873697916, "motion_smoothness": 0.9823468822810759, "aesthetic_quality": 0.40205585956573486, "imaging_quality": 0.6219053151656171, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ade9de24.mp4", "clean_score": 0.0, "clean_xclip": 0.23726075887680054, "clean_vbench": {}, "adv_vid_id": "vids/92d3ecc3.mp4", "adv_score": 0.0, "adv_xclip": 0.24909794330596924, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/184e96c6.mp4", "clean_score": 1.0, "clean_xclip": 0.212079718708992, "clean_vbench": {}, "adv_vid_id": "vids/6934f878.mp4", "adv_score": 0.0, "adv_xclip": 0.2325911968946457, "adv_vbench": {}}}}
{"id": "684ff64f7dea4153bfdc66126a60c51f", "source": "vatex", "video_id": "NcACCCcY-_c_000015_000025", "video_description": "A man is demonstrating and explaining how to tie and lace up shoes, focusing on a specific knot technique.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a shoe while demonstrating how to tie it.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "shoe"}, "target_prompt": "A person standing to the left of a shoe while demonstrating how to tie it.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "shoe"}, "evaluation_question": "Is the person to the **right** of the shoe?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A person standing to the right of a shoe while demonstrating how to tie it.Ohne fries Antrag poveste vecin", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/15f07b07036842189a6139e60a60cd7a.mp4", "clean_score": 1.0, "clean_xclip": 0.20771265029907227, "clean_vbench": {"subject_consistency": 0.9329589003076156, "background_consistency": 0.9600880940755209, "motion_smoothness": 0.966994759516461, "aesthetic_quality": 0.5237627625465393, "imaging_quality": 0.5229761917737066, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c94f6e35e695485c853dfa40ab7cfae4.mp4", "adv_score": 0.0, "adv_xclip": 0.20340242981910706, "adv_vbench": {"subject_consistency": 0.9536102072646221, "background_consistency": 0.9672342936197916, "motion_smoothness": 0.9579864603506012, "aesthetic_quality": 0.5855390429496765, "imaging_quality": 0.6961697379910216, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7e598959.mp4", "clean_score": 1.0, "clean_xclip": 0.2274709939956665, "clean_vbench": {}, "adv_vid_id": "vids/0d0702f8.mp4", "adv_score": 0.0, "adv_xclip": 0.18955174088478088, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3848fa26.mp4", "clean_score": 0.0, "clean_xclip": 0.1763942688703537, "clean_vbench": {}, "adv_vid_id": "vids/75d8cce6.mp4", "adv_score": 0.0, "adv_xclip": 0.19013242423534393, "adv_vbench": {}}}}
{"id": "d90df70d82ee4f99bb62ea4af88aa1b1", "source": "vatex", "video_id": "eAz-jW31Iq8_000205_000215", "video_description": "A man is demonstrating how to shuffle a deck of cards on a table, occasionally chatting with another man.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a table demonstrating how to shuffle a deck of cards.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "table"}, "target_prompt": "A person beside a table demonstrating how to shuffle a deck of cards.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "table"}, "evaluation_question": "Is the person **above** the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person above a table demonstrating how to shuffle a deck of cards. -%QP%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cd9dfc1151c4c0b987abcc6cc3b3061.mp4", "clean_score": 1.0, "clean_xclip": 0.19836539030075073, "clean_vbench": {"subject_consistency": 0.8425161074846983, "background_consistency": 0.9258015950520834, "motion_smoothness": 0.9324770001525559, "aesthetic_quality": 0.35241609811782837, "imaging_quality": 0.38997966299251635, "dynamic_degree": 1.0}, "adv_vid_id": "vids/abf933e0ea044d878e26af8b399ec652.mp4", "adv_score": 0.0, "adv_xclip": 0.19206984341144562, "adv_vbench": {"subject_consistency": 0.8187149278819561, "background_consistency": 0.8859914143880209, "motion_smoothness": 0.9376188400836157, "aesthetic_quality": 0.3641749620437622, "imaging_quality": 0.46932230968864597, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/34b58b5a.mp4", "clean_score": 0.0, "clean_xclip": 0.18548262119293213, "clean_vbench": {}, "adv_vid_id": "vids/2a20ce60.mp4", "adv_score": 1.0, "adv_xclip": 0.19836357235908508, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0ebca15a.mp4", "clean_score": 0.0, "clean_xclip": 0.19357725977897644, "clean_vbench": {}, "adv_vid_id": "vids/78472ba3.mp4", "adv_score": 0.0, "adv_xclip": 0.20218601822853088, "adv_vbench": {}}}}
{"id": "6b331b5a908549039b14e323119aed72", "source": "vatex", "video_id": "axUFmA1cpws_000000_000010", "video_description": "A young man is practicing throwing a frisbee in a wooded area, preparing and making throwing motions.", "task": "Counting", "clean_prompt": "Four people practicing throwing a frisbee in a wooded area.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person practicing throwing a frisbee in a wooded area.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people practicing throwing a frisbee in the wooded area?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Four people practicing throwing a frisbee in a wooded area. !D|*&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8cc58f510d7b428aac8c6c7a2e0c0b7c.mp4", "clean_score": 1.0, "clean_xclip": 0.09775875508785248, "clean_vbench": {"subject_consistency": 0.8973140368858973, "background_consistency": 0.8895975748697916, "motion_smoothness": 0.9739886251311224, "aesthetic_quality": 0.5119451284408569, "imaging_quality": 0.615472326473314, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3f0ee4104b6141e8ba4da64a4b8629aa.mp4", "adv_score": 0.0, "adv_xclip": 0.16400745511054993, "adv_vbench": {"subject_consistency": 0.8857706865916649, "background_consistency": 0.9010518391927084, "motion_smoothness": 0.9726513989437081, "aesthetic_quality": 0.48523423075675964, "imaging_quality": 0.709818836912817, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b60c49e8.mp4", "clean_score": 0.0, "clean_xclip": 0.24075952172279358, "clean_vbench": {}, "adv_vid_id": "vids/09f7931b.mp4", "adv_score": 1.0, "adv_xclip": 0.21753135323524475, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/39923f3d.mp4", "clean_score": 0.0, "clean_xclip": 0.22428731620311737, "clean_vbench": {}, "adv_vid_id": "vids/08d871f5.mp4", "adv_score": 0.0, "adv_xclip": 0.20445261895656586, "adv_vbench": {}}}}
{"id": "5b1461fedd0c43cea4d2f1873463e48b", "source": "vatex", "video_id": "8GcGjOTkccQ_000001_000011", "video_description": "A little boy attempts to hit a baseball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "task": "ObjectRecognition", "clean_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "clean_property": {"obj": "ball"}, "target_prompt": "A little boy attempts to fly a kite on a windy day, but the kite gets stuck in a tree.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object the boy is trying to hit a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying. SLJR|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ea53ec60fc6b46099e5c99657286d0c1.mp4", "clean_score": 1.0, "clean_xclip": 0.18945631384849548, "clean_vbench": {"subject_consistency": 0.7959985674048463, "background_consistency": 0.8905588785807291, "motion_smoothness": 0.9332398432141632, "aesthetic_quality": 0.4588090181350708, "imaging_quality": 0.3596944221185179, "dynamic_degree": 1.0}, "adv_vid_id": "vids/7dd0d30978264d779c0f1a6d04078231.mp4", "adv_score": 0.0, "adv_xclip": 0.15710529685020447, "adv_vbench": {"subject_consistency": 0.754162464911739, "background_consistency": 0.8819173177083334, "motion_smoothness": 0.9253293060472646, "aesthetic_quality": 0.4431687891483307, "imaging_quality": 0.3853942096476652, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a991c442.mp4", "clean_score": 1.0, "clean_xclip": 0.18206746876239777, "clean_vbench": {}, "adv_vid_id": "vids/3e18b0f8.mp4", "adv_score": 0.0, "adv_xclip": 0.21406862139701843, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c3eec2b4.mp4", "clean_score": 1.0, "clean_xclip": 0.1878354251384735, "clean_vbench": {}, "adv_vid_id": "vids/88df1a46.mp4", "adv_score": 1.0, "adv_xclip": 0.21886655688285828, "adv_vbench": {}}}}
{"id": "d40860684741457689d4fde7c1a7300c", "source": "vatex", "video_id": "mg4eMlZSbVI_000212_000222", "video_description": "A woman is demonstrating how to make a snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "task": "Counting", "clean_prompt": "A woman is demonstrating how to make three snowman dolls using a white sock, adding features like eyes and hats on a kitchen table.", "clean_property": {"obj": "snowman doll", "count": "three"}, "target_prompt": "A woman is demonstrating how to make one snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "target_property": {"obj": "snowman doll", "count": "one"}, "evaluation_question": "Are there exactly **three** snowman dolls being made?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman is demonstrating how to make three snowman dolls using a white sock, adding features like eyes and hats on a kitchen table. Aujourd acasa kompetentecita cazare", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/77e79f944e094211b86922caca3b9d11.mp4", "clean_score": 1.0, "clean_xclip": 0.193986713886261, "clean_vbench": {"subject_consistency": 0.9440397961686054, "background_consistency": 0.9622650146484375, "motion_smoothness": 0.9731465806680182, "aesthetic_quality": 0.5059615969657898, "imaging_quality": 0.7601740996691646, "dynamic_degree": 1.0}, "adv_vid_id": "vids/272a717aedc34dae9d1e67724b77bd6f.mp4", "adv_score": 0.0, "adv_xclip": 0.23403629660606384, "adv_vbench": {"subject_consistency": 0.9542678880194823, "background_consistency": 0.9559987386067709, "motion_smoothness": 0.9735110456444667, "aesthetic_quality": 0.4927658438682556, "imaging_quality": 0.7349526572714047, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d87963ef.mp4", "clean_score": 1.0, "clean_xclip": 0.23638813197612762, "clean_vbench": {}, "adv_vid_id": "vids/93453481.mp4", "adv_score": 0.0, "adv_xclip": 0.23575033247470856, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/08d8d570.mp4", "clean_score": 0.0, "clean_xclip": 0.22903531789779663, "clean_vbench": {}, "adv_vid_id": "vids/74bec664.mp4", "adv_score": 0.0, "adv_xclip": 0.23182770609855652, "adv_vbench": {}}}}
{"id": "1098df9081c04641927c978d0613d974", "source": "vatex", "video_id": "zH2qJbxLkzg_000022_000032", "video_description": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event. Onlookers applaud after the board is broken.", "task": "ObjectRecognition", "clean_prompt": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event.", "clean_property": {"obj": "instructor"}, "target_prompt": "A young boy demonstrates his martial arts skills while a spectator watches at a martial arts event.", "target_property": {"obj": "spectator"}, "evaluation_question": "Is the person holding the board in the video an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event. 2BC2$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a18232bd87741e381274dbf5122d2dd.mp4", "clean_score": 1.0, "clean_xclip": 0.16061994433403015, "clean_vbench": {"subject_consistency": 0.9565590359270573, "background_consistency": 0.9399973551432291, "motion_smoothness": 0.9573439529875736, "aesthetic_quality": 0.5182132720947266, "imaging_quality": 0.4405631882803781, "dynamic_degree": 1.0}, "adv_vid_id": "vids/afab45d543eb4193a16d25e7d4ffe816.mp4", "adv_score": 0.0, "adv_xclip": 0.15164408087730408, "adv_vbench": {"subject_consistency": 0.9486181152363619, "background_consistency": 0.9400533040364584, "motion_smoothness": 0.9579321028630073, "aesthetic_quality": 0.459360271692276, "imaging_quality": 0.543714359828404, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f6b6b254.mp4", "clean_score": 0.0, "clean_xclip": 0.14350512623786926, "clean_vbench": {}, "adv_vid_id": "vids/94c59edb.mp4", "adv_score": 0.0, "adv_xclip": 0.13823798298835754, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ae58f244.mp4", "clean_score": 0.0, "clean_xclip": 0.16226355731487274, "clean_vbench": {}, "adv_vid_id": "vids/0ca8fb83.mp4", "adv_score": 0.0, "adv_xclip": 0.12596768140792847, "adv_vbench": {}}}}
{"id": "36884a124bf342fd880234050bf82e54", "source": "vatex", "video_id": "qW57bMrrA8M_000000_000010", "video_description": "A man wearing a black hat is in a cluttered room, yawning multiple times while listening to music.", "task": "Counting", "clean_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are sitting in a cluttered room, yawning multiple times while listening to music.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music. \u00b7@H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8bf84406aa942c9a46f42e59e9ecd2c.mp4", "clean_score": 1.0, "clean_xclip": 0.132634237408638, "clean_vbench": {"subject_consistency": 0.937743234137694, "background_consistency": 0.958984375, "motion_smoothness": 0.9879503528327483, "aesthetic_quality": 0.5130073428153992, "imaging_quality": 0.5342679775004484, "dynamic_degree": 0.0}, "adv_vid_id": "vids/c0f2b7d4cba2448bb8cd835c017c7e4e.mp4", "adv_score": 0.0, "adv_xclip": 0.1473342776298523, "adv_vbench": {"subject_consistency": 0.9660182949155569, "background_consistency": 0.9461466471354166, "motion_smoothness": 0.989047280029553, "aesthetic_quality": 0.4921227991580963, "imaging_quality": 0.6587825954203703, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f446a593.mp4", "clean_score": 1.0, "clean_xclip": 0.13658078014850616, "clean_vbench": {}, "adv_vid_id": "vids/4d614f96.mp4", "adv_score": 0.0, "adv_xclip": 0.14760984480381012, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/94f87efe.mp4", "clean_score": 1.0, "clean_xclip": 0.13000616431236267, "clean_vbench": {}, "adv_vid_id": "vids/78b2b3c6.mp4", "adv_score": 0.0, "adv_xclip": 0.15284739434719086, "adv_vbench": {}}}}
{"id": "f36bba298c254de8a7aa0d7adda48acf", "source": "vatex", "video_id": "tEpRURa-1gQ_000000_000010", "video_description": "A person is washing a golden retriever dog outside in the sunlight, using a bucket of water. The dog is being positioned and pulled towards the bucket during the bath.", "task": "SpatialUnderstanding", "clean_prompt": "A bucket positioned to the left of a golden retriever dog being washed outside in the sunlight.", "clean_property": {"obj_1": "bucket", "relation": "left of", "obj_2": "dog"}, "target_prompt": "A bucket positioned to the right of a golden retriever dog being washed outside in the sunlight.", "target_property": {"obj_1": "bucket", "relation": "right of", "obj_2": "dog"}, "evaluation_question": "Is the bucket to the **left** of the golden retriever dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bucket positioned to the left of a golden retriever dog being washed outside in the sunlight. FE7,E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/383d131649eb4a908641de1c72ace2a3.mp4", "clean_score": 1.0, "clean_xclip": 0.2267560362815857, "clean_vbench": {"subject_consistency": 0.9452858219544092, "background_consistency": 0.9639180501302084, "motion_smoothness": 0.9812415998131506, "aesthetic_quality": 0.5946799516677856, "imaging_quality": 0.7158366970140106, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1ce31fb8e03a4dd8bdb2701bc0e1cb0d.mp4", "adv_score": 0.0, "adv_xclip": 0.25270476937294006, "adv_vbench": {"subject_consistency": 0.9495572683711847, "background_consistency": 0.9597676595052084, "motion_smoothness": 0.9736863663900488, "aesthetic_quality": 0.5321829915046692, "imaging_quality": 0.7324344043342434, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f7ff7de.mp4", "clean_score": 1.0, "clean_xclip": 0.24817129969596863, "clean_vbench": {}, "adv_vid_id": "vids/3a3f7432.mp4", "adv_score": 1.0, "adv_xclip": 0.27314192056655884, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5bbab245.mp4", "clean_score": 0.0, "clean_xclip": 0.24122849106788635, "clean_vbench": {}, "adv_vid_id": "vids/676d8a55.mp4", "adv_score": 1.0, "adv_xclip": 0.25397294759750366, "adv_vbench": {}}}}
{"id": "4c031f7e2a6c48458ca717972b94a8a8", "source": "vatex", "video_id": "zaPA6JrqRRo_000019_000029", "video_description": "A group of people form a circle indoors, watching a couple of young men dance wildly in the center to heavy metal music.", "task": "SpatialUnderstanding", "clean_prompt": "A dancer to the left of a crowd indoors.", "clean_property": {"obj_1": "dancer", "relation": "left of", "obj_2": "crowd"}, "target_prompt": "A dancer to the right of a crowd indoors.", "target_property": {"obj_1": "dancer", "relation": "right of", "obj_2": "crowd"}, "evaluation_question": "Is the dancer to the **left** of a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dancer to the left of a crowd indoors. ))!D&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73caa36436fe450eae3134a506faa9ef.mp4", "clean_score": 1.0, "clean_xclip": 0.18333685398101807, "clean_vbench": {"subject_consistency": 0.882382221519947, "background_consistency": 0.91827392578125, "motion_smoothness": 0.9608889103223593, "aesthetic_quality": 0.4259738326072693, "imaging_quality": 0.2117328511452188, "dynamic_degree": 1.0}, "adv_vid_id": "vids/48fa93fc21ce4ac2b8e3c89b8feba68a.mp4", "adv_score": 0.0, "adv_xclip": 0.13736523687839508, "adv_vbench": {"subject_consistency": 0.8331093533585469, "background_consistency": 0.9234161376953125, "motion_smoothness": 0.9404249560613854, "aesthetic_quality": 0.4098224937915802, "imaging_quality": 0.23489971394441564, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/8bee7a5a.mp4", "clean_score": 1.0, "clean_xclip": 0.13420803844928741, "clean_vbench": {}, "adv_vid_id": "vids/8ec97b78.mp4", "adv_score": 1.0, "adv_xclip": 0.127033993601799, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/33356520.mp4", "clean_score": 1.0, "clean_xclip": 0.15517261624336243, "clean_vbench": {}, "adv_vid_id": "vids/52abd54f.mp4", "adv_score": 1.0, "adv_xclip": 0.14395223557949066, "adv_vbench": {}}}}
{"id": "3b0fb96bcfdc4156bebdf3721fd1bdcb", "source": "vatex", "video_id": "RIz7nXX6RpI_000081_000091", "video_description": "A group of people are inside an airplane, preparing to skydive.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of an airplane.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "airplane"}, "target_prompt": "A person standing to the left of an airplane.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "airplane"}, "evaluation_question": "Is the person to the **right** of the airplane?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the right of an airplane. %QSBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e64cf56128b64b91a14c78e9fdeb3a44.mp4", "clean_score": 1.0, "clean_xclip": 0.1520504355430603, "clean_vbench": {"subject_consistency": 0.9752045894662539, "background_consistency": 0.9584096272786459, "motion_smoothness": 0.9932627831739692, "aesthetic_quality": 0.4652799069881439, "imaging_quality": 0.7478658574941207, "dynamic_degree": 0.0}, "adv_vid_id": "vids/1d299330b5df4459b74ece3efc30ea66.mp4", "adv_score": 0.0, "adv_xclip": 0.10901793092489243, "adv_vbench": {"subject_consistency": 0.9438935127109289, "background_consistency": 0.9464009602864584, "motion_smoothness": 0.9958253410128197, "aesthetic_quality": 0.42604002356529236, "imaging_quality": 0.5794816534859794, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1610c3ef.mp4", "clean_score": 0.0, "clean_xclip": 0.19177791476249695, "clean_vbench": {}, "adv_vid_id": "vids/8fd9ab5e.mp4", "adv_score": 0.0, "adv_xclip": 0.1758636087179184, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c053292e.mp4", "clean_score": 0.0, "clean_xclip": 0.1814255714416504, "clean_vbench": {}, "adv_vid_id": "vids/529d76f5.mp4", "adv_score": 0.0, "adv_xclip": 0.14726120233535767, "adv_vbench": {}}}}
{"id": "776cbbe6708547828e38017e1451beb3", "source": "vatex", "video_id": "lYGoMB5u4SE_000000_000010", "video_description": "A person is inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "task": "Counting", "clean_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people inside the Tesla?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive. ED7SS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/772a542fd68949959acbd7a5858c93c2.mp4", "clean_score": 1.0, "clean_xclip": 0.1605059802532196, "clean_vbench": {"subject_consistency": 0.9703695935507616, "background_consistency": 0.9600728352864584, "motion_smoothness": 0.9890944068728315, "aesthetic_quality": 0.5509909987449646, "imaging_quality": 0.4482485619369818, "dynamic_degree": 1.0}, "adv_vid_id": "vids/4ceb4cd928e64c3ea02ae3756e86c88f.mp4", "adv_score": 0.0, "adv_xclip": 0.15925201773643494, "adv_vbench": {"subject_consistency": 0.9795602528999249, "background_consistency": 0.967498779296875, "motion_smoothness": 0.9907901729428912, "aesthetic_quality": 0.5621920228004456, "imaging_quality": 0.6861554827008929, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/703c5a3c.mp4", "clean_score": 0.0, "clean_xclip": 0.22361281514167786, "clean_vbench": {}, "adv_vid_id": "vids/d44cda38.mp4", "adv_score": 0.0, "adv_xclip": 0.19588983058929443, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/c7791de9.mp4", "clean_score": 0.0, "clean_xclip": 0.2130073606967926, "clean_vbench": {}, "adv_vid_id": "vids/06357769.mp4", "adv_score": 1.0, "adv_xclip": 0.2174982726573944, "adv_vbench": {}}}}
{"id": "000205c3d9f042129f2e57dce014f319", "source": "vatex", "video_id": "-iruowAZ8Fw_000580_000590", "video_description": "A woman, acting as a massage therapist, is giving a professional back massage to another person lying face down on a massage table. The therapist applies oil or lotion to her hands before massaging the client's back. Acoustic guitar music plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A client closer to the camera than a massage table.", "clean_property": {"obj_1": "client", "relation": "closer to the camera than", "obj_2": "massage table"}, "target_prompt": "A client further from the camera than a massage table.", "target_property": {"obj_1": "client", "relation": "further from the camera than", "obj_2": "massage table"}, "evaluation_question": "Is the client **closer to the camera than** the massage table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A client closer to the camera than a massage table. RR8X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/408db7c8795e4f8182acc51561a7ad1d.mp4", "clean_score": 1.0, "clean_xclip": 0.15886631608009338, "clean_vbench": {"subject_consistency": 0.99314586011072, "background_consistency": 0.9749043782552084, "motion_smoothness": 0.9969234687991709, "aesthetic_quality": 0.4232262372970581, "imaging_quality": 0.31713407594330456, "dynamic_degree": 0.0}, "adv_vid_id": "vids/5e6c51d016ad47d8a35f459e76355ed8.mp4", "adv_score": 0.0, "adv_xclip": 0.15069632232189178, "adv_vbench": {"subject_consistency": 0.9829362947493792, "background_consistency": 0.9789784749348959, "motion_smoothness": 0.9968819187557997, "aesthetic_quality": 0.40138477087020874, "imaging_quality": 0.5953688446356326, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3231584a.mp4", "clean_score": 1.0, "clean_xclip": 0.14746657013893127, "clean_vbench": {}, "adv_vid_id": "vids/31804bb6.mp4", "adv_score": 1.0, "adv_xclip": 0.1466728299856186, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/e35e1066.mp4", "clean_score": 1.0, "clean_xclip": 0.14565733075141907, "clean_vbench": {}, "adv_vid_id": "vids/1faa73ee.mp4", "adv_score": 1.0, "adv_xclip": 0.16166162490844727, "adv_vbench": {}}}}
{"id": "0566c7f5dbb14aeca8593e3f5376ab5f", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "ActionRecognition", "clean_prompt": "A waterskier water skiing beside a motorboat.", "clean_property": {"obj": "waterskier", "action": "water skiing", "target": null}, "target_prompt": "A waterskier falling into water beside a motorboat.", "target_property": {"obj": "waterskier", "action": "falling into water", "target": null}, "evaluation_question": "Is the waterskier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A waterskier water skiing beside a motorboat. >@I|@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57d78a87dac248e6a9aec3a8c98dabba.mp4", "clean_score": 1.0, "clean_xclip": 0.2232389599084854, "clean_vbench": {"subject_consistency": 0.9471851177513599, "background_consistency": 0.9377593994140625, "motion_smoothness": 0.9836400111517086, "aesthetic_quality": 0.5951381325721741, "imaging_quality": 0.6304501918870575, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5d164d3251a949afac2ebf0c6dfc41ed.mp4", "adv_score": 0.0, "adv_xclip": 0.25938767194747925, "adv_vbench": {"subject_consistency": 0.9111257685969273, "background_consistency": 0.9333394368489584, "motion_smoothness": 0.9737986719443436, "aesthetic_quality": 0.39881521463394165, "imaging_quality": 0.5875387472035933, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/092d321d.mp4", "clean_score": 0.0, "clean_xclip": 0.17398597300052643, "clean_vbench": {}, "adv_vid_id": "vids/e0234cf6.mp4", "adv_score": 1.0, "adv_xclip": 0.20609478652477264, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/179a274d.mp4", "clean_score": 1.0, "clean_xclip": 0.1741238236427307, "clean_vbench": {}, "adv_vid_id": "vids/b54c8d80.mp4", "adv_score": 1.0, "adv_xclip": 0.16364306211471558, "adv_vbench": {}}}}
{"id": "6a89a83c70a5441686ca9f19f7094840", "source": "vatex", "video_id": "-asB1gNPw38_000136_000146", "video_description": "A man in cycling gear, wearing a helmet, is riding a bicycle at high speeds on a busy road, trying to keep up with other bikers.", "task": "Counting", "clean_prompt": "Two bikers riding bicycles at high speeds on a busy road.", "clean_property": {"obj": "biker", "count": "two"}, "target_prompt": "One biker riding a bicycle at high speeds on a busy road.", "target_property": {"obj": "biker", "count": "one"}, "evaluation_question": "Are there exactly **two** bikers riding on the road?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two bikers riding bicycles at high speeds on a busy road. >TS49", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1f29daa801b6413d80fef2a8f0ae41a0.mp4", "clean_score": 1.0, "clean_xclip": 0.22905026376247406, "clean_vbench": {"subject_consistency": 0.9638055289785067, "background_consistency": 0.9479268391927084, "motion_smoothness": 0.9498243856473917, "aesthetic_quality": 0.5223560333251953, "imaging_quality": 0.5617353750734914, "dynamic_degree": 1.0}, "adv_vid_id": "vids/32311d360caa48869214cf39f0ffc80d.mp4", "adv_score": 0.0, "adv_xclip": 0.23966257274150848, "adv_vbench": {"subject_consistency": 0.9239203737427791, "background_consistency": 0.9375813802083334, "motion_smoothness": 0.9619303678550897, "aesthetic_quality": 0.47388729453086853, "imaging_quality": 0.46021249265086894, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/2bf36aba.mp4", "clean_score": 1.0, "clean_xclip": 0.21092519164085388, "clean_vbench": {}, "adv_vid_id": "vids/5c8fd67f.mp4", "adv_score": 1.0, "adv_xclip": 0.22471174597740173, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7af9907c.mp4", "clean_score": 1.0, "clean_xclip": 0.23114849627017975, "clean_vbench": {}, "adv_vid_id": "vids/26148ab4.mp4", "adv_score": 1.0, "adv_xclip": 0.20515750348567963, "adv_vbench": {}}}}
{"id": "dcdd6bed273241e49b79c40fedfc8d9e", "source": "vatex", "video_id": "3YpPMnCb3O4_000123_000133", "video_description": "A man demonstrates how to copy an identification card using a photocopier.", "task": "Counting", "clean_prompt": "A man demonstrates how to copy three identification cards using a photocopier.", "clean_property": {"obj": "identification card", "count": "three"}, "target_prompt": "A man demonstrates how to copy one identification card using a photocopier.", "target_property": {"obj": "identification card", "count": "one"}, "evaluation_question": "Are there exactly **three** identification cards being copied?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to copy three identification cards using a photocopier. FE@#>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d93e7f9d64143d188552af9ee7de295.mp4", "clean_score": 1.0, "clean_xclip": 0.18356993794441223, "clean_vbench": {"subject_consistency": 0.9379763274143139, "background_consistency": 0.9365386962890625, "motion_smoothness": 0.9658893063687667, "aesthetic_quality": 0.440472275018692, "imaging_quality": 0.6909028897966657, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c42a3067c934450086474e352bc81fd6.mp4", "adv_score": 0.0, "adv_xclip": 0.2341313362121582, "adv_vbench": {"subject_consistency": 0.9200664572417736, "background_consistency": 0.9128316243489584, "motion_smoothness": 0.961418364008412, "aesthetic_quality": 0.3684355318546295, "imaging_quality": 0.5401028115408761, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4a2a72db.mp4", "clean_score": 0.0, "clean_xclip": 0.22874295711517334, "clean_vbench": {}, "adv_vid_id": "vids/c9bed09f.mp4", "adv_score": 0.0, "adv_xclip": 0.2042984813451767, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3b4c5a89.mp4", "clean_score": 1.0, "clean_xclip": 0.23237189650535583, "clean_vbench": {}, "adv_vid_id": "vids/6d166ca0.mp4", "adv_score": 1.0, "adv_xclip": 0.22313544154167175, "adv_vbench": {}}}}
{"id": "596c6f2d805142b29a698960951126d4", "source": "vatex", "video_id": "Lrgs9rwTHuY_000043_000053", "video_description": "A person is performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music.", "task": "Counting", "clean_prompt": "Three people performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people performing water sports on the lake?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Three people performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a55c820b8ae4fa5bc0bf0cabcf60d37.mp4", "clean_score": 1.0, "clean_xclip": 0.28130435943603516, "clean_vbench": {"subject_consistency": 0.8530947590867678, "background_consistency": 0.9236246744791666, "motion_smoothness": 0.9829276368211893, "aesthetic_quality": 0.5847339034080505, "imaging_quality": 0.3451997811453683, "dynamic_degree": 1.0}, "adv_vid_id": "vids/27be5c2d03e84b3e8f0ec0fb43cd690c.mp4", "adv_score": 0.0, "adv_xclip": 0.2867615222930908, "adv_vbench": {"subject_consistency": 0.8683255289991697, "background_consistency": 0.9327646891276041, "motion_smoothness": 0.9863098140394275, "aesthetic_quality": 0.5502984523773193, "imaging_quality": 0.30361383788439694, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c163e1e1.mp4", "clean_score": 1.0, "clean_xclip": 0.19292956590652466, "clean_vbench": {}, "adv_vid_id": "vids/69cb74ba.mp4", "adv_score": 0.0, "adv_xclip": 0.21216696500778198, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/143fbb4e.mp4", "clean_score": 0.0, "clean_xclip": 0.2568960189819336, "clean_vbench": {}, "adv_vid_id": "vids/7668f9cd.mp4", "adv_score": 0.0, "adv_xclip": 0.2040451020002365, "adv_vbench": {}}}}
{"id": "8d4b00a1fff44ede9dbc24a6f22fdd30", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "ActionRecognition", "clean_prompt": "A waterskier water skiing beside a motorboat.", "clean_property": {"obj": "waterskier", "action": "water skiing", "target": null}, "target_prompt": "A waterskier falling into water beside a motorboat.", "target_property": {"obj": "waterskier", "action": "falling into water", "target": null}, "evaluation_question": "Is the waterskier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A waterskier water skiing beside a motorboat. )!G*P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/817ec9c0f512448cb0b9d3319e9cdc83.mp4", "clean_score": 1.0, "clean_xclip": 0.2232389599084854, "clean_vbench": {"subject_consistency": 0.9471851177513599, "background_consistency": 0.9377593994140625, "motion_smoothness": 0.9836400111517086, "aesthetic_quality": 0.5951381325721741, "imaging_quality": 0.6304501918870575, "dynamic_degree": 1.0}, "adv_vid_id": "vids/31d2c0ece9cf4adda6c1d6a86590895b.mp4", "adv_score": 0.0, "adv_xclip": 0.19045688211917877, "adv_vbench": {"subject_consistency": 0.9229911131163439, "background_consistency": 0.9081319173177084, "motion_smoothness": 0.9709986871999314, "aesthetic_quality": 0.4630853235721588, "imaging_quality": 0.6476791887867208, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/0c4c3f6b.mp4", "clean_score": 1.0, "clean_xclip": 0.19868610799312592, "clean_vbench": {}, "adv_vid_id": "vids/26dae3e6.mp4", "adv_score": 1.0, "adv_xclip": 0.21349093317985535, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/293bed81.mp4", "clean_score": 1.0, "clean_xclip": 0.13015499711036682, "clean_vbench": {}, "adv_vid_id": "vids/b276b53e.mp4", "adv_score": 0.0, "adv_xclip": 0.16216519474983215, "adv_vbench": {}}}}
{"id": "8a58d1ad0764413e9ea8b2658b3813ae", "source": "vatex", "video_id": "QKPxRS-KQOo_000110_000120", "video_description": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while motorcycles rev their engines in the background.", "task": "ObjectRecognition", "clean_prompt": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while a car is parked in the background.", "clean_property": {"obj": "car"}, "target_prompt": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while a bicycle is parked in the background.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is there a **car** parked in the background of the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while a car is parked in the background. Fahr Sno Ec Sunt Reise", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e6fad3bb42334227bfe1ee42486e5099.mp4", "clean_score": 1.0, "clean_xclip": 0.2817244529724121, "clean_vbench": {"subject_consistency": 0.959517490118742, "background_consistency": 0.94757080078125, "motion_smoothness": 0.971042438271605, "aesthetic_quality": 0.5563023686408997, "imaging_quality": 0.7026105148938236, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1ad2fe5e067547cf9372b17122e58d1d.mp4", "adv_score": 0.0, "adv_xclip": 0.2833878993988037, "adv_vbench": {"subject_consistency": 0.9565549480418364, "background_consistency": 0.9507344563802084, "motion_smoothness": 0.979088717389605, "aesthetic_quality": 0.5579097867012024, "imaging_quality": 0.7243180816027583, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f8fb0ef1.mp4", "clean_score": 1.0, "clean_xclip": 0.22276261448860168, "clean_vbench": {}, "adv_vid_id": "vids/c9f63ff2.mp4", "adv_score": 1.0, "adv_xclip": 0.2431889921426773, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/567e5f58.mp4", "clean_score": 1.0, "clean_xclip": 0.28875115513801575, "clean_vbench": {}, "adv_vid_id": "vids/dea1a295.mp4", "adv_score": 1.0, "adv_xclip": 0.320069819688797, "adv_vbench": {}}}}
{"id": "b97d20c351274cbeaf7cf8a2d61b4ec1", "source": "vatex", "video_id": "Whfyh4v6Mkw_000001_000011", "video_description": "A group of people, including a woman and a child, are playing a game of Monopoly. They are handling cards and money, discussing the rules, and making transactions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a Monopoly board.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "Monopoly board"}, "target_prompt": "A person further from the camera than a Monopoly board.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "Monopoly board"}, "evaluation_question": "Is the person **closer to the camera than** the Monopoly board?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a Monopoly board. @TVH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/06145e5b595f410d922aa0dcd37bf700.mp4", "clean_score": 1.0, "clean_xclip": 0.09615785628557205, "clean_vbench": {"subject_consistency": 0.9864101173977057, "background_consistency": 0.9820556640625, "motion_smoothness": 0.9953633455504115, "aesthetic_quality": 0.39982351660728455, "imaging_quality": 0.22616912335765604, "dynamic_degree": 0.0}, "adv_vid_id": "vids/ef434188a32944e09fcf127c663da019.mp4", "adv_score": 0.0, "adv_xclip": 0.12051940709352493, "adv_vbench": {"subject_consistency": 0.9777091623594364, "background_consistency": 0.9800923665364584, "motion_smoothness": 0.9925273896113229, "aesthetic_quality": 0.3952926993370056, "imaging_quality": 0.32260984187223474, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ba8aa48c.mp4", "clean_score": 1.0, "clean_xclip": 0.12392593920230865, "clean_vbench": {}, "adv_vid_id": "vids/f3597fa1.mp4", "adv_score": 0.0, "adv_xclip": 0.12113672494888306, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/715c30da.mp4", "clean_score": 1.0, "clean_xclip": 0.12860062718391418, "clean_vbench": {}, "adv_vid_id": "vids/0076a5e1.mp4", "adv_score": 1.0, "adv_xclip": 0.11745218932628632, "adv_vbench": {}}}}
{"id": "0c42d98b99a7465ba8d5c51a9dc8a21a", "source": "vatex", "video_id": "b1x_oZ11U0Y_000016_000026", "video_description": "A large group of people are playing various percussion instruments, including xylophones, maracas, and drums, outside in a parking lot or street.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the left of an instrument.", "clean_property": {"obj_1": "musician", "relation": "left of", "obj_2": "instrument"}, "target_prompt": "A musician standing to the right of an instrument.", "target_property": {"obj_1": "musician", "relation": "right of", "obj_2": "instrument"}, "evaluation_question": "Is the musician to the **left** of an instrument?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A musician standing to the left of an instrument. Gamheure medizin", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4b3ee867b2f2480ea268055c70de3a97.mp4", "clean_score": 1.0, "clean_xclip": 0.09838628768920898, "clean_vbench": {"subject_consistency": 0.960215845455726, "background_consistency": 0.943023681640625, "motion_smoothness": 0.9793738249414992, "aesthetic_quality": 0.4704003632068634, "imaging_quality": 0.48900977621273123, "dynamic_degree": 1.0}, "adv_vid_id": "vids/22d6e637873d43d08702f1bd1d5c4c6b.mp4", "adv_score": 0.0, "adv_xclip": 0.12745051085948944, "adv_vbench": {"subject_consistency": 0.9566080694397291, "background_consistency": 0.935302734375, "motion_smoothness": 0.9859320912006778, "aesthetic_quality": 0.3553817868232727, "imaging_quality": 0.4178323356472716, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/a5ab1617.mp4", "clean_score": 0.0, "clean_xclip": 0.1385830193758011, "clean_vbench": {}, "adv_vid_id": "vids/fbbb70df.mp4", "adv_score": 0.0, "adv_xclip": 0.15048587322235107, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/b0e8d76e.mp4", "clean_score": 1.0, "clean_xclip": 0.11739352345466614, "clean_vbench": {}, "adv_vid_id": "vids/c851b3e5.mp4", "adv_score": 0.0, "adv_xclip": 0.08685459196567535, "adv_vbench": {}}}}
{"id": "e9d664d9bed742808c5a89a26e796667", "source": "vatex", "video_id": "6QetWvqJCkU_000023_000033", "video_description": "A man in a jean outfit and hat is dancing to music in a garage with a guitar in the background.", "task": "ObjectRecognition", "clean_prompt": "A man dancing in a garage with a guitar in the background.", "clean_property": {"obj": "guitar"}, "target_prompt": "A man dancing in a garage with a drum in the background.", "target_property": {"obj": "drum"}, "evaluation_question": "Is there a **guitar** in the background of the video?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A man dancing in a garage with a guitar in the background. U%3*U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c2c88dc99bb4987b5e16907751f40c5.mp4", "clean_score": 1.0, "clean_xclip": 0.10474741458892822, "clean_vbench": {"subject_consistency": 0.792209280654788, "background_consistency": 0.8906707763671875, "motion_smoothness": 0.9530845643394961, "aesthetic_quality": 0.44020819664001465, "imaging_quality": 0.3020542732550173, "dynamic_degree": 1.0}, "adv_vid_id": "vids/5b5ec567da3d4660bd0f5ce68896af07.mp4", "adv_score": 0.0, "adv_xclip": 0.09762457013130188, "adv_vbench": {"subject_consistency": 0.7512220367789268, "background_consistency": 0.8940785725911459, "motion_smoothness": 0.9616341117465504, "aesthetic_quality": 0.4139780104160309, "imaging_quality": 0.268113956451416, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/abe3d61d.mp4", "clean_score": 1.0, "clean_xclip": 0.20427703857421875, "clean_vbench": {}, "adv_vid_id": "vids/64278437.mp4", "adv_score": 1.0, "adv_xclip": 0.19235192239284515, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/09ce36bc.mp4", "clean_score": 1.0, "clean_xclip": 0.179630309343338, "clean_vbench": {}, "adv_vid_id": "vids/b2807917.mp4", "adv_score": 1.0, "adv_xclip": 0.16468970477581024, "adv_vbench": {}}}}
{"id": "b957d9ca6cf945bb9c3fb67ff06b0408", "source": "vatex", "video_id": "9EZKYCAOAvk_000119_000129", "video_description": "A man is demonstrating and explaining how to clean a window sill using a spray bottle and a cloth.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth.", "clean_property": {"obj": "window", "attribute": "uPVC"}, "target_prompt": "A man is demonstrating how to clean a wooden window sill using a spray bottle and a cloth.", "target_property": {"obj": "window", "attribute": "wooden"}, "evaluation_question": "Is the window sill made of **uPVC**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth. LF&3S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40e6e977fbb64ada9e7b73d0c885d39f.mp4", "clean_score": 1.0, "clean_xclip": 0.2050771862268448, "clean_vbench": {"subject_consistency": 0.9113432988524437, "background_consistency": 0.9203440348307291, "motion_smoothness": 0.9781902340282821, "aesthetic_quality": 0.3817373812198639, "imaging_quality": 0.3410568727765764, "dynamic_degree": 1.0}, "adv_vid_id": "vids/030cc718339345e98304551b55baa01a.mp4", "adv_score": 0.0, "adv_xclip": 0.24871012568473816, "adv_vbench": {"subject_consistency": 0.848261167605718, "background_consistency": 0.9260050455729166, "motion_smoothness": 0.9698015060480211, "aesthetic_quality": 0.3622189164161682, "imaging_quality": 0.48529203765246337, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/c3041dd6.mp4", "clean_score": 0.0, "clean_xclip": 0.22153402864933014, "clean_vbench": {}, "adv_vid_id": "vids/e59639f7.mp4", "adv_score": 0.0, "adv_xclip": 0.19771185517311096, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/db7017cc.mp4", "clean_score": 0.0, "clean_xclip": 0.22343604266643524, "clean_vbench": {}, "adv_vid_id": "vids/bf45f430.mp4", "adv_score": 0.0, "adv_xclip": 0.22982773184776306, "adv_vbench": {}}}}
{"id": "5b0c8c05a13f4362b940e6745e2bbf0d", "source": "vatex", "video_id": "1d4ZOE0y3e4_000275_000285", "video_description": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her.", "task": "Counting", "clean_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while seven fans blow air on her.", "clean_property": {"obj": "fan", "count": "seven"}, "target_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while two fans blow air on her.", "target_property": {"obj": "fan", "count": "two"}, "evaluation_question": "Are there exactly **seven** fans blowing air on her?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while seven fans blow air on her. )!G*C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/755b98888441473c9dc4185eb87d54b5.mp4", "clean_score": 1.0, "clean_xclip": 0.23341727256774902, "clean_vbench": {"subject_consistency": 0.9499717839062214, "background_consistency": 0.9158477783203125, "motion_smoothness": 0.9742929318718228, "aesthetic_quality": 0.43439310789108276, "imaging_quality": 0.7247666401765784, "dynamic_degree": 1.0}, "adv_vid_id": "vids/757ea8437b2047e6a6b9a03822043a70.mp4", "adv_score": 0.0, "adv_xclip": 0.228438138961792, "adv_vbench": {"subject_consistency": 0.9593631171931823, "background_consistency": 0.9004007975260416, "motion_smoothness": 0.9796980317139716, "aesthetic_quality": 0.3778266906738281, "imaging_quality": 0.7372928868507853, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9a6460f1.mp4", "clean_score": 0.0, "clean_xclip": 0.2179831713438034, "clean_vbench": {}, "adv_vid_id": "vids/6b1065ec.mp4", "adv_score": 0.0, "adv_xclip": 0.2158021181821823, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/39144de9.mp4", "clean_score": 1.0, "clean_xclip": 0.23056569695472717, "clean_vbench": {}, "adv_vid_id": "vids/10488c50.mp4", "adv_score": 0.0, "adv_xclip": 0.23135577142238617, "adv_vbench": {}}}}
{"id": "b3d29c5bed1046bbaa29ad85bbde0204", "source": "vatex", "video_id": "M3-oz_R_xsk_000019_000029", "video_description": "A man in a yellow shirt and black exercise shorts is repeatedly hitting a large rubber tire with a sledgehammer outdoors.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a tire outdoors.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "tire"}, "target_prompt": "A person kicking a tire outdoors.", "target_property": {"obj": "person", "action": "kicking", "target": "tire"}, "evaluation_question": "Is the person **using a sledge hammer** on the tire?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person using a sledge hammer on a tire outdoors. SNEM/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/421755f5ad7244a0a458dea41b0109ec.mp4", "clean_score": 1.0, "clean_xclip": 0.18487314879894257, "clean_vbench": {"subject_consistency": 0.9502305705100298, "background_consistency": 0.9425760904947916, "motion_smoothness": 0.9616815815253571, "aesthetic_quality": 0.48593324422836304, "imaging_quality": 0.6837147903442383, "dynamic_degree": 1.0}, "adv_vid_id": "vids/06e8ec0580664c7b866c657b79c71636.mp4", "adv_score": 0.0, "adv_xclip": 0.24553152918815613, "adv_vbench": {"subject_consistency": 0.9183061557511488, "background_consistency": 0.9310862223307291, "motion_smoothness": 0.9557538424223856, "aesthetic_quality": 0.5255234837532043, "imaging_quality": 0.6742758388908543, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3001dceb.mp4", "clean_score": 1.0, "clean_xclip": 0.22729389369487762, "clean_vbench": {}, "adv_vid_id": "vids/db8d884d.mp4", "adv_score": 1.0, "adv_xclip": 0.19617018103599548, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dc2ef1b3.mp4", "clean_score": 0.0, "clean_xclip": 0.209428608417511, "clean_vbench": {}, "adv_vid_id": "vids/099c0a17.mp4", "adv_score": 1.0, "adv_xclip": 0.23756352066993713, "adv_vbench": {}}}}
{"id": "1be328fe8c0c43eea411e31db7892eb6", "source": "vatex", "video_id": "NcACCCcY-_c_000015_000025", "video_description": "A man is demonstrating and explaining how to tie and lace up shoes, focusing on a specific knot technique.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a shoe while demonstrating how to tie it.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "shoe"}, "target_prompt": "A person standing to the left of a shoe while demonstrating how to tie it.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "shoe"}, "evaluation_question": "Is the person to the **right** of the shoe?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person standing to the right of a shoe while demonstrating how to tie it. )%H))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/05dda8891f7747a0acad07fcade78afd.mp4", "clean_score": 1.0, "clean_xclip": 0.20771265029907227, "clean_vbench": {"subject_consistency": 0.9329589003076156, "background_consistency": 0.9600880940755209, "motion_smoothness": 0.966994759516461, "aesthetic_quality": 0.5237627625465393, "imaging_quality": 0.5229761917737066, "dynamic_degree": 1.0}, "adv_vid_id": "vids/754cc559f8cf49fab75091384211383e.mp4", "adv_score": 0.0, "adv_xclip": 0.19261883199214935, "adv_vbench": {"subject_consistency": 0.920008164520065, "background_consistency": 0.9559478759765625, "motion_smoothness": 0.9555211858824033, "aesthetic_quality": 0.4550209641456604, "imaging_quality": 0.5996110900567503, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/511a059d.mp4", "clean_score": 1.0, "clean_xclip": 0.17906582355499268, "clean_vbench": {}, "adv_vid_id": "vids/bacfd192.mp4", "adv_score": 0.0, "adv_xclip": 0.2002699077129364, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/0771214a.mp4", "clean_score": 0.0, "clean_xclip": 0.19102516770362854, "clean_vbench": {}, "adv_vid_id": "vids/0fc72d72.mp4", "adv_score": 0.0, "adv_xclip": 0.19567672908306122, "adv_vbench": {}}}}
{"id": "8882f6d2dc9946e5bf77ecba69cdfb58", "source": "vatex", "video_id": "fNa0EZiUib8_000053_000063", "video_description": "A man is on a ladder trying to reach something in a tree during the daytime. He descends the ladder, makes a comment about not being able to reach it, and adjusts his camera.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a ladder during the daytime.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "ladder"}, "target_prompt": "A woman standing to the right of a tree during the daytime.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "tree"}, "evaluation_question": "Is the man to the **left** of a ladder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a ladder during the daytime. FG70", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb871f858f4645caa41b87c3e77ff32d.mp4", "clean_score": 1.0, "clean_xclip": 0.20904666185379028, "clean_vbench": {"subject_consistency": 0.9861608340094487, "background_consistency": 0.9414418538411459, "motion_smoothness": 0.99643166710164, "aesthetic_quality": 0.39920368790626526, "imaging_quality": 0.6160543029162349, "dynamic_degree": 0.0}, "adv_vid_id": "vids/7fd4ed57b87145fab6f3c8080c0a2c0b.mp4", "adv_score": 0.0, "adv_xclip": 0.15430817008018494, "adv_vbench": {"subject_consistency": 0.9801968485116959, "background_consistency": 0.940765380859375, "motion_smoothness": 0.994836335910393, "aesthetic_quality": 0.3977261781692505, "imaging_quality": 0.7529778523347815, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/45768202.mp4", "clean_score": 1.0, "clean_xclip": 0.210951566696167, "clean_vbench": {}, "adv_vid_id": "vids/2d4e882c.mp4", "adv_score": 1.0, "adv_xclip": 0.19105634093284607, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/69a2397e.mp4", "clean_score": 0.0, "clean_xclip": 0.13981199264526367, "clean_vbench": {}, "adv_vid_id": "vids/2266bdfa.mp4", "adv_score": 0.0, "adv_xclip": 0.20896372199058533, "adv_vbench": {}}}}
{"id": "f72552611b0c4b4b8c5eb26fb6d78cc6", "source": "vatex", "video_id": "4d6Ch7lhz5w_000000_000010", "video_description": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "task": "ObjectRecognition", "clean_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "clean_property": {"obj": "hair dryer"}, "target_prompt": "A man is in a kitchen using a toaster to toast bread while singing and speaking.", "target_property": {"obj": "toaster"}, "evaluation_question": "Is the man using a **hair dryer** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking. 8MOEZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b817b7d62ba842fe9d7a5f887b7ebe75.mp4", "clean_score": 1.0, "clean_xclip": 0.15222717821598053, "clean_vbench": {"subject_consistency": 0.8826088986049095, "background_consistency": 0.9142913818359375, "motion_smoothness": 0.9605914466899156, "aesthetic_quality": 0.4550797641277313, "imaging_quality": 0.44367271656892737, "dynamic_degree": 1.0}, "adv_vid_id": "vids/c2c0817595b2462e8df7f3808569d1c0.mp4", "adv_score": 0.0, "adv_xclip": 0.21955418586730957, "adv_vbench": {"subject_consistency": 0.9398917835205793, "background_consistency": 0.9242401123046875, "motion_smoothness": 0.95642088023481, "aesthetic_quality": 0.47338882088661194, "imaging_quality": 0.5348699943386779, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f67e24b5.mp4", "clean_score": 0.0, "clean_xclip": 0.1564149409532547, "clean_vbench": {}, "adv_vid_id": "vids/b9f461e7.mp4", "adv_score": 0.0, "adv_xclip": 0.12325172126293182, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/ce4cb491.mp4", "clean_score": 1.0, "clean_xclip": 0.23366442322731018, "clean_vbench": {}, "adv_vid_id": "vids/175bdb59.mp4", "adv_score": 1.0, "adv_xclip": 0.20688064396381378, "adv_vbench": {}}}}
{"id": "b1243f6993d34142bcaab9c9646f07ef", "source": "vatex", "video_id": "0aSmZ91nawo_000060_000070", "video_description": "Two women are involved in an exercise demonstration. One woman is holding a baby while squeezing a red exercise ball between her legs, and the other woman is instructing the exercise.", "task": "ObjectRecognition", "clean_prompt": "A woman holding a baby while squeezing a red exercise ball between her legs, with another woman instructing the exercise.", "clean_property": {"obj": "baby"}, "target_prompt": "A woman holding a puppy while squeezing a red exercise ball between her legs, with another woman instructing the exercise.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the woman holding a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman holding a baby while squeezing a red exercise ball between her legs, with another woman instructing the exercise. >%BSA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1d74ebb2490c4b5cb690b6aa0e30203b.mp4", "clean_score": 1.0, "clean_xclip": 0.259146511554718, "clean_vbench": {"subject_consistency": 0.9827562551945448, "background_consistency": 0.9891357421875, "motion_smoothness": 0.9846167678137356, "aesthetic_quality": 0.5185555219650269, "imaging_quality": 0.5023312362359494, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1e0826c0700143c3ad0523eb3935bac1.mp4", "adv_score": 0.0, "adv_xclip": 0.23719438910484314, "adv_vbench": {"subject_consistency": 0.971264997497201, "background_consistency": 0.9755503336588541, "motion_smoothness": 0.9847960425618293, "aesthetic_quality": 0.44995060563087463, "imaging_quality": 0.6120006607989875, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ad6b7f57.mp4", "clean_score": 0.0, "clean_xclip": 0.22164057195186615, "clean_vbench": {}, "adv_vid_id": "vids/aa5d76c9.mp4", "adv_score": 0.0, "adv_xclip": 0.2631511092185974, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3d4f0556.mp4", "clean_score": 1.0, "clean_xclip": 0.2375446856021881, "clean_vbench": {}, "adv_vid_id": "vids/0bc8e88f.mp4", "adv_score": 1.0, "adv_xclip": 0.2588835656642914, "adv_vbench": {}}}}
{"id": "020e3504ffd1431d9b02655bd7a07528", "source": "vatex", "video_id": "lHe6Ehd5S0Y_000001_000011", "video_description": "A young man with long hair is having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "task": "Counting", "clean_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people having a staring contest?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play. Spotify Backgroundoricar adaugindividuellen", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/398752cc7ccd45cfadd7f8a1dabca1e1.mp4", "clean_score": 1.0, "clean_xclip": 0.15607887506484985, "clean_vbench": {"subject_consistency": 0.9158669399718443, "background_consistency": 0.9352773030598959, "motion_smoothness": 0.9414777333033264, "aesthetic_quality": 0.3906383812427521, "imaging_quality": 0.5758094740887078, "dynamic_degree": 1.0}, "adv_vid_id": "vids/de9eadc0363644c19c7351b1d2c6f3da.mp4", "adv_score": 0.0, "adv_xclip": 0.1900608092546463, "adv_vbench": {"subject_consistency": 0.9009816845258077, "background_consistency": 0.9057769775390625, "motion_smoothness": 0.9605803301258775, "aesthetic_quality": 0.4356282651424408, "imaging_quality": 0.46246472339240874, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/38c8a098.mp4", "clean_score": 1.0, "clean_xclip": 0.15159562230110168, "clean_vbench": {}, "adv_vid_id": "vids/8156a2f8.mp4", "adv_score": 0.0, "adv_xclip": 0.15119411051273346, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/3921f9f5.mp4", "clean_score": 0.0, "clean_xclip": 0.192650705575943, "clean_vbench": {}, "adv_vid_id": "vids/3c98fcf5.mp4", "adv_score": 0.0, "adv_xclip": 0.2000802904367447, "adv_vbench": {}}}}
{"id": "0e9428fcf2ba4521afccdf0cc4717772", "source": "vatex", "video_id": "s7qkYZTezYs_000002_000012", "video_description": "A person is cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "task": "AttributeRecognition", "clean_prompt": "A person cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "clean_property": {"obj": "toilet", "attribute": "poorly kept"}, "target_prompt": "A person cleaning a spotlessly clean toilet using a toilet brush while wearing gloves.", "target_property": {"obj": "toilet", "attribute": "spotlessly clean"}, "evaluation_question": "Is the toilet **poorly kept**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person cleaning a poorly kept toilet using a toilet brush while wearing gloves. ))!%H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fa840445ca734d05a288ff7aeaeb8962.mp4", "clean_score": 1.0, "clean_xclip": 0.24046018719673157, "clean_vbench": {"subject_consistency": 0.8497675179193417, "background_consistency": 0.9110463460286459, "motion_smoothness": 0.9639404326030825, "aesthetic_quality": 0.3830769658088684, "imaging_quality": 0.4220808363933953, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8cc8820e335940679d6a81a3fdc6725c.mp4", "adv_score": 0.0, "adv_xclip": 0.24138306081295013, "adv_vbench": {"subject_consistency": 0.867793877919515, "background_consistency": 0.9287007649739584, "motion_smoothness": 0.960202301702574, "aesthetic_quality": 0.37143900990486145, "imaging_quality": 0.38138324659697864, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/3f899fa0.mp4", "clean_score": 1.0, "clean_xclip": 0.23842263221740723, "clean_vbench": {}, "adv_vid_id": "vids/a3d35f0d.mp4", "adv_score": 0.0, "adv_xclip": 0.22784480452537537, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/25552293.mp4", "clean_score": 0.0, "clean_xclip": 0.25514769554138184, "clean_vbench": {}, "adv_vid_id": "vids/da4f8d6d.mp4", "adv_score": 0.0, "adv_xclip": 0.25367993116378784, "adv_vbench": {}}}}
{"id": "4d370539bd9f46ad9ab39b42b5348e4e", "source": "vatex", "video_id": "B9qb-EQNkfk_000000_000010", "video_description": "A little girl interacts with a pregnant woman's belly, talking, listening, and feeling for the baby inside.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the left of a little girl, interacting with her belly.", "clean_property": {"obj_1": "woman", "relation": "left of", "obj_2": "girl"}, "target_prompt": "A woman standing to the right of a little girl, interacting with her belly.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "girl"}, "evaluation_question": "Is the woman to the **left** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the left of a little girl, interacting with her belly. !0D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95534e8331f645e2b36167b610301f58.mp4", "clean_score": 1.0, "clean_xclip": 0.22625038027763367, "clean_vbench": {"subject_consistency": 0.9673485333720843, "background_consistency": 0.944366455078125, "motion_smoothness": 0.9862482550633422, "aesthetic_quality": 0.5523834824562073, "imaging_quality": 0.7319025779257015, "dynamic_degree": 1.0}, "adv_vid_id": "vids/2e186e6ede7f455c9ce9d4ec705dd2b5.mp4", "adv_score": 0.0, "adv_xclip": 0.2079358994960785, "adv_vbench": {"subject_consistency": 0.9721622746437788, "background_consistency": 0.958892822265625, "motion_smoothness": 0.9875387231892501, "aesthetic_quality": 0.5411314368247986, "imaging_quality": 0.7325029256392499, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/41510888.mp4", "clean_score": 1.0, "clean_xclip": 0.13165420293807983, "clean_vbench": {}, "adv_vid_id": "vids/010a3fc9.mp4", "adv_score": 0.0, "adv_xclip": 0.1742248833179474, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/15920e27.mp4", "clean_score": 1.0, "clean_xclip": 0.1769404113292694, "clean_vbench": {}, "adv_vid_id": "vids/c5b16f93.mp4", "adv_score": 1.0, "adv_xclip": 0.1838890016078949, "adv_vbench": {}}}}
{"id": "35de3e7b61c240f0a61a5372ed28d1a2", "source": "vatex", "video_id": "Ea_Wr5Lt3lc_000022_000032", "video_description": "A group of people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering.", "task": "Counting", "clean_prompt": "Seven people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering.", "clean_property": {"obj": "people", "count": "seven"}, "target_prompt": "Four people are in a small boat sailing on a calm lake, enjoying the scenery and taking photos.", "target_property": {"obj": "people", "count": "four"}, "evaluation_question": "Are there exactly **seven** people in the amphibious vehicle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering. =A$XS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/92fbfac4c0784a74b19da765ee058060.mp4", "clean_score": 1.0, "clean_xclip": 0.15392586588859558, "clean_vbench": {"subject_consistency": 0.9607395902276039, "background_consistency": 0.9366607666015625, "motion_smoothness": 0.9707624191201687, "aesthetic_quality": 0.5616791844367981, "imaging_quality": 0.651729245867048, "dynamic_degree": 1.0}, "adv_vid_id": "vids/3e4b5cf53d2c4acfb09d0ab915d59624.mp4", "adv_score": 0.0, "adv_xclip": 0.17795947194099426, "adv_vbench": {"subject_consistency": 0.960429904361566, "background_consistency": 0.9507802327473959, "motion_smoothness": 0.9669409909765089, "aesthetic_quality": 0.5328606963157654, "imaging_quality": 0.623021610026457, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7ca80691.mp4", "clean_score": 0.0, "clean_xclip": 0.185689777135849, "clean_vbench": {}, "adv_vid_id": "vids/97959943.mp4", "adv_score": 0.0, "adv_xclip": 0.15618640184402466, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/bb308547.mp4", "clean_score": 0.0, "clean_xclip": 0.14282624423503876, "clean_vbench": {}, "adv_vid_id": "vids/3774fb04.mp4", "adv_score": 0.0, "adv_xclip": 0.2030235230922699, "adv_vbench": {}}}}
{"id": "9a733f4b77a34ddb9166e314a9aceecd", "source": "vatex", "video_id": "J3OG-RLowJc_000024_000034", "video_description": "A group of young people are competing in a dodgeball tournament in an indoor gym. The game starts with players running to the center of the court to grab balls.", "task": "AttributeRecognition", "clean_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym.", "clean_property": {"obj": "player", "attribute": "student"}, "target_prompt": "A player who is a professional competing in a dodgeball tournament in an indoor gym.", "target_property": {"obj": "player", "attribute": "professional"}, "evaluation_question": "Is the player a **student**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym. TY&K6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0d4189b17594e35bc72bf87fe4a7629.mp4", "clean_score": 1.0, "clean_xclip": 0.15062636137008667, "clean_vbench": {"subject_consistency": 0.9244303411493698, "background_consistency": 0.9112396240234375, "motion_smoothness": 0.9640421178727406, "aesthetic_quality": 0.45633548498153687, "imaging_quality": 0.5290387967168069, "dynamic_degree": 1.0}, "adv_vid_id": "vids/bbf72ec499cc4758b701ba1a1a370230.mp4", "adv_score": 0.0, "adv_xclip": 0.19177427887916565, "adv_vbench": {"subject_consistency": 0.9255938058098158, "background_consistency": 0.8982340494791666, "motion_smoothness": 0.9628948664631748, "aesthetic_quality": 0.42826414108276367, "imaging_quality": 0.5702228265879106, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/4a3e1bfa.mp4", "clean_score": 1.0, "clean_xclip": 0.10096225142478943, "clean_vbench": {}, "adv_vid_id": "vids/e681a875.mp4", "adv_score": 1.0, "adv_xclip": 0.13599206507205963, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6c8b33a7.mp4", "clean_score": 0.0, "clean_xclip": 0.1462189108133316, "clean_vbench": {}, "adv_vid_id": "vids/eb1ce64d.mp4", "adv_score": 1.0, "adv_xclip": 0.14379237592220306, "adv_vbench": {}}}}
{"id": "e7e0def3b9d748cc8d4b7bceba24e39d", "source": "vatex", "video_id": "Vvs5E6bJFNM_000005_000015", "video_description": "Two elderly women and two young children, a girl and a boy, are in a house. One woman is in a wheelchair, another is seated in a chair, and they are demonstrating hand exercises and games to the children.", "task": "ObjectRecognition", "clean_prompt": "Two elderly women are demonstrating hand exercises to a young boy and a young girl in a cozy living room.", "clean_property": {"obj": "young boy"}, "target_prompt": "Two elderly women are demonstrating hand exercises to a young girl in a cozy living room.", "target_property": {"obj": "young girl"}, "evaluation_question": "Is the child in the video a **young boy**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Two elderly women are demonstrating hand exercises to a young boy and a young girl in a cozy living room. kleinkultur konsequent Cristian Petru", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f7218873ef44e219cc72765b2a11d11.mp4", "clean_score": 1.0, "clean_xclip": 0.15312013030052185, "clean_vbench": {"subject_consistency": 0.9591677089532217, "background_consistency": 0.9690144856770834, "motion_smoothness": 0.982341741084937, "aesthetic_quality": 0.6790093779563904, "imaging_quality": 0.7836240947489835, "dynamic_degree": 1.0}, "adv_vid_id": "vids/f83fd9a7a7be4124bff4d36b5e11d84e.mp4", "adv_score": 0.0, "adv_xclip": 0.1867188811302185, "adv_vbench": {"subject_consistency": 0.9618448317050934, "background_consistency": 0.9681193033854166, "motion_smoothness": 0.9827676517237554, "aesthetic_quality": 0.5755707025527954, "imaging_quality": 0.6780635530121473, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/ec1d54ec.mp4", "clean_score": 1.0, "clean_xclip": 0.15289306640625, "clean_vbench": {}, "adv_vid_id": "vids/5da01608.mp4", "adv_score": 1.0, "adv_xclip": 0.08356048166751862, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/eadaa186.mp4", "clean_score": 1.0, "clean_xclip": 0.19485121965408325, "clean_vbench": {}, "adv_vid_id": "vids/df336fba.mp4", "adv_score": 1.0, "adv_xclip": 0.15334387123584747, "adv_vbench": {}}}}
{"id": "f17283a1fb714aaaa73759740897c9c1", "source": "vatex", "video_id": "tTMD0YpVIpg_000118_000128", "video_description": "A woman is preparing and applying a homemade face scrub or mask to her face.", "task": "AttributeRecognition", "clean_prompt": "A woman applying a natural face scrub to her face.", "clean_property": {"obj": "face scrub", "attribute": "natural"}, "target_prompt": "A woman applying a chemical face scrub to her face.", "target_property": {"obj": "face scrub", "attribute": "chemical"}, "evaluation_question": "Is the face scrub **natural**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman applying a natural face scrub to her face.jpg Deutsche scrub clinique dermatolog", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95cdd763f41048d3b87db2b85da720cc.mp4", "clean_score": 1.0, "clean_xclip": 0.22591018676757812, "clean_vbench": {"subject_consistency": 0.9643411990255117, "background_consistency": 0.9718017578125, "motion_smoothness": 0.9734940722270133, "aesthetic_quality": 0.4578331410884857, "imaging_quality": 0.6504320339280731, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6fb9fa23c2084ffd90a2cd0322533d1b.mp4", "adv_score": 0.0, "adv_xclip": 0.213751882314682, "adv_vbench": {"subject_consistency": 0.9396330819775661, "background_consistency": 0.9658304850260416, "motion_smoothness": 0.9756384236564997, "aesthetic_quality": 0.4639754593372345, "imaging_quality": 0.6457609526965084, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1936c845.mp4", "clean_score": 1.0, "clean_xclip": 0.2305176854133606, "clean_vbench": {}, "adv_vid_id": "vids/1a745390.mp4", "adv_score": 1.0, "adv_xclip": 0.22872796654701233, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/190c36ef.mp4", "clean_score": 1.0, "clean_xclip": 0.2371823489665985, "clean_vbench": {}, "adv_vid_id": "vids/2d3544b7.mp4", "adv_score": 0.0, "adv_xclip": 0.2047281265258789, "adv_vbench": {}}}}
{"id": "04002a386a8e4c76b95b6bcbd4c2e206", "source": "vatex", "video_id": "WFHuy4Cv5qY_000116_000126", "video_description": "A woman is in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "task": "Counting", "clean_prompt": "Five women in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "A woman in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Five women in a kitchen demonstrating how to cook scrambled eggs and place them on toast. Ofert ilustrtigeAFP Vector", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/583ea32a48b24f5688d88a4db13f2b7e.mp4", "clean_score": 1.0, "clean_xclip": 0.2641748785972595, "clean_vbench": {"subject_consistency": 0.9696921321252981, "background_consistency": 0.96624755859375, "motion_smoothness": 0.9839327315256092, "aesthetic_quality": 0.5520374774932861, "imaging_quality": 0.7504086474983059, "dynamic_degree": 0.0}, "adv_vid_id": "vids/635248fbd4f04b068f798408ab25eeba.mp4", "adv_score": 0.0, "adv_xclip": 0.20431697368621826, "adv_vbench": {"subject_consistency": 0.9906678174932798, "background_consistency": 0.9877980550130209, "motion_smoothness": 0.9960166568009663, "aesthetic_quality": 0.5708708763122559, "imaging_quality": 0.7306938685203085, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/940a92bf.mp4", "clean_score": 0.0, "clean_xclip": 0.20912691950798035, "clean_vbench": {}, "adv_vid_id": "vids/02bc6b82.mp4", "adv_score": 0.0, "adv_xclip": 0.19496217370033264, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/54f17125.mp4", "clean_score": 1.0, "clean_xclip": 0.23028986155986786, "clean_vbench": {}, "adv_vid_id": "vids/69f07c87.mp4", "adv_score": 1.0, "adv_xclip": 0.22428223490715027, "adv_vbench": {}}}}
{"id": "4b7c9358caeb403bb2befac965a8e8ca", "source": "vatex", "video_id": "M5Iv3vnl2Ys_000022_000032", "video_description": "A man in a red pullover and khaki pants is on a windy golf course, demonstrating how to hit a golf ball with a club.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a golf club on a windy golf course.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "golf club"}, "target_prompt": "A man closer to the camera than a golf club on a windy golf course.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "golf club"}, "evaluation_question": "Is the man **farther from the camera than** the golf club?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man farther from the camera than a golf club on a windy golf course. Unterkunft coursetzen colorful panoramic", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e3bb8e1e09f463d9ee51c0c8c5bb806.mp4", "clean_score": 1.0, "clean_xclip": 0.13554635643959045, "clean_vbench": {"subject_consistency": 0.9089191369712353, "background_consistency": 0.9435475667317709, "motion_smoothness": 0.9929780984603204, "aesthetic_quality": 0.5176742076873779, "imaging_quality": 0.5134012276785714, "dynamic_degree": 0.0}, "adv_vid_id": "vids/334f4d6b7dd44c118d8c071abf7530d0.mp4", "adv_score": 0.0, "adv_xclip": 0.10703188925981522, "adv_vbench": {"subject_consistency": 0.9352980771412452, "background_consistency": 0.9637044270833334, "motion_smoothness": 0.9962260734701546, "aesthetic_quality": 0.496741384267807, "imaging_quality": 0.7169526547801738, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/b5002347.mp4", "clean_score": 0.0, "clean_xclip": 0.11501648277044296, "clean_vbench": {}, "adv_vid_id": "vids/5a10cdb3.mp4", "adv_score": 0.0, "adv_xclip": 0.11935427784919739, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7f4ee3f9.mp4", "clean_score": 0.0, "clean_xclip": 0.15280503034591675, "clean_vbench": {}, "adv_vid_id": "vids/109fd3f1.mp4", "adv_score": 0.0, "adv_xclip": 0.09227293729782104, "adv_vbench": {}}}}
{"id": "c2f33008ffc54aea8ea6f2ec00ab0afa", "source": "vatex", "video_id": "hmRfB4ubBZM_000000_000010", "video_description": "A man uses a power drill to make a hole in a coconut and inserts a straw for drinking.", "task": "Counting", "clean_prompt": "Three people using power drills to make holes in coconuts and inserting straws for drinking.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person using a power drill to make a hole in a coconut and inserting a straw for drinking.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people using power drills in the video?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three people using power drills to make holes in coconuts and inserting straws for drinking. animeaufnahme sleekkontakt Darstellung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a42b3e3902fe4fa2a61b231f55afc295.mp4", "clean_score": 1.0, "clean_xclip": 0.26758894324302673, "clean_vbench": {"subject_consistency": 0.9788000080734491, "background_consistency": 0.9505971272786459, "motion_smoothness": 0.9714284836008735, "aesthetic_quality": 0.5991400480270386, "imaging_quality": 0.7306308886469627, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fc44e1cdb42349919e4d42efcd655333.mp4", "adv_score": 0.0, "adv_xclip": 0.17693234980106354, "adv_vbench": {"subject_consistency": 0.9882978647947311, "background_consistency": 0.9580485026041666, "motion_smoothness": 0.9907639109527556, "aesthetic_quality": 0.5281070470809937, "imaging_quality": 0.7607521851208745, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/7f1b679c.mp4", "clean_score": 0.0, "clean_xclip": 0.2252701222896576, "clean_vbench": {}, "adv_vid_id": "vids/6c4f7c3d.mp4", "adv_score": 0.0, "adv_xclip": 0.25349560379981995, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/dcee6b1d.mp4", "clean_score": 0.0, "clean_xclip": 0.2829423248767853, "clean_vbench": {}, "adv_vid_id": "vids/11e89e93.mp4", "adv_score": 1.0, "adv_xclip": 0.29299023747444153, "adv_vbench": {}}}}
{"id": "f335df7c5ea94fa4ac6901327536fa4a", "source": "vatex", "video_id": "HcfF0yaE2gk_000044_000054", "video_description": "A person is holding a knife menacingly.", "task": "AttributeRecognition", "clean_prompt": "A person holding a mini marshmallow with a knife menacingly.", "clean_property": {"obj": "marshmallow", "attribute": "mini"}, "target_prompt": "A person holding a giant marshmallow with a knife menacingly.", "target_property": {"obj": "marshmallow", "attribute": "giant"}, "evaluation_question": "Is the marshmallow **mini**?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A person holding a mini marshmallow with a knife menacingly. ):(!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/06dcbb4313c04e0f89bfb93013c6f713.mp4", "clean_score": 1.0, "clean_xclip": 0.17796412110328674, "clean_vbench": {"subject_consistency": 0.8683243747800589, "background_consistency": 0.9322001139322916, "motion_smoothness": 0.9776583572568688, "aesthetic_quality": 0.4773252606391907, "imaging_quality": 0.6283238765171596, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ba58377f4c804a80861a86c4a7d61530.mp4", "adv_score": 0.0, "adv_xclip": 0.2409469187259674, "adv_vbench": {"subject_consistency": 0.9755121332903703, "background_consistency": 0.9704945882161459, "motion_smoothness": 0.9844866691693396, "aesthetic_quality": 0.5409344434738159, "imaging_quality": 0.38027440908003823, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5e95d267.mp4", "clean_score": 1.0, "clean_xclip": 0.233941450715065, "clean_vbench": {}, "adv_vid_id": "vids/99725b9b.mp4", "adv_score": 0.0, "adv_xclip": 0.26420503854751587, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fb218064.mp4", "clean_score": 1.0, "clean_xclip": 0.222951740026474, "clean_vbench": {}, "adv_vid_id": "vids/e8b04d25.mp4", "adv_score": 1.0, "adv_xclip": 0.25805556774139404, "adv_vbench": {}}}}
{"id": "ca5d50f8c8a74a749155665163a7b3b9", "source": "vatex", "video_id": "h1Ftl9t0rhA_000006_000016", "video_description": "A man is demonstrating how to tie a knot using a string and a silver ring, which is hanging from another string.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to tie a knot using a string and a silver ring.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to tie a knot using a string and a silver ring.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A man demonstrating how to tie a knot using a string and a silver ring. Vector ADHDlamptouteskleidung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3bdefddc73824e5baeaf2ad42cf5e92f.mp4", "clean_score": 1.0, "clean_xclip": 0.22255930304527283, "clean_vbench": {"subject_consistency": 0.8518482701232036, "background_consistency": 0.9405568440755209, "motion_smoothness": 0.9285669215988865, "aesthetic_quality": 0.36214229464530945, "imaging_quality": 0.5432429706807039, "dynamic_degree": 1.0}, "adv_vid_id": "vids/fd63f974665546a5adf9fa19b6466c35.mp4", "adv_score": 0.0, "adv_xclip": 0.20469406247138977, "adv_vbench": {"subject_consistency": 0.8575601577758789, "background_consistency": 0.93701171875, "motion_smoothness": 0.9503567397863208, "aesthetic_quality": 0.38380616903305054, "imaging_quality": 0.5431900460379464, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/cc64c410.mp4", "clean_score": 1.0, "clean_xclip": 0.24053031206130981, "clean_vbench": {}, "adv_vid_id": "vids/d3734163.mp4", "adv_score": 1.0, "adv_xclip": 0.19433122873306274, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6f7361d1.mp4", "clean_score": 1.0, "clean_xclip": 0.2334417700767517, "clean_vbench": {}, "adv_vid_id": "vids/d7aa55d9.mp4", "adv_score": 0.0, "adv_xclip": 0.22128558158874512, "adv_vbench": {}}}}
{"id": "0a00de4bdfb04d058b86010328a7dd14", "source": "vatex", "video_id": "V77pj1em6yI_000087_000097", "video_description": "A woman and a child are playing kickball in a backyard, passing the ball back and forth.", "task": "ActionRecognition", "clean_prompt": "A woman playing kickball in a backyard.", "clean_property": {"obj": "woman", "action": "playing kickball", "target": "ball"}, "target_prompt": "A woman kicking a ball towards a goal in a backyard.", "target_property": {"obj": "woman", "action": "kicking a ball", "target": "goal"}, "evaluation_question": "Is the woman **playing kickball**?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A woman playing kickball in a backyard. Vier Gazageschaltet Angriffziert", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38ca4bb2ebbc452ca4e460bfde61666e.mp4", "clean_score": 1.0, "clean_xclip": 0.15521740913391113, "clean_vbench": {"subject_consistency": 0.8835564473023018, "background_consistency": 0.9031728108723959, "motion_smoothness": 0.9599071959094853, "aesthetic_quality": 0.47513633966445923, "imaging_quality": 0.5382608273564553, "dynamic_degree": 1.0}, "adv_vid_id": "vids/1104ae73305740a7b0e00a9d88c4fef7.mp4", "adv_score": 0.0, "adv_xclip": 0.14629577100276947, "adv_vbench": {"subject_consistency": 0.8663642716904482, "background_consistency": 0.9186503092447916, "motion_smoothness": 0.9415255116610688, "aesthetic_quality": 0.4303538501262665, "imaging_quality": 0.5521182827073701, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/5030abda.mp4", "clean_score": 1.0, "clean_xclip": 0.17829234898090363, "clean_vbench": {}, "adv_vid_id": "vids/50f3ebed.mp4", "adv_score": 1.0, "adv_xclip": 0.1434096395969391, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/531fac33.mp4", "clean_score": 0.0, "clean_xclip": 0.21609872579574585, "clean_vbench": {}, "adv_vid_id": "vids/8fc15e9e.mp4", "adv_score": 0.0, "adv_xclip": 0.2341032326221466, "adv_vbench": {}}}}
{"id": "18217ea153464698bc6b431be8732f27", "source": "vatex", "video_id": "SCSSnsCBeDQ_000040_000050", "video_description": "A busy Middle-Eastern market with people in traditional attire buying and selling goods like figs and dates.", "task": "Counting", "clean_prompt": "Two people in traditional attire are buying figs and dates in a busy Middle-Eastern market.", "clean_property": {"obj": "goods", "count": "two"}, "target_prompt": "Two people in traditional attire are buying five different types of goods in a busy Middle-Eastern market.", "target_property": {"obj": "goods", "count": "five"}, "evaluation_question": "Are there exactly **two** goods being bought in the market?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "Two people in traditional attire are buying figs and dates in a busy Middle-Eastern market. TS@)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/402980814fed4e90bdacbe0a2a6f5d2e.mp4", "clean_score": 1.0, "clean_xclip": 0.13205213844776154, "clean_vbench": {"subject_consistency": 0.9739571486910185, "background_consistency": 0.96710205078125, "motion_smoothness": 0.9781083049024651, "aesthetic_quality": 0.698976993560791, "imaging_quality": 0.7471345722432039, "dynamic_degree": 1.0}, "adv_vid_id": "vids/ffcda7e11e9f44faab78304310657f65.mp4", "adv_score": 0.0, "adv_xclip": 0.16575086116790771, "adv_vbench": {"subject_consistency": 0.9720990030715863, "background_consistency": 0.9739583333333334, "motion_smoothness": 0.9791237217141229, "aesthetic_quality": 0.6762166023254395, "imaging_quality": 0.7732283129010882, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/e3129e62.mp4", "clean_score": 1.0, "clean_xclip": 0.20612883567810059, "clean_vbench": {}, "adv_vid_id": "vids/ddbf0805.mp4", "adv_score": 1.0, "adv_xclip": 0.18847572803497314, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/f1507ba1.mp4", "clean_score": 1.0, "clean_xclip": 0.2138923555612564, "clean_vbench": {}, "adv_vid_id": "vids/ab018376.mp4", "adv_score": 1.0, "adv_xclip": 0.22062720358371735, "adv_vbench": {}}}}
{"id": "970789941b7b43fbb5782cff3cd2aa4f", "source": "vatex", "video_id": "IyhDBSyWCYw_000013_000023", "video_description": "A man opens a door and steps outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. The scene transitions from a dark room to a beautiful outdoor setting with music playing.", "task": "ActionRecognition", "clean_prompt": "A man opening a door and stepping outside into a dream-like landscape with green fields, snowy mountains, and changing leaves.", "clean_property": {"obj": "man", "action": "opening door", "target": null}, "target_prompt": "A man closing a door and stepping back into a dark room.", "target_property": {"obj": "man", "action": "closing door", "target": null}, "evaluation_question": "Is the man **opening** a door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man opening a door and stepping outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. @JSL\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dadb5179565647e084aa7794421e9e45.mp4", "clean_score": 1.0, "clean_xclip": 0.18703593313694, "clean_vbench": {"subject_consistency": 0.9359557144343853, "background_consistency": 0.9642333984375, "motion_smoothness": 0.9924066876525559, "aesthetic_quality": 0.5230466723442078, "imaging_quality": 0.6782533505498146, "dynamic_degree": 0.0}, "adv_vid_id": "vids/f73a4ccf9dd24256b91ca1bd9ec37476.mp4", "adv_score": 0.0, "adv_xclip": 0.26110631227493286, "adv_vbench": {"subject_consistency": 0.983003418892622, "background_consistency": 0.992584228515625, "motion_smoothness": 0.9968554707987876, "aesthetic_quality": 0.43218502402305603, "imaging_quality": 0.6557765859487106, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f629cb85.mp4", "clean_score": 0.0, "clean_xclip": 0.18491911888122559, "clean_vbench": {}, "adv_vid_id": "vids/a2df64fa.mp4", "adv_score": 0.0, "adv_xclip": 0.26028701663017273, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/fd652878.mp4", "clean_score": 0.0, "clean_xclip": 0.25000375509262085, "clean_vbench": {}, "adv_vid_id": "vids/b40409c8.mp4", "adv_score": 0.0, "adv_xclip": 0.2377510368824005, "adv_vbench": {}}}}
{"id": "4f22c41a55134235a6aa461e0de1b2f4", "source": "vatex", "video_id": "4jznikNJSG0_000005_000015", "video_description": "A person is creating artwork by carving and burning images and text into a small circular piece of wood using a heat gun.", "task": "SpatialUnderstanding", "clean_prompt": "A piece of wood that is farther from the camera than a heat gun.", "clean_property": {"obj_1": "wood", "relation": "farther from the camera than", "obj_2": "heat gun"}, "target_prompt": "A piece of wood that is closer to the camera than a heat gun.", "target_property": {"obj_1": "wood", "relation": "closer to the camera than", "obj_2": "heat gun"}, "evaluation_question": "Is the piece of wood **farther from the camera than** the heat gun?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A piece of wood that is farther from the camera than a heat gun. ;E&UF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfcde8c0e7cd496d973b5b56bf4875e0.mp4", "clean_score": 1.0, "clean_xclip": 0.19949139654636383, "clean_vbench": {"subject_consistency": 0.9257247932255268, "background_consistency": 0.9652506510416666, "motion_smoothness": 0.9963251071358328, "aesthetic_quality": 0.3894484043121338, "imaging_quality": 0.6110856301443918, "dynamic_degree": 0.0}, "adv_vid_id": "vids/c83b07b600914548aee29d5fbc22292c.mp4", "adv_score": 0.0, "adv_xclip": 0.1842046082019806, "adv_vbench": {"subject_consistency": 0.9383945909018317, "background_consistency": 0.9787699381510416, "motion_smoothness": 0.9963969319562959, "aesthetic_quality": 0.4180692434310913, "imaging_quality": 0.6508722998171436, "dynamic_degree": 0.0}}, "VideoCrafter2": {"clean_vid_id": "vids/1f64767b.mp4", "clean_score": 0.0, "clean_xclip": 0.18138417601585388, "clean_vbench": {}, "adv_vid_id": "vids/f2cc0177.mp4", "adv_score": 0.0, "adv_xclip": 0.2006721794605255, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/44c75999.mp4", "clean_score": 0.0, "clean_xclip": 0.14037179946899414, "clean_vbench": {}, "adv_vid_id": "vids/0fe63c60.mp4", "adv_score": 0.0, "adv_xclip": 0.20901845395565033, "adv_vbench": {}}}}
{"id": "e5fda64a8804466ca214138dde801198", "source": "vatex", "video_id": "AbL-AXmlmmM_000008_000018", "video_description": "A young boy is driving and steering a riding lawnmower with an older man sitting behind him, guiding and teaching him in a grassy field.", "task": "Counting", "clean_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field, with four boys playing nearby.", "clean_property": {"obj": "boy", "count": "four"}, "target_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **four** boys playing nearby?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field, with four boys playing nearby. terrasse frunze  Notre profesionale", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b79f93481ffa488d86ef37ca43f5ff2c.mp4", "clean_score": 1.0, "clean_xclip": 0.22849175333976746, "clean_vbench": {"subject_consistency": 0.9398459096749624, "background_consistency": 0.9287261962890625, "motion_smoothness": 0.9802676052320362, "aesthetic_quality": 0.682537317276001, "imaging_quality": 0.7462927479646644, "dynamic_degree": 1.0}, "adv_vid_id": "vids/acfb7d8d0bc142c4bfe01c227966ecf1.mp4", "adv_score": 0.0, "adv_xclip": 0.2241947203874588, "adv_vbench": {"subject_consistency": 0.9337436792751154, "background_consistency": 0.90869140625, "motion_smoothness": 0.9803979016632373, "aesthetic_quality": 0.5587689280509949, "imaging_quality": 0.6551110972190389, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/541dacfd.mp4", "clean_score": 0.0, "clean_xclip": 0.2321493923664093, "clean_vbench": {}, "adv_vid_id": "vids/98f8df27.mp4", "adv_score": 1.0, "adv_xclip": 0.2420661300420761, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/d4ca0c66.mp4", "clean_score": 0.0, "clean_xclip": 0.21643149852752686, "clean_vbench": {}, "adv_vid_id": "vids/f57eb505.mp4", "adv_score": 1.0, "adv_xclip": 0.24199551343917847, "adv_vbench": {}}}}
{"id": "c140fa0a1cfe4e9ba6d3603daa889cb2", "source": "vatex", "video_id": "g-161r3ibds_000266_000276", "video_description": "A man is having his leg hair waxed by a woman using wax strips. The man is sitting with his leg extended on a table while the woman applies and removes the wax strips, showing them to the camera.", "task": "ObjectRecognition", "clean_prompt": "A man is sitting on a chair while a woman waxes his leg hair.", "clean_property": {"obj": "chair"}, "target_prompt": "A man is sitting on a sofa while a woman waxes his leg hair.", "target_property": {"obj": "sofa"}, "evaluation_question": "Is the man sitting on a **chair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on a chair while a woman waxes his leg hair. ))!',", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6db6167336c44b9a0c648ad5daf9e15.mp4", "clean_score": 1.0, "clean_xclip": 0.19465920329093933, "clean_vbench": {"subject_consistency": 0.961457584053278, "background_consistency": 0.9671732584635416, "motion_smoothness": 0.9854315304632656, "aesthetic_quality": 0.5466734766960144, "imaging_quality": 0.74235978418467, "dynamic_degree": 1.0}, "adv_vid_id": "vids/a13e47813894416eb912852ceac5a9c2.mp4", "adv_score": 0.0, "adv_xclip": 0.18003468215465546, "adv_vbench": {"subject_consistency": 0.9697520956397057, "background_consistency": 0.9717356363932291, "motion_smoothness": 0.9849938459147805, "aesthetic_quality": 0.5028679370880127, "imaging_quality": 0.7611845117685746, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/dd088413.mp4", "clean_score": 1.0, "clean_xclip": 0.17543071508407593, "clean_vbench": {}, "adv_vid_id": "vids/257908da.mp4", "adv_score": 1.0, "adv_xclip": 0.10992074757814407, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/673bf307.mp4", "clean_score": 1.0, "clean_xclip": 0.18371812999248505, "clean_vbench": {}, "adv_vid_id": "vids/e0c9a3a5.mp4", "adv_score": 1.0, "adv_xclip": 0.20764614641666412, "adv_vbench": {}}}}
{"id": "4708cae904184d1d8d7d1cad4f9875e5", "source": "vatex", "video_id": "tXtLASDaPrY_000026_000036", "video_description": "Two young children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room.", "task": "Counting", "clean_prompt": "Three children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child is playing and riding on a toy vehicle in a living room.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children playing in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room. RGBionengouttebmw brillant", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f9c388f3b1d4379a51575a00e997c86.mp4", "clean_score": 1.0, "clean_xclip": 0.22287127375602722, "clean_vbench": {"subject_consistency": 0.9502090166012446, "background_consistency": 0.9456685384114584, "motion_smoothness": 0.96325264167524, "aesthetic_quality": 0.5554254651069641, "imaging_quality": 0.6549308667864118, "dynamic_degree": 1.0}, "adv_vid_id": "vids/583195a6dd2a43bd86f6fcad3fba3543.mp4", "adv_score": 0.0, "adv_xclip": 0.21642684936523438, "adv_vbench": {"subject_consistency": 0.9332718489070734, "background_consistency": 0.94549560546875, "motion_smoothness": 0.9701485973054346, "aesthetic_quality": 0.5392025113105774, "imaging_quality": 0.7079044427677077, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/9826baba.mp4", "clean_score": 1.0, "clean_xclip": 0.22072601318359375, "clean_vbench": {}, "adv_vid_id": "vids/76b2321f.mp4", "adv_score": 0.0, "adv_xclip": 0.18937115371227264, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/41071dcd.mp4", "clean_score": 0.0, "clean_xclip": 0.2150879204273224, "clean_vbench": {}, "adv_vid_id": "vids/5a9d4880.mp4", "adv_score": 1.0, "adv_xclip": 0.1943534016609192, "adv_vbench": {}}}}
{"id": "e0e5c8d717064c80a4384164832221ea", "source": "vatex", "video_id": "PetC18IbTtQ_000155_000165", "video_description": "A choir of African American men and women sing gospel songs enthusiastically in a church, led by a pastor. They sway, clap, and sing hymns during a service.", "task": "SpatialUnderstanding", "clean_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically.", "clean_property": {"obj_1": "choir", "relation": "left of", "obj_2": "pastor"}, "target_prompt": "A choir to the right of a pastor in a church, singing gospel songs enthusiastically.", "target_property": {"obj_1": "choir", "relation": "right of", "obj_2": "pastor"}, "evaluation_question": "Is the choir to the **left** of the pastor?", "surrogate_model": "CogVideoX-2b", "attack": "genetic", "adversarial_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically. X\\7^V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/feb6d3686cf0446caf5535a14ec69140.mp4", "clean_score": 1.0, "clean_xclip": 0.16354867815971375, "clean_vbench": {"subject_consistency": 0.9447596607108911, "background_consistency": 0.9476064046223959, "motion_smoothness": 0.961755214164498, "aesthetic_quality": 0.52422034740448, "imaging_quality": 0.4576585754083128, "dynamic_degree": 1.0}, "adv_vid_id": "vids/632dc7ba46844f4d82377428d37fe445.mp4", "adv_score": 0.0, "adv_xclip": 0.19764244556427002, "adv_vbench": {"subject_consistency": 0.9324921822796265, "background_consistency": 0.9417724609375, "motion_smoothness": 0.9599266061234164, "aesthetic_quality": 0.5877534747123718, "imaging_quality": 0.5085971956836934, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/6824f45a.mp4", "clean_score": 0.0, "clean_xclip": 0.17727819085121155, "clean_vbench": {}, "adv_vid_id": "vids/6d65d186.mp4", "adv_score": 0.0, "adv_xclip": 0.1912691593170166, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2a2ac374.mp4", "clean_score": 1.0, "clean_xclip": 0.20396482944488525, "clean_vbench": {}, "adv_vid_id": "vids/93f2478f.mp4", "adv_score": 1.0, "adv_xclip": 0.2023315131664276, "adv_vbench": {}}}}
{"id": "ab21a2cfd6c8403a9cdbf02f78751711", "source": "vatex", "video_id": "JJWu9ybc_fs_000001_000011", "video_description": "Two boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "task": "Counting", "clean_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "clean_property": {"obj": "boy", "count": "three"}, "target_prompt": "One boy is playing in a snowy field, making a snowman using a tool.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **three** boys playing in the snowy field?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman. Photoshopstuhl ochikonzept ilustr", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d6a512e0d1a4c3c949cbff7894f647c.mp4", "clean_score": 1.0, "clean_xclip": 0.2245214581489563, "clean_vbench": {"subject_consistency": 0.9344577429195245, "background_consistency": 0.95867919921875, "motion_smoothness": 0.9793368916046358, "aesthetic_quality": 0.7090281844139099, "imaging_quality": 0.6735292380196708, "dynamic_degree": 1.0}, "adv_vid_id": "vids/16866490f7764f778d5defc02d936c95.mp4", "adv_score": 0.0, "adv_xclip": 0.2182459533214569, "adv_vbench": {"subject_consistency": 0.9516876433044672, "background_consistency": 0.9694569905598959, "motion_smoothness": 0.9737926669478233, "aesthetic_quality": 0.6833341717720032, "imaging_quality": 0.5901549849218252, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/d7091969.mp4", "clean_score": 0.0, "clean_xclip": 0.2084766924381256, "clean_vbench": {}, "adv_vid_id": "vids/17c6a5f9.mp4", "adv_score": 0.0, "adv_xclip": 0.2102603316307068, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/2ece1908.mp4", "clean_score": 0.0, "clean_xclip": 0.22426798939704895, "clean_vbench": {}, "adv_vid_id": "vids/09773f4d.mp4", "adv_score": 1.0, "adv_xclip": 0.21539738774299622, "adv_vbench": {}}}}
{"id": "37cab47ce4fa48beb408ece97b758769", "source": "vatex", "video_id": "1XhixsI46yE_000003_000013", "video_description": "A man in blue shorts is in a room bending a metal bar around his legs while being instructed.", "task": "ObjectRecognition", "clean_prompt": "A man in blue shorts is bending a metal bar around his legs in a room.", "clean_property": {"obj": "metal bar"}, "target_prompt": "A man in blue shorts is bending a wooden stick around his legs in a room.", "target_property": {"obj": "wooden stick"}, "evaluation_question": "Is the object being bent in the video a **metal bar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in blue shorts is bending a metal bar around his legs in a room. $FET$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/44534bf6ecd246c1a9ee8bf33fbbfbc0.mp4", "clean_score": 1.0, "clean_xclip": 0.13247042894363403, "clean_vbench": {"subject_consistency": 0.9524089551220337, "background_consistency": 0.963409423828125, "motion_smoothness": 0.9783717284013657, "aesthetic_quality": 0.3977873623371124, "imaging_quality": 0.5776549234195631, "dynamic_degree": 1.0}, "adv_vid_id": "vids/6c5c13a13b844b76a42898f04991d5a9.mp4", "adv_score": 0.0, "adv_xclip": 0.16725671291351318, "adv_vbench": {"subject_consistency": 0.9574292736748854, "background_consistency": 0.9537200927734375, "motion_smoothness": 0.9787443401453946, "aesthetic_quality": 0.41922861337661743, "imaging_quality": 0.5969798232098015, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/dc444b2f.mp4", "clean_score": 1.0, "clean_xclip": 0.11663687229156494, "clean_vbench": {}, "adv_vid_id": "vids/1d04bb8b.mp4", "adv_score": 1.0, "adv_xclip": 0.18419799208641052, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/5d656642.mp4", "clean_score": 0.0, "clean_xclip": 0.1570967137813568, "clean_vbench": {}, "adv_vid_id": "vids/d83a6d69.mp4", "adv_score": 1.0, "adv_xclip": 0.10871666669845581, "adv_vbench": {}}}}
{"id": "20cc9899c11640abbaf79c3073325f38", "source": "vatex", "video_id": "e5qBwONhahU_000000_000010", "video_description": "A young man is riding a skateboard down a city sidewalk. Another young man appears and looks at the camera.", "task": "Counting", "clean_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background.", "clean_property": {"obj": "branch", "count": "three"}, "target_prompt": "A young man is riding a skateboard down a city sidewalk with one branch in the background.", "target_property": {"obj": "branch", "count": "one"}, "evaluation_question": "Are there exactly **three** branches in the background?", "surrogate_model": "CogVideoX-2b", "attack": "gcg", "adversarial_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background. encore copilMostly acasa Ausstattung", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6c40e307cf8e4e32afe68ca9555fc255.mp4", "clean_score": 1.0, "clean_xclip": 0.18404442071914673, "clean_vbench": {"subject_consistency": 0.9357319722572962, "background_consistency": 0.9502512613932291, "motion_smoothness": 0.979954524952342, "aesthetic_quality": 0.47712981700897217, "imaging_quality": 0.5787853054124482, "dynamic_degree": 1.0}, "adv_vid_id": "vids/8eadaa8095bb4682a0b59a63454a0e66.mp4", "adv_score": 0.0, "adv_xclip": 0.20769374072551727, "adv_vbench": {"subject_consistency": 0.9603759149710337, "background_consistency": 0.9485626220703125, "motion_smoothness": 0.9921351438627148, "aesthetic_quality": 0.5056625604629517, "imaging_quality": 0.6435389156730809, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/f74e4be8.mp4", "clean_score": 0.0, "clean_xclip": 0.15689533948898315, "clean_vbench": {}, "adv_vid_id": "vids/314403bc.mp4", "adv_score": 0.0, "adv_xclip": 0.17098882794380188, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/6dc7f53a.mp4", "clean_score": 0.0, "clean_xclip": 0.15918216109275818, "clean_vbench": {}, "adv_vid_id": "vids/0cb16ff9.mp4", "adv_score": 0.0, "adv_xclip": 0.16343778371810913, "adv_vbench": {}}}}
{"id": "efaeec9324ff432c812bbf272e93683b", "source": "vatex", "video_id": "e5qBwONhahU_000000_000010", "video_description": "A young man is riding a skateboard down a city sidewalk. Another young man appears and looks at the camera.", "task": "Counting", "clean_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background.", "clean_property": {"obj": "branch", "count": "three"}, "target_prompt": "A young man is riding a skateboard down a city sidewalk with one branch in the background.", "target_property": {"obj": "branch", "count": "one"}, "evaluation_question": "Are there exactly **three** branches in the background?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background. M9L*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dcc50f6b61841acbc043f2c1c753305.mp4", "clean_score": 1.0, "clean_xclip": 0.18404442071914673, "clean_vbench": {"subject_consistency": 0.9357319722572962, "background_consistency": 0.9502512613932291, "motion_smoothness": 0.979954524952342, "aesthetic_quality": 0.47712981700897217, "imaging_quality": 0.5787853054124482, "dynamic_degree": 1.0}, "adv_vid_id": "vids/9013481f67774e8fbed7da323dca03c4.mp4", "adv_score": 0.0, "adv_xclip": 0.18893136084079742, "adv_vbench": {"subject_consistency": 0.9479311481118202, "background_consistency": 0.9221547444661459, "motion_smoothness": 0.9834061329039074, "aesthetic_quality": 0.5576907992362976, "imaging_quality": 0.5321489871278101, "dynamic_degree": 1.0}}, "VideoCrafter2": {"clean_vid_id": "vids/86b48ba0.mp4", "clean_score": 0.0, "clean_xclip": 0.16489645838737488, "clean_vbench": {}, "adv_vid_id": "vids/49f7625f.mp4", "adv_score": 0.0, "adv_xclip": 0.17054888606071472, "adv_vbench": {}}, "Vchitect2": {"clean_vid_id": "vids/7864566d.mp4", "clean_score": 0.0, "clean_xclip": 0.15713483095169067, "clean_vbench": {}, "adv_vid_id": "vids/f02d920a.mp4", "adv_score": 0.0, "adv_xclip": 0.15495425462722778, "adv_vbench": {}}}}
