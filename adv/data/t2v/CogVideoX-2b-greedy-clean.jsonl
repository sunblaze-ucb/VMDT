{"id": "2c32fc3f8aa34515b8b65ae121b7856b", "source": "vatex", "video_id": "pzmHPAP11qs_000037_000047", "video_description": "A person is spray painting graffiti on a street wall using silver, black, and white paint.", "task": "Counting", "clean_prompt": "Six people spray painting graffiti on a street wall using silver, black, and white paint.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Three people spray painting graffiti on a street wall using vibrant colors.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **six** people spray painting on the wall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people spray painting graffiti on a street wall using silver, black, and white paint. LY#1M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/318a20535ff9418bba58cd1daaaf9666.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "958b02db8e7a462194d7a3289b4cee71", "source": "vatex", "video_id": "kbfio_dNFEc_000032_000042", "video_description": "A person is on the roof of a house using a high-pressure water jet to clean debris from the gutters.", "task": "ActionRecognition", "clean_prompt": "A person cleaning gutters on the roof of a house using a high-pressure water jet.", "clean_property": {"obj": "person", "action": "cleaning gutters", "target": null}, "target_prompt": "A person relaxing on the roof of a house.", "target_property": {"obj": "person", "action": "relaxing", "target": null}, "evaluation_question": "Is the person **cleaning gutters**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning gutters on the roof of a house using a high-pressure water jet. BMEMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b8e94153a584a058e2268ca6a99081f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2f373349fe64c10b6802a5cbd8cd6ac", "source": "vatex", "video_id": "sAtugMHcHE0_000000_000010", "video_description": "Two young boys are playing and demonstrating how to sharpen a pencil using a nose-shaped pencil sharpener inside a room.", "task": "AttributeRecognition", "clean_prompt": "Two young boys are playing and demonstrating how to sharpen a pencil using a nose-shaped pencil sharpener inside a room.", "clean_property": {"obj": "nose sharpener", "attribute": "nose-shaped"}, "target_prompt": "Two young boys are playing and demonstrating how to sharpen a pencil using a star-shaped pencil sharpener inside a room.", "target_property": {"obj": "nose sharpener", "attribute": "star-shaped"}, "evaluation_question": "Is the pencil sharpener **nose-shaped**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys are playing and demonstrating how to sharpen a pencil using a nose-shaped pencil sharpener inside a room. 4%JS\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40bd56dfd6ce460c9fbf4940a5eeb44e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "022f89b810bc4f72a8595b26f69cc300", "source": "vatex", "video_id": "o-MhYRW1Stk_000002_000012", "video_description": "A group of blindfolded people are conducting a blind taste test, tasting food with a spoon.", "task": "ActionRecognition", "clean_prompt": "A person tasting food in a blind taste test.", "clean_property": {"obj": "person", "action": "tasting food", "target": "food"}, "target_prompt": "A person spitting out food in a blind taste test.", "target_property": {"obj": "person", "action": "spitting out food", "target": "food"}, "evaluation_question": "Is the person **tasting** food?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tasting food in a blind taste test. FE;Y@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38baf7880e864816b87fe71bf66f2c91.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c7dccc3684f546fcbd7aec56c6acc840", "source": "vatex", "video_id": "_QxCm-caLQE_000025_000035", "video_description": "A person is filling a glass with beer from a tap indoors, creating a large foam head.", "task": "ActionRecognition", "clean_prompt": "A person pouring beer into a glass from a tap indoors.", "clean_property": {"obj": "person", "action": "pouring beer", "target": "glass"}, "target_prompt": "A person spilling beer on the floor indoors.", "target_property": {"obj": "person", "action": "spilling beer", "target": "floor"}, "evaluation_question": "Is the person **pouring beer** into a glass?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person pouring beer into a glass from a tap indoors. '!%|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/23d2f6608bcd4016b4afe20e0dfcda1d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b21eff00b974c778ba6bb6b6a1f3c52", "source": "vatex", "video_id": "_I0jgwU01oY_000067_000077", "video_description": "A man wearing a motorcycle helmet and gloves is welding metal pieces together in a garage.", "task": "SpatialUnderstanding", "clean_prompt": "A welding tool closer to the camera than a person wearing a motorcycle helmet and gloves in a garage.", "clean_property": {"obj_1": "welding tool", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A welding tool further from the camera than a person wearing a motorcycle helmet and gloves in a garage.", "target_property": {"obj_1": "welding tool", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the welding tool **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A welding tool closer to the camera than a person wearing a motorcycle helmet and gloves in a garage. !FE-W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4f78527341664a5a9473aeeb1bafac10.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bbaefe3e389f45639a954c35dd1488c4", "source": "vatex", "video_id": "yb2FMVp6Wzc_000157_000167", "video_description": "A young boy is demonstrating how to make a paper airplane using ruled composition paper, explaining the process as he folds and shows off the finished product.", "task": "ActionRecognition", "clean_prompt": "A boy making paper aeroplanes using ruled composition paper.", "clean_property": {"obj": "boy", "action": "making paper aeroplanes", "target": null}, "target_prompt": "A boy destroying paper aeroplanes using ruled composition paper.", "target_property": {"obj": "boy", "action": "destroying paper aeroplanes", "target": null}, "evaluation_question": "Is the boy **making** paper aeroplanes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy making paper aeroplanes using ruled composition paper. :FEI9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/598965529fa94efa99dc75a80b400e7d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fbe9a2f5d0f943e8a9fa2058d6cdfd25", "source": "vatex", "video_id": "jIBunMqpvcs_000346_000356", "video_description": "A woman and a boy are setting a dining table by placing drinking glasses upside down at each place setting.", "task": "Counting", "clean_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman setting a dining table by placing drinking glasses upside down at each place setting.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women setting the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four women setting a dining table by placing drinking glasses upside down at each place setting. )!0DK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1eba90fc4f644cb29982592b360bf147.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fee27eff645f4fd699776f636cb2625d", "source": "vatex", "video_id": "Be2eKTN05Rs_000003_000013", "video_description": "Several people, including two men, are using ATM machines outside a bank. One man is wearing a gray jacket and another is wearing black. The ATMs are green and silver, and people are taking out money.", "task": "ActionRecognition", "clean_prompt": "A person using an ATM outside a bank.", "clean_property": {"obj": "person", "action": "using atm", "target": null}, "target_prompt": "A person walking away from an ATM outside a bank.", "target_property": {"obj": "person", "action": "walking away from atm", "target": null}, "evaluation_question": "Is the person **using** the ATM?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using an ATM outside a bank. =SN-@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1c3dbe300f74f63beceee2fa3dc3288.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0fe84145964844b0be9a33967d66e97e", "source": "vatex", "video_id": "HCvBleeJxGk_000673_000683", "video_description": "Two women are on a golf course practicing various golf strokes, including chipping and putting, while one woman observes and assists the other.", "task": "Counting", "clean_prompt": "Three women are on a golf course practicing various golf strokes, including chipping and putting, while one woman observes and assists the others.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "One woman is on a golf course practicing various golf strokes, including chipping and putting.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women on the golf course?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women are on a golf course practicing various golf strokes, including chipping and putting, while one woman observes and assists the others. UH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c96ccb2826634d2588d23723f90abdce.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b26128024ea044b5832d818f6eb27bc5", "source": "vatex", "video_id": "hFOsmgjU2X0_000005_000015", "video_description": "In a living room, two young kids, a boy in a yellow shirt and a girl in a tank top, are performing hand and wrist motions, including snapping, cracking, and flicking, while laughing and interacting with each other.", "task": "ObjectRecognition", "clean_prompt": "Two kids in a living room are laughing and performing hand and wrist motions.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a ball of yarn in a living room.", "target_property": {"obj": "cat"}, "evaluation_question": "Are the characters in the video **people**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two kids in a living room are laughing and performing hand and wrist motions. !0O7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d899519770034da68a60a2ed51ffd409.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab803d587ec641708e2a7f7c46c78ab0", "source": "vatex", "video_id": "jDRUFw2seU8_000007_000017", "video_description": "A tattoo artist is applying a colorful flower tattoo to a woman's left foot using an electric tattoo tool.", "task": "AttributeRecognition", "clean_prompt": "A tattoo artist is applying a colorful flower tattoo to a woman's left foot using an electric tattoo tool.", "clean_property": {"obj": "flower tattoo", "attribute": "colorful"}, "target_prompt": "A tattoo artist is applying a black and white flower tattoo to a woman's left foot using an electric tattoo tool.", "target_property": {"obj": "flower tattoo", "attribute": "black and white"}, "evaluation_question": "Is the flower tattoo **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tattoo artist is applying a colorful flower tattoo to a woman's left foot using an electric tattoo tool. EL.(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1bdfff348e342e1878c983ca0c9f546.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "07a2fa3fe73c46fdaa347f6d351be4b8", "source": "vatex", "video_id": "430wrLC8lAs_000234_000244", "video_description": "Two women are in a kitchen demonstrating how to poach eggs. Two eggs are cooking in a frying pan on the stove.", "task": "AttributeRecognition", "clean_prompt": "Two women in a kitchen demonstrating how to poach eggs with a dark frying pan on the stove.", "clean_property": {"obj": "frying pan", "attribute": "dark"}, "target_prompt": "Two women in a kitchen demonstrating how to poach eggs with a bright red frying pan on the stove.", "target_property": {"obj": "frying pan", "attribute": "bright red"}, "evaluation_question": "Is the frying pan **dark** in color?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women in a kitchen demonstrating how to poach eggs with a dark frying pan on the stove. FE7MT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/623fee556e244303b8c46bd88a6014d4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "86a7f260bf0d4a2399906aa69b38fe3a", "source": "vatex", "video_id": "31mjIwvFr7s_000017_000027", "video_description": "A man in a messy room is attempting to demolish a white wall using a sledgehammer, creating holes in the process.", "task": "Counting", "clean_prompt": "Four people in a messy room, watching a man demolish a white wall with a sledgehammer.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a clean room, painting a colorful mural on a wall.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a messy room, watching a man demolish a white wall with a sledgehammer. V+FE1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2e43669a11c9423cb9962848c9c194f2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b4c3b2809c564e5d8880b9f94ed2433e", "source": "vatex", "video_id": "vk7ZsxvcvNo_000024_000034", "video_description": "A young boy is playing soccer in a yard, setting up and kicking a soccer ball into a goal net.", "task": "ActionRecognition", "clean_prompt": "A boy kicking a soccer ball into a goal.", "clean_property": {"obj": "boy", "action": "kicking soccer ball", "target": "goal"}, "target_prompt": "A boy throwing a soccer ball into a basket.", "target_property": {"obj": "boy", "action": "throwing soccer ball", "target": "basket"}, "evaluation_question": "Is the boy **kicking** a soccer ball into a goal?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy kicking a soccer ball into a goal. ,FEA$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f1a1f4ce9a04b1c8e6a988600338f7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99346f8ceaef4ebb83ecc85328c95719", "source": "vatex", "video_id": "tlPLdpJF86g_000046_000056", "video_description": "A large group of people, including children, are singing Christmas carols while standing in a formation resembling a Christmas tree. They are swaying back and forth on a pyramid-shaped platform outdoors.", "task": "SpatialUnderstanding", "clean_prompt": "A singer standing on a pyramid-shaped platform while a large group of people sings Christmas carols around them.", "clean_property": {"obj_1": "platform", "relation": "below", "obj_2": "singer"}, "target_prompt": "A singer on top of a pyramid-shaped platform while a large group of people sings Christmas carols around them.", "target_property": {"obj_1": "singer", "relation": "on top of", "obj_2": "platform"}, "evaluation_question": "Is the singer **below** the platform?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A singer standing on a pyramid-shaped platform while a large group of people sings Christmas carols around them. OT=)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8a06f7a8b8249edb4daadde9cf0a2dc.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "45908b805f2a4348bb010531ad5f11e9", "source": "vatex", "video_id": "wDrBUlSReb4_000019_000029", "video_description": "A group of children and young people are playing limbo on roller skates at a skating rink, taking turns to skate under a raised limbo bar without touching it.", "task": "Counting", "clean_prompt": "A group of children and young people are playing limbo on roller skates, taking turns to skate under a raised limbo bar without touching it, with two roller skates visible.", "clean_property": {"obj": "roller skates", "count": "two"}, "target_prompt": "A group of children and young people are playing limbo on roller skates, taking turns to skate under a raised limbo bar without touching it, with four roller skates visible.", "target_property": {"obj": "roller skates", "count": "four"}, "evaluation_question": "Are there exactly **two** roller skates visible?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children and young people are playing limbo on roller skates, taking turns to skate under a raised limbo bar without touching it, with two roller skates visible. TYQU\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b020ae2e5994905a0c57c492ce63049.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e85653762923408c897fba05cdaf5854", "source": "vatex", "video_id": "_bciTU-EiDk_000024_000034", "video_description": "A woman demonstrates and explains how a special latch works on an appliance door, specifically a refrigerator, including how to open and secure it.", "task": "Counting", "clean_prompt": "A woman demonstrates how to use two latches on a refrigerator door.", "clean_property": {"obj": "latch", "count": "two"}, "target_prompt": "A woman demonstrates how to use one latch on a refrigerator door.", "target_property": {"obj": "latch", "count": "one"}, "evaluation_question": "Are there exactly **two** latches on the refrigerator door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to use two latches on a refrigerator door. @JSI+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f4cfcd65e194f79ac1b8c843f4cb6d3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "15b1edeba81e4014a399b9966cc9a443", "source": "vatex", "video_id": "Bb_ksbWpLxI_000000_000010", "video_description": "A man is on a basketball court practicing dribbling tricks with two basketballs while music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A person dribbling basketballs on a basketball court.", "clean_property": {"obj": "person", "action": "dribbling basketball", "target": null}, "target_prompt": "A person shooting basketballs on a basketball court.", "target_property": {"obj": "person", "action": "shooting basketball", "target": null}, "evaluation_question": "Is the person **dribbling** basketballs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person dribbling basketballs on a basketball court. '),!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0db5c696fb124d16b7240e8178bed24e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6dccd533281349e2957b34e7faca0c7d", "source": "vatex", "video_id": "1HPBOjRFnyo_000004_000014", "video_description": "Two people are parasailing in the ocean, being pulled by a boat with a colorful parachute.", "task": "AttributeRecognition", "clean_prompt": "Two people parasailing in the ocean with a colorful parachute.", "clean_property": {"obj": "parachute", "attribute": "colorful"}, "target_prompt": "Two people parasailing in the ocean with a black parachute.", "target_property": {"obj": "parachute", "attribute": "black"}, "evaluation_question": "Is the parachute **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people parasailing in the ocean with a colorful parachute. (8RRV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de34096df9a348ada222e175b82b2a61.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "152ff55fe10d439cb8627bb21c0a60db", "source": "vatex", "video_id": "VMC7TPGygow_000021_000031", "video_description": "Two girls are in a field with a brown horse. One girl is brushing the horse's mane with a large brush, while the other girl walks up and pets the horse's head.", "task": "SpatialUnderstanding", "clean_prompt": "A girl farther from the camera than a brown horse in a field.", "clean_property": {"obj_1": "girl", "relation": "farther from the camera than", "obj_2": "horse"}, "target_prompt": "A girl closer to the camera than a brown horse in a field.", "target_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "horse"}, "evaluation_question": "Is the girl **farther from the camera than** the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl farther from the camera than a brown horse in a field. WW7'G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e3c9ccdf341c436eaeb0d376ef1b4845.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "260ca5b4c6c34bc7aff67197d4b43cd0", "source": "vatex", "video_id": "LZXdpZvN988_000059_000069", "video_description": "A woman is demonstrating wood burning techniques on a piece of oak using a burner, while explaining the process and differences in wood.", "task": "ObjectRecognition", "clean_prompt": "A woman is demonstrating wood burning techniques on a piece of oak using a burner, while explaining the process and differences in wood.", "clean_property": {"obj": "burner"}, "target_prompt": "A woman is demonstrating soldering techniques on a piece of metal using a soldering iron, while explaining the process and differences in materials.", "target_property": {"obj": "soldering iron"}, "evaluation_question": "Is the tool being used in the video a **burner**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating wood burning techniques on a piece of oak using a burner, while explaining the process and differences in wood. >OCEE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cddf6db2bdce4b97a17ced2fe5f78754.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ea4ad0c19b28464da2de967031054b98", "source": "vatex", "video_id": "qW57bMrrA8M_000000_000010", "video_description": "A man wearing a black hat is in a cluttered room, yawning multiple times while listening to music.", "task": "ActionRecognition", "clean_prompt": "A person yawning in a cluttered room while listening to music.", "clean_property": {"obj": "person", "action": "yawning", "target": null}, "target_prompt": "A person dancing in a cluttered room while listening to music.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **yawning**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person yawning in a cluttered room while listening to music. $E#TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/343399445d324a7296683042cd6b41f2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "df598df8b4e34da4820001a9b3b95fd0", "source": "vatex", "video_id": "RA90UGf5wxA_000000_000010", "video_description": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them.", "task": "Counting", "clean_prompt": "Five women laughing at two men dancing on a windy and icy street.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman laughing at two men dancing on a windy and icy street.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women laughing at the men?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women laughing at two men dancing on a windy and icy street. LYT)1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1901cff2b79849f29ae2ee133d4e9caf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "084c61d7ee414282bce79f2aef5e072b", "source": "vatex", "video_id": "-c_4PXY7SMk_000000_000010", "video_description": "A man dances energetically in front of a large street band playing various musical instruments outside a store.", "task": "AttributeRecognition", "clean_prompt": "A man dances energetically in front of a store selling apparel.", "clean_property": {"obj": "store", "attribute": "apparel"}, "target_prompt": "A man dances energetically in front of a store selling electronics.", "target_property": {"obj": "store", "attribute": "electronics"}, "evaluation_question": "Is the store selling **apparel**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man dances energetically in front of a store selling apparel. R*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/feeed8ff6c284fc4977c399a43ce776a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "04bb3c94c30f4c179f10be9aa6680d31", "source": "vatex", "video_id": "lYGoMB5u4SE_000000_000010", "video_description": "A person is inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "task": "ActionRecognition", "clean_prompt": "A person driving a Tesla, holding and slightly turning the steering wheel with both hands.", "clean_property": {"obj": "person", "action": "driving car", "target": null}, "target_prompt": "A person riding a bicycle on a sunny day.", "target_property": {"obj": "person", "action": "riding a bicycle", "target": null}, "evaluation_question": "Is the person **driving a car**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person driving a Tesla, holding and slightly turning the steering wheel with both hands. FE@Y,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f47891dcf7f644999dac160a5a67a6ea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a4352b74b7fa4aaf97f1c563eec8fff5", "source": "vatex", "video_id": "D-kcF7b_klQ_000011_000021", "video_description": "A young woman throws a shoe into the air, watches it fall, retrieves it, and puts it on.", "task": "AttributeRecognition", "clean_prompt": "A young woman throws a tennis shoe into the air, watches it fall, retrieves it, and puts it on.", "clean_property": {"obj": "shoe", "attribute": "tennis"}, "target_prompt": "A young woman throws a high-heeled shoe into the air, watches it fall, retrieves it, and puts it on.", "target_property": {"obj": "shoe", "attribute": "high-heeled"}, "evaluation_question": "Is the shoe a **tennis** shoe?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman throws a tennis shoe into the air, watches it fall, retrieves it, and puts it on. $BC'>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5f5911dfbd4349f6bb268755afa578a3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f5640f53699a439fabd3d7288b92a8e0", "source": "vatex", "video_id": "mdFZkeQv2Rc_000092_000102", "video_description": "A person is preparing a surprise by wrapping an engagement ring in a Valentine's Day themed paper and placing it in a handmade origami card.", "task": "AttributeRecognition", "clean_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper full of hearts and placing it in a handmade origami card.", "clean_property": {"obj": "paper", "attribute": "full of hearts"}, "target_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper full of stars and placing it in a handmade origami card.", "target_property": {"obj": "paper", "attribute": "full of stars"}, "evaluation_question": "Is the paper full of **hearts**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper full of hearts and placing it in a handmade origami card. .TZB1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb166a600be045e387f690e6fc58b514.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3d6746b32654f1bb26cc2ce6af89a17", "source": "vatex", "video_id": "i-xTMQu-QgU_000000_000010", "video_description": "A man is preparing to climb a rope hanging from the ceiling in a garage, while interacting with a friend and being filmed.", "task": "ObjectRecognition", "clean_prompt": "A man is preparing to climb a rope hanging from the ceiling in a garage, while interacting with a friend and being filmed with a camera.", "clean_property": {"obj": "camera"}, "target_prompt": "A man is preparing to climb a rope hanging from the ceiling in a garage, while interacting with a friend and being filmed with a drone.", "target_property": {"obj": "drone"}, "evaluation_question": "Is the filming device in the video a **camera**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is preparing to climb a rope hanging from the ceiling in a garage, while interacting with a friend and being filmed with a camera. !0D'|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2c0be8bb07a4c2bbbd3aec00abcc29a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "69bba3f95d7a44ecbea2095dcf3caebc", "source": "vatex", "video_id": "--SIRvUHMTc_000000_000010", "video_description": "A person is attempting to water ski behind a boat on a body of water, occasionally falling into the water.", "task": "ActionRecognition", "clean_prompt": "A person water skiing behind a boat on a body of water.", "clean_property": {"obj": "person", "action": "water skiing", "target": null}, "target_prompt": "A person snow skiing down a snowy slope.", "target_property": {"obj": "person", "action": "snow skiing", "target": null}, "evaluation_question": "Is the person **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person water skiing behind a boat on a body of water. ))!%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/04894b9fa6d94ec1ab1475de4fd35060.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "93d7e8ee5e094561b4f031d69ea4db49", "source": "vatex", "video_id": "lxGsTCRWw00_000014_000024", "video_description": "People are cooking flatbread over an open fire using a grill and metal paddles. A woman and a man are discussing the cooking process.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a metal paddle while cooking flatbread over an open fire.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "metal paddle"}, "target_prompt": "A person further from the camera than a metal paddle while cooking flatbread over an open fire.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "metal paddle"}, "evaluation_question": "Is the person **closer to the camera than** the metal paddle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a metal paddle while cooking flatbread over an open fire. FSB2G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3505475e112244cab8d7df90c8be80d2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "000205c3d9f042129f2e57dce014f319", "source": "vatex", "video_id": "-iruowAZ8Fw_000580_000590", "video_description": "A woman, acting as a massage therapist, is giving a professional back massage to another person lying face down on a massage table. The therapist applies oil or lotion to her hands before massaging the client's back. Acoustic guitar music plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A client closer to the camera than a massage table.", "clean_property": {"obj_1": "client", "relation": "closer to the camera than", "obj_2": "massage table"}, "target_prompt": "A client further from the camera than a massage table.", "target_property": {"obj_1": "client", "relation": "further from the camera than", "obj_2": "massage table"}, "evaluation_question": "Is the client **closer to the camera than** the massage table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A client closer to the camera than a massage table. RR8X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/408db7c8795e4f8182acc51561a7ad1d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0ea103fbfe6948e99bcff4777682a98c", "source": "vatex", "video_id": "jiu8rEK9yEk_000000_000010", "video_description": "A young girl hands a toy phone to her father, who pretends to talk on it and then hands it back to her.", "task": "SpatialUnderstanding", "clean_prompt": "A child closer to the camera than a toy phone.", "clean_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "toy phone"}, "target_prompt": "A child further from the camera than a toy phone.", "target_property": {"obj_1": "child", "relation": "further from the camera than", "obj_2": "toy phone"}, "evaluation_question": "Is the child **closer to the camera than** the toy phone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child closer to the camera than a toy phone. FL.@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73d7d4f6f5ff40dcb7f2c67237c4664b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ffe110f2f4be487b98aea11ee5b2b0cc", "source": "vatex", "video_id": "hrTttLArF24_000001_000011", "video_description": "A woman wearing an eye patch is holding a flashlight during a vision test in an eye doctor's exam room. A man instructs her to read an eye chart.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the left of a man in an eye doctor's exam room.", "clean_property": {"obj_1": "woman", "relation": "left of", "obj_2": "man"}, "target_prompt": "A woman standing to the right of a man in an eye doctor's exam room.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "man"}, "evaluation_question": "Is the woman to the **left** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the left of a man in an eye doctor's exam room. !0D|B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8737164343c6478799a7d74b75d65fda.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "23f0d25d62234588b2e60e98b5d7b16f", "source": "vatex", "video_id": "z8l7Gy9JtAg_000012_000022", "video_description": "In a garden, a boy is swinging on a swing set while another boy runs, jumps, and kicks the swing, causing the swinging boy to fall.", "task": "ActionRecognition", "clean_prompt": "A boy falling off a chair in a garden.", "clean_property": {"obj": "boy_2", "action": "falling off chair", "target": null}, "target_prompt": "A boy jumping off a chair in a garden.", "target_property": {"obj": "boy_2", "action": "jumping off a chair", "target": null}, "evaluation_question": "Is the boy **falling off a chair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy falling off a chair in a garden. @UL#$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/511d5a22d9e246939181bb78fac58f4a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "394e195ff61b493d9f0f035b6e890d96", "source": "vatex", "video_id": "RRsPuL0uSLk_000002_000012", "video_description": "A woman with long blond hair stands in front of two men, cracking her knuckles and challenging them to a fight. The men are armed with tools and appear threatening.", "task": "AttributeRecognition", "clean_prompt": "A woman with long blond hair stands in front of two men armed with tools, cracking her knuckles and challenging them to a fight.", "clean_property": {"obj": "men", "attribute": "armed with tools"}, "target_prompt": "A woman with long blond hair stands in front of two men unarmed, cracking her knuckles and challenging them to a fight.", "target_property": {"obj": "men", "attribute": "unarmed"}, "evaluation_question": "Are the men armed with tools?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman with long blond hair stands in front of two men armed with tools, cracking her knuckles and challenging them to a fight. #JU\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56f8c923aee04b7c9f168d5a519dd3a1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e70233ba63b14eb7840c128090e97406", "source": "vatex", "video_id": "N81OHjhcrbY_000198_000208", "video_description": "A woman is demonstrating and explaining how to color and apply makeup to eyebrows using q-tips.", "task": "ActionRecognition", "clean_prompt": "A person dyeing eyebrows using q-tips.", "clean_property": {"obj": "person", "action": "dyeing eyebrows", "target": null}, "target_prompt": "A person shaving eyebrows using a razor.", "target_property": {"obj": "person", "action": "shaving eyebrows", "target": null}, "evaluation_question": "Is the person **dyeing** eyebrows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person dyeing eyebrows using q-tips. FE(E(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/884ceb4f0eaa4b519f15272eb99477c2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f4dd747178749d685d82684fe3d65d3", "source": "vatex", "video_id": "Ysx54fi7QrQ_000167_000177", "video_description": "A woman demonstrates sewing techniques at a sewing machine, including how to stitch fabric for inserting elastic.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates sewing techniques at a sewing machine, stitching fabric for inserting elastic.", "clean_property": {"obj": "fabric"}, "target_prompt": "A woman demonstrates crafting techniques at a table, cutting paper for a project.", "target_property": {"obj": "paper"}, "evaluation_question": "Is the material being used in the video **fabric**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates sewing techniques at a sewing machine, stitching fabric for inserting elastic. SL3I(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e04dea5e653e4adda7763bc3e2a5980c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a776a5c24a834c42ab64cc1204e6c70c", "source": "vatex", "video_id": "0bbSopvgYAI_000000_000010", "video_description": "A man and a woman are hugging each other in a nightclub or bar setting with music and talking in the background. The woman kisses the man on the cheek.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a man in a nightclub setting.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "man"}, "target_prompt": "A woman closer to the camera than a man in a nightclub setting.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "man"}, "evaluation_question": "Is the woman **farther from the camera than** the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a man in a nightclub setting. QMO~@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9c7450da11b44c59a40a71f24a160cd9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "25fa6555d7fa469b97ecf1b3c6b1893e", "source": "vatex", "video_id": "VGfoC1OgA1s_000075_000085", "video_description": "A person is demonstrating various weaving techniques using different materials like yarn, rope, and leaves to create items such as baskets and macrame projects.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating various weaving techniques to create a basket using yarn and rope.", "clean_property": {"obj": "basket"}, "target_prompt": "A person demonstrating various weaving techniques to create a hat using yarn and rope.", "target_property": {"obj": "hat"}, "evaluation_question": "Is the item being created in the video a **basket**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating various weaving techniques to create a basket using yarn and rope. +PEY(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/43583b9755d94c98acd4c69970d42a0f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "057afc413112432989b7d00d427e2196", "source": "vatex", "video_id": "s7qkYZTezYs_000002_000012", "video_description": "A person is cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "task": "AttributeRecognition", "clean_prompt": "A person cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "clean_property": {"obj": "toilet", "attribute": "poorly kept"}, "target_prompt": "A person cleaning a spotlessly clean toilet using a toilet brush while wearing gloves.", "target_property": {"obj": "toilet", "attribute": "spotlessly clean"}, "evaluation_question": "Is the toilet **poorly kept**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning a poorly kept toilet using a toilet brush while wearing gloves. LYMNJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e97f0503ee24b1a84daafcc8c977704.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2ecf5633e634d11b7338a2f3f1f6656", "source": "vatex", "video_id": "xrZwvaZAnqo_000262_000272", "video_description": "A person is riding a bicycle in a snowy area at night, wearing a helmet. The path includes a snowy sidewalk, a bridge, and a road nearby.", "task": "SpatialUnderstanding", "clean_prompt": "A person riding a bicycle in a snowy area at night, farther from the camera than the road.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "road"}, "target_prompt": "A person riding a bicycle in a snowy area at night, closer to the camera than the road.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "road"}, "evaluation_question": "Is the person **farther from the camera than** the road?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a bicycle in a snowy area at night, farther from the camera than the road. \u00b7FE)G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b35510bfd424e499a6e3d3d51ba98e3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd78c3d714b0415aa20d91a215c48e35", "source": "vatex", "video_id": "chQmm-R1Io4_000056_000066", "video_description": "A young man is practicing field goal kicks on a football field, successfully scoring goals.", "task": "SpatialUnderstanding", "clean_prompt": "A football positioned to the left of a goal.", "clean_property": {"obj_1": "football", "relation": "left of", "obj_2": "goal"}, "target_prompt": "A football positioned to the right of a goal.", "target_property": {"obj_1": "football", "relation": "right of", "obj_2": "goal"}, "evaluation_question": "Is the football to the **left** of the goal?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A football positioned to the left of a goal. ;FJMC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aa8adff96f8a473e829b96d61b95731a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2999aea3627142a79cc20b647a58a9cd", "source": "vatex", "video_id": "MRzT1Im1u_g_000036_000046", "video_description": "A woman demonstrates how to apply lotion to her leg while seated, then proceeds to pick up hay bales in a farm area.", "task": "Counting", "clean_prompt": "A woman demonstrates how to apply lotion to her leg while seated, then proceeds to pick up seven hay bales in a farm area.", "clean_property": {"obj": "hay", "count": "seven"}, "target_prompt": "A woman demonstrates how to apply lotion to her leg while seated, then proceeds to pick up four hay bales in a farm area.", "target_property": {"obj": "hay", "count": "four"}, "evaluation_question": "Are there exactly **seven** hay bales being picked up in the farm area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to apply lotion to her leg while seated, then proceeds to pick up seven hay bales in a farm area. +2SLG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/07e58c70282a4a5db40467efc8381767.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1237c120c8d44632a83ae9a5ccc98ac4", "source": "vatex", "video_id": "RMLINvORYgQ_000000_000010", "video_description": "A man and a child are sitting at a dinner table playing dominoes. The child is keeping score on a pad.", "task": "ActionRecognition", "clean_prompt": "A man playing dominoes at a dinner table with a child keeping score.", "clean_property": {"obj": "man", "action": "playing dominoes", "target": "woman"}, "target_prompt": "A man playing cards at a dinner table with a woman.", "target_property": {"obj": "man", "action": "playing cards", "target": "woman"}, "evaluation_question": "Is the man **playing dominoes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing dominoes at a dinner table with a child keeping score. EL4.=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f267bc265ed34409ba88e0802f5f332b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6906f8ff5b7e44a895805fc3d83b1a0c", "source": "vatex", "video_id": "P6XFADT0ZCE_000026_000036", "video_description": "People are playing disc golf in a forest, throwing frisbees into chain baskets.", "task": "Counting", "clean_prompt": "Three baskets are set up in a forest where people are playing disc golf, throwing frisbees into the chain baskets.", "clean_property": {"obj": "basket", "count": "three"}, "target_prompt": "One basket is set up in a forest where people are playing disc golf, throwing frisbees into the chain basket.", "target_property": {"obj": "basket", "count": "one"}, "evaluation_question": "Are there exactly **three** baskets in the forest?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three baskets are set up in a forest where people are playing disc golf, throwing frisbees into the chain baskets. =)CFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6f9a932ca137474d86602592c1e27640.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1703e28b4677420089422ba726f9a4b3", "source": "vatex", "video_id": "i3notciKv3w_000240_000250", "video_description": "A woman and a child are roasting marshmallows over a gas stove. The woman is melting marshmallows while the child watches and participates by sticking marshmallows onto a metal stick and melting them under the flame.", "task": "ActionRecognition", "clean_prompt": "A child roasting marshmallows over a gas stove.", "clean_property": {"obj": "child", "action": "roasting marshmallows", "target": null}, "target_prompt": "A child burning marshmallows over a campfire.", "target_property": {"obj": "child", "action": "burning marshmallows", "target": null}, "evaluation_question": "Is the child **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child roasting marshmallows over a gas stove. FE@9M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/391afdd4105c4f8a9322d4b5ddd31a47.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b0d2c465a7014e7bb59155d926ae0203", "source": "vatex", "video_id": "Q_izBQ28WNI_000127_000137", "video_description": "A young man is in a bedroom demonstrating and practicing knife throwing at a target on a bed.", "task": "ObjectRecognition", "clean_prompt": "A young man practicing knife throwing at a target on a bed in a bedroom.", "clean_property": {"obj": "person"}, "target_prompt": "A woman practicing knife throwing at a target on a bed in a bedroom.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **young man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man practicing knife throwing at a target on a bed in a bedroom. FEA$A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f741c07da718407c8c287bf65c2b1ebe.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd969f845f514f588df4c56624748b4d", "source": "vatex", "video_id": "d-YUho_dHJE_000017_000027", "video_description": "A person is demonstrating how to properly cut and peel a red onion using a sharp knife, with instructions being narrated.", "task": "ObjectRecognition", "clean_prompt": "A person is demonstrating how to properly cut and peel a red onion using a sharp knife, with instructions being narrated.", "clean_property": {"obj": "onion"}, "target_prompt": "A person is demonstrating how to properly cut and peel garlic using a sharp knife, with instructions being narrated.", "target_property": {"obj": "garlic"}, "evaluation_question": "Is the object being cut in the video an **onion**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to properly cut and peel a red onion using a sharp knife, with instructions being narrated. RD'?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d40dbc05d8294c49aee2142c8025f572.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a7d2416e54446f3a5e16ba2fc296aa8", "source": "vatex", "video_id": "mcMqVzsTkkU_000051_000061", "video_description": "A man is performing stunts and walking on a tightrope across a deep canyon, high above the ground, with mountains in the background.", "task": "ActionRecognition", "clean_prompt": "A person tying a knot on a tightrope.", "clean_property": {"obj": "person", "action": "tying knot (not on a tie)", "target": "tightrope"}, "target_prompt": "A person falling from a tightrope.", "target_property": {"obj": "person", "action": "falling", "target": "tightrope"}, "evaluation_question": "Is the person **tying a knot** on the tightrope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a knot on a tightrope. FEI'9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3bb95324692842e88084d29310f5ca67.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ca7e85af02a475289c3f8bb42d743e1", "source": "vatex", "video_id": "I08yHasZUzw_000021_000031", "video_description": "A man is on a golf course demonstrating and explaining the proper golfing stance and technique before hitting a golf ball with a club.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a golf club on a golf course.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "golf club"}, "target_prompt": "A person closer to the camera than a golf club on a golf course.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "golf club"}, "evaluation_question": "Is the person farther from the camera than the golf club?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a golf club on a golf course. NKFE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/581e657c4e9d482190d31da0765fb08f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5a47decfb51243c69e481cd3fdb954a6", "source": "vatex", "video_id": "IOKQVcsNVk4_000080_000090", "video_description": "A group of three young boys are outside in the snow, dancing, playing, and interacting with the camera.", "task": "ObjectRecognition", "clean_prompt": "Three young boys are outside in the snow, dancing and playing with a camera.", "clean_property": {"obj": "camera"}, "target_prompt": "Three young boys are outside in the snow, dancing and playing with a drone.", "target_property": {"obj": "drone"}, "evaluation_question": "Are the boys interacting with a **camera**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three young boys are outside in the snow, dancing and playing with a camera. >%BSF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13e1284d3a0b4a4eaf4233e65879c611.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f2e64ab91cc4490ab0973d94989c4fe7", "source": "vatex", "video_id": "PbGvLf7HvXQ_000063_000073", "video_description": "Two women are demonstrating how to make a spinach salad with garlic, using their hands to mix the ingredients in a wooden bowl.", "task": "ActionRecognition", "clean_prompt": "A person preparing a salad in a kitchen.", "clean_property": {"obj": "person", "action": "preparing salad", "target": null}, "target_prompt": "A person cooking pasta in a kitchen.", "target_property": {"obj": "person", "action": "cooking pasta", "target": null}, "evaluation_question": "Is the person **preparing a salad**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person preparing a salad in a kitchen. DTQFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d44427dd6e6048d383233196cddeea96.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0bac77179be2412e8121b8b2e658f32a", "source": "vatex", "video_id": "nZt6VHJ73Ls_000010_000020", "video_description": "A group of children and teenagers are riding sleds down a snowy hill, taking turns and expressing excitement.", "task": "AttributeRecognition", "clean_prompt": "A group of children and teenagers riding old fashioned wooden sleds down a snowy hill, taking turns and expressing excitement.", "clean_property": {"obj": "sled", "attribute": "old fashioned wooden"}, "target_prompt": "A group of children and teenagers riding modern plastic sleds down a snowy hill, taking turns and expressing excitement.", "target_property": {"obj": "sled", "attribute": "modern plastic"}, "evaluation_question": "Are the sleds old fashioned wooden sleds?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children and teenagers riding old fashioned wooden sleds down a snowy hill, taking turns and expressing excitement. ;D&MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f5634775c6b4f6dbffc423938104008.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "14820e836eb84f8d85da6a00de72cae4", "source": "vatex", "video_id": "rjv8GzaSFgQ_000010_000020", "video_description": "A man demonstrates how to attach a metal whisk to a cordless drill, effectively turning it into a kitchen hand mixer.", "task": "ActionRecognition", "clean_prompt": "A person using a power drill to attach a metal whisk.", "clean_property": {"obj": "person", "action": "using a power drill", "target": "whisk"}, "target_prompt": "A person using a power drill to attach a screwdriver.", "target_property": {"obj": "person", "action": "using a power drill", "target": "screwdriver"}, "evaluation_question": "Is the person **using a power drill** to attach a metal whisk?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a power drill to attach a metal whisk. )&A=,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0164052c2f23454fa18fa77ab6bba794.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f0962b5fbe1d4906a978968f88f450fb", "source": "vatex", "video_id": "kiQinygkerY_000055_000065", "video_description": "A group of men in military uniforms are loading white bags onto a conveyor belt from a truck.", "task": "ActionRecognition", "clean_prompt": "A soldier unloading a bag from a truck.", "clean_property": {"obj": "soldier", "action": "unloading truck", "target": "bag"}, "target_prompt": "A soldier loading a box onto a truck.", "target_property": {"obj": "soldier", "action": "loading truck", "target": "box"}, "evaluation_question": "Is the soldier **unloading** a bag from the truck?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A soldier unloading a bag from a truck. >P%4|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d0062755cb84305a388fa0441df1073.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "23f11db7b73940b2bb3c7026d693fa83", "source": "vatex", "video_id": "BcW6Y7eufQE_000239_000249", "video_description": "Three women and a man are sitting and talking in a home setting. The women are giggling and laughing at the man's comments, while two of the women occasionally stare at each other.", "task": "SpatialUnderstanding", "clean_prompt": "A woman sitting to the right of a man in a home setting, while they talk and laugh.", "clean_property": {"obj_1": "woman", "relation": "right of", "obj_2": "man"}, "target_prompt": "A woman sitting to the left of a man in a home setting, while they talk and laugh.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the woman sitting to the **right** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman sitting to the right of a man in a home setting, while they talk and laugh. VTV9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4240aba37ecb432ea8c18266cedaabba.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "610fd8424e7541a39ae116ea57fcdc08", "source": "vatex", "video_id": "RFyFZJJGK_g_000000_000010", "video_description": "A woman is practicing scuba diving skills in a deep swimming pool, wearing full scuba gear.", "task": "Counting", "clean_prompt": "Two scuba divers practicing skills in a deep swimming pool.", "clean_property": {"obj": "scuba diver", "count": "two"}, "target_prompt": "One scuba diver practicing skills in a deep swimming pool.", "target_property": {"obj": "scuba diver", "count": "one"}, "evaluation_question": "Are there exactly **two** scuba divers in the swimming pool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two scuba divers practicing skills in a deep swimming pool. @ZFVP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c4e94c613fad4ed58c0e744a9c16690e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "245acc29c68741f686698a69f91c8be6", "source": "vatex", "video_id": "dfo3WR33AcY_000407_000417", "video_description": "A man is applying polish to a boot and using a heat gun to cure and shine the material.", "task": "AttributeRecognition", "clean_prompt": "A man applying black polish to a boot using a heat gun to cure and shine the material.", "clean_property": {"obj": "polish", "attribute": "black"}, "target_prompt": "A man applying red polish to a boot using a heat gun to cure and shine the material.", "target_property": {"obj": "polish", "attribute": "red"}, "evaluation_question": "Is the polish being applied **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man applying black polish to a boot using a heat gun to cure and shine the material. 7TVAJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a27d367d470a4526b66c5c1ea5810680.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afad3fb18021466a9aa6465978e64efb", "source": "vatex", "video_id": "_5loyvwKrb0_000000_000010", "video_description": "A girl is performing the moonwalk on a snow and ice-covered street.", "task": "AttributeRecognition", "clean_prompt": "A girl performing the moonwalk on a snow-covered street.", "clean_property": {"obj": "street", "attribute": "snow-covered"}, "target_prompt": "A girl performing the moonwalk on a sunny street.", "target_property": {"obj": "street", "attribute": "sunny"}, "evaluation_question": "Is the street **snow-covered**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing the moonwalk on a snow-covered street. '))!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d9cad88293cd431cb686fca9ba742195.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b427ef14e3cc42d49d6514f948637870", "source": "vatex", "video_id": "ZcYB6tPK2Eo_000138_000148", "video_description": "A man is demonstrating how to solve a Rubik's cube, explaining his process while manipulating the cube.", "task": "Counting", "clean_prompt": "Four people are gathered around a table, watching a man demonstrate how to solve a Rubik's cube while explaining his process.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is sitting at a table, demonstrating how to solve a Rubik's cube.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people gathered around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are gathered around a table, watching a man demonstrate how to solve a Rubik's cube while explaining his process. E=SL-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a3335671883a40a2bcac462dc456d04d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c38071172cd4e9e8b9f0fe92332b014", "source": "vatex", "video_id": "GbaeEawJd4k_000014_000024", "video_description": "A man is performing freestyle swimming in a lane of an indoor pool, wearing goggles and flippers.", "task": "Counting", "clean_prompt": "A man is performing freestyle swimming in a lane of an indoor pool, wearing goggles and flippers, with seven people watching from the side.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man is performing freestyle swimming in a lane of an indoor pool, wearing goggles and flippers, with three people watching from the side.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching from the side?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is performing freestyle swimming in a lane of an indoor pool, wearing goggles and flippers, with seven people watching from the side. WN8UU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19ffe31bed344139b5d3e60c0999e0ca.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "88f0914d4b9b45d8bb7ba8940cc5ecd6", "source": "vatex", "video_id": "MGLdh7d-384_000038_000048", "video_description": "A group of people are base jumping and parachuting off a bridge and a cliff, landing on rocks below. One person lands on a stone platform with a parachute, while others jump off a bridge and release their parachutes on the way down.", "task": "ObjectRecognition", "clean_prompt": "A group of people base jumping and parachuting off a bridge and a cliff, landing on rocks below, with one person landing on a stone platform with a parachute.", "clean_property": {"obj": "parachute"}, "target_prompt": "A group of people taking off in a hot air balloon over a scenic landscape.", "target_property": {"obj": "hot air balloon"}, "evaluation_question": "Is the object in the video a **parachute**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people base jumping and parachuting off a bridge and a cliff, landing on rocks below, with one person landing on a stone platform with a parachute. #-PEM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d551c1b87f92438f820c67e01b7319b5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "182ebbff958a48f683176932dc45dfc8", "source": "vatex", "video_id": "Y0_a2gnlSA4_000025_000035", "video_description": "A compilation of people performing various acrobatic and yoga poses, including handstands and splits, both indoors and outdoors, with some scenes set in a snowy environment.", "task": "ActionRecognition", "clean_prompt": "A person standing on hands in a snowy environment.", "clean_property": {"obj": "person", "action": "standing on hands", "target": null}, "target_prompt": "A person doing a backflip in a snowy environment.", "target_property": {"obj": "person", "action": "doing a backflip", "target": null}, "evaluation_question": "Is the person **standing on hands**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing on hands in a snowy environment. )'!W/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/84732333b21a4fc7b468deb26436e852.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1a766287a7fc48e3853c718d2aa0e9f0", "source": "vatex", "video_id": "-JF20LJFGZM_000105_000115", "video_description": "Multiple skiers, including one in an orange suit, are skiing down a race course with cones. The skier in orange falls multiple times but continues skiing. Onlookers watch from behind a fence.", "task": "Counting", "clean_prompt": "Six onlookers watching skiers from behind a fence.", "clean_property": {"obj": "onlooker", "count": "six"}, "target_prompt": "Three onlookers watching skiers from behind a fence.", "target_property": {"obj": "onlooker", "count": "three"}, "evaluation_question": "Are there exactly **six** onlookers watching the skiers?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six onlookers watching skiers from behind a fence. SL!I(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6e642efa31743229a8217f8afa82af0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2385cff6fb0b4674b0aeac04762ba51b", "source": "vatex", "video_id": "3KpRmpaXnV4_000051_000061", "video_description": "A man is demonstrating and performing various exercises and stretches on a blue exercise mat.", "task": "SpatialUnderstanding", "clean_prompt": "A mat closer to the camera than a person demonstrating exercises.", "clean_property": {"obj_1": "mat", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A mat further from the camera than a person demonstrating exercises.", "target_property": {"obj_1": "mat", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the mat closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A mat closer to the camera than a person demonstrating exercises. FSJ&7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/009f6c47020947b786617ad9512e23ea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "db1ab74fb86a4d91a7df13c99c2c5fbf", "source": "vatex", "video_id": "LDfe8kezEA8_000771_000781", "video_description": "Two musicians are busking on a street corner, one playing a guitar and the other a keyboard, in front of a store under a bridge.", "task": "ActionRecognition", "clean_prompt": "A musician playing keyboard on a street corner.", "clean_property": {"obj": "musician", "action": "playing keyboard", "target": null}, "target_prompt": "A musician singing into a microphone on a street corner.", "target_property": {"obj": "musician", "action": "singing", "target": "microphone"}, "evaluation_question": "Is the musician **playing keyboard**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician playing keyboard on a street corner. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13ba5fa36ed0435e97bf69f04a3b5e3c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "475d86b0b8e34705b0c8d9ebcb3cb6f6", "source": "vatex", "video_id": "3a9yKjC2tNw_000005_000015", "video_description": "A young male skateboarder performs various maneuvers, including sliding with hands and feet, and standing upright while skateboarding through a park and neighborhood.", "task": "ObjectRecognition", "clean_prompt": "A young male skateboarder performs various maneuvers in a park.", "clean_property": {"obj": "skateboard"}, "target_prompt": "A young male cyclist performs various maneuvers in a park.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is the performer in the video a **skateboarder**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young male skateboarder performs various maneuvers in a park. ''!D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c66fd6617e85452d823a8c342eb6dc3a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a9802b349df413699e809090fd5ce21", "source": "vatex", "video_id": "Z8YcQALgi2o_000351_000361", "video_description": "A man wearing a helmet and harness is rappelling down a slippery mountain next to a rushing waterfall using a rope.", "task": "AttributeRecognition", "clean_prompt": "A man rappelling down a slippery mountain next to a rushing waterfall.", "clean_property": {"obj": "waterfall", "attribute": "rushing"}, "target_prompt": "A man rappelling down a slippery mountain next to a calm waterfall.", "target_property": {"obj": "waterfall", "attribute": "calm"}, "evaluation_question": "Is the waterfall **rushing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man rappelling down a slippery mountain next to a rushing waterfall. #$H%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b95a878ea0546a7b003c965a934aa65.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cbb7a258856e4c448c4370c51d533f7a", "source": "vatex", "video_id": "hBhyqgseghA_000008_000018", "video_description": "A young woman is jumping rope in slow motion with a big smile on her face, wearing pink pants and barefoot, while dance music plays in the background.", "task": "AttributeRecognition", "clean_prompt": "A person smiling while jumping rope in slow motion.", "clean_property": {"obj": "person", "attribute": "smiling"}, "target_prompt": "A person frowning while jumping rope in slow motion.", "target_property": {"obj": "person", "attribute": "frowning"}, "evaluation_question": "Is the person smiling while jumping rope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person smiling while jumping rope in slow motion. NT..C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/675955575e6e472f9cae902fb4d02b22.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1a536765dc724e58b81988857dc019db", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "SpatialUnderstanding", "clean_prompt": "A laptop positioned to the right of a TV.", "clean_property": {"obj_1": "laptop", "relation": "right of", "obj_2": "tv"}, "target_prompt": "A laptop positioned to the left of a TV.", "target_property": {"obj_1": "laptop", "relation": "left of", "obj_2": "tv"}, "evaluation_question": "Is the laptop to the **right** of the TV?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A laptop positioned to the right of a TV. RR#E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/737c3976e6cc437dbae1f38c97cc3bb0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fabb55d17bd24664bd9158fc0314fb0c", "source": "vatex", "video_id": "_dpT1Jd4S74_000033_000043", "video_description": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face. The man is holding a selfie stick and recording their experience.", "task": "Counting", "clean_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face, while the man is holding two selfie sticks and recording their experience.", "clean_property": {"obj": "selfie stick", "count": "two"}, "target_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face, while the man is holding one selfie stick and recording their experience.", "target_property": {"obj": "selfie stick", "count": "one"}, "evaluation_question": "Are there exactly **two** selfie sticks being held by the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face, while the man is holding two selfie sticks and recording their experience. &FE\u00b7T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/348a90d312de491fa58cc30d5d60a27d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f2399d3de50e4072bd7c5c32aa3bf328", "source": "vatex", "video_id": "IRRTibpBYdM_000017_000027", "video_description": "A group of children are playing soccer on a grassy field in an outdoor park. Some children are running, kicking, and holding the ball.", "task": "Counting", "clean_prompt": "Four children are playing soccer on a grassy field in an outdoor park.", "clean_property": {"obj": "child", "count": "four"}, "target_prompt": "One child is playing soccer on a sandy beach.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **four** children playing soccer on the field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four children are playing soccer on a grassy field in an outdoor park. FE4C@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c2ee586600984da383c03e9cdc2eb98c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "12b6d80667e34e9b8dad987239c6586b", "source": "vatex", "video_id": "H9FzA7Sltxs_000004_000014", "video_description": "Two young boys are standing next to each other in a room, making faces and interacting with a woman.", "task": "AttributeRecognition", "clean_prompt": "Two young boys, one small, are standing next to each other in a room, making faces and interacting with a woman.", "clean_property": {"obj": "boy", "attribute": "small"}, "target_prompt": "Two young boys, one tall, are standing next to each other in a room, making faces and interacting with a woman.", "target_property": {"obj": "boy", "attribute": "tall"}, "evaluation_question": "Is one of the boys **small**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys, one small, are standing next to each other in a room, making faces and interacting with a woman. @@EZ\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2eab28320e2b4e42ab5b010e4459a462.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3de2296088f14adc9154b9e7d1eec191", "source": "vatex", "video_id": "oX_R_BB8Jk4_000018_000028", "video_description": "A woman wearing sunglasses is outdoors, eating a sandwich while walking and talking. She is vlogging and occasionally taking selfie videos.", "task": "Counting", "clean_prompt": "A woman wearing sunglasses is outdoors, eating five sandwiches while walking and talking, vlogging and occasionally taking selfie videos.", "clean_property": {"obj": "sandwich", "count": "five"}, "target_prompt": "A woman wearing sunglasses is outdoors, eating one sandwich while walking and talking, vlogging and occasionally taking selfie videos.", "target_property": {"obj": "sandwich", "count": "one"}, "evaluation_question": "Are there exactly **five** sandwiches being eaten?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman wearing sunglasses is outdoors, eating five sandwiches while walking and talking, vlogging and occasionally taking selfie videos. >THIF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6fc6f1ace894e40972482a116c6683e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5809e192a2e24e548cb4f191a3d13b82", "source": "vatex", "video_id": "B5lAcaojk0E_000000_000010", "video_description": "A man is in a bathroom in front of a mirror, adjusting his hair and posing for the camera. A woman films him as he drools into the sink.", "task": "ActionRecognition", "clean_prompt": "A man adjusting his hair and posing for the camera in front of a bathroom mirror while drooling into the sink.", "clean_property": {"obj": "man", "action": "drooling", "target": null}, "target_prompt": "A man laughing with a woman in front of a bathroom mirror.", "target_property": {"obj": "man", "action": "laughing", "target": "woman"}, "evaluation_question": "Is the man **drooling** into the sink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man adjusting his hair and posing for the camera in front of a bathroom mirror while drooling into the sink. @3/BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35289876dc9942448ebf124bf43bf7f9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a0fd93b3d8e84fdea341743c38645d6e", "source": "vatex", "video_id": "79PeclarQcI_000000_000010", "video_description": "A group of young people are in a backyard, demonstrating and practicing axe throwing at a target.", "task": "Counting", "clean_prompt": "A group of young people are in a backyard, demonstrating and practicing axe throwing with seven axes at a target.", "clean_property": {"obj": "axe", "count": "seven"}, "target_prompt": "A group of young people are in a backyard, demonstrating and practicing axe throwing with three axes at a target.", "target_property": {"obj": "axe", "count": "three"}, "evaluation_question": "Are there exactly **seven** axes being used in the backyard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young people are in a backyard, demonstrating and practicing axe throwing with seven axes at a target. UH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fce8506ee47b4db796dd1cea22a73f61.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6504b816d7a248a8a0099cc5a7a8daf1", "source": "vatex", "video_id": "4rt6cd0DbjY_000371_000381", "video_description": "A man is riding a horse in a fenced outdoor area, possibly a ranch or paddock, while music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A person riding a horse in a fenced outdoor area.", "clean_property": {"obj": "person", "action": "riding or walking with horse", "target": null}, "target_prompt": "A person walking with a horse in a fenced outdoor area.", "target_property": {"obj": "person", "action": "walking with horse", "target": null}, "evaluation_question": "Is the person **riding** a horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a horse in a fenced outdoor area. GN84", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8854ce5b19a44c118c6b2c2c167a63fc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5810af470ebf477db53ff1b6222459b4", "source": "vatex", "video_id": "VZIcu3ibJew_000085_000095", "video_description": "A person is lying down while a technician pierces their ear and installs jewelry.", "task": "Counting", "clean_prompt": "Three people in a clinic, one lying down while a technician pierces their ear and installs jewelry.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in a clinic, lying down while a technician pierces their ear and installs jewelry.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in the clinic?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in a clinic, one lying down while a technician pierces their ear and installs jewelry. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11cf0810797244f6a09ab0f7e258a194.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad5d4d35df4f4930bdb9c879c0d93650", "source": "vatex", "video_id": "1rm5FMiDwH4_000174_000184", "video_description": "A woman is holding a dog on a table while another person bandages the dog's leg.", "task": "Counting", "clean_prompt": "A woman is holding a dog on a table while another person bandages the dog's leg.", "clean_property": {"obj": "woman", "count": "seven"}, "target_prompt": "Four women are playing with dogs in a park.", "target_property": {"obj": "woman", "count": "four"}, "evaluation_question": "Are there exactly **seven** women in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is holding a dog on a table while another person bandages the dog's leg. =SMVJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57fe363f21274200825a01a480e2b89f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "01f2f8260e2a443a944caf1a37b1d765", "source": "vatex", "video_id": "L9DHrUYTKWU_000000_000010", "video_description": "A woman is using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "task": "AttributeRecognition", "clean_prompt": "A woman smiling while blow drying a young girl's hair on the front porch of a house.", "clean_property": {"obj": "woman", "attribute": "smiling"}, "target_prompt": "A woman frowning while blow drying a young girl's hair on the front porch of a house.", "target_property": {"obj": "woman", "attribute": "frowning"}, "evaluation_question": "Is the woman **smiling** while blow drying the hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman smiling while blow drying a young girl's hair on the front porch of a house. LY2;S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9586529de34f43af938d5e72f0ef69e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21e5cdafa1724c25bfac7656ba764e05", "source": "vatex", "video_id": "OcJ6fkoWEq0_000004_000014", "video_description": "A woman in a pink dress sings karaoke with a microphone in a store or restaurant setting, while a group of people gather around, cheering, clapping, and talking loudly.", "task": "Counting", "clean_prompt": "A woman in a pink dress singing karaoke with a microphone, while seven people gather around, cheering and clapping.", "clean_property": {"obj": "woman", "count": "seven"}, "target_prompt": "A woman in a pink dress singing karaoke with a microphone, while four people gather around, cheering and clapping.", "target_property": {"obj": "woman", "count": "four"}, "evaluation_question": "Are there exactly **seven** people gathering around the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a pink dress singing karaoke with a microphone, while seven people gather around, cheering and clapping. MXPBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01c6aed6139a4342ac627c2bb3607737.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "85498c3b76ef49da82a2deb549125a69", "source": "vatex", "video_id": "1apesjwcwJ8_000015_000025", "video_description": "A group of young men are playing and practicing volleyball in a gym.", "task": "ActionRecognition", "clean_prompt": "A volleyball player playing volleyball in a gym.", "clean_property": {"obj": "volleyball player", "action": "playing volleyball", "target": "volleyball"}, "target_prompt": "A volleyball player watching volleyball in a gym.", "target_property": {"obj": "volleyball player", "action": "watching volleyball", "target": "volleyball"}, "evaluation_question": "Is the volleyball player **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A volleyball player playing volleyball in a gym. UB!TV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a423d06ee6874843b3e20d598363c85d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f74ae25c27a542b4a77fa489c9d438af", "source": "vatex", "video_id": "CMfyvou9Z_0_000000_000010", "video_description": "A young boy wearing goggles attempts a dive from a low diving board into a backyard swimming pool, resulting in a belly flop. The scene is filmed in slow motion with sound effects of applause and a cheering crowd.", "task": "ActionRecognition", "clean_prompt": "A boy springboard diving into a backyard swimming pool.", "clean_property": {"obj": "boy", "action": "springboard diving", "target": null}, "target_prompt": "A boy cannonballing into a backyard swimming pool.", "target_property": {"obj": "boy", "action": "cannonballing", "target": null}, "evaluation_question": "Is the boy **springboard diving**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy springboard diving into a backyard swimming pool. (FS\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0010ef743d4945a682f0441eab53606d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "231fd39e8ab540a2b2e365e1a0544466", "source": "vatex", "video_id": "E1wfdjBqL3g_000094_000104", "video_description": "A muscular man in a red tank top performs a shot put throw on an outdoor field, spinning before launching the heavy ball while spectators watch.", "task": "ObjectRecognition", "clean_prompt": "A muscular man in a red tank top performs a shot put throw on an outdoor field.", "clean_property": {"obj": "ball"}, "target_prompt": "A muscular man in a red tank top throws a frisbee on an outdoor field.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Is the object being thrown in the video a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A muscular man in a red tank top performs a shot put throw on an outdoor field. 4/TZ/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b08ea4ae4f54f368d67a3ce56aecb71.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "19c4bdecaf6b4673a1a29bea6b5a7ff4", "source": "vatex", "video_id": "yGs9BsfNA14_000000_000010", "video_description": "A man is standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel.", "task": "ObjectRecognition", "clean_prompt": "A man standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel.", "clean_property": {"obj": "person"}, "target_prompt": "A woman standing beside a motorcycle, using a wrench to adjust the engine.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel. FE@A)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7565eefe7d0946609c7b4b588c4dde96.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3eb74d2d59e04366afa953d08fc1b713", "source": "vatex", "video_id": "-AvjZ4eRgRM_000049_000059", "video_description": "A young man is practicing soccer tricks alone on a field, juggling and dribbling a soccer ball.", "task": "ActionRecognition", "clean_prompt": "A person juggling a soccer ball on a field.", "clean_property": {"obj": "person", "action": "juggling soccer ball", "target": null}, "target_prompt": "A person kicking a soccer ball on a field.", "target_property": {"obj": "person", "action": "kicking soccer ball", "target": null}, "evaluation_question": "Is the person **juggling** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person juggling a soccer ball on a field. MC&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be3b22bbf4724985b72f8eea881bb592.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1f4d1ec2663d43cb87bf2952f9139950", "source": "vatex", "video_id": "E-gaCwIVipE_001233_001243", "video_description": "A young man with long, shoulder-length hair is sitting in a chair while a teenage girl uses a flat iron to straighten his hair. They are in a bedroom, and there is conversation happening in the background.", "task": "ObjectRecognition", "clean_prompt": "A teenage girl is using a flat iron to straighten a young man's long hair in a cozy bedroom.", "clean_property": {"obj": "flat iron"}, "target_prompt": "A teenage girl is using a curling iron to style a young man's long hair in a cozy bedroom.", "target_property": {"obj": "curling iron"}, "evaluation_question": "Is the styling tool being used in the video a **flat iron**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenage girl is using a flat iron to straighten a young man's long hair in a cozy bedroom. ZX.OT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/519ea0fc91b34324bc6fde6246806399.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7cf25f688b634f2c840525cf21bd813a", "source": "vatex", "video_id": "NeqJ6TbCdNE_000031_000041", "video_description": "A person is using a pencil to draw various designs on a piece of paper while music plays in the background.", "task": "Counting", "clean_prompt": "Three people are using pencils to draw various designs on a piece of paper while music plays in the background.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is using a pencil to draw various designs on a piece of paper while music plays in the background.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people drawing on the paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are using pencils to draw various designs on a piece of paper while music plays in the background. IPSST", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e85455b038f412a9037c6509b7f4b73.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "59da3959600f4f4aa521114622a3d758", "source": "vatex", "video_id": "aOq--ppDs2Y_000030_000040", "video_description": "Two friends are sitting on a couch. One man is using his phone to play a game while the other tries to distract him by putting his foot in the man's face.", "task": "Counting", "clean_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene.", "clean_property": {"obj": "man_1", "count": "five"}, "target_prompt": "Two men are sitting on a couch, one playing a game on his phone while the other tries to distract him.", "target_property": {"obj": "man", "count": "two"}, "evaluation_question": "Are there exactly **five** men in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on a couch playing a game on his phone while another man tries to distract him by putting his foot in his face. There are five men in total in the scene. .BVFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cb3c8a30fee4200be9021f87618b22e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "04ad45e5df004771b2352a0412319e35", "source": "vatex", "video_id": "DCazg9KYRTk_000002_000012", "video_description": "A man is sitting on a couch or chair, eating chips while holding a baby in his lap. The baby opens his mouth each time the man eats a chip, wanting to eat them too.", "task": "Counting", "clean_prompt": "A man is sitting on a couch, eating chips while holding a baby in his lap. The baby opens his mouth each time the man eats a chip.", "clean_property": {"obj": "man", "count": "three"}, "target_prompt": "A man is sitting on a couch, eating chips.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **three** men in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on a couch, eating chips while holding a baby in his lap. The baby opens his mouth each time the man eats a chip. LFE=V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76668c3c5f2c44c4b66a688a3a457829.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce2fc62f4b514dbab012ce8d36e16996", "source": "vatex", "video_id": "CnYoY8iq8vY_000003_000013", "video_description": "A young girl with braces is laughing and smiling for the camera.", "task": "Counting", "clean_prompt": "Two people, a young girl with braces and her friend, laughing and smiling for the camera.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person, a young girl with braces, laughing and smiling for the camera.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people, a young girl with braces and her friend, laughing and smiling for the camera. !0O9E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/84177ff9ec504ea4b74d71b4b9a797f8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8efedf29f8cc422fbbe49ea9a455e02f", "source": "vatex", "video_id": "-XTQ7kDUXjk_000087_000097", "video_description": "A window cleaner is using a long pole to clean high windows and gutters on a house.", "task": "ActionRecognition", "clean_prompt": "A window cleaner cleaning gutters on a house.", "clean_property": {"obj": "window cleaner", "action": "cleaning gutters", "target": "gutter"}, "target_prompt": "A window cleaner painting walls on a house.", "target_property": {"obj": "window cleaner", "action": "painting walls", "target": "wall"}, "evaluation_question": "Is the window cleaner **cleaning gutters**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A window cleaner cleaning gutters on a house. HS8M@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e87efcefa12448d2bf63cc1cd4fc2917.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d5e9e51ca8f491c8d9c82a6ebc957bd", "source": "vatex", "video_id": "eibBrEaSB8A_000000_000010", "video_description": "Two men are sitting on motorcycles, revving the engines while stationary. One man wears a red helmet and the other a black helmet.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a motorcycle.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "motorcycle"}, "target_prompt": "A person closer to the camera than a motorcycle.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "motorcycle"}, "evaluation_question": "Is the person **farther from the camera than** the motorcycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a motorcycle. ~))',", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3357ad8f8f084d51bf73209f3a47a88e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a9e45fef60764fcb9d90fe6deeb7de26", "source": "vatex", "video_id": "lZ7-OqFQaPc_000000_000010", "video_description": "A young boy is demonstrating and explaining how to fish by casting a fishing line into a body of water.", "task": "ObjectRecognition", "clean_prompt": "A young boy is demonstrating and explaining how to fish by casting a fishing line into a body of water.", "clean_property": {"obj": "fishing line"}, "target_prompt": "A young boy is demonstrating and explaining how to fish by using a fishing net in a body of water.", "target_property": {"obj": "fishing net"}, "evaluation_question": "Is the boy using a **fishing line**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is demonstrating and explaining how to fish by casting a fishing line into a body of water. HSTFJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19237f3f42a54bdfafd5d25e75a6ec7a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4dfa790ac3ce43ee9d67fcd3dadefb92", "source": "vatex", "video_id": "dZuj-1lt1u8_000463_000473", "video_description": "A woman is demonstrating how to shape a long black balloon into a circular shape on a stage with a table.", "task": "ObjectRecognition", "clean_prompt": "A woman is shaping a long black balloon into a circular shape on a stage with a table.", "clean_property": {"obj": "balloon"}, "target_prompt": "A woman is flying a colorful kite on a stage with a table.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object being shaped in the video a **balloon**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is shaping a long black balloon into a circular shape on a stage with a table. SL$#V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfe38ee90b0149ff9eb0e9d38966c782.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "56b39921defd43458a3c76939036d9dd", "source": "vatex", "video_id": "saxpZNQIcVg_000000_000010", "video_description": "A young child is sitting in a chair, examining and eating chips while occasionally smiling.", "task": "Counting", "clean_prompt": "A young child is sitting in a chair, examining and eating three chips while occasionally smiling.", "clean_property": {"obj": "chip", "count": "three"}, "target_prompt": "A young child is sitting in a chair, examining and eating one chip while occasionally smiling.", "target_property": {"obj": "chip", "count": "one"}, "evaluation_question": "Are there exactly **three** chips being examined and eaten by the child?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young child is sitting in a chair, examining and eating three chips while occasionally smiling. ZZFET", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/612d766c9ce34752a0fcb00e4af0c043.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "878c797c110142728adba393fbbbcfed", "source": "vatex", "video_id": "BeevuXU4xSM_000000_000010", "video_description": "A man is practicing shot put throwing techniques, spinning around and throwing the shot put in a marked area outdoors.", "task": "Counting", "clean_prompt": "Four men practicing shot put throwing techniques outdoors.", "clean_property": {"obj": "man", "count": "four"}, "target_prompt": "One man practicing shot put throwing techniques outdoors.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **four** men practicing shot put outdoors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four men practicing shot put throwing techniques outdoors. RR|O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a2e8cbbc79954a73b3b111d67db00bf2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "770226bfcad9414f8b234be4d686a3b5", "source": "vatex", "video_id": "SAISuCs1IiI_000017_000027", "video_description": "A large, muscular man is working out his arms using various machines in a gym. He is wearing black clothing and a gray shirt at different times, performing exercises like triceps extensions and pull downs.", "task": "AttributeRecognition", "clean_prompt": "A person wearing black clothing is working out in a gym.", "clean_property": {"obj": "person", "attribute": "wearing black clothing"}, "target_prompt": "A person wearing bright yellow clothing is working out in a gym.", "target_property": {"obj": "person", "attribute": "wearing bright yellow clothing"}, "evaluation_question": "Is the person wearing **black** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing black clothing is working out in a gym. NKYUY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14fc609a277041fa81ff2ba6c9df2547.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4787902456646259e5aa8604daa9b47", "source": "vatex", "video_id": "_YhK30D1w4U_000000_000010", "video_description": "Two men are singing karaoke indoors, one standing and singing into a microphone while the other sits and sings into another microphone. They are in a room with a TV screen displaying lyrics and loud, distorted music playing.", "task": "AttributeRecognition", "clean_prompt": "A person who is overweight singing karaoke indoors.", "clean_property": {"obj": "person", "attribute": "overweight"}, "target_prompt": "An athletic person singing karaoke indoors.", "target_property": {"obj": "person", "attribute": "athletic"}, "evaluation_question": "Is the person overweight?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who is overweight singing karaoke indoors. U%/%=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ff63a7c837d64f378007c7b50efaa3b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c411fa4f1add4d3eb3dbfd834faaef35", "source": "vatex", "video_id": "UhV7te0jknc_000513_000523", "video_description": "A person is using a hot glue gun to attach buttons to a snowman made from a sock.", "task": "ObjectRecognition", "clean_prompt": "A person is using a hot glue gun to attach buttons to a snowman made from a sock.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a snowman made from a sock.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is using a hot glue gun to attach buttons to a snowman made from a sock. TY'TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b749b9fd2d5a47beb34ed57af814bea6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ddc685cc0ad84a799a14dcb56ca12f4a", "source": "vatex", "video_id": "1fhKRQdEA3Q_000123_000133", "video_description": "A martial arts class where individuals demonstrate breaking techniques using kicks and punches on tiles, boards, and blocks.", "task": "AttributeRecognition", "clean_prompt": "An adult martial artist demonstrating breaking techniques using kicks and punches on tiles.", "clean_property": {"obj": "martial artist", "attribute": "adult"}, "target_prompt": "A child martial artist demonstrating breaking techniques using kicks and punches on tiles.", "target_property": {"obj": "martial artist", "attribute": "child"}, "evaluation_question": "Is the martial artist an **adult**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult martial artist demonstrating breaking techniques using kicks and punches on tiles. UB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14ef88131f0b475d951e95c65b4ffdf7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc46197424a242a3a7c1731f6c7358d6", "source": "vatex", "video_id": "Y22t5TNfysQ_000160_000170", "video_description": "Two young boys are demonstrating how to tie the shoe laces of a person standing on a table in a classroom.", "task": "Counting", "clean_prompt": "Two young boys are demonstrating how to tie the shoe laces of a person standing on a table in a classroom.", "clean_property": {"obj": "boy", "count": "six"}, "target_prompt": "Six boys are playing soccer in a park.", "target_property": {"obj": "boy", "count": "six"}, "evaluation_question": "Are there exactly **two** boys demonstrating shoe tying in the classroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys are demonstrating how to tie the shoe laces of a person standing on a table in a classroom. #BSIT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fda7a956546f4621ab508cfaec7e3650.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d685680d35e4b4daecf24cbd97672dd", "source": "vatex", "video_id": "oIXP4X_WVbQ_000012_000022", "video_description": "A woman demonstrates how to fold a piece of origami paper that is pink on one side and blue on the other.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrates how to fold a piece of origami paper that is pink on one side and blue on the other.", "clean_property": {"obj": "paper", "attribute": "blue on the other side"}, "target_prompt": "A woman demonstrates how to fold a piece of origami paper that is green on both sides.", "target_property": {"obj": "paper", "attribute": "green on both sides"}, "evaluation_question": "Is the paper blue on the other side?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to fold a piece of origami paper that is pink on one side and blue on the other. KKFE)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/96da8f0ce47b432aa32ed9bfdc864edb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "20da2dc3248d426da2c1bb67ef460241", "source": "vatex", "video_id": "2kJxrcNRS9w_000047_000057", "video_description": "A young girl is performing a gymnastics routine outdoors, including cartwheels, flips, and poses, with music playing in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A girl performing a gymnastics routine farther from the camera than the camera.", "clean_property": {"obj_1": "girl", "relation": "farther from the camera than", "obj_2": "camera"}, "target_prompt": "A girl performing a gymnastics routine closer to the camera than the camera.", "target_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "camera"}, "evaluation_question": "Is the girl **farther from the camera than** the camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing a gymnastics routine farther from the camera than the camera. 'G*9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e63fd14395af45419b3c641fec39e332.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "260529e2a364456eb312f04e22af6e8c", "source": "vatex", "video_id": "C29kvQkzadQ_000017_000027", "video_description": "A man in a gym demonstrates a workout with free weights, performing standing front raises while music plays.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating a workout with free weights, performing standing front raises while music plays, showcasing a muscular physique.", "clean_property": {"obj": "person", "attribute": "muscular"}, "target_prompt": "A person demonstrating a workout with free weights, performing standing front raises while music plays, showcasing a slim physique.", "target_property": {"obj": "person", "attribute": "slim"}, "evaluation_question": "Is the person demonstrating a workout **muscularly**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating a workout with free weights, performing standing front raises while music plays, showcasing a muscular physique. =DMS$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e77c47756824a4a9807ec6ad6f1f052.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "370754f081f94d1e8ada86006b590584", "source": "vatex", "video_id": "Y0zwBnxzd1I_000027_000037", "video_description": "A young boy is showing off his mobile phone and its features in front of a camera while talking about it.", "task": "ObjectRecognition", "clean_prompt": "A young boy is showing off his mobile phone and its features in front of a camera while talking about it.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a mobile phone in front of a camera.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is showing off his mobile phone and its features in front of a camera while talking about it. !0D=|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16f6354244cd458781560df5db4a4f7f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "658401b4edf741ed949677a0390c2ee2", "source": "vatex", "video_id": "Nu6MHmc6BSc_000000_000010", "video_description": "A man in a gym is preparing and attempting to lift a heavy barbell with weights on both sides.", "task": "AttributeRecognition", "clean_prompt": "A man in a gym is preparing and attempting to lift a heavy barbell with weights on both sides.", "clean_property": {"obj": "barbell", "attribute": "heavy"}, "target_prompt": "A man in a gym is preparing and attempting to lift a light barbell with weights on both sides.", "target_property": {"obj": "barbell", "attribute": "light"}, "evaluation_question": "Is the barbell **heavy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a gym is preparing and attempting to lift a heavy barbell with weights on both sides. W%B&,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/849262aa44044b978b0480469798e03f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad120d14d90f431bb3391bdd4ee3afb1", "source": "vatex", "video_id": "s-bHUbr-4p8_000001_000011", "video_description": "A female athlete is participating in an indoor track event, performing long jump and triple jump maneuvers while onlookers watch.", "task": "Counting", "clean_prompt": "A female athlete is performing long jump and triple jump maneuvers while six onlookers watch.", "clean_property": {"obj": "onlookers", "count": "six"}, "target_prompt": "A female athlete is performing long jump and triple jump maneuvers while two onlookers watch.", "target_property": {"obj": "onlookers", "count": "two"}, "evaluation_question": "Are there exactly **six** onlookers watching the athlete?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female athlete is performing long jump and triple jump maneuvers while six onlookers watch. BERMC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6e3124a000a142b4ae31c7334611db3a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cf1b562540e240ec9c0a4dba7c03bcd1", "source": "vatex", "video_id": "Vl7YXD9uycc_000000_000010", "video_description": "A man is interviewing various individuals in costumes, including a person in a green full-body superhero costume, using a microphone.", "task": "ObjectRecognition", "clean_prompt": "An interviewer is speaking with various individuals in costumes, including a person in a green full-body superhero costume, using a microphone.", "clean_property": {"obj": "interviewer"}, "target_prompt": "A reporter is speaking with various individuals in costumes, including a person in a green full-body superhero costume, using a microphone.", "target_property": {"obj": "reporter"}, "evaluation_question": "Is the person in the video an **interviewer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An interviewer is speaking with various individuals in costumes, including a person in a green full-body superhero costume, using a microphone. P6SAS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d233f6945d2e4cb8aacd6538f065e181.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c356da3a728648be85dced4da073e0b5", "source": "vatex", "video_id": "6HJ_rP-o8tA_000000_000010", "video_description": "A man in a gym is preparing to lift a heavily weighted barbell from the floor using lifting straps.", "task": "ObjectRecognition", "clean_prompt": "A man in a gym is preparing to lift a heavily weighted barbell from the floor using lifting straps.", "clean_property": {"obj": "person"}, "target_prompt": "A woman in a gym is preparing to lift a heavily weighted barbell from the floor using lifting straps.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a gym is preparing to lift a heavily weighted barbell from the floor using lifting straps. P-MEJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/417bebdb041a4e60ac8f3dcd9a471b67.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b18d59968ee48a59aa84961c3d5bf9d", "source": "vatex", "video_id": "A3cqM3Mk2Mg_000876_000886", "video_description": "A group of people are sitting at a kitchen bar or restaurant counter, watching as a couple or staff prepare salads.", "task": "SpatialUnderstanding", "clean_prompt": "A staff member standing to the right of a counter in a kitchen bar.", "clean_property": {"obj_1": "staff", "relation": "right of", "obj_2": "counter"}, "target_prompt": "A staff member standing to the left of a counter in a kitchen bar.", "target_property": {"obj_1": "staff", "relation": "left of", "obj_2": "counter"}, "evaluation_question": "Is the staff member to the **right** of the counter?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A staff member standing to the right of a counter in a kitchen bar. ;D&|J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1945326191aa43b3b6c019a5eebb4ac9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d628618425f4ec5a7a62bf1ffe216f2", "source": "vatex", "video_id": "ihaCkiCbZK8_000023_000033", "video_description": "A baby is sitting in a walker, shaking their head happily and smiling. The baby is amused by a parent or someone playing with them, and occasionally reaches towards the camera.", "task": "ActionRecognition", "clean_prompt": "A baby shaking their head happily in a walker.", "clean_property": {"obj": "baby", "action": "shaking head", "target": null}, "target_prompt": "A baby crying in a walker.", "target_property": {"obj": "baby", "action": "crying", "target": null}, "evaluation_question": "Is the baby **shaking their head** happily?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby shaking their head happily in a walker. ))!0P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/70299e786fef401e90c05d37bcd028b2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "49cfb09c8986416f93e188e386dd79c5", "source": "vatex", "video_id": "VrsrsP28vrU_000000_000010", "video_description": "A boy is sleeping in a bunk bed when someone throws a pillow at him, waking him up.", "task": "Counting", "clean_prompt": "A boy is sleeping in a bunk bed with four levels when someone throws a pillow at him, waking him up.", "clean_property": {"obj": "bunk bed", "count": "four"}, "target_prompt": "A boy is sleeping in a bunk bed with two levels when someone throws a pillow at him, waking him up.", "target_property": {"obj": "bunk bed", "count": "two"}, "evaluation_question": "Are there exactly **four** levels in the bunk bed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy is sleeping in a bunk bed with four levels when someone throws a pillow at him, waking him up. OU-SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce76ad69d84548c785b2d6aa58c04b6f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a3148975b9c94525bbd18a2ad3e91d5b", "source": "vatex", "video_id": "6mUXbkDiL5w_000000_000010", "video_description": "A group of children are riding a wagon down a dirt hill. The wagon flips at the bottom, causing the children to fall out.", "task": "AttributeRecognition", "clean_prompt": "A small child riding a wagon down a dirt hill.", "clean_property": {"obj": "child", "attribute": "small"}, "target_prompt": "A large child riding a wagon down a dirt hill.", "target_property": {"obj": "child", "attribute": "large"}, "evaluation_question": "Is the child **small**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A small child riding a wagon down a dirt hill. TZR)F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef97438474d64549b825e2894e063ba0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d84b3d4efcd41c3b6f58d22cdb40452", "source": "vatex", "video_id": "xBbE1E5A8FA_000313_000323", "video_description": "Two young women in costumes and Halloween makeup are sitting cross-legged on the ground, talking and laughing with each other.", "task": "ObjectRecognition", "clean_prompt": "Two young women in costumes and Halloween makeup are sitting cross-legged on the ground, talking and laughing with each other.", "clean_property": {"obj": "person"}, "target_prompt": "Two cats in costumes are sitting cross-legged on the ground, playing and interacting with each other.", "target_property": {"obj": "cat"}, "evaluation_question": "Are the characters in the video **people**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young women in costumes and Halloween makeup are sitting cross-legged on the ground, talking and laughing with each other. L*Y&4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/abb2b80ac8c34c9a808e35996e7d4a8f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d81547d798c54d8994de1541a395e4d1", "source": "vatex", "video_id": "k3rmqNVqy2Q_000010_000020", "video_description": "A young man is lying on a bed with a white, creamy substance on his hand while another person plays a joke on him, causing laughter.", "task": "AttributeRecognition", "clean_prompt": "A young man lying on a bed with a white, creamy substance on his hand while another person plays a joke on him, causing laughter.", "clean_property": {"obj": "substance", "attribute": "white"}, "target_prompt": "A young man lying on a bed with a black, creamy substance on his hand while another person plays a joke on him, causing laughter.", "target_property": {"obj": "substance", "attribute": "black"}, "evaluation_question": "Is the substance on the young man's hand **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man lying on a bed with a white, creamy substance on his hand while another person plays a joke on him, causing laughter. O9G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a4bada3ff6ea4a35b4785ecaac1bd04c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "232a615dbb79440dafa0ca0897c5c945", "source": "vatex", "video_id": "RcqKQXQ6wJI_000046_000056", "video_description": "A man is playing the bagpipes while walking down a hallway in a school building, with people watching from the sides.", "task": "ActionRecognition", "clean_prompt": "A person playing bagpipes while walking down a hallway in a school building.", "clean_property": {"obj": "person", "action": "playing bagpipes", "target": null}, "target_prompt": "A person playing drums while walking down a hallway in a school building.", "target_property": {"obj": "person", "action": "playing drums", "target": null}, "evaluation_question": "Is the person **playing bagpipes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing bagpipes while walking down a hallway in a school building. UF$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5cbd3ce1c2f847ca984aedd99a2d8c9c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1533663df3eb4e40b53ff3b14d046804", "source": "vatex", "video_id": "Sq82j_WAYTg_000000_000010", "video_description": "A man is riding a segway with a lawn mower attached, cutting grass across a yard.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a lawn mower.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "lawn mower"}, "target_prompt": "A person further from the camera than a lawn mower.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "lawn mower"}, "evaluation_question": "Is the person closer to the camera than the lawn mower?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a lawn mower. RRQP4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c100d4428bb945a9a1bc2e7f57e08750.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a29a389077d47b4bb9a549e7af08615", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a pipe bending tool.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "pipe bending tool"}, "target_prompt": "A person welding a pipe bending tool.", "target_property": {"obj": "person", "action": "welding", "target": "pipe bending tool"}, "evaluation_question": "Is the person **using a sledge hammer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer on a pipe bending tool. &&FEI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/deb0faafb6a34b748bd8af2e9556c0a4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8530ea5dbc3349429870e398fe67490c", "source": "vatex", "video_id": "WFHuy4Cv5qY_000116_000126", "video_description": "A woman is in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "task": "Counting", "clean_prompt": "Five women in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "A woman in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women in a kitchen demonstrating how to cook scrambled eggs and place them on toast. EHU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0deeee61fb9146b581ecd6b86d290c32.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0ddc009f122545e3860995a3cca1c418", "source": "vatex", "video_id": "RIz7nXX6RpI_000081_000091", "video_description": "A group of people are inside an airplane, preparing to skydive.", "task": "ActionRecognition", "clean_prompt": "A person skydiving from an airplane.", "clean_property": {"obj": "person", "action": "skydiving", "target": null}, "target_prompt": "A person paragliding over a mountain landscape.", "target_property": {"obj": "person", "action": "paragliding", "target": null}, "evaluation_question": "Is the person **skydiving**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person skydiving from an airplane. SLID-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5dec723ea31d45f297c9d0246df1a605.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e08f22b57ef74e85a019c05ea4c1bb11", "source": "vatex", "video_id": "V7r_lGdJiko_000014_000024", "video_description": "A person in protective gear is welding metal on a scaffolding with decorations, creating sparks.", "task": "AttributeRecognition", "clean_prompt": "A person in protective gear is welding silver metal on a scaffolding with decorations, creating sparks.", "clean_property": {"obj": "metal", "attribute": "silver"}, "target_prompt": "A person in protective gear is welding gold metal on a scaffolding with decorations, creating sparks.", "target_property": {"obj": "metal", "attribute": "gold"}, "evaluation_question": "Is the metal being welded **silver**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in protective gear is welding silver metal on a scaffolding with decorations, creating sparks. HSOHJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1edbcede4f5048eba477d3e816b6edac.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6115bcd17a4544c89b32ab46c146be04", "source": "vatex", "video_id": "pfMOjZqjaoc_000029_000039", "video_description": "A man in a purple outfit and a weird hat is demonstrating and explaining how to create balloon animals at a show.", "task": "ObjectRecognition", "clean_prompt": "A man in a purple outfit and a weird hat is demonstrating how to create balloon animals at a show.", "clean_property": {"obj": "balloon"}, "target_prompt": "A man in a purple outfit and a weird hat is demonstrating how to fly a kite at a show.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the man demonstrating how to create **balloon animals**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a purple outfit and a weird hat is demonstrating how to create balloon animals at a show. HL2FK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/30386af614ca42498bf53d930b99f484.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "343dfab528d346d2a37489bf3647ae55", "source": "vatex", "video_id": "qpTtNJRcPjc_000218_000228", "video_description": "A young man is standing at a podium in a yellow room, reading from various documents including a newspaper and a book, while giving a speech to an audience.", "task": "ActionRecognition", "clean_prompt": "A person reading a newspaper at a podium in a yellow room.", "clean_property": {"obj": "person", "action": "reading newspaper", "target": null}, "target_prompt": "A person throwing a newspaper at a podium in a yellow room.", "target_property": {"obj": "person", "action": "throwing newspaper", "target": null}, "evaluation_question": "Is the person **reading** a newspaper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person reading a newspaper at a podium in a yellow room. )!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee740251c67048088fa8672fd57f7ac8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8181702e7074c828ed88dc5ed58646f", "source": "vatex", "video_id": "133KOQpZmrY_000016_000026", "video_description": "A man is sitting on a patio chair holding a baby on his lap while a little girl plays with the baby, making him laugh.", "task": "ActionRecognition", "clean_prompt": "A girl kissing a baby while a man sits on a patio chair.", "clean_property": {"obj": "girl", "action": "kissing", "target": "baby"}, "target_prompt": "A girl hugging a baby while a man sits on a patio chair.", "target_property": {"obj": "girl", "action": "hugging", "target": "baby"}, "evaluation_question": "Is the girl **kissing** the baby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl kissing a baby while a man sits on a patio chair. =8LFX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4ddb70f49b034a99b4eb662360ec776a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a29f2e56c7314a2e8caac4d3a2765829", "source": "vatex", "video_id": "qpTtNJRcPjc_000218_000228", "video_description": "A young man is standing at a podium in a yellow room, reading from various documents including a newspaper and a book, while giving a speech to an audience.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone closer to the camera than a person standing at a podium in a yellow room.", "clean_property": {"obj_1": "microphone", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A microphone further from the camera than a person standing at a podium in a yellow room.", "target_property": {"obj_1": "microphone", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the microphone closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microphone closer to the camera than a person standing at a podium in a yellow room. SL1MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6363ff2a8e3140e599360d35817d97b7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99326160c4dd46aebadbc6cae57d6488", "source": "vatex", "video_id": "B5U_KlU_TCI_000021_000031", "video_description": "A young woman with pigtails and heavy makeup is smoking a cigarette and exhaling smoke in a dark setting.", "task": "ActionRecognition", "clean_prompt": "A person smoking a cigarette in a dark setting.", "clean_property": {"obj": "person", "action": "smoking", "target": "cigarette"}, "target_prompt": "A person dancing with a cigarette in a bright setting.", "target_property": {"obj": "person", "action": "dancing", "target": "cigarette"}, "evaluation_question": "Is the person **smoking** a cigarette?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person smoking a cigarette in a dark setting. ))!%-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56779d4ff5074b8e81e6b751db0d4656.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cca5ad73f51740249071b16cdcca2d61", "source": "vatex", "video_id": "rkv6-qHmyPg_000069_000079", "video_description": "A woman is lying face down on a massage table outdoors by the water, receiving a deep muscle massage from a man. Soft music plays in the background.", "task": "AttributeRecognition", "clean_prompt": "A man acting as a masseuse giving a deep muscle massage to a woman lying face down on a massage table outdoors by the water.", "clean_property": {"obj": "man", "attribute": "masseuse"}, "target_prompt": "A man wearing a clown costume giving a deep muscle massage to a woman lying face down on a massage table outdoors by the water.", "target_property": {"obj": "man", "attribute": "wearing a clown costume"}, "evaluation_question": "Is the man acting as a masseuse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man acting as a masseuse giving a deep muscle massage to a woman lying face down on a massage table outdoors by the water. ''!%:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6d75dbf28f32442e9050af2cb25bac39.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3c6ca0b8f9fd4b79a2c2ec9d1968be5e", "source": "vatex", "video_id": "mNdTGphRHrY_000020_000030", "video_description": "A man is applying makeup to a woman's lips using a lip liner and lipstick, while explaining the process and discussing the products.", "task": "Counting", "clean_prompt": "Seven people are gathered around a table, discussing makeup techniques and sharing tips.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Four people are gathered around a table, discussing makeup techniques and sharing tips.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **seven** people gathered around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are gathered around a table, discussing makeup techniques and sharing tips. 0D&);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ca306a78c1864a7686bc42475704f231.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7689de70c1140fbabf5f1fffb598dbe", "source": "vatex", "video_id": "T65sBQHF9Bk_000085_000095", "video_description": "A woman demonstrates how to make an egg sandwich with poached eggs on cheesy toast. She puts shredded cheese on slices of bread, places them on a cooking tray, and moves them to the oven. Meanwhile, eggs are boiling in a pot and frying in a pan on the stove.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing above an oven while preparing an egg sandwich.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "oven"}, "target_prompt": "A person standing beside an oven while preparing an egg sandwich.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "oven"}, "evaluation_question": "Is the person **above** the oven?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing above an oven while preparing an egg sandwich. ?I?$A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18a40bc2e85142b5a27d4ba7e367af5d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7020cc11361e4867ac5d7fe5bff48a55", "source": "vatex", "video_id": "EDo0d6HMV1k_000041_000051", "video_description": "A man is performing a breakdancing routine alone in a large, dimly lit room with TV monitors around him and music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A man performing a breakdancing routine alone in a large, dimly lit room with TV monitors around him and music playing in the background.", "clean_property": {"obj": "person"}, "target_prompt": "A woman performing a breakdancing routine alone in a large, dimly lit room with TV monitors around her and music playing in the background.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the performer in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing a breakdancing routine alone in a large, dimly lit room with TV monitors around him and music playing in the background. LY%\u00b7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/484f190667944583825dc7a15c0b2de2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9324f4a40f514976b35fd0243fdca2e4", "source": "vatex", "video_id": "LRtwpDIf6iY_000136_000146", "video_description": "A person is tending to another person's face and head while they sit in a chair.", "task": "Counting", "clean_prompt": "A person is tending to another person's face and head while they sit in a chair, with seven people watching.", "clean_property": {"obj": "person_2", "count": "seven"}, "target_prompt": "A person is tending to another person's face and head while they sit in a chair, with three people watching.", "target_property": {"obj": "person_2", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is tending to another person's face and head while they sit in a chair, with seven people watching. $MC\u00b7U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2cde7fef3ce94a698542fb2eb175cddc.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd0be46bd1f74d6c80afd68fda99c4a0", "source": "vatex", "video_id": "4b9-FaG16Y4_000012_000022", "video_description": "A boy is performing tricks and spinning on a green hoverboard indoors and on a balcony.", "task": "SpatialUnderstanding", "clean_prompt": "A boy is positioned to the right of a green hoverboard, performing tricks indoors.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "hoverboard"}, "target_prompt": "A girl is positioned to the left of a skateboard, performing tricks outdoors.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "skateboard"}, "evaluation_question": "Is the boy to the **right** of a green hoverboard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy is positioned to the right of a green hoverboard, performing tricks indoors. SLQPP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a90bdbf1e74460c8548600723533d03.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f41c5fb2a223400c8ab1090656d60a88", "source": "vatex", "video_id": "7lPFqjNlWBI_000001_000011", "video_description": "A woman is practicing on a flying trapeze indoors, wearing a harness and safety equipment. She is assisted by a man who pushes her off the platform. The room is lit in a shade of purple.", "task": "ObjectRecognition", "clean_prompt": "A man assisting a woman on a flying trapeze indoors, wearing a harness and safety equipment.", "clean_property": {"obj": "man"}, "target_prompt": "A woman assisting another woman on a flying trapeze indoors, wearing a harness and safety equipment.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the assistant in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man assisting a woman on a flying trapeze indoors, wearing a harness and safety equipment. DW%AQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c11b8cea9d4948d69829c0e3563998eb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ccd0496ba7564c908b8ae3f43644fb4f", "source": "vatex", "video_id": "KeJRWZAEAxM_000031_000041", "video_description": "A man is in a gym working out with weights, focusing on tricep and forearm exercises using a pulley machine. He experiences discomfort in his arm during the workout.", "task": "ObjectRecognition", "clean_prompt": "A man is in a gym working out with weights, focusing on tricep and forearm exercises using a pulley machine.", "clean_property": {"obj": "weights"}, "target_prompt": "A man is in a gym working out with exercise bands, focusing on tricep and forearm exercises using a pulley machine.", "target_property": {"obj": "exercise bands"}, "evaluation_question": "Is the man working out with **weights**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is in a gym working out with weights, focusing on tricep and forearm exercises using a pulley machine. UTB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/267e5d4fa8894fef95879af3d2e08634.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d9610e9196d14fe1a26e9a1b2a8fef41", "source": "vatex", "video_id": "uT5gwTixM7A_000118_000128", "video_description": "A woman is demonstrating and explaining how to cut and arrange greenery, including ferns, into a vase for a flower arrangement.", "task": "SpatialUnderstanding", "clean_prompt": "A vase closer to the camera than a person demonstrating how to arrange greenery.", "clean_property": {"obj_1": "vase", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A vase further from the camera than a person demonstrating how to arrange greenery.", "target_property": {"obj_1": "vase", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the vase closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A vase closer to the camera than a person demonstrating how to arrange greenery. RPZJN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/697a1062ec13429d91e998488a48dd75.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ba3971cb505d459787f781ccb39b8096", "source": "vatex", "video_id": "elad6vOMAFY_000076_000086", "video_description": "A woman is in the kitchen preparing dough and making homemade granola. She braids the dough into a loaf shape and prepares granola bars.", "task": "ActionRecognition", "clean_prompt": "A woman shaping bread dough in the kitchen.", "clean_property": {"obj": "woman", "action": "shaping bread dough", "target": "dough"}, "target_prompt": "A woman baking cookies in the kitchen.", "target_property": {"obj": "woman", "action": "baking cookies", "target": "cookies"}, "evaluation_question": "Is the woman **shaping bread dough**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman shaping bread dough in the kitchen. MV@KF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dc9b22093914f5591459c6e52ee06eb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bcce142db05c4fa29bd265acd468edf3", "source": "vatex", "video_id": "W0JLIG8Vo0s_000069_000079", "video_description": "A baby is sitting on a play mat in a playroom, playing with a toy xylophone.", "task": "Counting", "clean_prompt": "A baby is sitting on a play mat in a playroom, playing with two xylophones.", "clean_property": {"obj": "xylophone", "count": "two"}, "target_prompt": "A baby is sitting on a play mat in a playroom, playing with one xylophone.", "target_property": {"obj": "xylophone", "count": "one"}, "evaluation_question": "Are there exactly **two** xylophones in the playroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is sitting on a play mat in a playroom, playing with two xylophones. 2%SBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38f362208627445bb7bbce2d586bcb1c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2cf2655e89eb4bc6aa6d1807f679e8ec", "source": "vatex", "video_id": "o2mqzjWJJNw_000010_000020", "video_description": "A man is welding a metallic object outside near his house, wearing full safety gear including a helmet and face mask, using an electrical welding tool on a workbench.", "task": "Counting", "clean_prompt": "A man is using seven welding tools on a workbench outside near his house, wearing full safety gear including a helmet and face mask.", "clean_property": {"obj": "welding tool", "count": "seven"}, "target_prompt": "A man is using two welding tools on a workbench outside near his house, wearing full safety gear including a helmet and face mask.", "target_property": {"obj": "welding tool", "count": "two"}, "evaluation_question": "Are there exactly **seven** welding tools being used on the workbench?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using seven welding tools on a workbench outside near his house, wearing full safety gear including a helmet and face mask. !0D1B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd2a76333b594e03827942ff13793df8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "846d087892d64d7a8c5977f1331762d0", "source": "vatex", "video_id": "m2_qmRnjICE_000017_000027", "video_description": "A man in a black hoodie and trousers is picking apples in an orchard, carefully placing them in a bag and then into a wooden crate, while a narrator explains the process.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a wooden crate.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "crate"}, "target_prompt": "A person closer to the camera than a wooden crate.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "crate"}, "evaluation_question": "Is the person farther from the camera than a wooden crate?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a wooden crate. \u00b7))!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d61d69cc266b4abd8ece3b3ad194b336.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c140fa0a1cfe4e9ba6d3603daa889cb2", "source": "vatex", "video_id": "g-161r3ibds_000266_000276", "video_description": "A man is having his leg hair waxed by a woman using wax strips. The man is sitting with his leg extended on a table while the woman applies and removes the wax strips, showing them to the camera.", "task": "ObjectRecognition", "clean_prompt": "A man is sitting on a chair while a woman waxes his leg hair.", "clean_property": {"obj": "chair"}, "target_prompt": "A man is sitting on a sofa while a woman waxes his leg hair.", "target_property": {"obj": "sofa"}, "evaluation_question": "Is the man sitting on a **chair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on a chair while a woman waxes his leg hair. ))!',", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6db6167336c44b9a0c648ad5daf9e15.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0bd7581d05da42958a92793924acc5cb", "source": "vatex", "video_id": "Y2Y8uhqwBUs_000015_000025", "video_description": "A man is unboxing a package wrapped in plastic, showing its contents to the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a package while unboxing it.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "package"}, "target_prompt": "A person standing to the right of a package while unboxing it.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "package"}, "evaluation_question": "Is the person to the **left** of the package?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a package while unboxing it. FEA+.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6c075791270a4c89bc55b04ed5fe0031.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b7274ecb7e1435f89b545ff332a384d", "source": "vatex", "video_id": "UVZhX5N1rKE_000012_000022", "video_description": "A man wearing a hard hat and carrying a bucket is rappelling down the side of a tall building using a rope and harness, performing window cleaning.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a bucket while rappelling down a tall building.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "bucket"}, "target_prompt": "A person closer to the camera than a bucket while rappelling down a tall building.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "bucket"}, "evaluation_question": "Is the person farther from the camera than a bucket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a bucket while rappelling down a tall building. /LF|E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bce38afd66fe4f049a07de68ba10524e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "83ce97b8bedf4a78900b78d29b3a6607", "source": "vatex", "video_id": "Zr7VBWsIaA0_000025_000035", "video_description": "A man demonstrates how to open oysters and clams using a special knife and a towel for safety.", "task": "Counting", "clean_prompt": "Two men demonstrating how to open oysters and clams using a special knife and a towel for safety.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One man demonstrating how to open oysters and clams using a special knife and a towel for safety.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** men demonstrating how to open oysters and clams?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men demonstrating how to open oysters and clams using a special knife and a towel for safety. !D*))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6d6ec1c4ba304e7b90c473c62c7fcc41.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e51519b5fd8a4f66b8e374fc799996d0", "source": "vatex", "video_id": "o2mqzjWJJNw_000010_000020", "video_description": "A man is welding a metallic object outside near his house, wearing full safety gear including a helmet and face mask, using an electrical welding tool on a workbench.", "task": "ObjectRecognition", "clean_prompt": "A man welding a metallic object outside near his house, wearing full safety gear including a helmet and face mask, using an electrical welding tool on a workbench.", "clean_property": {"obj": "welding tool"}, "target_prompt": "A man soldering a metallic object outside near his house, wearing full safety gear including a helmet and face mask, using a soldering iron on a workbench.", "target_property": {"obj": "soldering iron"}, "evaluation_question": "Is the man using a **welding tool**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man welding a metallic object outside near his house, wearing full safety gear including a helmet and face mask, using an electrical welding tool on a workbench. 8ED@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/21316ccc97b84615b7ae22bf7f375b13.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e22a1556a763480986785338f3ac9cb6", "source": "vatex", "video_id": "tEpRURa-1gQ_000000_000010", "video_description": "A person is washing a golden retriever dog outside in the sunlight, using a bucket of water. The dog is being positioned and pulled towards the bucket during the bath.", "task": "ObjectRecognition", "clean_prompt": "A person washing a golden retriever dog outside in the sunlight with a bucket of water.", "clean_property": {"obj": "person"}, "target_prompt": "A person washing a cat outside in the sunlight with a bucket of water.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the animal being washed in the video a **dog**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person washing a golden retriever dog outside in the sunlight with a bucket of water. UB7SM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6e75dec07a4643d79aeaa54675504280.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "311ff3cfd8474d3caf38c5d7d4a1addf", "source": "vatex", "video_id": "mg4eMlZSbVI_000212_000222", "video_description": "A woman is demonstrating how to make a snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "task": "Counting", "clean_prompt": "A woman is demonstrating how to make three snowman dolls using a white sock, adding features like eyes and hats on a kitchen table.", "clean_property": {"obj": "snowman doll", "count": "three"}, "target_prompt": "A woman is demonstrating how to make one snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "target_property": {"obj": "snowman doll", "count": "one"}, "evaluation_question": "Are there exactly **three** snowman dolls being made?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to make three snowman dolls using a white sock, adding features like eyes and hats on a kitchen table. #TPBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e4a9ac7c95e45ce8cae74a74baf3b80.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c5571bf49004b6ea2381c352cce6ebd", "source": "vatex", "video_id": "8PAU5Mzg01g_000041_000051", "video_description": "In a bedroom, two young men argue about a card flipping game.", "task": "ActionRecognition", "clean_prompt": "A young man arguing in a bedroom.", "clean_property": {"obj": "young man", "action": "arguing", "target": null}, "target_prompt": "A young man laughing in a bedroom.", "target_property": {"obj": "young man", "action": "laughing", "target": null}, "evaluation_question": "Is the young man **arguing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man arguing in a bedroom. =-!T/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c811c5bacc9647a9a1b85c80df4fbb83.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e44d698d4d1f49af81dd91b03b19909e", "source": "vatex", "video_id": "LSbiHaeXIUU_000067_000077", "video_description": "A man is laying down flooring pieces by spreading adhesive and placing tiles on top, using a trowel and separators.", "task": "ActionRecognition", "clean_prompt": "A person laying tiles on the floor using a trowel and separators.", "clean_property": {"obj": "person", "action": "laying tiles", "target": null}, "target_prompt": "A person removing tiles from the floor using a crowbar.", "target_property": {"obj": "person", "action": "removing tiles", "target": null}, "evaluation_question": "Is the person **laying tiles**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person laying tiles on the floor using a trowel and separators. .?&SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d26f3b5491b4e1891680e5813ff7d0e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "92e8558983124d5988e874e9b9b58160", "source": "vatex", "video_id": "T1XpVz9-mMs_000002_000012", "video_description": "A man is demonstrating various techniques for tying knots using a red rope outdoors.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a red rope.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "rope"}, "target_prompt": "A person closer to the camera than a red rope.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "red rope"}, "evaluation_question": "Is the person **farther from the camera than** the red rope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a red rope. ;D#T.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a2ab454c97c41cb9c5b8a1c519d162d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca0147ad11004a8194056728065214c5", "source": "vatex", "video_id": "31mjIwvFr7s_000017_000027", "video_description": "A man in a messy room is attempting to demolish a white wall using a sledgehammer, creating holes in the process.", "task": "AttributeRecognition", "clean_prompt": "A man is attempting to demolish a white wall using a sledgehammer in a messy room.", "clean_property": {"obj": "wall", "attribute": "white"}, "target_prompt": "A man is attempting to demolish a blue wall using a sledgehammer in a messy room.", "target_property": {"obj": "wall", "attribute": "blue"}, "evaluation_question": "Is the wall **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is attempting to demolish a white wall using a sledgehammer in a messy room. (3%FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2fbcf02d98fc41afa37d5e676605f8d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "347f9c03ab4e48afa9d5ce7c9220d0cd", "source": "vatex", "video_id": "a-jZ3b7BMmA_000000_000010", "video_description": "A man is in a gym demonstrating various push-up exercises, including clapping and jumping in between push-ups.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating various push-up exercises in a gym.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating various push-up exercises in a gym.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating various push-up exercises in a gym. -WK*)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/efe7c671128547b7aff03a9feb238e10.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "337f98699c9243f4a4f671c6b230d453", "source": "vatex", "video_id": "FQH-fHyEBmc_000019_000029", "video_description": "A person in protective gear is using various hoses to clean and treat a wooden structure, including the underside of a roof and walls, with water, air, and chemicals.", "task": "Counting", "clean_prompt": "Three people in protective gear are using various hoses to clean and treat a wooden structure.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in protective gear is using a hose to clean a wooden structure.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in protective gear cleaning the structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in protective gear are using various hoses to clean and treat a wooden structure. !/!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8506fba474d418fbf51faaf42988e13.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae918978dd1347f8bdbba800ec4db3c2", "source": "vatex", "video_id": "4L8JlFs6MsY_000123_000133", "video_description": "A man is outdoors demonstrating and explaining how to properly clean a window using a squeegee.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a window, demonstrating how to clean it with a squeegee.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "window"}, "target_prompt": "A person further from the camera than a window, demonstrating how to clean it with a squeegee.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "window"}, "evaluation_question": "Is the person closer to the camera than the window?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a window, demonstrating how to clean it with a squeegee. W0DEH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3feebaa7bd154902adde4464de58baae.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "14b9326e9473445ebd97561cccbd14b7", "source": "vatex", "video_id": "5QXLmh3YNdM_000046_000056", "video_description": "A woman is outdoors using a rolling device to perform lunges and yoga poses, demonstrating various exercises.", "task": "AttributeRecognition", "clean_prompt": "A woman outdoors using a blue rolling device to perform lunges and yoga poses.", "clean_property": {"obj": "rolling device", "attribute": "blue"}, "target_prompt": "A woman outdoors using a red rolling device to perform lunges and yoga poses.", "target_property": {"obj": "rolling device", "attribute": "red"}, "evaluation_question": "Is the rolling device **blue**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman outdoors using a blue rolling device to perform lunges and yoga poses. QDY&M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24feea55052940669fe685380fb37ee0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8ce00597e94c496ca7659926421025d6", "source": "vatex", "video_id": "xfqst3Ql8cc_000009_000019", "video_description": "Three people are parasailing over the ocean, attached to a colorful parachute and being pulled by a fast-moving boat.", "task": "ObjectRecognition", "clean_prompt": "Three people parasailing over the ocean, attached to a colorful parachute and being pulled by a fast-moving boat.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running along the beach, playing in the sand and splashing in the waves.", "target_property": {"obj": "dog"}, "evaluation_question": "Are there **people** parasailing in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people parasailing over the ocean, attached to a colorful parachute and being pulled by a fast-moving boat. NK)1~", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bddd6a12bf204933adfa37f097841c32.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "25cb271ba5224c26bd1aeb8870ef235a", "source": "vatex", "video_id": "qGfEiJEu0AM_000003_000013", "video_description": "A person is seated in a room, playing a guitar on their lap in a unique way that includes strumming, plucking, and tapping the guitar for percussion, while singing.", "task": "ObjectRecognition", "clean_prompt": "A person seated in a room, playing a guitar on their lap, strumming, plucking, and tapping for percussion while singing.", "clean_property": {"obj": "person"}, "target_prompt": "A cat seated in a room, playing with a ball of yarn and making playful movements.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person seated in a room, playing a guitar on their lap, strumming, plucking, and tapping for percussion while singing. SAQFT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f95633c6aaab4997925b4e64df67b932.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b8bc2e72dfb4bbdab5ee31268dba5d4", "source": "vatex", "video_id": "g9s8fB6fc7k_000339_000349", "video_description": "A young girl in a spring dress is carrying a basket and searching for Easter eggs outside in a meadow and wooded area, while a man and woman watch.", "task": "AttributeRecognition", "clean_prompt": "A girl wearing a spring dress is carrying a basket and searching for Easter eggs in a meadow.", "clean_property": {"obj": "girl", "attribute": "wearing a spring dress"}, "target_prompt": "A girl wearing a winter coat is carrying a basket and searching for Easter eggs in a snowy landscape.", "target_property": {"obj": "girl", "attribute": "wearing a winter coat"}, "evaluation_question": "Is the girl wearing a **spring dress**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl wearing a spring dress is carrying a basket and searching for Easter eggs in a meadow. FE+=S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8393d9e20c03420898fc99d30a90c4a7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1af43bbd45a4b0bb275b933d59ca5cd", "source": "vatex", "video_id": "CzOWluWaxbg_000063_000073", "video_description": "A group of kids are participating in a hot dog eating contest while sitting on a bench. Some kids are standing and screaming. The contest ends with a boy at the end winning, and everyone cheers.", "task": "ActionRecognition", "clean_prompt": "A kid eating a hotdog at a contest.", "clean_property": {"obj": "kid", "action": "eating hotdog", "target": null}, "target_prompt": "A kid throwing a hotdog at a contest.", "target_property": {"obj": "kid", "action": "throwing hotdog", "target": null}, "evaluation_question": "Is the kid **eating** a hotdog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A kid eating a hotdog at a contest. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d7728c6a63b240658d5f7c12fbceb827.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4cbc048004bf497aba3565923e5ec248", "source": "vatex", "video_id": "YQEqUVwt8uE_000070_000080", "video_description": "A young girl is standing outside, holding a large snake wrapped around her hand. She is near a door of a vehicle and occasionally talks to a man in the background.", "task": "AttributeRecognition", "clean_prompt": "A young girl is standing outside, holding a large snake wrapped around her hand.", "clean_property": {"obj": "snake", "attribute": "large"}, "target_prompt": "A young girl is standing outside, holding a small snake wrapped around her hand.", "target_property": {"obj": "snake", "attribute": "small"}, "evaluation_question": "Is the snake **large**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is standing outside, holding a large snake wrapped around her hand. UF\u00b77E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec6aa343c40a45b8820c79d1e72ab158.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8008620b4405413e81ee49bd11706585", "source": "vatex", "video_id": "x4j1gW2wG8E_000000_000010", "video_description": "A young woman is demonstrating how to perform lunges and squats correctly in a gym setting.", "task": "ActionRecognition", "clean_prompt": "A person squatting in a gym setting.", "clean_property": {"obj": "person", "action": "squat", "target": null}, "target_prompt": "A person jumping in a gym setting.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **squatting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person squatting in a gym setting. ))0!|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/00851683b0a74df38b75e038d6d96b3c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "be775e99bf9d4d6d814d5cf552e1550d", "source": "vatex", "video_id": "W9UK_TCYoA8_000003_000013", "video_description": "A man is timing himself while attaching a pre-tied necktie to his collar, using a stopwatch or phone to measure the time.", "task": "AttributeRecognition", "clean_prompt": "A man is timing himself while attaching a pre-tied necktie to his collar.", "clean_property": {"obj": "necktie", "attribute": "pre-tied"}, "target_prompt": "A man is timing himself while attaching a self-tied necktie to his collar.", "target_property": {"obj": "necktie", "attribute": "self-tied"}, "evaluation_question": "Is the necktie **pre-tied**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is timing himself while attaching a pre-tied necktie to his collar. ))!W*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4cf86da4091a4dfabe9fb501e7080dd3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c21dee643e254b228a707abcecc1d64e", "source": "vatex", "video_id": "3nhUQtCrpQc_000262_000272", "video_description": "A woman is sitting in a chair while another person, sometimes identified as a woman or a gentleman, is brushing, playing with, and massaging her hair.", "task": "ObjectRecognition", "clean_prompt": "A standing person is interacting with another person who is brushing their hair.", "clean_property": {"obj": "standing person"}, "target_prompt": "A sitting person is interacting with another person who is brushing their hair.", "target_property": {"obj": "sitting person"}, "evaluation_question": "Is the person in the video **standing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A standing person is interacting with another person who is brushing their hair. SL&WM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c7788c2bca604632ad4cfbe3f7b1887c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "69e5d2b0a0b94dec84cd65bfb373768a", "source": "vatex", "video_id": "LGsslQpXVY0_000025_000035", "video_description": "A man is in a kitchen using a cooking pot to iron a pair of pants while a woman laughs.", "task": "Counting", "clean_prompt": "Seven women laughing together in a kitchen.", "clean_property": {"obj": "woman", "count": "seven"}, "target_prompt": "Four women cooking together in a kitchen.", "target_property": {"obj": "woman", "count": "four"}, "evaluation_question": "Are there exactly **seven** women in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven women laughing together in a kitchen. D%((!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/08b304a2a725460ca01e6e3aafc7a45e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a16b7626c9e6475ba76b7b87f81c7ed0", "source": "vatex", "video_id": "71qRCvVL8wM_000029_000039", "video_description": "A man is pretending to have a phone conversation by playing two different characters, switching back and forth between them, using exaggerated facial expressions.", "task": "ActionRecognition", "clean_prompt": "A person talking on a cell phone, pretending to have a conversation by switching between two characters with exaggerated facial expressions.", "clean_property": {"obj": "person", "action": "talking on cell phone", "target": null}, "target_prompt": "A person talking to a dog, pretending to have a conversation by switching between two characters with exaggerated facial expressions.", "target_property": {"obj": "person", "action": "talking to a friend", "target": "dog"}, "evaluation_question": "Is the person **talking on a cell phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person talking on a cell phone, pretending to have a conversation by switching between two characters with exaggerated facial expressions. =7SLF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c98578010bd48a493149a400ade56ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b36a1c801db84baaae3eca314199a18d", "source": "vatex", "video_id": "YCh5-mKZcOY_000062_000072", "video_description": "A woman is in a kitchen cooking sausages in a pan, putting a lid on it, and explaining how to make a dressing.", "task": "AttributeRecognition", "clean_prompt": "A woman chef cooking sausages in a kitchen.", "clean_property": {"obj": "woman", "attribute": "chef"}, "target_prompt": "A woman baker preparing pastries in a bakery.", "target_property": {"obj": "woman", "attribute": "baker"}, "evaluation_question": "Is the woman a **chef**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman chef cooking sausages in a kitchen. HS2Y@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b663c5769da40af91f73e584bfed345.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46ed6f3a913d460d939c0a3fd92c1bcb", "source": "vatex", "video_id": "-EtxOLPc5mw_000063_000073", "video_description": "A little girl in a dress is playing, walking, and occasionally falling in a bouncy house.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the left of a bouncy house.", "clean_property": {"obj_1": "girl", "relation": "left of", "obj_2": "bouncy house"}, "target_prompt": "A girl standing to the right of a bouncy house.", "target_property": {"obj_1": "girl", "relation": "right of", "obj_2": "bouncy house"}, "evaluation_question": "Is the girl to the **left** of the bouncy house?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the left of a bouncy house. @QA(Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd740cbeacd547a1b2c0e0244506b1ca.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "92b14f82e897459099e3462a757bfd0d", "source": "vatex", "video_id": "L0-klmDvEos_001296_001306", "video_description": "A man is sitting outdoors on a stool or low chair, displaying and examining various rocks, pottery shards, and antiquated tools like round clubs and mortars.", "task": "AttributeRecognition", "clean_prompt": "A man is sitting outdoors on a stool, examining various rocks, pottery shards, and antiquated tools like round clubs and mortars.", "clean_property": {"obj": "tools", "attribute": "antiquated"}, "target_prompt": "A man is sitting outdoors on a stool, examining various rocks, pottery shards, and modern tools like hammers and screwdrivers.", "target_property": {"obj": "tools", "attribute": "modern"}, "evaluation_question": "Are the tools being examined by the man antiquated?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting outdoors on a stool, examining various rocks, pottery shards, and antiquated tools like round clubs and mortars. FE5EK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c7841e343b874ad1ae18b0e117bdf4d3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3ea58c8c5180471b95ed3aae94562d16", "source": "vatex", "video_id": "GJJ_5dPMZ2c_000038_000048", "video_description": "A young man wearing black is dancing enthusiastically to music in his living room, with bags on the wall.", "task": "ActionRecognition", "clean_prompt": "A person singing in a living room.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing to music in a living room.", "target_property": {"obj": "person", "action": "dancing", "target": "music"}, "evaluation_question": "Is the person **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person singing in a living room. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5985a0f0eb774dcda29242de0d92aa07.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1e317f2e2dd4acea3150558c0bb45b7", "source": "vatex", "video_id": "LBjfN2PFv1w_000074_000084", "video_description": "A person is cooking and serving a sunny side up fried egg using a hotplate and spatula.", "task": "SpatialUnderstanding", "clean_prompt": "A hotplate farther from the camera than a plate.", "clean_property": {"obj_1": "hotplate", "relation": "farther from the camera than", "obj_2": "plate"}, "target_prompt": "A hotplate closer to the camera than a plate.", "target_property": {"obj_1": "hotplate", "relation": "closer to the camera than", "obj_2": "plate"}, "evaluation_question": "Is the hotplate **farther from the camera than** the plate?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A hotplate farther from the camera than a plate. TZD$E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/09060d4ed9c0479395d7398e58d63b53.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2f93360bb43448daa4a5a27e86ccce7", "source": "vatex", "video_id": "8YJ9Pxj6BCc_000021_000031", "video_description": "A child rides a bike and a scooter down a hill, crashes at the bottom, while another child laughs.", "task": "ObjectRecognition", "clean_prompt": "A child rides a bike and a scooter down a hill, crashes at the bottom, while another child laughs.", "clean_property": {"obj": "child_3"}, "target_prompt": "An adult rides a bike and a scooter down a hill, crashes at the bottom, while another adult laughs.", "target_property": {"obj": "adult"}, "evaluation_question": "Is the person riding the bike and scooter a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child rides a bike and a scooter down a hill, crashes at the bottom, while another child laughs. LFESV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cb7019a02ba41de828c96a5e47aa550.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d0812f70b517498fa00e987a3b644da8", "source": "vatex", "video_id": "Jh1dYYpOTWU_000000_000010", "video_description": "A man wearing a helmet rides a bicycle across a porch, jumps over a set of stairs, and lands safely on the ground.", "task": "ActionRecognition", "clean_prompt": "A person riding a bike across a porch.", "clean_property": {"obj": "person", "action": "riding a bike", "target": null}, "target_prompt": "A person skateboarding across a porch.", "target_property": {"obj": "person", "action": "skateboarding", "target": null}, "evaluation_question": "Is the person **riding a bike**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a bike across a porch. !0||&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ca95bd4cbea14cdf8402dbfa3353b243.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f3ddb250a0fe41fe80abae5b66085f84", "source": "vatex", "video_id": "wXmNSFXaAyY_000749_000759", "video_description": "A middle-aged couple and an older man sit around a rustic kitchen table. A woman waves at a camera while two men are talking.", "task": "ObjectRecognition", "clean_prompt": "A middle-aged couple and an older man sit around a rustic kitchen table. A woman waves at a camera while two men are talking.", "clean_property": {"obj": "camera"}, "target_prompt": "A middle-aged couple and an older man sit around a rustic kitchen table. A woman waves at a microphone while two men are talking.", "target_property": {"obj": "microphone"}, "evaluation_question": "Is there a **camera** present in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A middle-aged couple and an older man sit around a rustic kitchen table. A woman waves at a camera while two men are talking. FEYUJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e59fd10c99904e6aaacc6478dcf52d0c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f3aa5cc5e16c40e494a9260085f15699", "source": "vatex", "video_id": "KeqTgvq6PpQ_000077_000087", "video_description": "A man is outdoors on a winter day, chopping and splitting wood logs with an axe. The logs are arranged in a circle and some are strapped together. There is snow on the ground.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than the logs, outdoors on a winter day, chopping and splitting wood logs with an axe.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "logs"}, "target_prompt": "A man closer to the camera than the logs, outdoors on a winter day, chopping and splitting wood logs with an axe.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "logs"}, "evaluation_question": "Is the man **farther from the camera than** the logs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than the logs, outdoors on a winter day, chopping and splitting wood logs with an axe. SFEYU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9cf9df113cc4e8ca009ec1c334964fb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c190c803d87647c4b4da2593b56b762c", "source": "vatex", "video_id": "uk0GF4oBtZ8_000036_000046", "video_description": "A woman is demonstrating how to clip fingernails, counting each nail as she clips, in a therapy-like setting.", "task": "ActionRecognition", "clean_prompt": "A woman cutting nails on a child in a therapy-like setting.", "clean_property": {"obj": "woman", "action": "cutting nails", "target": "child"}, "target_prompt": "A woman painting nails on a child in a therapy-like setting.", "target_property": {"obj": "woman", "action": "painting nails", "target": "child"}, "evaluation_question": "Is the woman **cutting nails** on the child?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman cutting nails on a child in a therapy-like setting. N-/))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d14e87974d714e5ab026aa5c4867d68f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57d3e18c644e4f8f8ff3be97f7a1955e", "source": "vatex", "video_id": "DJ6EhnhrQsg_000000_000010", "video_description": "Two children, a boy and a girl, are in a bathroom or locker room drying their hair with white blow dryers.", "task": "AttributeRecognition", "clean_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers.", "clean_property": {"obj": "blow dryer", "attribute": "white"}, "target_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with black blow dryers.", "target_property": {"obj": "blow dryer", "attribute": "black"}, "evaluation_question": "Are the blow dryers **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers. >DEAJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3dc094bdd95c423a8b4d27f2e11f7317.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dbc764e013a44f8a842f673db6308a94", "source": "vatex", "video_id": "0hWgePf9Vfw_000199_000209", "video_description": "A child is making an origami paper airplane using scissors and folding techniques at a table.", "task": "ObjectRecognition", "clean_prompt": "A child is making an origami paper airplane at a table using scissors and folding techniques.", "clean_property": {"obj": "child"}, "target_prompt": "An adult is making an origami paper airplane at a table using scissors and folding techniques.", "target_property": {"obj": "adult"}, "evaluation_question": "Is the person in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is making an origami paper airplane at a table using scissors and folding techniques. ;TZ?P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/03156ea30ce84320a603719943f7ee32.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "78c3dd46771f4ad6a8cf05458ad56ca7", "source": "vatex", "video_id": "THwHCIdsEHc_000044_000054", "video_description": "A man is in a gym performing deadlifts with a barbell loaded with heavy weights, wearing headphones.", "task": "Counting", "clean_prompt": "Seven people are in a gym, watching a man perform deadlifts with a barbell loaded with heavy weights, while he wears headphones.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "One person is in a gym, performing deadlifts with a barbell loaded with heavy weights, while wearing headphones.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **seven** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are in a gym, watching a man perform deadlifts with a barbell loaded with heavy weights, while he wears headphones. )'W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46cc35a1523c4c808ff01c1f801f487c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac8682f498b84169827071bcc080ec9a", "source": "vatex", "video_id": "4kixfScXLX0_000067_000077", "video_description": "A family gathering where two children are playing Twister on the floor while adults watch, drink, and smoke.", "task": "AttributeRecognition", "clean_prompt": "An adult in 70's style clothing watching children play Twister at a family gathering.", "clean_property": {"obj": "adult", "attribute": "70's style"}, "target_prompt": "An adult in modern casual style watching children play Twister at a family gathering.", "target_property": {"obj": "adult", "attribute": "modern casual style"}, "evaluation_question": "Is the adult wearing **70's style** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult in 70's style clothing watching children play Twister at a family gathering. MJBMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/17c518bdcb864ee2bf95a287cb99336b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "205d9fd84daf43639933608fd7906e74", "source": "vatex", "video_id": "IkEmoLzENaQ_000013_000023", "video_description": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background.", "task": "Counting", "clean_prompt": "A man and a woman are sitting on a couch, kissing passionately while five men talk in the background.", "clean_property": {"obj": "man", "count": "five"}, "target_prompt": "A man and a woman are sitting on a couch, kissing passionately while two men talk in the background.", "target_property": {"obj": "man", "count": "two"}, "evaluation_question": "Are there exactly **five** men talking in the background?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are sitting on a couch, kissing passionately while five men talk in the background. W%!))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c99f1cbc90c147bfbeece25e4f6f4832.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f2073a0751664e64b77ab482fa5d8665", "source": "vatex", "video_id": "RybJjqxR_e4_000134_000144", "video_description": "A young man, identified as an 'assignment expert' by his T-shirt, is demonstrating and explaining complex mathematical problems on a clear screen board using a white marker.", "task": "AttributeRecognition", "clean_prompt": "A young man identified as an 'assignment expert' by his T-shirt is demonstrating and explaining complex mathematical problems on a clear screen board using a white marker.", "clean_property": {"obj": "marker", "attribute": "white"}, "target_prompt": "A young man identified as an 'assignment expert' by his T-shirt is demonstrating and explaining complex mathematical problems on a clear screen board using a red marker.", "target_property": {"obj": "marker", "attribute": "red"}, "evaluation_question": "Is the young man using a **white** marker?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man identified as an 'assignment expert' by his T-shirt is demonstrating and explaining complex mathematical problems on a clear screen board using a white marker. /?B*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6c123179c97647ec8d5b75b24310613d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7e48a996edc541b48a2fce64958f2564", "source": "vatex", "video_id": "k8oNh6lcuOg_000014_000024", "video_description": "A man is sitting in a chair while a young girl uses electric clippers to shave his head.", "task": "Counting", "clean_prompt": "A man is sitting in a chair while a young girl uses two electric clippers to shave his head.", "clean_property": {"obj": "electric clippers", "count": "two"}, "target_prompt": "A man is sitting in a chair while a young girl uses one electric clipper to shave his head.", "target_property": {"obj": "electric clippers", "count": "one"}, "evaluation_question": "Are there exactly **two** electric clippers being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting in a chair while a young girl uses two electric clippers to shave his head. '');!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a465ee2b22f84b1095b12beb28e62126.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3705357896594d539d464824c5ed99e4", "source": "vatex", "video_id": "bqHFdldKo-k_000922_000932", "video_description": "A person is sitting on the ground, using a white cloth to polish and shine the black leather shoes they are wearing.", "task": "Counting", "clean_prompt": "A person is sitting on the ground, using seven pieces of cloth to polish and shine the black leather shoes they are wearing.", "clean_property": {"obj": "cloth", "count": "seven"}, "target_prompt": "A person is sitting on the ground, using three pieces of cloth to polish and shine the black leather shoes they are wearing.", "target_property": {"obj": "cloth", "count": "three"}, "evaluation_question": "Are there exactly **seven** pieces of cloth being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is sitting on the ground, using seven pieces of cloth to polish and shine the black leather shoes they are wearing. ELLJ)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c81d6e4d52924811a0eac7e9900dfb9a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1f98189d4d0b409ebec8c95ca6817215", "source": "vatex", "video_id": "i8MIQuEsVTg_000000_000010", "video_description": "A woman is demonstrating how to slice a large piece of pork into smaller pieces using a large, sharp knife.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating how to slice a large piece of pork using a large, sharp knife.", "clean_property": {"obj": "knife", "attribute": "sharp"}, "target_prompt": "A woman demonstrating how to slice a large piece of pork using a large, blunt knife.", "target_property": {"obj": "knife", "attribute": "blunt"}, "evaluation_question": "Is the knife **sharp**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to slice a large piece of pork using a large, sharp knife. !))*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/43366f6e49a44915bce4593826236867.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4342de1e8fe444a1a4f9c708aadb55a1", "source": "vatex", "video_id": "xBNJ8tSeRhQ_000000_000010", "video_description": "A man is performing one-handed and one-finger push-ups outdoors on a brick or pavement surface.", "task": "ObjectRecognition", "clean_prompt": "A man performing one-handed and one-finger push-ups outdoors on a brick surface.", "clean_property": {"obj": "person"}, "target_prompt": "A woman performing one-handed and one-finger push-ups outdoors on a brick surface.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the performer in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing one-handed and one-finger push-ups outdoors on a brick surface. >BSMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb8f2c950ed74056b95d079ca35ead66.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "36fcdcd988294c8eb2d847f8633a4322", "source": "vatex", "video_id": "iGpkNVakUQw_000162_000172", "video_description": "Two young males are seated at a table in a public space, eating doughnuts and having a conversation. One of them stacks two doughnuts together.", "task": "Counting", "clean_prompt": "Two young males are seated at a table with three doughnuts in a public space, eating and having a conversation.", "clean_property": {"obj": "table", "count": "three"}, "target_prompt": "Two young males are seated at one table with doughnuts in a public space, eating and having a conversation.", "target_property": {"obj": "table", "count": "one"}, "evaluation_question": "Are there exactly **three** tables in the public space?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young males are seated at a table with three doughnuts in a public space, eating and having a conversation. &$NU7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cf13c8bd02a64f468c78993b936c81c4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "621d51cda7a14045be9c5261a692bbb7", "source": "vatex", "video_id": "b1x_oZ11U0Y_000016_000026", "video_description": "A large group of people are playing various percussion instruments, including xylophones, maracas, and drums, outside in a parking lot or street.", "task": "Counting", "clean_prompt": "Two musicians playing percussion instruments in a parking lot.", "clean_property": {"obj": "musician", "count": "two"}, "target_prompt": "Four musicians playing percussion instruments in a park.", "target_property": {"obj": "musician", "count": "four"}, "evaluation_question": "Are there exactly **two** musicians playing in the parking lot?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two musicians playing percussion instruments in a parking lot. !0D0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/633a70e8d20a432ca5cda4e114065600.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90c1fb086f224b4fa5acab1e0907f92d", "source": "vatex", "video_id": "k1peqGMGvAc_000000_000010", "video_description": "A person is outdoors in front of a garage, practicing jump rope techniques for boxing training.", "task": "ActionRecognition", "clean_prompt": "A person skipping rope outdoors in front of a garage.", "clean_property": {"obj": "person", "action": "skipping rope", "target": null}, "target_prompt": "A person jogging outdoors in front of a garage.", "target_property": {"obj": "person", "action": "jogging", "target": null}, "evaluation_question": "Is the person **skipping rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person skipping rope outdoors in front of a garage. 8RRVP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bab4415061d34e8595800799e56ca5a9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "23a38d66a62449aeb4269f46f9128b77", "source": "vatex", "video_id": "GoXR-RIJXV4_000000_000010", "video_description": "A girl performs a series of back flips on a mat in a gym.", "task": "ActionRecognition", "clean_prompt": "A girl performing a somersault in a gym.", "clean_property": {"obj": "girl", "action": "somersaulting", "target": null}, "target_prompt": "A girl jumping on a trampoline in a gym.", "target_property": {"obj": "girl", "action": "jumping", "target": "trampoline"}, "evaluation_question": "Is the girl **somersaulting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing a somersault in a gym. F%D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b746dbb0b1874b0e96922a4cf8428533.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b4ab6b899c424ac58bfbfd238add82aa", "source": "vatex", "video_id": "bM7dNsdx7JA_000001_000011", "video_description": "A man is standing on a stage playing a ukulele and singing into a microphone, occasionally leaning toward the crowd.", "task": "ObjectRecognition", "clean_prompt": "A musician standing on a stage playing a ukulele and singing into a microphone.", "clean_property": {"obj": "musician"}, "target_prompt": "A painter creating a mural on a large canvas.", "target_property": {"obj": "painter"}, "evaluation_question": "Is the person in the video a **musician**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician standing on a stage playing a ukulele and singing into a microphone. )PDSX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8fd242e1e20c47b7888e6b5407074f89.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6505e77a669c44a98342f15aa33e75a0", "source": "vatex", "video_id": "5MIZPTc10uU_000017_000027", "video_description": "A young girl is in her living room demonstrating and explaining how to solve a Rubik's Cube, naming the colors and showing how to play with it.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the right of a Rubik's Cube.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "rubik's cube"}, "target_prompt": "A girl standing to the left of a Rubik's Cube.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "rubik's cube"}, "evaluation_question": "Is the girl to the **right** of a Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the right of a Rubik's Cube. BSQ2G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a183b33e62764d1c8480c7bb9f9bde5c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c0b66379aa1047a8921ecda738edd7e5", "source": "vatex", "video_id": "nDHHn9MxshU_000005_000015", "video_description": "A man is performing in a shopping area, sitting with a guitar on his lap, singing into a microphone.", "task": "ActionRecognition", "clean_prompt": "A person playing guitar in a shopping area.", "clean_property": {"obj": "person", "action": "playing guitar", "target": null}, "target_prompt": "A person playing piano in a shopping area.", "target_property": {"obj": "person", "action": "playing piano", "target": null}, "evaluation_question": "Is the person **playing guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing guitar in a shopping area. RY.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/36bd6215d2624ee0ac20e2cd1dab1a70.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "daceb32c37c841109e817a5178b69f3a", "source": "vatex", "video_id": "d9Gtq_qQguk_000030_000040", "video_description": "A man is playing a unique string instrument, similar to a guitar, in front of a store and gas station.", "task": "ObjectRecognition", "clean_prompt": "A man playing a unique string instrument in front of a store and gas station.", "clean_property": {"obj": "person"}, "target_prompt": "A woman playing a unique string instrument in front of a store and gas station.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the musician in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing a unique string instrument in front of a store and gas station. !D'?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b99949ef0154fbc977a760c0da8b5ed.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "da544cbde9aa45c8a01531f38b183e2f", "source": "vatex", "video_id": "LB5GuxpNNcg_000028_000038", "video_description": "People are interacting with a display of earrings in a store, examining and switching them between hooks.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than an earring in a store display.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "earring"}, "target_prompt": "A person further from the camera than an earring in a store display.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "earring"}, "evaluation_question": "Is the person **closer to the camera than** the earring?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than an earring in a store display. SL$GG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b91372fcd71e43278ec7bc3e1106d4c2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a20b5a8d7264bc0ba854c67a0620e24", "source": "vatex", "video_id": "N7PyPtN3iDs_000016_000026", "video_description": "A man is operating a snow blower to clear snow from a driveway and roadway on a snowy day.", "task": "Counting", "clean_prompt": "Two people operating a snow blower to clear snow from a driveway on a snowy day.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person operating a snow blower to clear snow from a driveway on a snowy day.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people operating the snow blower?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people operating a snow blower to clear snow from a driveway on a snowy day. =@ZBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a214cae7d66a4c26922e5db534e6e73f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cdbfdb33bdcb4c19b2a2ede513528b3f", "source": "vatex", "video_id": "ATGGerW1bnQ_000012_000022", "video_description": "A dog is being groomed on a table by a woman in a pink shirt. The dog is on a leash and is being offered treats while its fur is brushed and cut.", "task": "Counting", "clean_prompt": "A woman in a pink shirt is grooming a dog on a table with seven treats nearby.", "clean_property": {"obj": "table", "count": "seven"}, "target_prompt": "A woman in a pink shirt is grooming a dog on a table with three treats nearby.", "target_property": {"obj": "table", "count": "three"}, "evaluation_question": "Are there exactly **seven** treats nearby the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a pink shirt is grooming a dog on a table with seven treats nearby. !0D=|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78e74f948e9e44e89b243e5fb95ddb30.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90433f4d0da341a98012d9b7010bc2f0", "source": "vatex", "video_id": "EBNDZ7IKQ5c_000006_000016", "video_description": "A young boy is skateboarding in a snowy environment. He attempts to jump off a wooden deck or stairs but slips and falls on the icy ground.", "task": "SpatialUnderstanding", "clean_prompt": "A skateboard farther from the camera than the stairs in a snowy environment.", "clean_property": {"obj_1": "skateboard", "relation": "farther from the camera than", "obj_2": "stairs"}, "target_prompt": "A skateboard closer to the camera than the stairs in a snowy environment.", "target_property": {"obj_1": "skateboard", "relation": "closer to the camera than", "obj_2": "stairs"}, "evaluation_question": "Is the skateboard **farther from the camera than** the stairs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skateboard farther from the camera than the stairs in a snowy environment. RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/491cb7adf2af4f24bcb93c2aa9e06ded.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c69ed04c323e45db8bd6ddee450d11e8", "source": "vatex", "video_id": "RadfPQjOJTs_000791_000801", "video_description": "A woman is adjusting and arranging a Christmas tree in a living room, talking on her cellphone while ensuring the tree is straight and well-lit.", "task": "AttributeRecognition", "clean_prompt": "A woman is adjusting and arranging a lighted Christmas tree in a living room while talking on her cellphone.", "clean_property": {"obj": "Christmas tree", "attribute": "lighted"}, "target_prompt": "A woman is adjusting and arranging an unlit Christmas tree in a living room while talking on her cellphone.", "target_property": {"obj": "Christmas tree", "attribute": "unlit"}, "evaluation_question": "Is the Christmas tree **lighted**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is adjusting and arranging a lighted Christmas tree in a living room while talking on her cellphone. \u00b7!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c8326a9a9be84f0f903af86140972367.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42826e825d8440f4bc55c93861670550", "source": "vatex", "video_id": "HnBTadnbmlY_000519_000529", "video_description": "A young man wearing a helmet is skateboarding downhill on a wet road in the woods, followed by a car that is recording the activity.", "task": "Counting", "clean_prompt": "Two people skateboarding downhill on a wet road in the woods.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person skateboarding downhill on a wet road in the woods.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people skateboarding downhill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people skateboarding downhill on a wet road in the woods. UF+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/326393dd12e249faa575ca6995551ba9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c03748904c25412296665563c0ea4538", "source": "vatex", "video_id": "W-64tYeFF5I_000014_000024", "video_description": "A group of children are playing dodgeball in a gymnasium using yellow rubber balls.", "task": "ObjectRecognition", "clean_prompt": "A group of children are playing dodgeball in a gymnasium with yellow rubber balls.", "clean_property": {"obj": "children"}, "target_prompt": "A group of adults are playing volleyball in a gymnasium with blue volleyballs.", "target_property": {"obj": "adults"}, "evaluation_question": "Are the players in the video **children**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children are playing dodgeball in a gymnasium with yellow rubber balls. !D9*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/00c20e53812d4a35a2f9b9253747d64e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c8f087abad2a4f64b15a2aab9169e69d", "source": "vatex", "video_id": "WCdlpVUrbWs_000019_000029", "video_description": "A young girl in a pink tutu is playing hopscotch and dancing in a dance studio with the guidance of an adult instructor dressed in black. The music 'Oh Susannah' is playing on the piano in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the left of an instructor in a dance studio.", "clean_property": {"obj_1": "girl", "relation": "left of", "obj_2": "instructor"}, "target_prompt": "A girl standing to the right of an instructor in a dance studio.", "target_property": {"obj_1": "girl", "relation": "right of", "obj_2": "instructor"}, "evaluation_question": "Is the girl to the **left** of the instructor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the left of an instructor in a dance studio. FE@()", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1de05048cf404c4cba85248063c73195.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c9d259d6e44040368d236932ee8ade44", "source": "vatex", "video_id": "e26p7hcUy9U_000488_000498", "video_description": "A person is demonstrating how to spray paint an electronic item gray, kneeling on the floor with the item on a table covered with a white tablecloth.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to spray paint an electronic item gray, kneeling on the floor with the item on a table covered with a white tablecloth.", "clean_property": {"obj": "table", "attribute": "covered with white tablecloth"}, "target_prompt": "A person demonstrating how to spray paint an electronic item gray, kneeling on the floor with the item on a table covered with a black tablecloth.", "target_property": {"obj": "table", "attribute": "covered with a black tablecloth"}, "evaluation_question": "Is the table covered with a **white** tablecloth?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to spray paint an electronic item gray, kneeling on the floor with the item on a table covered with a white tablecloth. EET\u00b7M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ecdd6bb75e7a47d0a8b7f61cc645b98b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5b2c806c10d7432fa030b75d896a057a", "source": "vatex", "video_id": "l6_2Ax9-3DQ_000063_000073", "video_description": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles.", "task": "ActionRecognition", "clean_prompt": "A person knitting with red yarn and knitting needles.", "clean_property": {"obj": "person", "action": "knitting", "target": null}, "target_prompt": "A person crocheting with colorful yarn and a crochet hook.", "target_property": {"obj": "person", "action": "crocheting", "target": null}, "evaluation_question": "Is the person **knitting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person knitting with red yarn and knitting needles. )/(&D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4899d7093f4847d090a0d3bea4f4bda4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "11eaf1dbd9c64d27b794fb4447600eba", "source": "vatex", "video_id": "BzxSeJSnqV0_000009_000019", "video_description": "A young boy performs a flexible and acrobatic dance routine on stage in front of an audience, accompanied by music.", "task": "AttributeRecognition", "clean_prompt": "A boy performing a flexible and acrobatic dance routine on stage in front of an audience.", "clean_property": {"obj": "boy", "attribute": "flexible"}, "target_prompt": "A boy performing a rigid and stiff dance routine on stage in front of an audience.", "target_property": {"obj": "boy", "attribute": "rigid"}, "evaluation_question": "Is the boy performing a **flexible** dance routine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy performing a flexible and acrobatic dance routine on stage in front of an audience. &>BCS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98b329c06838439cb8593da3b2fa77fd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46409b7c5f744acfae59408c8ed010ce", "source": "vatex", "video_id": "kOf-vl-GmVI_000115_000125", "video_description": "A woman is riding a horse in a fenced area, occasionally petting the horse.", "task": "ActionRecognition", "clean_prompt": "A person petting a horse in a fenced area.", "clean_property": {"obj": "person", "action": "petting animal (not cat)", "target": "horse"}, "target_prompt": "A person feeding a horse in a fenced area.", "target_property": {"obj": "person", "action": "feeding animal", "target": "horse"}, "evaluation_question": "Is the person **petting** the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person petting a horse in a fenced area. RL83>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fbe2b41b3534711873db887c00de82b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "812693f5b3504d6186fb9ca4fd86aec0", "source": "vatex", "video_id": "-0sNYhpevoU_000000_000010", "video_description": "A man with black hair and a receding hairline is massaging his own head in a kitchen.", "task": "Counting", "clean_prompt": "Seven people are gathered in a kitchen, chatting and laughing together.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are gathered in a kitchen, chatting and laughing together.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are gathered in a kitchen, chatting and laughing together. ?))*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4350678277da47b78f83c2c3f57d4453.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4cd021b9c0cc44aeb97a44f99875b8b4", "source": "vatex", "video_id": "pjSt3ZBs7hQ_000025_000035", "video_description": "Two young boys are unboxing a new headset and discussing it while speaking a foreign language.", "task": "ObjectRecognition", "clean_prompt": "Two young boys are unboxing a new headset from a box and discussing it while speaking a foreign language.", "clean_property": {"obj": "box"}, "target_prompt": "Two young boys are unboxing a new headset from a bag and discussing it while speaking a foreign language.", "target_property": {"obj": "bag"}, "evaluation_question": "Are the boys unboxing the headset from a **box**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys are unboxing a new headset from a box and discussing it while speaking a foreign language. =ED7.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/93a2899b66314c1b83e9d068970ba78a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bace10393c5c4cf89c20def60297e71e", "source": "vatex", "video_id": "kZmT74BWtuE_000000_000010", "video_description": "Two teenagers, a boy and a girl, are sharpening pencils using a manual sharpener mounted on a wall. The girl sharpens her pencil slowly while the boy sharpens his quickly. The sound of a motorcycle plays in the background.", "task": "ActionRecognition", "clean_prompt": "A teenager sharpening a pencil using a manual sharpener mounted on a wall.", "clean_property": {"obj": "teenager", "action": "sharpening pencil", "target": null}, "target_prompt": "A teenager drawing on a piece of paper.", "target_property": {"obj": "teenager", "action": "drawing", "target": null}, "evaluation_question": "Is the teenager **sharpening a pencil**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenager sharpening a pencil using a manual sharpener mounted on a wall. %B&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f199ad58338a4839ba973e502a73349e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7e1c5728376a42619e3dc68b1765cdaa", "source": "vatex", "video_id": "V7r_lGdJiko_000014_000024", "video_description": "A person in protective gear is welding metal on a scaffolding with decorations, creating sparks.", "task": "SpatialUnderstanding", "clean_prompt": "A welding torch to the left of a piece of metal as a person in protective gear welds on scaffolding, creating sparks.", "clean_property": {"obj_1": "welding torch", "relation": "left of", "obj_2": "metal"}, "target_prompt": "A welding torch to the right of a piece of metal as a person in protective gear welds on scaffolding, creating sparks.", "target_property": {"obj_1": "welding torch", "relation": "right of", "obj_2": "metal"}, "evaluation_question": "Is the welding torch to the **left** of the metal?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A welding torch to the left of a piece of metal as a person in protective gear welds on scaffolding, creating sparks. DYEKP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f42f63dc848943be9f91b2ab884f8766.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "851cedabb1fe46c19eba6d9fc26710e9", "source": "vatex", "video_id": "8YBGHniZSVA_000000_000010", "video_description": "A young woman is performing a modified jumping jack exercise outdoors in a field or park, with music playing in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than the music in a field.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "music"}, "target_prompt": "A person closer to the camera than the music in a field.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "music"}, "evaluation_question": "Is the person **farther from the camera than** the music?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than the music in a field. FE()V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0bf25d81c8c343739625cb343c082e61.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "48c1fb69f947415dacc5bf5b34a7012e", "source": "vatex", "video_id": "ADbYYql06k4_000027_000037", "video_description": "A group of people, including kids and adults, are in a creek or river. Some are playing in the water, while others are catching fish with nets as the fish jump out of the water.", "task": "ObjectRecognition", "clean_prompt": "A group of people, including kids and adults, are playing in a creek, some catching fish with nets.", "clean_property": {"obj": "person"}, "target_prompt": "A group of dogs playing in a creek, some catching fish with nets.", "target_property": {"obj": "dog"}, "evaluation_question": "Are there **people** playing in the creek?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people, including kids and adults, are playing in a creek, some catching fish with nets. FE+NG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/089f0ce42f9f4f86be5fdc683a2e9308.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a678e8ee95e428484d67820c83b4970", "source": "vatex", "video_id": "cAxBY04KV2c_000002_000012", "video_description": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards.", "task": "ObjectRecognition", "clean_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a drumstick.", "clean_property": {"obj": "drumstick"}, "target_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a guitar.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the seated man holding a **drumstick**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young men playfully jostle another young man sitting in a chair, leading to the seated man falling backwards while holding a drumstick. FE*8!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/21e610ea613e4b70bff5295692cca821.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31487450975d4d7f821888801fce2bc4", "source": "vatex", "video_id": "ukoa19O5Mtc_000088_000098", "video_description": "A group of friends, including a man and a woman, are participating in a karaoke game, singing and dancing with microphones in a room.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone positioned to the left of a person singing karaoke.", "clean_property": {"obj_1": "microphone", "relation": "left of", "obj_2": "person"}, "target_prompt": "A microphone positioned to the right of a person singing karaoke.", "target_property": {"obj_1": "microphone", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the microphone to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microphone positioned to the left of a person singing karaoke. @EZVS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4d941d0fb1ae440e86bd8e5a050a362d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e16ae2ab007c40b5a70e2b99790a21aa", "source": "vatex", "video_id": "94H3kHrtzT4_000025_000035", "video_description": "A person is in a gym running sideways on an inclined treadmill.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a treadmill in a gym.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "treadmill"}, "target_prompt": "A person further from the camera than a treadmill in a gym.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "treadmill"}, "evaluation_question": "Is the person **closer to the camera** than the treadmill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a treadmill in a gym. )!C%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d13b840edce434dacec08fcbee269d1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ed44b628cd14817bee538bbbb4862ac", "source": "vatex", "video_id": "RXDUufYbSto_000092_000102", "video_description": "A baby girl wearing a bonnet is being fed milk from a bottle by an adult.", "task": "AttributeRecognition", "clean_prompt": "A baby girl wearing a bonnet is being fed milk from a baby bottle by an adult.", "clean_property": {"obj": "bottle", "attribute": "baby bottle"}, "target_prompt": "A baby girl wearing a bonnet is being fed water from a water bottle by an adult.", "target_property": {"obj": "bottle", "attribute": "water bottle"}, "evaluation_question": "Is the baby being fed from a **baby** bottle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby girl wearing a bonnet is being fed milk from a baby bottle by an adult. OL)FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/97337fcf99ea4ee7ba3309a5ba9a8170.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f11cc3746b2048eabf5001831279ccad", "source": "vatex", "video_id": "x6T2Wejr8W8_000024_000034", "video_description": "A woman is playing a saxophone while another woman dances in a kitchen.", "task": "Counting", "clean_prompt": "Five women playing saxophones in a kitchen.", "clean_property": {"obj": "woman_2", "count": "five"}, "target_prompt": "One woman playing a saxophone in a kitchen.", "target_property": {"obj": "woman_2", "count": "one"}, "evaluation_question": "Are there exactly **five** women playing saxophones in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women playing saxophones in a kitchen. SL;\u00b7#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1af9b58b0d97444e8621b10da0144539.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b93d437d6dd149d8acd32edc1ad789cd", "source": "vatex", "video_id": "z-KDduwJNOU_000012_000022", "video_description": "A person, sometimes identified as a child or young woman, is sitting on the floor with their feet in an electric foot massager, laughing uncontrollably as the machine tickles their feet.", "task": "AttributeRecognition", "clean_prompt": "A person sitting on the floor with their feet in an electric foot massager, laughing uncontrollably as the machine tickles their feet.", "clean_property": {"obj": "foot massager", "attribute": "electric"}, "target_prompt": "A person sitting on the floor with their feet in a manual foot massager, laughing uncontrollably as they use their hands to operate it.", "target_property": {"obj": "foot massager", "attribute": "manual"}, "evaluation_question": "Is the foot massager **electric**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting on the floor with their feet in an electric foot massager, laughing uncontrollably as the machine tickles their feet. FEYE)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20c2da3e406a4fb69cbd00f65ba5f5f2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "36e572e95c5c47168fe16fb454d9da3a", "source": "vatex", "video_id": "OJLx2iuJiLk_000003_000013", "video_description": "A man explains the importance and process of cleaning gutters to prevent structural damage, while another man climbs a ladder and cleans leaves from the gutters of a house.", "task": "ObjectRecognition", "clean_prompt": "A man explaining the importance of cleaning gutters while another man cleans leaves from the gutters of a house.", "clean_property": {"obj": "gutter"}, "target_prompt": "A man explaining the importance of maintaining a roof while another man inspects the roof of a house.", "target_property": {"obj": "roof"}, "evaluation_question": "Is the object being cleaned in the video a **gutter**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man explaining the importance of cleaning gutters while another man cleans leaves from the gutters of a house. '$MC.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/22b2de56f2d34777869644ac38471d89.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f056c7555fe546dba31a51b49c0f5416", "source": "vatex", "video_id": "108JatWCL28_000198_000208", "video_description": "A man is sitting on a box, playing a didgeridoo and using the box as a percussion instrument in a gallery with wall-mounted horns.", "task": "ActionRecognition", "clean_prompt": "A person playing didgeridoo in a gallery.", "clean_property": {"obj": "person", "action": "playing didgeridoo", "target": null}, "target_prompt": "A person playing guitar in a gallery.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing didgeridoo**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing didgeridoo in a gallery. !0D0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a2c4af9de6a14532b7d2515796365367.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "84982801639d4bfa8edea2f9224d51ec", "source": "vatex", "video_id": "U_u0hPg8wT8_000021_000031", "video_description": "A young man is in his bedroom, talking to a camera and playing an ocarina.", "task": "ObjectRecognition", "clean_prompt": "A young man in his bedroom, talking to a camera and playing an ocarina.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a toy in a living room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in his bedroom, talking to a camera and playing an ocarina. XSLFT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/80a025c9eebb4a1eb13b3d6168d75eb0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3241619a222d49d79e0e170739a4c45f", "source": "vatex", "video_id": "gJXDt5uvqf0_000006_000016", "video_description": "A group of people are participating in an archery competition at an outdoor range, shooting bows and arrows at targets.", "task": "SpatialUnderstanding", "clean_prompt": "An arrow flying to the left of an archer at an outdoor archery range.", "clean_property": {"obj_1": "arrow", "relation": "left of", "obj_2": "archer"}, "target_prompt": "An arrow flying to the right of an archer at an outdoor archery range.", "target_property": {"obj_1": "arrow", "relation": "right of", "obj_2": "archer"}, "evaluation_question": "Is the arrow flying to the **left** of the archer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An arrow flying to the left of an archer at an outdoor archery range. U'+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e80711f954a45a184faaf0d942838a1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bf717e2edc9c41df82eadcb720d39b7b", "source": "vatex", "video_id": "k9BUdYCalgk_000028_000038", "video_description": "In a gym, multiple people are using weight machines to perform triceps pull downs.", "task": "ObjectRecognition", "clean_prompt": "A person using a weight machine to perform triceps pull downs in a gym.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing in a park.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a weight machine to perform triceps pull downs in a gym. ))!%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c1528d4c7e3d4bbe81549ad0b970d721.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a9b44a86f384fafb476cc3d83ef00bb", "source": "vatex", "video_id": "TIXA4ZQxURQ_000022_000032", "video_description": "A man is throwing frisbees of different colors in a large, open grassy field with cars driving in the background.", "task": "Counting", "clean_prompt": "Four people are throwing frisbees of different colors in a large, open grassy field with cars driving in the background.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is throwing a frisbee in a large, open grassy field with cars driving in the background.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people throwing frisbees in the field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are throwing frisbees of different colors in a large, open grassy field with cars driving in the background. ))!B|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42eedebda7c14ca4bfe38727dd9c8e52.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "17266b8c93b941aa840bdcabe11ddc87", "source": "vatex", "video_id": "IyhDBSyWCYw_000013_000023", "video_description": "A man opens a door and steps outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. The scene transitions from a dark room to a beautiful outdoor setting with music playing.", "task": "AttributeRecognition", "clean_prompt": "A man steps outside into a dream-like landscape with green fields and snowy mountains.", "clean_property": {"obj": "landscape", "attribute": "snowy mountains"}, "target_prompt": "A man steps outside into a dream-like landscape with green fields and a desert.", "target_property": {"obj": "landscape", "attribute": "desert"}, "evaluation_question": "Does the landscape include **snowy mountains**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man steps outside into a dream-like landscape with green fields and snowy mountains. H!UA/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c1aa916ab45742398cdaa5a7aa6abb15.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "11a58cfc54d9417ababc5c5cddd9ca5d", "source": "vatex", "video_id": "35BYA6MCqcA_000070_000080", "video_description": "A group of men are working outdoors on a construction site, laying bricks as part of a building. A man wearing a hard hat provides commentary on masonry work.", "task": "Counting", "clean_prompt": "Seven men working outdoors on a construction site, laying bricks as part of a building.", "clean_property": {"obj": "wall", "count": "seven"}, "target_prompt": "Three men standing next to a completed wall at a construction site.", "target_property": {"obj": "wall", "count": "three"}, "evaluation_question": "Are there exactly **seven** men working on the construction site?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven men working outdoors on a construction site, laying bricks as part of a building. ))!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dd93cc1eb474f7db565c6dc06c920d5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3b6ba4d2bb584a24bfa62236b05540b2", "source": "vatex", "video_id": "c0zKotiZDF8_000094_000104", "video_description": "A person is creating art using spray paint on a circular, metal object placed on a turntable. The person is wearing a protective mask while working outdoors.", "task": "Counting", "clean_prompt": "Seven artists creating art using spray paint on a circular, metal object placed on a turntable, while wearing protective masks outdoors.", "clean_property": {"obj": "artist", "count": "seven"}, "target_prompt": "Three artists creating art using spray paint on a circular, metal object placed on a turntable, while wearing protective masks outdoors.", "target_property": {"obj": "artist", "count": "three"}, "evaluation_question": "Are there exactly **seven** artists creating art outdoors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven artists creating art using spray paint on a circular, metal object placed on a turntable, while wearing protective masks outdoors. >BCRR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e1829deb4f2d4f3c835d95fea9908cd5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f494879ff46344aea0b0b9aad89b1311", "source": "vatex", "video_id": "ZauyT7fRopg_000002_000012", "video_description": "A baby is sitting in a high chair being fed baby food with a spoon by a woman. The baby occasionally spits out the food, and the woman wipes away the extra food.", "task": "SpatialUnderstanding", "clean_prompt": "A woman closer to the camera than a high chair.", "clean_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "high chair"}, "target_prompt": "A woman further from the camera than a high chair.", "target_property": {"obj_1": "woman", "relation": "further from the camera than", "obj_2": "high chair"}, "evaluation_question": "Is the woman **closer to the camera than** the high chair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman closer to the camera than a high chair. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e96f2957cedd48feb4220d5c322f36da.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5b60b00a01104fb7848a673a023a88a4", "source": "vatex", "video_id": "p49Z8Kq2RMA_000029_000039", "video_description": "A man and a woman are seated in a car, exchanging rings and the woman kisses the man's hand.", "task": "ObjectRecognition", "clean_prompt": "A man and a woman are seated in a car, exchanging rings and the woman kisses the man's hand.", "clean_property": {"obj": "ring"}, "target_prompt": "A man and a woman are seated in a car, exchanging necklaces and the woman kisses the man's hand.", "target_property": {"obj": "necklace"}, "evaluation_question": "Are the individuals in the video exchanging **rings**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are seated in a car, exchanging rings and the woman kisses the man's hand. ELIFI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/29646a2c894d481cabd21944d5231f06.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4eb444fdacd84353b0caea363b7c206c", "source": "vatex", "video_id": "WbaWjMZMLBA_000000_000010", "video_description": "A young woman is performing a workout routine in a gym, involving squats, lunges, and arm lifts while holding dumbbells.", "task": "ActionRecognition", "clean_prompt": "A person squatting in a gym while performing a workout routine.", "clean_property": {"obj": "person", "action": "squat", "target": null}, "target_prompt": "A person jumping in a gym while performing a workout routine.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **squatting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person squatting in a gym while performing a workout routine. AN!'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/62d04c598cfc4f6f85f0fd30d8323aab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e4f5b0e55d594c0eab76ce4999409da4", "source": "vatex", "video_id": "659G415dDLc_000010_000020", "video_description": "A young man is in a gym using two heavy ropes attached to the wall to perform an exercise. He demonstrates various movements, including standing, kneeling, and swinging the ropes in a double-dutch jump rope style.", "task": "Counting", "clean_prompt": "A person using two heavy ropes in a gym, demonstrating various movements.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person using one heavy rope in a gym, demonstrating various movements.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** persons using the ropes in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using two heavy ropes in a gym, demonstrating various movements. !0MY)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5dfd1518c00e45b89108af217288acd9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "45b926fac6fa4ed2a024c1cb497f595d", "source": "vatex", "video_id": "zAO7HLux_I8_000025_000035", "video_description": "A man is demonstrating how to properly do push-ups in a gym setting.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a mat in a gym setting.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "mat"}, "target_prompt": "A person closer to the camera than a mat in a gym setting.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person **farther from the camera than** the mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a mat in a gym setting. XLFSJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3eaf993c04644778814b9e5ba8a85f6f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "15da0c9921e9441d8a0e8e8aa6c34c8b", "source": "vatex", "video_id": "pa1yAsPth9Y_000007_000017", "video_description": "In a gym, two football players are practicing drills. One player runs in place, then charges and tackles the other player, lifting and carrying him. A coach is present, guiding the practice.", "task": "SpatialUnderstanding", "clean_prompt": "A football player standing to the right of a coach in a gym.", "clean_property": {"obj_1": "football player", "relation": "right of", "obj_2": "coach"}, "target_prompt": "A football player standing to the left of a coach in a gym.", "target_property": {"obj_1": "football player", "relation": "left of", "obj_2": "coach"}, "evaluation_question": "Is the football player to the **right** of the coach?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A football player standing to the right of a coach in a gym. LY1E$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec0113330abe4408b0e1bf7e100b1194.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bde9d815ae3141868521eae9f12732aa", "source": "vatex", "video_id": "M3-oz_R_xsk_000019_000029", "video_description": "A man in a yellow shirt and black exercise shorts is repeatedly hitting a large rubber tire with a sledgehammer outdoors.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a tire outdoors.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "tire"}, "target_prompt": "A person kicking a tire outdoors.", "target_property": {"obj": "person", "action": "kicking", "target": "tire"}, "evaluation_question": "Is the person **using a sledge hammer** on the tire?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer on a tire outdoors. !0D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c4f107f0ee04dd39a1d390e59b5038f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ec64eb3d0d84efc98abbb15ba1c65d6", "source": "vatex", "video_id": "1TOcO_XjVW0_000000_000010", "video_description": "Two men wearing straw hats and white T-shirts are dancing and stomping on grapes in a wooden barrel while another man pours more grapes into the barrel. Music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A man stomping on grapes in a wooden barrel.", "clean_property": {"obj": "man", "action": "stomping grapes", "target": "grapes"}, "target_prompt": "A man pouring grapes into a wooden barrel.", "target_property": {"obj": "man", "action": "pouring grapes", "target": "grapes"}, "evaluation_question": "Is the man **stomping** on grapes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man stomping on grapes in a wooden barrel. WNX71", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33e31e0cafa24e1a8faadb1ccd457cfa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f64e7b2d18144f0cb14b29fd36894f24", "source": "vatex", "video_id": "Kfq72mbcHtA_000023_000033", "video_description": "A man and two children are playing music on homemade xylophones made of bamboo tubes, set up outside in a park. The xylophones are suspended from wooden poles, and the group uses mallets and sticks to play melodies.", "task": "ActionRecognition", "clean_prompt": "A person playing a xylophone in a park.", "clean_property": {"obj": "person", "action": "playing xylophone", "target": null}, "target_prompt": "A person playing drums in a park.", "target_property": {"obj": "person", "action": "playing drums", "target": null}, "evaluation_question": "Is the person **playing a xylophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing a xylophone in a park. UB(7*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c14c12233ea34badb194c86168af6119.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d9edfc5be02241aaa3036e6871bfb225", "source": "vatex", "video_id": "wI4AcImyDVI_000445_000455", "video_description": "A person is carving a pumpkin using various tools to create a design, possibly for a Halloween lantern.", "task": "ObjectRecognition", "clean_prompt": "A person is carving a pumpkin using a carving tool to create a spooky design.", "clean_property": {"obj": "carving tool"}, "target_prompt": "A person is painting a pumpkin using a paintbrush to create a colorful design.", "target_property": {"obj": "paintbrush"}, "evaluation_question": "Is the person using a **carving tool** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is carving a pumpkin using a carving tool to create a spooky design. *DX#V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/506d0556b6714c0c83c504ad0bf6915c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "06fe7026c4c847739c8988a4d9d3871a", "source": "vatex", "video_id": "2S75k2FikM8_000006_000016", "video_description": "A woman is using a photocopier at her job to make copies of her chest and bottom while no one is looking.", "task": "ObjectRecognition", "clean_prompt": "A woman is using a photocopier at her job to make copies.", "clean_property": {"obj": "photocopier"}, "target_prompt": "A woman is using a printer at her job to print documents.", "target_property": {"obj": "printer"}, "evaluation_question": "Is the woman using a **photocopier**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using a photocopier at her job to make copies. F%D=|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fc3aa89b10946a6a78d837ffc164193.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2b2895a9d4f447e79d23422faf441e4a", "source": "vatex", "video_id": "eRihvtICHZk_000000_000010", "video_description": "A pee-wee football game is taking place on a grass field. One team wears white tops and black bottoms, while the other team wears navy tops and red bottoms. Cheerleaders are present, cheering for the teams.", "task": "SpatialUnderstanding", "clean_prompt": "A football player farther from the camera than a football on a grass field.", "clean_property": {"obj_1": "football player", "relation": "farther from the camera than", "obj_2": "football"}, "target_prompt": "A football player closer to the camera than a football on a grass field.", "target_property": {"obj_1": "football player", "relation": "closer to the camera than", "obj_2": "football"}, "evaluation_question": "Is the football player **farther from the camera than** the football?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A football player farther from the camera than a football on a grass field. ))!B=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c3800991fc9e4e398b5898bd8f25d22c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "51cf66b431be4af2b59a55221933bce9", "source": "vatex", "video_id": "hLDFV24U7Bs_000014_000024", "video_description": "A man is demonstrating how to carve a gargoyle from a stone block using a hammer and chisel.", "task": "SpatialUnderstanding", "clean_prompt": "A tool positioned to the right of a person demonstrating how to carve a gargoyle from a stone block.", "clean_property": {"obj_1": "tool", "relation": "right of", "obj_2": "person"}, "target_prompt": "A tool positioned to the left of a person demonstrating how to carve a gargoyle from a stone block.", "target_property": {"obj_1": "tool", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the tool to the **right** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tool positioned to the right of a person demonstrating how to carve a gargoyle from a stone block. >8MEJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01341418eaf042c1ba0537c7c374c17d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "86fe04f350554f7dba8fc230c97768bd", "source": "vatex", "video_id": "tIGde0O8Brk_000000_000010", "video_description": "A man performs a high jump over a bar, landing on a cushioned mat in an outdoor park setting.", "task": "ObjectRecognition", "clean_prompt": "An athlete performing a high jump over a bar in an outdoor park.", "clean_property": {"obj": "athlete"}, "target_prompt": "A swimmer diving into a pool in an outdoor setting.", "target_property": {"obj": "swimmer"}, "evaluation_question": "Is the person in the video an **athlete**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a high jump over a bar in an outdoor park. 4|/SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d9934d3a30ff4556a3c6d3acafb64b70.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "60298118f03340ffaa05318ca16e5b0f", "source": "vatex", "video_id": "jaw8VCLSFp0_000351_000361", "video_description": "A young girl is sitting on a bed, demonstrating how to wrap string around a wooden stick while adjusting a camera to capture the process.", "task": "ActionRecognition", "clean_prompt": "A girl tying a knot around a wooden stick.", "clean_property": {"obj": "girl", "action": "tying knot (not on a tie)", "target": "wooden stick"}, "target_prompt": "A girl throwing a wooden stick.", "target_property": {"obj": "girl", "action": "throwing a stick", "target": "wooden stick"}, "evaluation_question": "Is the girl **tying a knot** around a wooden stick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl tying a knot around a wooden stick. !Q7#V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0f99085629db4803976d236f29eb6d53.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1cd2e8bb2946492fb09e4abcb12dcfd7", "source": "vatex", "video_id": "NXdLU5LM7cQ_000007_000017", "video_description": "A young woman and a young man are taking turns drinking shots of liquor from tall shot glasses on a city street in broad daylight.", "task": "ObjectRecognition", "clean_prompt": "A young woman and a young man are taking turns drinking shots of liquor from tall shot glasses on a city street in broad daylight.", "clean_property": {"obj": "shot glass"}, "target_prompt": "A young woman and a young man are taking turns drinking coffee from large coffee mugs on a city street in broad daylight.", "target_property": {"obj": "coffee mug"}, "evaluation_question": "Are the characters drinking from **shot glasses**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman and a young man are taking turns drinking shots of liquor from tall shot glasses on a city street in broad daylight. FE99M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ec0247f9745489ab826745794ec1aaa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8213785fa50a4997b6fdc72a68b57156", "source": "vatex", "video_id": "TF83Xt0Ekog_000000_000010", "video_description": "A muscular, shirtless man is demonstrating and performing abdominal exercises on a fitness mat next to a swimming pool.", "task": "AttributeRecognition", "clean_prompt": "A muscular, shirtless man demonstrating abdominal exercises on a fitness mat next to a pool with still water.", "clean_property": {"obj": "pool", "attribute": "with still water"}, "target_prompt": "A muscular, shirtless man demonstrating abdominal exercises on a fitness mat next to a pool with rippling water.", "target_property": {"obj": "pool", "attribute": "with rippling water"}, "evaluation_question": "Is the pool **with still water**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A muscular, shirtless man demonstrating abdominal exercises on a fitness mat next to a pool with still water. SL$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8916996382d419eb71ce3ab72ce7a26.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b8252d0ef8cf4d07898b58e918f14216", "source": "vatex", "video_id": "8stzRPQRbk8_000058_000068", "video_description": "A man is demonstrating and explaining how to tie a noose using a white rope.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to tie a noose using a thin white rope.", "clean_property": {"obj": "rope", "attribute": "thin"}, "target_prompt": "A man is demonstrating how to tie a noose using a thick white rope.", "target_property": {"obj": "rope", "attribute": "thick"}, "evaluation_question": "Is the rope being used thin?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to tie a noose using a thin white rope. %|!''", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8eae6b4224ed4abd87e59a173f07ef29.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e0794248ce947f9ab5a38f3452fd4ac", "source": "vatex", "video_id": "oV-x98Bs0i4_000010_000020", "video_description": "A person is preparing bread dough by placing it into a baking dish and scoring it with a tool.", "task": "Counting", "clean_prompt": "A person is preparing bread dough by placing it into a baking dish and scoring it with three tools.", "clean_property": {"obj": "tool", "count": "three"}, "target_prompt": "A person is preparing bread dough by placing it into a baking dish and scoring it with one tool.", "target_property": {"obj": "tool", "count": "one"}, "evaluation_question": "Are there exactly **three** tools being used to score the dough?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is preparing bread dough by placing it into a baking dish and scoring it with three tools. FS7DJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8cb86ea185db4351b2f3fae530212e6b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4d0a5904909642a59a490d4e845697dd", "source": "vatex", "video_id": "GOH6fBhoi2o_000010_000020", "video_description": "A young child is sitting close to a television in a dark living room, laughing and talking while watching TV. Music is playing in the background.", "task": "Counting", "clean_prompt": "A child is sitting close to a television in a dark living room, laughing and talking while watching TV.", "clean_property": {"obj": "child", "count": "six"}, "target_prompt": "Two children are sitting close to a television in a brightly lit living room, playing games and laughing.", "target_property": {"obj": "child", "count": "two"}, "evaluation_question": "Are there exactly **six** children in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is sitting close to a television in a dark living room, laughing and talking while watching TV. UD@1J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9f7d5dee1a34a41a3a439917614ef15.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "71994ce6478743e18061c5555005c417", "source": "vatex", "video_id": "uCo8WIVpPHw_000008_000018", "video_description": "A young Asian man uses a long sword to slice a hanging watermelon in a slanting motion.", "task": "ActionRecognition", "clean_prompt": "A person cutting a watermelon with a long sword in a slanting motion.", "clean_property": {"obj": "person", "action": "cutting watermelon", "target": null}, "target_prompt": "A person smashing a watermelon with a hammer.", "target_property": {"obj": "person", "action": "smashing watermelon", "target": null}, "evaluation_question": "Is the person **cutting** a watermelon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cutting a watermelon with a long sword in a slanting motion. )57FL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c12c12f2107b4cf7a8779a384557e8e9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c2e2854a4ba4b5ea39c98218b219ea9", "source": "vatex", "video_id": "Rnta1wIPe1s_000196_000206", "video_description": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom. Another man is present, talking.", "task": "ObjectRecognition", "clean_prompt": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom.", "clean_property": {"obj": "person"}, "target_prompt": "A woman wearing a colorful hat is ironing a shirt on an ironing board in a bathroom.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom. HS51Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b4cc77c419f4d1399bc5d1756c2deec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5005a4b7613041e5954de87c59d44efb", "source": "vatex", "video_id": "Z2_Xy-rqaS0_000011_000021", "video_description": "A man in a black hoodie is throwing a playing card towards a door in slow motion.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a door.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "door"}, "target_prompt": "A person closer to the camera than a door.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "door"}, "evaluation_question": "Is the person **farther from the camera than** the door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a door. ))!F/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/540caa2ac3a442518114425982fd0722.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c42abb81ce00436280a864c65d60da3a", "source": "vatex", "video_id": "Ljd56L3pvQc_000091_000101", "video_description": "A man is demonstrating rock climbing on an indoor rock wall while a TV anchor provides commentary. Other people are watching the event.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating rock climbing on an indoor rock wall while spectators watch.", "clean_property": {"obj": "spectators"}, "target_prompt": "A man demonstrating rock climbing on an indoor rock wall with participants engaged in the activity.", "target_property": {"obj": "participants"}, "evaluation_question": "Are there **spectators** watching the event?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating rock climbing on an indoor rock wall while spectators watch. );'',", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/96ec58811bc545ba8bff9a90375de847.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fec34603c1284644a3c820de066e9335", "source": "vatex", "video_id": "l6_2Ax9-3DQ_000063_000073", "video_description": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles.", "task": "Counting", "clean_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by seven people who are watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by three people who are watching her.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and explaining how to knit using red yarn and knitting needles, surrounded by seven people who are watching her. LFE-0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7609085146ec41c1aacd6dedfd9da79d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "943f0152ecc04d078d572b56131afed4", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "SpatialUnderstanding", "clean_prompt": "Graffiti farther from the camera than a laser gun in an outdoor environment.", "clean_property": {"obj_1": "graffiti", "relation": "farther from the camera than", "obj_2": "laser gun"}, "target_prompt": "Graffiti closer to the camera than a laser gun in an outdoor environment.", "target_property": {"obj_1": "graffiti", "relation": "closer to the camera than", "obj_2": "laser gun"}, "evaluation_question": "Is the graffiti **farther from the camera than** the laser gun?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Graffiti farther from the camera than a laser gun in an outdoor environment. !'G*U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3cfed5a44074ae79788e132de092c2d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4377d7f67ecc4937af3ba956eedd51c0", "source": "vatex", "video_id": "7T5nKVJrP5U_000120_000130", "video_description": "A woman is using a sewing machine to sew a piece of blue fabric, then cuts the thread and moves the fabric to a table.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a sewing machine.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "sewing machine"}, "target_prompt": "A person closer to the camera than a sewing machine.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "sewing machine"}, "evaluation_question": "Is the person **farther from the camera than** the sewing machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a sewing machine. FS+,|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b00a039b8a3644699f587dce7ec5c0f8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8b660a6ef7c04eb8bdb155d5a68b7954", "source": "vatex", "video_id": "RtV8ySth6w4_000252_000262", "video_description": "A woman in a green cardigan is sitting at a desk, reading from a computer, and writing on paper while explaining a writing tutorial.", "task": "Counting", "clean_prompt": "A woman in a green cardigan is sitting at two desks, reading from a computer, and writing on paper while explaining a writing tutorial.", "clean_property": {"obj": "desk", "count": "two"}, "target_prompt": "A woman in a green cardigan is sitting at one desk, reading from a computer, and writing on paper while explaining a writing tutorial.", "target_property": {"obj": "desk", "count": "one"}, "evaluation_question": "Are there exactly **two** desks in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a green cardigan is sitting at two desks, reading from a computer, and writing on paper while explaining a writing tutorial. #BCMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bd7f61396b014812b40dc004c3488e21.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aa5906c165d9462790bcadae87c3ff7e", "source": "vatex", "video_id": "qXRzqpPu_zE_000004_000014", "video_description": "A young man in a blue shirt is in the woods, smashing an acoustic guitar against a tree until it breaks into pieces.", "task": "AttributeRecognition", "clean_prompt": "A young man in a blue shirt is in the woods, smashing an acoustic guitar against a tree until it breaks into pieces.", "clean_property": {"obj": "guitar", "attribute": "acoustic"}, "target_prompt": "A young man in a blue shirt is in the woods, smashing an electric guitar against a tree until it breaks into pieces.", "target_property": {"obj": "guitar", "attribute": "electric"}, "evaluation_question": "Is the guitar being smashed an **acoustic** guitar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in a blue shirt is in the woods, smashing an acoustic guitar against a tree until it breaks into pieces. HP.TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c2d4e0262973431e8e35edbe02f51010.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae074e56bc284fcea0830512d3024344", "source": "vatex", "video_id": "5Dk32jjcdrw_000001_000011", "video_description": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "task": "Counting", "clean_prompt": "Two children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "clean_property": {"obj": "child", "count": "two"}, "target_prompt": "One child is riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **two** children riding the carousel?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles. W%|*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/942291d4c92d4bccb74515e11ebb2f47.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f45ff2246e304b9588102c743d8e3ed9", "source": "vatex", "video_id": "0fwkAvo6wGI_000007_000017", "video_description": "A man is in a gym demonstrating and performing ab mat sit ups using a foam wedge or sit up pad under his back.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a mat in a gym.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a mat in a gym.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person closer to the camera than the mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a mat in a gym. @XR37", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4157222bc3d435996dec6f76085acf9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "262d393d43f6448abde80ecaf3b2e310", "source": "vatex", "video_id": "rHJ53a4PI1Y_000547_000557", "video_description": "A man is in a gym demonstrating various exercises and stretches on a blue exercise ball, focusing on shoulder and chest workouts while lying on his stomach.", "task": "ActionRecognition", "clean_prompt": "A person exercising with an exercise ball in a gym.", "clean_property": {"obj": "person", "action": "exercising with an exercise ball", "target": null}, "target_prompt": "A person playing with a beach ball in a park.", "target_property": {"obj": "person", "action": "playing with a beach ball", "target": null}, "evaluation_question": "Is the person **exercising with an exercise ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person exercising with an exercise ball in a gym. EDJ)P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5e7213efa814edca2f56e4909f5ac18.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2cc0908f9e9e447dbb7a7a71359f280e", "source": "vatex", "video_id": "_SUeogHI5rg_000043_000053", "video_description": "A man is on a golf course making an instructional video about golfing techniques, including how to hit a ball to land just short of the green and how to putt.", "task": "AttributeRecognition", "clean_prompt": "A person who is a golf instructor making an instructional video about golfing techniques.", "clean_property": {"obj": "person", "attribute": "golf instructor"}, "target_prompt": "A person who is a tennis instructor making an instructional video about tennis techniques.", "target_property": {"obj": "person", "attribute": "tennis instructor"}, "evaluation_question": "Is the person a **golf** instructor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who is a golf instructor making an instructional video about golfing techniques. XGFEI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1cd38620ae5442e96c8e5f45c2e11d1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "664a4cbbfe5c4538bed60d69a10cbbb8", "source": "vatex", "video_id": "FLhNVUgSHNQ_000031_000041", "video_description": "A young man is riding a skateboard down a road, performing tricks and adjusting his hat.", "task": "ActionRecognition", "clean_prompt": "A person skateboarding down a road, performing tricks and adjusting his hat.", "clean_property": {"obj": "person", "action": "skateboarding", "target": null}, "target_prompt": "A person rollerblading down a road, performing tricks and adjusting his hat.", "target_property": {"obj": "person", "action": "rollerblading", "target": null}, "evaluation_question": "Is the person **skateboarding**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person skateboarding down a road, performing tricks and adjusting his hat. H%B&=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35787387af794537a33e851305ed4782.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5bb448e0a994c50b395ce3ce52052ac", "source": "vatex", "video_id": "6kxxQjo5FK0_000023_000033", "video_description": "In a karate studio, a group of kids practice martial arts skills with their coach, including breaking wooden boards.", "task": "AttributeRecognition", "clean_prompt": "A coach who is a karate instructor guiding kids in a karate studio as they practice breaking wooden boards.", "clean_property": {"obj": "coach", "attribute": "karate instructor"}, "target_prompt": "A coach who is a yoga instructor guiding kids in a yoga studio as they practice poses.", "target_property": {"obj": "coach", "attribute": "yoga instructor"}, "evaluation_question": "Is the coach a **karate** instructor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A coach who is a karate instructor guiding kids in a karate studio as they practice breaking wooden boards. PXBSQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/345bb92495d84cb185c471da6e912f02.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de367e9ad9a848daa354ba072913c59a", "source": "vatex", "video_id": "7u_3lPIRUSU_000349_000359", "video_description": "A young girl in a kitchen demonstrates how to bake cookies, showing cookie dough on sheets and placing them in an oven while explaining the process.", "task": "ActionRecognition", "clean_prompt": "A girl baking cookies in a kitchen.", "clean_property": {"obj": "girl", "action": "baking cookies", "target": null}, "target_prompt": "A girl decorating cupcakes in a kitchen.", "target_property": {"obj": "girl", "action": "decorating cupcakes", "target": null}, "evaluation_question": "Is the girl **baking cookies**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl baking cookies in a kitchen. ISHIM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0bb0cacad1b64217ab7d2254a9b7203b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d62cf62ba31d4fdba73d4ab598ab7c80", "source": "vatex", "video_id": "XmP8CYWwSPk_000224_000234", "video_description": "A man is demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions.", "clean_property": {"obj": "fishing lure", "attribute": "colorful"}, "target_prompt": "A man demonstrating how to make a monochrome fishing lure, including tying and painting it, while giving instructions.", "target_property": {"obj": "fishing lure", "attribute": "monochrome"}, "evaluation_question": "Is the fishing lure **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions. PG0BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7e3dd9de0dbe44038e1556e5a6118295.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7381c4db4a5f4472bd0acf6e16e336cf", "source": "vatex", "video_id": "6CG6U4b8v44_000058_000068", "video_description": "Two skydivers jump from a plane, one carrying the other piggyback, and deploy a parachute while descending.", "task": "Counting", "clean_prompt": "Six planes flying in formation in a clear blue sky.", "clean_property": {"obj": "plane", "count": "six"}, "target_prompt": "One plane flying solo in a clear blue sky.", "target_property": {"obj": "plane", "count": "one"}, "evaluation_question": "Are there exactly **six** planes flying in the sky?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six planes flying in formation in a clear blue sky. U%/:&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d980503fa2cf4f4eb071a472903ce25f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab85d2b0168c4686bac16791390e744c", "source": "vatex", "video_id": "1mAkM2AZnPM_000000_000010", "video_description": "A young man is playing with a lighter, inhaling gas and blowing it out to create a large flame.", "task": "SpatialUnderstanding", "clean_prompt": "A lighter farther from the camera than a person.", "clean_property": {"obj_1": "lighter", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A lighter closer to the camera than a person.", "target_property": {"obj_1": "lighter", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the lighter **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A lighter farther from the camera than a person. MM#SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9967129bdad841819387f8d7f89b9f47.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5037d70db9534ad6810125a6b986533f", "source": "vatex", "video_id": "JJWu9ybc_fs_000001_000011", "video_description": "Two boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "task": "Counting", "clean_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman.", "clean_property": {"obj": "boy", "count": "three"}, "target_prompt": "One boy is playing in a snowy field, making a snowman using a tool.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **three** boys playing in the snowy field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three boys are playing in a snowy field. One boy is making a snowman using a tool, while the other boy is throwing snowballs at the snowman. 9POE7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b15daa08723400ebbf06556c7de39e6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5248990cd7254e9da9cbdfed046f65c5", "source": "vatex", "video_id": "0FDVa0TOc3A_000000_000010", "video_description": "A woman in gym clothes is climbing a rope hanging from the ceiling in a fitness room, while a man encourages her.", "task": "ActionRecognition", "clean_prompt": "A woman climbing a rope in a fitness room.", "clean_property": {"obj": "woman", "action": "climbing a rope", "target": null}, "target_prompt": "A woman sliding down a rope in a fitness room.", "target_property": {"obj": "woman", "action": "sliding down a rope", "target": null}, "evaluation_question": "Is the woman **climbing** a rope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman climbing a rope in a fitness room. TSJ4@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b3bba83049b4eb8a19367d5fc99297c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "17aa37e84813489885de5f55eca506a6", "source": "vatex", "video_id": "_gAvn9s8p0s_000001_000011", "video_description": "A person is using a sewing machine to sew a red piece of cloth in a workshop.", "task": "ActionRecognition", "clean_prompt": "A person sewing a red piece of cloth in a workshop.", "clean_property": {"obj": "person", "action": "sewing", "target": "cloth"}, "target_prompt": "A person cutting cloth in a workshop.", "target_property": {"obj": "person", "action": "cutting cloth", "target": "cloth"}, "evaluation_question": "Is the person **sewing** a red piece of cloth?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sewing a red piece of cloth in a workshop. OT)CV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ddc645a8823e45f09486146cde9be6bb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f24b77836ea74e8e9d5fc00d582ca9f9", "source": "vatex", "video_id": "phpv6WPyKDo_000000_000010", "video_description": "A man demonstrates how to chop green onions quickly and finely using a knife on a wooden cutting board.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrates how to chop green onions quickly and finely using a knife on a wooden cutting board.", "clean_property": {"obj": "green onion"}, "target_prompt": "A man demonstrates how to chop carrots quickly and finely using a knife on a wooden cutting board.", "target_property": {"obj": "carrot"}, "evaluation_question": "Is the man chopping **green onions**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to chop green onions quickly and finely using a knife on a wooden cutting board. FFQ03", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b706c60a6b154d428e1b057cf1bcd782.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f358e39dbd14585b03871fd20753d3d", "source": "vatex", "video_id": "H2ihippbg-U_000000_000010", "video_description": "A young boy is practicing pole vaulting at school, successfully vaulting over a high bar onto a foam mat while people cheer and applaud.", "task": "Counting", "clean_prompt": "A young boy is practicing pole vaulting at school with six audience members cheering and applauding.", "clean_property": {"obj": "audience", "count": "six"}, "target_prompt": "A young boy is practicing pole vaulting at school with two audience members cheering and applauding.", "target_property": {"obj": "audience", "count": "two"}, "evaluation_question": "Are there exactly **six** audience members cheering and applauding?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is practicing pole vaulting at school with six audience members cheering and applauding. UF\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01673fb8fc474c25b28e551040ff0915.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "009c4139988e4ef7934ea8088790f5e4", "source": "vatex", "video_id": "G-UDM5Npk_8_000501_000511", "video_description": "A woman is demonstrating and explaining the process of bookbinding, including measuring, cutting, and gluing materials to create book covers and spine end covers.", "task": "SpatialUnderstanding", "clean_prompt": "Craft material farther from the camera than a person demonstrating bookbinding.", "clean_property": {"obj_1": "craft material", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "Craft material closer to the camera than a person demonstrating bookbinding.", "target_property": {"obj_1": "craft material", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the craft material **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Craft material farther from the camera than a person demonstrating bookbinding. ~$6\u00b7U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a4a164564aa40978bcfc65c0cfb5d2c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b778a490ea754a3b9f0bf1ef4d3ca467", "source": "vatex", "video_id": "DSoEZpKkhAs_000010_000020", "video_description": "A woman is on a beach with a man, attempting to skip stones on the water. She walks along the shore, throws stones that bounce on the water, while the man cheers her on.", "task": "ActionRecognition", "clean_prompt": "A woman skipping stones on the beach.", "clean_property": {"obj": "woman", "action": "skipping stone", "target": "stone"}, "target_prompt": "A woman throwing shells on the beach.", "target_property": {"obj": "woman", "action": "throwing stones", "target": "shell"}, "evaluation_question": "Is the woman **skipping stones**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman skipping stones on the beach. 6*4(|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/914d5203e2ca4ab5846ecdc6c6127c27.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5eeeca33ffd44379c4c1ee79f3da746", "source": "vatex", "video_id": "PrPsMxHzUBI_000027_000037", "video_description": "A group of people, including a man and a woman, are barefoot stomping grapes in a large tub while music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A person stomping grapes in a large tub.", "clean_property": {"obj": "person", "action": "stomping grapes", "target": null}, "target_prompt": "A person dancing in a large tub.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **stomping grapes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stomping grapes in a large tub. FE(E$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/74bfe45d9fc44896b75ef6653d96185f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd5d576b435046eab05cb25787871d5a", "source": "vatex", "video_id": "kSdDF-ry2Cg_000011_000021", "video_description": "A skateboarder in a red shirt is performing tricks in a skate park with a curved area and ramps, while a group of people watch.", "task": "Counting", "clean_prompt": "Six people watching a skateboarder in a red shirt performing tricks in a skate park.", "clean_property": {"obj": "audience", "count": "six"}, "target_prompt": "Three people watching a skateboarder in a red shirt performing tricks in a skate park.", "target_property": {"obj": "audience", "count": "three"}, "evaluation_question": "Are there exactly **six** people watching the skateboarder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people watching a skateboarder in a red shirt performing tricks in a skate park. !G%F9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fbd7ff1c19434be489eed4ccc859d28a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "66969abec9e647b6a5ad1f1c86b12744", "source": "vatex", "video_id": "MFt0MwJGTxU_000000_000010", "video_description": "A young boy is sitting in a room, smoking from a hookah pipe and exhaling smoke.", "task": "Counting", "clean_prompt": "Five people are sitting in a room, one of them is smoking from a hookah pipe and exhaling smoke.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person is sitting in a room, smoking from a hookah pipe and exhaling smoke.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people are sitting in a room, one of them is smoking from a hookah pipe and exhaling smoke. )!0D:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/808c7b1db8ee49628851ccbd25c92995.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eff087604e114f148607238674c5653e", "source": "vatex", "video_id": "_8w8b5auFkc_000002_000012", "video_description": "A skiing competition is taking place on a large snowy slope. Skiers are skiing downhill through flags, while spectators cheer them on.", "task": "ObjectRecognition", "clean_prompt": "Skiers racing downhill through flags on a snowy slope.", "clean_property": {"obj": "flags"}, "target_prompt": "Skiers racing downhill through banners on a snowy slope.", "target_property": {"obj": "banners"}, "evaluation_question": "Are the skiers skiing through **flags**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Skiers racing downhill through flags on a snowy slope. FE0=&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9e20dfbc1f7841c09df7690c859cbc59.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed1986c2727e4dbdbefa37715cb7ea79", "source": "vatex", "video_id": "o7g3QX8cESw_000033_000043", "video_description": "A man is unboxing a device, removing electronic items, including a charger and several cables, and placing them on a bed.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a box.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "box"}, "target_prompt": "A person standing to the left of a box.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "box"}, "evaluation_question": "Is the person to the **right** of a box?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a box. FE|.?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6b2a62648ca405b9d6ab39a0a4b8683.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7ad2cc41779c49769666dac365b439ba", "source": "vatex", "video_id": "7rPXR4duVqE_000000_000010", "video_description": "A bald man stands on a porch, drinks alcohol from a bottle, and spits it towards a lit lighter, creating a large flame.", "task": "ObjectRecognition", "clean_prompt": "A bald man stands on a porch, drinks alcohol from a bottle, and spits it towards a lit lighter, creating a large flame.", "clean_property": {"obj": "lighter"}, "target_prompt": "A bald man stands on a porch, drinks alcohol from a bottle, and strikes a match, creating a large flame.", "target_property": {"obj": "match"}, "evaluation_question": "Is the object being used to create a flame a **lighter**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bald man stands on a porch, drinks alcohol from a bottle, and spits it towards a lit lighter, creating a large flame. !'!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb08fbf5b185488299facb9aa04ee993.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae2f284a0bd24e9a990402c72489073f", "source": "vatex", "video_id": "icxsQqVxnoU_000109_000119", "video_description": "A woman is playing a word game similar to Scrabble, using letter tiles and a dictionary to teach others how to play.", "task": "Counting", "clean_prompt": "A woman is playing a word game with seven books and letter tiles, teaching others how to play.", "clean_property": {"obj": "book", "count": "seven"}, "target_prompt": "A woman is playing a word game with four books and letter tiles, teaching others how to play.", "target_property": {"obj": "book", "count": "four"}, "evaluation_question": "Are there exactly **seven** books being used in the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is playing a word game with seven books and letter tiles, teaching others how to play. )!B*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/288ab2218969409d8ad7b265e5a7ab4a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd85d2774e1a46c5a4ff15b8882ae244", "source": "vatex", "video_id": "L5Mp4_pwiK8_000000_000010", "video_description": "Two teams are playing a game of cricket on a cricket field, with players batting, catching, and throwing the ball.", "task": "ActionRecognition", "clean_prompt": "A cricket player playing cricket on a cricket field.", "clean_property": {"obj": "cricket player", "action": "playing cricket", "target": null}, "target_prompt": "A cricket player watching cricket on a cricket field.", "target_property": {"obj": "cricket player", "action": "watching cricket", "target": null}, "evaluation_question": "Is the cricket player **playing** cricket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cricket player playing cricket on a cricket field. ;TZ@P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a35aeca722245a085c8ec7e83e06423.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c70b6ee71e4f4802b6f42d5048661d45", "source": "vatex", "video_id": "hbRePiTRK_Y_000033_000043", "video_description": "A group of people, including young men and a woman, are at an indoor party playing beer pong. Some are standing around a table with drinks, talking and watching the game.", "task": "ObjectRecognition", "clean_prompt": "A group of people at an indoor party playing beer pong with drinks on the table.", "clean_property": {"obj": "drinks"}, "target_prompt": "A group of people at an indoor party enjoying snacks while playing games.", "target_property": {"obj": "snacks"}, "evaluation_question": "Are the people in the video playing beer pong with **drinks**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people at an indoor party playing beer pong with drinks on the table. >3/UT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b4637b2393c64a14b79b3bedeb700138.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a6310db1033549dda12e454a6f1b2492", "source": "vatex", "video_id": "QQC4ESiMUY0_000399_000409", "video_description": "A man is demonstrating and counting pennies labeled with numbers on a whiteboard.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating and counting pennies labeled with numbers on a whiteboard.", "clean_property": {"obj": "penny", "attribute": "labeled with numbers"}, "target_prompt": "A man is demonstrating and counting unlabeled pennies on a whiteboard.", "target_property": {"obj": "penny", "attribute": "unlabeled"}, "evaluation_question": "Are the pennies labeled with **numbers**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating and counting pennies labeled with numbers on a whiteboard. ))A%-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be957a2289bd4eaaa6a74726232675e7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0d6299dc51e54b428abdccc6510fe868", "source": "vatex", "video_id": "sbZQtqT59jk_000018_000028", "video_description": "A man is explaining the features and speed of a snowmobile parked in the snow in front of a large yellow building.", "task": "SpatialUnderstanding", "clean_prompt": "A building farther from the camera than a snowmobile parked in the snow.", "clean_property": {"obj_1": "building", "relation": "farther from the camera than", "obj_2": "snowmobile"}, "target_prompt": "A building closer to the camera than a snowmobile parked in the snow.", "target_property": {"obj_1": "building", "relation": "closer to the camera than", "obj_2": "snowmobile"}, "evaluation_question": "Is the building **farther from the camera than** the snowmobile?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A building farther from the camera than a snowmobile parked in the snow. '),!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0af7d3b6695f4e749c17fe076d679b6e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6854263606234eeab2c2c5af14c7fa83", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "Counting", "clean_prompt": "Four people are watching a man standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are watching a man standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly. -?)!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a9497e3e1b5146bba97cd954f2caa123.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dc8ce7ab203f49a5bf26a703103afbf7", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "Counting", "clean_prompt": "Three people sitting around a poker table in a casino, playing poker with cards and chips.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting alone at a poker table in a casino, playing poker with cards and chips.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting around the poker table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people sitting around a poker table in a casino, playing poker with cards and chips. E/SL*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eec459a9f52744d9a97de1eeab06f394.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3e02fc112f34714af717406ca5105ae", "source": "vatex", "video_id": "7JubqqrrURI_000958_000968", "video_description": "A woman is standing and talking to two students who are sitting with musical instruments in a room, possibly a music class.", "task": "Counting", "clean_prompt": "A teacher is standing and talking to two students who are sitting with musical instruments in a music class.", "clean_property": {"obj": "teacher", "count": "six"}, "target_prompt": "Six teachers are standing and talking to a group of students in a large classroom.", "target_property": {"obj": "teacher", "count": "six"}, "evaluation_question": "Are there exactly **six** teachers in the classroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teacher is standing and talking to two students who are sitting with musical instruments in a music class. &2/SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0ecf29d0fd324548b789b7c861ce029b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed2da048c02449e0910e51be66970588", "source": "vatex", "video_id": "CeQ5f7l-mQQ_000019_000029", "video_description": "A young man is practicing archery in a large open field, shooting arrows with a bow at a high angle into the sky.", "task": "ActionRecognition", "clean_prompt": "A person practicing archery in a large open field.", "clean_property": {"obj": "person", "action": "archery", "target": null}, "target_prompt": "A person fencing in a large open field.", "target_property": {"obj": "person", "action": "fencing", "target": null}, "evaluation_question": "Is the person **practicing archery**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing archery in a large open field. %|\u00b7%1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35f80bcf1d3e4273ab503b18cecc3456.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6bd4cc3bcfc947c2906a4119486ef657", "source": "vatex", "video_id": "5Dk32jjcdrw_000001_000011", "video_description": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "task": "AttributeRecognition", "clean_prompt": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "clean_property": {"obj": "motorcycle carousel", "attribute": "colorful"}, "target_prompt": "Children are riding a monochrome motorcycle carousel at a carnival, making excited noises as they go around in circles.", "target_property": {"obj": "motorcycle carousel", "attribute": "monochrome"}, "evaluation_question": "Is the motorcycle carousel **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles. 5TMTZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed9afadd02c54eb484cd1b91929e977e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0fa88fe3f90148dea3236caf2828d13c", "source": "vatex", "video_id": "PYRzNkcs4s8_000006_000016", "video_description": "Three kids are sliding on a sled across a long icy path in a park, while adults watch and cheer.", "task": "SpatialUnderstanding", "clean_prompt": "A sled farther from the camera than the adults watching and cheering.", "clean_property": {"obj_1": "sled", "relation": "farther from the camera than", "obj_2": "adults"}, "target_prompt": "A sled closer to the camera than the adults watching and cheering.", "target_property": {"obj_1": "sled", "relation": "closer to the camera than", "obj_2": "adults"}, "evaluation_question": "Is the sled **farther from the camera than** the adults?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sled farther from the camera than the adults watching and cheering. FG?.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20c7cf90922c4601a9275839448cf2d4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57fec342161f4729a06f1d87d19d3086", "source": "vatex", "video_id": "O5XxrtNZbgk_000055_000065", "video_description": "Various people, including men and kids, are performing tricks and stunts with a jump rope in different indoor and outdoor locations.", "task": "ActionRecognition", "clean_prompt": "A person skipping rope in a park.", "clean_property": {"obj": "person", "action": "skipping rope", "target": null}, "target_prompt": "A person jumping rope with a hula hoop in a park.", "target_property": {"obj": "person", "action": "jumping rope", "target": "hula hoop"}, "evaluation_question": "Is the person **skipping rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person skipping rope in a park. C>((1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9b082b0db9994ab39f0ec638597ac6f9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9fd6090036754e828cd01c2b9f61ffc4", "source": "vatex", "video_id": "NEH1HLP5nPM_000217_000227", "video_description": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with multiple panes of glass.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a drill while drilling holes into a wall.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "drill"}, "target_prompt": "A person standing to the right of a drill while drilling holes into a wall.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "drill"}, "evaluation_question": "Is the person to the **left** of the drill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a drill while drilling holes into a wall. ))'!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f57e1a5c51cf492eb313d83f2352c644.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9c6fd6a1f8a848879d5beb1891b261ad", "source": "vatex", "video_id": "UTpl0VRiYs0_000052_000062", "video_description": "A group of five dancers perform a choreographed dance routine on a dark stage illuminated by a spotlight. Two dancers perform in the spotlight while three others watch from the edge of the light.", "task": "SpatialUnderstanding", "clean_prompt": "A dancer farther from the camera than a spotlight.", "clean_property": {"obj_1": "dancer", "relation": "farther from the camera than", "obj_2": "spotlight"}, "target_prompt": "A dancer closer to the camera than a spotlight.", "target_property": {"obj_1": "dancer", "relation": "closer to the camera than", "obj_2": "spotlight"}, "evaluation_question": "Is the dancer **farther from the camera than** the spotlight?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dancer farther from the camera than a spotlight. )!U0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4bfb673f6c949788e34e0ecc18125fb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f77bf5fcc306461388385efa4d11655d", "source": "vatex", "video_id": "81ptKSgwvfA_000000_000010", "video_description": "A woman is in a music room playing a rhythm on two large cymbals, concentrating as she crashes them together.", "task": "ObjectRecognition", "clean_prompt": "A woman is in a music room playing a rhythm on two large cymbals, concentrating as she crashes them together.", "clean_property": {"obj": "cymbals"}, "target_prompt": "A woman is in a music room playing a rhythm on a large drum, concentrating as she strikes it.", "target_property": {"obj": "drum"}, "evaluation_question": "Is the woman playing **cymbals**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is in a music room playing a rhythm on two large cymbals, concentrating as she crashes them together. MVJWF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6492f9944e1546ba8f69e6e88548ea39.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90c36a0a5bcd47ffa36ea53b32925aa9", "source": "vatex", "video_id": "Dc6KNfDx_bo_000114_000124", "video_description": "A woman is demonstrating and discussing how to sew and crochet a vibrant needlework piece using brightly colored yarn.", "task": "SpatialUnderstanding", "clean_prompt": "A needlework piece farther from the camera than a person demonstrating how to sew and crochet.", "clean_property": {"obj_1": "needlework piece", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A needlework piece closer to the camera than a person demonstrating how to sew and crochet.", "target_property": {"obj_1": "needlework piece", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the needlework piece **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A needlework piece farther from the camera than a person demonstrating how to sew and crochet. LY1VR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e8eec1fbca594262afda82e4beef2846.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "30ad73850eb84faca0b5830dde3adf50", "source": "vatex", "video_id": "xzLthRwnBQI_000055_000065", "video_description": "A woman is using a power tool with a buffing attachment to polish various pieces of jewelry, including a ring, brooch, and bracelet, while giving verbal instructions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than the jewelry while polishing various pieces.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "jewelry"}, "target_prompt": "A person further from the camera than the jewelry while polishing various pieces.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "jewelry"}, "evaluation_question": "Is the person **closer to the camera than** the jewelry?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than the jewelry while polishing various pieces. UD7P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/db8de5e26c0d4b1a92195ea8111bbbcb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c0a645d8797476c8c933eb5174f2c26", "source": "vatex", "video_id": "7u_3lPIRUSU_000349_000359", "video_description": "A young girl in a kitchen demonstrates how to bake cookies, showing cookie dough on sheets and placing them in an oven while explaining the process.", "task": "SpatialUnderstanding", "clean_prompt": "Baking sheets closer to the camera than a girl in a kitchen demonstrating how to bake cookies.", "clean_property": {"obj_1": "baking sheets", "relation": "closer to the camera than", "obj_2": "girl"}, "target_prompt": "Baking sheets further from the camera than a girl in a kitchen demonstrating how to bake cookies.", "target_property": {"obj_1": "baking sheets", "relation": "further from the camera than", "obj_2": "girl"}, "evaluation_question": "Are the baking sheets **closer to the camera than** the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Baking sheets closer to the camera than a girl in a kitchen demonstrating how to bake cookies. EVUMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8c5039dcbe85434ca9ff5405f73d5f45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "72ad0f20d73140da9f6a23bd2988cbd0", "source": "vatex", "video_id": "HwyGx77uGxU_000156_000166", "video_description": "A person is cooking at a stove, transferring and mixing ingredients between a small pan and a larger pan with vegetables using a spoon.", "task": "Counting", "clean_prompt": "A person is cooking at a stove, using three spoons to transfer and mix ingredients between a small pan and a larger pan with vegetables.", "clean_property": {"obj": "spoon", "count": "three"}, "target_prompt": "A person is cooking at a stove, using one spoon to transfer and mix ingredients between a small pan and a larger pan with vegetables.", "target_property": {"obj": "spoon", "count": "one"}, "evaluation_question": "Are there exactly **three** spoons being used in the cooking process?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is cooking at a stove, using three spoons to transfer and mix ingredients between a small pan and a larger pan with vegetables. #TZ\u00b7~", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/192d79179b88429490f3c4b5f2c2542e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9a5390965ae84973a28b8e0cd273c673", "source": "vatex", "video_id": "w70REJeQqOI_000040_000050", "video_description": "A person is lying on a bed, wiggling their toes and cracking their knuckles.", "task": "ActionRecognition", "clean_prompt": "A person lying on a bed, wiggling their toes and cracking their knuckles.", "clean_property": {"obj": "person", "action": "cracking knuckles", "target": null}, "target_prompt": "A person lying on a bed, wiggling their toes and stretching.", "target_property": {"obj": "person", "action": "stretching", "target": null}, "evaluation_question": "Is the person **cracking their knuckles**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person lying on a bed, wiggling their toes and cracking their knuckles. A/&W%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0ee1bc799f7448b69d30f383e0d49ed8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5ac5fd3e2efd4083be6cff95f97879c2", "source": "vatex", "video_id": "839TvHPk66E_000022_000032", "video_description": "A person in a fox costume with a mask and tail interacts with various toys and dances to music.", "task": "AttributeRecognition", "clean_prompt": "A person wearing a fox costume with a mask and tail interacts with various toys and dances to music.", "clean_property": {"obj": "person", "attribute": "wearing tail"}, "target_prompt": "A person wearing a dinosaur costume interacts with various toys and dances to music.", "target_property": {"obj": "person", "attribute": "wearing a dinosaur costume"}, "evaluation_question": "Is the person wearing a **fox** costume?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a fox costume with a mask and tail interacts with various toys and dances to music. MWLFC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/89ab657da44e4215967d6b36243449b2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b717417726a140488081674a554ed19f", "source": "vatex", "video_id": "IBg3LfOHYFI_000013_000023", "video_description": "A woman demonstrates how to fold orange origami paper into various shapes, including triangles and butterflies, with a child's song playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to fold orange origami paper into various shapes, including triangles and butterflies, with a child's song playing in the background.", "clean_property": {"obj": "origami paper"}, "target_prompt": "A woman demonstrates how to fold colorful plastic sheets into various shapes, including triangles and butterflies, with a child's song playing in the background.", "target_property": {"obj": "plastic sheets"}, "evaluation_question": "Is the material being folded in the video **origami paper**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to fold orange origami paper into various shapes, including triangles and butterflies, with a child's song playing in the background. -BC3P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35a10ed8235e4c97960cf7f6daa4f685.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "35e2093c1dec42508c7d6e950b081087", "source": "vatex", "video_id": "54s2722ZB5I_000013_000023", "video_description": "A group of young girls are practicing a dance routine in a dance studio, facing a mirror and wearing top hats, under the direction of an instructor.", "task": "ObjectRecognition", "clean_prompt": "An instructor guiding a group of young girls practicing a dance routine in a studio.", "clean_property": {"obj": "instructor"}, "target_prompt": "A singer leading a group of young girls practicing a song in a studio.", "target_property": {"obj": "singer"}, "evaluation_question": "Is the person leading the group an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instructor guiding a group of young girls practicing a dance routine in a studio. ''!,%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a7e959c308b4ac5a927c8c3f46f70b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a42b011544c74359b651e1a1bb7df6cc", "source": "vatex", "video_id": "yH0nta6KQHE_000094_000104", "video_description": "A time-lapse video shows a woman and a man weaving fabric using looms and other weaving devices.", "task": "AttributeRecognition", "clean_prompt": "A woman and a man weaving fabric using a wooden loom.", "clean_property": {"obj": "loom", "attribute": "wooden"}, "target_prompt": "A woman and a man weaving fabric using a metal loom.", "target_property": {"obj": "loom", "attribute": "metal"}, "evaluation_question": "Is the loom made of **wood**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman and a man weaving fabric using a wooden loom. FE@1T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/992ce068d58742fe89131010f8dacf33.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3b6f0dd830ba4862be761bf7255fcadf", "source": "vatex", "video_id": "P-VTnhumswY_000031_000041", "video_description": "A man and a woman are playing ping pong on a table set flat on the ground, while a small dog tries to interfere by chasing the ball.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a dog.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "dog"}, "target_prompt": "A person standing behind a dog.", "target_property": {"obj_1": "person", "relation": "behind", "obj_2": "dog"}, "evaluation_question": "Is the person to the **left** of a dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a dog. LYI%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/103f8a16eab04d78bc3f20a839e2648e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0ea94ea798a749cfa9a930c33f488afa", "source": "vatex", "video_id": "jQjNdmkqHpg_000085_000095", "video_description": "A woman is demonstrating how to sew using a sewing machine, including preparing and cutting fabric.", "task": "Counting", "clean_prompt": "A woman is demonstrating how to sew using a sewing machine, with six people watching her closely.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A woman is demonstrating how to sew using a sewing machine, with one person watching her closely.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **six** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to sew using a sewing machine, with six people watching her closely. XBS@J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a46d1c6b935440aa078d694bdc404d5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "67896e484f4b4e8daf808bee8929b763", "source": "vatex", "video_id": "MhQGVBOx96w_000001_000011", "video_description": "A woman is demonstrating a leg exercise by squeezing a small, blue, bouncy ball between her legs in a fitness video.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating a leg exercise by squeezing a small, blue, bouncy ball between her legs.", "clean_property": {"obj": "ball"}, "target_prompt": "A woman demonstrating a leg exercise by squeezing a small cushion between her legs.", "target_property": {"obj": "cushion"}, "evaluation_question": "Is the object being squeezed in the video a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating a leg exercise by squeezing a small, blue, bouncy ball between her legs. ?)!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de41b7cf2fef4f5ab8d466b7ed012cda.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fcf8a20a06494bbbb8f4fa5739a43575", "source": "vatex", "video_id": "h9m7Jsw5vrw_000046_000056", "video_description": "A man is performing push-ups in a gymnasium while being guided by a trainer on proper form.", "task": "ActionRecognition", "clean_prompt": "A person performing push-ups in a gymnasium.", "clean_property": {"obj": "person", "action": "push up", "target": null}, "target_prompt": "A person doing jumping jacks in a gymnasium.", "target_property": {"obj": "person", "action": "jumping jacks", "target": null}, "evaluation_question": "Is the person **performing push-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing push-ups in a gymnasium. FEEB-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d74ad3583f3b4de181cff9ca30e00c95.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "baa93770de504dec8223fce31ffeeb9e", "source": "vatex", "video_id": "tEpRURa-1gQ_000000_000010", "video_description": "A person is washing a golden retriever dog outside in the sunlight, using a bucket of water. The dog is being positioned and pulled towards the bucket during the bath.", "task": "AttributeRecognition", "clean_prompt": "A person is washing a golden retriever dog outside in the sunlight using a bucket of water.", "clean_property": {"obj": "dog", "attribute": "golden retriever"}, "target_prompt": "A person is washing a bulldog outside in the sunlight using a bucket of water.", "target_property": {"obj": "dog", "attribute": "bulldog"}, "evaluation_question": "Is the dog a **golden retriever**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is washing a golden retriever dog outside in the sunlight using a bucket of water. FE)IL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6433ab2b896e4bbe9325953d77ff7c02.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e2a3f16261e845bfb394099d2ffd5a19", "source": "vatex", "video_id": "5kdhoRxtwvI_000030_000040", "video_description": "A man is outside in a snowy yard, repeatedly swinging an axe to chop a large piece of wood into smaller pieces.", "task": "ActionRecognition", "clean_prompt": "A person chopping wood in a snowy yard.", "clean_property": {"obj": "person", "action": "chopping wood", "target": "wood"}, "target_prompt": "A person building a snowman in a snowy yard.", "target_property": {"obj": "person", "action": "building a snowman", "target": "snow"}, "evaluation_question": "Is the person **chopping wood**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person chopping wood in a snowy yard. \u00b7/!0&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/05ef2f698771475e9994dcaa57e3377a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7db0e4dd50964794826f62db0ffe65c6", "source": "vatex", "video_id": "FM9ZVAyt_F4_000011_000021", "video_description": "A man is running barefoot on a motorized treadmill in a workout facility, shown in slow motion.", "task": "ActionRecognition", "clean_prompt": "A person running on a treadmill in a workout facility.", "clean_property": {"obj": "person", "action": "running on treadmill", "target": null}, "target_prompt": "A person walking on a treadmill in a workout facility.", "target_property": {"obj": "person", "action": "walking on a treadmill", "target": null}, "evaluation_question": "Is the person **running** on the treadmill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person running on a treadmill in a workout facility. BSXN@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d55f9e459a24de0a769a02b41b63a48.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7b1b7a48032241e7a189ca7a34147ffe", "source": "vatex", "video_id": "x6m12TincPk_000151_000161", "video_description": "A woman is in a bathroom using an electric razor to shave all the hair off her head.", "task": "ObjectRecognition", "clean_prompt": "A woman in a bathroom using an electric razor to shave all the hair off her head.", "clean_property": {"obj": "person"}, "target_prompt": "A man in a bathroom using an electric razor to shave all the hair off his head.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a bathroom using an electric razor to shave all the hair off her head. ?U0UU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8456535846a64b849ee7345f3270eb2e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7792fb0e21d43a1ad61acaab0cec6f7", "source": "vatex", "video_id": "82EPrYttZKA_000059_000069", "video_description": "Three people are playing a game of Monopoly at a table, with one person shaking dice, another arranging game pieces, and the third observing.", "task": "Counting", "clean_prompt": "Three people are playing a game of Monopoly at a table, with one person shaking six dice, another arranging game pieces, and the third observing.", "clean_property": {"obj": "dice", "count": "six"}, "target_prompt": "Three people are playing a game of Monopoly at a table, with one person shaking two dice, another arranging game pieces, and the third observing.", "target_property": {"obj": "dice", "count": "two"}, "evaluation_question": "Are there exactly **six** dice being shaken?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are playing a game of Monopoly at a table, with one person shaking six dice, another arranging game pieces, and the third observing. SG/PD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19eb91b69f4d46879c57281018f819da.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e29361a887f74afda9fdac2a01862a2d", "source": "vatex", "video_id": "CITK0KMw6wE_000000_000010", "video_description": "A boy is preparing to play a saxophone in front of a crowd in a room.", "task": "SpatialUnderstanding", "clean_prompt": "A saxophone farther from the camera than a crowd in a room.", "clean_property": {"obj_1": "saxophone", "relation": "farther from the camera than", "obj_2": "crowd"}, "target_prompt": "A saxophone closer to the camera than a crowd in a room.", "target_property": {"obj_1": "saxophone", "relation": "closer to the camera than", "obj_2": "crowd"}, "evaluation_question": "Is the saxophone **farther from the camera than** the crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A saxophone farther from the camera than a crowd in a room. =7+RR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fe3bd0426bf743d9ad0379587ec0b1ef.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1518bc39f2a45599f7273acb35c40b9", "source": "vatex", "video_id": "VOUl3u_7Caw_000004_000014", "video_description": "In a snowy yard, a group of children and adults are playing and building a snowman. They pose and take pictures with the snowman.", "task": "SpatialUnderstanding", "clean_prompt": "A man closer to the camera than an adult in a snowy yard.", "clean_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "adult"}, "target_prompt": "A man further from the camera than an adult in a snowy yard.", "target_property": {"obj_1": "man", "relation": "further from the camera than", "obj_2": "adult"}, "evaluation_question": "Is the man **closer to the camera than** the adult?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man closer to the camera than an adult in a snowy yard. XQFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5518a7267f534476a1a900bdb23850b8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "47cba4df4cad435fa658d5240b178af3", "source": "vatex", "video_id": "vVRA70DLFmg_000058_000068", "video_description": "A group of polo players on horseback are playing a game of polo on a large open grass field. The players are in team colors and are carrying sticks to play the game. The scene is viewed from high overhead with music playing in the background.", "task": "ActionRecognition", "clean_prompt": "A polo player playing polo on a large open grass field.", "clean_property": {"obj": "polo player", "action": "playing polo", "target": null}, "target_prompt": "A polo player watching polo on a large open grass field.", "target_property": {"obj": "polo player", "action": "watching polo", "target": null}, "evaluation_question": "Is the polo player **playing** polo?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A polo player playing polo on a large open grass field. LYLBK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3643dc1fece34b1faae40d70c76a7994.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "371b703e4cc84a48bad24096db13b7de", "source": "vatex", "video_id": "B0EKYDSv_yQ_000002_000012", "video_description": "A young girl is cooking scrambled eggs on a stove using a spatula, preparing the meal for herself and her mother.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the right of a frying pan with scrambled eggs cooking on the stove.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "eggs"}, "target_prompt": "A girl standing to the left of a frying pan with scrambled eggs cooking on the stove.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "frying pan"}, "evaluation_question": "Is the girl to the **right** of the frying pan?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the right of a frying pan with scrambled eggs cooking on the stove. >V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7febc03441aa471ea3776305df206eca.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a863594ec78144099205d6ddaf2abc04", "source": "vatex", "video_id": "oTHRujgyKLo_000011_000021", "video_description": "A woman is applying makeup to her face and neck using a brush while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A woman applying makeup to her face and neck using a brush.", "clean_property": {"obj": "person"}, "target_prompt": "A child painting with colorful crayons on a large sheet of paper.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman applying makeup to her face and neck using a brush. L-|W%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7dfe920ee43b45e4b72e15e95456fe08.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f49bacec76ad440c92dcf7101180e141", "source": "vatex", "video_id": "WeXnmmh_GpE_000074_000084", "video_description": "A group of children are playing various games, including kickball and basketball, on a playground and sports court during recess. A woman is filming the event with her phone, occasionally cheering and struggling with the camera.", "task": "ActionRecognition", "clean_prompt": "A child playing basketball on a sports court.", "clean_property": {"obj": "child", "action": "playing basketball", "target": null}, "target_prompt": "A child playing soccer on a sports field.", "target_property": {"obj": "child", "action": "playing soccer", "target": null}, "evaluation_question": "Is the child **playing basketball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child playing basketball on a sports court. \u00b7)!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df9a064c79a6400195144203d0d49a1f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "119d95a879a2411fad15509fb7f4ca7c", "source": "vatex", "video_id": "VawlEZaX0_g_000195_000205", "video_description": "A woman is in her kitchen explaining and demonstrating how to bake chocolate chip cookies, including timing and recipe tips.", "task": "Counting", "clean_prompt": "Three people in a kitchen demonstrating how to bake chocolate chip cookies, sharing tips and timing.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in a kitchen demonstrating how to bake chocolate chip cookies, sharing tips and timing.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in a kitchen demonstrating how to bake chocolate chip cookies, sharing tips and timing. !0D=|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a0429f5c2aee4f8283d2bdbb66914faf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "66ca192369474c099364ba2774028489", "source": "vatex", "video_id": "EeaJD7UzSkk_000000_000010", "video_description": "An elderly man is attempting to write on a piece of paper using a black pen, but his hand is shaking due to tremors.", "task": "Counting", "clean_prompt": "An elderly man is attempting to write on two pieces of paper using a black pen, but his hand is shaking due to tremors.", "clean_property": {"obj": "paper", "count": "two"}, "target_prompt": "An elderly man is attempting to write on one piece of paper using a black pen, but his hand is shaking due to tremors.", "target_property": {"obj": "paper", "count": "one"}, "evaluation_question": "Are there exactly **two** pieces of paper being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An elderly man is attempting to write on two pieces of paper using a black pen, but his hand is shaking due to tremors. UHU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f0e8e00838aa4bd19c21887a1e81fd5f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4f9f48dffb1342ee9f7d1a5340e3cd47", "source": "vatex", "video_id": "0lg0_CVvLGU_000010_000020", "video_description": "A large group of people are snowboarding down a snowy slope at night, with one man falling down during the activity.", "task": "Counting", "clean_prompt": "Three snowboarders racing down a snowy slope at night.", "clean_property": {"obj": "snowboarder", "count": "three"}, "target_prompt": "One snowboarder racing down a snowy slope at night.", "target_property": {"obj": "snowboarder", "count": "one"}, "evaluation_question": "Are there exactly **three** snowboarders racing down the slope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three snowboarders racing down a snowy slope at night. !0)!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8bff2b6cf6d649548ad3ab5ddbfc7dde.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c08011fc263419eb057939d358be0b2", "source": "vatex", "video_id": "_l3JTGMjuYk_000013_000023", "video_description": "In a gymnasium, a man is instructing a woman and the person filming on how to properly kick a soccer ball. He demonstrates the technique and passes the ball to the woman.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a woman in a gymnasium.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "woman"}, "target_prompt": "A man standing to the right of a woman in a gymnasium.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "woman"}, "evaluation_question": "Is the man to the **left** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a woman in a gymnasium. P+V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cbc72aed1f54463885ff5c5cec2e8c85.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6aa70eb0d01f4555a60763189b2950c4", "source": "vatex", "video_id": "7nvm0QypB3U_000061_000071", "video_description": "A chef demonstrates how to prepare and cook vegetables using various methods, including boiling, frying, and saut\u00e9ing, and then plates them with meat.", "task": "Counting", "clean_prompt": "A chef demonstrates how to prepare and cook seven vegetables using various methods, including boiling, frying, and saut\u00e9ing, and then plates them with meat.", "clean_property": {"obj": "vegetable", "count": "seven"}, "target_prompt": "A chef demonstrates how to prepare and cook four vegetables using various methods, including boiling, frying, and saut\u00e9ing, and then plates them with meat.", "target_property": {"obj": "vegetable", "count": "four"}, "evaluation_question": "Are there exactly **seven** vegetables being prepared by the chef?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef demonstrates how to prepare and cook seven vegetables using various methods, including boiling, frying, and saut\u00e9ing, and then plates them with meat. LKLFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11b48dfffd6e411baa6d9055942112f4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3277cc7cfc1142b982d431d64c3ca08f", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "ActionRecognition", "clean_prompt": "A person writing 'Happy Birthday' in decorative cursive and print on a sheet of paper.", "clean_property": {"obj": "person", "action": "writing", "target": "paper"}, "target_prompt": "A person drawing on a sheet of paper.", "target_property": {"obj": "person", "action": "drawing", "target": "paper"}, "evaluation_question": "Is the person **writing** on the paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person writing 'Happy Birthday' in decorative cursive and print on a sheet of paper. UF@.O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3deaaac5190f4ccba5b0d466d8aad255.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8231b5894c284485bb2fa680678b99bd", "source": "vatex", "video_id": "WASt2JwMglY_000002_000012", "video_description": "An animation of a circling globe is shown followed by a title card.", "task": "ActionRecognition", "clean_prompt": "A person mopping the floor.", "clean_property": {"obj": "person", "action": "mopping floor", "target": null}, "target_prompt": "A person dancing.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **mopping the floor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person mopping the floor. $ZO%1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ca33c0986ae5426a8848c0ba64f87c22.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "60ff08b2be474692809dfbafc49621dd", "source": "vatex", "video_id": "G-UDM5Npk_8_000501_000511", "video_description": "A woman is demonstrating and explaining the process of bookbinding, including measuring, cutting, and gluing materials to create book covers and spine end covers.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating the process of bookbinding using cardboard as craft material.", "clean_property": {"obj": "craft material", "attribute": "cardboard"}, "target_prompt": "A woman demonstrating the process of bookbinding using fabric as craft material.", "target_property": {"obj": "craft material", "attribute": "fabric"}, "evaluation_question": "Is the craft material being used **cardboard**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating the process of bookbinding using cardboard as craft material. 1*=1|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b572f60064d24ebf9e9fec380eb1c913.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ccb270991fb94176bb581f4ca6d8bc30", "source": "vatex", "video_id": "SAISuCs1IiI_000017_000027", "video_description": "A large, muscular man is working out his arms using various machines in a gym. He is wearing black clothing and a gray shirt at different times, performing exercises like triceps extensions and pull downs.", "task": "SpatialUnderstanding", "clean_prompt": "A weight machine farther from the camera than a person in a gym.", "clean_property": {"obj_1": "weight machine", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A weight machine closer to the camera than a person in a gym.", "target_property": {"obj_1": "weight machine", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the weight machine **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A weight machine farther from the camera than a person in a gym. 'LPO7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d25c733c29034841aff36bda78195051.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "11b1efcea9e1419db9c5de9379bff11b", "source": "vatex", "video_id": "pO7wu-p1Fls_000133_000143", "video_description": "A beekeeper is using smoke to manage bees and extract honey from a hive located in a log and a concrete tube in a remote area.", "task": "ObjectRecognition", "clean_prompt": "A beekeeper using smoke to manage bees and extract honey from a hive.", "clean_property": {"obj": "honey"}, "target_prompt": "A chef preparing jam in a kitchen.", "target_property": {"obj": "jam"}, "evaluation_question": "Is the product being extracted in the video **honey**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A beekeeper using smoke to manage bees and extract honey from a hive. >NK@P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56237e423dc74c3592ecc2926c84a245.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c7b2d73a3d3422e997b2c06e8074cda", "source": "vatex", "video_id": "O0sdVwdE-lM_000006_000016", "video_description": "A man is sitting at a table, using an inhaler after receiving it from a woman speaking a foreign language. He is being instructed on how to use it properly.", "task": "ActionRecognition", "clean_prompt": "A man using an inhaler at a table.", "clean_property": {"obj": "man", "action": "using inhaler", "target": null}, "target_prompt": "A man throwing an inhaler at a table.", "target_property": {"obj": "man", "action": "throwing inhaler", "target": null}, "evaluation_question": "Is the man **using** an inhaler?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using an inhaler at a table. ;$Z9\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1cd50118b75b476a9aba62f4d200d489.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d097ef9600245439387427d6db5f7c7", "source": "vatex", "video_id": "eK_gVBy2kC8_000000_000010", "video_description": "A commercial demonstrating a three dollar corded mini drill being used to drill into a piece of wood clamped in a vise.", "task": "ObjectRecognition", "clean_prompt": "A commercial demonstrating a three dollar corded mini drill being used to drill into a piece of wood clamped in a vise.", "clean_property": {"obj": "wood"}, "target_prompt": "A commercial demonstrating a three dollar corded mini drill being used to drill into a piece of metal clamped in a vise.", "target_property": {"obj": "metal"}, "evaluation_question": "Is the material being drilled into in the video **wood**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A commercial demonstrating a three dollar corded mini drill being used to drill into a piece of wood clamped in a vise. Y))!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f81e94a677cf4d9aad924f785b45e787.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "27a7d3c8faa74c35893417e41a03568a", "source": "vatex", "video_id": "TgGQ6awU5HE_000033_000043", "video_description": "A man is demonstrating how to tie and untie various knots, including a slip knot, using a rope attached to a pole.", "task": "AttributeRecognition", "clean_prompt": "A person who is a construction worker demonstrating how to tie and untie various knots with a rope attached to a pole.", "clean_property": {"obj": "person", "attribute": "construction worker"}, "target_prompt": "A chef demonstrating how to tie and untie various knots with a rope attached to a pole.", "target_property": {"obj": "person", "attribute": "chef"}, "evaluation_question": "Is the person a **construction worker**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who is a construction worker demonstrating how to tie and untie various knots with a rope attached to a pole. BSQTV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61ee4d1aa1a049ceabf423b57079c49e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0b10211da7004a8cb1cc531b6e830b78", "source": "vatex", "video_id": "X2Qn08i-I48_000062_000072", "video_description": "A man is playing a song on a trumpet in a dimly lit room.", "task": "Counting", "clean_prompt": "Two people in a dimly lit room, one playing a song on a trumpet.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person in a dimly lit room, playing a song on a trumpet.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in a dimly lit room, one playing a song on a trumpet. )!%|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ffb0784194e40779779df7569913790.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "47b62e05995441f19db33e3a03284c1a", "source": "vatex", "video_id": "chQmm-R1Io4_000056_000066", "video_description": "A young man is practicing field goal kicks on a football field, successfully scoring goals.", "task": "Counting", "clean_prompt": "A young man is practicing field goal kicks on a football field, successfully scoring four goals.", "clean_property": {"obj": "goal", "count": "four"}, "target_prompt": "A young man is practicing field goal kicks on a football field, successfully scoring one goal.", "target_property": {"obj": "goal", "count": "one"}, "evaluation_question": "Are there exactly **four** goals scored by the young man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is practicing field goal kicks on a football field, successfully scoring four goals. UF/O-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/66924674fe934642834715962ed87eaa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "390d2d792ac34c1e9acab202a7e1ebaf", "source": "vatex", "video_id": "J4YjMOdSx9g_000008_000018", "video_description": "A male entertainer performs a sword swallowing act in front of an audience, involving inserting and removing a sword from his mouth, wiping it with a cloth, and placing it in a basket.", "task": "Counting", "clean_prompt": "A male entertainer performs a sword swallowing act in front of an audience of six.", "clean_property": {"obj": "audience", "count": "six"}, "target_prompt": "A male entertainer performs a sword swallowing act in front of an audience of two.", "target_property": {"obj": "audience", "count": "two"}, "evaluation_question": "Are there exactly **six** audience members watching the performance?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A male entertainer performs a sword swallowing act in front of an audience of six. NK-TS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c839380a8bae4521827420d307f8edb9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "09fa5b9117904eb89053f4c778deb39b", "source": "vatex", "video_id": "d8J6Ss9iOXs_000000_000010", "video_description": "A group of teenage boys in navy blue practice American football on a field, focusing on snapping, holding, and kicking the ball through the uprights.", "task": "AttributeRecognition", "clean_prompt": "A football player wearing navy blue practicing American football on a field.", "clean_property": {"obj": "football player", "attribute": "wearing navy blue"}, "target_prompt": "A football player wearing bright red practicing American football on a field.", "target_property": {"obj": "football player", "attribute": "wearing bright red"}, "evaluation_question": "Is the football player wearing **navy blue**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A football player wearing navy blue practicing American football on a field. GSJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6314740e061e4453a516e11c0c20aabc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "961a2cfdb2f04957aba79a0c401a71b0", "source": "vatex", "video_id": "FpkEF-Wrc0g_000004_000014", "video_description": "A class of young ballerinas, led by an instructor, practice ballet in a circle while wearing tutus.", "task": "Counting", "clean_prompt": "Four ballerinas practicing ballet in a circle while wearing tutus.", "clean_property": {"obj": "ballerina", "count": "four"}, "target_prompt": "One ballerina practicing ballet alone in a spotlight.", "target_property": {"obj": "ballerina", "count": "one"}, "evaluation_question": "Are there exactly **four** ballerinas practicing in a circle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four ballerinas practicing ballet in a circle while wearing tutus. ))'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/22994f3ca9404e028fe0ff18952e3d54.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3c5123d36f944ec92b8fea6ef00077f", "source": "vatex", "video_id": "07wNWA70ht4_000076_000086", "video_description": "A large international poker tournament is taking place with various groups of people playing poker at tables. A commentator provides background information about the tournament.", "task": "SpatialUnderstanding", "clean_prompt": "A poker table located to the right of a commentator.", "clean_property": {"obj_1": "poker table", "relation": "right of", "obj_2": "commentator"}, "target_prompt": "A poker table located to the left of a commentator.", "target_property": {"obj_1": "poker table", "relation": "left of", "obj_2": "commentator"}, "evaluation_question": "Is the poker table to the **right** of the commentator?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A poker table located to the right of a commentator. RR(;7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/90de2bee2cf04c338d349fb1434d7065.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ffcaf6d955804277b377e2a3d0de9c18", "source": "vatex", "video_id": "-cqADbIiZ1Q_000129_000139", "video_description": "A baseball game is in progress with a pitcher pitching a softball underhand to a batter and a catcher in an orange uniform. An umpire is present behind home base.", "task": "AttributeRecognition", "clean_prompt": "A catcher wearing an orange uniform during a baseball game.", "clean_property": {"obj": "catcher", "attribute": "wearing orange uniform"}, "target_prompt": "A catcher wearing a blue uniform during a baseball game.", "target_property": {"obj": "catcher", "attribute": "wearing a blue uniform"}, "evaluation_question": "Is the catcher wearing an **orange** uniform?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A catcher wearing an orange uniform during a baseball game. ))!%/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/69c73045a30948158acefef484e0610f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "36ea0165e5c8452885416b79ac282cb8", "source": "vatex", "video_id": "MatpRf5p5io_000012_000022", "video_description": "A large group of young adults are playing a game of dodgeball on a grassy area surrounded by buildings.", "task": "AttributeRecognition", "clean_prompt": "A group of young adults playing dodgeball on a grassy area.", "clean_property": {"obj": "person", "attribute": "young adult"}, "target_prompt": "A group of elderly people playing dodgeball on a grassy area.", "target_property": {"obj": "person", "attribute": "elderly"}, "evaluation_question": "Are the players in the video young adults?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young adults playing dodgeball on a grassy area. !0~#B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/432778fb3be74109a5453f316f4f8848.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9de5998149a4c0da546617baee6ad1f", "source": "vatex", "video_id": "Ysx54fi7QrQ_000167_000177", "video_description": "A woman demonstrates sewing techniques at a sewing machine, including how to stitch fabric for inserting elastic.", "task": "AttributeRecognition", "clean_prompt": "A person who is a seamstress demonstrating sewing techniques at a sewing machine.", "clean_property": {"obj": "person", "attribute": "seamstress"}, "target_prompt": "A person who is a chef demonstrating cooking techniques in a kitchen.", "target_property": {"obj": "person", "attribute": "chef"}, "evaluation_question": "Is the person a **seamstress**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who is a seamstress demonstrating sewing techniques at a sewing machine. =)FEM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e1bf94969f141a8975f73ac825abe06.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c9ccd397dec460d8f7d32cc924c04b5", "source": "vatex", "video_id": "V18XWMwhP8M_000000_000010", "video_description": "A woman is in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card.", "task": "SpatialUnderstanding", "clean_prompt": "A car is positioned to the left of a person at a drive-thru ATM.", "clean_property": {"obj_1": "car", "relation": "left of", "obj_2": "person"}, "target_prompt": "A car is positioned to the right of a person at a drive-thru ATM.", "target_property": {"obj_1": "car", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the car to the **left** of the person at the drive-thru ATM?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A car is positioned to the left of a person at a drive-thru ATM. RIE7J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0912df3d00c447d6aa5036a4b818c90d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cde4d087e84e48e282c9566f2f55aaf4", "source": "vatex", "video_id": "5379yXlh9og_000000_000010", "video_description": "A male athlete is practicing and performing long jump and triple jump on an outdoor track, landing in a sand pit.", "task": "ObjectRecognition", "clean_prompt": "A male athlete practicing long jump and triple jump, landing in a sand pit.", "clean_property": {"obj": "sand pit"}, "target_prompt": "A male athlete practicing long jump and triple jump, landing in a water pool.", "target_property": {"obj": "water pool"}, "evaluation_question": "Is the athlete landing in a **sand pit**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A male athlete practicing long jump and triple jump, landing in a sand pit. FE=@#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d87ca01d5b5a49428312a07158c24989.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8075b249ec4c4e2d890d3873b1986396", "source": "vatex", "video_id": "158_R3Ow1_c_000044_000054", "video_description": "A man is demonstrating a white vacuum cleaner on a black rug with the word 'Maytag' printed on it in a store setting.", "task": "ActionRecognition", "clean_prompt": "A person vacuuming a floor with a white vacuum cleaner on a black rug.", "clean_property": {"obj": "person", "action": "vacuuming floor", "target": "rug"}, "target_prompt": "A person cleaning windows near a rug.", "target_property": {"obj": "person", "action": "cleaning windows", "target": "rug"}, "evaluation_question": "Is the person **vacuuming** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person vacuuming a floor with a white vacuum cleaner on a black rug. =S-LF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f7f024e741d7481188d4c3d2d25e9efb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0900987990b24751a36a7cb462d690e9", "source": "vatex", "video_id": "w0b3iw74zHE_000145_000155", "video_description": "A man and a woman are trimming the nails of a cat and a dog. The woman holds and pets the animals to calm them while the man clips their nails.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a dog.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "dog"}, "target_prompt": "A woman closer to the camera than a dog.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "dog"}, "evaluation_question": "Is the woman **farther from the camera than** the dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a dog. ;D&GX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/141ec25138d24b108350dd901a586935.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "23aeaa7d8f074939a2cabc0bc46a6eab", "source": "vatex", "video_id": "o-MhYRW1Stk_000002_000012", "video_description": "A group of blindfolded people are conducting a blind taste test, tasting food with a spoon.", "task": "Counting", "clean_prompt": "A group of blindfolded people are conducting a blind taste test, tasting seven different types of food with a spoon.", "clean_property": {"obj": "food", "count": "seven"}, "target_prompt": "A group of blindfolded people are conducting a blind taste test, tasting four different types of food with a spoon.", "target_property": {"obj": "food", "count": "four"}, "evaluation_question": "Are there exactly **seven** types of food being tasted?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of blindfolded people are conducting a blind taste test, tasting seven different types of food with a spoon. !D|W*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/84fe9e22bbaf4d829f5391a3bc567770.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a264d9d653f4739b16a2b738e069af8", "source": "vatex", "video_id": "1V_Njbc_dos_000256_000266", "video_description": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process.", "task": "ActionRecognition", "clean_prompt": "A person drawing a picture of a woman's face with a pencil on a white piece of paper.", "clean_property": {"obj": "person", "action": "drawing", "target": "paper"}, "target_prompt": "A person painting a landscape on a canvas.", "target_property": {"obj": "person", "action": "painting", "target": "canvas"}, "evaluation_question": "Is the person **drawing** on paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person drawing a picture of a woman's face with a pencil on a white piece of paper. EAMD.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9be3f6b73af843aba068d4112a66a6c8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1e663e2af0f04d9b96cdd9f38924c948", "source": "vatex", "video_id": "q-rj2OXeAek_000088_000098", "video_description": "A woman demonstrates and explains various sewing and embroidery techniques using a needle and blue yarn on beige fabric.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrates sewing techniques using a needle and blue yarn on beige fabric.", "clean_property": {"obj": "yarn", "attribute": "blue"}, "target_prompt": "A woman demonstrates sewing techniques using a needle and red yarn on beige fabric.", "target_property": {"obj": "yarn", "attribute": "red"}, "evaluation_question": "Is the yarn being used **blue**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates sewing techniques using a needle and blue yarn on beige fabric. 2\u00b7#UV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/916f3a55aabd4fed91efd9f6c08769a3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8bd4e06ae706496fbaa650ac7b972887", "source": "vatex", "video_id": "HuHTYY9a4po_000000_000010", "video_description": "Two American football teams, one in red and the other in blue, are playing a game in a stadium. The game is being viewed on a TV screen. The quarterback throws a long pass down the field.", "task": "ObjectRecognition", "clean_prompt": "Two American football teams are playing a game in a stadium, with one team in red and the other in blue. The quarterback throws a long pass down the field.", "clean_property": {"obj": "team_red"}, "target_prompt": "Two American football teams are playing a game in a stadium, with one team in green and the other in blue. The quarterback throws a long pass down the field.", "target_property": {"obj": "team_green"}, "evaluation_question": "Is one of the teams in the video wearing **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two American football teams are playing a game in a stadium, with one team in red and the other in blue. The quarterback throws a long pass down the field. FE+9K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ae47eb010da4fb9890a45fedb1020b8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9721d178843a42beb6e9ef998d6bf3c2", "source": "vatex", "video_id": "xGe0cXA3OnI_000004_000014", "video_description": "A group of people are riding camels in the desert during the daytime. The camels kneel and sit to allow the riders to dismount.", "task": "AttributeRecognition", "clean_prompt": "A person wearing a head cover riding a camel in the desert.", "clean_property": {"obj": "person", "attribute": "wearing head cover"}, "target_prompt": "A person wearing sunglasses riding a camel in the desert.", "target_property": {"obj": "person", "attribute": "wearing sunglasses"}, "evaluation_question": "Is the person wearing a **head cover**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a head cover riding a camel in the desert. .|FE;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ffd40810315f4281a76ad5cd3bbe4aa0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "318e36f7cc5e46dc84df954a5137c79e", "source": "vatex", "video_id": "89fh_WNDejY_000028_000038", "video_description": "A young boy is lying in bed, trying to hide under a blue blanket while a woman, presumably his mother, attempts to wake him up by pulling the blanket off.", "task": "Counting", "clean_prompt": "A young boy is lying in bed, trying to hide under four blankets while a woman, presumably his mother, attempts to wake him up by pulling the blankets off.", "clean_property": {"obj": "blanket", "count": "four"}, "target_prompt": "A young boy is lying in bed, trying to hide under one blanket while a woman, presumably his mother, attempts to wake him up by pulling the blanket off.", "target_property": {"obj": "blanket", "count": "one"}, "evaluation_question": "Are there exactly **four** blankets on the bed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is lying in bed, trying to hide under four blankets while a woman, presumably his mother, attempts to wake him up by pulling the blankets off. YD!%!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bbbe37bc435047eca508ad865d159b43.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5115ed1ff4ec4d16a43890515471ac48", "source": "vatex", "video_id": "98ieFdWqr3E_000165_000175", "video_description": "A group of people are playing laser tag in a building, primarily in the stairwells. A man with a toy gun is shooting at others, who fall when hit, as he moves through the building.", "task": "AttributeRecognition", "clean_prompt": "A man with a yellow toy gun is shooting at others in a building during a laser tag game.", "clean_property": {"obj": "toy gun", "attribute": "yellow"}, "target_prompt": "A man with a red toy gun is shooting at others in a building during a laser tag game.", "target_property": {"obj": "toy gun", "attribute": "red"}, "evaluation_question": "Is the toy gun **yellow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man with a yellow toy gun is shooting at others in a building during a laser tag game. EHU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5eb078e757504072971d06f1648670ff.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0dcd4a69c9b0437d9ed774d804a36e5b", "source": "vatex", "video_id": "W1Cxl-vz0Vc_000000_000010", "video_description": "A large group of people are roller skating in an indoor rink with wooden flooring, surrounded by colorful flashing lights and loud music.", "task": "SpatialUnderstanding", "clean_prompt": "Lights to the left of the rink.", "clean_property": {"obj_1": "lights", "relation": "left of", "obj_2": "rink"}, "target_prompt": "Lights to the right of the rink.", "target_property": {"obj_1": "lights", "relation": "right of", "obj_2": "rink"}, "evaluation_question": "Are the lights to the **left** of the rink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Lights to the left of the rink. '!-R%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd79f0522abc442c9199e92562e8ea8b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "48133f88827f49148d91f0a1a8871941", "source": "vatex", "video_id": "PetC18IbTtQ_000155_000165", "video_description": "A choir of African American men and women sing gospel songs enthusiastically in a church, led by a pastor. They sway, clap, and sing hymns during a service.", "task": "ObjectRecognition", "clean_prompt": "A choir of African American men and women singing gospel songs enthusiastically in a church.", "clean_property": {"obj": "choir"}, "target_prompt": "An orchestra of musicians playing classical music in a concert hall.", "target_property": {"obj": "orchestra"}, "evaluation_question": "Is the group in the video a **choir**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A choir of African American men and women singing gospel songs enthusiastically in a church. N(=(/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61969295c173417598c94f9ff276e943.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e44ea075543a431e868c07029295e9b9", "source": "vatex", "video_id": "RZNHLZa_OzI_000100_000110", "video_description": "A ballet dancer is performing various movements in a studio while being observed by younger girls.", "task": "ObjectRecognition", "clean_prompt": "A ballet dancer is performing various movements in a studio while being observed by younger girls.", "clean_property": {"obj": "younger girls"}, "target_prompt": "A ballet dancer is performing various movements in a studio while being observed by older women.", "target_property": {"obj": "older women"}, "evaluation_question": "Are the observers in the video **younger girls**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A ballet dancer is performing various movements in a studio while being observed by younger girls. EDIJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4fe10cbc91d04505ac6b7940e56c2071.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7306d9cc8f0c454585187ac108ae92ed", "source": "vatex", "video_id": "CVVTcvOrWv8_000590_000600", "video_description": "Several construction workers are working indoors, using dollies to transport and lay bricks on the ground.", "task": "AttributeRecognition", "clean_prompt": "Several construction workers are working indoors, using dollies to transport and lay red bricks on the ground.", "clean_property": {"obj": "brick", "attribute": "red"}, "target_prompt": "Several construction workers are working indoors, using dollies to transport and lay blue bricks on the ground.", "target_property": {"obj": "brick", "attribute": "blue"}, "evaluation_question": "Are the bricks being laid **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several construction workers are working indoors, using dollies to transport and lay red bricks on the ground. >P.LR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24faa7fb2733470b80ed7ebbd8850018.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d59696bc2b945428b17c2d4ac231c7f", "source": "vatex", "video_id": "A_RumvVrXu4_000138_000148", "video_description": "A group of young people are running through an obstacle course in a gym, performing various gymnastics techniques such as jumping over objects and climbing stairs.", "task": "ObjectRecognition", "clean_prompt": "A group of young people running through an obstacle course in a gym, jumping over obstacles and climbing stairs.", "clean_property": {"obj": "obstacle"}, "target_prompt": "A group of young people running through a gym, trying to break through barriers and climbing walls.", "target_property": {"obj": "barrier"}, "evaluation_question": "Are the young people encountering **obstacles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young people running through an obstacle course in a gym, jumping over obstacles and climbing stairs. '''!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e298a8d4d3ac4537a3713803225c35fb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0ecb80b219a54f42bc13d4066dc3f6d1", "source": "vatex", "video_id": "BgRJnAWjQZU_000293_000303", "video_description": "A young woman in a red shirt and black trousers is demonstrating how to cook scrambled eggs in a black pan on a stove in her kitchen.", "task": "ActionRecognition", "clean_prompt": "A person cooking scrambled eggs in a kitchen.", "clean_property": {"obj": "person", "action": "cooking egg", "target": "egg"}, "target_prompt": "A person burning an egg in a kitchen.", "target_property": {"obj": "person", "action": "burning egg", "target": "egg"}, "evaluation_question": "Is the person **cooking** scrambled eggs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cooking scrambled eggs in a kitchen. NNPO@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5a2cc94d4ceb4aef8b07ee8b891a6f69.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d75c41671fed4c3ab9edf687b42d8d06", "source": "vatex", "video_id": "QgWqXNe-4Ac_000134_000144", "video_description": "A man is in a workshop using a large machine to trim and shape large pieces of wood into smaller planks.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a machine in a workshop.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "machine"}, "target_prompt": "A person repairing a machine in a workshop.", "target_property": {"obj": "person", "action": "repairing a machine", "target": "machine"}, "evaluation_question": "Is the person **using a sledge hammer** on the machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer on a machine in a workshop. )!&!&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5f43a2b7c9284db588a89f069f2d89e2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0f69908ee5a849ae940c7942f70e3ef0", "source": "vatex", "video_id": "weEPAn5xsR4_000008_000018", "video_description": "A group of missionary workers, including a Caucasian woman, visit an African village and play jump rope with the local children.", "task": "ObjectRecognition", "clean_prompt": "A group of missionary workers playing jump rope with local children in an African village.", "clean_property": {"obj": "child"}, "target_prompt": "A group of missionary workers playing jump rope with local adults in an African village.", "target_property": {"obj": "adult"}, "evaluation_question": "Are the participants in the video **children**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of missionary workers playing jump rope with local children in an African village. @XGKU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cbecfb8705504f66a1977fba75a0221f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6ae0a20aff8441da994a6873a21ca939", "source": "vatex", "video_id": "kmFC4sOQZ4c_000007_000017", "video_description": "A community event where people of various ages gather to clean up a natural area, including a riverbank, forest, and ocean. They pick up litter and place it into plastic bags.", "task": "SpatialUnderstanding", "clean_prompt": "Litter farther from the camera than people at a community cleanup event.", "clean_property": {"obj_1": "litter", "relation": "farther from the camera than", "obj_2": "people"}, "target_prompt": "Litter closer to the camera than people at a community cleanup event.", "target_property": {"obj_1": "litter", "relation": "closer to the camera than", "obj_2": "people"}, "evaluation_question": "Is the litter **farther from the camera than** the people?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Litter farther from the camera than people at a community cleanup event. R)*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac1ebf6185954456ada1f664da34cc20.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad55a200514f4d38a7c3ea878989543f", "source": "vatex", "video_id": "1BJOhgPUmy0_000071_000081", "video_description": "A woman demonstrates how to tie a napkin with a rubber band to create a bow shape.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrates how to tie a napkin with a clear rubber band to create a bow shape.", "clean_property": {"obj": "rubber band", "attribute": "clear"}, "target_prompt": "A woman demonstrates how to tie a napkin with a colored rubber band to create a bow shape.", "target_property": {"obj": "rubber band", "attribute": "colored"}, "evaluation_question": "Is the rubber band **clear**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to tie a napkin with a clear rubber band to create a bow shape. \u00b7))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6c998b400c624d69ab23f0a799d2c183.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3abc93b76ba5463193a5040d59c31083", "source": "vatex", "video_id": "WiMM3rliyRI_000003_000013", "video_description": "A man is in a swimming pool demonstrating the front crawl swimming technique, including underwater views.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating the front crawl swimming technique with a strong stroke in a swimming pool, including underwater views.", "clean_property": {"obj": "swimming technique", "attribute": "strong stroke"}, "target_prompt": "A man demonstrating the front crawl swimming technique with a weak stroke in a swimming pool, including underwater views.", "target_property": {"obj": "swimming technique", "attribute": "weak stroke"}, "evaluation_question": "Is the man demonstrating a **strong** stroke?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating the front crawl swimming technique with a strong stroke in a swimming pool, including underwater views. W%U!)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4d9321cba1cc4f478a7e6a8f2d0e2571.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0e7dd1eb50b9478b848565e98ed4f2ff", "source": "vatex", "video_id": "Z5XMRPhi-aE_000035_000045", "video_description": "A group of men are practicing axe throwing at tree stumps and logs, some marked with red hearts, both outdoors and indoors.", "task": "ActionRecognition", "clean_prompt": "A man throwing an axe at a log.", "clean_property": {"obj": "man", "action": "throwing axe", "target": "log"}, "target_prompt": "A man throwing a knife at a target board.", "target_property": {"obj": "man", "action": "throwing knife", "target": "target board"}, "evaluation_question": "Is the man **throwing an axe** at a log?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man throwing an axe at a log. RL0RM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/052f2ba1a06d4f918756c7e8349455a9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5a3b9cc8cf8d49c8a049aca4b75fb831", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "ObjectRecognition", "clean_prompt": "A young man water skiing beside a motorboat, holding onto a pole extending from the boat.", "clean_property": {"obj": "waterskier"}, "target_prompt": "A young man wakeboarding beside a motorboat, holding onto a rope attached to the boat.", "target_property": {"obj": "wakeboarder"}, "evaluation_question": "Is the person in the video a **waterskier**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man water skiing beside a motorboat, holding onto a pole extending from the boat. SLHSF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e6009ff1287e46f6824598337b6ca757.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8b863644b0c1445ca4745a3d0eae3885", "source": "vatex", "video_id": "DhCOD9AGFiM_000000_000010", "video_description": "Two girls are on a sidewalk performing a physical stunt where one girl carries the other on her back and bends over to stretch.", "task": "ObjectRecognition", "clean_prompt": "Two girls are on a sidewalk performing a physical stunt where one girl carries the other on her back and bends over to stretch.", "clean_property": {"obj": "sidewalk"}, "target_prompt": "Two girls are on a grassy field performing a physical stunt where one girl carries the other on her back and bends over to stretch.", "target_property": {"obj": "grass"}, "evaluation_question": "Are the girls performing the stunt on a **sidewalk**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two girls are on a sidewalk performing a physical stunt where one girl carries the other on her back and bends over to stretch. )?G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fbef4288477f4ab292252b6e4c401190.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ffeac4de1e60473a95c4fadd496bb804", "source": "vatex", "video_id": "0cmkVC2QT5Q_000031_000041", "video_description": "A young man is sitting in a chair getting his eyebrows waxed and makeup applied by a beautician in a salon setting.", "task": "SpatialUnderstanding", "clean_prompt": "A chair closer to the camera than a beautician in a salon setting.", "clean_property": {"obj_1": "chair", "relation": "closer to the camera than", "obj_2": "beautician"}, "target_prompt": "A chair further from the camera than a beautician in a salon setting.", "target_property": {"obj_1": "chair", "relation": "further from the camera than", "obj_2": "beautician"}, "evaluation_question": "Is the chair **closer to the camera than** the beautician?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chair closer to the camera than a beautician in a salon setting. VT93", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c8c3e0f6f8048d7bc30429eda131fb9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31b87183ff3e479685700b27028e1ea6", "source": "vatex", "video_id": "qGw6tfeebrU_000036_000046", "video_description": "A man is sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums.", "task": "ObjectRecognition", "clean_prompt": "A man sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums.", "clean_property": {"obj": "mandolin"}, "target_prompt": "A man sitting down, skillfully playing a folk song on a guitar with slow, gentle strums.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the man playing a **mandolin**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums. -!W%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d5b438cf54c348359965f38702e932ce.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4fadc4685ea14c22b222319a065d4e80", "source": "vatex", "video_id": "abaLFY_GI8k_000295_000305", "video_description": "A group of boys are playing volleyball on an outdoor dirt court with a slightly broken net.", "task": "ActionRecognition", "clean_prompt": "A boy playing volleyball on an outdoor dirt court.", "clean_property": {"obj": "boy", "action": "playing volleyball", "target": null}, "target_prompt": "A boy watching volleyball on an outdoor dirt court.", "target_property": {"obj": "boy", "action": "watching volleyball", "target": null}, "evaluation_question": "Is the boy **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy playing volleyball on an outdoor dirt court. RL#E.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b1d8a232c141496792a422d5bc6e6118.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e183c28413b94287b5f3a5fdaba4482b", "source": "vatex", "video_id": "QCIxw5_ZZBU_000029_000039", "video_description": "A woman with long hair is riding a spinning mechanical bull in a bar at night, while a crowd cheers her on.", "task": "SpatialUnderstanding", "clean_prompt": "A crowd cheering to the right of a woman riding a spinning mechanical bull in a bar at night.", "clean_property": {"obj_1": "crowd", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A crowd cheering to the left of a woman riding a spinning mechanical bull in a bar at night.", "target_property": {"obj_1": "crowd", "relation": "left of", "obj_2": "woman"}, "evaluation_question": "Is the crowd to the **right** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd cheering to the right of a woman riding a spinning mechanical bull in a bar at night. ');\u00b7&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b76341e592874d7ab5fca6f84709fd79.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b49eb1bfaae7437cacb26803485e5727", "source": "vatex", "video_id": "to1MWchQCqM_000002_000012", "video_description": "A soccer match is being played in a large stadium filled with fans. A player scores a goal from a corner kick, and the team celebrates.", "task": "ObjectRecognition", "clean_prompt": "A crowd cheering in a large stadium during a soccer match.", "clean_property": {"obj": "crowd"}, "target_prompt": "An audience watching a concert in a large arena.", "target_property": {"obj": "audience"}, "evaluation_question": "Is the group of people in the video a **crowd**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd cheering in a large stadium during a soccer match. ELJMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b62803dec17746a2a8c848c063bbc412.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f2d549d979884f7ba7053240d673e98d", "source": "vatex", "video_id": "2BjyVQyTwoo_000076_000086", "video_description": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays.", "task": "AttributeRecognition", "clean_prompt": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays, appearing aggressive.", "clean_property": {"obj": "man", "attribute": "aggressive"}, "target_prompt": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays, appearing calm.", "target_property": {"obj": "man", "attribute": "calm"}, "evaluation_question": "Is the man appearing **aggressive**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays, appearing aggressive. AO0DU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40b12cf714d2490eb7c8debee0071c0b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b22531314a2a4b97b967ef7dd7cb8738", "source": "vatex", "video_id": "t8Qq5EbUTRM_000013_000023", "video_description": "Two men are in a room practicing a medical technique where one man stands behind the other, crosses his hands on his chest, and lifts him to crack his back.", "task": "Counting", "clean_prompt": "Five men in a room practicing a medical technique where one man stands behind the other, crossing his hands on his chest and lifting him to crack his back.", "clean_property": {"obj": "man_1", "count": "five"}, "target_prompt": "One man in a room practicing a medical technique where he stands behind another man, crossing his hands on his chest and lifting him to crack his back.", "target_property": {"obj": "man_1", "count": "one"}, "evaluation_question": "Are there exactly **five** men in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five men in a room practicing a medical technique where one man stands behind the other, crossing his hands on his chest and lifting him to crack his back. -O9*)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b2fe0e72f00c492f89de29e42a2a2028.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7680128a4d8d4aa3bdcf09638088a037", "source": "vatex", "video_id": "LGDmMs-PiZc_000150_000160", "video_description": "A group of young people, including teenagers and children, are having a playful water balloon fight in a large parking lot.", "task": "ObjectRecognition", "clean_prompt": "A group of young people having a playful water balloon fight in a large parking lot.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing with water balloons in a large parking lot.", "target_property": {"obj": "dog"}, "evaluation_question": "Are the participants in the video **people**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young people having a playful water balloon fight in a large parking lot. HLFE@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc90c7141b9b47bbae91e2026d9f9d23.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a7fbcdd075d4de2a78fbd15ae40f65e", "source": "vatex", "video_id": "bj_kAPISHaE_000109_000119", "video_description": "A young girl is getting her ears pierced by a technician in a store setting, while talking with her friend.", "task": "SpatialUnderstanding", "clean_prompt": "A girl farther from the camera than a technician in a store setting.", "clean_property": {"obj_1": "girl", "relation": "farther from the camera than", "obj_2": "technician"}, "target_prompt": "A girl closer to the camera than a technician in a store setting.", "target_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "technician"}, "evaluation_question": "Is the girl **farther from the camera than** the technician?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl farther from the camera than a technician in a store setting. LYMVJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8924be6d90e840369e84e7878648bb1d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "32a76e911e084be6aaa3f8a4de3b0c77", "source": "vatex", "video_id": "ZiUz5arlOhk_000172_000182", "video_description": "A person is drawing a cartoon character resembling a princess or Snow White using a black pen on white paper, accompanied by whimsical music.", "task": "Counting", "clean_prompt": "A person is drawing a cartoon character resembling a princess using seven black pens on white paper, accompanied by whimsical music.", "clean_property": {"obj": "pen", "count": "seven"}, "target_prompt": "A person is drawing a cartoon character resembling a princess using one black pen on white paper, accompanied by whimsical music.", "target_property": {"obj": "pen", "count": "one"}, "evaluation_question": "Are there exactly **seven** black pens being used to draw the character?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is drawing a cartoon character resembling a princess using seven black pens on white paper, accompanied by whimsical music. ''.!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33d89aff880544b0979a92f1752d36f2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "01d41ff570d648be82489dd3bc74cb44", "source": "vatex", "video_id": "a7duB3wE8uw_000020_000030", "video_description": "A man, possibly a butcher, is in a supermarket or automercado, describing and demonstrating how to cut and prepare meat, focusing on removing fat and discussing tenderness and cooking methods.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to cut and prepare meat on a butcher's block.", "clean_property": {"obj": "butcher's block"}, "target_prompt": "A man demonstrating how to cut and prepare meat on a kitchen counter.", "target_property": {"obj": "kitchen counter"}, "evaluation_question": "Is the man using a **butcher's block** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to cut and prepare meat on a butcher's block. FE1HP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/36162d8d32ab466bb014ddb4f444a198.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2c344e0296554a13baf0e3bae6a40a20", "source": "vatex", "video_id": "XFqgX4D4iVU_000229_000239", "video_description": "A child is sitting and kneeling on the floor, watching and playing with a toy train set that includes a train, railcars, and a track. The train moves slowly along the track, which is indoors.", "task": "ActionRecognition", "clean_prompt": "A child is sitting and kneeling on the floor, watching and playing with a toy train set that includes a train, railcars, and a track.", "clean_property": {"obj": "train", "action": "playing with trains", "target": null}, "target_prompt": "A train crashing into obstacles on the floor.", "target_property": {"obj": "train", "action": "crashing into obstacles", "target": null}, "evaluation_question": "Is the child **playing with trains**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is sitting and kneeling on the floor, watching and playing with a toy train set that includes a train, railcars, and a track. BS@EJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba930b71dda3433e89fcdbb654117863.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "baec9939d69247ff9bbfbdc35ffb8b14", "source": "vatex", "video_id": "_5loyvwKrb0_000000_000010", "video_description": "A girl is performing the moonwalk on a snow and ice-covered street.", "task": "ActionRecognition", "clean_prompt": "A person moon walking on a snow and ice-covered street.", "clean_property": {"obj": "person", "action": "moon walking", "target": null}, "target_prompt": "A person running on a snow and ice-covered street.", "target_property": {"obj": "person", "action": "running", "target": null}, "evaluation_question": "Is the person **moon walking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person moon walking on a snow and ice-covered street. =)NLV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6c40b97bbf6d4995b697d641fecadb92.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a7cf0d6550dc47d194bde925fbe426ee", "source": "vatex", "video_id": "icxsQqVxnoU_000109_000119", "video_description": "A woman is playing a word game similar to Scrabble, using letter tiles and a dictionary to teach others how to play.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a book.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "book"}, "target_prompt": "A person closer to the camera than a book.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "book"}, "evaluation_question": "Is the person **farther from the camera than** the book?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a book. .UMOT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/346d63f778c84ed9a3fdfd0f7b3c8d67.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "67d919ea601f447ebba432047a026be0", "source": "vatex", "video_id": "Ojwg76QZH48_000000_000010", "video_description": "A man is outside in Ottawa during the winter of 2008, demonstrating how to clear large amounts of snow using a hand-held snow scoop and a large shovel. He pushes the snow up a hill and occasionally falls.", "task": "ActionRecognition", "clean_prompt": "A person shoveling snow outside in Ottawa during winter.", "clean_property": {"obj": "person", "action": "shoveling snow", "target": null}, "target_prompt": "A person building a snowman outside in Ottawa during winter.", "target_property": {"obj": "person", "action": "building a snowman", "target": null}, "evaluation_question": "Is the person **shoveling snow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shoveling snow outside in Ottawa during winter. BAAQ%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/22159d39e612405aab2d342081db9fe3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4c43a5fcbdeb434f88fd4d2f2af1b99b", "source": "vatex", "video_id": "DNdZBDJL09E_000004_000014", "video_description": "A man wearing a breathing mask uses a sledgehammer to demolish a bathroom sink.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a sink.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "sink"}, "target_prompt": "A person closer to the camera than a sink.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "sink"}, "evaluation_question": "Is the person **farther from the camera than** the sink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a sink. :J)>S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ce18ae66b1a4279a65b26f6585f8b26.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "63e02154807044c0a7e26f4e9d8cf726", "source": "vatex", "video_id": "m4xsBl0bp9A_000025_000035", "video_description": "A man, acting as a teacher, is demonstrating and explaining math problems on a chalkboard, including equations involving triangles and angles.", "task": "ObjectRecognition", "clean_prompt": "A teacher demonstrating math problems on a chalkboard.", "clean_property": {"obj": "teacher"}, "target_prompt": "A scientist conducting an experiment in a laboratory.", "target_property": {"obj": "scientist"}, "evaluation_question": "Is the person in the video a **teacher**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teacher demonstrating math problems on a chalkboard. U%U0=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3fd78d202df842f29232ec686fbd81a0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "475f5bc9d3b841a0bf03ce9566b818a7", "source": "vatex", "video_id": "QfhXD7SgsBc_000011_000021", "video_description": "A woman is using sign language to interpret songs for a group of deaf people at a live music concert.", "task": "AttributeRecognition", "clean_prompt": "A woman using sign language to interpret songs for a group of deaf people at a live music concert.", "clean_property": {"obj": "audience", "attribute": "deaf"}, "target_prompt": "A woman using sign language to interpret songs for a group of hearing people at a live music concert.", "target_property": {"obj": "audience", "attribute": "hearing"}, "evaluation_question": "Is the audience **deaf**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman using sign language to interpret songs for a group of deaf people at a live music concert. V1#VV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/daa597312f4c4c318bf5b04e447a035a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a99f4bf034aa482a948d6a36d4b55ef4", "source": "vatex", "video_id": "UqAjuPrbD6c_000015_000025", "video_description": "A police officer is riding a Segway at a festival, talking to a person holding a camera. The officer is wearing a helmet and demonstrating the Segway's use for patrolling.", "task": "ActionRecognition", "clean_prompt": "A police officer using a Segway at a festival.", "clean_property": {"obj": "police officer", "action": "using segway", "target": null}, "target_prompt": "A police officer walking through a crowd at a festival.", "target_property": {"obj": "police officer", "action": "walking", "target": "crowd"}, "evaluation_question": "Is the police officer **using a Segway**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A police officer using a Segway at a festival. HL2YJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/65b0db060edc4cee9414c3ca3be0abb6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "871e3aa0e6bf47029977d1d1668000c0", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "SpatialUnderstanding", "clean_prompt": "A card farther from the camera than a chip on a poker table.", "clean_property": {"obj_1": "card", "relation": "farther from the camera than", "obj_2": "chip"}, "target_prompt": "A card closer to the camera than a chip on a poker table.", "target_property": {"obj_1": "card", "relation": "closer to the camera than", "obj_2": "chip"}, "evaluation_question": "Is the card **farther from the camera than** the chip?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A card farther from the camera than a chip on a poker table. FS-CX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95e874adf5c244b8aa3280ecc7a7fec4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eaf0db6d942347bda6e1c7ccec5811d2", "source": "vatex", "video_id": "h8wsO9A9v_c_000016_000026", "video_description": "A young boy is riding a bicycle with training wheels and a yellow basket around a yard and driveway.", "task": "ActionRecognition", "clean_prompt": "A boy riding a bike with training wheels in a yard.", "clean_property": {"obj": "boy", "action": "riding a bike", "target": null}, "target_prompt": "A boy falling off a bike in a yard.", "target_property": {"obj": "boy", "action": "falling off a bike", "target": null}, "evaluation_question": "Is the boy **riding** a bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy riding a bike with training wheels in a yard. ))*--", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/75ca7382c5ce4d76becc5ac068d9906e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2d6a57f029814af3aab2a8f29eb0ddad", "source": "vatex", "video_id": "bcdvuA2FXsU_000000_000010", "video_description": "A young child is sitting in a stroller, shaking his head back and forth, possibly to music, while holding a toy.", "task": "ObjectRecognition", "clean_prompt": "A young child in a stroller, shaking his head back and forth while holding a toy.", "clean_property": {"obj": "toy"}, "target_prompt": "A young child in a stroller, shaking his head back and forth while holding a book.", "target_property": {"obj": "book"}, "evaluation_question": "Is the child holding a **toy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young child in a stroller, shaking his head back and forth while holding a toy. $UMEJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6ad9814185448d09ae50e3d25a6c76e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f8d72c4bbd9b494ba285defda3d2c5f4", "source": "vatex", "video_id": "XCugpFc1CAU_000033_000043", "video_description": "A female news anchor is presenting a top news story in a studio, using a map of a downtown area displayed on a screen to explain the details.", "task": "SpatialUnderstanding", "clean_prompt": "A news anchor presenting a top news story in a studio, farther from the camera than the screen displaying a map of a downtown area.", "clean_property": {"obj_1": "news anchor", "relation": "farther from the camera than", "obj_2": "screen"}, "target_prompt": "A news anchor presenting a top news story in a studio, closer to the camera than the screen displaying a map of a downtown area.", "target_property": {"obj_1": "news anchor", "relation": "closer to the camera than", "obj_2": "screen"}, "evaluation_question": "Is the news anchor **farther from the camera than** the screen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A news anchor presenting a top news story in a studio, farther from the camera than the screen displaying a map of a downtown area. U%W-B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5770f5de814e46bc943040b643e7543f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5e2ae4e0de08401cb7b24ac388f32cd1", "source": "vatex", "video_id": "1d4ZOE0y3e4_000275_000285", "video_description": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her.", "task": "ObjectRecognition", "clean_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her.", "clean_property": {"obj": "clothes"}, "target_prompt": "A young girl is sitting on a messy bed, organizing toys and placing them into a large suitcase while a fan blows air on her.", "target_property": {"obj": "toys"}, "evaluation_question": "Is the girl folding **clothes** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her. FE7;J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e37c51926d44c3e96fd2c44431fa2bd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7d5f549ea8a4bdf8984506f56fbd3d6", "source": "vatex", "video_id": "Q4iLBdTnhjE_000028_000038", "video_description": "A man and a boy are playing music together, with the man on an accordion and the boy on a drum. Both are wearing cowboy hats.", "task": "ActionRecognition", "clean_prompt": "A man playing accordion.", "clean_property": {"obj": "man", "action": "playing accordion", "target": null}, "target_prompt": "A man playing guitar.", "target_property": {"obj": "man", "action": "playing guitar", "target": null}, "evaluation_question": "Is the man **playing accordion**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing accordion. FS>O>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5963b30808824da99927d54b8c7c31d3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a47b22c640194157bd6de03d011fc9f8", "source": "vatex", "video_id": "DijDpS1g03M_000000_000010", "video_description": "A young woman is creating decorative ornaments using yarn, feathers, string, and a piece of plastic. She is spinning yarn on a spindle and hanging the ornaments from the ceiling.", "task": "Counting", "clean_prompt": "A young woman is creating four decorative ornaments using yarn, feathers, string, and a piece of plastic.", "clean_property": {"obj": "ornament", "count": "four"}, "target_prompt": "A young woman is creating one decorative ornament using yarn, feathers, string, and a piece of plastic.", "target_property": {"obj": "ornament", "count": "one"}, "evaluation_question": "Are there exactly **four** decorative ornaments being created?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman is creating four decorative ornaments using yarn, feathers, string, and a piece of plastic. $BC=G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e7280a8e2ba4c4d8ca15f51fa885baf.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5de9fe2ca88e4881aa555440335c9a0e", "source": "vatex", "video_id": "HR47Ib_c9aw_000007_000017", "video_description": "A group of people, including two women and a man, are in a living room drinking shots and interacting in front of a television.", "task": "Counting", "clean_prompt": "Three people in a living room drinking shots and interacting in front of a television.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in a living room drinking shots and interacting in front of a television.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in a living room drinking shots and interacting in front of a television. 0D+)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2926f4e2d5ad4a7faff665871968fa6c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "22b83ad3d564409e9e445028920b108a", "source": "vatex", "video_id": "phpv6WPyKDo_000000_000010", "video_description": "A man demonstrates how to chop green onions quickly and finely using a knife on a wooden cutting board.", "task": "Counting", "clean_prompt": "A man demonstrates how to chop two green onions quickly and finely using a knife on a wooden cutting board.", "clean_property": {"obj": "green onion", "count": "two"}, "target_prompt": "A man demonstrates how to chop four green onions quickly and finely using a knife on a wooden cutting board.", "target_property": {"obj": "green onion", "count": "four"}, "evaluation_question": "Are there exactly **two** green onions being chopped?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to chop two green onions quickly and finely using a knife on a wooden cutting board. MBVP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/81b4d0357e414372bfcfc3ec94ee6f3d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "650719b2575a4dc695384e7736268180", "source": "vatex", "video_id": "q9fj-Qzpgyc_000058_000068", "video_description": "A young woman with ponytails and red highlights is in her room, experiencing difficulty breathing due to an asthma attack. She uses an inhaler to help her breathe.", "task": "ObjectRecognition", "clean_prompt": "A young woman with ponytails and red highlights is in her room, experiencing difficulty breathing due to an asthma attack. She uses an inhaler to help her breathe.", "clean_property": {"obj": "person"}, "target_prompt": "A cat sitting in a room, looking around curiously.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman with ponytails and red highlights is in her room, experiencing difficulty breathing due to an asthma attack. She uses an inhaler to help her breathe. ?/!:=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a8208be1941430994126d7b2562d50b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "098c5509e35f49bdb93478d9504ad109", "source": "vatex", "video_id": "v8DNLQVCPuY_000065_000075", "video_description": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head.", "clean_property": {"obj": "person"}, "target_prompt": "A child plays with a toy while assembling a colorful building block set.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to assemble a floor sweeper by attaching a handle to the mop head. !*!0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/701fc040d8c8489f8e4ae08f8d49ef64.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7cbd929b084c4b9290d633f3847c0191", "source": "vatex", "video_id": "5jg1LgRRypc_000039_000049", "video_description": "A man dressed in black demonstrates exercises, including planks and push-ups, on a mat in a studio or gym setting.", "task": "ObjectRecognition", "clean_prompt": "A man dressed in black demonstrates exercises, including planks and push-ups, on a mat in a studio.", "clean_property": {"obj": "mat"}, "target_prompt": "A man dressed in black demonstrates exercises, including planks and push-ups, on a bench in a studio.", "target_property": {"obj": "bench"}, "evaluation_question": "Is the man exercising on a **mat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man dressed in black demonstrates exercises, including planks and push-ups, on a mat in a studio. FEY@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2508adc3a9e8416db5a01c21488b734c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "131f026464c04d71b5fe3cccd39369d2", "source": "vatex", "video_id": "-asB1gNPw38_000136_000146", "video_description": "A man in cycling gear, wearing a helmet, is riding a bicycle at high speeds on a busy road, trying to keep up with other bikers.", "task": "ActionRecognition", "clean_prompt": "A biker riding a bike on a busy road.", "clean_property": {"obj": "biker", "action": "riding a bike", "target": null}, "target_prompt": "A biker stopping a bike on a busy road.", "target_property": {"obj": "biker", "action": "stopping a bike", "target": null}, "evaluation_question": "Is the biker **riding** a bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A biker riding a bike on a busy road. XFC@P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/127267e6e7ef4e39a8d21ff4c038566e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4f0a2e442bd3406f908b96b333f23720", "source": "vatex", "video_id": "n2k6sl1j1JE_000011_000021", "video_description": "A person is riding a mountain bike down a dirt road with rough terrain, including rocks, puddles, and icy patches. The person suddenly brakes and falls off the bike.", "task": "AttributeRecognition", "clean_prompt": "A person riding a mountain bike down a dirt road with rough terrain.", "clean_property": {"obj": "bike", "attribute": "mountain"}, "target_prompt": "A person riding a road bike down a smooth highway.", "target_property": {"obj": "bike", "attribute": "road bike"}, "evaluation_question": "Is the bike a **mountain** bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a mountain bike down a dirt road with rough terrain. U+XBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/86397514c53f49b7b19bdeacb89df45d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e9a19e80f9e34b8684fe2ca32b4db8bb", "source": "vatex", "video_id": "LB5GuxpNNcg_000028_000038", "video_description": "People are interacting with a display of earrings in a store, examining and switching them between hooks.", "task": "Counting", "clean_prompt": "Two people interacting with a display of earrings in a store, examining and switching them between hooks.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person interacting with a display of earrings in a store, examining and switching them between hooks.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people interacting with the display of earrings?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people interacting with a display of earrings in a store, examining and switching them between hooks. >L-SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1eb0554c3d9f450abc250acb41802460.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42f31dd4474046799ee818dac3709f22", "source": "vatex", "video_id": "h9Fmjxibpc4_000004_000014", "video_description": "A female track athlete performs a high jump at an indoor track competition. She runs towards the bar, clears it successfully, and lands on the mat. The crowd cheers loudly.", "task": "SpatialUnderstanding", "clean_prompt": "A crowd standing to the left of an athlete performing a high jump.", "clean_property": {"obj_1": "crowd", "relation": "left of", "obj_2": "athlete"}, "target_prompt": "A crowd standing to the right of an athlete performing a high jump.", "target_property": {"obj_1": "crowd", "relation": "right of", "obj_2": "athlete"}, "evaluation_question": "Is the crowd to the **left** of the athlete?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd standing to the left of an athlete performing a high jump. FE()V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64ea1b0ed8834372b3de02d6b3c6d552.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2dc99707d8cc4ac0b81d805c037c88fb", "source": "vatex", "video_id": "bHbQMgQtmNE_000002_000012", "video_description": "A woman is demonstrating how to wrap and spin string using a wooden toy and a drop spindle, while instructing a child.", "task": "Counting", "clean_prompt": "A woman is demonstrating how to wrap and spin string using five drop spindles, while instructing a child.", "clean_property": {"obj": "drop spindle", "count": "five"}, "target_prompt": "A woman is demonstrating how to wrap and spin string using one drop spindle, while instructing a child.", "target_property": {"obj": "drop spindle", "count": "one"}, "evaluation_question": "Are there exactly **five** drop spindles being used in the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to wrap and spin string using five drop spindles, while instructing a child. !QSSG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d19eb9c6336345b38b1eed993af52386.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f159ce31b05b4e13b40cafed826642b1", "source": "vatex", "video_id": "xbFechNcpsg_000006_000016", "video_description": "An award ceremony is taking place on stage where two women are presenting awards to a group of men in business suits. One woman is in a red dress. The event is formal with music playing in the background.", "task": "AttributeRecognition", "clean_prompt": "A man wearing business suits at an award ceremony where two women are presenting awards.", "clean_property": {"obj": "man", "attribute": "wearing business suits"}, "target_prompt": "A man wearing casual clothes at an award ceremony where two women are presenting awards.", "target_property": {"obj": "man", "attribute": "wearing casual clothes"}, "evaluation_question": "Is the man wearing **business suits**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing business suits at an award ceremony where two women are presenting awards. 4)OH'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7319067f0854a5ab555f2ef1e68759c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8bd755076cc45a6a0e7288873072b64", "source": "vatex", "video_id": "KdBJS2_7-Cg_000004_000014", "video_description": "A soccer coach discusses the importance and experiences of attending an international goalkeeping conference.", "task": "Counting", "clean_prompt": "A soccer coach discussing the importance of attending an international goalkeeping conference with six players.", "clean_property": {"obj": "coach", "count": "six"}, "target_prompt": "A soccer coach discussing the importance of attending an international goalkeeping conference with three players.", "target_property": {"obj": "coach", "count": "three"}, "evaluation_question": "Are there exactly **six** players with the coach?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A soccer coach discussing the importance of attending an international goalkeeping conference with six players. 3/:FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f4ba4988b1a242de84943c153489b742.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad83213b9e974ea18057a9cb1f5217db", "source": "vatex", "video_id": "e7ft9fizUXQ_000078_000088", "video_description": "A person is creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques on a piece of paper.", "task": "Counting", "clean_prompt": "Five people are creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques on a piece of paper.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "A person is creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques on a piece of paper.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people creating the Christmas card?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people are creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques on a piece of paper. +VRNU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8cb5a687f78b44d7b93ca25efb3ccc27.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "815d890fcdd349c8ad0c22e68f2c12eb", "source": "vatex", "video_id": "7FMweTGNlJ0_000000_000010", "video_description": "A man is swimming in a large indoor pool, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "task": "Counting", "clean_prompt": "A man is swimming in a large indoor pool with two lanes, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "clean_property": {"obj": "pool", "count": "two"}, "target_prompt": "A man is swimming in a large indoor pool with one lane, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool.", "target_property": {"obj": "pool", "count": "one"}, "evaluation_question": "Are there exactly **two** lanes in the pool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is swimming in a large indoor pool with two lanes, performing various swimming maneuvers including diving to the bottom, swimming across the surface, and making turns at the edge of the pool. LFS7S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8825e3e996984b379901de74226621ad.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b2add6038f94cf8926b537a8322cc86", "source": "vatex", "video_id": "x2JkxZT9AMQ_000000_000010", "video_description": "A little boy sneezes and smiles in a room with a man sitting at a table using a computer. A woman is also present, laughing, and a baby is nearby with a stuffed toy.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the left of a woman in a room.", "clean_property": {"obj_1": "boy", "relation": "left of", "obj_2": "woman"}, "target_prompt": "A boy standing to the right of a woman in a room.", "target_property": {"obj_1": "boy", "relation": "right of", "obj_2": "woman"}, "evaluation_question": "Is the boy to the **left** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the left of a woman in a room. FEKP$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1d55489e0aa4d679f87987a0e6e061d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b10fa3a32443442cb210c7a881b69618", "source": "vatex", "video_id": "s5KND8CzUJw_000059_000069", "video_description": "A woman is massaging and applying lotion to a young boy's feet while he lies on a couch. After the massage, the boy gets up and jumps off the couch.", "task": "SpatialUnderstanding", "clean_prompt": "A woman sitting to the left of a couch.", "clean_property": {"obj_1": "woman", "relation": "left of", "obj_2": "couch"}, "target_prompt": "A woman sitting to the right of a couch.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "couch"}, "evaluation_question": "Is the woman to the **left** of the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman sitting to the left of a couch. FITWR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c92a629badd64495bbd2794d89998306.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2ec63cdc916b48d88d2620f9cedba91f", "source": "vatex", "video_id": "N3b2dorwKPg_000004_000014", "video_description": "A person is practicing and recording themselves playing a trumpet in a room with pictures on the wall.", "task": "AttributeRecognition", "clean_prompt": "A person practicing and recording themselves playing a silver trumpet in a room with pictures on the wall.", "clean_property": {"obj": "trumpet", "attribute": "silver"}, "target_prompt": "A person practicing and recording themselves playing a gold trumpet in a room with pictures on the wall.", "target_property": {"obj": "trumpet", "attribute": "gold"}, "evaluation_question": "Is the trumpet being played **silver**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing and recording themselves playing a silver trumpet in a room with pictures on the wall. !0D||", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57d319c976ea45c0866acff35d5b244c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7a541e957c26459196a772ee921bb077", "source": "vatex", "video_id": "R-mnp_08VIc_000122_000132", "video_description": "A young girl is blowing a large bubble with bubble gum while another girl claps behind her.", "task": "SpatialUnderstanding", "clean_prompt": "A girl blowing a large bubble with bubble gum while another girl claps behind her, with girl_1 to the left of girl_2.", "clean_property": {"obj_1": "girl_1", "relation": "left of", "obj_2": "girl_2"}, "target_prompt": "A girl blowing a large bubble with bubble gum while another girl claps behind her, with girl_1 to the right of girl_2.", "target_property": {"obj_1": "girl_1", "relation": "right of", "obj_2": "girl_2"}, "evaluation_question": "Is girl_1 to the **left** of girl_2?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl blowing a large bubble with bubble gum while another girl claps behind her, with girl_1 to the left of girl_2. >7FEF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b09316c9622d49d9b48b32046d33bbb7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "35d44976b58a4b438094a6e1594f240f", "source": "vatex", "video_id": "x3n6smykdrI_000107_000117", "video_description": "A person is preparing wooden stairs for finishing by vacuuming and sanding them. Technicians are involved in the process, and a narrator describes the steps.", "task": "AttributeRecognition", "clean_prompt": "A person is preparing wooden stairs for finishing by vacuuming and sanding them.", "clean_property": {"obj": "stairs", "attribute": "wooden"}, "target_prompt": "A person is preparing metal stairs for finishing by vacuuming and sanding them.", "target_property": {"obj": "stairs", "attribute": "metal"}, "evaluation_question": "Are the stairs **wooden**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is preparing wooden stairs for finishing by vacuuming and sanding them. 3/LF&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6808cb9957c44acacc36ff6e6a26f44.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "30df5b5bb2934ce7893253ca08615e3b", "source": "vatex", "video_id": "1u9OGTJcMEw_000011_000021", "video_description": "A group of people are watching a polo match on a green field with horses and players. An announcer is speaking through a loudspeaker, and some spectators are taking pictures and filming the event.", "task": "ActionRecognition", "clean_prompt": "A polo player playing polo on a green field.", "clean_property": {"obj": "polo player", "action": "playing polo", "target": null}, "target_prompt": "A polo player watching polo on a green field.", "target_property": {"obj": "polo player", "action": "watching polo", "target": null}, "evaluation_question": "Is the polo player **playing** polo?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A polo player playing polo on a green field. >P$PC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/496065be8d434690a662aca9be1027b7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "be00a20a684046838b2a96beb5e692ea", "source": "vatex", "video_id": "KFF_zkxtOh8_000104_000114", "video_description": "A woman is demonstrating how to style her hair using a round brush and a blow dryer, explaining the steps for a blowout.", "task": "Counting", "clean_prompt": "A woman demonstrating how to style her hair using a round brush and a blow dryer, with five people watching her.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "A woman demonstrating how to style her hair using a round brush and a blow dryer, with one person watching her.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to style her hair using a round brush and a blow dryer, with five people watching her. '1C%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc16dacddb68424ba27f8eb5df329c87.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc9730a8e5b947b8aa4aea0918157061", "source": "vatex", "video_id": "wduiTN5eP9g_000032_000042", "video_description": "A man is balancing and walking on a tightrope while juggling three flaming sticks in front of a cheering crowd.", "task": "SpatialUnderstanding", "clean_prompt": "A crowd farther from the camera than a tightrope.", "clean_property": {"obj_1": "crowd", "relation": "farther from the camera than", "obj_2": "tightrope"}, "target_prompt": "A crowd closer to the camera than a tightrope.", "target_property": {"obj_1": "crowd", "relation": "closer to the camera than", "obj_2": "tightrope"}, "evaluation_question": "Is the crowd **farther from the camera than** the tightrope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd farther from the camera than a tightrope. FEYJX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ea9cb47127e4df998b2f62377991099.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b60c05e9ccd042f9acadab08d8673ef8", "source": "vatex", "video_id": "M5Iv3vnl2Ys_000022_000032", "video_description": "A man in a red pullover and khaki pants is on a windy golf course, demonstrating how to hit a golf ball with a club.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a golf club on a windy golf course.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "golf club"}, "target_prompt": "A man closer to the camera than a golf club on a windy golf course.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "golf club"}, "evaluation_question": "Is the man **farther from the camera than** the golf club?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a golf club on a windy golf course. FE,Z'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bcde7e021c094c45bfa3749f3c4dedef.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8285612fa1b54f7d92ab61b08a1b0640", "source": "vatex", "video_id": "n1HvY9wR5-Q_000000_000010", "video_description": "A woman is demonstrating and performing knee push-ups on a mat in a gym.", "task": "ObjectRecognition", "clean_prompt": "A woman is demonstrating and performing knee push-ups on a mat in a gym.", "clean_property": {"obj": "mat"}, "target_prompt": "A woman is demonstrating and performing knee push-ups on a bench in a gym.", "target_property": {"obj": "bench"}, "evaluation_question": "Is the woman performing knee push-ups on a **mat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and performing knee push-ups on a mat in a gym. LY%QS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24555f03e7ed4912835bce573360d680.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c443470c50e4022bebcd6a22812159e", "source": "vatex", "video_id": "bdFfqJg4d4Q_000070_000080", "video_description": "A person is riding a camel in a desert setting, guided by another person, while a motorcycle follows behind.", "task": "ActionRecognition", "clean_prompt": "A rider riding a camel in a desert setting.", "clean_property": {"obj": "rider", "action": "riding camel", "target": null}, "target_prompt": "A rider walking beside a camel in a desert setting.", "target_property": {"obj": "rider", "action": "walking beside camel", "target": null}, "evaluation_question": "Is the rider **riding** the camel?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rider riding a camel in a desert setting. '');-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c5603eaa07714c1584a699bdb9113ad9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5938663e46bc42abb47e0f554c80d835", "source": "vatex", "video_id": "ubf2QKqKVLo_000000_000010", "video_description": "An adult and a child are lying on a bed in a bedroom, watching a television show while music plays.", "task": "ActionRecognition", "clean_prompt": "A child watching TV in a bedroom.", "clean_property": {"obj": "child", "action": "watching tv", "target": null}, "target_prompt": "A child playing outside in a park.", "target_property": {"obj": "child", "action": "playing outside", "target": null}, "evaluation_question": "Is the child **watching TV**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child watching TV in a bedroom. NK:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f9ed7de613f472cadc74ecd2bb039de.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b39ffbead71f4b87abff959369f4c0ec", "source": "vatex", "video_id": "ZBE9K32bVBg_000086_000096", "video_description": "A young boy is in his bedroom demonstrating and playing with a fidget spinner, showing its features and how it operates.", "task": "AttributeRecognition", "clean_prompt": "A young boy in his bedroom demonstrating and playing with a white fidget spinner.", "clean_property": {"obj": "fidget spinner", "attribute": "white"}, "target_prompt": "A young boy in his bedroom demonstrating and playing with a red fidget spinner.", "target_property": {"obj": "fidget spinner", "attribute": "red"}, "evaluation_question": "Is the fidget spinner **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy in his bedroom demonstrating and playing with a white fidget spinner. !')):", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a82982450b4e4aef9b79e06457342c7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8cc3aeee32f74b6db236b2a138db7b91", "source": "vatex", "video_id": "ZI3YTbXNaUY_000035_000045", "video_description": "A woman is vacuuming a tile floor while wearing high heel shoes.", "task": "SpatialUnderstanding", "clean_prompt": "A vacuum closer to the camera than a person vacuuming a tile floor while wearing high heel shoes.", "clean_property": {"obj_1": "vacuum", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A vacuum further from the camera than a person vacuuming a tile floor while wearing high heel shoes.", "target_property": {"obj_1": "vacuum", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the vacuum **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A vacuum closer to the camera than a person vacuuming a tile floor while wearing high heel shoes. SL?VY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/80d1de389ac74ff8b8f865ae9f78c7ac.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "20d8dadb110145189e3525aa74a888f4", "source": "vatex", "video_id": "eY_J9xvXk88_000080_000090", "video_description": "A dog stands in a shallow river watching two men who are shoveling dirt and rocks into buckets and panning for valuables.", "task": "Counting", "clean_prompt": "Seven dogs standing in a shallow river watching two men who are shoveling dirt and rocks into buckets and panning for valuables.", "clean_property": {"obj": "dog", "count": "seven"}, "target_prompt": "Four dogs standing in a shallow river watching two men who are shoveling dirt and rocks into buckets and panning for valuables.", "target_property": {"obj": "dog", "count": "four"}, "evaluation_question": "Are there exactly **seven** dogs standing in the river?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven dogs standing in a shallow river watching two men who are shoveling dirt and rocks into buckets and panning for valuables. !FE-W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/62d9ac3c053e4040be31c0bfb36138b0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd711cece6c240298ea239cb63416006", "source": "vatex", "video_id": "P02zv3sQE4I_000028_000038", "video_description": "A wheelchair basketball game is taking place between two teams in a gym. Players in wheelchairs are competing, passing, and shooting the ball. Dramatic music plays in the background, and text in a foreign language is displayed.", "task": "AttributeRecognition", "clean_prompt": "A basketball player in a wheelchair competing in a game.", "clean_property": {"obj": "basketball player", "attribute": "in wheelchair"}, "target_prompt": "A basketball player standing and competing in a game.", "target_property": {"obj": "basketball player", "attribute": "standing"}, "evaluation_question": "Is the basketball player in a **wheelchair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A basketball player in a wheelchair competing in a game. ISHM@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35f7c15bb96f43deaa995988a057ee01.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3f62a7582a43462e9b3cb0c8bc146621", "source": "vatex", "video_id": "49lGjg-CSNE_000095_000105", "video_description": "A man in a workshop is using various tools to work on metal pieces, including grinding, cutting, and welding, while wearing protective gear.", "task": "Counting", "clean_prompt": "Two people in a workshop are using various tools to work on metal pieces, including grinding, cutting, and welding, while wearing protective gear.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person in a workshop is using various tools to work on metal pieces, including grinding, cutting, and welding, while wearing protective gear.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the workshop?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in a workshop are using various tools to work on metal pieces, including grinding, cutting, and welding, while wearing protective gear. =FEF$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b5262e8b7a964bebbb197189adb5de67.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "af1c250f45e348769c4c26b8cf7c26c7", "source": "vatex", "video_id": "0oyynsvcGpg_000533_000543", "video_description": "A man is demonstrating how to make a fly fishing lure by wrapping wire and thread around a small object using various tools.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to make a fly fishing lure by wrapping wire and thread around a small object using various tools.", "clean_property": {"obj": "wire"}, "target_prompt": "A man demonstrating how to make a fly fishing lure by wrapping wood and thread around a small object using various tools.", "target_property": {"obj": "wood"}, "evaluation_question": "Is the object being wrapped in the video **wire**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to make a fly fishing lure by wrapping wire and thread around a small object using various tools. W%UZ|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b80a74d98df463b9e86b3c665257140.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f8b531628954472997f5034e09bd5e03", "source": "vatex", "video_id": "pKHzmL4p5Ao_000000_000010", "video_description": "Two men open a door and discuss the importance of acquiring skills for a job while smiling and talking to the camera.", "task": "AttributeRecognition", "clean_prompt": "Two men discussing the importance of acquiring skills for a job while smiling and talking to the camera, one of them wearing a hat.", "clean_property": {"obj": "person", "attribute": "wearing a hat"}, "target_prompt": "Two men discussing the importance of acquiring skills for a job while smiling and talking to the camera, one of them wearing sunglasses.", "target_property": {"obj": "person", "attribute": "wearing sunglasses"}, "evaluation_question": "Is one of the men wearing a **hat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men discussing the importance of acquiring skills for a job while smiling and talking to the camera, one of them wearing a hat. FEA+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f08e0cb163234132a7b3f6460d66e589.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aefd8889752245d793ff1f78f2269226", "source": "vatex", "video_id": "lhfl15MmKAk_000002_000012", "video_description": "A young boy is in a bedroom, making cross-eyed faces while talking to a camera about action figures.", "task": "ActionRecognition", "clean_prompt": "A boy crossing his eyes while talking to a camera about action figures in a bedroom.", "clean_property": {"obj": "boy", "action": "crossing eyes", "target": null}, "target_prompt": "A boy making silly faces while talking to a camera about action figures in a bedroom.", "target_property": {"obj": "boy", "action": "making silly faces", "target": null}, "evaluation_question": "Is the boy **crossing his eyes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy crossing his eyes while talking to a camera about action figures in a bedroom. UBXJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/357bf111f7b8495683e1237e21baeaed.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a66b98e9ceed4e7ca7067983e9a6552f", "source": "vatex", "video_id": "z-KDduwJNOU_000012_000022", "video_description": "A person, sometimes identified as a child or young woman, is sitting on the floor with their feet in an electric foot massager, laughing uncontrollably as the machine tickles their feet.", "task": "Counting", "clean_prompt": "A child sitting on the floor with three foot massagers, laughing uncontrollably as they enjoy the tickling sensation.", "clean_property": {"obj": "foot massager", "count": "three"}, "target_prompt": "A child sitting on the floor with one foot massager, laughing uncontrollably as they enjoy the tickling sensation.", "target_property": {"obj": "foot massager", "count": "one"}, "evaluation_question": "Are there exactly **three** foot massagers present?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child sitting on the floor with three foot massagers, laughing uncontrollably as they enjoy the tickling sensation. 2BC1%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46e984d8a524456e89d7c757b54db483.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d43790730bb44c25b669094f93caebec", "source": "vatex", "video_id": "siDOEndS9Eo_000003_000013", "video_description": "A young girl is outside trying to blow up an orange balloon using her nose, with her father coaching and encouraging her.", "task": "ActionRecognition", "clean_prompt": "A girl inflating an orange balloon using her nose while her father encourages her.", "clean_property": {"obj": "girl", "action": "inflating balloons", "target": "balloon"}, "target_prompt": "A girl popping an orange balloon while her father watches.", "target_property": {"obj": "girl", "action": "popping balloons", "target": "balloon"}, "evaluation_question": "Is the girl **inflating** a balloon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl inflating an orange balloon using her nose while her father encourages her. ISEJZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5073433cea3d414dbb895b109a316154.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "707463eed20a47b28a8dc1a54277eec3", "source": "vatex", "video_id": "wI0TiLy5QjU_000229_000239", "video_description": "A young woman is demonstrating arm exercises and stretches with the help of an instructor, using a wall for support.", "task": "SpatialUnderstanding", "clean_prompt": "A young woman demonstrating arm exercises above an instructor.", "clean_property": {"obj_1": "young woman", "relation": "above", "obj_2": "instructor"}, "target_prompt": "A young woman demonstrating arm exercises beside an instructor.", "target_property": {"obj_1": "young woman", "relation": "beside", "obj_2": "instructor"}, "evaluation_question": "Is the young woman **above** the instructor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman demonstrating arm exercises above an instructor. =@!,X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aaf065083e88424cab68b37d4ec7aed0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1bb32b4fda0540619be73a6bb5f18a97", "source": "vatex", "video_id": "clVnyEpMJEM_000000_000010", "video_description": "Pete Rose, a baseball player in a uniform with 'Rose' on the back, is hitting a baseball with a bat during a game. The scene is captured from a birdseye view, showing him swinging and hitting the ball in slow motion outdoors.", "task": "ObjectRecognition", "clean_prompt": "A baseball player in a uniform with 'Rose' on the back is hitting a baseball with a bat during a game.", "clean_property": {"obj": "baseball player"}, "target_prompt": "A soccer player in a uniform is kicking a soccer ball on a field.", "target_property": {"obj": "soccer player"}, "evaluation_question": "Is the player in the video a **baseball player**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baseball player in a uniform with 'Rose' on the back is hitting a baseball with a bat during a game. *UVFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c2c2155d656d4a0d99aeee50508c1de7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33bf7a57355b42b7a85269e449acf5ff", "source": "vatex", "video_id": "E7-8duZ65lk_000000_000010", "video_description": "Two women are jump roping together inside a gym, using one rope and jumping face-to-face.", "task": "ActionRecognition", "clean_prompt": "A woman skipping rope in a gym.", "clean_property": {"obj": "woman", "action": "skipping rope", "target": null}, "target_prompt": "A woman running in a gym.", "target_property": {"obj": "woman", "action": "running", "target": null}, "evaluation_question": "Is the woman **skipping rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman skipping rope in a gym. 0#!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b874a5df37af4eccb40bbda26022ea69.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bea0611f53184a78aaf730f6e4bb1ae2", "source": "vatex", "video_id": "AVn6O5tB5GA_000073_000083", "video_description": "A young girl is in a stable demonstrating how to properly brush a large white horse using a handheld brush.", "task": "Counting", "clean_prompt": "A young girl is in a stable demonstrating how to properly brush five large white horses using a handheld brush.", "clean_property": {"obj": "horse", "count": "five"}, "target_prompt": "A young girl is in a stable demonstrating how to properly brush one large white horse using a handheld brush.", "target_property": {"obj": "horse", "count": "one"}, "evaluation_question": "Are there exactly **five** large white horses being brushed in the stable?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is in a stable demonstrating how to properly brush five large white horses using a handheld brush. EZ\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ebf45c395ce40f590678d322fcb5872.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "323f773331374d53bfc722e5079f8e9a", "source": "vatex", "video_id": "fRqFwXo7hks_000167_000177", "video_description": "A person is demonstrating how to use a video game controller to interact with a computer, with a split screen showing both the controller and the computer monitor.", "task": "Counting", "clean_prompt": "Three people demonstrating how to use a video game controller to interact with a computer, with a split screen showing both the controller and the computer monitor.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person demonstrating how to use a video game controller to interact with a computer, with a split screen showing both the controller and the computer monitor.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people demonstrating the video game controller?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people demonstrating how to use a video game controller to interact with a computer, with a split screen showing both the controller and the computer monitor. -WN8U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e2eb45fff144f7bbe20ebb2cdaab47f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ebad5e4ea9a8493284c9c713090b77f2", "source": "vatex", "video_id": "Ds6rpXfIBS8_000000_000010", "video_description": "A young man pretends to open automatic sliding doors with his mind and hand gestures.", "task": "Counting", "clean_prompt": "A young man pretends to open five automatic sliding doors with his mind and hand gestures.", "clean_property": {"obj": "doors", "count": "five"}, "target_prompt": "A young man pretends to open two automatic sliding doors with his mind and hand gestures.", "target_property": {"obj": "doors", "count": "two"}, "evaluation_question": "Are there exactly **five** automatic sliding doors being opened?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man pretends to open five automatic sliding doors with his mind and hand gestures. NK.U?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/beb68fec25f94052a886a450433d8882.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad0dd9ca67ce48d99090e99e16ab9d98", "source": "vatex", "video_id": "_fmcxBm_Kfc_000008_000018", "video_description": "A group of skiers, including a skilled male skier, are performing a downhill slalom on a snowy slope, weaving in and out of poles and flags.", "task": "ObjectRecognition", "clean_prompt": "A skilled male skier performing a downhill slalom on a snowy slope.", "clean_property": {"obj": "skier"}, "target_prompt": "A skilled male snowboarder performing tricks on a snowy slope.", "target_property": {"obj": "snowboarder"}, "evaluation_question": "Is the performer in the video a **skier**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skilled male skier performing a downhill slalom on a snowy slope. FE.&G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7256f800cef94348863f052c705a8468.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "982db709678a4972983a1d1fa5510af7", "source": "vatex", "video_id": "5Dk32jjcdrw_000001_000011", "video_description": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "task": "ObjectRecognition", "clean_prompt": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles.", "clean_property": {"obj": "motorcycle carousel"}, "target_prompt": "Children are riding a colorful ferris wheel at a carnival, making excited noises as they go around in circles.", "target_property": {"obj": "ferris wheel"}, "evaluation_question": "Are the children riding a **motorcycle carousel**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Children are riding a colorful motorcycle carousel at a carnival, making excited noises as they go around in circles. ML@FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd52facc027e4323a0616e2e55f628c2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b1d944ee6c84357b714a25e7e0505c0", "source": "vatex", "video_id": "ba2SS4b70vA_000012_000022", "video_description": "A man is standing on a rocky shore, skipping rocks across a body of water while another man cheers him on.", "task": "AttributeRecognition", "clean_prompt": "A man is standing on a rocky shore, skipping rocks across a body of water while another man cheers him on.", "clean_property": {"obj": "water", "attribute": "body of water"}, "target_prompt": "A man is standing on a rocky shore, skipping rocks across a frozen lake while another man cheers him on.", "target_property": {"obj": "water", "attribute": "frozen lake"}, "evaluation_question": "Is the man skipping rocks across a **body of water**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing on a rocky shore, skipping rocks across a body of water while another man cheers him on. -W%|*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d705d0dbb2754514a1ebf2d13ded86e8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8d2c8b152f4e4618bcf8293e9c235208", "source": "vatex", "video_id": "L23BUNaAn2w_000013_000023", "video_description": "A young blonde woman is sitting on a couch, talking to the camera, using hand gestures and facial expressions to illustrate her points.", "task": "ObjectRecognition", "clean_prompt": "A young blonde woman is sitting on a couch, talking to the camera, using hand gestures and facial expressions to illustrate her points.", "clean_property": {"obj": "camera"}, "target_prompt": "A young blonde woman is sitting on a couch, talking into a microphone, using hand gestures and facial expressions to illustrate her points.", "target_property": {"obj": "microphone"}, "evaluation_question": "Is the woman talking to a **camera**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young blonde woman is sitting on a couch, talking to the camera, using hand gestures and facial expressions to illustrate her points. YZG*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ac8efd8a94a4d4aa71216fe954d9303.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de6dacb245ab4e9c9089e68060bae400", "source": "vatex", "video_id": "8RSqPkHIPbo_000000_000010", "video_description": "A man is cleaning the windows and gutters of a two-story house using various tools, including a long stick and a pressure washer.", "task": "Counting", "clean_prompt": "A man is cleaning the windows and gutters of five houses using various tools, including a long stick and a pressure washer.", "clean_property": {"obj": "house", "count": "five"}, "target_prompt": "A man is cleaning the windows and gutters of one house using various tools, including a long stick and a pressure washer.", "target_property": {"obj": "house", "count": "one"}, "evaluation_question": "Are there exactly **five** houses being cleaned?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is cleaning the windows and gutters of five houses using various tools, including a long stick and a pressure washer. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4b944dff3b8c4ada85d85ce318593cf4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f0340fc8a73d45ffa29dcebcd6c1c84f", "source": "vatex", "video_id": "XkM820TdELw_000009_000019", "video_description": "A commercial showcases a man using a machine to clean and sand hardwood floors, leaving them dust-free. The advertisement highlights a company's floor cleaning and finishing services.", "task": "SpatialUnderstanding", "clean_prompt": "A machine closer to the camera than a man using it to clean hardwood floors.", "clean_property": {"obj_1": "machine", "relation": "closer to the camera than", "obj_2": "man"}, "target_prompt": "A machine further from the camera than a man using it to clean hardwood floors.", "target_property": {"obj_1": "machine", "relation": "further from the camera than", "obj_2": "man"}, "evaluation_question": "Is the machine **closer to the camera than** the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A machine closer to the camera than a man using it to clean hardwood floors. M|&A=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98514818a46449c4a7dfb2f7256b47c2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bf16f9a2d063491eb41e8a8f203a0eae", "source": "vatex", "video_id": "6mUXbkDiL5w_000000_000010", "video_description": "A group of children are riding a wagon down a dirt hill. The wagon flips at the bottom, causing the children to fall out.", "task": "Counting", "clean_prompt": "Four children riding a wagon down a dirt hill.", "clean_property": {"obj": "wagon", "count": "four"}, "target_prompt": "One child riding a wagon down a dirt hill.", "target_property": {"obj": "wagon", "count": "one"}, "evaluation_question": "Are there exactly **four** children riding the wagon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four children riding a wagon down a dirt hill. MJF0F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cf818257addd41e9a6fbb3f06e246f7a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "354f956e8ff3408ba7af3a2a3b10c937", "source": "vatex", "video_id": "Rnta1wIPe1s_000196_000206", "video_description": "A young man wearing a colorful hat is ironing a shirt on an ironing board in a bathroom. Another man is present, talking.", "task": "Counting", "clean_prompt": "A young man is ironing two shirts on an ironing board in a bathroom.", "clean_property": {"obj": "shirt", "count": "two"}, "target_prompt": "A young man is ironing one shirt on an ironing board in a bathroom.", "target_property": {"obj": "shirt", "count": "one"}, "evaluation_question": "Are there exactly **two** shirts being ironed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is ironing two shirts on an ironing board in a bathroom. )!G*D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e1224e1cf39f4ff5adb9308ed6d7313f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21520b5a7b854e73b2db39c62aa2f10e", "source": "vatex", "video_id": "9jiRn7q-Fl8_000075_000085", "video_description": "A man is at a street market, peeling and cutting a pineapple using a knife.", "task": "ObjectRecognition", "clean_prompt": "A man peeling and cutting a pineapple at a street market.", "clean_property": {"obj": "pineapple"}, "target_prompt": "A man peeling and cutting a watermelon at a street market.", "target_property": {"obj": "watermelon"}, "evaluation_question": "Is the fruit being cut in the video a **pineapple**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man peeling and cutting a pineapple at a street market. @X|FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f02c3b2174504c9c99b40f699649a087.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "58f86cb7bb29437bb4a13bc07007c714", "source": "vatex", "video_id": "FmNGI94OgKI_000105_000115", "video_description": "A girl is seated at a table demonstrating how to knit a small item using tiny knitting needles or toothpicks and yarn.", "task": "ObjectRecognition", "clean_prompt": "A girl is seated at a table demonstrating how to knit a small item using tiny knitting needles and yarn.", "clean_property": {"obj": "yarn"}, "target_prompt": "A girl is seated at a table demonstrating how to sew a small item using tiny sewing needles and fabric.", "target_property": {"obj": "fabric"}, "evaluation_question": "Is the girl using **yarn** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl is seated at a table demonstrating how to knit a small item using tiny knitting needles and yarn. >$NG\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f3014b2bd6d4321b13df9bc49b183a3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fe0e074cfda74b0e91165dea26c3e975", "source": "vatex", "video_id": "UmbJQOAl5mQ_000013_000023", "video_description": "A performer is demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "task": "SpatialUnderstanding", "clean_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "clean_property": {"obj_1": "performer", "relation": "left of", "obj_2": "fire stick"}, "target_prompt": "A performer standing to the right of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "target_property": {"obj_1": "performer", "relation": "right of", "obj_2": "fire stick"}, "evaluation_question": "Is the performer to the **left** of the fire stick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A performer standing to the left of a fire stick, demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting. =XSIT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/978a2f785f134d2594cf95bcf87fd497.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e92a93651d624935bddd0072e939c913", "source": "vatex", "video_id": "_Ve2cyloT6o_000036_000046", "video_description": "A man is working on a vehicle, using various tools like a spray painter, sand blaster, and pressure washer to paint and clean the vehicle.", "task": "Counting", "clean_prompt": "A man is using two pressure washers to clean a vehicle.", "clean_property": {"obj": "pressure washer", "count": "two"}, "target_prompt": "A man is using one pressure washer to clean a vehicle.", "target_property": {"obj": "pressure washer", "count": "one"}, "evaluation_question": "Are there exactly **two** pressure washers being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using two pressure washers to clean a vehicle. FEA$@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/36e0233c36414e718e58b89053a13a67.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c2badbae47334700a3d96cbe3c5dedf2", "source": "vatex", "video_id": "3FPYYqGyk4w_000023_000033", "video_description": "A fitness trainer guides and explains various exercises, including push-ups, mountain climbing, and stretches, as a young man demonstrates them in a gym.", "task": "AttributeRecognition", "clean_prompt": "A trainer wearing black guides a young man through various exercises in a gym.", "clean_property": {"obj": "trainer", "attribute": "wearing black"}, "target_prompt": "A trainer wearing bright red guides a young man through various exercises in a gym.", "target_property": {"obj": "trainer", "attribute": "wearing bright red"}, "evaluation_question": "Is the trainer wearing **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A trainer wearing black guides a young man through various exercises in a gym. RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/575f22502eff4c65aeea021cd80478c0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "51e5a16c65594f35b45aacc96e75369e", "source": "vatex", "video_id": "hmRfB4ubBZM_000000_000010", "video_description": "A man uses a power drill to make a hole in a coconut and inserts a straw for drinking.", "task": "ActionRecognition", "clean_prompt": "A person using a power drill to make a hole in a coconut.", "clean_property": {"obj": "person", "action": "using a power drill", "target": "coconut"}, "target_prompt": "A person using a power drill to make a hole in a watermelon.", "target_property": {"obj": "person", "action": "using a power drill", "target": "watermelon"}, "evaluation_question": "Is the person **using a power drill** on a coconut?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a power drill to make a hole in a coconut. ELLDI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c87f720db4ea4fd8ad6dd40422c480cb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "97c3eb8aea5d4349ac510a26f7c112c5", "source": "vatex", "video_id": "a5eMVl_mqjw_000044_000054", "video_description": "A woman is demonstrating how to apply nail polish at a table using various nail supplies.", "task": "ActionRecognition", "clean_prompt": "A person doing nails at a table with various nail supplies.", "clean_property": {"obj": "person", "action": "doing nails", "target": null}, "target_prompt": "A person removing nail polish at a table with various nail supplies.", "target_property": {"obj": "person", "action": "removing nail polish", "target": null}, "evaluation_question": "Is the person **doing nails**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person doing nails at a table with various nail supplies. EL)R2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5797d27b71e54322b74f324d51e94592.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4d0aa236634541ea93c0ef0181314045", "source": "vatex", "video_id": "O9kGwMsJm7I_000170_000180", "video_description": "A woman is demonstrating how to fold a red cloth napkin into various intricate designs on a table.", "task": "ActionRecognition", "clean_prompt": "A person folding a red cloth napkin into various intricate designs on a table.", "clean_property": {"obj": "person", "action": "folding napkins", "target": "napkin"}, "target_prompt": "A person throwing napkins in a dining room.", "target_property": {"obj": "person", "action": "throwing napkins", "target": "napkin"}, "evaluation_question": "Is the person **folding** napkins?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding a red cloth napkin into various intricate designs on a table. \u00b7))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5dcd53e6f9f24c9cbdf6cd46c66dbaab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bf986a1155d14d7e9e3f39654ccebb70", "source": "vatex", "video_id": "1HBtXrz0fO8_000034_000044", "video_description": "A large man is riding a small bicycle outside on a driveway. The bicycle tips over, causing the man to dismount.", "task": "ObjectRecognition", "clean_prompt": "A man riding a small bicycle outside on a driveway.", "clean_property": {"obj": "man"}, "target_prompt": "A woman riding a small bicycle outside on a driveway.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person riding the bicycle a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man riding a small bicycle outside on a driveway. ;S)MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f6505fc2891e455c9572556f7f86ac5c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "204a7c1229354566a2b2bf606c3ddd5e", "source": "vatex", "video_id": "1J9Ru1qtzk8_000273_000283", "video_description": "Multiple people are base jumping and paragliding from a tall structure, using colorful parachutes under a blue sky.", "task": "Counting", "clean_prompt": "Seven people base jumping and paragliding from a tall structure, using colorful parachutes under a blue sky.", "clean_property": {"obj": "structure", "count": "seven"}, "target_prompt": "Three people base jumping and paragliding from a tall structure, using colorful parachutes under a blue sky.", "target_property": {"obj": "structure", "count": "three"}, "evaluation_question": "Are there exactly **seven** people base jumping and paragliding from the structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people base jumping and paragliding from a tall structure, using colorful parachutes under a blue sky. W%|!:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee8cfeb0b8e44a80b4a1b64efe9948f6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd1000c3ac0545278a00c27026b183ca", "source": "vatex", "video_id": "aEuMovRpBwY_000056_000066", "video_description": "A group of women are performing a synchronized dance workout routine to music in an indoor gym or studio.", "task": "ObjectRecognition", "clean_prompt": "A group of women performing a synchronized dance workout routine in an indoor gym.", "clean_property": {"obj": "woman"}, "target_prompt": "A group of men performing a synchronized dance workout routine in an indoor gym.", "target_property": {"obj": "man"}, "evaluation_question": "Are the performers in the video **women**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of women performing a synchronized dance workout routine in an indoor gym. %SBS@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35b66a3534c8417aab287387d0aef999.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ce855653e144686867687fcc6f6cb3a", "source": "vatex", "video_id": "G4gp1gApVVE_000058_000068", "video_description": "A person demonstrates various techniques for folding napkins into decorative shapes on a table.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating various techniques for folding a white napkin into decorative shapes on a table.", "clean_property": {"obj": "napkin", "attribute": "white"}, "target_prompt": "A person demonstrating various techniques for folding a red napkin into decorative shapes on a table.", "target_property": {"obj": "napkin", "attribute": "red"}, "evaluation_question": "Is the napkin **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating various techniques for folding a white napkin into decorative shapes on a table. |DJMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a1b71af786c465d9b1c6b6d27e98611.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f54e5b0d9e424652b4df1fd7c42a6a23", "source": "vatex", "video_id": "RuFUVbQyW84_000002_000012", "video_description": "A child rides a bike over a snow ramp, flips the bike, falls head first into the snow, and then gets up and cheers.", "task": "ObjectRecognition", "clean_prompt": "A child rides a bike over a snow ramp, flips the bike, falls head first into the snow, and then gets up and cheers.", "clean_property": {"obj": "child"}, "target_prompt": "A dog runs up a snow ramp, jumps, tumbles in the snow, and then barks happily.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child rides a bike over a snow ramp, flips the bike, falls head first into the snow, and then gets up and cheers. .'!FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8c6a0cf9cba04b3fb82e95eea1be6fc8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cb4aae6caf646f9a073e7287e61e936", "source": "vatex", "video_id": "9ALCrxTtYr4_000261_000271", "video_description": "A person is sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "task": "AttributeRecognition", "clean_prompt": "A person sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "clean_property": {"obj": "woven structure", "attribute": "made of vegetation"}, "target_prompt": "A person sitting on the ground using various tools to trim and complete a woven structure made of plastic, shaped like a Christmas tree.", "target_property": {"obj": "woven structure", "attribute": "made of plastic"}, "evaluation_question": "Is the woven structure made of **vegetation**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree. W%|:!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/153d2cac91124ee09f9dde0de1a47596.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b42e060128114816a901cebcf7f36033", "source": "vatex", "video_id": "ZI3YTbXNaUY_000035_000045", "video_description": "A woman is vacuuming a tile floor while wearing high heel shoes.", "task": "ObjectRecognition", "clean_prompt": "A woman is vacuuming a tile floor while wearing high heel shoes.", "clean_property": {"obj": "vacuum"}, "target_prompt": "A woman is sweeping a tile floor while wearing high heel shoes.", "target_property": {"obj": "broom"}, "evaluation_question": "Is the woman using a **vacuum** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is vacuuming a tile floor while wearing high heel shoes. D|&&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c9343bcdb4e6431f8f15e2790d7f014b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "98fc2b11f00c42b68160c7daa7f914e3", "source": "vatex", "video_id": "vHvx4SNmBfs_000039_000049", "video_description": "A man and a young boy are on a treadmill in a gym. The man helps the boy walk on the treadmill by holding his hands and walking behind him. They are laughing and enjoying the activity.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a treadmill.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "treadmill"}, "target_prompt": "A man closer to the camera than a treadmill.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "treadmill"}, "evaluation_question": "Is the man **farther from the camera than** the treadmill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a treadmill. ))!'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/50b0dbc883c549a6829bcce31d17769a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33eef2d4a3f64d2dbe1704a2430560b2", "source": "vatex", "video_id": "G4gp1gApVVE_000058_000068", "video_description": "A person demonstrates various techniques for folding napkins into decorative shapes on a table.", "task": "SpatialUnderstanding", "clean_prompt": "A person demonstrating various techniques for folding napkins into decorative shapes on a table that is farther from the camera than the person.", "clean_property": {"obj_1": "table", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A person demonstrating various techniques for folding napkins into decorative shapes on a table that is closer to the camera than the person.", "target_property": {"obj_1": "table", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the table farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating various techniques for folding napkins into decorative shapes on a table that is farther from the camera than the person. )ICAV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18249238ffff4df79e87447df648e6fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "968a8f8c40d34dad9febd9d636c9baa1", "source": "vatex", "video_id": "31rIxx-7KvQ_000040_000050", "video_description": "A man is indoors using a large belt sander machine to sharpen a knife blade.", "task": "ObjectRecognition", "clean_prompt": "A man is indoors using a large belt sander machine to sharpen a knife blade.", "clean_property": {"obj": "machine"}, "target_prompt": "A robot is indoors using a large belt sander to sharpen a knife blade.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the object in the video a **machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is indoors using a large belt sander machine to sharpen a knife blade. )7BAS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d057852ebc344eaaa8feaec9a3c85d0e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fa1de53f88144d36b953d805ba7d8564", "source": "vatex", "video_id": "r6rnLJHjc9s_000218_000228", "video_description": "A man is juggling a soccer ball with his feet in various locations including a street, soccer field, gymnasium, and stadium.", "task": "ActionRecognition", "clean_prompt": "A person juggling a soccer ball with their feet in various locations.", "clean_property": {"obj": "person", "action": "juggling soccer ball", "target": null}, "target_prompt": "A person kicking a soccer ball in various locations.", "target_property": {"obj": "person", "action": "kicking a soccer ball", "target": null}, "evaluation_question": "Is the person **juggling** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person juggling a soccer ball with their feet in various locations. %|?))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb4eec2d61424aa0a7f1d6ce51ce075c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c909930a13f44ff9f2b064cc61977f5", "source": "vatex", "video_id": "ofnDF6Ci03M_000041_000051", "video_description": "Two women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth.", "task": "Counting", "clean_prompt": "Three women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth.", "clean_property": {"obj": "woman_2", "count": "three"}, "target_prompt": "One woman is interacting playfully outdoors. She is sitting on a sofa with her eyes closed.", "target_property": {"obj": "woman_2", "count": "one"}, "evaluation_question": "Are there exactly **three** women interacting outdoors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth. OC@EJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2ad394147de24039b24b3b7d8a50e79e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3dcbc38df0dc4309854469180e251b09", "source": "vatex", "video_id": "Yf-1NTG-L0A_000019_000029", "video_description": "A group of people wearing safety gear, including helmets with lights, are walking through knee-deep mud in a dark cave environment.", "task": "ObjectRecognition", "clean_prompt": "A group of people wearing safety gear, including helmets with lights, are walking through knee-deep mud in a dark cave environment.", "clean_property": {"obj": "person"}, "target_prompt": "A group of animals navigating through knee-deep mud in a dark cave environment.", "target_property": {"obj": "animal"}, "evaluation_question": "Are the characters in the video **people**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people wearing safety gear, including helmets with lights, are walking through knee-deep mud in a dark cave environment. @SL@U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3f6dce4e58e447a2887d2fa876d59c6d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f93abcb463944d2db0c2645a0ae93db1", "source": "vatex", "video_id": "USqpgt4hHH4_000144_000154", "video_description": "A person demonstrates how to use a paint roller with a handle that feeds paint directly onto the roller to paint a red wall.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrates how to use a paint roller with a handle that feeds paint directly onto the roller to paint a red wall.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a paint roller on a red wall.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrates how to use a paint roller with a handle that feeds paint directly onto the roller to paint a red wall. SL=SB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1041781dd526430eb338b62ba9408269.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d66b7edabc84742b40fee2825bd5b36", "source": "vatex", "video_id": "mdFZkeQv2Rc_000092_000102", "video_description": "A person is preparing a surprise by wrapping an engagement ring in a Valentine's Day themed paper and placing it in a handmade origami card.", "task": "ObjectRecognition", "clean_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper and placing it in a handmade origami card with a box nearby.", "clean_property": {"obj": "box"}, "target_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper and placing it in a handmade origami card with a basket nearby.", "target_property": {"obj": "basket"}, "evaluation_question": "Is there a **box** present in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper and placing it in a handmade origami card with a box nearby. TS)E.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/85b130c1f8e242eaab9ba61b8f00b1e2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "415e88c01ec241b781af0b32a6848401", "source": "vatex", "video_id": "0C_TGr-V2Bw_000000_000010", "video_description": "A man is competing in a long jump event at a track field, with a crowd of spectators watching and cheering.", "task": "AttributeRecognition", "clean_prompt": "A man competing in a long jump event at an outdoor track field with a crowd of spectators watching and cheering.", "clean_property": {"obj": "track", "attribute": "outdoor"}, "target_prompt": "A man competing in a long jump event at an indoor track field with a crowd of spectators watching and cheering.", "target_property": {"obj": "track", "attribute": "indoor"}, "evaluation_question": "Is the long jump event taking place at an **outdoor** track?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man competing in a long jump event at an outdoor track field with a crowd of spectators watching and cheering. .R%A1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/51b120418aba46fb89525112d98ab112.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f75e704118f3451f86b05ca0b39da14b", "source": "vatex", "video_id": "bU9B_ZiVXRs_000111_000121", "video_description": "A little girl is learning archery with the help of an adult woman, while a man narrates about the family-friendly nature of the sport.", "task": "Counting", "clean_prompt": "Two girls learning archery with an adult woman, while a man narrates about the family-friendly nature of the sport.", "clean_property": {"obj": "girl", "count": "two"}, "target_prompt": "One girl learning archery with an adult woman, while a man narrates about the family-friendly nature of the sport.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **two** girls learning archery?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two girls learning archery with an adult woman, while a man narrates about the family-friendly nature of the sport. W%'7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7e6a0d0823b14dae9412361f66891a1c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d834ddd8f90344ec9f8d2a0cbb510148", "source": "vatex", "video_id": "p1eBzh3rkN4_000032_000042", "video_description": "A young man is practicing the saxophone in his living room while reading sheet music.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than the sheet music.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "sheet music"}, "target_prompt": "A person further from the camera than the sheet music.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "sheet music"}, "evaluation_question": "Is the person **closer to the camera than** the sheet music?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than the sheet music. RP\u00b7RR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b775ab67f85642f3bc00a02e7bc03505.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b8a15c7c52ef49599004457715cf5a77", "source": "vatex", "video_id": "f48POlM6Hzg_000081_000091", "video_description": "A trainer is guiding a man in an orange top on how to use a weight machine for arm exercises in a gym.", "task": "Counting", "clean_prompt": "Five trainers guiding a man in an orange top on how to use a weight machine for arm exercises in a gym.", "clean_property": {"obj": "trainer", "count": "five"}, "target_prompt": "One trainer guiding a woman in a blue top on how to use a weight machine for leg exercises in a gym.", "target_property": {"obj": "trainer", "count": "one"}, "evaluation_question": "Are there exactly **five** trainers guiding in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five trainers guiding a man in an orange top on how to use a weight machine for arm exercises in a gym. !0*)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd71a988233c47a9ba6dd4056d1ce970.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6071e14ac3e74536837b30c366fa5102", "source": "vatex", "video_id": "pKHzmL4p5Ao_000000_000010", "video_description": "Two men open a door and discuss the importance of acquiring skills for a job while smiling and talking to the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a door.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "door"}, "target_prompt": "A person closer to the camera than a door.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "door"}, "evaluation_question": "Is the person **farther from the camera than** the door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a door. ))!F/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c7f2d95eafd4f7caeffcabe00a412a7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c9a46cc1a3694e88b3c7bfeb63d5282d", "source": "vatex", "video_id": "Q7p82CcJ4Fc_000108_000118", "video_description": "Two men, one of whom is young, are working in a woodshop. They are using a machine to cut and mill wood, with one man turning a crank and the other handling the wood through the machine.", "task": "ActionRecognition", "clean_prompt": "A person sawing wood in a woodshop.", "clean_property": {"obj": "person", "action": "sawing wood", "target": null}, "target_prompt": "A person painting wood in a woodshop.", "target_property": {"obj": "person", "action": "painting wood", "target": null}, "evaluation_question": "Is the person **sawing** wood?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sawing wood in a woodshop. UF\u00b7)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b830275c379740f2a56327d9f09e30ed.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f5ada2e52bb84ca5a277a954da2a5919", "source": "vatex", "video_id": "FE_MkMS-Rk0_000130_000140", "video_description": "A woman is kneeling on a carpeted floor, surrounded by clothes, demonstrating how to pack a suitcase and giving instructions.", "task": "Counting", "clean_prompt": "A woman is kneeling on a carpeted floor, surrounded by clothes, demonstrating how to pack a suitcase and giving instructions, with five people assisting her.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "A woman is kneeling on a carpeted floor, surrounded by clothes, demonstrating how to pack a suitcase and giving instructions, with one person assisting her.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people assisting her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is kneeling on a carpeted floor, surrounded by clothes, demonstrating how to pack a suitcase and giving instructions, with five people assisting her. ?ZG*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16565a7953394f679141ce3e1063e9c5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9a695bf66643493192177299d3484816", "source": "vatex", "video_id": "xgIaB0VojPI_000036_000046", "video_description": "A tour group is riding camels in a long line through a dusty desert, with a woman talking.", "task": "Counting", "clean_prompt": "A woman is leading a tour group of six camels through a dusty desert.", "clean_property": {"obj": "woman", "count": "six"}, "target_prompt": "A woman is leading a tour group of three camels through a dusty desert.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** camels in the tour group?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is leading a tour group of six camels through a dusty desert. DP/HU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a83d5ea7ef1f4cc8b3f2b0618b25980a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5ddce19774e42b68445338453d72263", "source": "vatex", "video_id": "B3kvcXsJj74_000000_000010", "video_description": "A person is playing a cymbal on a drum set using a drumstick, experimenting with different rhythms and sounds.", "task": "ActionRecognition", "clean_prompt": "A person playing cymbals on a drum set.", "clean_property": {"obj": "person", "action": "playing cymbals", "target": null}, "target_prompt": "A person playing guitar on a stage.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing cymbals**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing cymbals on a drum set. )!W*P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/baee849c1dd34f9fb40e0e0ba399cb4a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a15908f8c04499dbbfc2e6bc56a8bed", "source": "vatex", "video_id": "n0o8KmFf33k_000022_000032", "video_description": "A young boy is using a milking machine to milk multiple cows in a barn.", "task": "ActionRecognition", "clean_prompt": "A boy using a milking machine to milk cows in a barn.", "clean_property": {"obj": "boy", "action": "milking cow", "target": "cow"}, "target_prompt": "A boy feeding cows in a barn.", "target_property": {"obj": "boy", "action": "feeding cow", "target": "cow"}, "evaluation_question": "Is the boy **milking** the cow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy using a milking machine to milk cows in a barn. \u00b7!FE-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aeef82cb4ed4469e8f0fdb54414dec0a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5cc02e0a7eaf4b2c9282919a8287811a", "source": "vatex", "video_id": "tk6XdoUmoW0_000060_000070", "video_description": "A man is in an outdoor park demonstrating and explaining exercises using a large purple exercise ball.", "task": "ActionRecognition", "clean_prompt": "A person exercising with an exercise ball in an outdoor park.", "clean_property": {"obj": "person", "action": "exercising with an exercise ball", "target": null}, "target_prompt": "A person playing with a beach ball in an outdoor park.", "target_property": {"obj": "person", "action": "playing with a beach ball", "target": null}, "evaluation_question": "Is the person **exercising with an exercise ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person exercising with an exercise ball in an outdoor park. >TSQF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/44b7601004404e38a5bd00b080f68409.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b652134d68424582bcb424d4d8a2c5aa", "source": "vatex", "video_id": "NDiUkSEKNxg_000085_000095", "video_description": "A woman is in a room speaking about life goals and the impact of shaping our lives.", "task": "SpatialUnderstanding", "clean_prompt": "A horse standing to the right of a woman in a room as she speaks about life goals.", "clean_property": {"obj_1": "horse", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A horse standing to the left of a woman in a room as she speaks about life goals.", "target_property": {"obj_1": "horse", "relation": "left of", "obj_2": "woman"}, "evaluation_question": "Is the horse to the **right** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A horse standing to the right of a woman in a room as she speaks about life goals. SL73Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78c25dcc8dbd4689842d73280d27fcc6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "001c5875ca8c4b14bee7056a854e079e", "source": "vatex", "video_id": "t3AQIPQsxy8_000023_000033", "video_description": "A girl is rapidly talking about and eating potato chips from a bag while showing it on a webcam.", "task": "SpatialUnderstanding", "clean_prompt": "A person sitting to the left of a bag of potato chips while talking excitedly into a webcam.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "potato chip"}, "target_prompt": "A person sitting to the right of a bag of potato chips while talking excitedly into a webcam.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "potato chip"}, "evaluation_question": "Is the person to the **left** of a bag of potato chips?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting to the left of a bag of potato chips while talking excitedly into a webcam. #FEMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/65d31c7447a04e11be97f54e463d30f7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0587db07ac3d46788499c18a63636415", "source": "vatex", "video_id": "_QneeovmCQ0_000523_000533", "video_description": "A woman is demonstrating and explaining how to knit using metal needles and a feathery yarn.", "task": "ObjectRecognition", "clean_prompt": "A woman is demonstrating and explaining how to knit using metal needles and a feathery yarn.", "clean_property": {"obj": "yarn"}, "target_prompt": "A woman is demonstrating and explaining how to tie knots using metal needles and a colorful string.", "target_property": {"obj": "string"}, "evaluation_question": "Is the material being used in the video **yarn**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and explaining how to knit using metal needles and a feathery yarn. &FSQS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d5375e8ed10c49d99182ac3ad31dd6f0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e3ca8748b9f1446293cd96b49b5ffaff", "source": "vatex", "video_id": "ZoWgCBQc6wE_000002_000012", "video_description": "A man on horseback lassos a calf, dismounts, and ties the calf's legs.", "task": "Counting", "clean_prompt": "Two men on horseback lassoing a calf, dismounting, and tying the calf's legs.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "A man on horseback lassoing a calf, dismounting, and tying the calf's legs.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men on horseback in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men on horseback lassoing a calf, dismounting, and tying the calf's legs. HSMV\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f228d089d904121a1f687448ec938cc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b65cabeafef74a1a84087fe81e8bae56", "source": "vatex", "video_id": "qFDrQ5YtmA4_000047_000057", "video_description": "An industrial machine is packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them. A person observes and occasionally picks up a packet from the floor.", "task": "AttributeRecognition", "clean_prompt": "An industrial machine packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them.", "clean_property": {"obj": "packet", "attribute": "Asian characters"}, "target_prompt": "An industrial machine packaging and dispensing small, sealed packets of a brown sandy substance with Western characters on them.", "target_property": {"obj": "packet", "attribute": "Western characters"}, "evaluation_question": "Do the packets have **Asian** characters on them?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An industrial machine packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them. O!BCX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7601036da6fa4e54ac52607a5ad3a90d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0fb851ae488f4cb3a1c5071bada9ef9c", "source": "vatex", "video_id": "svuaRfbvhWk_000000_000010", "video_description": "A young man is using a paint roller on a concrete sidewalk while another person is present, making sarcastic comments.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a paint roller.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "paint roller"}, "target_prompt": "A person further from the camera than a paint roller.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "paint roller"}, "evaluation_question": "Is the person **closer to the camera than** the paint roller?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a paint roller. UL)RM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/83a2b071894b418ea22c2942d5d2f92c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aa0ab00068cc40e78216eb09022cfd77", "source": "vatex", "video_id": "-AvjZ4eRgRM_000049_000059", "video_description": "A young man is practicing soccer tricks alone on a field, juggling and dribbling a soccer ball.", "task": "Counting", "clean_prompt": "Four people practicing soccer tricks on a field.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person practicing soccer tricks on a field.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people practicing soccer tricks on the field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people practicing soccer tricks on a field. /))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a40d26f85f247d983f04df6bb24ed01.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d22066b049a4c46a9d17a9cb328ff56", "source": "vatex", "video_id": "QP3cjM6o6N8_000017_000027", "video_description": "A group of people are practicing field hockey, taking turns shooting balls at a goalie who attempts to block the shots. A coach is present, providing instructions.", "task": "ActionRecognition", "clean_prompt": "A player playing field hockey on a practice field.", "clean_property": {"obj": "player", "action": "playing field hockey", "target": null}, "target_prompt": "A player watching field hockey on a practice field.", "target_property": {"obj": "player", "action": "watching field hockey", "target": null}, "evaluation_question": "Is the player **playing** field hockey?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A player playing field hockey on a practice field. @JRC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0823e8775f8943e5b0179a2baea20337.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7a72f3995f5748309dbf6ac1202bba32", "source": "vatex", "video_id": "A4I-Qt0jT6k_000016_000026", "video_description": "A man is playing a full set of drums enthusiastically and rapidly in a dark room.", "task": "ActionRecognition", "clean_prompt": "A person playing drums enthusiastically in a dark room.", "clean_property": {"obj": "person", "action": "playing drums", "target": null}, "target_prompt": "A person playing guitar enthusiastically in a dark room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing drums**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing drums enthusiastically in a dark room. )(G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57a7aded5c4e4c2684511f713543c1cc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "762c909830f4448f8f82b6a0a4c54490", "source": "vatex", "video_id": "87xYpTZVJqc_000029_000039", "video_description": "Two high school lacrosse teams are playing a game on a large outdoor grassy field. During the game, a scuffle breaks out between players, and a referee intervenes to separate them.", "task": "SpatialUnderstanding", "clean_prompt": "A scuffle occurring closer to the camera than a referee on a large outdoor grassy field.", "clean_property": {"obj_1": "scuffle", "relation": "closer to the camera than", "obj_2": "referee"}, "target_prompt": "A scuffle occurring further from the camera than a referee on a large outdoor grassy field.", "target_property": {"obj_1": "scuffle", "relation": "further from the camera than", "obj_2": "referee"}, "evaluation_question": "Is the scuffle **closer to the camera than** the referee?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scuffle occurring closer to the camera than a referee on a large outdoor grassy field. ,0BCX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e358841c3b448cbbffa765f3ec5cbb3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "27d75ba2ef04443d8b828adb1c93d29f", "source": "vatex", "video_id": "v-HVFopY6Xs_000023_000033", "video_description": "Four women are sitting around a lab table in a classroom, playing a game of dominoes and discussing the rules.", "task": "ObjectRecognition", "clean_prompt": "Four women are sitting around a lab table in a classroom, playing a game of dominoes and discussing the rules.", "clean_property": {"obj": "woman"}, "target_prompt": "Four men are sitting around a lab table in a classroom, playing a game of dominoes and discussing the rules.", "target_property": {"obj": "man"}, "evaluation_question": "Are the players in the video **women**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four women are sitting around a lab table in a classroom, playing a game of dominoes and discussing the rules. #8LFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98222248fde44e35a7d57d5d2789972f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4bfd789bb62f42f2b11aad8f1ca72ec9", "source": "vatex", "video_id": "HFxj1Q1fRDU_000073_000083", "video_description": "A woman is demonstrating how to make a bow using a bow maker and a wide piece of black ribbon on a table.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a wide piece of black ribbon on a table.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "ribbon"}, "target_prompt": "A person closer to the camera than a wide piece of black ribbon on a table.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "ribbon"}, "evaluation_question": "Is the person **farther from the camera than** the ribbon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a wide piece of black ribbon on a table. EL>3Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61916c2eae024c10bdadc03b21a63f7d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9759ee51fb1748d18e9a1a6bd4ac2b6c", "source": "vatex", "video_id": "D9aCTlKLF5Y_000060_000070", "video_description": "A person demonstrates the process of baking small cookie-like treats, placing dough balls on a tray, baking them, and then transferring them to a glass container.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrates the process of baking small cookie-like treats, placing small dough balls on a tray.", "clean_property": {"obj": "dough", "attribute": "small"}, "target_prompt": "A person demonstrates the process of baking large cookie-like treats, placing large dough balls on a tray.", "target_property": {"obj": "dough", "attribute": "large"}, "evaluation_question": "Are the dough balls **small**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrates the process of baking small cookie-like treats, placing small dough balls on a tray. >LFY9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5f7747f0259148b990d021c3c3e05e65.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a69fe5b8944c4c8f8fe7b35ded8e326b", "source": "vatex", "video_id": "_8w8b5auFkc_000002_000012", "video_description": "A skiing competition is taking place on a large snowy slope. Skiers are skiing downhill through flags, while spectators cheer them on.", "task": "AttributeRecognition", "clean_prompt": "A professional skier racing downhill through flags on a snowy slope.", "clean_property": {"obj": "skier", "attribute": "professional"}, "target_prompt": "An amateur skier racing downhill through flags on a snowy slope.", "target_property": {"obj": "skier", "attribute": "amateur"}, "evaluation_question": "Is the skier a **professional**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A professional skier racing downhill through flags on a snowy slope. 4IEZ$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c7e060f383b04ee3a3cd905cad564675.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "92e85946f9cd49fabac22e1d82d7d8df", "source": "vatex", "video_id": "5vA-kP3C-WY_000303_000313", "video_description": "A man in red pants performs a breakdancing solo in a dance studio, surrounded by a group of people watching and clapping.", "task": "ActionRecognition", "clean_prompt": "A dancer breakdancing in a dance studio.", "clean_property": {"obj": "dancer", "action": "breakdancing", "target": null}, "target_prompt": "A dancer ballet dancing in a dance studio.", "target_property": {"obj": "dancer", "action": "ballet dancing", "target": null}, "evaluation_question": "Is the dancer **breakdancing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dancer breakdancing in a dance studio. TY,7I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2cf32d4fb7a04d5691d8f2d7574de013.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4c031f7e2a6c48458ca717972b94a8a8", "source": "vatex", "video_id": "zaPA6JrqRRo_000019_000029", "video_description": "A group of people form a circle indoors, watching a couple of young men dance wildly in the center to heavy metal music.", "task": "SpatialUnderstanding", "clean_prompt": "A dancer to the left of a crowd indoors.", "clean_property": {"obj_1": "dancer", "relation": "left of", "obj_2": "crowd"}, "target_prompt": "A dancer to the right of a crowd indoors.", "target_property": {"obj_1": "dancer", "relation": "right of", "obj_2": "crowd"}, "evaluation_question": "Is the dancer to the **left** of a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dancer to the left of a crowd indoors. ))!D&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73caa36436fe450eae3134a506faa9ef.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ec2b3a8ca27c411ba1ee5f69a145452c", "source": "vatex", "video_id": "0pDqEbRFaII_000000_000010", "video_description": "A woman is in a kitchen, demonstrating and explaining how to make scrambled eggs. She stirs beaten eggs in a pan on the stove using a spatula.", "task": "ActionRecognition", "clean_prompt": "A person scrambling eggs in a kitchen.", "clean_property": {"obj": "person", "action": "scrambling eggs", "target": null}, "target_prompt": "A person baking a cake in a kitchen.", "target_property": {"obj": "person", "action": "baking a cake", "target": null}, "evaluation_question": "Is the person **scrambling eggs**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person scrambling eggs in a kitchen. VR@,R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a330f3eb677e47b98ff55cdb84437f2a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3f83099c50f340cf83e85d3d01672b8f", "source": "vatex", "video_id": "DGVqqu2PA-c_000008_000018", "video_description": "Two young boys are jumping on a bed in a dark room, taking turns doing flips.", "task": "SpatialUnderstanding", "clean_prompt": "A boy jumping above a bed in a dark room.", "clean_property": {"obj_1": "boy", "relation": "above", "obj_2": "bed"}, "target_prompt": "A girl sitting beside a sofa in a brightly lit room.", "target_property": {"obj_1": "girl", "relation": "beside", "obj_2": "sofa"}, "evaluation_question": "Is the boy **above** the bed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy jumping above a bed in a dark room. F'C\u00b7R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8861100f9ede454c80a82c0f6671767d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "934cdc125efa4bcf8897347636655bd0", "source": "vatex", "video_id": "8gvvRHbMRIg_000016_000026", "video_description": "A man is unboxing an electronic device from a black box while narrating a commercial for Best Buy.", "task": "ObjectRecognition", "clean_prompt": "A man unboxing an electronic device from a black box while narrating a commercial for Best Buy.", "clean_property": {"obj": "box"}, "target_prompt": "A man unboxing an electronic device from a black bag while narrating a commercial for Best Buy.", "target_property": {"obj": "bag"}, "evaluation_question": "Is the man unboxing from a **box**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man unboxing an electronic device from a black box while narrating a commercial for Best Buy. &,PFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/553364ba44e8421aae4f432933c1dca5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81e4428354b84f6fb1a90504d7717738", "source": "vatex", "video_id": "HpRmj5ce32c_000001_000011", "video_description": "A group of people are playing and practicing curling on an indoor ice rink, using brooms to sweep the ice in front of the curling rock.", "task": "ObjectRecognition", "clean_prompt": "A group of people are playing and practicing curling on an indoor ice rink, using brooms to sweep the ice in front of the curling rock.", "clean_property": {"obj": "broom"}, "target_prompt": "A group of people are shoveling snow on an outdoor surface.", "target_property": {"obj": "shovel"}, "evaluation_question": "Are the people in the video using **brooms**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people are playing and practicing curling on an indoor ice rink, using brooms to sweep the ice in front of the curling rock. FEJ&(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/55abfc6cab6a49ed89f95a5b8e100eed.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4595da08344f4b89bee8c5261f2a0beb", "source": "vatex", "video_id": "Npt_JirV0Fo_000016_000026", "video_description": "A man is on stage attempting to perform a sword swallowing trick while a woman watches.", "task": "Counting", "clean_prompt": "Two men on stage attempting to perform a sword swallowing trick while a woman watches.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "A man on stage attempting to perform a sword swallowing trick while a woman watches.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men on stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men on stage attempting to perform a sword swallowing trick while a woman watches. 9QG\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6fed7e3894f643b9afc71ee4d12fd99a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1374f0bd73e5446f9173fbdb8f3213ec", "source": "vatex", "video_id": "cm66wB7giOM_000000_000010", "video_description": "A group of people, including children, are playing kickball in a grassy field. The game involves rolling, kicking, and catching the ball.", "task": "AttributeRecognition", "clean_prompt": "A person playing kickball in a grassy field.", "clean_property": {"obj": "person", "attribute": "man"}, "target_prompt": "A woman playing kickball in a sandy beach.", "target_property": {"obj": "person", "attribute": "woman"}, "evaluation_question": "Is the person playing kickball a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing kickball in a grassy field. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/700ca6b476f140b08ccec6b4c6baa155.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4c087df9fe4c458bbf09edd4372cf8c2", "source": "vatex", "video_id": "oCOFLIpsaVA_000235_000245", "video_description": "A professional chef is demonstrating how to make a sushi roll on a cooking show set in front of a live audience.", "task": "SpatialUnderstanding", "clean_prompt": "An audience closer to the camera than a chef demonstrating how to make a sushi roll.", "clean_property": {"obj_1": "audience", "relation": "closer to the camera than", "obj_2": "chef"}, "target_prompt": "An audience further from the camera than a chef demonstrating how to make a sushi roll.", "target_property": {"obj_1": "audience", "relation": "further from the camera than", "obj_2": "chef"}, "evaluation_question": "Is the audience closer to the camera than the chef?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An audience closer to the camera than a chef demonstrating how to make a sushi roll. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/906449405b474475a428c7faff688d66.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f74e025ff4a84a64be0f33855ddabebc", "source": "vatex", "video_id": "hyqD2ZGznWo_000040_000050", "video_description": "A young woman is outdoors in a backyard, throwing knives at a cardboard box placed on a chair.", "task": "ActionRecognition", "clean_prompt": "A woman throwing knives at a cardboard box in a backyard.", "clean_property": {"obj": "woman", "action": "throwing knife", "target": "box"}, "target_prompt": "A woman catching a frisbee with a dog in a backyard.", "target_property": {"obj": "woman", "action": "catching frisbee", "target": "dog"}, "evaluation_question": "Is the woman **throwing knives**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman throwing knives at a cardboard box in a backyard. &;LF2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1d27dc8c1e6b4ff4ae80d5c12745d03b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8dec840cf62f40ce9159e285c634f9dc", "source": "vatex", "video_id": "S1LSTV7gFR8_000306_000316", "video_description": "A woman is demonstrating how to make and adjust a bow tie using a sewing machine and Velcro.", "task": "Counting", "clean_prompt": "Two people are demonstrating how to make and adjust a bow tie using a sewing machine and Velcro.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person is demonstrating how to make and adjust a bow tie using a sewing machine and Velcro.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people demonstrating the bow tie adjustment?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are demonstrating how to make and adjust a bow tie using a sewing machine and Velcro. Y)!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/351fcf0d4a794bf29170ba5fa681ee76.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e1a696bdf74545debdd8283dc4a54178", "source": "vatex", "video_id": "eBTYOQQeZWA_000000_000010", "video_description": "A man is performing a deadlift with a barbell loaded with heavy weights in a gym setting.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a barbell in a gym setting.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "barbell"}, "target_prompt": "A person standing to the right of a barbell in a gym setting.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "barbell"}, "evaluation_question": "Is the person to the **left** of the barbell?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a barbell in a gym setting. -#LFG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0f527c522fe94c26957694519ecf91e8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a145e2a165a4cb69b444ae3320913ee", "source": "vatex", "video_id": "FA1riAWEji4_000170_000180", "video_description": "A person is riding a bicycle through various areas of a city at night with rock music playing in the background.", "task": "Counting", "clean_prompt": "Six people riding bicycles through various areas of a city at night with rock music playing in the background.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A person riding a bicycle through various areas of a city at night with rock music playing in the background.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **six** people riding bicycles in the city?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people riding bicycles through various areas of a city at night with rock music playing in the background. @JZJF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bacecc6513b14276ae47e10123d24367.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "05a5f4e041724bb2aa0662b2939ee623", "source": "vatex", "video_id": "aQ4uMrvliQo_000037_000047", "video_description": "A man in a flashy, ornate outfit is dancing and picking up trash in a park and on a pier, putting it into a garbage can while music plays.", "task": "ActionRecognition", "clean_prompt": "A person collecting garbage in a park while music plays.", "clean_property": {"obj": "person", "action": "person collecting garbage", "target": null}, "target_prompt": "A person dancing in a park while music plays.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **collecting garbage**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person collecting garbage in a park while music plays. '!(\u00b7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9afe0dbf779b4ef4968fbff5853653e7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "483fa3237d20481bad67fdc932f5c1bd", "source": "vatex", "video_id": "E8wPUDB5WAc_000000_000010", "video_description": "A male athlete at a track and field event performs a high jump, running up to a bar, jumping over it, and landing on a mat. Spectators watch the event.", "task": "ObjectRecognition", "clean_prompt": "A male athlete running up to a bar and performing a high jump.", "clean_property": {"obj": "bar"}, "target_prompt": "A male athlete running up to a hurdle and performing a jump.", "target_property": {"obj": "hurdle"}, "evaluation_question": "Is the athlete jumping over a **bar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A male athlete running up to a bar and performing a high jump. WPSBB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb07cbc9ca0e4a3d99008b413848e09c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2ccf8822210a45b391d101037f89b687", "source": "vatex", "video_id": "MN_RWRIWUw4_000603_000613", "video_description": "A young girl is demonstrating and explaining how to clean and groom a horse's hoof using a tool.", "task": "AttributeRecognition", "clean_prompt": "A young girl is demonstrating and explaining how to clean and groom a brown horse's hoof using a tool.", "clean_property": {"obj": "horse", "attribute": "brown"}, "target_prompt": "A young girl is demonstrating and explaining how to clean and groom a white horse's hoof using a tool.", "target_property": {"obj": "horse", "attribute": "white"}, "evaluation_question": "Is the horse **brown**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is demonstrating and explaining how to clean and groom a brown horse's hoof using a tool. +FESV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/856d57f9a5aa4a78a7c366a4ad3b6ff8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "65311baa69104102a8f18186d1b215a6", "source": "vatex", "video_id": "D9QhY6ecmrw_000006_000016", "video_description": "A young man is demonstrating and explaining how to solve a Rubik's Cube, showing various techniques and strategies.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a Rubik's Cube, demonstrating how to solve it.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "rubik's cube"}, "target_prompt": "A person standing to the left of a Rubik's Cube, demonstrating how to solve it.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "Rubik's Cube"}, "evaluation_question": "Is the person to the **right** of a Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a Rubik's Cube, demonstrating how to solve it. &+FE#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e58aea56857a495d8a947d235226c9d8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a5bce518a3c34cbea2dd3c57fe0c8b6f", "source": "vatex", "video_id": "dPOKCHIV4fI_000146_000156", "video_description": "Two children are inside, one is operating and running on a treadmill while the other is using an iPad to record or play.", "task": "ObjectRecognition", "clean_prompt": "Two children are inside, one is operating and running on a treadmill while the other is using an iPad to record or play.", "clean_property": {"obj": "iPad"}, "target_prompt": "Two children are inside, one is operating and running on a treadmill while the other is using a laptop to record or play.", "target_property": {"obj": "laptop"}, "evaluation_question": "Is the device being used by the child an **iPad**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children are inside, one is operating and running on a treadmill while the other is using an iPad to record or play. 1UMVY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e435d1decf24a4f97024f93890a10c2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99f0f9e23afd4442a8ecd920ba8d8829", "source": "vatex", "video_id": "ALTXb9DwYvs_000077_000087", "video_description": "A group of people are demonstrating how to brush a cat's teeth. One person holds the cat while another brushes its teeth.", "task": "SpatialUnderstanding", "clean_prompt": "A cat sitting to the left of a person demonstrating how to brush its teeth.", "clean_property": {"obj_1": "cat", "relation": "left of", "obj_2": "person"}, "target_prompt": "A cat sitting to the right of a person demonstrating how to brush its teeth.", "target_property": {"obj_1": "cat", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the cat to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cat sitting to the left of a person demonstrating how to brush its teeth. )!B%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/afff427c1f0546c1b0903a6b045b4164.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "87522d1320ef4a8b97d5e2dd2320591b", "source": "vatex", "video_id": "5UU3iRQW28U_000000_000010", "video_description": "A baby boy is sitting on his father's lap, eating a piece of cake with his hands, getting frosting all over his face.", "task": "AttributeRecognition", "clean_prompt": "A father smiling while holding a baby boy on his lap as the baby eats cake.", "clean_property": {"obj": "father", "attribute": "smiling"}, "target_prompt": "A father frowning while holding a baby boy on his lap as the baby eats cake.", "target_property": {"obj": "father", "attribute": "frowning"}, "evaluation_question": "Is the father **smiling**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A father smiling while holding a baby boy on his lap as the baby eats cake. LY-2T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9b432e0c02fd4c3896cd8fe01ded69af.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "59e71cc63a4243468261ee4542355198", "source": "vatex", "video_id": "wLRymsBNbl0_000002_000012", "video_description": "A group of people, including a man, a young boy, and other teens, are practicing archery in a dark room or basement. They are using bows and arrows to shoot at various targets, including a wall, hanging clothes, and a moving target. Some are competing, while others watch or film the activity.", "task": "ActionRecognition", "clean_prompt": "A person practicing archery in a dark room.", "clean_property": {"obj": "person", "action": "archery", "target": null}, "target_prompt": "A person fencing in a dark room.", "target_property": {"obj": "person", "action": "fencing", "target": null}, "evaluation_question": "Is the person **practicing archery**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing archery in a dark room. W%((%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ed33a58a79b44378c8f5adadd60dc3d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a7a7a3e1e8bb4cdf86d81630c78a2132", "source": "vatex", "video_id": "kBAI99LSGh4_000002_000012", "video_description": "Two men in yellow shirts and black shorts are demonstrating soccer techniques on a field in front of an audience, including children.", "task": "AttributeRecognition", "clean_prompt": "A soccer player wearing a yellow shirt and black shorts demonstrating techniques on a field.", "clean_property": {"obj": "soccer player", "attribute": "wearing yellow shirt and black shorts"}, "target_prompt": "A soccer player wearing a blue shirt and red shorts demonstrating techniques on a field.", "target_property": {"obj": "soccer player", "attribute": "wearing blue shirt and red shorts"}, "evaluation_question": "Is the soccer player wearing a **yellow** shirt and black shorts?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A soccer player wearing a yellow shirt and black shorts demonstrating techniques on a field. LY2OS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8ccd6802237423488498d305e14df64.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fe57b38b9d3444cb9f683eac438f6e11", "source": "vatex", "video_id": "r2BadvUBRWc_000008_000018", "video_description": "An athlete is performing a long jump at a track event, running and jumping into a sand pit. The event is filmed in slow motion on a cloudy day.", "task": "Counting", "clean_prompt": "Two athletes performing a long jump at a track event, running and jumping into a sand pit in slow motion on a cloudy day.", "clean_property": {"obj": "athlete", "count": "two"}, "target_prompt": "An athlete performing a long jump at a track event, running and jumping into a sand pit in slow motion on a cloudy day.", "target_property": {"obj": "athlete", "count": "one"}, "evaluation_question": "Are there exactly **two** athletes performing the long jump?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two athletes performing a long jump at a track event, running and jumping into a sand pit in slow motion on a cloudy day. VEX@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c68f4afc16a48c09ef9322599bb945a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8db99be3b87f4daaafea61c55e6b0d1b", "source": "vatex", "video_id": "wPUeRxWYMPE_000050_000060", "video_description": "A doctor is demonstrating and explaining how to bandage a young man's head.", "task": "AttributeRecognition", "clean_prompt": "A doctor is demonstrating how to bandage a young man's head using a plastic bandage.", "clean_property": {"obj": "bandage", "attribute": "plastic"}, "target_prompt": "A doctor is demonstrating how to bandage a young man's head using a cloth bandage.", "target_property": {"obj": "bandage", "attribute": "cloth"}, "evaluation_question": "Is the bandage being used **plastic**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A doctor is demonstrating how to bandage a young man's head using a plastic bandage. )!U=B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24397427c47e46f09f068a99ee59148f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7f3709937db640c7aef9f170fbf0e4ab", "source": "vatex", "video_id": "NZLydTq7Q98_000003_000013", "video_description": "A man in a blue top, wearing a baseball cap and sports equipment, is at an outdoor archery range holding a bow and arrow. He prepares to fire at a target and walks towards the camera.", "task": "AttributeRecognition", "clean_prompt": "A person wearing sports clothing and equipment is at an outdoor archery range holding a bow and arrow.", "clean_property": {"obj": "person", "attribute": "wearing sports clothing and equipment"}, "target_prompt": "A person wearing formal attire is at an outdoor archery range holding a bow and arrow.", "target_property": {"obj": "person", "attribute": "wearing formal attire"}, "evaluation_question": "Is the person wearing **sports clothing and equipment**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing sports clothing and equipment is at an outdoor archery range holding a bow and arrow. '',?U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ee95b7a80064a84bd19c4e33a4847c3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f51e87a6421c4832a23677d3f7967867", "source": "vatex", "video_id": "PYRzNkcs4s8_000006_000016", "video_description": "Three kids are sliding on a sled across a long icy path in a park, while adults watch and cheer.", "task": "Counting", "clean_prompt": "Two adults watching and cheering as three kids slide on a sled across a long icy path in a park.", "clean_property": {"obj": "adults", "count": "two"}, "target_prompt": "One adult watching and cheering as three kids slide on a sled across a long icy path in a park.", "target_property": {"obj": "adults", "count": "one"}, "evaluation_question": "Are there exactly **two** adults watching and cheering?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two adults watching and cheering as three kids slide on a sled across a long icy path in a park. 92ZQG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d3063bfe58bc43769077cb1aa0318638.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "641f1d5326604eff8f4af84bac013222", "source": "vatex", "video_id": "1rNA1LeL_Fg_000177_000187", "video_description": "A man is at a construction site applying mortar to a brick wall using a plastering tool.", "task": "ObjectRecognition", "clean_prompt": "A man applying mortar to a brick wall using a plastering tool at a construction site.", "clean_property": {"obj": "mortar"}, "target_prompt": "A man applying paint to a wooden fence using a brush.", "target_property": {"obj": "paint"}, "evaluation_question": "Is the man applying **mortar** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man applying mortar to a brick wall using a plastering tool at a construction site. QCK8O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8666a601197247d2b38b3f84899b0dbc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d5a056d8ac06414789365238860647e1", "source": "vatex", "video_id": "_KwDAPzozw8_000075_000085", "video_description": "An older man with a long, gray beard is sitting in a barber's chair at a salon, having his beard shaved and trimmed by a stylist using a trimmer.", "task": "SpatialUnderstanding", "clean_prompt": "A man sitting to the right of a barber's chair.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "chair"}, "target_prompt": "A woman sitting to the left of a sofa.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "sofa"}, "evaluation_question": "Is the man sitting to the **right** of a barber's chair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sitting to the right of a barber's chair. FEA@J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/41ef7c431bbf438a87168e26777d6692.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0be2bcafc3da4099b629c57958a494d9", "source": "vatex", "video_id": "s15QnL6P2JM_000071_000081", "video_description": "Four people, including three men and a woman, are on stage at an award ceremony accepting an award. The audience is clapping and applauding as one of the recipients speaks with gratitude.", "task": "ActionRecognition", "clean_prompt": "An award recipient giving a speech while receiving an award on stage.", "clean_property": {"obj": "award recipient", "action": "giving or receiving award", "target": "award"}, "target_prompt": "An award recipient rejecting an award on stage.", "target_property": {"obj": "award recipient", "action": "rejecting award", "target": "award"}, "evaluation_question": "Is the award recipient **giving** or **receiving** an award?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An award recipient giving a speech while receiving an award on stage. %SLG$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d4ee3edc4fdd48efb1661ac8382bf772.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d9230e072d04cc5a346fd27768fc5e3", "source": "vatex", "video_id": "_SDbgNgZUfU_000000_000010", "video_description": "A man is racing a small green lawn mower around a makeshift dirt track while a large crowd watches.", "task": "ObjectRecognition", "clean_prompt": "A person racing a small green lawn mower around a makeshift dirt track while a large crowd watches.", "clean_property": {"obj": "person"}, "target_prompt": "A dog racing a small green lawn mower around a makeshift dirt track while a large crowd watches.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the racer in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person racing a small green lawn mower around a makeshift dirt track while a large crowd watches. W+SL'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/abd230445671472580dbe6b4cbd0e0d5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d92f3853500344288c9e5dee0cfefe74", "source": "vatex", "video_id": "e-rVEXeqeWQ_000446_000456", "video_description": "A child is assembling a structure using various colored and shaped Lego pieces.", "task": "ObjectRecognition", "clean_prompt": "A child is assembling a structure using various colored and shaped Lego pieces.", "clean_property": {"obj": "child"}, "target_prompt": "A robot is assembling a structure using various colored and shaped Lego pieces.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the character in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is assembling a structure using various colored and shaped Lego pieces. ))'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/90113d0e91e04ef1a8595378140c921b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9e90f410ab514838b73e19bcda490560", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "ObjectRecognition", "clean_prompt": "People are playing laser tag in an outdoor environment with graffiti-covered structures.", "clean_property": {"obj": "graffiti"}, "target_prompt": "People are playing laser tag in an outdoor environment with mural-covered structures.", "target_property": {"obj": "mural"}, "evaluation_question": "Is the environment covered with **graffiti**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "People are playing laser tag in an outdoor environment with graffiti-covered structures. >$%#E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6e5f48aeba841cc81e0216f296559f6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "481342f87a474cf29b34984fc438623d", "source": "vatex", "video_id": "_gPhYONNqoY_000013_000023", "video_description": "A woman is demonstrating how to clean and polish a pair of stylish black high heels using a hand-held brush.", "task": "ActionRecognition", "clean_prompt": "A person cleaning shoes with a hand-held brush.", "clean_property": {"obj": "person", "action": "cleaning shoes", "target": "shoes"}, "target_prompt": "A person throwing shoes in a room.", "target_property": {"obj": "person", "action": "throwing shoes", "target": "shoes"}, "evaluation_question": "Is the person **cleaning** shoes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning shoes with a hand-held brush. ;S#TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3be18e9549f348f89ee55a8ba77ca28e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "077aa06b2e31401eb507cd7b1c1a0167", "source": "vatex", "video_id": "5Avba2W6uxQ_000146_000156", "video_description": "A person is creating a vase on a pottery wheel, shaping it with their hands. The process is accompanied by string instrument music in the background. The finished vase is painted blue and displayed.", "task": "ActionRecognition", "clean_prompt": "A person making a vase on a pottery wheel.", "clean_property": {"obj": "person", "action": "clay pottery making", "target": "vase"}, "target_prompt": "A person breaking a vase on a pottery wheel.", "target_property": {"obj": "person", "action": "breaking pottery", "target": "vase"}, "evaluation_question": "Is the person **making** a vase?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making a vase on a pottery wheel. HL3T.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a343dd4f8bed43ae84b0d5b0517754f4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "008349643dff4ccfb5b7889dd9c1ebbc", "source": "vatex", "video_id": "7tzlzR6-tSk_000003_000013", "video_description": "A woman is playing a didgeridoo in a living room while heavy rock music plays in the background.", "task": "Counting", "clean_prompt": "Two people in a living room, one playing a didgeridoo while heavy rock music plays in the background.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person in a living room, playing a didgeridoo while heavy rock music plays in the background.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in a living room, one playing a didgeridoo while heavy rock music plays in the background. W%B!B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8968c959aeff4f2a99b1fa3dfc82c514.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "669f0d92977e4f42b8cb3ec0b467719c", "source": "vatex", "video_id": "oFSqN-c-4ro_000141_000151", "video_description": "A man is at a campsite in the woods, cooking beans in a cast iron kettle over an open fire and eating from a bowl.", "task": "ObjectRecognition", "clean_prompt": "A man cooking beans in a cast iron kettle over an open fire at a campsite.", "clean_property": {"obj": "beans"}, "target_prompt": "A man cooking soup in a cast iron kettle over an open fire at a campsite.", "target_property": {"obj": "soup"}, "evaluation_question": "Is the man cooking **beans** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man cooking beans in a cast iron kettle over an open fire at a campsite. @,(LF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cbceb09b313b4861b301800d3f9b56ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "583ae67ea2354de6ab86b28d548b0a2a", "source": "vatex", "video_id": "ognDVWEpuOg_000031_000041", "video_description": "A young boy is at a table in a restaurant, making a personal pizza by tearing and placing pieces of ham on it while explaining his preference for ham over chicken.", "task": "Counting", "clean_prompt": "A young boy is at a table in a restaurant, making a personal pizza by tearing and placing three pieces of ham on it while explaining his preference for ham over chicken.", "clean_property": {"obj": "ham", "count": "three"}, "target_prompt": "A young boy is at a table in a restaurant, making a personal pizza by tearing and placing one piece of ham on it while explaining his preference for ham over chicken.", "target_property": {"obj": "ham", "count": "one"}, "evaluation_question": "Are there exactly **three** pieces of ham on the pizza?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is at a table in a restaurant, making a personal pizza by tearing and placing three pieces of ham on it while explaining his preference for ham over chicken. TS@E.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4604227ff6f54a88b67890af1b13a670.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c6192fa16446457bb34045a0a1c0b122", "source": "vatex", "video_id": "r9JyAaVXJ3o_000001_000011", "video_description": "A young man attempts various skateboard tricks involving a bench and a rail, but falls each time.", "task": "Counting", "clean_prompt": "A young man attempting skateboard tricks with six skateboarders around him.", "clean_property": {"obj": "skateboarder", "count": "six"}, "target_prompt": "A young man attempting skateboard tricks with two skateboarders around him.", "target_property": {"obj": "skateboarder", "count": "two"}, "evaluation_question": "Are there exactly **six** skateboarders around him?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man attempting skateboard tricks with six skateboarders around him. S/!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4f507b4a244f48c28d903265181256db.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4765a5f868a74e3c84aa0ab1bcfc1c0b", "source": "vatex", "video_id": "aM4WyvYFP1k_000795_000805", "video_description": "A man is sitting on the floor in front of a brick fireplace, surrounded by multiple power tools, including drills, and discussing tool maintenance.", "task": "ObjectRecognition", "clean_prompt": "A person sitting on the floor in front of a brick fireplace, discussing tool maintenance.", "clean_property": {"obj": "person"}, "target_prompt": "A cat sitting on the floor in front of a brick fireplace, playing with a ball of yarn.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting on the floor in front of a brick fireplace, discussing tool maintenance. )?W%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6a4e9141f2b442ef9bc5e100746d6fff.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f575ae81d32746bca37f2fa758d0122b", "source": "vatex", "video_id": "YcBw2Zk3JNA_000021_000031", "video_description": "A group of young children are practicing hockey on an ice rink, with some falling down. There are two adults present, possibly coaches, and someone is yelling in the background.", "task": "SpatialUnderstanding", "clean_prompt": "An adult standing to the left of a child on an ice rink.", "clean_property": {"obj_1": "adult", "relation": "left of", "obj_2": "child"}, "target_prompt": "An adult standing to the right of a child on an ice rink.", "target_property": {"obj_1": "adult", "relation": "right of", "obj_2": "child"}, "evaluation_question": "Is the adult to the **left** of the child?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult standing to the left of a child on an ice rink. @I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9d743315391f41f89014e451ed00c5fb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "317418ba33cc4dd4a1fa50bbd53e6cdc", "source": "vatex", "video_id": "yBO8rAMeqjc_000007_000017", "video_description": "Two men are shearing a sheep on stage in front of a large audience, including children. One man is shearing while the other explains the process.", "task": "ActionRecognition", "clean_prompt": "A man shearing a sheep on stage in front of a large audience.", "clean_property": {"obj": "man", "action": "shearing sheep", "target": "sheep"}, "target_prompt": "A man shearing a goat on stage in front of a large audience.", "target_property": {"obj": "man", "action": "shearing sheep", "target": "goat"}, "evaluation_question": "Is the man **shearing a sheep**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man shearing a sheep on stage in front of a large audience. SL-YR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c36e8a39c1dc41df8e64261c776a930a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "05fb3b05011f46ae9d0e4da5b546929b", "source": "vatex", "video_id": "ad8VP_08yLw_000000_000010", "video_description": "A young boy is sitting in a plastic chair inside a room, practicing and playing rhythms on a large drum set with cymbals.", "task": "ActionRecognition", "clean_prompt": "A boy playing drums in a room.", "clean_property": {"obj": "boy", "action": "playing drums", "target": null}, "target_prompt": "A boy playing guitar in a room.", "target_property": {"obj": "boy", "action": "playing guitar", "target": null}, "evaluation_question": "Is the boy **playing drums**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy playing drums in a room. G*!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/74696b3b3e0444da91498fb9d7bf97da.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e41512f865294ac4ab04f47b3582233d", "source": "vatex", "video_id": "_Ve2cyloT6o_000036_000046", "video_description": "A man is working on a vehicle, using various tools like a spray painter, sand blaster, and pressure washer to paint and clean the vehicle.", "task": "ObjectRecognition", "clean_prompt": "A man using a spray painter to paint a vehicle.", "clean_property": {"obj": "spray painter"}, "target_prompt": "A man using a roller brush to paint a vehicle.", "target_property": {"obj": "roller brush"}, "evaluation_question": "Is the man using a **spray painter** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a spray painter to paint a vehicle. RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ed9e33886b346a888ef4f23fe222f9f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c1c5a87102a14a349fc0f6058ceb1f65", "source": "vatex", "video_id": "9dyOMEVd9GM_000000_000010", "video_description": "Two young women are dancing to the Macarena indoors, with music playing in the background.", "task": "ActionRecognition", "clean_prompt": "A dancer dancing the Macarena indoors.", "clean_property": {"obj": "dancer", "action": "dancing macarena", "target": null}, "target_prompt": "A dancer dancing salsa indoors.", "target_property": {"obj": "dancer", "action": "dancing salsa", "target": null}, "evaluation_question": "Is the dancer **dancing the Macarena**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dancer dancing the Macarena indoors. UF;\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb2331bdb9b34492bf1098257936582b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aadb669185cc45d59a70a9f863c4b732", "source": "vatex", "video_id": "PBpxD7WP-Rg_000098_000108", "video_description": "A young boy is demonstrating and explaining how to make a paper airplane on a pool table.", "task": "ActionRecognition", "clean_prompt": "A person making paper airplanes on a pool table.", "clean_property": {"obj": "person", "action": "making paper aeroplanes", "target": null}, "target_prompt": "A person flying paper airplanes in a park.", "target_property": {"obj": "person", "action": "flying paper airplanes", "target": null}, "evaluation_question": "Is the person **making** paper airplanes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making paper airplanes on a pool table. '''?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1c87ce6e26004d57a2611ea5e489560f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7daf98d31e644476ada169b3f9edfd0e", "source": "vatex", "video_id": "yb2FMVp6Wzc_000157_000167", "video_description": "A young boy is demonstrating how to make a paper airplane using ruled composition paper, explaining the process as he folds and shows off the finished product.", "task": "SpatialUnderstanding", "clean_prompt": "A paper airplane flying to the left of a boy.", "clean_property": {"obj_1": "paper airplane", "relation": "left of", "obj_2": "boy"}, "target_prompt": "A paper airplane flying to the right of a boy.", "target_property": {"obj_1": "paper airplane", "relation": "right of", "obj_2": "boy"}, "evaluation_question": "Is the paper airplane flying to the **left** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A paper airplane flying to the left of a boy. ))'!-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b6833873697429a84ea8521e3d096f2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4482e8663cf1400daffc9cbff7660252", "source": "vatex", "video_id": "LDfe8kezEA8_000771_000781", "video_description": "Two musicians are busking on a street corner, one playing a guitar and the other a keyboard, in front of a store under a bridge.", "task": "ObjectRecognition", "clean_prompt": "Two musicians are busking on a street corner, one playing a guitar and the other a keyboard.", "clean_property": {"obj": "instrument"}, "target_prompt": "Two musicians are busking on a street corner, one playing a drum and the other a keyboard.", "target_property": {"obj": "drum"}, "evaluation_question": "Are the musicians playing **instruments** that include a **guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two musicians are busking on a street corner, one playing a guitar and the other a keyboard. EZXSY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8adf85810c56487f90fe7f171c8d330f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c62b27f17c9f4109b10bef08f5742717", "source": "vatex", "video_id": "ffdu09tQWNA_000030_000040", "video_description": "A black and white cat is watching a figure skater perform on a television from a very short distance while a woman speaks to the cat.", "task": "Counting", "clean_prompt": "Four figure skaters performing a synchronized routine on ice.", "clean_property": {"obj": "figure skater", "count": "four"}, "target_prompt": "One figure skater performing a solo routine on ice.", "target_property": {"obj": "figure skater", "count": "one"}, "evaluation_question": "Are there exactly **four** figure skaters performing on the ice?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four figure skaters performing a synchronized routine on ice. DPVU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ebb6a7508f0f41e4b70f69c3b9f14154.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "02cdd85a5a7e457ba37689c53c80f19a", "source": "vatex", "video_id": "_IEhvtusy8Y_000021_000031", "video_description": "A person is folding various types of decorative paper, including floral and patterned napkins, into squares while soft music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A person is folding decorative paper into squares while soft music plays in the background.", "clean_property": {"obj": "paper"}, "target_prompt": "A person is folding decorative fabric into squares while soft music plays in the background.", "target_property": {"obj": "fabric"}, "evaluation_question": "Is the person folding **paper** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is folding decorative paper into squares while soft music plays in the background. JMV;@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b8fbd98c2394843ac5d1a65913eabbc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9035bc5a4bea4ae6b80da56c1e085fe3", "source": "vatex", "video_id": "D9SLYYEAEf8_000000_000010", "video_description": "A woman is sitting on a couch holding a baby who is laughing while a man counts money next to them.", "task": "SpatialUnderstanding", "clean_prompt": "A baby farther from the camera than money.", "clean_property": {"obj_1": "baby", "relation": "farther from the camera than", "obj_2": "money"}, "target_prompt": "A baby closer to the camera than money.", "target_property": {"obj_1": "baby", "relation": "closer to the camera than", "obj_2": "money"}, "evaluation_question": "Is the baby **farther from the camera than** the money?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby farther from the camera than money. FG.?Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e323583d3f694565bf573b5cb2ef1c17.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eedd32553e3143eb9ff9094ed6eec827", "source": "vatex", "video_id": "CJUDL32Q7do_000018_000028", "video_description": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away.", "task": "SpatialUnderstanding", "clean_prompt": "A man closer to the camera than a toy on a carpet floor.", "clean_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "toy"}, "target_prompt": "A man further from the camera than a toy on a carpet floor.", "target_property": {"obj_1": "man", "relation": "further from the camera than", "obj_2": "toy"}, "evaluation_question": "Is the man **closer to the camera** than the toy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man closer to the camera than a toy on a carpet floor. EL1FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d4ecc6f496074346b64ad3d4b7924d4d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "184fff98d9304c7f90229d03f312596d", "source": "vatex", "video_id": "Fao59Dt8j9E_000000_000010", "video_description": "A young boy throws an axe into a large tree while providing commentary. The tree is next to a pile of chopped wood.", "task": "ActionRecognition", "clean_prompt": "A boy throwing an axe into a large tree while providing commentary.", "clean_property": {"obj": "boy", "action": "throwing axe", "target": "tree"}, "target_prompt": "A boy throwing a ball into a basket while providing commentary.", "target_property": {"obj": "boy", "action": "throwing ball", "target": "basket"}, "evaluation_question": "Is the boy **throwing an axe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy throwing an axe into a large tree while providing commentary. QSTX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac0ababb282d4fb2b6e6dc5c36d1d953.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c0e7bb787d614ab39e613990f24dfc71", "source": "vatex", "video_id": "Ayt728vAWDo_000003_000013", "video_description": "A shirtless man stands on a bridge over a large body of water, jumps off, and releases a parachute during free fall.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the right of a large body of water.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "water"}, "target_prompt": "A woman standing to the left of a mountain.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "mountain"}, "evaluation_question": "Is the man to the **right** of a large body of water?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the right of a large body of water. FE7H$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a844c9a9dc0645f8be526f40cbf2c47e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "07f60c3583244e7cba2d40adae07e1b8", "source": "vatex", "video_id": "8uHiwUKKyMg_000000_000010", "video_description": "A person sets up a large number of video game cases in a domino pattern in a room and knocks them over, creating a domino effect.", "task": "ObjectRecognition", "clean_prompt": "A person sets up a large number of video game cases in a domino pattern in a room and knocks them over, creating a domino effect.", "clean_property": {"obj": "video game case"}, "target_prompt": "A person sets up a large number of books in a domino pattern in a room and knocks them over, creating a domino effect.", "target_property": {"obj": "book"}, "evaluation_question": "Is the object being knocked over in the video a **video game case**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sets up a large number of video game cases in a domino pattern in a room and knocks them over, creating a domino effect. LYTQR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab44e59c9b7548059208b3ecd602343a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7f6652b37ee4a75a2fb5b5fadf3b199", "source": "vatex", "video_id": "0zNEeg9UCrM_000010_000020", "video_description": "A young woman is skateboarding smoothly through various urban areas, including a street, court, plaza, and mall, at night. She is carrying a backpack and is surrounded by buildings and stores.", "task": "ActionRecognition", "clean_prompt": "A skateboarder skateboarding smoothly through various urban areas at night.", "clean_property": {"obj": "skateboarder", "action": "skateboarding", "target": null}, "target_prompt": "A skateboarder falling in various urban areas at night.", "target_property": {"obj": "skateboarder", "action": "falling", "target": null}, "evaluation_question": "Is the skateboarder **skateboarding**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skateboarder skateboarding smoothly through various urban areas at night. D0D=%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/772062e807964ebd98085406fbe82808.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7796a3b11a4749caaeb36b8693a24649", "source": "vatex", "video_id": "v8EU-HFdUkY_000000_000010", "video_description": "A man rides a bicycle quickly towards a ramp and jumps into a lake, while a group of people cheer him on.", "task": "Counting", "clean_prompt": "Three people cheering as a man rides a bicycle quickly towards a ramp and jumps into a lake.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person cheering as a man rides a bicycle quickly towards a ramp and jumps into a lake.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people cheering?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people cheering as a man rides a bicycle quickly towards a ramp and jumps into a lake. TSAA>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/32c2c67478ca4122b6533e9ad37588e9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8d726bc97b4549558dfb436cdc3242ba", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "ObjectRecognition", "clean_prompt": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "clean_property": {"obj": "person"}, "target_prompt": "A woman is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly. -FE,Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/daacbab246ea42b09c77b4df9c8aa24b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81d8cf6809274d68b1bce489155fb8d1", "source": "vatex", "video_id": "sbZQtqT59jk_000018_000028", "video_description": "A man is explaining the features and speed of a snowmobile parked in the snow in front of a large yellow building.", "task": "AttributeRecognition", "clean_prompt": "A snowmobile parked in the snow in front of a large yellow building.", "clean_property": {"obj": "snowmobile", "attribute": "parked"}, "target_prompt": "A snowmobile in motion in front of a large yellow building.", "target_property": {"obj": "snowmobile", "attribute": "in motion"}, "evaluation_question": "Is the snowmobile parked?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A snowmobile parked in the snow in front of a large yellow building. 9IVS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9440f5281a8045dcbe3cffca7208623e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9c95d04061b49c5868ef383910a7d30", "source": "vatex", "video_id": "q4IByVNoML4_000128_000138", "video_description": "A man is demonstrating and explaining how to tie various knots, including a square knot, using a rope.", "task": "Counting", "clean_prompt": "A man is demonstrating how to tie various knots with four people watching and learning.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "A man is demonstrating how to tie various knots with one person watching.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to tie various knots with four people watching and learning. DPWNW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b5333c86bf8411398feec3da009ca7e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1312aa61c3bb4b0ba41535980be3a945", "source": "vatex", "video_id": "0OuQ07pCRHc_000212_000222", "video_description": "A group of people are participating in a fitness class led by a male instructor, performing synchronized dance and aerobic exercises in a studio with music playing.", "task": "ObjectRecognition", "clean_prompt": "A male instructor leading a fitness class with a group of people performing synchronized dance and aerobic exercises in a studio with music playing.", "clean_property": {"obj": "instructor"}, "target_prompt": "An audience watching a fitness class being performed in a studio with music playing.", "target_property": {"obj": "audience"}, "evaluation_question": "Is the main focus of the video on an **instructor** leading the class?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A male instructor leading a fitness class with a group of people performing synchronized dance and aerobic exercises in a studio with music playing. >TSL9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b5444156b1d04895be913431829c2c37.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d646fa054db8454090533507bba8eac2", "source": "vatex", "video_id": "PCDLlZt5Ckc_000130_000140", "video_description": "A tutorial demonstrates how to paint and decorate fingernails with various designs using nail polish, including a purple coat and glittery finish.", "task": "ActionRecognition", "clean_prompt": "A person doing nails with a purple coat and glittery finish.", "clean_property": {"obj": "person", "action": "doing nails", "target": "nail"}, "target_prompt": "A person removing nails with a nail clipper.", "target_property": {"obj": "person", "action": "removing nails", "target": "nail"}, "evaluation_question": "Is the person **doing** nails?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person doing nails with a purple coat and glittery finish. ELL1#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ffc16a06c9664a66bb270753927bcc14.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c679e5959dd4377928ea414299e18c2", "source": "vatex", "video_id": "YFRfLbTKcvE_000013_000023", "video_description": "A woman demonstrates how to properly bandage a leg for first aid, sitting on a bed and wrapping her leg with an ace bandage.", "task": "Counting", "clean_prompt": "A woman demonstrates how to properly bandage a leg for first aid, sitting on a bed and wrapping her leg with an ace bandage, with seven people watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman demonstrates how to properly bandage a leg for first aid, sitting on a bed and wrapping her leg with an ace bandage, with one person watching her.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to properly bandage a leg for first aid, sitting on a bed and wrapping her leg with an ace bandage, with seven people watching her. FE(E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5338c1346f9d41398b1fde670f9102a1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "759bbf303d754b1aae823133f3474ba3", "source": "vatex", "video_id": "oY4cg_nrD6c_000175_000185", "video_description": "A person is demonstrating how to use a video game controller to copy files on a computer.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating how to use a game controller to copy files on a computer.", "clean_property": {"obj": "game controller"}, "target_prompt": "A person demonstrating how to use a keyboard to copy files on a computer.", "target_property": {"obj": "keyboard"}, "evaluation_question": "Is the device being used in the video a **game controller**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to use a game controller to copy files on a computer. ))'!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f6756661a694aca80cf3c8dbc7b763b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2861a35103e24ddc9f86d032ac27b571", "source": "vatex", "video_id": "ygAPJh9wMmM_000038_000048", "video_description": "A person is skateboarding down a street at night, wearing a helmet, with cars parked along the roadside.", "task": "ActionRecognition", "clean_prompt": "A skateboarder skateboarding down a street at night.", "clean_property": {"obj": "skateboarder", "action": "skateboarding", "target": null}, "target_prompt": "A skateboarder falling down a street at night.", "target_property": {"obj": "skateboarder", "action": "falling", "target": null}, "evaluation_question": "Is the skateboarder **skateboarding**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skateboarder skateboarding down a street at night. H%%D&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9d88e0e38bf34d32ad24d1444ec820e8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd25c89ebe8c461e911cd747800d560e", "source": "vatex", "video_id": "5iLZs5BDXrk_000209_000219", "video_description": "A man with glasses stands in front of a digital board, discussing math and financial calculations in Portuguese and Spanish.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a digital board.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "digital board"}, "target_prompt": "A person standing to the right of a digital board.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "digital board"}, "evaluation_question": "Is the person to the **left** of the digital board?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a digital board. ;D&,J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1174a43a92b34920958f7724e1cd32d9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3da2ebe88238448090fe84167c2e6dbe", "source": "vatex", "video_id": "V18XWMwhP8M_000000_000010", "video_description": "A woman is in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card.", "task": "Counting", "clean_prompt": "A woman in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card with six cars in the background.", "clean_property": {"obj": "car", "count": "six"}, "target_prompt": "A woman in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card with two cars in the background.", "target_property": {"obj": "car", "count": "two"}, "evaluation_question": "Are there exactly **six** cars in the background?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card with six cars in the background. FE7BB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a8ac0f9fd454e519f4411216386b80b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a348c5055e694de88dcc7fb0f74bde8f", "source": "vatex", "video_id": "2vXmRgsKYjY_000012_000022", "video_description": "A sporting event is taking place in a gymnasium where children and adults are playing a shuffleboard-like game. A man slides a puck towards a bullseye while a girl coaches children on how to play. The game resembles curling, and spectators, including children, watch and cheer.", "task": "Counting", "clean_prompt": "Seven girls coaching children on how to play a shuffleboard-like game in a gymnasium.", "clean_property": {"obj": "girl", "count": "seven"}, "target_prompt": "Four girls coaching children on how to play a shuffleboard-like game in a gymnasium.", "target_property": {"obj": "girl", "count": "four"}, "evaluation_question": "Are there exactly **seven** girls coaching in the gymnasium?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven girls coaching children on how to play a shuffleboard-like game in a gymnasium. )=8WR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d60d14160b94421ba38451190e5c883.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4b6a5c1fbf2b412ea873386db4653224", "source": "vatex", "video_id": "DGzfHewaZFg_000188_000198", "video_description": "A man demonstrates how to use and sharpen a serrated pocket knife, showing its cutting capabilities and how to maintain its sharpness.", "task": "SpatialUnderstanding", "clean_prompt": "A knife farther from the camera than a person demonstrating its use.", "clean_property": {"obj_1": "knife", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A knife closer to the camera than a person demonstrating its use.", "target_property": {"obj_1": "knife", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the knife **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A knife farther from the camera than a person demonstrating its use. )!'F=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0bb591ba61074206b8d4f63be1af9d14.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b0bbec74cae342efbd7f735ec8fff1ec", "source": "vatex", "video_id": "CZhwoBSGMKE_000093_000103", "video_description": "A woman is demonstrating and discussing how to use a makeup brush to apply makeup on her face, focusing on her cheeks.", "task": "Counting", "clean_prompt": "Four people are gathered around a table, watching a woman demonstrate how to use a makeup brush on her cheeks.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is demonstrating how to use a makeup brush on their cheeks.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people gathered around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are gathered around a table, watching a woman demonstrate how to use a makeup brush on her cheeks. /!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d2a5cc41922d494a8a2e410d64391b28.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99e9a7b6eb4941f2a34755732a861c4c", "source": "vatex", "video_id": "vARwTQvd1_g_000066_000076", "video_description": "A group of children and people are playing various ball games, including baseball and kickball, outdoors in a residential neighborhood on pavement and in a cul-de-sac.", "task": "ObjectRecognition", "clean_prompt": "A group of children playing with a ball in a cul-de-sac.", "clean_property": {"obj": "ball"}, "target_prompt": "A group of children playing with a frisbee in a cul-de-sac.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Are the children playing with a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children playing with a ball in a cul-de-sac. VL)FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/db0ce8cd074a462b9bc2c5bacc5d7dce.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a8c7694c1ad4c0bbdc276cc7d26769d", "source": "vatex", "video_id": "DIPva58z4qU_000083_000093", "video_description": "A person is performing various bicycle tricks, including riding off a porch, down ramps and steps, and skidding on icy roads and sidewalks in a commercial district and shopping center.", "task": "ActionRecognition", "clean_prompt": "A bicyclist riding a bike in a commercial district.", "clean_property": {"obj": "bicyclist", "action": "riding a bike", "target": null}, "target_prompt": "A bicyclist performing tricks in a commercial district.", "target_property": {"obj": "bicyclist", "action": "performing tricks", "target": null}, "evaluation_question": "Is the bicyclist **riding a bike**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bicyclist riding a bike in a commercial district. !FE4B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9f82ae3062345cb95d32ae1d9e33762.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f2a035e15e34f0b8705148c2c368473", "source": "vatex", "video_id": "9-cJ8KW-u5M_000046_000056", "video_description": "A boy is sitting on a beach, burying his legs in the sand and building a sandcastle while using a cellphone. The day is cloudy.", "task": "ActionRecognition", "clean_prompt": "A boy building a sandcastle on a beach.", "clean_property": {"obj": "boy", "action": "building sandcastle", "target": null}, "target_prompt": "A boy destroying a sandcastle on a beach.", "target_property": {"obj": "boy", "action": "destroying sandcastle", "target": null}, "evaluation_question": "Is the boy **building** a sandcastle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy building a sandcastle on a beach. GS$IZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3fe64b2dee214154909903caae15e0ea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "92e1085ef165497f82f3740a867ce4e9", "source": "vatex", "video_id": "_dpT1Jd4S74_000033_000043", "video_description": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face. The man is holding a selfie stick and recording their experience.", "task": "AttributeRecognition", "clean_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face.", "clean_property": {"obj": "parachute", "attribute": "large smiling face"}, "target_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a small frowning face.", "target_property": {"obj": "parachute", "attribute": "small frowning face"}, "evaluation_question": "Is the parachute displaying a **large smiling face**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are parasailing over the ocean, using a parachute with a large smiling face. \u00b7W*DE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ebc0b00d16574e14b653b6528a60a965.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c505b95ee5974ca9b0a984068cb1260d", "source": "vatex", "video_id": "CEUpjs4NWBc_000045_000055", "video_description": "A woman is giving a massage to a client, focusing on the neck and back, while discussing the use of massage oils and tonics.", "task": "ActionRecognition", "clean_prompt": "A woman massaging a client's neck and back while discussing massage oils.", "clean_property": {"obj": "woman", "action": "massaging neck", "target": "client"}, "target_prompt": "A woman giving a facial to a client while discussing skincare products.", "target_property": {"obj": "woman", "action": "giving a facial", "target": "client"}, "evaluation_question": "Is the woman **massaging** the client's neck?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman massaging a client's neck and back while discussing massage oils. 6)L", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf177b6fb1d6403dae5cd85181b37813.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7cec87fd6f0746478815c18ff8b01023", "source": "vatex", "video_id": "pLHb2G9NPLE_000007_000017", "video_description": "A man is using a shovel to apply a mixture of cement, mud, or mortar onto a wall inside a home.", "task": "AttributeRecognition", "clean_prompt": "A man is using a shovel to apply a mixture of cement onto a broken wall inside a home.", "clean_property": {"obj": "wall", "attribute": "broken"}, "target_prompt": "A man is using a shovel to apply a mixture of cement onto an intact wall inside a home.", "target_property": {"obj": "wall", "attribute": "intact"}, "evaluation_question": "Is the wall **broken**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using a shovel to apply a mixture of cement onto a broken wall inside a home. OT7ID", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/59b1871d1b8146dea47ca3dcc9bff0a0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fdef6de99f40456a8ae2588ea4c528b9", "source": "vatex", "video_id": "xfqst3Ql8cc_000009_000019", "video_description": "Three people are parasailing over the ocean, attached to a colorful parachute and being pulled by a fast-moving boat.", "task": "AttributeRecognition", "clean_prompt": "Three people parasailing over the ocean, attached to a colorful parachute and being pulled by a fast-moving boat.", "clean_property": {"obj": "boat", "attribute": "fast-moving"}, "target_prompt": "Three people parasailing over the ocean, attached to a colorful parachute and being pulled by a slow-moving boat.", "target_property": {"obj": "boat", "attribute": "slow-moving"}, "evaluation_question": "Is the boat **fast-moving**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people parasailing over the ocean, attached to a colorful parachute and being pulled by a fast-moving boat. ED1@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/211fc5cd13454eb99bb7501bce2faaba.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b259f10952a046b6a105dbdf70c7d2ad", "source": "vatex", "video_id": "IT09m7mOItM_000024_000034", "video_description": "A pizza making competition is taking place with competitors racing to make pizzas as fast as possible while being cheered on by a crowd.", "task": "SpatialUnderstanding", "clean_prompt": "A pizza closer to the camera than a competitor in a pizza making competition.", "clean_property": {"obj_1": "pizza", "relation": "closer to the camera than", "obj_2": "competitor"}, "target_prompt": "A pizza further from the camera than a competitor in a pizza making competition.", "target_property": {"obj_1": "pizza", "relation": "further from the camera than", "obj_2": "competitor"}, "evaluation_question": "Is the pizza **closer to the camera than** the competitor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pizza closer to the camera than a competitor in a pizza making competition. -))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f7ab5fedb5143e082232de4ec41dabc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fdd92d99c72649da97a4e4f6d999d330", "source": "vatex", "video_id": "MlHUgTphTEA_000053_000063", "video_description": "A group of construction workers demonstrate and use tools to lay bricks and mortar, constructing a brick wall in a factory setting.", "task": "Counting", "clean_prompt": "Two construction workers laying bricks to build a wall in a factory setting.", "clean_property": {"obj": "wall", "count": "two"}, "target_prompt": "One construction worker laying bricks to build a wall in a factory setting.", "target_property": {"obj": "wall", "count": "one"}, "evaluation_question": "Are there exactly **two** construction workers laying bricks?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two construction workers laying bricks to build a wall in a factory setting. TZ-MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0bc223ed002b43b38ef77c4888fa1605.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "814697ff1a5848d891985d17aaac3cc4", "source": "vatex", "video_id": "EvGkyGUuZnU_000026_000036", "video_description": "A man is demonstrating how to remove scratches and polish a metal bar using a power tool.", "task": "ActionRecognition", "clean_prompt": "A person using a power drill on a metal bar.", "clean_property": {"obj": "person", "action": "using a power drill", "target": "metal bar"}, "target_prompt": "A person polishing a metal bar.", "target_property": {"obj": "person", "action": "polishing", "target": "metal bar"}, "evaluation_question": "Is the person **using a power drill**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a power drill on a metal bar. )QZ,X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e32dbbc5d9504bbea9c8a9f9a041c0ae.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "75b9038cbfad4832ace0b26f5b1b206a", "source": "vatex", "video_id": "rkv6-qHmyPg_000069_000079", "video_description": "A woman is lying face down on a massage table outdoors by the water, receiving a deep muscle massage from a man. Soft music plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A woman lying face down on a massage table outdoors by the water, receiving a deep muscle massage from a man who is to her right.", "clean_property": {"obj_1": "woman", "relation": "right of", "obj_2": "man"}, "target_prompt": "A woman lying face down on a massage table outdoors by the water, receiving a deep muscle massage from a man who is to her left.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the woman to the **right** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman lying face down on a massage table outdoors by the water, receiving a deep muscle massage from a man who is to her right. U%UZU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a3ab9124a9048edace041b9b8ce5f47.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "776cbbe6708547828e38017e1451beb3", "source": "vatex", "video_id": "lYGoMB5u4SE_000000_000010", "video_description": "A person is inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "task": "Counting", "clean_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person inside a Tesla, holding and slightly turning the steering wheel with both hands while pretending to drive.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people inside the Tesla?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people inside a Tesla, each holding and slightly turning the steering wheel with both hands while pretending to drive. ED7SS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/772a542fd68949959acbd7a5858c93c2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4edc30b5dd90458a86dd10f314fc250a", "source": "vatex", "video_id": "77aSi1xRVtY_000000_000010", "video_description": "A woman with glasses is juggling four to five white balls in a living area, successfully catching them all.", "task": "Counting", "clean_prompt": "A woman with glasses is juggling six white balls in a living area, successfully catching them all.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Two people are juggling in a living area, successfully catching colorful balls.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people juggling in the living area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman with glasses is juggling six white balls in a living area, successfully catching them all. SLPC>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2bf66eaefec94cfb8e9a9f4bcca98af4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "898b3b0404414d93b8dfdb80baab459a", "source": "vatex", "video_id": "DZLANAmOx78_000031_000041", "video_description": "A group of boys are sitting inside a tent, performing various actions like cracking their knuckles, necks, and other joints, as well as break dancing and gesticulating.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the left of a tent.", "clean_property": {"obj_1": "boy", "relation": "left of", "obj_2": "tent"}, "target_prompt": "A boy standing to the right of a tent.", "target_property": {"obj_1": "boy", "relation": "right of", "obj_2": "tent"}, "evaluation_question": "Is the boy to the **left** of the tent?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the left of a tent. FE)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cbb3e4054d145c689670a9f769c1aef.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a00f47e35c6e4eac8cb43a4e2fe13c86", "source": "vatex", "video_id": "BeevuXU4xSM_000000_000010", "video_description": "A man is practicing shot put throwing techniques, spinning around and throwing the shot put in a marked area outdoors.", "task": "ActionRecognition", "clean_prompt": "A man practicing shot put throwing techniques outdoors.", "clean_property": {"obj": "man", "action": "shot put", "target": null}, "target_prompt": "A man practicing javelin throwing techniques outdoors.", "target_property": {"obj": "man", "action": "javelin throwing", "target": null}, "evaluation_question": "Is the man **practicing shot put** throwing techniques?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man practicing shot put throwing techniques outdoors. RV!@N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb6a0f6b06324820b9828509bfc19d8a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2b0c50440f1c41b0a1338c1ae7c05ff5", "source": "vatex", "video_id": "Z9AzAk3OzEM_000067_000077", "video_description": "A worker operates a large, shiny drill press in an industrial setting with music playing in the background. The drill press is shown from various angles, highlighting its features.", "task": "ObjectRecognition", "clean_prompt": "A worker operates a large, shiny drill press in an industrial setting.", "clean_property": {"obj": "worker"}, "target_prompt": "A chef cooking in a modern kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **worker**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A worker operates a large, shiny drill press in an industrial setting. HL2FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9bf943db0bb54a14987b0c432f0e26a5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e19207c5258447c19bc64e72135e9f82", "source": "vatex", "video_id": "b5wAeJw0fho_000042_000052", "video_description": "A person is rhythmically hitting a cymbal on a drum set with drumsticks, creating a melody.", "task": "Counting", "clean_prompt": "Two people rhythmically hitting cymbals on a drum set with drumsticks, creating a melody.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person rhythmically hitting a cymbal on a drum set with drumsticks, creating a melody.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people hitting the cymbals?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people rhythmically hitting cymbals on a drum set with drumsticks, creating a melody. FE@2(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a097e9d8e6c0478987297669a339edbc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81b4ec7ebacb421ca545716e5bb73a5f", "source": "vatex", "video_id": "k7-NIKmhrJE_000205_000215", "video_description": "A man is in an industrial kitchen demonstrating and explaining the proper way to mop a floor, including how to clean and store the mop.", "task": "ActionRecognition", "clean_prompt": "A person mopping the floor in an industrial kitchen.", "clean_property": {"obj": "person", "action": "mopping floor", "target": null}, "target_prompt": "A person cleaning windows in an industrial kitchen.", "target_property": {"obj": "person", "action": "cleaning windows", "target": null}, "evaluation_question": "Is the person **mopping the floor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person mopping the floor in an industrial kitchen. (6*4B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec6439d249df48b394c3cba98372190c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "12cbcb26dcc24161b6720b44e64880b6", "source": "vatex", "video_id": "iRhXNX-KJY8_000001_000011", "video_description": "A woman is outside on a sunny day, shooting an arrow at a target with the assistance of another woman and a coach.", "task": "Counting", "clean_prompt": "A woman is outside on a sunny day, shooting an arrow at a target with the assistance of another woman and five coaches.", "clean_property": {"obj": "coach", "count": "five"}, "target_prompt": "A woman is outside on a sunny day, shooting an arrow at a target with the assistance of another woman and one coach.", "target_property": {"obj": "coach", "count": "one"}, "evaluation_question": "Are there exactly **five** coaches assisting the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is outside on a sunny day, shooting an arrow at a target with the assistance of another woman and five coaches. J.FOE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd9cca1cdef249659e7a9964a8aa6c4e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a6a708f0e51a4429801295649418c95a", "source": "vatex", "video_id": "16st7ZGa6Bg_000094_000104", "video_description": "A woman is demonstrating and discussing the features of a pottery jar she made, including how to add a lip to a clay pot.", "task": "Counting", "clean_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors.", "clean_property": {"obj": "razor", "count": "two"}, "target_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding one razor.", "target_property": {"obj": "razor", "count": "one"}, "evaluation_question": "Are there exactly **two** razors being held by the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and discussing the features of a pottery jar she made, while holding two razors. \u00b7(XJR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13c608ff0e344ba98828af90c258000a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f196aa4e884c4549ae0262b21dc13024", "source": "vatex", "video_id": "_YhK30D1w4U_000000_000010", "video_description": "Two men are singing karaoke indoors, one standing and singing into a microphone while the other sits and sings into another microphone. They are in a room with a TV screen displaying lyrics and loud, distorted music playing.", "task": "ActionRecognition", "clean_prompt": "A person singing karaoke indoors.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing indoors.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **singing** karaoke?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person singing karaoke indoors. )?G%D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba1b7a1afe5544519e2691d19f2c7023.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "141a72fcd7804b98969944446220bfae", "source": "vatex", "video_id": "hW2ZI3zp74I_000190_000200", "video_description": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night. The truck is slowly driving down a road, with workers walking around and behind it, bringing garbage cans to the back.", "task": "ActionRecognition", "clean_prompt": "A garbage truck driving down a road at night while workers collect garbage.", "clean_property": {"obj": "garbage truck", "action": "driving car", "target": null}, "target_prompt": "A garbage truck parked in a brightly lit area while workers unload garbage.", "target_property": {"obj": "garbage truck", "action": "driving car", "target": null}, "evaluation_question": "Is the garbage truck **driving** down a road?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A garbage truck driving down a road at night while workers collect garbage. RL7RM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a2838c826a894953a2a153a6bbb9ab6e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c98dd2b2d5224bd09ce4f006f3dc78b5", "source": "vatex", "video_id": "MBPInWTFtgQ_000199_000209", "video_description": "A person is sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands.", "task": "SpatialUnderstanding", "clean_prompt": "A person sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands, closer to the camera than the o-ring.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "o-ring"}, "target_prompt": "A person sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands, further from the camera than the o-ring.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "o-ring"}, "evaluation_question": "Is the person **closer to the camera than** the o-ring?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands, closer to the camera than the o-ring. FEJ\u00b7G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9dfd18c90b6540c8a6b602475f6cd469.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c3d8ad334474eb3bf1c0f731a020754", "source": "vatex", "video_id": "mdFZkeQv2Rc_000092_000102", "video_description": "A person is preparing a surprise by wrapping an engagement ring in a Valentine's Day themed paper and placing it in a handmade origami card.", "task": "ActionRecognition", "clean_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper.", "clean_property": {"obj": "person", "action": "wrapping present", "target": "ring"}, "target_prompt": "A person unwrapping an engagement ring from Valentine's Day themed paper.", "target_property": {"obj": "person", "action": "unwrapping present", "target": "ring"}, "evaluation_question": "Is the person **wrapping** an engagement ring?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wrapping an engagement ring in Valentine's Day themed paper. '))*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e53d744884c04359a323062e3ebf77b0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f49cec098adf4115a215dda4d4f685cb", "source": "vatex", "video_id": "mg4eMlZSbVI_000212_000222", "video_description": "A woman is demonstrating how to make a snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "task": "AttributeRecognition", "clean_prompt": "A woman is demonstrating how to make a snowman doll using crafting materials that include eyes, a hat, and a glue gun on a kitchen table.", "clean_property": {"obj": "crafting materials", "attribute": "includes eyes, hat, glue gun"}, "target_prompt": "A woman is demonstrating how to make a snowman doll using crafting materials that include buttons, a scarf, and tape on a kitchen table.", "target_property": {"obj": "crafting materials", "attribute": "includes buttons, scarf, and tape"}, "evaluation_question": "Do the crafting materials include **eyes**, a hat, and a glue gun?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to make a snowman doll using crafting materials that include eyes, a hat, and a glue gun on a kitchen table. >S-JE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4514c517a3d14c6ea5765eac43cfe170.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c03975a1e944837bc01280a55748aeb", "source": "vatex", "video_id": "nAdQVnYmghw_000048_000058", "video_description": "A man is demonstrating how to poach an egg in a pan of boiling water on a gas stove.", "task": "Counting", "clean_prompt": "A man is demonstrating how to poach five eggs in a pan of boiling water on a gas stove.", "clean_property": {"obj": "egg", "count": "five"}, "target_prompt": "A man is demonstrating how to poach one egg in a pan of boiling water on a gas stove.", "target_property": {"obj": "egg", "count": "one"}, "evaluation_question": "Are there exactly **five** eggs being poached in the pan?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to poach five eggs in a pan of boiling water on a gas stove. SL,VP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ff9fd13ac8dd4bcb861c216562a5cc39.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b466a659b2984262906f8b748b24932d", "source": "vatex", "video_id": "5D-lITAUrac_000000_000010", "video_description": "A young boy is sitting at a table in a classroom setting, repeatedly banging his head on the table while interacting with friends.", "task": "Counting", "clean_prompt": "Two boys sitting at a table in a classroom, interacting with friends while one of them bangs his head on the table.", "clean_property": {"obj": "boy", "count": "two"}, "target_prompt": "Two girls sitting at a table in a classroom, interacting with friends while one of them bangs her head on the table.", "target_property": {"obj": "girl", "count": "two"}, "evaluation_question": "Are there exactly **two** boys sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys sitting at a table in a classroom, interacting with friends while one of them bangs his head on the table. !',W*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fab4b31f8eaf46bd87dafcfce67b73ce.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb471cb1494b4de8b337f8e0fff9e8e7", "source": "vatex", "video_id": "aj8YXq-dn4s_000005_000015", "video_description": "Two young boys with blonde hair are eating cake from the same plate using forks, and one of them is laughing.", "task": "ObjectRecognition", "clean_prompt": "Two young boys with blonde hair are eating cake from the same plate using forks, and one of them is laughing.", "clean_property": {"obj": "cake"}, "target_prompt": "Two young boys with blonde hair are eating ice cream from the same plate using spoons, and one of them is laughing.", "target_property": {"obj": "ice cream"}, "evaluation_question": "Are the boys eating **cake** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys with blonde hair are eating cake from the same plate using forks, and one of them is laughing. ?W%|:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bbc2ba7c2f6347aa9ee8e2cf26d6442d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a2a7e1c3049a4cfabea4718ff456e51f", "source": "vatex", "video_id": "k84mJC-QFDU_000004_000014", "video_description": "A baseball game is taking place with a batter, catcher, umpire, and a cheering crowd. The batter swings at pitches, sometimes hitting the ball, while the catcher and umpire perform their roles behind the plate.", "task": "ActionRecognition", "clean_prompt": "A batter swinging a baseball bat at a pitch during a baseball game.", "clean_property": {"obj": "batter", "action": "swinging baseball bat", "target": "baseball"}, "target_prompt": "A batter missing a swing at a baseball during a baseball game.", "target_property": {"obj": "batter", "action": "missing swing", "target": "baseball"}, "evaluation_question": "Is the batter **swinging** a baseball bat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A batter swinging a baseball bat at a pitch during a baseball game. &8BC2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f214c4ea8e4d440bb3ae70681cbff595.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33fa1f306b704f329bcb32e0a150195e", "source": "vatex", "video_id": "_qWviQq2RcM_000016_000026", "video_description": "A young man is in the woods chopping wood with an axe near a cabin and a campfire.", "task": "ActionRecognition", "clean_prompt": "A person chopping wood near a cabin in the woods.", "clean_property": {"obj": "person", "action": "chopping wood", "target": "log"}, "target_prompt": "A person sawing wood near a cabin in the woods.", "target_property": {"obj": "person", "action": "sawing wood", "target": "log"}, "evaluation_question": "Is the person **chopping** wood?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person chopping wood near a cabin in the woods. VHRU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ec88a89e4404ec4b096c23c7efbd30f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "96bf9912be6945efb59589d18554afce", "source": "vatex", "video_id": "9cMLd-7Yj3w_000006_000016", "video_description": "A man in a white tank top with black hair and tattoos opens two large barn doors and walks out into the sunlight.", "task": "ActionRecognition", "clean_prompt": "A man opening a door.", "clean_property": {"obj": "man", "action": "opening door", "target": null}, "target_prompt": "A man closing a door.", "target_property": {"obj": "man", "action": "closing door", "target": null}, "evaluation_question": "Is the man **opening** a door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man opening a door. R)MW>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/340aaea74afb48ffa163257425b60533.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "025633d38dad49c8a21bc2a1f4fef077", "source": "vatex", "video_id": "BxgWZBhSGE4_000000_000010", "video_description": "Two men approach a refrigerator in a kitchen, open it, and look inside to find only one bottle of beer. They look at each other, contemplating the situation.", "task": "Counting", "clean_prompt": "Three men approach a refrigerator in a kitchen, open it, and look inside to find only one bottle of beer. They look at each other, contemplating the situation.", "clean_property": {"obj": "man", "count": "three"}, "target_prompt": "One man approaches a refrigerator in a kitchen, opens it, and looks inside to find only one bottle of beer. He looks around, contemplating the situation.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **three** men in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three men approach a refrigerator in a kitchen, open it, and look inside to find only one bottle of beer. They look at each other, contemplating the situation. )&))=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f3d27e515c7c4081972b6c181d81b11b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c68650b5527b420e87bbfbd259536e95", "source": "vatex", "video_id": "DIFI0CrjclA_000021_000031", "video_description": "Two young children, a boy and a girl, are outside in a yard throwing water balloons at each other.", "task": "SpatialUnderstanding", "clean_prompt": "A child farther from the camera than a water balloon.", "clean_property": {"obj_1": "child", "relation": "farther from the camera than", "obj_2": "water balloon"}, "target_prompt": "A child closer to the camera than a water balloon.", "target_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "water balloon"}, "evaluation_question": "Is the child **farther from the camera than** the water balloon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child farther from the camera than a water balloon. ,E)P%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b1f6388b5664d4987f6e72476e284ac.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c52ef8afcc0e4c71ba884e24b44a1268", "source": "vatex", "video_id": "BFWrilD5uws_000023_000033", "video_description": "A person uses a printer/copier to print a test page with a smiley face, removes the paper, and shows it to the camera.", "task": "AttributeRecognition", "clean_prompt": "A person uses a printer to print a test page with a smiley face, removes the paper, and shows it to the camera.", "clean_property": {"obj": "paper", "attribute": "test print"}, "target_prompt": "A person uses a printer to print a colorful poster, removes it, and shows it to the camera.", "target_property": {"obj": "paper", "attribute": "colorful poster"}, "evaluation_question": "Is the paper being printed a **test print**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person uses a printer to print a test page with a smiley face, removes the paper, and shows it to the camera. >BC@+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ea0f84b3713e41b9b6e6554d125bbbec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "88a3a3e6546b47f1bd72869c88b7bad8", "source": "vatex", "video_id": "MVFcxo-Pnq8_000169_000179", "video_description": "A man in a black suit performs a sword swallowing trick in an office setting. A woman assists by pulling the sword out of his mouth while a crowd claps and cheers.", "task": "ActionRecognition", "clean_prompt": "A crowd clapping and cheering in an office setting.", "clean_property": {"obj": "crowd", "action": "clapping", "target": null}, "target_prompt": "A crowd booing in an office setting.", "target_property": {"obj": "crowd", "action": "booing", "target": null}, "evaluation_question": "Is the crowd **clapping**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd clapping and cheering in an office setting. FS7MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/65b80daa14d94440adc3c8ac70cc8258.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "29104456be464429be2bd95b8037452d", "source": "vatex", "video_id": "xJYB7jfE09w_000209_000219", "video_description": "A woman is cleaning a window indoors using water and a cloth, while explaining the process and making product recommendations.", "task": "ActionRecognition", "clean_prompt": "A person cleaning windows indoors with water and a cloth.", "clean_property": {"obj": "person", "action": "cleaning windows", "target": null}, "target_prompt": "A person breaking windows indoors.", "target_property": {"obj": "person", "action": "breaking windows", "target": null}, "evaluation_question": "Is the person **cleaning** windows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning windows indoors with water and a cloth. RRQ)W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb1b5be1cb7642e580da555861680b73.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1972aaf55d994d048e086270892ea64f", "source": "vatex", "video_id": "352eUp-RrsU_000110_000120", "video_description": "A woman is in a beauty salon getting her eyebrows waxed by a beautician using wax strips. She is happy with the results.", "task": "AttributeRecognition", "clean_prompt": "A woman is in a beauty salon getting her eyebrows waxed using a white wax strip.", "clean_property": {"obj": "wax strip", "attribute": "white"}, "target_prompt": "A woman is in a beauty salon getting her eyebrows waxed using a blue wax strip.", "target_property": {"obj": "wax strip", "attribute": "blue"}, "evaluation_question": "Is the wax strip **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is in a beauty salon getting her eyebrows waxed using a white wax strip. >E.MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/469dad4c32bf46e2968b89546a24ea10.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bcef562a47af48f6a2f50074cf9567fc", "source": "vatex", "video_id": "pE_c6seMumw_000037_000047", "video_description": "A man is in a gym, lying on a blue mat, demonstrating leg stretches by pulling his legs towards his head.", "task": "ActionRecognition", "clean_prompt": "A person stretching their leg on a blue mat in a gym.", "clean_property": {"obj": "person", "action": "stretching leg", "target": null}, "target_prompt": "A person jumping on a blue mat in a gym.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **stretching their leg**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stretching their leg on a blue mat in a gym. ''),!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef3a4dc32a2343b0a0ba4f8c0d2767a8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21ef65d28cad45b490ebc3dd65b657a6", "source": "vatex", "video_id": "mUu--gT2E40_000028_000038", "video_description": "A large group of people are outside during winter, throwing snowballs at a stationary police car.", "task": "ObjectRecognition", "clean_prompt": "A large group of people are outside during winter, throwing snowballs at a stationary police car.", "clean_property": {"obj": "people"}, "target_prompt": "A large group of animals are outside during winter, playing in the snow.", "target_property": {"obj": "animals"}, "evaluation_question": "Are there **people** throwing snowballs in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A large group of people are outside during winter, throwing snowballs at a stationary police car. =MEOF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78688fd0d07a458ab27e76b16adb6fdc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "17cce612939d4d4ab5ee3a9f85ca4ba6", "source": "vatex", "video_id": "82SWkRfNjaQ_000017_000027", "video_description": "A hockey game is being played with players racing across the ice, trying to score goals. A coach and a man are watching the game, which is also being shown on NBC news.", "task": "ObjectRecognition", "clean_prompt": "A man watching a hockey game with a coach.", "clean_property": {"obj": "man"}, "target_prompt": "A woman watching a hockey game with a coach.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person watching the hockey game a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man watching a hockey game with a coach. VSIMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f848438d1c9b4f1f8c6dee47126c7cd7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7ea601f536024d7eae1d0b9fc595477f", "source": "vatex", "video_id": "k79HofPYIgY_000001_000011", "video_description": "A man in a gym is performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters.", "task": "AttributeRecognition", "clean_prompt": "A man performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters.", "clean_property": {"obj": "barbell", "attribute": "loaded with heavy weights"}, "target_prompt": "A man performing squats with an unloaded barbell on his shoulders, assisted by two spotters.", "target_property": {"obj": "barbell", "attribute": "unloaded"}, "evaluation_question": "Is the barbell loaded with **heavy weights**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters. G*D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/740c931b83344280852847b2222a8569.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "34935dc21aeb47f7a15c38804e5735c1", "source": "vatex", "video_id": "NAshG3XdoLA_000041_000051", "video_description": "A man and a woman dressed in old English outfits are playing unique string instruments, including a violin and a guitar-like instrument, inside a decorated room.", "task": "AttributeRecognition", "clean_prompt": "A musician dressed in old English outfits is playing unique string instruments in a decorated room.", "clean_property": {"obj": "musician", "attribute": "dressed in old English outfits"}, "target_prompt": "A musician dressed in modern casual clothing is playing unique string instruments in a decorated room.", "target_property": {"obj": "musician", "attribute": "dressed in modern casual clothing"}, "evaluation_question": "Is the musician dressed in **old English outfits**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician dressed in old English outfits is playing unique string instruments in a decorated room. ED2NW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aa5ba151234b424495c4b44f0cb3146f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc3a00a9af824f05bc7187761410d8dc", "source": "vatex", "video_id": "cMjSLTiMmd4_000030_000040", "video_description": "Multiple people, including a man, a woman, and some young kids, are riding horses on a dirt road and trails in the countryside. A woman is speaking about the outing.", "task": "ActionRecognition", "clean_prompt": "A rider riding a horse on a dirt road in the countryside.", "clean_property": {"obj": "rider", "action": "riding or walking with horse", "target": null}, "target_prompt": "A rider walking with a horse on a dirt road in the countryside.", "target_property": {"obj": "rider", "action": "walking with horse", "target": null}, "evaluation_question": "Is the rider **riding** a horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rider riding a horse on a dirt road in the countryside. GO4@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/54148c5c138a4c1d8e45c358792741a9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cf4004f6d0c4f61ab2ee0d43fc3ecf5", "source": "vatex", "video_id": "0hWgePf9Vfw_000199_000209", "video_description": "A child is making an origami paper airplane using scissors and folding techniques at a table.", "task": "AttributeRecognition", "clean_prompt": "A child is making an origami paper airplane using scissors and folding techniques with a white paper at a table.", "clean_property": {"obj": "paper", "attribute": "white"}, "target_prompt": "A child is making an origami paper airplane using scissors and folding techniques with a blue paper at a table.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper being used by the child **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is making an origami paper airplane using scissors and folding techniques with a white paper at a table. LCJPS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c8d852d9b9a5488594eec53ad0fe421a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d82fe01e69a04abea777800a05f2cd55", "source": "vatex", "video_id": "OOxphqMuui8_000011_000021", "video_description": "A sushi chef is preparing sushi in a kitchen, using fresh ingredients and wearing gloves.", "task": "ObjectRecognition", "clean_prompt": "A chef preparing sushi in a kitchen with fresh ingredients.", "clean_property": {"obj": "chef"}, "target_prompt": "A baker preparing bread in a bakery with fresh ingredients.", "target_property": {"obj": "baker"}, "evaluation_question": "Is the person in the video a **chef**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef preparing sushi in a kitchen with fresh ingredients. ;7FEA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6786a1998cd6427db6985bd63ce8ba19.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9d2c6859d6a47f9be12e8ca0b8d17be", "source": "vatex", "video_id": "pVRN4ryZ33s_000000_000010", "video_description": "Two people are imitating the sport of curling indoors using a robotic vacuum and mops on a smooth, shiny floor.", "task": "Counting", "clean_prompt": "Two people are imitating the sport of curling indoors using a robotic vacuum and mops on a smooth, shiny floor.", "clean_property": {"obj": "robotic vacuum", "count": "two"}, "target_prompt": "Two people are imitating the sport of curling indoors using one robotic vacuum and mops on a smooth, shiny floor.", "target_property": {"obj": "robotic vacuum", "count": "one"}, "evaluation_question": "Are there exactly **two** robotic vacuums being used in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are imitating the sport of curling indoors using a robotic vacuum and mops on a smooth, shiny floor. 1*D3B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/60a64ae23e5748c98f170a2f965546d8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b507192a97504a5cac439c9e1628621c", "source": "vatex", "video_id": "ZcYB6tPK2Eo_000138_000148", "video_description": "A man is demonstrating how to solve a Rubik's cube, explaining his process while manipulating the cube.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a Rubik's cube, demonstrating how to solve it.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "rubik's cube"}, "target_prompt": "A person beside a Rubik's cube, demonstrating how to solve it.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "Rubik's cube"}, "evaluation_question": "Is the person **above** the Rubik's cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person above a Rubik's cube, demonstrating how to solve it. ')'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1ea54b7ad4048dd9821f4a4b24b675f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9ff0f1c577b445cd8321219bf5b02569", "source": "vatex", "video_id": "qFDrQ5YtmA4_000047_000057", "video_description": "An industrial machine is packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them. A person observes and occasionally picks up a packet from the floor.", "task": "ObjectRecognition", "clean_prompt": "An industrial machine is packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them.", "clean_property": {"obj": "machine"}, "target_prompt": "A robot is packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the machine in the video an **industrial machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An industrial machine is packaging and dispensing small, sealed packets of a brown sandy substance with Asian characters on them. =7FCJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b47bf04abdbd4a2aaf2f785e2ce2b7b5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8488ebdd84144909a9a6081398450b43", "source": "vatex", "video_id": "-Nf6YMhldus_000036_000046", "video_description": "A woman is repeatedly tearing and ripping various types of paper into smaller pieces with her hands.", "task": "ActionRecognition", "clean_prompt": "A person ripping paper into smaller pieces with her hands.", "clean_property": {"obj": "person", "action": "ripping paper", "target": null}, "target_prompt": "A person folding paper into smaller pieces with her hands.", "target_property": {"obj": "person", "action": "folding paper", "target": null}, "evaluation_question": "Is the person **ripping** paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person ripping paper into smaller pieces with her hands. !D|&A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/992e4134f9b44c1d898fdc18ee6bcd20.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6caafa6e85914c2cbe2f90a39b2ac614", "source": "vatex", "video_id": "jODN7qCOn1U_000004_000014", "video_description": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "task": "AttributeRecognition", "clean_prompt": "Multiple people are working on cleaning and smoothing a wooden floor using an electric sander.", "clean_property": {"obj": "tool", "attribute": "electric sander"}, "target_prompt": "Multiple people are working on cleaning and smoothing a wooden floor using a manual sander.", "target_property": {"obj": "tool", "attribute": "manual sander"}, "evaluation_question": "Are the people using an **electric** sander?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Multiple people are working on cleaning and smoothing a wooden floor using an electric sander. =RJEZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ef55dcb71574265b426c1533c042d2b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4decffa1f75d4221a3e7a0222c55be3b", "source": "vatex", "video_id": "Nrh0vgGq5hY_000388_000398", "video_description": "A young woman is demonstrating and giving tips on how to apply makeup using various brushes.", "task": "AttributeRecognition", "clean_prompt": "A young woman demonstrating how to apply makeup using various brushes, focusing on foundation.", "clean_property": {"obj": "makeup", "attribute": "foundation"}, "target_prompt": "A young woman demonstrating how to apply makeup using various brushes, focusing on lipstick.", "target_property": {"obj": "makeup", "attribute": "lipstick"}, "evaluation_question": "Is the focus of the demonstration on **foundation**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman demonstrating how to apply makeup using various brushes, focusing on foundation. GNJJ@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b97a8291b0e497386e262d3d6c2c3f6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "62b05e334a6d4aa9abf8fe45e693884a", "source": "vatex", "video_id": "5FlC5V1ipLk_000000_000010", "video_description": "A woman is demonstrating how to curl a young girl's hair using a curling iron. The girl is seated while the woman styles her hair.", "task": "Counting", "clean_prompt": "A woman is curling the hair of six girls using a curling iron.", "clean_property": {"obj": "girl", "count": "six"}, "target_prompt": "A woman is curling the hair of three girls using a curling iron.", "target_property": {"obj": "girl", "count": "three"}, "evaluation_question": "Are there exactly **six** girls having their hair curled?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is curling the hair of six girls using a curling iron. LY%~K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6e23b8957ec4dba8ea4f4658917ba62.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f058570143f4414c91f04b46e42c0476", "source": "vatex", "video_id": "kbfio_dNFEc_000032_000042", "video_description": "A person is on the roof of a house using a high-pressure water jet to clean debris from the gutters.", "task": "ObjectRecognition", "clean_prompt": "A person is on the roof of a house using a high-pressure water jet to clean debris from the gutters.", "clean_property": {"obj": "water jet"}, "target_prompt": "A person is on the roof of a house using a fire hose to spray water on the roof.", "target_property": {"obj": "fire hose"}, "evaluation_question": "Is the person using a **water jet** to clean the gutters?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is on the roof of a house using a high-pressure water jet to clean debris from the gutters. LFE>$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d3fec52c2b1844a6b3afafaad9cda979.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "51e4a61ba70f4900867f78d6c9c4a3bb", "source": "vatex", "video_id": "2HQNJ8GrSqY_000000_000010", "video_description": "A man is water skiing behind a boat, holding onto a rope, and occasionally raising one hand in the air. The scene is set in a beautiful area with someone on the boat recording the activity.", "task": "ActionRecognition", "clean_prompt": "A person water skiing behind a boat, holding onto a rope and occasionally raising one hand in the air.", "clean_property": {"obj": "person", "action": "water skiing", "target": null}, "target_prompt": "A person snowboarding down a snowy slope.", "target_property": {"obj": "person", "action": "snowboarding", "target": null}, "evaluation_question": "Is the person **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person water skiing behind a boat, holding onto a rope and occasionally raising one hand in the air. &)FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/365cc09b329049288e8b44cd810ef832.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a5db871813ad4ed388beae8f43692add", "source": "vatex", "video_id": "f-JzfOaiVOE_000076_000086", "video_description": "Several people are in a gym or court bouncing balls, including basketballs and medicine balls, as part of an exercise routine.", "task": "Counting", "clean_prompt": "Four people in a gym bouncing basketballs and medicine balls as part of an exercise routine.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a gym bouncing a basketball as part of an exercise routine.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a gym bouncing basketballs and medicine balls as part of an exercise routine. =6XFM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d07306bbd487438cb23b3589f99ec61d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "26d9f16a6bfc4b92976907b78c585461", "source": "vatex", "video_id": "S1j4JuXKG1w_000100_000110", "video_description": "A man is driving a car with a manual transmission, explaining how to drive and safely stop on a hill and at railroad crossings. He demonstrates stopping the car, applying the handbrake, and getting out of the car.", "task": "Counting", "clean_prompt": "A man is driving a car with a manual transmission, explaining how to drive and safely stop on a hill and at railroad crossings, with five people in the car.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "A man is driving a car with a manual transmission, explaining how to drive and safely stop on a hill and at railroad crossings, with one person in the car.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people in the car?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is driving a car with a manual transmission, explaining how to drive and safely stop on a hill and at railroad crossings, with five people in the car. >FOMS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/28fc59a0db054f4f9a5547c45e6525a7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "16a83d8f24f74d798ec95e22a97a8103", "source": "vatex", "video_id": "qDCYp7gjFWE_000157_000167", "video_description": "A man is shearing wool off a sheep using a shearing machine outdoors on a farm, while a border collie dog walks around.", "task": "Counting", "clean_prompt": "Four men shearing wool off a sheep using shearing machines outdoors on a farm, while a border collie dog walks around.", "clean_property": {"obj": "man", "count": "four"}, "target_prompt": "One man shearing wool off a sheep using a shearing machine outdoors on a farm, while a border collie dog walks around.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **four** men shearing wool on the farm?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four men shearing wool off a sheep using shearing machines outdoors on a farm, while a border collie dog walks around. FE;TJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2a34ed54489419a98780d21b601d720.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1cd30c082ff344fea6a45147d75a44eb", "source": "vatex", "video_id": "rDZa20STPUU_000340_000350", "video_description": "Two boys are playing a game of kickball in a grassy backyard. One boy rolls a blue ball to the other, who kicks it and runs towards a shed.", "task": "ObjectRecognition", "clean_prompt": "Two boys are playing kickball in a grassy backyard, with one boy rolling a blue ball to the other who kicks it and runs towards a shed.", "clean_property": {"obj": "shed"}, "target_prompt": "Two boys are playing kickball in a grassy backyard, with one boy rolling a blue ball to the other who kicks it and runs towards a treehouse.", "target_property": {"obj": "treehouse"}, "evaluation_question": "Are the boys running towards a **shed**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys are playing kickball in a grassy backyard, with one boy rolling a blue ball to the other who kicks it and runs towards a shed. >BC$Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6fc02f3bcab4b2a9b53fac2e82923f0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5192553dd8c04776ba78513733a27988", "source": "vatex", "video_id": "3gH5Ik0QMGg_000000_000010", "video_description": "A person is in a car learning how to operate a manual transmission with a man providing instructions.", "task": "AttributeRecognition", "clean_prompt": "A person is in a car learning how to operate a manual transmission with a man providing instructions.", "clean_property": {"obj": "car", "attribute": "manual transmission"}, "target_prompt": "A person is in a car learning how to operate an automatic transmission with a man providing instructions.", "target_property": {"obj": "car", "attribute": "automatic transmission"}, "evaluation_question": "Is the car equipped with a **manual** transmission?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is in a car learning how to operate a manual transmission with a man providing instructions. ;T&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd47958e8b264a1f9ef005a1de2a658e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "965e814b67a04e82bf3d4cafcd7d69b0", "source": "vatex", "video_id": "5eAmn18L0OY_000045_000055", "video_description": "A group of bartenders, both male and female, are working in a bar, pouring and serving drinks to customers. A woman explains bartending as a job, discussing its benefits and challenges.", "task": "SpatialUnderstanding", "clean_prompt": "A bartender standing to the left of a customer in a busy bar.", "clean_property": {"obj_1": "bartender", "relation": "left of", "obj_2": "customer"}, "target_prompt": "A bartender standing to the right of a customer in a busy bar.", "target_property": {"obj_1": "bartender", "relation": "right of", "obj_2": "customer"}, "evaluation_question": "Is the bartender to the **left** of the customer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bartender standing to the left of a customer in a busy bar. )TSDJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6df24e317c634641a47f25e8ce98bb34.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ef21002e39f948cb83d639b98ceb3021", "source": "vatex", "video_id": "0bbub2tFSow_000026_000036", "video_description": "A small brown dog is playfully interacting with a mop while a woman is mopping the tiled kitchen floor.", "task": "ActionRecognition", "clean_prompt": "A woman mopping the tiled kitchen floor.", "clean_property": {"obj": "woman", "action": "mopping floor", "target": null}, "target_prompt": "A woman playing with a dog in a kitchen.", "target_property": {"obj": "woman", "action": "playing with a dog", "target": null}, "evaluation_question": "Is the woman **mopping** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman mopping the tiled kitchen floor. !0D+1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a593669b5f24fefa6c91f62a67cea80.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "44e3db0330e84091bb75cabc9b620b79", "source": "vatex", "video_id": "L2SV8OU406c_000012_000022", "video_description": "A man is using a leaf blower to clean leaves from a driveway and sidewalk around a house.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a leaf blower while cleaning leaves from a driveway.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "leaf blower"}, "target_prompt": "A person standing to the right of a leaf blower while cleaning leaves from a driveway.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "leaf blower"}, "evaluation_question": "Is the person to the **left** of the leaf blower?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a leaf blower while cleaning leaves from a driveway. LY8J)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9d9dfab694c34fa9a45a041629ef31bb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c79abcf2e6584079b4a7853906deb00f", "source": "vatex", "video_id": "I72uIE-va4E_000072_000082", "video_description": "A young girl is standing on a bed, shaping an orange balloon into an animal figure.", "task": "ObjectRecognition", "clean_prompt": "A young girl is shaping an orange balloon into an animal figure while standing on a bed.", "clean_property": {"obj": "balloon"}, "target_prompt": "A young girl is flying a colorful kite in a park.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object in the video a **balloon**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is shaping an orange balloon into an animal figure while standing on a bed. JARKZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/66169d8a0f044f25aa05baf71fa184bb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bbbd1ab2525d45588af14aa60fbb290b", "source": "vatex", "video_id": "PeeFfrmfHN4_000064_000074", "video_description": "A person is demonstrating how to wrap a black box with red wrapping paper on a table.", "task": "AttributeRecognition", "clean_prompt": "A person is demonstrating how to wrap a rectangular black box with red wrapping paper on a table.", "clean_property": {"obj": "box", "attribute": "rectangular"}, "target_prompt": "A person is demonstrating how to wrap a cylindrical black box with red wrapping paper on a table.", "target_property": {"obj": "box", "attribute": "cylindrical"}, "evaluation_question": "Is the box **rectangular**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to wrap a rectangular black box with red wrapping paper on a table. =M$QS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/391242fcdae349f480b0492d033ae8ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "95b667380bf840419399af76f3def042", "source": "vatex", "video_id": "h-1VpOK07vg_000067_000077", "video_description": "Two teams of children, wearing team uniforms and safety gear, are playing a game of lacrosse on an open field in a park. The teams are in red and white uniforms, and the game is taking place on a sunny day.", "task": "AttributeRecognition", "clean_prompt": "Children playing lacrosse on an open field in a park.", "clean_property": {"obj": "player", "attribute": "child"}, "target_prompt": "Adults playing lacrosse on an open field in a park.", "target_property": {"obj": "player", "attribute": "adult"}, "evaluation_question": "Are the players children?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Children playing lacrosse on an open field in a park. QR|'-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c53db8a5679b4bf69516b17aa5250f1e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9cd8bb4c09544812870769d6afb415e9", "source": "vatex", "video_id": "T8fXPNh7u_M_000000_000010", "video_description": "A woman is performing sit-ups on a yoga mat on a rooftop with a view of tall buildings.", "task": "AttributeRecognition", "clean_prompt": "A person wearing all black clothing is performing sit-ups on a yoga mat on a rooftop with a view of tall buildings.", "clean_property": {"obj": "person", "attribute": "wearing all black clothing"}, "target_prompt": "A person wearing bright yellow clothing is performing sit-ups on a yoga mat on a rooftop with a view of tall buildings.", "target_property": {"obj": "person", "attribute": "wearing bright yellow clothing"}, "evaluation_question": "Is the person wearing **all black** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing all black clothing is performing sit-ups on a yoga mat on a rooftop with a view of tall buildings. =TZ\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/02fd777194b34507b93c33b41aa7bd68.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd6ea720bce7478d97eb6e9c615cc18c", "source": "vatex", "video_id": "r7B2l4qXtNw_000005_000015", "video_description": "A man is jumping rope in slow motion outside in his yard, wearing athletic wear including a black shirt, blue shorts, and tennis shoes.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a jump rope.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "jump rope"}, "target_prompt": "A person closer to the camera than a jump rope.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "jump rope"}, "evaluation_question": "Is the person **farther from the camera than** the jump rope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a jump rope. ))'!A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b42b70c512dc447ba8fd753f6a417c06.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5d91a39168c9402f9e60ba05e0907bfc", "source": "vatex", "video_id": "tSUvmyE156k_000017_000027", "video_description": "A girl is teaching her friend, Shayna, how to wink. They are sitting in a room, with one girl demonstrating winking while the other struggles to wink.", "task": "AttributeRecognition", "clean_prompt": "A girl is teaching her friend Shayna how to wink, demonstrating while Shayna is struggling to wink.", "clean_property": {"obj": "girl_2", "attribute": "struggling to wink"}, "target_prompt": "A girl is teaching her friend Shayna how to wink, demonstrating while Shayna is successfully winking.", "target_property": {"obj": "girl_2", "attribute": "successfully winking"}, "evaluation_question": "Is the girl struggling to wink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl is teaching her friend Shayna how to wink, demonstrating while Shayna is struggling to wink. )!W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8c2600dce6d4f1089119127cbf997b3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7af74d5861c049988d013c285e05aadb", "source": "vatex", "video_id": "WHAEDr-9PBk_000000_000010", "video_description": "A young man is skillfully riding a Segway up a ramp and then down a set of stairs in a park.", "task": "Counting", "clean_prompt": "Three people are watching a young man skillfully riding a Segway up a ramp and then down a set of stairs in a park.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is watching a young man skillfully riding a Segway up a ramp and then down a set of stairs in a park.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people watching the young man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are watching a young man skillfully riding a Segway up a ramp and then down a set of stairs in a park. 4&FEY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e02a892ae29849cf841c7696a24fddba.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1b63fccda8145ec90d98a483081d213", "source": "vatex", "video_id": "-HEqHN3KYuM_000010_000020", "video_description": "A person is removing a black plastic bag from an open cardboard box and attempting to empty its contents.", "task": "ObjectRecognition", "clean_prompt": "A person is removing a black plastic bag from an open cardboard box and attempting to empty its contents.", "clean_property": {"obj": "person"}, "target_prompt": "A cat is playing with a black plastic bag near an open cardboard box.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is removing a black plastic bag from an open cardboard box and attempting to empty its contents. >FEIL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4b2c5aad44424318b0c536d1dd48b24e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "984dc62f5f9c4aecbf518d0a563af47e", "source": "vatex", "video_id": "lHe6Ehd5S0Y_000001_000011", "video_description": "A young man with long hair is having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "task": "ActionRecognition", "clean_prompt": "A person staring at the camera during a staring contest.", "clean_property": {"obj": "person", "action": "staring", "target": null}, "target_prompt": "A person laughing at the camera during a funny moment.", "target_property": {"obj": "person", "action": "laughing", "target": "camera"}, "evaluation_question": "Is the person **staring** at the camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person staring at the camera during a staring contest. )&&&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b6874acb7b8c4b889677d3ebdde49263.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "237c55d4de0643aaa968a2c3d902e437", "source": "vatex", "video_id": "tXtLASDaPrY_000026_000036", "video_description": "Two young children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room.", "task": "ActionRecognition", "clean_prompt": "A child riding a bike in a living room.", "clean_property": {"obj": "child", "action": "riding a bike", "target": "toy vehicle"}, "target_prompt": "A child playing with a toy vehicle in a living room.", "target_property": {"obj": "child", "action": "playing with a toy", "target": "toy vehicle"}, "evaluation_question": "Is the child **riding a bike**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child riding a bike in a living room. !0=!&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1751f057ce20432da6009b2e142162e1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed8cd62147564f7cbe07f33076f295b5", "source": "vatex", "video_id": "1vnr8-bq9io_000002_000012", "video_description": "A young girl is in a house watching television, then starts throwing a tantrum by jumping up and down, screaming, and crying. An adult, possibly her parent, is seated nearby and talking to her.", "task": "ActionRecognition", "clean_prompt": "A child watching television in a house.", "clean_property": {"obj": "child", "action": "watching tv", "target": "television"}, "target_prompt": "A child throwing a tantrum with toys in a house.", "target_property": {"obj": "child", "action": "throwing a tantrum", "target": "toys"}, "evaluation_question": "Is the child **watching television**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child watching television in a house. NKP@@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9abeebc419084274bf64771267d37c2f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0464b5546ad442f681a6524aee1c0d4c", "source": "vatex", "video_id": "IczD9OzKvco_000102_000112", "video_description": "A baby is sitting in a high chair, shaking his head and smiling, while a woman interacts with him by talking, shaking her head, and laughing.", "task": "AttributeRecognition", "clean_prompt": "A woman who is a mother interacting with a baby in a high chair.", "clean_property": {"obj": "woman", "attribute": "mother"}, "target_prompt": "A woman who is a sister interacting with a baby in a high chair.", "target_property": {"obj": "woman", "attribute": "sister"}, "evaluation_question": "Is the woman a **mother**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman who is a mother interacting with a baby in a high chair. >;MV?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c262f9dd39a44348a5dd8d040a69b208.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "200e0188abb14cf7bec9d48146729e21", "source": "vatex", "video_id": "RXDUufYbSto_000092_000102", "video_description": "A baby girl wearing a bonnet is being fed milk from a bottle by an adult.", "task": "ObjectRecognition", "clean_prompt": "A baby girl wearing a bonnet is being fed milk from a bottle by an adult.", "clean_property": {"obj": "baby"}, "target_prompt": "A puppy being fed from a bowl by an adult.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the subject in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby girl wearing a bonnet is being fed milk from a bottle by an adult. @VSV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c15236ece248439284f03f3e20fc18a2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c7c4ef3f10be40a0ac4082f16b76b197", "source": "vatex", "video_id": "ZL73Rek4-ds_000838_000848", "video_description": "A young girl in an orange jacket is using a smartphone, singing and talking to herself while texting.", "task": "Counting", "clean_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting.", "clean_property": {"obj": "girl", "count": "seven"}, "target_prompt": "Four girls in blue jackets are using tablets, dancing and laughing together.", "target_property": {"obj": "girl", "count": "four"}, "evaluation_question": "Are there exactly **seven** girls in orange jackets using smartphones?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven girls in orange jackets are using smartphones, singing and talking to themselves while texting. OC|FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3f9a30e5092c438ba747ce8d1ff2c73a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "87730236c2b04756a844b86507892a9e", "source": "vatex", "video_id": "QAgcSr8Khus_000012_000022", "video_description": "A man wearing a winter coat takes out garbage bags to the trash bins on a snowy day and pets a cat.", "task": "ObjectRecognition", "clean_prompt": "A man wearing a winter coat takes out garbage bags to the trash bins on a snowy day and pets a cat.", "clean_property": {"obj": "garbage bag"}, "target_prompt": "A man wearing a winter coat takes out recycling bins to the trash area on a snowy day and pets a dog.", "target_property": {"obj": "recycling bin"}, "evaluation_question": "Is the man taking out **garbage bags**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing a winter coat takes out garbage bags to the trash bins on a snowy day and pets a cat. /-,:!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd42b7c59ad7498a96f5ae42bdcdc2f6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "710f0e0fa7504008ac85f256e14c1818", "source": "vatex", "video_id": "W-64tYeFF5I_000014_000024", "video_description": "A group of children are playing dodgeball in a gymnasium using yellow rubber balls.", "task": "SpatialUnderstanding", "clean_prompt": "A group of children playing dodgeball in a gymnasium, with the children farther from the camera than the ball.", "clean_property": {"obj_1": "children", "relation": "farther from the camera than", "obj_2": "ball"}, "target_prompt": "A group of children playing dodgeball in a gymnasium, with the children closer to the camera than the ball.", "target_property": {"obj_1": "children", "relation": "closer to the camera than", "obj_2": "ball"}, "evaluation_question": "Are the children **farther from the camera than** the ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children playing dodgeball in a gymnasium, with the children farther from the camera than the ball. W%('U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9ca69e60e29e4915b2f3978c48e0446f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dbe0149fb3b345b19d51a054b9c5c4cf", "source": "vatex", "video_id": "2BjyVQyTwoo_000076_000086", "video_description": "A man is in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays.", "task": "ObjectRecognition", "clean_prompt": "A man in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays.", "clean_property": {"obj": "snake"}, "target_prompt": "A man in a concrete pit at a construction site, handling a lizard with a stick while religious chanting music plays.", "target_property": {"obj": "lizard"}, "evaluation_question": "Is the man handling a **snake** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a concrete pit at a construction site, handling a snake with a stick while religious chanting music plays. >BC2V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/27d55b2eca934ccc99644a1147efd017.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99408f25713540a59465fdd210814e63", "source": "vatex", "video_id": "jCd7wi4ygf0_000089_000099", "video_description": "A young male athlete is performing a high jump on a track and field setup, with a woman commentating on the event.", "task": "Counting", "clean_prompt": "A young male athlete is performing a high jump on a track and field setup, with six commentators providing insights on the event.", "clean_property": {"obj": "commentator", "count": "six"}, "target_prompt": "A young male athlete is performing a high jump on a track and field setup, with two commentators providing insights on the event.", "target_property": {"obj": "commentator", "count": "two"}, "evaluation_question": "Are there exactly **six** commentators providing insights on the event?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young male athlete is performing a high jump on a track and field setup, with six commentators providing insights on the event. IREZI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73d1a8642d92443893098805dcc1aeb2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9a2772d7e54246a49da2b19bad71d598", "source": "vatex", "video_id": "7O_3PcJND-A_000008_000018", "video_description": "A group of tourists are riding camels in a line across a desert landscape with some trees, accompanied by local guides.", "task": "SpatialUnderstanding", "clean_prompt": "A camel standing to the left of a guide in a desert landscape.", "clean_property": {"obj_1": "camel", "relation": "left of", "obj_2": "guide"}, "target_prompt": "A camel standing to the right of a guide in a desert landscape.", "target_property": {"obj_1": "camel", "relation": "right of", "obj_2": "guide"}, "evaluation_question": "Is the camel to the **left** of the guide?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A camel standing to the left of a guide in a desert landscape. /G*E&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce5cdcab4709492cb2f06eedd5076232.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "06d7e9f8607f41ec8555007251cd7607", "source": "vatex", "video_id": "Yc_y0lZfQtU_000000_000010", "video_description": "A young girl performs a high jump over a bar, landing on a large pad, while a crowd watches and cheers.", "task": "ActionRecognition", "clean_prompt": "A girl performing a high jump over a bar.", "clean_property": {"obj": "girl", "action": "high jump", "target": null}, "target_prompt": "A girl running on a track.", "target_property": {"obj": "girl", "action": "running", "target": null}, "evaluation_question": "Is the girl **performing a high jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing a high jump over a bar. SL%O1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b05a3a8df0b4c16b15bee7f7e53378f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e47e24c3ac814efb8f10914b79701b50", "source": "vatex", "video_id": "IiAiVAmxSF4_000034_000044", "video_description": "In a gym, a man sitting on an exercise ball is being instructed by another man sitting in a chair on how to properly perform exercises, including lifting weights.", "task": "SpatialUnderstanding", "clean_prompt": "A trainee farther from the camera than an exercise ball in a gym.", "clean_property": {"obj_1": "trainee", "relation": "farther from the camera than", "obj_2": "exercise ball"}, "target_prompt": "A trainee closer to the camera than an exercise ball in a gym.", "target_property": {"obj_1": "trainee", "relation": "closer to the camera than", "obj_2": "exercise ball"}, "evaluation_question": "Is the trainee **farther from the camera than** the exercise ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A trainee farther from the camera than an exercise ball in a gym. 0-FOE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/891092fe2649488cb2e7823a5529626f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d211a9904ac64626ae85853c80828385", "source": "vatex", "video_id": "vfTxhmVLDvw_000216_000226", "video_description": "A person is ice fishing, pulling a fish from a hole in the ice and lifting it out of a bucket filled with water.", "task": "ActionRecognition", "clean_prompt": "A person ice fishing, pulling a fish from a hole in the ice.", "clean_property": {"obj": "person", "action": "ice fishing", "target": "fish"}, "target_prompt": "A person catching fish with a net.", "target_property": {"obj": "person", "action": "catching fish", "target": "net"}, "evaluation_question": "Is the person **ice fishing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person ice fishing, pulling a fish from a hole in the ice. 8%FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f3090c380c0c446bb69337b1059c13bf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "32e0e34d9b2d4eb0aebdd2622f849aa9", "source": "vatex", "video_id": "BBZaHZ0DPDc_000031_000041", "video_description": "A man is sitting at a table counting twenty dollar bills and arranging them into piles.", "task": "ActionRecognition", "clean_prompt": "A person counting money at a table.", "clean_property": {"obj": "person", "action": "counting money", "target": "money"}, "target_prompt": "A person throwing money at a table.", "target_property": {"obj": "person", "action": "throwing money", "target": "money"}, "evaluation_question": "Is the person **counting** money?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person counting money at a table. FE.)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8ad992a08374f3da02cf09270570845.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f627e774f99e42789ab542fd81f76603", "source": "vatex", "video_id": "7qTjhLfDb7c_000063_000073", "video_description": "A young girl is riding a unicycle back and forth in a living room, demonstrating and explaining how to balance on it.", "task": "ActionRecognition", "clean_prompt": "A girl riding a unicycle back and forth in a living room.", "clean_property": {"obj": "girl", "action": "riding unicycle", "target": null}, "target_prompt": "A girl falling off a unicycle in a living room.", "target_property": {"obj": "girl", "action": "falling off unicycle", "target": null}, "evaluation_question": "Is the girl **riding** a unicycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl riding a unicycle back and forth in a living room. RP4|G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e88d5ab3b594333aed4e5fbc5333f79.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1178e2116132479f9b25bd0c04a88bfb", "source": "vatex", "video_id": "aXUa36rKo5w_000006_000016", "video_description": "A man is in a gym demonstrating and explaining how to perform exercises using a large exercise ball.", "task": "ActionRecognition", "clean_prompt": "A person exercising with an exercise ball in a gym.", "clean_property": {"obj": "person", "action": "exercising with an exercise ball", "target": null}, "target_prompt": "A person playing with an exercise ball in a gym.", "target_property": {"obj": "person", "action": "playing with an exercise ball", "target": null}, "evaluation_question": "Is the person **exercising** with an exercise ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person exercising with an exercise ball in a gym. )LVTV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6973a6dce41d4eac80722b1ae8d80993.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd8be2dc814849ac8141f8d6e462bcb1", "source": "vatex", "video_id": "458ISYfR7dU_000000_000010", "video_description": "A person is watching and recording a professional ice hockey game on television, occasionally pausing the playback.", "task": "ActionRecognition", "clean_prompt": "A team playing ice hockey on a rink.", "clean_property": {"obj": "team", "action": "playing ice hockey", "target": null}, "target_prompt": "A team playing soccer on a field.", "target_property": {"obj": "team", "action": "playing soccer", "target": null}, "evaluation_question": "Is the team **playing ice hockey**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A team playing ice hockey on a rink. !W0XB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/80bcd3e3dc7a4782a63e1354da404f12.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6ed3d37ecd8f4924bfd7a8c0a1ed1d12", "source": "vatex", "video_id": "UgEAu_Ld9D8_000052_000062", "video_description": "A woman is riding a mechanical bull at an outdoor fair or carnival, with the bull moving slowly back and forth.", "task": "ObjectRecognition", "clean_prompt": "A woman riding a mechanical bull at an outdoor fair.", "clean_property": {"obj": "woman"}, "target_prompt": "A man riding a mechanical bull at an outdoor fair.", "target_property": {"obj": "man"}, "evaluation_question": "Is the rider on the mechanical bull a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman riding a mechanical bull at an outdoor fair. ''!>-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57646d820b4a4dbb8118874290bc6634.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fe9f6bbbd2824e3c9e2fe88bf2475554", "source": "vatex", "video_id": "9TjkUylMBgQ_000134_000144", "video_description": "A woman is training a small dog outdoors by throwing treats and rewarding it for good behavior.", "task": "Counting", "clean_prompt": "A woman is training a small dog outdoors by throwing three treats and rewarding it for good behavior.", "clean_property": {"obj": "treat", "count": "three"}, "target_prompt": "A woman is training a small dog outdoors by throwing one treat and rewarding it for good behavior.", "target_property": {"obj": "treat", "count": "one"}, "evaluation_question": "Are there exactly **three** treats being thrown?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is training a small dog outdoors by throwing three treats and rewarding it for good behavior. -U0O-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2350c2edf58e4085931a20d3596e7e65.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "edb3da4101384b8d97e29de702cba615", "source": "vatex", "video_id": "5UU3iRQW28U_000000_000010", "video_description": "A baby boy is sitting on his father's lap, eating a piece of cake with his hands, getting frosting all over his face.", "task": "ObjectRecognition", "clean_prompt": "A baby boy is sitting on his father's lap, eating a piece of cake with his hands, getting frosting all over his face.", "clean_property": {"obj": "baby"}, "target_prompt": "A puppy is playing with a piece of cake, getting frosting all over its face.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the subject in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby boy is sitting on his father's lap, eating a piece of cake with his hands, getting frosting all over his face. LY7DJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fbb97ccaa59049d791123e9234837ec4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e66d64acbe344faf89ce272fca9c2748", "source": "vatex", "video_id": "5g1npcADyzE_000000_000010", "video_description": "A man on a golf course hits a golf ball with a golf club, and special effects make it appear as though the ball explodes.", "task": "ActionRecognition", "clean_prompt": "A man hitting a golf ball on a golf course.", "clean_property": {"obj": "man", "action": "hitting baseball", "target": "golf ball"}, "target_prompt": "A man kicking a soccer ball on a soccer field.", "target_property": {"obj": "man", "action": "kicking soccer ball", "target": "soccer ball"}, "evaluation_question": "Is the man **hitting** a golf ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man hitting a golf ball on a golf course. '!=W*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb8549a8040a44a88f5af69d0c31b616.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0d57d7007d774af58d0b9768d3ef82c0", "source": "vatex", "video_id": "Kh7SEzWU0hU_000003_000013", "video_description": "A young man is demonstrating how to use a video game controller, including holding it upside down, while talking to the camera.", "task": "ObjectRecognition", "clean_prompt": "A young man demonstrating how to use a video game controller while talking to the camera.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a video game controller while looking at the camera.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man demonstrating how to use a video game controller while talking to the camera. )?W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfbbc9ce05b14b419dbf4ba0e92664f5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f8588260a29c46a98cddd8d5bed10f33", "source": "vatex", "video_id": "iIl35DGzWio_000000_000010", "video_description": "A man is performing various jump rope exercises in a gym, demonstrating skillful and fancy jumps.", "task": "AttributeRecognition", "clean_prompt": "An older person performing various jump rope exercises in a gym.", "clean_property": {"obj": "person", "attribute": "older"}, "target_prompt": "A younger person performing various jump rope exercises in a gym.", "target_property": {"obj": "person", "attribute": "younger"}, "evaluation_question": "Is the person performing jump rope exercises **older**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An older person performing various jump rope exercises in a gym. ))(U=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/31ef6da4681f474486b9a4aff948ac58.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b314fb54c7624ee9b91e071ac16e046c", "source": "vatex", "video_id": "mrKntbg0ibw_000068_000078", "video_description": "A woman dives off a high diving board into a swimming pool, followed by a young boy who is waiting to jump.", "task": "ActionRecognition", "clean_prompt": "A woman springboard diving into a swimming pool.", "clean_property": {"obj": "woman", "action": "springboard diving", "target": null}, "target_prompt": "A woman swimming in a swimming pool.", "target_property": {"obj": "woman", "action": "swimming", "target": null}, "evaluation_question": "Is the woman **springboard diving**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman springboard diving into a swimming pool. FE@1V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20e4587a6f1c4899bbe1a36a9002fc45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33ff56fb91d946888d8f7087ea0e14b7", "source": "vatex", "video_id": "va3txyK3Xck_000552_000562", "video_description": "A person is demonstrating knitting techniques, including casting off, using green or teal yarn and needles, with opera music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating knitting techniques with knitting needles and green yarn, accompanied by opera music.", "clean_property": {"obj": "knitting needles"}, "target_prompt": "A person demonstrating crochet techniques with crochet hooks and teal yarn, accompanied by opera music.", "target_property": {"obj": "crochet hooks"}, "evaluation_question": "Is the person using **knitting needles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating knitting techniques with knitting needles and green yarn, accompanied by opera music. GBS4A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/687982cd54904ddf8aecf4dd714385f3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "737202ae9e164155a2e3c8fc077faeca", "source": "vatex", "video_id": "O-Hy9k_Kf3c_000019_000029", "video_description": "A man in a suit and tie is demonstrating and explaining how to make balloon animals, including shaping a balloon into an elephant.", "task": "AttributeRecognition", "clean_prompt": "A person wearing a suit and tie demonstrating how to make balloon animals.", "clean_property": {"obj": "person", "attribute": "wearing a suit and tie"}, "target_prompt": "A person wearing casual clothes demonstrating how to make balloon animals.", "target_property": {"obj": "person", "attribute": "wearing casual clothes"}, "evaluation_question": "Is the person wearing a **suit and tie**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a suit and tie demonstrating how to make balloon animals. @SFC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3909dd47db814e6eb7f11118ff1427a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ff74a7354a3b435cb65be1bc104d0c25", "source": "vatex", "video_id": "JQTZTmaD86Q_000020_000030", "video_description": "A young girl stands on a bathroom counter in front of a mirror, brushing her teeth while wearing pajamas and an Olympic medal. Music is playing in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the left of a toothbrush while brushing her teeth.", "clean_property": {"obj_1": "girl", "relation": "left of", "obj_2": "toothbrush"}, "target_prompt": "A girl standing to the right of a toothbrush while brushing her teeth.", "target_property": {"obj_1": "girl", "relation": "right of", "obj_2": "toothbrush"}, "evaluation_question": "Is the girl to the **left** of the toothbrush?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the left of a toothbrush while brushing her teeth. EL(O\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e03b3189b8b24675a593ef1fce30667a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7b9afd42b1104c558ce447f93b25b358", "source": "vatex", "video_id": "gcW4uVP8Cos_000000_000010", "video_description": "A person is cleaning various windows using a squeegee and soapy water at a gas station.", "task": "AttributeRecognition", "clean_prompt": "A person cleaning windows at a gas station using a squeegee with a long pole.", "clean_property": {"obj": "squeegee", "attribute": "long pole"}, "target_prompt": "A person cleaning windows at a gas station using a squeegee with a short handle.", "target_property": {"obj": "squeegee", "attribute": "short handle"}, "evaluation_question": "Is the squeegee being used a **long pole** type?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning windows at a gas station using a squeegee with a long pole. ,P9HV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bdb9fbeab34d4cdca535cb5f3067d9e3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "74e97ed11d6f46dcbe0861c650146f84", "source": "vatex", "video_id": "KLc4My5e80I_000012_000022", "video_description": "A man attempts to drink a flaming shot, resulting in his face catching fire.", "task": "SpatialUnderstanding", "clean_prompt": "A coke bottle closer to the camera than a flaming shot.", "clean_property": {"obj_1": "coke bottle", "relation": "closer to the camera than", "obj_2": "flaming shot"}, "target_prompt": "A coke bottle further from the camera than a flaming shot.", "target_property": {"obj_1": "coke bottle", "relation": "further from the camera than", "obj_2": "flaming shot"}, "evaluation_question": "Is the coke bottle **closer to the camera than** the flaming shot?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A coke bottle closer to the camera than a flaming shot. LFVDJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4c7803b074344d23a933134837cd96ea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a7bfa5a095e47518864a5f20adb7a7b", "source": "vatex", "video_id": "lF84xIuQ5Uk_000137_000147", "video_description": "A young girl is demonstrating how to tie a necktie while wearing a white dress shirt.", "task": "ObjectRecognition", "clean_prompt": "A young girl is demonstrating how to tie a necktie while wearing a white dress shirt.", "clean_property": {"obj": "tie"}, "target_prompt": "A young girl is demonstrating how to tie a scarf while wearing a white dress shirt.", "target_property": {"obj": "scarf"}, "evaluation_question": "Is the girl demonstrating how to tie a **necktie**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is demonstrating how to tie a necktie while wearing a white dress shirt. USTJZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/43db88c753964f299415e848b05c90b5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e38b1aeb5a85415c86027b4b627cc25d", "source": "vatex", "video_id": "2Y7Z2Eb7B-g_000000_000010", "video_description": "A young boy is pushing a girl in a wheelchair quickly through the aisles of a grocery store.", "task": "Counting", "clean_prompt": "Three girls are being pushed in wheelchairs quickly through the aisles of a grocery store.", "clean_property": {"obj": "girl", "count": "three"}, "target_prompt": "A girl is being pushed in a wheelchair quickly through the aisles of a grocery store.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **three** girls being pushed in wheelchairs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls are being pushed in wheelchairs quickly through the aisles of a grocery store. FS;9G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/babc025d2a144c17922c782b890cd0cb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e115eff8e4004ee598e6141ccf807e5a", "source": "vatex", "video_id": "rg-fGN7hgSA_000019_000029", "video_description": "A man is demonstrating how to tie a knot using two pieces of different colored rope, one yellow and one blue.", "task": "SpatialUnderstanding", "clean_prompt": "A rope positioned to the left of a person demonstrating how to tie a knot.", "clean_property": {"obj_1": "rope", "relation": "left of", "obj_2": "person"}, "target_prompt": "A rope positioned to the right of a person demonstrating how to tie a knot.", "target_property": {"obj_1": "rope", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the rope to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rope positioned to the left of a person demonstrating how to tie a knot. LYP9J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ae8e1b9e5e4e4d3e8a179824d1fc8ed2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "00489b1a2db941a1ba32095287a15d9a", "source": "vatex", "video_id": "iT4p5yYblbA_000032_000042", "video_description": "A female street performer with red hair performs a sword swallowing act in front of a cheering crowd outdoors.", "task": "ActionRecognition", "clean_prompt": "A crowd applauding a female street performer with red hair performing a sword swallowing act outdoors.", "clean_property": {"obj": "crowd", "action": "applauding", "target": null}, "target_prompt": "A crowd booing a female street performer with red hair performing a sword swallowing act outdoors.", "target_property": {"obj": "crowd", "action": "booing", "target": null}, "evaluation_question": "Is the crowd **applauding** the performer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd applauding a female street performer with red hair performing a sword swallowing act outdoors. FE4E@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4cac1c9d9b0e4327b2e24942ba236ace.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4f22c41a55134235a6aa461e0de1b2f4", "source": "vatex", "video_id": "4jznikNJSG0_000005_000015", "video_description": "A person is creating artwork by carving and burning images and text into a small circular piece of wood using a heat gun.", "task": "SpatialUnderstanding", "clean_prompt": "A piece of wood that is farther from the camera than a heat gun.", "clean_property": {"obj_1": "wood", "relation": "farther from the camera than", "obj_2": "heat gun"}, "target_prompt": "A piece of wood that is closer to the camera than a heat gun.", "target_property": {"obj_1": "wood", "relation": "closer to the camera than", "obj_2": "heat gun"}, "evaluation_question": "Is the piece of wood **farther from the camera than** the heat gun?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A piece of wood that is farther from the camera than a heat gun. ;E&UF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfcde8c0e7cd496d973b5b56bf4875e0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cecae258e91c4caaaa3c879b996f64dc", "source": "vatex", "video_id": "kFXX_-mKF1g_000034_000044", "video_description": "A man is demonstrating and explaining how to clean a bathroom, including the shower, toilet, and glass surfaces, using a spray cleaner and a cloth.", "task": "SpatialUnderstanding", "clean_prompt": "A person demonstrating how to clean a bathroom, standing farther from the camera than a spray cleaner.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "spray cleaner"}, "target_prompt": "A person demonstrating how to clean a bathroom, standing closer to the camera than a spray cleaner.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "spray cleaner"}, "evaluation_question": "Is the person **farther from the camera than** the spray cleaner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to clean a bathroom, standing farther from the camera than a spray cleaner. !C%|!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8192ee3c06f440ddbaf9cdc23d7b57e5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd1b06409f1e44b1adb8d2a0d44c5524", "source": "vatex", "video_id": "4IPJloqi8jE_000227_000237", "video_description": "A woman is shaving a man's head bald in a kitchen while he sits in a chair. Another man is present, talking to the woman.", "task": "Counting", "clean_prompt": "Five women are shaving a man's head bald in a kitchen while he sits in a chair. Another man is present, talking to the women.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman is shaving a man's head bald in a kitchen while he sits in a chair. Another man is present, talking to her.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women are shaving a man's head bald in a kitchen while he sits in a chair. Another man is present, talking to the women. #LFJ2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/75dad3a9691f43fc86f1c9993ca5d02c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "05b6295622b143afb369c903e225d0fe", "source": "vatex", "video_id": "q0aP8ZxGZBw_000000_000010", "video_description": "In a kitchen, several young men are joking around with a power drill, with one man holding the drill and another pretending to put the spinning drill bit into his mouth.", "task": "ObjectRecognition", "clean_prompt": "Several young men are joking around in a kitchen with a power drill.", "clean_property": {"obj": "drill"}, "target_prompt": "Several young men are joking around in a kitchen with a screwdriver.", "target_property": {"obj": "screwdriver"}, "evaluation_question": "Are the young men in the kitchen using a **drill**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several young men are joking around in a kitchen with a power drill. UG6,#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6496e69d9a314cb4951795d351231d77.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3c7d50a7d8eb4485afc9761015022086", "source": "vatex", "video_id": "t-W6nF_ULeU_000187_000197", "video_description": "Eight professional speed skaters are racing around an ice rink in an indoor arena, watched by a crowd.", "task": "SpatialUnderstanding", "clean_prompt": "A skater to the left of a crowd in an indoor arena.", "clean_property": {"obj_1": "skater", "relation": "left of", "obj_2": "crowd"}, "target_prompt": "A skater to the right of a crowd in an indoor arena.", "target_property": {"obj_1": "skater", "relation": "right of", "obj_2": "crowd"}, "evaluation_question": "Is the skater to the **left** of the crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skater to the left of a crowd in an indoor arena. ))'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42a798f820904b74b54b41ab5c99fb20.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a4f01c0007ca402e8bda14d231813df7", "source": "vatex", "video_id": "4YIbweBRUJ8_000059_000069", "video_description": "A woman is petting a dog and opens the blinds for the dog to look outside.", "task": "ActionRecognition", "clean_prompt": "A person petting a dog and opening the blinds for the dog to look outside.", "clean_property": {"obj": "person", "action": "petting cat", "target": "dog"}, "target_prompt": "A person playing with a cat in a sunny room.", "target_property": {"obj": "person", "action": "playing with cat", "target": "cat"}, "evaluation_question": "Is the person **petting a dog**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person petting a dog and opening the blinds for the dog to look outside. LY%-J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b532911e21144eccb33492eeebf745e9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "befef596642e472c92be50f99cb49b2c", "source": "vatex", "video_id": "H7LKm3h1yj0_000090_000100", "video_description": "A man in a blue shirt demonstrates how to tie a necktie, adjusting and tightening it around his neck while talking to the camera.", "task": "Counting", "clean_prompt": "A man demonstrating how to tie a necktie while talking to the camera, with four people watching him.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "A man demonstrating how to tie a necktie while talking to the camera, with one person watching him.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to tie a necktie while talking to the camera, with four people watching him. &FE@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e0062bb3fb04ae1b9c50acd6c98d679.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4de965c237e7411590516d021b06b750", "source": "vatex", "video_id": "CEUpjs4NWBc_000045_000055", "video_description": "A woman is giving a massage to a client, focusing on the neck and back, while discussing the use of massage oils and tonics.", "task": "AttributeRecognition", "clean_prompt": "A client lying face down while receiving a massage on the neck and back.", "clean_property": {"obj": "client", "attribute": "lying face down"}, "target_prompt": "A client sitting upright while receiving a massage on the neck and back.", "target_property": {"obj": "client", "attribute": "sitting upright"}, "evaluation_question": "Is the client lying face down?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A client lying face down while receiving a massage on the neck and back. >8%PC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8de7da9c52e41d9aa1afed6e9a78655.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3a16be87c7314360afc32b386401d350", "source": "vatex", "video_id": "94H3kHrtzT4_000025_000035", "video_description": "A person is in a gym running sideways on an inclined treadmill.", "task": "ObjectRecognition", "clean_prompt": "A person is running sideways on an inclined treadmill in a gym.", "clean_property": {"obj": "person"}, "target_prompt": "A dog is running sideways on an inclined treadmill in a gym.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is running sideways on an inclined treadmill in a gym. ED7|P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f08f71e5e32c4ae6b15d3853a8dabd87.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7af866ac49734c1782326729c6f45f00", "source": "vatex", "video_id": "elad6vOMAFY_000076_000086", "video_description": "A woman is in the kitchen preparing dough and making homemade granola. She braids the dough into a loaf shape and prepares granola bars.", "task": "AttributeRecognition", "clean_prompt": "A woman in the kitchen preparing dough and making homemade granola.", "clean_property": {"obj": "granola", "attribute": "homemade"}, "target_prompt": "A woman in the kitchen preparing dough and making store-bought granola.", "target_property": {"obj": "granola", "attribute": "store-bought"}, "evaluation_question": "Is the granola **homemade**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in the kitchen preparing dough and making homemade granola. UDIVZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9fcfa75b7d0f444aa560d080fcc31781.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "01681c13efd546ea801eb0ba15e9bc7d", "source": "vatex", "video_id": "0mj0mwhozPo_000000_000010", "video_description": "A female athlete at a track meet attempts a high jump but fails, knocking the bar down.", "task": "ActionRecognition", "clean_prompt": "An athlete attempting a high jump at a track meet.", "clean_property": {"obj": "athlete", "action": "high jump", "target": "bar"}, "target_prompt": "An athlete performing a long jump into a sand pit.", "target_property": {"obj": "athlete", "action": "long jump", "target": "sand pit"}, "evaluation_question": "Is the athlete **attempting a high jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete attempting a high jump at a track meet. Q+\u00b7BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1006a70e81d64b718c64a41addd5ac17.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "70e0d642e69c489c9251c67680640376", "source": "vatex", "video_id": "TnDlF_KaiY4_000044_000054", "video_description": "A group of children are playing inside an inflatable bouncy house, throwing and holding inflatable balls, and occasionally falling.", "task": "Counting", "clean_prompt": "A group of six children are playing inside a bouncy house, throwing and holding inflatable balls, and occasionally falling.", "clean_property": {"obj": "bouncy house", "count": "six"}, "target_prompt": "A group of children are playing inside one bouncy house, throwing and holding inflatable balls, and occasionally falling.", "target_property": {"obj": "bouncy house", "count": "one"}, "evaluation_question": "Are there exactly **six** bouncy houses in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of six children are playing inside a bouncy house, throwing and holding inflatable balls, and occasionally falling. C|'':", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/acca3bc3965648ef9f53fb7c328aeb30.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57a4dd741e0247d0acee4cac3808a80a", "source": "vatex", "video_id": "krmuNJrZ36A_000000_000010", "video_description": "A large group of people, including men and boys, are participating in a military reenactment on a grassy field. The men are dressed in historic military uniforms and carrying rifles, while the boys are in white shirts carrying sticks. The scene involves preparation and role-playing of a battle.", "task": "AttributeRecognition", "clean_prompt": "A boy wearing white shirts participating in a military reenactment on a grassy field.", "clean_property": {"obj": "boy", "attribute": "wearing white shirts"}, "target_prompt": "A boy wearing blue shirts participating in a military reenactment on a grassy field.", "target_property": {"obj": "boy", "attribute": "wearing blue shirts"}, "evaluation_question": "Is the boy wearing a **white** shirt?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy wearing white shirts participating in a military reenactment on a grassy field. %/!''", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/915a9cb2220049438ed8cbe7c06d7bc9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8c5783c7a39d4582a37590eaf0988047", "source": "vatex", "video_id": "P_0DGpySlPY_000013_000023", "video_description": "A person is using a small handheld vacuum cleaner to clean various parts of the interior of a car, including the floor, sides, and back seat.", "task": "ObjectRecognition", "clean_prompt": "A person is using a small handheld vacuum cleaner to clean various parts of the interior of a car.", "clean_property": {"obj": "vacuum cleaner"}, "target_prompt": "A person is using a carpet cleaner to clean the interior of a car.", "target_property": {"obj": "carpet cleaner"}, "evaluation_question": "Is the cleaning device in the video a **vacuum cleaner**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is using a small handheld vacuum cleaner to clean various parts of the interior of a car. ))'!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a4988c957eb4492b89b50a5a8ede23b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1b19012858b841b183acc60329043dc1", "source": "vatex", "video_id": "O0hqyxavhCE_000007_000017", "video_description": "A young boy is playing a drum set in a room with flashing multicolor lights.", "task": "AttributeRecognition", "clean_prompt": "A young boy is playing a drum set in a room with flashing multicolor lights.", "clean_property": {"obj": "lights", "attribute": "multicolor"}, "target_prompt": "A young boy is playing a drum set in a room with static white lights.", "target_property": {"obj": "lights", "attribute": "static white"}, "evaluation_question": "Are the lights in the room flashing **multicolor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is playing a drum set in a room with flashing multicolor lights. 8VSBB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab6f486aaa60494c8c9d7d12aedd6059.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "79a0a9f8320847b486aaee4b2c2d9c95", "source": "vatex", "video_id": "uplv5JSxlgM_000385_000395", "video_description": "A person is demonstrating how to use a paint roller on a wooden surface while speaking in a foreign language.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to use a paint roller with foam on a wooden surface.", "clean_property": {"obj": "paint roller", "attribute": "foam"}, "target_prompt": "A person demonstrating how to use a paint roller with bristle on a wooden surface.", "target_property": {"obj": "paint roller", "attribute": "bristle"}, "evaluation_question": "Is the paint roller made of **foam**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to use a paint roller with foam on a wooden surface. )FE#J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b41b1e9af7474e4795675faf1d388edc.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3c8aa31151654bc9954cc8964f44281d", "source": "vatex", "video_id": "X7IdCdNM8mc_000180_000190", "video_description": "A person is shaving the head of another person outside, while a woman and a boy are also involved in hair cutting activities.", "task": "ObjectRecognition", "clean_prompt": "A person is shaving the head of another person outside with a clipper, while a woman and a boy are also involved in hair cutting activities.", "clean_property": {"obj": "clipper"}, "target_prompt": "A person is cutting hair outside with scissors, while a woman and a boy are also involved in hair cutting activities.", "target_property": {"obj": "scissors"}, "evaluation_question": "Is the person using a **clipper** to cut hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is shaving the head of another person outside with a clipper, while a woman and a boy are also involved in hair cutting activities. SL7R'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a6f391e67104279a1990e62952d9ef3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bdae19f7c7cf45aba665c6a7c99261d5", "source": "vatex", "video_id": "hQUTRBRmN-8_000019_000029", "video_description": "Several men are outside in a snow-filled area, walking, talking, and engaging in a snowball fight.", "task": "ObjectRecognition", "clean_prompt": "Several men are outside in a snow-filled area, walking, talking, and engaging in a snowball fight.", "clean_property": {"obj": "snow"}, "target_prompt": "Several men are outside in a sand-filled area, walking, talking, and engaging in a sandcastle building activity.", "target_property": {"obj": "sand"}, "evaluation_question": "Are the men in the video in a **snow**-filled area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several men are outside in a snow-filled area, walking, talking, and engaging in a snowball fight. !')!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/06e6e1437b0b483c8315b19de14ed7e7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fdc4c36a9f964aa5a22f25ca01092c5f", "source": "vatex", "video_id": "lhdTVB8HhEM_000111_000121", "video_description": "A woman is receiving a neck and upper back massage from another woman who is narrating the process in a foreign language.", "task": "SpatialUnderstanding", "clean_prompt": "A client sitting to the left of a therapist who is giving a neck and upper back massage.", "clean_property": {"obj_1": "client", "relation": "left of", "obj_2": "therapist"}, "target_prompt": "A client sitting to the right of a therapist who is giving a neck and upper back massage.", "target_property": {"obj_1": "client", "relation": "right of", "obj_2": "therapist"}, "evaluation_question": "Is the client to the **left** of the therapist?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A client sitting to the left of a therapist who is giving a neck and upper back massage. ');!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/410cb1227d8b451e8b1db3ad56aac6fd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "47285b8198544840909d7a17a43a5d86", "source": "vatex", "video_id": "pdRZ2BfZIwk_000003_000013", "video_description": "A man is cleaning the gutters of a house using a vacuum cleaner with a long pipe attachment from the ground.", "task": "Counting", "clean_prompt": "A man is using five vacuum cleaners with long pipe attachments to clean the gutters of a house from the ground.", "clean_property": {"obj": "vacuum cleaner", "count": "five"}, "target_prompt": "A man is using one vacuum cleaner with a short pipe attachment to clean the floor of a room.", "target_property": {"obj": "vacuum cleaner", "count": "one"}, "evaluation_question": "Are there exactly **five** vacuum cleaners being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using five vacuum cleaners with long pipe attachments to clean the gutters of a house from the ground. >0BCV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/901ee3b4e17e4aa59f010e386a509d41.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ec281c73ec824f808f86063e1d3a5f39", "source": "vatex", "video_id": "42tR0bQ0oTk_000009_000019", "video_description": "A man is getting baptized in a church while the congregation cheers him on. People are worshiping, praying, and listening to a sermon. The atmosphere is lively with music, clapping, and expressions of praise.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a congregation in a church.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "congregation"}, "target_prompt": "A man standing to the right of a congregation in a church.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "congregation"}, "evaluation_question": "Is the man to the **left** of the congregation?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a congregation in a church. ZFEA$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/668dc51232dd41dd966b3beb086880b3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9c6ab07e5b3d4c9cb2e2e6e34291ad6a", "source": "vatex", "video_id": "Q_izBQ28WNI_000127_000137", "video_description": "A young man is in a bedroom demonstrating and practicing knife throwing at a target on a bed.", "task": "Counting", "clean_prompt": "A young man is practicing knife throwing at a target on a bed with four pillows arranged around the target.", "clean_property": {"obj": "pillow", "count": "four"}, "target_prompt": "A young man is practicing knife throwing at a target on a bed with one pillow placed beside the target.", "target_property": {"obj": "pillow", "count": "one"}, "evaluation_question": "Are there exactly **four** pillows arranged around the target?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is practicing knife throwing at a target on a bed with four pillows arranged around the target. )G%Y)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a87e7a8c63f144d99724e74fd2750337.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e16286052e6d4642b6436f18799a0519", "source": "vatex", "video_id": "Wir2t6hUl28_000085_000095", "video_description": "A young girl is chewing bubble gum and blowing bubbles, sometimes popping them, while staring into a computer screen.", "task": "ObjectRecognition", "clean_prompt": "A young girl is chewing bubble gum and blowing bubbles while staring into a computer screen.", "clean_property": {"obj": "computer screen"}, "target_prompt": "A young girl is chewing bubble gum and blowing bubbles while staring into a television.", "target_property": {"obj": "television"}, "evaluation_question": "Is the girl staring into a **computer screen**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is chewing bubble gum and blowing bubbles while staring into a computer screen. @ZJVS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b9f0c6368a043aabb41dbcefe6588ec.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5dc7c46ee5264436938aa9da583a4dfe", "source": "vatex", "video_id": "Oi7uFkc3qQ4_000054_000064", "video_description": "Two children, a boy and a girl, are jumping on a trampoline in a backyard. The video is sped up at the beginning and circus music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A child bouncing on a trampoline in a backyard.", "clean_property": {"obj": "child", "action": "bouncing on trampoline", "target": null}, "target_prompt": "A child falling off a trampoline in a backyard.", "target_property": {"obj": "child", "action": "falling off trampoline", "target": null}, "evaluation_question": "Is the child **bouncing** on the trampoline?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child bouncing on a trampoline in a backyard. X)FEM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dfdb46bb6dc04d3ab9c8a4e050e8e269.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "379c49527d414391a5cd884c2910750c", "source": "vatex", "video_id": "lg8wUqwgDnQ_000018_000028", "video_description": "A group of children, including a boy and a lady, are in a dark room using solar flashlights to shine on their faces, making scary faces and noises while music plays.", "task": "ActionRecognition", "clean_prompt": "A person shining a flashlight in a dark room.", "clean_property": {"obj": "person", "action": "shining flashlight", "target": null}, "target_prompt": "A person waving a flashlight in a dark room.", "target_property": {"obj": "person", "action": "waving flashlight", "target": null}, "evaluation_question": "Is the person **shining** a flashlight?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shining a flashlight in a dark room. R.$XW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19d1de59e7e3444681853e183db2587d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "690079dafc1e4903a39acac838e91131", "source": "vatex", "video_id": "bj_kAPISHaE_000109_000119", "video_description": "A young girl is getting her ears pierced by a technician in a store setting, while talking with her friend.", "task": "Counting", "clean_prompt": "Two technicians assisting a young girl in a store while she gets her ears pierced.", "clean_property": {"obj": "technician", "count": "two"}, "target_prompt": "A technician assisting a young girl in a store while she gets her ears pierced.", "target_property": {"obj": "technician", "count": "one"}, "evaluation_question": "Are there exactly **two** technicians assisting the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two technicians assisting a young girl in a store while she gets her ears pierced. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb617aaca0424669ba991360568ecfdf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "94fe5f03a80244cea44e5487f5e9f925", "source": "vatex", "video_id": "TnlYyCArrNY_000041_000051", "video_description": "A woman is sitting in a chair indoors, knitting various items such as a scarf, hat, or bag using different colored yarns.", "task": "ActionRecognition", "clean_prompt": "A person knitting various items such as a scarf, hat, or bag using different colored yarns while sitting in a chair indoors.", "clean_property": {"obj": "person", "action": "knitting", "target": null}, "target_prompt": "A person crocheting various items such as a scarf, hat, or bag using different colored yarns while sitting in a chair indoors.", "target_property": {"obj": "person", "action": "crocheting", "target": null}, "evaluation_question": "Is the person **knitting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person knitting various items such as a scarf, hat, or bag using different colored yarns while sitting in a chair indoors. NILEU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/77fea1e6210f4aeb9c09016b4428f214.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5356a1dc02a64acc9f3dc6208406eef0", "source": "vatex", "video_id": "2XRtxWhF8SI_000027_000037", "video_description": "A group of children are playing and bouncing inside an inflatable play structure with a slide, having fun.", "task": "SpatialUnderstanding", "clean_prompt": "A child closer to the camera than an inflatable structure.", "clean_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "inflatable structure"}, "target_prompt": "A child further from the camera than an inflatable structure.", "target_property": {"obj_1": "child", "relation": "further from the camera than", "obj_2": "inflatable structure"}, "evaluation_question": "Is the child **closer to the camera than** the inflatable structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child closer to the camera than an inflatable structure. XPV4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/443c82cc8f7e4ddb83647d336897d6de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e1bc6ff5ae614aa9999a00a9746ba447", "source": "vatex", "video_id": "Xk2lpqrCR4E_000167_000177", "video_description": "Two boys are in a room demonstrating and practicing card tricks, including how to hold and throw playing cards.", "task": "ObjectRecognition", "clean_prompt": "Two boys are in a room demonstrating and practicing card tricks with playing cards.", "clean_property": {"obj": "playing card"}, "target_prompt": "Two boys are in a room demonstrating and practicing a board game.", "target_property": {"obj": "board game"}, "evaluation_question": "Are the boys demonstrating card tricks with **playing cards**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys are in a room demonstrating and practicing card tricks with playing cards. !HH%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46a5e278631c4b56b075ea534529377d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1d2543467b2e4a8e8d4382d2a1f22079", "source": "vatex", "video_id": "EAaP5vjgg0U_000033_000043", "video_description": "A young boy is playing with a toy train and a snake-like toy on the floor of a bedroom.", "task": "SpatialUnderstanding", "clean_prompt": "A boy farther from the camera than a toy train in a bedroom.", "clean_property": {"obj_1": "boy", "relation": "farther from the camera than", "obj_2": "train"}, "target_prompt": "A boy closer to the camera than a toy train in a bedroom.", "target_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "train"}, "evaluation_question": "Is the boy **farther from the camera than** the toy train?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy farther from the camera than a toy train in a bedroom. ED&2Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/15eeaab5e4f24d0aaa8b547d127f79e1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a485eca29d3248918647aec5cba7fa87", "source": "vatex", "video_id": "1Ddy4W31UYQ_000019_000029", "video_description": "A man is trimming and shaving his beard and mustache using an electric razor with a guard, in front of a mirror.", "task": "ActionRecognition", "clean_prompt": "A person trimming and shaving his beard in front of a mirror.", "clean_property": {"obj": "person", "action": "trimming or shaving beard", "target": null}, "target_prompt": "A person growing a beard in front of a mirror.", "target_property": {"obj": "person", "action": "growing beard", "target": null}, "evaluation_question": "Is the person **trimming or shaving** his beard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person trimming and shaving his beard in front of a mirror. RP>T4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c6999c1477849e791681a828eb01163.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5c8b20046a1402e877621317e9ea8f9", "source": "vatex", "video_id": "vwj04OqdYNk_000039_000049", "video_description": "A young girl demonstrates and explains how to use an asthma inhaler, occasionally flailing her arms playfully.", "task": "SpatialUnderstanding", "clean_prompt": "A girl standing to the left of an inhaler, demonstrating how to use it.", "clean_property": {"obj_1": "girl", "relation": "left of", "obj_2": "inhaler"}, "target_prompt": "A girl standing to the right of an inhaler, demonstrating how to use it.", "target_property": {"obj_1": "girl", "relation": "right of", "obj_2": "inhaler"}, "evaluation_question": "Is the girl to the **left** of the inhaler?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing to the left of an inhaler, demonstrating how to use it. FEA$>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/62325c1db3d84bfbbe427ee37ca81b6f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "35e20299f6f043c8ab260fac4ff504f1", "source": "vatex", "video_id": "fZwFVgDSdXw_000014_000024", "video_description": "A large group of people are standing, clapping, and singing joyfully during a church service with organ music playing.", "task": "Counting", "clean_prompt": "Seven people standing, clapping, and singing joyfully during a church service with organ music playing.", "clean_property": {"obj": "people", "count": "seven"}, "target_prompt": "Three people standing, clapping, and singing joyfully during a church service with organ music playing.", "target_property": {"obj": "people", "count": "three"}, "evaluation_question": "Are there exactly **seven** people standing during the church service?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people standing, clapping, and singing joyfully during a church service with organ music playing. =5BC2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f89aa6cbc55246c39db4341baecaeef1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21aa38618a36471c97b89ecf860e4a0e", "source": "vatex", "video_id": "r2BadvUBRWc_000008_000018", "video_description": "An athlete is performing a long jump at a track event, running and jumping into a sand pit. The event is filmed in slow motion on a cloudy day.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a long jump into a sand pit at a track event.", "clean_property": {"obj": "athlete", "action": "long jump", "target": "sand pit"}, "target_prompt": "An athlete performing a high jump onto a mat.", "target_property": {"obj": "athlete", "action": "high jump", "target": "mat"}, "evaluation_question": "Is the athlete **performing a long jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a long jump into a sand pit at a track event. HSLFK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c91891bf36645a5a07a218cfaccc838.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5543b0c369604d4685cc61cc1fdffb85", "source": "vatex", "video_id": "KDUsKnUP-K0_000001_000011", "video_description": "A person, sometimes identified as a kid, is folding an orange piece of paper into a paper airplane on a table.", "task": "ActionRecognition", "clean_prompt": "A person folding an orange piece of paper into a paper airplane on a table.", "clean_property": {"obj": "person", "action": "folding paper", "target": "paper"}, "target_prompt": "A person tearing an orange piece of paper on a table.", "target_property": {"obj": "person", "action": "tearing paper", "target": "paper"}, "evaluation_question": "Is the person **folding** paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding an orange piece of paper into a paper airplane on a table. FE|NV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c41781a68cd048e6a0b0a73005ff7eb6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae0e05d4d8a9423e8537f70348b8ac9f", "source": "vatex", "video_id": "CVVTcvOrWv8_000590_000600", "video_description": "Several construction workers are working indoors, using dollies to transport and lay bricks on the ground.", "task": "ActionRecognition", "clean_prompt": "A worker laying bricks indoors using dollies.", "clean_property": {"obj": "worker", "action": "laying bricks", "target": "brick"}, "target_prompt": "A worker removing bricks indoors using dollies.", "target_property": {"obj": "worker", "action": "removing bricks", "target": "brick"}, "evaluation_question": "Is the worker **laying** bricks?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A worker laying bricks indoors using dollies. !D|(&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1bf490f48dce4c75bf715204249c6034.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f9f7f13859b04894b528fe843418219a", "source": "vatex", "video_id": "ZAaDRrMGGnQ_000010_000020", "video_description": "A man wearing a t-shirt, possibly with a Pink Floyd design, is demonstrating how to tie a burgundy neck tie.", "task": "ActionRecognition", "clean_prompt": "A person tying a burgundy necktie while wearing a t-shirt with a Pink Floyd design.", "clean_property": {"obj": "person", "action": "tying necktie", "target": "tie"}, "target_prompt": "A person untying a burgundy necktie while wearing a t-shirt with a Pink Floyd design.", "target_property": {"obj": "person", "action": "untie necktie", "target": "tie"}, "evaluation_question": "Is the person **tying** a necktie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a burgundy necktie while wearing a t-shirt with a Pink Floyd design. |\u00b7?DS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/155def83635d47d28fc1c2d74d7fe767.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "91fb6285755d4b16916fd64da2299763", "source": "vatex", "video_id": "sBl88WXnwQ4_000010_000020", "video_description": "A professional baseball game is taking place with players on the field and fans watching from the stands. A pitcher throws a strike past a batter, which is caught by the catcher. The batter swings and misses. Later, a batter hits a ball into the stands, and a fan catches it.", "task": "Counting", "clean_prompt": "Three fans cheering at a professional baseball game.", "clean_property": {"obj": "fan", "count": "three"}, "target_prompt": "One fan cheering at a professional baseball game.", "target_property": {"obj": "fan", "count": "one"}, "evaluation_question": "Are there exactly **three** fans cheering at the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three fans cheering at a professional baseball game. =)FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df2db312c9424a71bbe6887b75ee943a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ec457b4ad7a64b9580d8bb1f08cd5fe7", "source": "vatex", "video_id": "FF_wPtSTXSc_000024_000034", "video_description": "A dog sled race is starting in the snow with a crowd of spectators cheering and clapping as sledders begin their journey.", "task": "SpatialUnderstanding", "clean_prompt": "A sledder farther from the camera than a dog in a snowy landscape.", "clean_property": {"obj_1": "sledder", "relation": "farther from the camera than", "obj_2": "dog"}, "target_prompt": "A sledder closer to the camera than a dog in a snowy landscape.", "target_property": {"obj_1": "sledder", "relation": "closer to the camera than", "obj_2": "dog"}, "evaluation_question": "Is the sledder **farther from the camera than** the dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sledder farther from the camera than a dog in a snowy landscape. PD#\u00b7Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8e725541f04479fbc022ffb7ede29fb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "270e78019b304f99a1b3fc592e9e4ee9", "source": "vatex", "video_id": "2xVH-79zc_U_000000_000010", "video_description": "A man is performing a shot put throw in an indoor facility while other men watch.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a shot put throw in an indoor facility.", "clean_property": {"obj": "athlete", "action": "shot put", "target": null}, "target_prompt": "An athlete performing a javelin throw in an indoor facility.", "target_property": {"obj": "athlete", "action": "javelin throw", "target": null}, "evaluation_question": "Is the athlete **performing a shot put throw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a shot put throw in an indoor facility. FS#|J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f018aef848e432e82e06f3a4eee4099.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "50e7bc76563f4f788856c9dd7e866aab", "source": "vatex", "video_id": "fGA1IPQZGmM_000199_000209", "video_description": "A man demonstrates how to properly clean suede footwear using a brush with brass bristles. He displays the shoes on a table and uses the brush to buff and clean them.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrates how to properly clean a shoe using a brush with brass bristles.", "clean_property": {"obj": "shoe"}, "target_prompt": "A man demonstrates how to properly clean a boot using a brush with brass bristles.", "target_property": {"obj": "boot"}, "evaluation_question": "Is the footwear being cleaned a **shoe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to properly clean a shoe using a brush with brass bristles. U%D))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0cdcc9b52620438f86402fcb04f66f0f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a5870174993e4569bbc33fd909550771", "source": "vatex", "video_id": "RWuj_PJl-Ho_000000_000010", "video_description": "A young boy is sitting in a baby walker, eating food with his hands.", "task": "Counting", "clean_prompt": "A young boy is sitting in a baby walker, eating food with his hands, with two trays of food beside him.", "clean_property": {"obj": "tray", "count": "two"}, "target_prompt": "A young boy is sitting in a baby walker, eating food with his hands, with one tray of food beside him.", "target_property": {"obj": "tray", "count": "one"}, "evaluation_question": "Are there exactly **two** trays of food beside the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting in a baby walker, eating food with his hands, with two trays of food beside him. FE%XT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aefc2199b7d049fe99b0a28041a0c746.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "abb099762aba437eb838f1a4c64ab735", "source": "vatex", "video_id": "2FlVNwpozfI_000004_000014", "video_description": "A man in a white shirt stands behind a bar with a shelf full of liquor, demonstrating how to use a handheld device to remove bottle caps while talking to the camera.", "task": "AttributeRecognition", "clean_prompt": "A man in a white shirt stands behind a bar with a shelf full of liquor, demonstrating how to use a handheld device to remove bottle caps from a beer bottle.", "clean_property": {"obj": "bottle", "attribute": "beer"}, "target_prompt": "A man in a white shirt stands behind a bar with a shelf full of liquor, demonstrating how to use a handheld device to remove bottle caps from a soda bottle.", "target_property": {"obj": "bottle", "attribute": "soda"}, "evaluation_question": "Is the bottle being used a **beer** bottle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a white shirt stands behind a bar with a shelf full of liquor, demonstrating how to use a handheld device to remove bottle caps from a beer bottle. FEYT$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/712b6cb780ac4ac5826215b2f532f736.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "252de9e6d1ff4f3db5a0d3911766bf48", "source": "vatex", "video_id": "HaIbs963ZPg_000000_000010", "video_description": "A man is riding a mechanical bull in a large warehouse, surrounded by an inflated ring, while people watch and laugh.", "task": "ObjectRecognition", "clean_prompt": "A man riding a mechanical bull in a large warehouse, surrounded by spectators who are watching and laughing.", "clean_property": {"obj": "spectators"}, "target_prompt": "A man riding a mechanical bull in a large warehouse, surrounded by participants who are cheering and clapping.", "target_property": {"obj": "participants"}, "evaluation_question": "Are the people in the video **spectators**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man riding a mechanical bull in a large warehouse, surrounded by spectators who are watching and laughing. '''!)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aab4a67502964b409bb83f70dea86618.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "421e29c15d10484fb57dad83750af63e", "source": "vatex", "video_id": "V77pj1em6yI_000087_000097", "video_description": "A woman and a child are playing kickball in a backyard, passing the ball back and forth.", "task": "ActionRecognition", "clean_prompt": "A woman playing kickball in a backyard.", "clean_property": {"obj": "woman", "action": "playing kickball", "target": "ball"}, "target_prompt": "A woman kicking a ball towards a goal in a backyard.", "target_property": {"obj": "woman", "action": "kicking a ball", "target": "goal"}, "evaluation_question": "Is the woman **playing kickball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman playing kickball in a backyard. FE4IT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/00768f1796ea4eabad7db67e1f4c88fb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d59ac825827141f7a2f32c040f1a5467", "source": "vatex", "video_id": "9rZnxQ4A5k4_000379_000389", "video_description": "A woman in a white skirt and green helmet is attempting to ride a skateboard, while a little boy successfully skateboards around a neighborhood street.", "task": "AttributeRecognition", "clean_prompt": "A woman wearing a green helmet attempting to ride a skateboard.", "clean_property": {"obj": "woman", "attribute": "wearing a green helmet"}, "target_prompt": "A woman wearing a red helmet attempting to ride a skateboard.", "target_property": {"obj": "woman", "attribute": "wearing a red helmet"}, "evaluation_question": "Is the woman wearing a **green** helmet?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman wearing a green helmet attempting to ride a skateboard. %''?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1af4cc2d4a394b97a6a3a6e4eeae6f4d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0b9f764033c34d4cab041437f2f273d4", "source": "vatex", "video_id": "meL-J5bKds8_000106_000116", "video_description": "A man in a suit, who is a magician, demonstrates how to create various shapes and tricks using twisty balloons in a room.", "task": "Counting", "clean_prompt": "A magician in a suit demonstrating balloon tricks with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A magician in a suit demonstrating balloon tricks with four people watching.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **seven** people watching the magician?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A magician in a suit demonstrating balloon tricks with seven people watching. /TZ:A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dfd4c6a4a03845b7a2be1c06ebeb4062.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2b4298029f0046f397877f6dce5ad067", "source": "vatex", "video_id": "cAjEm1xu_lk_000009_000019", "video_description": "A woman demonstrates how to fold a white cloth napkin on a wooden table, explaining the steps for a fancy table setting.", "task": "Counting", "clean_prompt": "A woman demonstrates how to fold six white cloth napkins on a wooden table, explaining the steps for a fancy table setting.", "clean_property": {"obj": "napkin", "count": "six"}, "target_prompt": "A woman demonstrates how to fold two white cloth napkins on a wooden table, explaining the steps for a casual table setting.", "target_property": {"obj": "napkin", "count": "two"}, "evaluation_question": "Are there exactly **six** napkins being folded on the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to fold six white cloth napkins on a wooden table, explaining the steps for a fancy table setting. &FESJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6061b1eeefd405db4a61f8df58c64f5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e84d8298f4dc493dbe151cc3d5b3bab6", "source": "vatex", "video_id": "nWq29IA5Vv8_000043_000053", "video_description": "A man is feeding a small bird directly from his mouth while holding it on his hand.", "task": "ObjectRecognition", "clean_prompt": "A man is feeding a small bird from his mouth while holding it in his hand.", "clean_property": {"obj": "bird"}, "target_prompt": "A man is feeding a small cat from his mouth while holding it in his hand.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the animal being fed in the video a **bird**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is feeding a small bird from his mouth while holding it in his hand. /SL\u00b7@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/058229f6c20d402bb78b5bf5b632c171.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5ac19f49a36d4077b47b8db7f6d51aae", "source": "vatex", "video_id": "M3ft-obGuUk_000010_000020", "video_description": "A female athlete attempts a pole vault at a track meet, but fails to clear the bar and falls, missing the landing mats. Spectators are present, and a loudspeaker is audible.", "task": "ObjectRecognition", "clean_prompt": "A female athlete attempts a pole vault at a track meet, but falls and misses the landing mats.", "clean_property": {"obj": "mat"}, "target_prompt": "A female athlete attempts a pole vault at a track meet, but falls and lands in a pool of water.", "target_property": {"obj": "water"}, "evaluation_question": "Does the athlete land on **mats**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female athlete attempts a pole vault at a track meet, but falls and misses the landing mats. ')/!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5a44fee58afb4b9d8730189dd66b0bc2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90d7c01e15d14d6194b828ddbf1546e7", "source": "vatex", "video_id": "F-Bv7FBt9rM_000053_000063", "video_description": "A young female TV weather reporter is presenting the weather forecast in a studio, using an electronic screen displaying a map with weather symbols.", "task": "AttributeRecognition", "clean_prompt": "A young female TV weather reporter presenting the weather forecast in a studio, using an electronic screen displaying a map with weather symbols.", "clean_property": {"obj": "screen", "attribute": "electronic"}, "target_prompt": "A young female TV weather reporter presenting the weather forecast in a studio, using a paper screen displaying a map with weather symbols.", "target_property": {"obj": "screen", "attribute": "paper"}, "evaluation_question": "Is the screen being used by the reporter **electronic**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young female TV weather reporter presenting the weather forecast in a studio, using an electronic screen displaying a map with weather symbols. =F$XM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c5dd9d3d36a74b56bebaf3aca215d976.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e165da63f79f46cebdbff7f1cecb9415", "source": "vatex", "video_id": "hW2ZI3zp74I_000190_000200", "video_description": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night. The truck is slowly driving down a road, with workers walking around and behind it, bringing garbage cans to the back.", "task": "AttributeRecognition", "clean_prompt": "A worker who is a garbage collector loading garbage into a truck at night.", "clean_property": {"obj": "worker", "attribute": "garbage collector"}, "target_prompt": "A worker who is a street cleaner sweeping the road during the day.", "target_property": {"obj": "worker", "attribute": "street cleaner"}, "evaluation_question": "Is the worker a **garbage collector**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A worker who is a garbage collector loading garbage into a truck at night. XF2;6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab5dfe54a809465e82dda3ef12eb6104.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d6a9a47b748b49e98737ce3bec102022", "source": "vatex", "video_id": "6SBQJwsNMQM_000018_000028", "video_description": "A person wearing a Santa hat is sitting in a living room, opening a Christmas present wrapped in tissue paper.", "task": "Counting", "clean_prompt": "A person wearing a Santa hat is sitting in a living room, opening seven Christmas presents wrapped in tissue paper.", "clean_property": {"obj": "present", "count": "seven"}, "target_prompt": "A person wearing a Santa hat is sitting in a living room, opening three Christmas presents wrapped in tissue paper.", "target_property": {"obj": "present", "count": "three"}, "evaluation_question": "Are there exactly **seven** Christmas presents being opened?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a Santa hat is sitting in a living room, opening seven Christmas presents wrapped in tissue paper. LFE=C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/090ec3d73bda4734bd54a75fcb0d2d7d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "314a97280f894ffa85ab4cfe8c9b41c7", "source": "vatex", "video_id": "jDRUFw2seU8_000007_000017", "video_description": "A tattoo artist is applying a colorful flower tattoo to a woman's left foot using an electric tattoo tool.", "task": "SpatialUnderstanding", "clean_prompt": "A tattoo artist to the right of a woman.", "clean_property": {"obj_1": "tattoo artist", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A tattoo artist to the left of a woman.", "target_property": {"obj_1": "tattoo artist", "relation": "left of", "obj_2": "woman"}, "evaluation_question": "Is the tattoo artist to the **right** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tattoo artist to the right of a woman. FE7>*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/081809833e3e4c19b41a5be82e01cd4e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1376a0cba3264a10bfb78f893755c0d4", "source": "vatex", "video_id": "1V_Njbc_dos_000256_000266", "video_description": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process.", "task": "AttributeRecognition", "clean_prompt": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process.", "clean_property": {"obj": "paper", "attribute": "white"}, "target_prompt": "A young boy is drawing a picture of a woman's face with a pencil on a blue piece of paper, while explaining the process.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process. HSJ?\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9208e1f342d1443290b9b5857314942a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2e0bd7ec49046089a4309c8373cb1a2", "source": "vatex", "video_id": "LkONlu_JB7g_000000_000010", "video_description": "A person is outdoors in a yard, balancing and climbing a freestanding ladder without it leaning on anything.", "task": "ActionRecognition", "clean_prompt": "A person climbing a freestanding ladder in a yard.", "clean_property": {"obj": "person", "action": "climbing ladder", "target": null}, "target_prompt": "A person falling from a freestanding ladder in a yard.", "target_property": {"obj": "person", "action": "falling from ladder", "target": null}, "evaluation_question": "Is the person **climbing** the ladder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person climbing a freestanding ladder in a yard. -FEYV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e82935a32ac4a3db1321af355481c6b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "886197b508e745c6ac3225577e3ed943", "source": "vatex", "video_id": "EMPH4y2Zw3U_000006_000016", "video_description": "A man is participating in a rodeo or bullfighting event, riding a horse and interacting with a bull using a spear or lance.", "task": "ObjectRecognition", "clean_prompt": "A man participating in a rodeo, riding a horse and interacting with a bull using a spear.", "clean_property": {"obj": "bull"}, "target_prompt": "A man participating in a rodeo, riding a horse and interacting with a horse using a spear.", "target_property": {"obj": "horse"}, "evaluation_question": "Is the animal the man is interacting with a **bull**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man participating in a rodeo, riding a horse and interacting with a bull using a spear. 9TS$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8ae997d24a304c9ba322758f55b68325.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99dc525b38d7426a9bd2e8920a37a6d5", "source": "vatex", "video_id": "aHujd7e5Ppw_000265_000275", "video_description": "A person is demonstrating and explaining the process of buffing a car using a liquid solution and a buffing machine.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a buffing machine, demonstrating the process of buffing a car.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "buffing machine"}, "target_prompt": "A person standing to the left of a buffing machine, demonstrating the process of buffing a car.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "buffing machine"}, "evaluation_question": "Is the person to the **right** of the buffing machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a buffing machine, demonstrating the process of buffing a car. FE7PC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f5df6b527add47c8b14f5efeff9d8b3d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f331f800e3314698bb885928f6517256", "source": "vatex", "video_id": "bj3DrR-8kTQ_000023_000033", "video_description": "A traffic cop is standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "task": "SpatialUnderstanding", "clean_prompt": "A traffic cop standing to the left of cars at a busy city intersection.", "clean_property": {"obj_1": "traffic cop", "relation": "left of", "obj_2": "cars"}, "target_prompt": "A traffic cop standing to the right of cars at a busy city intersection.", "target_property": {"obj_1": "traffic cop", "relation": "right of", "obj_2": "cars"}, "evaluation_question": "Is the traffic cop to the **left** of the cars?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A traffic cop standing to the left of cars at a busy city intersection. \u00b7)FE.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/291d3acfaa924c4893fe8c4010ee9e1b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "74699080cebc486e9026154ac851d479", "source": "vatex", "video_id": "8vkNr_eysXY_000002_000012", "video_description": "A man is demonstrating how to cut a pineapple in a decorative fashion at a produce stand.", "task": "Counting", "clean_prompt": "Four people are gathered around a produce stand, watching a man demonstrate how to cut a pineapple in a decorative fashion.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is at a produce stand, demonstrating how to cut a pineapple in a decorative fashion.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people at the produce stand?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are gathered around a produce stand, watching a man demonstrate how to cut a pineapple in a decorative fashion. )!0D*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac3e5c8bcf3b457bb8f7ddea2c038f86.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd5ab773a61546dba95129e0de823e4b", "source": "vatex", "video_id": "_oiNIM2guMU_000373_000383", "video_description": "A person is demonstrating how to cut the core out of a slice of pineapple using a knife.", "task": "SpatialUnderstanding", "clean_prompt": "A person demonstrating how to cut the core out of a slice of pineapple using a knife, with the knife farther from the camera than the person.", "clean_property": {"obj_1": "knife", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A person demonstrating how to cut the core out of a slice of pineapple using a knife, with the knife closer to the camera than the person.", "target_property": {"obj_1": "knife", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the knife farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to cut the core out of a slice of pineapple using a knife, with the knife farther from the camera than the person. !0'|O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8198eab4a52049d5a6f0d745a1d813e4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae0a2c63b7f14de2bf8c846fe22f93a0", "source": "vatex", "video_id": "Ub55QO_MvUM_000013_000023", "video_description": "Two children are sitting on a couch playing with a large amount of paper money while a smaller child stands nearby watching.", "task": "ActionRecognition", "clean_prompt": "A child counting money while sitting on a couch.", "clean_property": {"obj": "child", "action": "counting money", "target": "money"}, "target_prompt": "A child throwing money while sitting on a couch.", "target_property": {"obj": "child", "action": "throwing money", "target": "money"}, "evaluation_question": "Is the child **counting** money?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child counting money while sitting on a couch. ?E.@O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3827f1373be4b549a1821ef4708de4e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c766e1b089a94ac98b47b7274bf367f9", "source": "vatex", "video_id": "ZC3cwb9vnb0_000004_000014", "video_description": "A man is talking on his cell phone and accidentally walks into a glass window, hurting his head.", "task": "ActionRecognition", "clean_prompt": "A person talking on a cell phone.", "clean_property": {"obj": "person", "action": "talking on cell phone", "target": null}, "target_prompt": "A person walking into a wall.", "target_property": {"obj": "person", "action": "walking into a wall", "target": null}, "evaluation_question": "Is the person **talking on a cell phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person talking on a cell phone. GN.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4349fdc2a44447208f1d46441f548c00.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "677119904dee44e4a4aa636dda9a9aef", "source": "vatex", "video_id": "uGt1mpsoERY_000048_000058", "video_description": "A woman is demonstrating various techniques and tools to adjust and fasten traditional garments, including a sari.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating various techniques to adjust and fasten a sari.", "clean_property": {"obj": "garment"}, "target_prompt": "A woman demonstrating various techniques to adjust and fasten a costume.", "target_property": {"obj": "costume"}, "evaluation_question": "Is the garment being demonstrated a **sari**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating various techniques to adjust and fasten a sari. !'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/db08a6aa6b8546d8a0de011afb07bac1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "556c0a6b11f4441c9c05c24e58682eca", "source": "vatex", "video_id": "zlf_Vd00AfY_000037_000047", "video_description": "A woman wearing a white hat is playing a flute in a living room with couches and a chair.", "task": "SpatialUnderstanding", "clean_prompt": "A flute farther from the camera than a person in a living room.", "clean_property": {"obj_1": "flute", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A flute closer to the camera than a person in a living room.", "target_property": {"obj_1": "flute", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the flute **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A flute farther from the camera than a person in a living room. !0D0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2692e3eb8487455d87d693ac34019745.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a4c87353ac84f4292143b37ddc3d312", "source": "vatex", "video_id": "_VTt8j4Now0_001288_001298", "video_description": "A woman is lying on a massage table receiving a shoulder and back massage from a man while narration plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a massage table.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "massage table"}, "target_prompt": "A man closer to the camera than a massage table.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "massage table"}, "evaluation_question": "Is the man **farther from the camera than** the massage table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a massage table. \u00b7G*Z)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6efcad2300114f498b03501236ea41c2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d0ab8124e254468bbf9b531c5111a249", "source": "vatex", "video_id": "5itHnZhjeg0_000092_000102", "video_description": "A man is in a recording studio, wearing headphones and standing in front of a microphone, singing and talking to record music.", "task": "SpatialUnderstanding", "clean_prompt": "A man wearing headphones standing to the right of a microphone in a recording studio.", "clean_property": {"obj_1": "headphones", "relation": "right of", "obj_2": "microphone"}, "target_prompt": "A man wearing headphones standing to the left of a microphone in a recording studio.", "target_property": {"obj_1": "headphones", "relation": "left of", "obj_2": "microphone"}, "evaluation_question": "Is the man wearing headphones **to the right** of the microphone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing headphones standing to the right of a microphone in a recording studio. !0O$B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1013bea32a50424ca45d1f3a26aa928a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a10f252b425d417381d9bf4f4b603128", "source": "vatex", "video_id": "sfl2CDKTp-Q_000004_000014", "video_description": "A man is in a gym balancing a sledgehammer with one arm, demonstrating an arm exercise.", "task": "SpatialUnderstanding", "clean_prompt": "A sledgehammer closer to the camera than a person in a gym.", "clean_property": {"obj_1": "sledgehammer", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A sledgehammer further from the camera than a person in a gym.", "target_property": {"obj_1": "sledgehammer", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the sledgehammer **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sledgehammer closer to the camera than a person in a gym. ?'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6fa2f44c2c334363bd88bba5605a1896.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "efffd0ffe31545008c244c6d448f5e8a", "source": "vatex", "video_id": "TGOraRFXygI_000062_000072", "video_description": "Two men are constructing a wall using cinder blocks and mortar, demonstrating and instructing on the process.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a cinder block.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "cinder block"}, "target_prompt": "A man closer to the camera than a cinder block.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "cinder block"}, "evaluation_question": "Is the man **farther from the camera than** the cinder block?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a cinder block. )=L)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/31bf7a65e88e4f79a7de3c222278dfa0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4fbaaa313831491dbb65a363f8cca975", "source": "vatex", "video_id": "8Wb8JPjcJCo_000028_000038", "video_description": "A man takes a pill and drinks a beverage, then kisses a woman. They are standing against a brick wall.", "task": "ObjectRecognition", "clean_prompt": "A man takes a pill and drinks a beverage, then kisses a woman against a brick wall.", "clean_property": {"obj": "beverage"}, "target_prompt": "A man takes a pill and eats food, then kisses a woman against a brick wall.", "target_property": {"obj": "food"}, "evaluation_question": "Is the man drinking a **beverage**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man takes a pill and drinks a beverage, then kisses a woman against a brick wall. ?'W%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a4ce5589f2444ec95502f74b8521a6e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5f3ab5df980f47f2bff27b03145603b5", "source": "vatex", "video_id": "jQjNdmkqHpg_000085_000095", "video_description": "A woman is demonstrating how to sew using a sewing machine, including preparing and cutting fabric.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to sew using a sewing machine.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a ball of yarn.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to sew using a sewing machine. ''!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e451ae9f2f2f4eaf90df5cd7a74d49ee.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a3bfc9247fb40f696fed287479de7ec", "source": "vatex", "video_id": "cuRpebukhx8_000097_000107", "video_description": "Two turkeys are in a grass field pecking at each other while being observed by a person from a hunting blind.", "task": "Counting", "clean_prompt": "Four turkeys pecking at each other in a grass field while being observed by a person from a hunting blind.", "clean_property": {"obj": "turkey", "count": "four"}, "target_prompt": "One turkey pecking at the ground in a grass field while being observed by a person from a hunting blind.", "target_property": {"obj": "turkey", "count": "one"}, "evaluation_question": "Are there exactly **four** turkeys in the grass field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four turkeys pecking at each other in a grass field while being observed by a person from a hunting blind. ED+E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5cc8a542ce71437288bad058bccacd30.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "abc9c1f510a74d22bc5840fda1950996", "source": "vatex", "video_id": "wAOrEF5hyQ4_000021_000031", "video_description": "A woman is carrying a young girl who is crying and wailing across a room, then sets her down.", "task": "ActionRecognition", "clean_prompt": "A woman carrying a young girl who is crying across a room.", "clean_property": {"obj": "woman", "action": "carrying baby", "target": "child"}, "target_prompt": "A woman playing with a child in a room.", "target_property": {"obj": "woman", "action": "playing with child", "target": "child"}, "evaluation_question": "Is the woman **carrying** a young girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman carrying a young girl who is crying across a room. OT,7A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d4b218335e354b2d91005ae863ba2111.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e205700a3a9640a29edbae3341215279", "source": "vatex", "video_id": "zeMgyQybSfs_000311_000321", "video_description": "A person is water skiing on a lake, being towed by a motor boat. The person is holding onto a rope attached to the boat and is wearing a GoPro camera.", "task": "ActionRecognition", "clean_prompt": "A person water skiing on a lake, being towed by a motor boat.", "clean_property": {"obj": "person", "action": "water skiing", "target": null}, "target_prompt": "A person snowboarding on a snowy mountain.", "target_property": {"obj": "person", "action": "snowboarding", "target": null}, "evaluation_question": "Is the person **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person water skiing on a lake, being towed by a motor boat. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d242592d15cf4edd9a4693b9fcfd4edd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d742ad00b8ab44b1baa19ca9483cd6a1", "source": "vatex", "video_id": "00pmPtsonQ4_000027_000037", "video_description": "A group of people are in a white water rafting boat on a river. A man rappels down a rope from a bridge above and lands in the boat. The Mission Impossible and James Bond theme music plays in the background.", "task": "AttributeRecognition", "clean_prompt": "A group of people in a white water rafting boat on a river, with a man rappelling down from a bridge above.", "clean_property": {"obj": "people", "attribute": "group"}, "target_prompt": "A group of people in a white water rafting boat on a river, singing together.", "target_property": {"obj": "people", "attribute": "singing"}, "evaluation_question": "Are the people in the boat **not** singing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people in a white water rafting boat on a river, with a man rappelling down from a bridge above. FCCFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d4d8065d967457281afed273378933f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "836d6e771a9a4ab3a54cbd5c602bae26", "source": "vatex", "video_id": "C39H2qdzy_s_000061_000071", "video_description": "A man is demonstrating and explaining how to paint an Artex wall using a paint roller.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a paint roller while demonstrating how to paint an Artex wall.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "paint roller"}, "target_prompt": "A person standing to the right of a paint roller while demonstrating how to paint an Artex wall.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "paint roller"}, "evaluation_question": "Is the person to the **left** of the paint roller?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a paint roller while demonstrating how to paint an Artex wall. >FEZJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4b155445834d45ddb6ecab3c27b589dd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "19a0297df3ab4f62900fb75989ca1aa3", "source": "vatex", "video_id": "X8HdzWEud4I_000066_000076", "video_description": "A group of men are participating in a hot dog eating contest while a crowd cheers them on. Some contestants are holding styrofoam cups and drinking water during the competition.", "task": "AttributeRecognition", "clean_prompt": "A contestant wearing an army t-shirt is participating in a hot dog eating contest while a crowd cheers.", "clean_property": {"obj": "contestant", "attribute": "wearing army t-shirt"}, "target_prompt": "A contestant wearing a clown costume is participating in a hot dog eating contest while a crowd cheers.", "target_property": {"obj": "contestant", "attribute": "wearing a clown costume"}, "evaluation_question": "Is the contestant wearing an **army** t-shirt?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A contestant wearing an army t-shirt is participating in a hot dog eating contest while a crowd cheers. =LF~D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0059ef301d6145a7a4febcd2e2ef923e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42c2da78bc4b4f2e8b3caa643a11ac0b", "source": "vatex", "video_id": "S-C86j0keqc_000217_000227", "video_description": "A young girl sings 'Amazing Grace' while a man plays the violin at a Civil War reenactment in a park on a summer's day.", "task": "ActionRecognition", "clean_prompt": "A man playing the violin at a Civil War reenactment in a park on a summer's day.", "clean_property": {"obj": "man", "action": "playing violin", "target": null}, "target_prompt": "A man playing the guitar at a Civil War reenactment in a park on a summer's day.", "target_property": {"obj": "man", "action": "playing guitar", "target": null}, "evaluation_question": "Is the man **playing the violin**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing the violin at a Civil War reenactment in a park on a summer's day. FE+R+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/118add7f6f7f4467b19e6034c9e232e0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d907497fbfd4078ab9ecc41c87331d3", "source": "vatex", "video_id": "V4ynfFv-EqE_000021_000031", "video_description": "A bald man in a white shirt is beatboxing and dancing in a colorful, well-lit room, possibly a television show stage, while holding a microphone.", "task": "ActionRecognition", "clean_prompt": "A person beatboxing and dancing in a colorful, well-lit room.", "clean_property": {"obj": "person", "action": "beatboxing", "target": null}, "target_prompt": "A person singing a song in a colorful, well-lit room.", "target_property": {"obj": "person", "action": "singing", "target": "song"}, "evaluation_question": "Is the person **beatboxing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person beatboxing and dancing in a colorful, well-lit room. )!U=B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/669838898baa47f39cd59d9fafb81df9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3fc31aafc2c34b69b0d45e26cdeaa3a7", "source": "vatex", "video_id": "Q1fYJxBm-cI_000032_000042", "video_description": "A woman, who is a sewing teacher, is sitting at a craft table in a classroom, demonstrating and explaining how to thread a needle and prepare for sewing.", "task": "Counting", "clean_prompt": "Three people sitting at a craft table, with a woman demonstrating how to thread a needle.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting at a craft table, demonstrating how to thread a needle.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people at the craft table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people sitting at a craft table, with a woman demonstrating how to thread a needle. 8BCZQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6495e85d32e8407083288d1ae6d3ba26.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "44e22047c2cd46ceb9037361f5c622d3", "source": "vatex", "video_id": "QHu1r44XhJ4_000160_000170", "video_description": "A man is paddling a yellow kayak in a river and ocean, navigating through waves and currents.", "task": "ObjectRecognition", "clean_prompt": "A man paddling a yellow kayak in a river, navigating through waves.", "clean_property": {"obj": "kayak"}, "target_prompt": "A man riding a surfboard in the ocean, navigating through waves.", "target_property": {"obj": "surfboard"}, "evaluation_question": "Is the man using a **kayak** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man paddling a yellow kayak in a river, navigating through waves. $FCCC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16b6d882a2ea4ed4a30c14b2b3d6a694.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1da392a093e4a379c98afe2bf95ab40", "source": "vatex", "video_id": "WFgdlkf9n5c_000001_000011", "video_description": "A young boy is attempting to skip a stone across a shallow body of water in a park-like setting.", "task": "ObjectRecognition", "clean_prompt": "A young boy is attempting to skip a stone across a shallow body of water in a park-like setting.", "clean_property": {"obj": "water"}, "target_prompt": "A young boy is building a sandcastle on the beach.", "target_property": {"obj": "sand"}, "evaluation_question": "Is the boy interacting with **water**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is attempting to skip a stone across a shallow body of water in a park-like setting. =4MVA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4900029ebf3a4aaabf6b0b6b2b27f9cf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "917dc85bd92b48d5bb7beb809546f2c3", "source": "vatex", "video_id": "_0ZBlXUcaOk_000013_000023", "video_description": "A young girl with blond hair is performing a walking handstand on a gym floor.", "task": "ObjectRecognition", "clean_prompt": "A child performing a walking handstand on a gym floor.", "clean_property": {"obj": "child"}, "target_prompt": "An adult performing a walking handstand on a gym floor.", "target_property": {"obj": "adult"}, "evaluation_question": "Is the performer in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child performing a walking handstand on a gym floor. !0D=|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c8081f3e2d374dccb1a5b152d6d1a715.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "95d9a9d16e4546acaa6c970789b17504", "source": "vatex", "video_id": "bhWFbwj7z6o_000005_000015", "video_description": "An older man holding a Civil War-era rifle is talking to a young boy at a historical reenactment event, possibly set in the 1800s, with an outdoor market setting.", "task": "SpatialUnderstanding", "clean_prompt": "A young boy standing farther from the camera than a rifle at a historical reenactment event.", "clean_property": {"obj_1": "young boy", "relation": "farther from the camera than", "obj_2": "rifle"}, "target_prompt": "A young boy standing closer to the camera than a rifle at a historical reenactment event.", "target_property": {"obj_1": "young boy", "relation": "closer to the camera than", "obj_2": "rifle"}, "evaluation_question": "Is the young boy farther from the camera than the rifle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy standing farther from the camera than a rifle at a historical reenactment event. FE)OC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b8a96b3db4642ed8cebd7e7a68614d9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0111aec8aab345158b4b2619cfa87e24", "source": "vatex", "video_id": "v6MBrnO1qyg_000010_000020", "video_description": "A person is kayaking on a river with large rocky banks and formations, navigating through a rocky coastline.", "task": "ActionRecognition", "clean_prompt": "A person kayaking on a river with large rocky banks.", "clean_property": {"obj": "person", "action": "canoeing or kayaking", "target": null}, "target_prompt": "A person swimming in a river with large rocky banks.", "target_property": {"obj": "person", "action": "swimming", "target": null}, "evaluation_question": "Is the person **kayaking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person kayaking on a river with large rocky banks. MT)FX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7eb88af25834a32ba90d234ffe75f0f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a1c6e8a00ceb4fa9815339d4fc8a482b", "source": "vatex", "video_id": "f34w1uhn9iY_000000_000010", "video_description": "Two women are sitting together, laughing and interacting with a phone. One woman is holding the phone, which is plugged in and charging.", "task": "ActionRecognition", "clean_prompt": "A woman laughing while sitting with a friend and interacting with a phone.", "clean_property": {"obj": "woman", "action": "laughing", "target": null}, "target_prompt": "A woman crying while sitting alone in a room.", "target_property": {"obj": "woman", "action": "crying", "target": null}, "evaluation_question": "Is the woman **laughing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman laughing while sitting with a friend and interacting with a phone. FE@X|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/89ee36d1c54346fa95e83c4164a40faf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "824d7657c0a54ec1a166a1153ff7e56f", "source": "vatex", "video_id": "hO5wLFjzrxQ_000061_000071", "video_description": "A woman is washing a large black dog in a bath, lathering shampoo into its fur while explaining the process.", "task": "Counting", "clean_prompt": "A woman is washing a large black dog in a bath, lathering shampoo into its fur while explaining the process, with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman is washing a large black dog in a bath, lathering shampoo into its fur while explaining the process, with three people watching.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching the woman wash the dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is washing a large black dog in a bath, lathering shampoo into its fur while explaining the process, with seven people watching. T.\u00b7TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/45612aafb4f04c0da89814f2fea17fc9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "557ce73818564a0bb51f83d353baf2aa", "source": "vatex", "video_id": "0RwUeRz82JU_000037_000047", "video_description": "A little boy is playing with pillows on a bed, throwing and stacking them, while also jumping and making noises.", "task": "Counting", "clean_prompt": "A little boy is playing with six pillows on a bed, throwing and stacking them, while also jumping and making noises.", "clean_property": {"obj": "pillow", "count": "six"}, "target_prompt": "A little boy is playing with two pillows on a bed, throwing and stacking them, while also jumping and making noises.", "target_property": {"obj": "pillow", "count": "two"}, "evaluation_question": "Are there exactly **six** pillows on the bed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A little boy is playing with six pillows on a bed, throwing and stacking them, while also jumping and making noises. )?K0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/37dcefc8d1c2482f8ef0271980daac78.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae248faf124e43458aab64a8077ecb4f", "source": "vatex", "video_id": "fIhA4yQjoDM_000074_000084", "video_description": "A boy in an orange shirt is making a sandwich at a kitchen table, spreading mayonnaise and mustard on bread while speaking in a foreign language.", "task": "ObjectRecognition", "clean_prompt": "A boy in an orange shirt is making a sandwich at a kitchen table, spreading mayonnaise and mustard on bread.", "clean_property": {"obj": "bread"}, "target_prompt": "A boy in an orange shirt is decorating a cake at a kitchen table, spreading frosting and adding sprinkles.", "target_property": {"obj": "cake"}, "evaluation_question": "Is the boy making a **sandwich**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy in an orange shirt is making a sandwich at a kitchen table, spreading mayonnaise and mustard on bread. @HJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/262ce2fcb6054c0184d24f665fca1533.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90d2799e31dc42199fdb8a0a83f8bf66", "source": "vatex", "video_id": "t3AQIPQsxy8_000023_000033", "video_description": "A girl is rapidly talking about and eating potato chips from a bag while showing it on a webcam.", "task": "Counting", "clean_prompt": "Four people are sitting around a table, enthusiastically discussing and sharing a bag of potato chips while one of them shows it on a webcam.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is sitting at a table, talking rapidly and eating potato chips from a bag while showing it on a webcam.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people sitting around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are sitting around a table, enthusiastically discussing and sharing a bag of potato chips while one of them shows it on a webcam. %P&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e13d8870c1194ca986a767974ba64993.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c2306a2904a24398b286ea2bd5b6add2", "source": "vatex", "video_id": "CBx-7WJRHgo_000000_000010", "video_description": "A person attempts to ride a motocross bike across a rapidly moving stream but falls into the water.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a motocross bike.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "motocross bike"}, "target_prompt": "A person standing to the left of a motocross bike.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "motocross bike"}, "evaluation_question": "Is the person to the **right** of a motocross bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a motocross bike. R%:);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33495c0bd3654f3d831ada87f38bb752.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bd2a5bf83d13453c9511338d462f73a2", "source": "vatex", "video_id": "XAoy-C2eroo_000115_000125", "video_description": "A baby boy in a diaper is interacting with a cell phone, placing it on a table, and making sounds into it. He walks around and sits on a step stool in a doctor's office.", "task": "SpatialUnderstanding", "clean_prompt": "A phone located to the right of a step stool in a doctor's office.", "clean_property": {"obj_1": "phone", "relation": "right of", "obj_2": "step stool"}, "target_prompt": "A tablet located to the left of a chair in a doctor's office.", "target_property": {"obj_1": "tablet", "relation": "left of", "obj_2": "chair"}, "evaluation_question": "Is the phone to the **right** of a step stool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A phone located to the right of a step stool in a doctor's office. TS)CJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef8d9e5d304f444fbb5207aad5d5ed85.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd7a2b27ea6749a59f15f957267607dc", "source": "vatex", "video_id": "sNBYqV4_dr0_000038_000048", "video_description": "A man is in his bathroom trimming and shaving his beard using an electric razor while looking into a mirror.", "task": "ActionRecognition", "clean_prompt": "A person trimming and shaving his beard in a bathroom.", "clean_property": {"obj": "person", "action": "trimming or shaving beard", "target": null}, "target_prompt": "A person washing his face in a bathroom.", "target_property": {"obj": "person", "action": "washing face", "target": null}, "evaluation_question": "Is the person **trimming or shaving his beard**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person trimming and shaving his beard in a bathroom. 1*4|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d9579f826c44309860f6bb4a3031c1c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "789071ba63d9424fa94f519021c6c768", "source": "vatex", "video_id": "NPnVbn5Xn4U_000114_000124", "video_description": "Two young girls are playing with dominoes at a kitchen table, stacking and moving them around.", "task": "AttributeRecognition", "clean_prompt": "Two young girls are playing with white dominoes at a kitchen table, stacking and moving them around.", "clean_property": {"obj": "domino", "attribute": "white"}, "target_prompt": "Two young girls are playing with black dominoes at a kitchen table, stacking and moving them around.", "target_property": {"obj": "domino", "attribute": "black"}, "evaluation_question": "Are the dominoes being played with **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young girls are playing with white dominoes at a kitchen table, stacking and moving them around. /!0DE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1061b7e58074321b543aeabf8f206f8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5945fa1750104bb1a701f5794a84637b", "source": "vatex", "video_id": "1V_Njbc_dos_000256_000266", "video_description": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process.", "task": "Counting", "clean_prompt": "Four people watching a young boy drawing a picture of a woman's face with a pencil on a white piece of paper.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person watching a young boy drawing a picture of a woman's face with a pencil on a white piece of paper.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people watching a young boy drawing a picture of a woman's face with a pencil on a white piece of paper. HZ-ED", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2af4b2dba5514766856fe06e639b373d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d72785d3b8244a5f8dc4a95a0ca06638", "source": "vatex", "video_id": "QgAzd_SK9-0_000001_000011", "video_description": "A young boy is sitting on a couch in his house, smiling and laughing while shaking his head energetically from side to side.", "task": "Counting", "clean_prompt": "A child is sitting on a couch in his house, smiling and laughing while shaking his head energetically from side to side.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "A child is sitting alone on a couch in a house, smiling and laughing while shaking his head energetically from side to side.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is sitting on a couch in his house, smiling and laughing while shaking his head energetically from side to side. ))/T%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/603e8ecf53e54ecb87fb0f443816aeaa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fe701607ae47415585a51cc950b39306", "source": "vatex", "video_id": "9QhCD0JUpls_000049_000059", "video_description": "A man is seated in a diner, demonstrating and explaining how to twist and turn a balloon into various shapes, including animals.", "task": "ObjectRecognition", "clean_prompt": "A man seated in a diner demonstrating how to twist and turn a balloon into various shapes.", "clean_property": {"obj": "balloon"}, "target_prompt": "A man seated in a diner demonstrating how to play with a toy.", "target_property": {"obj": "toy"}, "evaluation_question": "Is the object being twisted and turned in the video a **balloon**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man seated in a diner demonstrating how to twist and turn a balloon into various shapes. ))?D)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/45242efc01ba4162bf3b2eeffd65c3a2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "987f359f8215483dbba1e10dd4cf9b7a", "source": "vatex", "video_id": "CB3nEnx81mE_000061_000071", "video_description": "A man in a room is playing music on an organ, following sheet music.", "task": "ObjectRecognition", "clean_prompt": "A man playing music on an organ while following sheet music in a cozy room.", "clean_property": {"obj": "sheet music"}, "target_prompt": "A man playing music on a guitar in a cozy room.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the man playing music on **sheet music**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing music on an organ while following sheet music in a cozy room. 7G%ZU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/874cef938695426fa60607303bfc8ef6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab4c9fbab3fa4f58b80ac460f6e72875", "source": "vatex", "video_id": "HAVLxBVitWU_000000_000010", "video_description": "A boy is in a yard demonstrating soccer skills by juggling a soccer ball with his feet and knees, and occasionally kicking it into a goal post.", "task": "ActionRecognition", "clean_prompt": "A boy kicking a soccer ball in a yard.", "clean_property": {"obj": "boy", "action": "kicking soccer ball", "target": "goal post"}, "target_prompt": "A boy throwing a soccer ball into a basket in a yard.", "target_property": {"obj": "boy", "action": "throwing soccer ball", "target": "basket"}, "evaluation_question": "Is the boy **kicking** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy kicking a soccer ball in a yard. /W%|O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aaaa71d2cece4724969bcea301c3d388.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bd223c21e31a49a7b90ab04bcc29ddb1", "source": "vatex", "video_id": "_aH_akKsDyk_000000_000010", "video_description": "A young boy in a blue shirt is sitting on a park bench, snapping his fingers and smiling while occasionally looking at the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A boy farther from the camera than a park bench.", "clean_property": {"obj_1": "boy", "relation": "farther from the camera than", "obj_2": "bench"}, "target_prompt": "A boy closer to the camera than a park bench.", "target_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "bench"}, "evaluation_question": "Is the boy **farther from the camera than** the bench?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy farther from the camera than a park bench. %7BSG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d173f28a2031444c894d2026aeacf104.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "94f222d370714806a3c51cefa0c51fa4", "source": "vatex", "video_id": "L47aWT2v7PQ_000000_000010", "video_description": "In a large box store, a man kneels down in the middle of an aisle to tie his shoe and then performs a moonwalk dance down the aisle.", "task": "Counting", "clean_prompt": "Four people in a large box store, one man kneeling down in the middle of an aisle to tie his shoe and then performing a moonwalk dance down the aisle.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a large box store, kneeling down in the middle of an aisle to tie his shoe and then performing a moonwalk dance down the aisle.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the box store?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a large box store, one man kneeling down in the middle of an aisle to tie his shoe and then performing a moonwalk dance down the aisle. AN\u00b7'-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/292ad6d71e874f838bd44bcdf026af17.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b7c36bbf798e44ed81070add8b63b502", "source": "vatex", "video_id": "xBcHMVUU1E4_000013_000023", "video_description": "A man is assisting a woman in performing a handstand. He supports her legs for balance, lets go briefly, and then she falls over, gets up, and they high-five.", "task": "Counting", "clean_prompt": "Three women practicing a handstand with the help of a man.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "One woman practicing a handstand with the help of a man.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women practicing a handstand?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women practicing a handstand with the help of a man. E-NFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/47dea190903d438eab793381091b0ba4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1098df9081c04641927c978d0613d974", "source": "vatex", "video_id": "zH2qJbxLkzg_000022_000032", "video_description": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event. Onlookers applaud after the board is broken.", "task": "ObjectRecognition", "clean_prompt": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event.", "clean_property": {"obj": "instructor"}, "target_prompt": "A young boy demonstrates his martial arts skills while a spectator watches at a martial arts event.", "target_property": {"obj": "spectator"}, "evaluation_question": "Is the person holding the board in the video an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy demonstrates his martial arts skills by breaking a board held by a karate instructor at a martial arts event. 2BC2$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a18232bd87741e381274dbf5122d2dd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c0892f92b1cb4938a8ffbed33a7a373d", "source": "vatex", "video_id": "HHF4CTAc3d4_000000_000010", "video_description": "A woman demonstrates how to tie a calf's legs using a rope, after running towards it and turning it on its side. A group of people watch as she performs the task quickly, wearing blue clothing.", "task": "ActionRecognition", "clean_prompt": "A woman tackling a calf on its side.", "clean_property": {"obj": "woman", "action": "tackling", "target": "calf"}, "target_prompt": "A woman wrangling a calf on its side.", "target_property": {"obj": "woman", "action": "wrangling", "target": "calf"}, "evaluation_question": "Is the woman **tackling** the calf?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman tackling a calf on its side. >TD'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/04ca1f43fedd443e9c196307ceadb269.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9eb9d554a045425b8cc01cd26e962840", "source": "vatex", "video_id": "b-qLVLEjMcA_000011_000021", "video_description": "A group of young people, dressed in heavy winter clothing, are building a snowman in a snowy forest or park setting.", "task": "ActionRecognition", "clean_prompt": "A person making a snowman in a snowy forest.", "clean_property": {"obj": "person", "action": "making snowman", "target": null}, "target_prompt": "A person sledding in a snowy forest.", "target_property": {"obj": "person", "action": "sledding", "target": null}, "evaluation_question": "Is the person **making a snowman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making a snowman in a snowy forest. SL.89", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5630b67489d8412f91e2f365cb8885ed.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d3c64ac7fad4b6fa0b706587e94f144", "source": "vatex", "video_id": "EDt6Xies1Yo_000000_000010", "video_description": "A split screen shows a man and a baby interacting. The man is shaking his head and the baby mimics him. They are video chatting and laughing.", "task": "Counting", "clean_prompt": "A split screen shows a man and four babies interacting. The man is shaking his head and the babies are mimicking him. They are video chatting and laughing.", "clean_property": {"obj": "baby", "count": "four"}, "target_prompt": "A split screen shows a man and one baby interacting. The man is shaking his head and the baby is mimicking him. They are video chatting and laughing.", "target_property": {"obj": "baby", "count": "one"}, "evaluation_question": "Are there exactly **four** babies interacting with the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A split screen shows a man and four babies interacting. The man is shaking his head and the babies are mimicking him. They are video chatting and laughing. FE7BJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7717b674bed6416fa727d3356507dfb6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "09675acaadf848a7a9097b77e0daefd9", "source": "vatex", "video_id": "PBpxD7WP-Rg_000098_000108", "video_description": "A young boy is demonstrating and explaining how to make a paper airplane on a pool table.", "task": "Counting", "clean_prompt": "A young boy is demonstrating how to make seven paper airplanes on a pool table.", "clean_property": {"obj": "paper", "count": "seven"}, "target_prompt": "A young boy is demonstrating how to make four paper airplanes on a pool table.", "target_property": {"obj": "paper", "count": "four"}, "evaluation_question": "Are there exactly **seven** paper airplanes being demonstrated?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is demonstrating how to make seven paper airplanes on a pool table. HL2IT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a42ce7bb77d4069911fc221852319b9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d60eb7f3ec3c462692d28fa6c8d8e738", "source": "vatex", "video_id": "mOvPV97WseU_000026_000036", "video_description": "A person is climbing an outdoor artificial rock wall at a rock climbing amusement area.", "task": "ActionRecognition", "clean_prompt": "A person rock climbing on an outdoor artificial rock wall.", "clean_property": {"obj": "person", "action": "rock climbing", "target": null}, "target_prompt": "A person bungee jumping from a high platform.", "target_property": {"obj": "person", "action": "bungee jumping", "target": null}, "evaluation_question": "Is the person **rock climbing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person rock climbing on an outdoor artificial rock wall. BGZU.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/82b69d386a824d92acdd2a286811528f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8eb7ac32af584cb185c4b9833f472007", "source": "vatex", "video_id": "vLVriglUlpc_000193_000203", "video_description": "Two young boys are sitting on the floor in a room, playing with fidget spinner toys and superhero action figures, discussing their favorite toys.", "task": "Counting", "clean_prompt": "Four action figures are displayed on a table while two young boys play with fidget spinners on the floor.", "clean_property": {"obj": "action figure", "count": "four"}, "target_prompt": "One action figure is displayed on a table while two young boys play with fidget spinners on the floor.", "target_property": {"obj": "action figure", "count": "one"}, "evaluation_question": "Are there exactly **four** action figures displayed on the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four action figures are displayed on a table while two young boys play with fidget spinners on the floor. A)XBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fce2b54ac7e3422983da7b3fa16dbeb7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0080687a01d84670b95cd9599fdbb364", "source": "vatex", "video_id": "CnYoY8iq8vY_000003_000013", "video_description": "A young girl with braces is laughing and smiling for the camera.", "task": "ObjectRecognition", "clean_prompt": "A young girl with braces is laughing and smiling for the camera.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a ball of yarn.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl with braces is laughing and smiling for the camera. ND/?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/74845af9662f4384a5ef55548b659ac7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3ab46c56cd92493b849caf85423a860c", "source": "vatex", "video_id": "tC9dNm7AP80_000307_000317", "video_description": "A woman is shaving the head of a man sitting in a chair using electric clippers, while other people are present in a noisy room or hair salon.", "task": "Counting", "clean_prompt": "A woman is shaving the head of a man sitting in a chair using three clippers, while other people are present in a noisy hair salon.", "clean_property": {"obj": "clippers", "count": "three"}, "target_prompt": "A woman is shaving the head of a man sitting in a chair using one clipper, while other people are present in a noisy hair salon.", "target_property": {"obj": "clippers", "count": "one"}, "evaluation_question": "Are there exactly **three** clippers being used in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is shaving the head of a man sitting in a chair using three clippers, while other people are present in a noisy hair salon. )|8FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c932adf036d941a29d396a22f539bfc4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2fcd52d1e494119a3ed183ae478fe67", "source": "vatex", "video_id": "Q0rLouWb_S0_000067_000077", "video_description": "A man is sitting in a recliner, holding a parrot on his chest, and filing the parrot's claws while talking to it.", "task": "SpatialUnderstanding", "clean_prompt": "A man closer to the camera than a recliner.", "clean_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "recliner"}, "target_prompt": "A man further from the camera than a recliner.", "target_property": {"obj_1": "man", "relation": "further from the camera than", "obj_2": "recliner"}, "evaluation_question": "Is the man **closer to the camera than** the recliner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man closer to the camera than a recliner. Y))'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98ac6e252f5c4e6b9845843ce929cea0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "52cb99a03c3547768c24f5ab38943f9e", "source": "vatex", "video_id": "3axTI3jSNAg_000014_000024", "video_description": "A person is demonstrating basket weaving techniques using sticks, reeds, and twill, while another person observes. The setting is a classroom environment with students.", "task": "SpatialUnderstanding", "clean_prompt": "Reeds closer to the camera than a person demonstrating basket weaving techniques in a classroom.", "clean_property": {"obj_1": "reeds", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "Reeds further from the camera than a person demonstrating basket weaving techniques in a classroom.", "target_property": {"obj_1": "reeds", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Are the reeds **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Reeds closer to the camera than a person demonstrating basket weaving techniques in a classroom. /!);%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cb0070688714c60a7acf2e30a2f50f3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a018c7ccffb94c8e9083438c47906bed", "source": "vatex", "video_id": "2C6MGHJ9b4k_000000_000010", "video_description": "A man is in a gym performing arm exercises with dumbbells, alternating arms while lifting in front of a mirror.", "task": "ObjectRecognition", "clean_prompt": "A man performing arm exercises with dumbbells in front of a mirror at the gym.", "clean_property": {"obj": "person"}, "target_prompt": "A woman performing leg exercises with a barbell in front of a mirror at the gym.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing arm exercises with dumbbells in front of a mirror at the gym. \u00b7L*VV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc2ef3c86fd74ff3bb4010b052de3034.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3a126cd68f204dfd98be22f34e66709e", "source": "vatex", "video_id": "_liD2pIdpXk_000160_000170", "video_description": "A woman is sitting on a chair on stage, speaking into a microphone while another woman shaves her head in front of an audience.", "task": "Counting", "clean_prompt": "A woman is sitting on a chair on stage, speaking into two microphones while another woman shaves her head in front of an audience.", "clean_property": {"obj": "microphone", "count": "two"}, "target_prompt": "A woman is sitting on a chair on stage, speaking into one microphone while another woman shaves her head in front of an audience.", "target_property": {"obj": "microphone", "count": "one"}, "evaluation_question": "Are there exactly **two** microphones being used on stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is sitting on a chair on stage, speaking into two microphones while another woman shaves her head in front of an audience. RFEJJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ec87835291245b4bf9bd760b729f5d7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d624ed4e7b744abf9698c8f6f55ec3f6", "source": "vatex", "video_id": "ZOIDAYEzfjs_000000_000010", "video_description": "A person is spray painting various surfaces using a spray gun, including a black metal sheet, a section of a wall, and a blackboard, with white paint. They are also using a sand blaster to remove stains from a wall and paint from a piece of sheet metal.", "task": "SpatialUnderstanding", "clean_prompt": "A metal grate farther from the camera than a sand blaster.", "clean_property": {"obj_1": "metal grate", "relation": "farther from the camera than", "obj_2": "sand blaster"}, "target_prompt": "A metal grate closer to the camera than a sand blaster.", "target_property": {"obj_1": "metal grate", "relation": "closer to the camera than", "obj_2": "sand blaster"}, "evaluation_question": "Is the metal grate **farther from the camera than** the sand blaster?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A metal grate farther from the camera than a sand blaster. ))'!-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0881c17219a24c07ab231c3b0d3cd771.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03d2557b3a8f446d9e00211c50be3ecc", "source": "vatex", "video_id": "9IyZ8sJV7XU_000021_000031", "video_description": "In a sewing factory, multiple people, including two men, are using sewing machines to sew various types of fabric and garments. A narrator explains the sewing processes and specializations.", "task": "ObjectRecognition", "clean_prompt": "A person operating a sewing machine in a factory.", "clean_property": {"obj": "person"}, "target_prompt": "A robot operating a sewing machine in a factory.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the operator in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person operating a sewing machine in a factory. ))'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad21a0cc7d61456a9f74cc027213bd6a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5ed6e0b8ce42426faa7f93593e7bb626", "source": "vatex", "video_id": "GyGsq-LOOhU_000538_000548", "video_description": "A woman is lying on a mat receiving a Thai massage and assisted stretching from a therapist, with music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A woman lying on a mat receiving a Thai massage from a therapist, with soothing music playing in the background.", "clean_property": {"obj": "therapist"}, "target_prompt": "A woman lying on a mat receiving yoga instruction from a yoga instructor, with soothing music playing in the background.", "target_property": {"obj": "yoga instructor"}, "evaluation_question": "Is the person providing assistance in the video a **therapist**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman lying on a mat receiving a Thai massage from a therapist, with soothing music playing in the background. LYF)F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bea41f8562594590bdcd75bae1707e64.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c7f02b366ef447aaac01c4c87738562", "source": "vatex", "video_id": "QKPxRS-KQOo_000110_000120", "video_description": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while motorcycles rev their engines in the background.", "task": "ObjectRecognition", "clean_prompt": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while a car is parked in the background.", "clean_property": {"obj": "car"}, "target_prompt": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while a bicycle is parked in the background.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is there a **car** parked in the background of the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man proposes to a woman with a bouquet of flowers at a motorcycle event, while a car is parked in the background. &FEJE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c13c7bc91e242618cbe3bb25c5b062d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f6ff4d217524af088dc947560766da9", "source": "vatex", "video_id": "NAbX4DNVT3A_000007_000017", "video_description": "A person is outdoors on a sunny day, demonstrating how to open shellfish using a large, sharp knife.", "task": "AttributeRecognition", "clean_prompt": "A person outdoors on a sunny day demonstrating how to open shellfish, specifically clams or oysters, using a large, sharp knife.", "clean_property": {"obj": "shellfish", "attribute": "clam or oyster"}, "target_prompt": "A person outdoors on a sunny day demonstrating how to open shellfish, specifically scallops, using a large, sharp knife.", "target_property": {"obj": "shellfish", "attribute": "scallop"}, "evaluation_question": "Is the person demonstrating how to open **clams or oysters**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person outdoors on a sunny day demonstrating how to open shellfish, specifically clams or oysters, using a large, sharp knife. LF1@U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c09bba98356d43c1a77d82eb0efb57f4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "10bf984b049b48489af4531fb9ad54f3", "source": "vatex", "video_id": "8FC7KLzeFFs_000012_000022", "video_description": "A young woman is trying to balance on her knees on a large exercise ball. She falls off and laughs.", "task": "AttributeRecognition", "clean_prompt": "A young woman is trying to balance on her knees on a large exercise ball that is round. She falls off and laughs.", "clean_property": {"obj": "exercise ball", "attribute": "round"}, "target_prompt": "A young woman is trying to balance on her knees on a large exercise ball that is oval. She falls off and laughs.", "target_property": {"obj": "exercise ball", "attribute": "oval"}, "evaluation_question": "Is the exercise ball **round**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman is trying to balance on her knees on a large exercise ball that is round. She falls off and laughs. =XFCF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de814ed1d1384fd3b84ceea5324cc451.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5d226991ea304f62983474673e32d723", "source": "vatex", "video_id": "B860uZi5ZGo_000006_000016", "video_description": "A woman is giving a young boy a shower using a moveable shower head while he cries and screams.", "task": "ActionRecognition", "clean_prompt": "A boy is crying while a woman gives him a shower using a moveable shower head.", "clean_property": {"obj": "boy", "action": "crying", "target": null}, "target_prompt": "A boy is laughing while a woman gives him a shower using a moveable shower head.", "target_property": {"obj": "boy", "action": "laughing", "target": null}, "evaluation_question": "Is the boy **crying**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy is crying while a woman gives him a shower using a moveable shower head. @JSSU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9fd3bade7d684031b8803d951c3e5973.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cb835627c6fe4e3ab4787c236f4ea490", "source": "vatex", "video_id": "6IV0gaQy1UE_000000_000010", "video_description": "An older man is talking to a small boy on a sidewalk when a woman runs up and throws water balloons at the man.", "task": "ActionRecognition", "clean_prompt": "A woman throwing a water balloon at an older man on a sidewalk.", "clean_property": {"obj": "woman", "action": "throwing water balloon", "target": "older man"}, "target_prompt": "A woman throwing a snowball at a younger boy on a sidewalk.", "target_property": {"obj": "woman", "action": "throwing a snowball", "target": "younger boy"}, "evaluation_question": "Is the woman **throwing a water balloon**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman throwing a water balloon at an older man on a sidewalk. OT.6I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6254723cb8f04f208b9cbfcb0a3805ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4260e9ca5d2543458ee1d76c61540064", "source": "vatex", "video_id": "Yd2feQoXzTQ_000125_000135", "video_description": "A bride and groom are sitting together. The bride, dressed in a wedding dress, is helping the groom, who is in a suit, remove his shoe while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A bride is helping the groom remove his shoe while music plays in the background.", "clean_property": {"obj": "groom"}, "target_prompt": "A bride is dancing alone while music plays in the background.", "target_property": {"obj": "bride"}, "evaluation_question": "Is the person helping the groom in the video a **groom**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bride is helping the groom remove his shoe while music plays in the background. O9W%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/90f50a1b9caa47aaa070fcb26ed98c85.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "489955e80df34d3e9bb6123a4ecd68d1", "source": "vatex", "video_id": "kxbUUbwO-6o_000382_000392", "video_description": "A man is demonstrating how to work on a car engine, specifically focusing on removing a stuck cap from the engine compartment while explaining the process.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating how to work on a car engine, focusing on removing a seized cap from the engine compartment.", "clean_property": {"obj": "cap", "attribute": "seized"}, "target_prompt": "A man demonstrating how to work on a car engine, focusing on removing a loose cap from the engine compartment.", "target_property": {"obj": "cap", "attribute": "loose"}, "evaluation_question": "Is the cap **seized**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to work on a car engine, focusing on removing a seized cap from the engine compartment. )G%D|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/12c9bfffb647451e8033d83d850ea5c2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b356a14e6ec84211916f6092776d7feb", "source": "vatex", "video_id": "Y-EUjZBIMyc_000018_000028", "video_description": "A woman attempts a back flip off a diving board at a public pool, but hits her head on the board before falling into the water.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a pool.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "pool"}, "target_prompt": "A woman closer to the camera than a pool.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "pool"}, "evaluation_question": "Is the woman **farther from the camera than** the pool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a pool. FE7H@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d0c012bac85f4e5b9ff538a6460907bb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e7752a1079c74bceb93165d5c5667b15", "source": "vatex", "video_id": "W42ldlT9UCQ_000104_000114", "video_description": "A young child is playing a trumpet in a room, demonstrating how to play a note and occasionally talking to the camera.", "task": "ActionRecognition", "clean_prompt": "A child playing a trumpet in a room.", "clean_property": {"obj": "child", "action": "playing trumpet", "target": null}, "target_prompt": "A child playing piano in a room.", "target_property": {"obj": "child", "action": "playing piano", "target": null}, "evaluation_question": "Is the child **playing a trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child playing a trumpet in a room. )%BSF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76b919de214641a18703380f386e3919.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "153b8523e7974810b16329b5779fe1d1", "source": "vatex", "video_id": "CJUDL32Q7do_000018_000028", "video_description": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away.", "task": "ObjectRecognition", "clean_prompt": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away.", "clean_property": {"obj": "baby"}, "target_prompt": "A puppy is crawling on a carpet floor towards a toy, while a woman and a man interact with the puppy by moving the toy further away.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the main subject in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is crawling on a carpet floor towards a toy, while a woman and a man interact with the baby by moving the toy further away. LYP#Y", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/83ed662d401241f8a89a3a41c5e9c9d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aa144250f2514e4784cef26c1a0a7153", "source": "vatex", "video_id": "RDuX0bELvqY_000078_000088", "video_description": "Two young girls are in a carpeted room, one playing an acoustic guitar and the other singing into a microphone.", "task": "ActionRecognition", "clean_prompt": "A girl singing into a microphone in a carpeted room.", "clean_property": {"obj": "girl_2", "action": "singing", "target": null}, "target_prompt": "A girl dancing in a carpeted room.", "target_property": {"obj": "girl_2", "action": "dancing", "target": null}, "evaluation_question": "Is the girl **singing** into a microphone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl singing into a microphone in a carpeted room. OSTD$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e73f67d507b0476e95b54d9a56419e4b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33e7e42a47654f3f88207e2a26fc14cb", "source": "vatex", "video_id": "d82QwyOYhMs_000167_000177", "video_description": "A man is demonstrating how to make balloon animals using various colored balloons at a kid's party.", "task": "Counting", "clean_prompt": "Two balloon artists demonstrating how to make balloon animals at a kid's party.", "clean_property": {"obj": "balloon artist", "count": "two"}, "target_prompt": "A balloon artist demonstrating how to make balloon animals at a kid's party.", "target_property": {"obj": "balloon artist", "count": "one"}, "evaluation_question": "Are there exactly **two** balloon artists at the party?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two balloon artists demonstrating how to make balloon animals at a kid's party. #LFEA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/741c68a98534407fb8cb8579f0ede6dd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ec774cd3a4843e8bf3ec8a0467e48b5", "source": "vatex", "video_id": "fde0fnYJszI_000679_000689", "video_description": "A person is cooking scrambled eggs in a nonstick pan on a gas stove, using a spatula to stir and scoop the eggs.", "task": "AttributeRecognition", "clean_prompt": "A person cooking scrambled eggs in a nonstick pan on a gas stove, using a spatula to stir and scoop the eggs.", "clean_property": {"obj": "egg", "attribute": "scrambled"}, "target_prompt": "A person cooking boiled eggs in a pot on a gas stove, using a spoon to scoop the eggs out.", "target_property": {"obj": "egg", "attribute": "boiled"}, "evaluation_question": "Is the person cooking **scrambled** eggs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cooking scrambled eggs in a nonstick pan on a gas stove, using a spatula to stir and scoop the eggs. (XBBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a9d928cfec1945029ff5e01b798ab378.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "336660afcb2e47d3bc3155188f6ea4b6", "source": "vatex", "video_id": "l3axslccUQk_000102_000112", "video_description": "A person is drawing a face on a canvas, labeling each part, while music plays in the background.", "task": "AttributeRecognition", "clean_prompt": "A person is drawing a face on a canvas using a marker, labeling each part, while music plays in the background.", "clean_property": {"obj": "writing utensil", "attribute": "marker"}, "target_prompt": "A person is drawing a face on a canvas using a crayon, labeling each part, while music plays in the background.", "target_property": {"obj": "writing utensil", "attribute": "crayon"}, "evaluation_question": "Is the person using a **marker** to draw?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is drawing a face on a canvas using a marker, labeling each part, while music plays in the background. FS6;E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/58ef2211d2f94b8988e6e1ef44974fa5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "44d6813bb60e483884645a0bfbac1f3f", "source": "vatex", "video_id": "UFirX6T9h1Q_000013_000023", "video_description": "A man in a kitchen demonstrates how to sharpen a knife using a sharpening tool and a textured metal rod.", "task": "ActionRecognition", "clean_prompt": "A person sharpening knives in a kitchen.", "clean_property": {"obj": "person", "action": "sharpening knives", "target": null}, "target_prompt": "A person throwing knives in a kitchen.", "target_property": {"obj": "person", "action": "throwing knives", "target": null}, "evaluation_question": "Is the person **sharpening** knives?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sharpening knives in a kitchen. )!G*E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49838ea1a6e046899cdc34beec8f845d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "601b299bf190465a8169f53874d13fe7", "source": "vatex", "video_id": "gfxU41mMEDE_000020_000030", "video_description": "A little girl in a yellow dress is picking up apples from the ground in her backyard while a woman talks to her.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of a girl in a yellow dress who is picking up apples in her backyard.", "clean_property": {"obj_1": "woman", "relation": "right of", "obj_2": "girl"}, "target_prompt": "A woman standing to the left of a girl in a yellow dress who is picking up apples in her backyard.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "girl"}, "evaluation_question": "Is the woman to the **right** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the right of a girl in a yellow dress who is picking up apples in her backyard. FE2QG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/53a64422f73040dc9b95079939983f63.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5247319168a8472abdfc0353a7d2b2de", "source": "vatex", "video_id": "pFYbvFzOQVc_000028_000038", "video_description": "A young girl is practicing handstands and headstands in her living room, using the wall for support. She occasionally falls, crawls, and talks to the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A girl practicing handstands in her living room, farther from the camera than the wall.", "clean_property": {"obj_1": "girl", "relation": "farther from the camera than", "obj_2": "wall"}, "target_prompt": "A girl practicing handstands in her living room, closer to the camera than the wall.", "target_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "wall"}, "evaluation_question": "Is the girl farther from the camera than the wall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl practicing handstands in her living room, farther from the camera than the wall. '.:W%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c35d229574ae47bb85ae37fb26d29ac8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e39127474df840b1bf8cfd2c78ac9706", "source": "vatex", "video_id": "DasRdyFA0bU_000000_000010", "video_description": "A woman demonstrates how to clean windows using various tools and techniques, including a spray, cloth, and squeegee, to achieve streak-free results.", "task": "ActionRecognition", "clean_prompt": "A person cleaning windows using a spray, cloth, and squeegee.", "clean_property": {"obj": "person", "action": "cleaning windows", "target": null}, "target_prompt": "A person breaking windows using a hammer.", "target_property": {"obj": "person", "action": "breaking windows", "target": null}, "evaluation_question": "Is the person **cleaning** windows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning windows using a spray, cloth, and squeegee. )*!0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9119a5570df44e9a93c4ffbf671223da.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e578e393c06a4de1b9196ad8ebbcc3eb", "source": "vatex", "video_id": "IRRTibpBYdM_000017_000027", "video_description": "A group of children are playing soccer on a grassy field in an outdoor park. Some children are running, kicking, and holding the ball.", "task": "ObjectRecognition", "clean_prompt": "A group of children are playing soccer on a grassy field.", "clean_property": {"obj": "child"}, "target_prompt": "A dog playing with a ball on a grassy field.", "target_property": {"obj": "dog"}, "evaluation_question": "Are the characters in the video **children**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children are playing soccer on a grassy field. )FE4I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/970f015b8c184a46a1e09749d4bae3d3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "422a6d5b365a47dd8f2a6b94d826ad11", "source": "vatex", "video_id": "7MZhQApcQlw_000001_000011", "video_description": "Two young men are indoors throwing axes at wooden targets, aiming for bullseyes.", "task": "ActionRecognition", "clean_prompt": "A person throwing an axe at a wooden target indoors.", "clean_property": {"obj": "person", "action": "throwing axe", "target": "target"}, "target_prompt": "A person throwing a knife at a wooden target indoors.", "target_property": {"obj": "person", "action": "throwing knife", "target": "target"}, "evaluation_question": "Is the person **throwing an axe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person throwing an axe at a wooden target indoors. ))'!&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb77f6d023744e869dad1e5831d4e043.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4453f80340734c91bf83d28f38c4a02b", "source": "vatex", "video_id": "hmXQEqD2oWQ_000000_000010", "video_description": "A man is withdrawing money from an ATM machine, which dispenses $20 bills.", "task": "AttributeRecognition", "clean_prompt": "A man withdrawing money from an ATM machine, which dispenses $20 bills.", "clean_property": {"obj": "money", "attribute": "$20 bills"}, "target_prompt": "A man withdrawing money from an ATM machine, which dispenses $100 bills.", "target_property": {"obj": "money", "attribute": "$100 bills"}, "evaluation_question": "Is the ATM dispensing **$20** bills?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man withdrawing money from an ATM machine, which dispenses $20 bills. %''',", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c92c392cdb3143ceac8cd1cfd2953215.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bdc7d23d8da64805bd56fb4b570206d8", "source": "vatex", "video_id": "OfwAvNf7v7o_000000_000010", "video_description": "A person demonstrates how to slice a pineapple by first removing the crown in a tutorial or commercial setting.", "task": "ActionRecognition", "clean_prompt": "A person cutting a pineapple in a tutorial setting.", "clean_property": {"obj": "person", "action": "cutting pineapple", "target": null}, "target_prompt": "A person throwing a pineapple in a tutorial setting.", "target_property": {"obj": "person", "action": "throwing pineapple", "target": null}, "evaluation_question": "Is the person **cutting** a pineapple?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cutting a pineapple in a tutorial setting. RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a5919010a424212b2872b951a7eca1c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8b1f0500df264c1fbcb8b1229930a1d7", "source": "vatex", "video_id": "GKtkZZBG5O4_000086_000096", "video_description": "A group of people, including elderly individuals, are participating in an auction inside a building. A man in a cowboy hat is conducting the auction, speaking into a microphone and taking bids.", "task": "AttributeRecognition", "clean_prompt": "A group of elderly people participating in an auction inside a building.", "clean_property": {"obj": "people", "attribute": "elderly"}, "target_prompt": "A group of young adults participating in an auction inside a building.", "target_property": {"obj": "people", "attribute": "young adults"}, "evaluation_question": "Are the people participating in the auction **elderly**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of elderly people participating in an auction inside a building. SLJ?K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38b23148b9de44d3a1ec64f85bde3dd8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5e14258bf19451ba3a14d8c498eb4b2", "source": "vatex", "video_id": "GKDTGo89dR8_000002_000012", "video_description": "A woman is tying a young boy's shoelaces while the boy is sitting down. The woman appears to be using negative reinforcement techniques, including hitting the boy's leg, as the boy yells.", "task": "ActionRecognition", "clean_prompt": "A woman tying a young boy's shoelaces.", "clean_property": {"obj": "woman", "action": "tying shoe laces", "target": "boy"}, "target_prompt": "A woman tying a young girl's shoelaces.", "target_property": {"obj": "woman", "action": "tying shoelaces", "target": "girl"}, "evaluation_question": "Is the woman tying the shoelaces of a **boy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman tying a young boy's shoelaces. SL|RT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e30944766e18467380a8dd0663c88001.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1b4e40d76136464c8af202a5f7eca4b8", "source": "vatex", "video_id": "E-ffs43L-28_000000_000010", "video_description": "Multiple people are using ATM machines inside a bank, captured on security camera footage.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a security camera inside a bank.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "security camera"}, "target_prompt": "A person further from the camera than a security camera inside a bank.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "security camera"}, "evaluation_question": "Is the person **closer to the camera** than the security camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a security camera inside a bank. @@TD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e92624ebdce43fd9f4171d6aa8d2d5a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8882f6d2dc9946e5bf77ecba69cdfb58", "source": "vatex", "video_id": "fNa0EZiUib8_000053_000063", "video_description": "A man is on a ladder trying to reach something in a tree during the daytime. He descends the ladder, makes a comment about not being able to reach it, and adjusts his camera.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a ladder during the daytime.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "ladder"}, "target_prompt": "A woman standing to the right of a tree during the daytime.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "tree"}, "evaluation_question": "Is the man to the **left** of a ladder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a ladder during the daytime. FG70", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb871f858f4645caa41b87c3e77ff32d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a7f7ada4c86a41e0babae5e9cb3a53cf", "source": "vatex", "video_id": "e8Tu8fV3Dwc_000195_000205", "video_description": "A woman is performing yoga and stretching exercises on a purple yoga mat indoors, with music playing in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a purple yoga mat.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "yoga mat"}, "target_prompt": "A person closer to the camera than a purple yoga mat.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "yoga mat"}, "evaluation_question": "Is the person **farther from the camera than** the yoga mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a purple yoga mat. LY;3T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f1413843cd5466e82e1d6a29a4ce08c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0bc52fbba5f741689111dad37ea4d30b", "source": "vatex", "video_id": "HFxj1Q1fRDU_000073_000083", "video_description": "A woman is demonstrating how to make a bow using a bow maker and a wide piece of black ribbon on a table.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating how to make a bow using a bow maker and a wide piece of black ribbon on a table.", "clean_property": {"obj": "ribbon", "attribute": "black"}, "target_prompt": "A woman demonstrating how to make a bow using a bow maker and a wide piece of red ribbon on a table.", "target_property": {"obj": "ribbon", "attribute": "red"}, "evaluation_question": "Is the ribbon being used in the video **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to make a bow using a bow maker and a wide piece of black ribbon on a table. $UMO.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c439a9b577d4b34832a290c75c9e027.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2ad2971b710444618e668137dba34804", "source": "vatex", "video_id": "4sjALsnszUQ_000022_000032", "video_description": "A man is giving another man a massage on the street, starting with the face and moving to the head and back.", "task": "SpatialUnderstanding", "clean_prompt": "A person_2 is positioned to the right of person_1 while giving a massage on the street.", "clean_property": {"obj_1": "person_2", "relation": "right of", "obj_2": "person_1"}, "target_prompt": "A person_2 is positioned to the left of person_1 while giving a massage on the street.", "target_property": {"obj_1": "person_2", "relation": "left of", "obj_2": "person_1"}, "evaluation_question": "Is person_2 to the **right** of person_1?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person_2 is positioned to the right of person_1 while giving a massage on the street. ED%WH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aa3d1f0a58aa4278a7828f29e4181436.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3d48be12fcf4560aed4526a27b3cfc5", "source": "vatex", "video_id": "7N6ionlMMZw_000025_000035", "video_description": "A woman demonstrates how to sew a zigzag pattern and fix a garment using a sewing machine on a piece of fabric.", "task": "ActionRecognition", "clean_prompt": "A person sewing a zigzag pattern on a piece of fabric using a sewing machine.", "clean_property": {"obj": "person", "action": "sewing", "target": "fabric"}, "target_prompt": "A person cutting fabric with scissors.", "target_property": {"obj": "person", "action": "cutting fabric", "target": "fabric"}, "evaluation_question": "Is the person **sewing** fabric?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sewing a zigzag pattern on a piece of fabric using a sewing machine. FS3(#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7e60a43281994e4d83526a15ac28d9c1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a9e6f0ada9904a819e7770e6e0fa25ab", "source": "vatex", "video_id": "6kxxQjo5FK0_000023_000033", "video_description": "In a karate studio, a group of kids practice martial arts skills with their coach, including breaking wooden boards.", "task": "ObjectRecognition", "clean_prompt": "A group of kids practicing martial arts in a karate studio.", "clean_property": {"obj": "kid"}, "target_prompt": "An adult practicing martial arts in a karate studio.", "target_property": {"obj": "adult"}, "evaluation_question": "Are the practitioners in the video **kids**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of kids practicing martial arts in a karate studio. ED9SU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3856006665a44484a7e91a4d2eca06b2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "254f70ed7c2e4e388fd9bfa4a34700b6", "source": "vatex", "video_id": "CCSCjIP7hiA_000002_000012", "video_description": "A boy dressed as a mailman hands a girl some mail as she asks him where her mail is.", "task": "Counting", "clean_prompt": "A boy dressed as a mailman hands a girl seven pieces of mail as she asks him where her mail is.", "clean_property": {"obj": "mail", "count": "seven"}, "target_prompt": "A boy dressed as a mailman hands a girl three pieces of mail as she asks him where her mail is.", "target_property": {"obj": "mail", "count": "three"}, "evaluation_question": "Are there exactly **seven** pieces of mail being handed to the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy dressed as a mailman hands a girl seven pieces of mail as she asks him where her mail is. TY&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a87a96b71e394bc6b35a6a855a2164e1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "db6b66b12d3946cb99b672a4ec239ebb", "source": "vatex", "video_id": "1Ddy4W31UYQ_000019_000029", "video_description": "A man is trimming and shaving his beard and mustache using an electric razor with a guard, in front of a mirror.", "task": "ObjectRecognition", "clean_prompt": "A man trimming and shaving his beard and mustache using an electric razor with a guard, in front of a mirror.", "clean_property": {"obj": "electric razor"}, "target_prompt": "A man trimming and shaving his beard and mustache using a manual razor in front of a mirror.", "target_property": {"obj": "manual razor"}, "evaluation_question": "Is the man using an **electric razor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man trimming and shaving his beard and mustache using an electric razor with a guard, in front of a mirror. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c97deffd38148968b98e6b07e86a6fa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "db7f33ddd7ce4aa390cbd9584a17bc31", "source": "vatex", "video_id": "kgHoKUZWKCs_000026_000036", "video_description": "A female athlete is performing a long jump on a track and field event, landing in a sand pit.", "task": "Counting", "clean_prompt": "A female athlete is performing a long jump on a track with seven lanes, landing in a sand pit.", "clean_property": {"obj": "track", "count": "seven"}, "target_prompt": "A female athlete is performing a long jump on a track with three lanes, landing in a sand pit.", "target_property": {"obj": "track", "count": "three"}, "evaluation_question": "Are there exactly **seven** lanes on the track?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female athlete is performing a long jump on a track with seven lanes, landing in a sand pit. FE(E|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/656d53b9f5c24a34bf190c660f275110.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad86f18a879849458d0fb52fe426cdb9", "source": "vatex", "video_id": "OcaWxD1FVBg_000000_000010", "video_description": "A man is performing alternating toe-touch sit-ups on a floor mat in a gym.", "task": "ActionRecognition", "clean_prompt": "A person performing alternating toe-touch sit-ups on a floor mat in a gym.", "clean_property": {"obj": "person", "action": "situp", "target": null}, "target_prompt": "A person doing jumping jacks on a floor mat in a gym.", "target_property": {"obj": "person", "action": "jumping jacks", "target": null}, "evaluation_question": "Is the person **performing sit-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing alternating toe-touch sit-ups on a floor mat in a gym. UMQAM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/94f82acc112a475ca58adddd85fc24ba.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e29a4d9286724c899b90303012b89722", "source": "vatex", "video_id": "U-nJ0dFEc54_000000_000010", "video_description": "A man is in a gym demonstrating how to perform dumbbell front raises with proper form.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to perform dumbbell front raises with proper form in a gym.", "clean_property": {"obj": "dumbbell"}, "target_prompt": "A man demonstrating how to perform kettlebell front raises with proper form in a gym.", "target_property": {"obj": "kettlebell"}, "evaluation_question": "Is the object being used in the video a **dumbbell**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to perform dumbbell front raises with proper form in a gym. !L*DE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0698ccd052b6475393a9c9a71ca911e6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9845f6e6b8f54e82b95b91eedf9e7a9b", "source": "vatex", "video_id": "juIOpLYnW64_000019_000029", "video_description": "A girl is getting her eyebrow pierced by a man using a needle and plastic tube, while he explains the process.", "task": "SpatialUnderstanding", "clean_prompt": "A needle farther from the camera than a plastic tube.", "clean_property": {"obj_1": "needle", "relation": "farther from the camera than", "obj_2": "plastic tube"}, "target_prompt": "A needle closer to the camera than a plastic tube.", "target_property": {"obj_1": "needle", "relation": "closer to the camera than", "obj_2": "plastic tube"}, "evaluation_question": "Is the needle **farther from the camera than** the plastic tube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A needle farther from the camera than a plastic tube. %FE1#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b2751f3c28da4111ba5630f297b13a21.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd50ef6cafff4e5a8dd65e600c28df1d", "source": "vatex", "video_id": "rJk8fad5ZnU_000007_000017", "video_description": "A man is demonstrating and explaining how to use a pottery wheel to shape clay into pottery items like jars and bowls.", "task": "ActionRecognition", "clean_prompt": "A person making clay pottery on a pottery wheel.", "clean_property": {"obj": "person", "action": "clay pottery making", "target": null}, "target_prompt": "A person throwing clay in a pottery studio.", "target_property": {"obj": "person", "action": "throwing clay", "target": null}, "evaluation_question": "Is the person **making clay pottery**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making clay pottery on a pottery wheel. ILEG(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/72b39f614f134b1b976c5f3081184591.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2abd4613dea34dbd860d54360d76fe54", "source": "vatex", "video_id": "9lHeBYlJgXc_000000_000010", "video_description": "A young boy is outside in a backyard, throwing an axe at a wooden target hanging from a tree.", "task": "AttributeRecognition", "clean_prompt": "A young boy is outside in a backyard, throwing a hatchet at a wooden target hanging from a tree.", "clean_property": {"obj": "axe", "attribute": "hatchet"}, "target_prompt": "A young boy is outside in a backyard, throwing a sledgehammer at a wooden target hanging from a tree.", "target_property": {"obj": "axe", "attribute": "sledgehammer"}, "evaluation_question": "Is the boy throwing a **hatchet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is outside in a backyard, throwing a hatchet at a wooden target hanging from a tree. >?XTZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f989db7c328a45e7b2d55e0f802aff3b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8e6a471990c44273bca833e80f19840f", "source": "vatex", "video_id": "o-MhYRW1Stk_000002_000012", "video_description": "A group of blindfolded people are conducting a blind taste test, tasting food with a spoon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a plate of food during a blind taste test.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "food"}, "target_prompt": "A person standing to the right of a plate of food during a blind taste test.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "plate of food"}, "evaluation_question": "Is the person to the **left** of a plate of food?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a plate of food during a blind taste test. )!0DK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfeae7fd569046d8ab5ec83b9233cd1f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f70d57ce49fd424a94c42fd448f555f6", "source": "vatex", "video_id": "HznNrgamxvM_000109_000119", "video_description": "Two young women are in a living room with a carpet. One woman is vacuuming the carpet while the other watches.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a vacuum cleaner in a living room.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "vacuum cleaner"}, "target_prompt": "A woman closer to the camera than a vacuum cleaner in a living room.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "vacuum cleaner"}, "evaluation_question": "Is the woman **farther from the camera than** the vacuum cleaner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a vacuum cleaner in a living room. '!%|'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/30e504a3d4da423c8fe8f9fa1a648f95.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5885bb06a05149ac8bc68d5fa55b9a79", "source": "vatex", "video_id": "wo7qlyoLeKI_000014_000024", "video_description": "A person is attempting to bend a metal rod using their thigh and knee, wearing a pink or red shirt.", "task": "ActionRecognition", "clean_prompt": "A person bending a metal rod using their thigh and knee, wearing a pink shirt.", "clean_property": {"obj": "person", "action": "bending metal", "target": "metal rod"}, "target_prompt": "A person lifting a metal rod using their arms, wearing a blue shirt.", "target_property": {"obj": "person", "action": "lifting metal", "target": "metal rod"}, "evaluation_question": "Is the person **bending** a metal rod?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person bending a metal rod using their thigh and knee, wearing a pink shirt. FS7!E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4cef542da82142e9980ccf1743f204e4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a45ed2731aaf46e89f36db8a31ae4213", "source": "vatex", "video_id": "R9VF3gdf_Hk_000005_000015", "video_description": "A woman demonstrates how to fold a square white piece of paper in half, explaining the process and making a nice crease.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrates how to fold a square white piece of paper in half, explaining the process and making a nice crease.", "clean_property": {"obj": "paper", "attribute": "square"}, "target_prompt": "A woman demonstrates how to fold a circular white piece of paper in half, explaining the process and making a nice crease.", "target_property": {"obj": "paper", "attribute": "circular"}, "evaluation_question": "Is the piece of paper **square**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to fold a square white piece of paper in half, explaining the process and making a nice crease. &7FEF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e963ea9a5a024e76b0c44481a885f668.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5e859eaf793a4a9c956e698eca343760", "source": "vatex", "video_id": "diiX0pqZX3s_000002_000012", "video_description": "Two boys are in a room with a camera, making funny faces and moving closer and further from the lens.", "task": "Counting", "clean_prompt": "Three boys are in a room with a camera, making funny faces and moving closer and further from the lens.", "clean_property": {"obj": "boy", "count": "three"}, "target_prompt": "One boy is in a room with a camera, making funny faces and moving closer and further from the lens.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **three** boys in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three boys are in a room with a camera, making funny faces and moving closer and further from the lens. @SGJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/488fb14c09be43a2813722d833de0229.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dca8cf3ebf1e491e9897e3bfe3cdb59b", "source": "vatex", "video_id": "XFhKCXn_wqo_000030_000040", "video_description": "A man is in a gymnastics studio performing a swinging exercise on a high bar, demonstrating a wiggle swing technique.", "task": "ObjectRecognition", "clean_prompt": "A person performing a wiggle swing technique on a high bar in a gymnastics studio.", "clean_property": {"obj": "person"}, "target_prompt": "An animal swinging on a high bar in a gymnastics studio.", "target_property": {"obj": "animal"}, "evaluation_question": "Is the performer in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing a wiggle swing technique on a high bar in a gymnastics studio. EET.F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a182388e13c474781e4e81841d57118.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a33e810726514d5b8b334df45c2252ca", "source": "vatex", "video_id": "RjPp0ZPW0yc_000000_000010", "video_description": "A person is operating a large, orange-colored stationary saw in a workroom to cut a metal pipe.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a large, orange-colored stationary saw in a workroom.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "saw"}, "target_prompt": "A person further from the camera than a large, orange-colored stationary saw in a workroom.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "saw"}, "evaluation_question": "Is the person **closer to the camera than** the large, orange-colored stationary saw?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a large, orange-colored stationary saw in a workroom. )!G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c4db50c3700424da3f14f2d8eaa3d69.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f679c0122ac74b5ab052cd4fcaa62a58", "source": "vatex", "video_id": "L5Ixz3In8VU_000000_000010", "video_description": "A man is in a gym using a weight machine to perform arm exercises, specifically reverse grip triceps press downs, while maintaining proper form.", "task": "ObjectRecognition", "clean_prompt": "A man using a weight machine to perform reverse grip triceps press downs in a gym.", "clean_property": {"obj": "weight machine"}, "target_prompt": "A man using an exercise ball to perform arm exercises in a gym.", "target_property": {"obj": "exercise ball"}, "evaluation_question": "Is the equipment being used in the video a **weight machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a weight machine to perform reverse grip triceps press downs in a gym. 7BI%V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/41858110e4af4136973bdbb4d8ee343a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a67fb1d79e294bf2bbae32f70fb1ee1d", "source": "vatex", "video_id": "Bb8OqOF8sP4_000007_000017", "video_description": "Three children are playing hopscotch on a sidewalk. One child is jumping on the hopscotch pattern while the other two use chalk to draw and keep score.", "task": "ObjectRecognition", "clean_prompt": "Three children are playing hopscotch on a sidewalk.", "clean_property": {"obj": "child"}, "target_prompt": "Three adults are playing hopscotch on a sidewalk.", "target_property": {"obj": "adult"}, "evaluation_question": "Are the players in the video **children**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children are playing hopscotch on a sidewalk. !0RP1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fec7cfd4bfe34dbfa0d5cedec9f43bd2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "10016e0fa117495eb065ef095aa5ada8", "source": "vatex", "video_id": "_SUeogHI5rg_000043_000053", "video_description": "A man is on a golf course making an instructional video about golfing techniques, including how to hit a ball to land just short of the green and how to putt.", "task": "Counting", "clean_prompt": "Seven people on a golf course watching a man make an instructional video about golfing techniques.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Four people on a golf course watching a man make an instructional video about golfing techniques.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **seven** people on the golf course?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people on a golf course watching a man make an instructional video about golfing techniques. SL.RT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/36d0e900a3d648e099e5d187a7686bd0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "53205f82059b496e9e73e4c4d5d09779", "source": "vatex", "video_id": "V7UHgYDwg24_000006_000016", "video_description": "Several couples are swing dancing in a large room with a mirrored wall, accompanied by swing music.", "task": "Counting", "clean_prompt": "Five couples swing dancing in a large room with a mirrored wall, accompanied by swing music.", "clean_property": {"obj": "mirror", "count": "five"}, "target_prompt": "Couples swing dancing in a large room with one mirrored wall, accompanied by swing music.", "target_property": {"obj": "mirror", "count": "one"}, "evaluation_question": "Are there exactly **five** mirrors in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five couples swing dancing in a large room with a mirrored wall, accompanied by swing music. .F3)U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d80daaa5fabc47169e676e4c143362fd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13c0f7a57c834fb1bc86608f526f4071", "source": "vatex", "video_id": "3P5sjWImRqA_000010_000020", "video_description": "A young girl jumps off a high diving board into a swimming pool while a woman cheers her on.", "task": "AttributeRecognition", "clean_prompt": "A young girl jumps off a high diving board into a swimming pool while a woman cheers her on.", "clean_property": {"obj": "diving board", "attribute": "high"}, "target_prompt": "A young girl jumps off a low diving board into a swimming pool while a woman cheers her on.", "target_property": {"obj": "diving board", "attribute": "low"}, "evaluation_question": "Is the diving board **high**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl jumps off a high diving board into a swimming pool while a woman cheers her on. 3))!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/633d536905b44fdca52192863810a4b2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "95439bafa2e644bca30b69604c6774b1", "source": "vatex", "video_id": "USqpgt4hHH4_000144_000154", "video_description": "A person demonstrates how to use a paint roller with a handle that feeds paint directly onto the roller to paint a red wall.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to use a paint roller with a handle that feeds paint directly onto the roller to paint a red wall.", "clean_property": {"obj": "person", "attribute": "demonstrator"}, "target_prompt": "A person watching someone else paint a red wall with a paint roller.", "target_property": {"obj": "person", "attribute": "spectator"}, "evaluation_question": "Is the person a **demonstrator** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to use a paint roller with a handle that feeds paint directly onto the roller to paint a red wall. -)!0'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/713d55d698684a4ba8eaf4c1d59074d6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8e5b20effbd4d7f801107a770f0a27e", "source": "vatex", "video_id": "Z9V0G85qNvQ_000030_000040", "video_description": "A man is training a woman in boxing techniques in a gym, demonstrating proper form and moves.", "task": "Counting", "clean_prompt": "A man is training a woman in boxing techniques in a gym, demonstrating proper form and moves with six men.", "clean_property": {"obj": "man", "count": "six"}, "target_prompt": "A woman is training three men in boxing techniques in a gym, demonstrating proper form and moves.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** men training in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is training a woman in boxing techniques in a gym, demonstrating proper form and moves with six men. #-SL'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dabede5f8e8b4366b386c47975b344a5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afa7f05a9cf94fceb0762959b7745673", "source": "vatex", "video_id": "9d-ZXcIbYpk_000094_000104", "video_description": "A cricket match is taking place in a large stadium with loud music playing in the background. The red and blue teams are playing, with the blue team batting. The crowd is cheering.", "task": "SpatialUnderstanding", "clean_prompt": "A player farther from the camera than a cricket ball in a large stadium.", "clean_property": {"obj_1": "player", "relation": "farther from the camera than", "obj_2": "cricket ball"}, "target_prompt": "A player closer to the camera than a cricket ball in a large stadium.", "target_property": {"obj_1": "player", "relation": "closer to the camera than", "obj_2": "cricket ball"}, "evaluation_question": "Is the player **farther from the camera than** the cricket ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A player farther from the camera than a cricket ball in a large stadium. HS4O@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/550ec3e03e2c4d39ab9ba98065d4e679.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8830fc8bf2d441a8eb19f15c4de7599", "source": "vatex", "video_id": "Yb3aSpkcUeA_000016_000026", "video_description": "A young girl is demonstrating how to tie shoelaces on a pair of shoes while sitting on a chair.", "task": "ActionRecognition", "clean_prompt": "A girl tying shoelaces on a pair of shoes while sitting on a chair.", "clean_property": {"obj": "girl", "action": "tying shoe laces", "target": "shoelace"}, "target_prompt": "A girl untying shoelaces on a pair of shoes while sitting on a chair.", "target_property": {"obj": "girl", "action": "untie shoelaces", "target": "shoelace"}, "evaluation_question": "Is the girl **tying** shoelaces?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl tying shoelaces on a pair of shoes while sitting on a chair. >BC$X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7e7f882bc6348dcb985fab5ce49bca3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33794d19d28e4bf89b331699cc60770c", "source": "vatex", "video_id": "1sVu94u4bm0_000042_000052", "video_description": "Two men are in a bathroom, whistling harmoniously like birds while one dries his hair and face with a towel.", "task": "ObjectRecognition", "clean_prompt": "Two men in a bathroom whistling harmoniously while one dries his hair and face with a towel.", "clean_property": {"obj": "towel"}, "target_prompt": "Two men in a bathroom whistling harmoniously while one cleans his hair and face with a sponge.", "target_property": {"obj": "sponge"}, "evaluation_question": "Is one of the men drying his hair and face with a **towel**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men in a bathroom whistling harmoniously while one dries his hair and face with a towel. SL+;D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c87656da2b834630b63224b11833d9a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "844fb249e4f44fa7b7c06ad73e16d775", "source": "vatex", "video_id": "WUDcPhguvz4_000017_000027", "video_description": "Two men are working on a wooden platform, planing and polishing wood, and using hand saws to cut a large piece of wood during a renovation project.", "task": "ActionRecognition", "clean_prompt": "A person planing wood on a wooden platform.", "clean_property": {"obj": "person", "action": "planing wood", "target": null}, "target_prompt": "A person cutting wood on a wooden platform.", "target_property": {"obj": "person", "action": "cutting wood", "target": null}, "evaluation_question": "Is the person **planing** wood?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person planing wood on a wooden platform. BR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13754282a30f4958b60e0f8db8983b62.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "008736ad465543878cee0c0a2062798a", "source": "vatex", "video_id": "oNxxDYNA52s_000085_000095", "video_description": "A group of young girls in cheerleading outfits perform a gymnastics routine, including cartwheels, on a mat in a gymnasium. They are rehearsing and performing in front of a large audience.", "task": "ActionRecognition", "clean_prompt": "A cheerleader cartwheeling on a mat in a gymnasium.", "clean_property": {"obj": "cheerleader", "action": "cartwheeling", "target": null}, "target_prompt": "A cheerleader backflipping on a mat in a gymnasium.", "target_property": {"obj": "cheerleader", "action": "backflipping", "target": null}, "evaluation_question": "Is the cheerleader **cartwheeling**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cheerleader cartwheeling on a mat in a gymnasium. RLXSG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/edb47a314778441792014c645f8a2516.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "87aac7cb1bfd4834b7c42b7a85e71654", "source": "vatex", "video_id": "WjzAWnQZXoQ_000003_000013", "video_description": "A woman in jeans is riding a tan horse that is galloping through various terrains including a wooded trail, a gravel road, and a grassy field.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a horse, as the horse gallops through a wooded trail.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "horse"}, "target_prompt": "A person closer to the camera than a horse, as the horse gallops through a wooded trail.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "horse"}, "evaluation_question": "Is the person farther from the camera than the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a horse, as the horse gallops through a wooded trail. UFEE>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/075215f7773b45f8a0d318b512dcc2ad.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "59e6d65a55a84e869e594748b872ce5c", "source": "vatex", "video_id": "7T5nKVJrP5U_000120_000130", "video_description": "A woman is using a sewing machine to sew a piece of blue fabric, then cuts the thread and moves the fabric to a table.", "task": "ActionRecognition", "clean_prompt": "A person sewing a piece of blue fabric using a sewing machine.", "clean_property": {"obj": "person", "action": "sewing", "target": "fabric"}, "target_prompt": "A person cutting a piece of blue fabric on a table.", "target_property": {"obj": "person", "action": "cutting fabric", "target": "blue fabric"}, "evaluation_question": "Is the person **sewing** a piece of blue fabric?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sewing a piece of blue fabric using a sewing machine. >T&LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b35dc5dc42c4403b5fd8b6eeba9c150.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed043aebad24431fb556bace37843d85", "source": "vatex", "video_id": "mQVEXz1rjSk_000072_000082", "video_description": "A shirtless man slides down a large rock while seated and then jumps off the rock onto the ground.", "task": "ObjectRecognition", "clean_prompt": "A shirtless man slides down a large rock while seated and then jumps off the rock onto the ground.", "clean_property": {"obj": "rock"}, "target_prompt": "A shirtless man slides down a large tree while seated and then jumps off the tree onto the ground.", "target_property": {"obj": "tree"}, "evaluation_question": "Is the object the man is sliding down a **rock**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A shirtless man slides down a large rock while seated and then jumps off the rock onto the ground. WZ%QB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb24cfc4ade14ec9a07c842305a8359e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "308b2d36f4bf4777847582eb46df3898", "source": "vatex", "video_id": "L5Mp4_pwiK8_000000_000010", "video_description": "Two teams are playing a game of cricket on a cricket field, with players batting, catching, and throwing the ball.", "task": "ObjectRecognition", "clean_prompt": "Two teams are playing a game of cricket on a cricket field, with players batting, catching, and throwing a cricket ball.", "clean_property": {"obj": "cricket ball"}, "target_prompt": "Two teams are playing a game of football on a football field, with players kicking, catching, and throwing a football.", "target_property": {"obj": "football"}, "evaluation_question": "Is the ball being used in the game a **cricket ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teams are playing a game of cricket on a cricket field, with players batting, catching, and throwing a cricket ball. NK6LF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f7ef4ddf62e40dda389c26688b0870e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "87a420bd0e0d42bbafb923cb8f127880", "source": "vatex", "video_id": "3axTI3jSNAg_000014_000024", "video_description": "A person is demonstrating basket weaving techniques using sticks, reeds, and twill, while another person observes. The setting is a classroom environment with students.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating basket weaving techniques using sticks in a classroom.", "clean_property": {"obj": "sticks"}, "target_prompt": "A person demonstrating basket weaving techniques using balls in a classroom.", "target_property": {"obj": "balls"}, "evaluation_question": "Is the person using **sticks** for basket weaving?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating basket weaving techniques using sticks in a classroom. FE4GM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2a744452b5742618381c24dd097f154.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1019d1cd8f2e4e918dd70f727079dda0", "source": "vatex", "video_id": "YbqVivLaWw4_000011_000021", "video_description": "A man is using a floor sanding machine to sand and finish a wooden floor or deck, removing old paint and stain.", "task": "Counting", "clean_prompt": "Four people are watching a man using a floor sanding machine to sand and finish a wooden floor.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is using a floor sanding machine to sand and finish a wooden floor.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are watching a man using a floor sanding machine to sand and finish a wooden floor. \u00b7GFEW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/367dfc4032644a79a558d1e703b52f75.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2716f45f26cb47b0bb6b3927eb691995", "source": "vatex", "video_id": "pWOJhO1o-Ek_000012_000022", "video_description": "A group of young boys and girls perform a dance routine on a stage with black curtains, to the song 'When You Wish Upon a Star', in front of an audience.", "task": "ObjectRecognition", "clean_prompt": "A group of young boys and girls perform a dance routine on a stage with black curtains, in front of an audience.", "clean_property": {"obj": "audience"}, "target_prompt": "A group of performers showcasing a dance routine on a stage with black curtains.", "target_property": {"obj": "performers"}, "evaluation_question": "Is there an **audience** present in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young boys and girls perform a dance routine on a stage with black curtains, in front of an audience. >N1%\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/99824287a347445393f6bcb07274ab23.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0d826b1be22249dfb6bc61c8fbe23795", "source": "vatex", "video_id": "dNUxmjY8sfQ_000006_000016", "video_description": "A group of people, including a bartender, are demonstrating how to properly pour beer from a tap into glasses at a brewery.", "task": "ObjectRecognition", "clean_prompt": "A group of people, including a bartender, are demonstrating how to properly pour beer from a tap into glasses at a brewery.", "clean_property": {"obj": "person"}, "target_prompt": "A group of dogs playing in a park.", "target_property": {"obj": "dog"}, "evaluation_question": "Is there a **person** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people, including a bartender, are demonstrating how to properly pour beer from a tap into glasses at a brewery. SLJOY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad1d834374c4483696165e17f0862dbb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b8cd4993fa5f4a73a853e1637a39f5fc", "source": "vatex", "video_id": "KpgnU13h-zc_000008_000018", "video_description": "A toddler in a diaper is on a kitchen counter over a stove, cooking hot dogs in a pan using a wooden spoon, while a man watches.", "task": "Counting", "clean_prompt": "A toddler in a diaper is cooking hot dogs in a pan using a wooden spoon, while a man watches.", "clean_property": {"obj": "pan", "count": "three"}, "target_prompt": "A toddler in a diaper is cooking hot dogs in one pan using a wooden spoon, while a man watches.", "target_property": {"obj": "pan", "count": "one"}, "evaluation_question": "Are there exactly **three** pans being used in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A toddler in a diaper is cooking hot dogs in a pan using a wooden spoon, while a man watches. #XFEM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dbb968884d17448b98f74d1fd58d32e1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d63b80647c6c458287076e930b2e23a9", "source": "vatex", "video_id": "t6w-_xe4OPM_000000_000010", "video_description": "A young boy is performing a pole vault routine at a track meet, running down a lane with a pole and attempting to jump over a high bar.", "task": "ObjectRecognition", "clean_prompt": "A young boy is performing a pole vault routine at a track meet.", "clean_property": {"obj": "pole"}, "target_prompt": "A young boy is running towards a hurdle at a track meet.", "target_property": {"obj": "hurdle"}, "evaluation_question": "Is the object the boy is using in the video a **pole**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is performing a pole vault routine at a track meet. -))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bdb7811eeee24f67b145d008d7ca33c8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e03b752ee677463d939c67d324145b07", "source": "vatex", "video_id": "O0hqyxavhCE_000007_000017", "video_description": "A young boy is playing a drum set in a room with flashing multicolor lights.", "task": "Counting", "clean_prompt": "Five boys playing a drum set in a room with flashing multicolor lights.", "clean_property": {"obj": "boy", "count": "five"}, "target_prompt": "Three girls playing a guitar in a room with bright neon lights.", "target_property": {"obj": "girl", "count": "three"}, "evaluation_question": "Are there exactly **five** boys playing the drum set?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five boys playing a drum set in a room with flashing multicolor lights. OSS$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc954c140a5441ea8afa5e88bb89c99a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "70bba8518c094478bac27ff6e13068b5", "source": "vatex", "video_id": "9IyZ8sJV7XU_000021_000031", "video_description": "In a sewing factory, multiple people, including two men, are using sewing machines to sew various types of fabric and garments. A narrator explains the sewing processes and specializations.", "task": "AttributeRecognition", "clean_prompt": "In a sewing factory, multiple people, including two men, are using sewing machines that are single purpose to sew various types of fabric and garments.", "clean_property": {"obj": "sewing machine", "attribute": "single purpose"}, "target_prompt": "In a sewing factory, multiple people, including two men, are using multi-purpose sewing machines to sew various types of fabric and garments.", "target_property": {"obj": "sewing machine", "attribute": "multi-purpose"}, "evaluation_question": "Are the sewing machines single purpose?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "In a sewing factory, multiple people, including two men, are using sewing machines that are single purpose to sew various types of fabric and garments. BSX2~", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/302a02f3cd4c4e2cbe0b4d254e60d43a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "057b80e433974ab6bf54dfac56eee340", "source": "vatex", "video_id": "ffnKgRrtBfs_000035_000045", "video_description": "A man demonstrates how to separate egg yolks from egg whites using a plastic bottle.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrates how to separate egg yolks from egg whites using a plastic bottle.", "clean_property": {"obj": "plastic bottle"}, "target_prompt": "A man demonstrates how to separate egg yolks from egg whites using a glass jar.", "target_property": {"obj": "glass jar"}, "evaluation_question": "Is the man using a **plastic bottle** to separate the egg yolks from the egg whites?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to separate egg yolks from egg whites using a plastic bottle. 0QVA7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7b23e4e7d5bb4481b5e8fc126945d2e0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3e0321ce50514232ba54e440a8154f7d", "source": "vatex", "video_id": "sGxujaBZWEI_000001_000011", "video_description": "A man is performing deadlifts in a busy gym, lifting a barbell with heavy weights up to his thighs and then lowering it back down in multiple repetitions.", "task": "ActionRecognition", "clean_prompt": "A person deadlifting a barbell in a busy gym.", "clean_property": {"obj": "person", "action": "deadlifting", "target": "barbell"}, "target_prompt": "A person squatting with a barbell in a busy gym.", "target_property": {"obj": "person", "action": "squatting", "target": "barbell"}, "evaluation_question": "Is the person **deadlifting** a barbell?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person deadlifting a barbell in a busy gym. )L$FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2acc0a51fa914029aca79ff51d19892c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb73bff7489744b79a4a170e78f72955", "source": "vatex", "video_id": "EvLWCVtUKAw_000095_000105", "video_description": "A man is preparing to go geocaching at a local park using an old-fashioned mobile phone with a digital display and a GPS device.", "task": "AttributeRecognition", "clean_prompt": "A man is preparing to go geocaching at a local park using an old-fashioned mobile phone with a digital display.", "clean_property": {"obj": "mobile phone", "attribute": "digital display"}, "target_prompt": "A man is preparing to go geocaching at a local park using a modern mobile phone with a touchscreen display.", "target_property": {"obj": "mobile phone", "attribute": "touchscreen display"}, "evaluation_question": "Does the mobile phone have a **digital** display?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is preparing to go geocaching at a local park using an old-fashioned mobile phone with a digital display. FEYT8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a080ef5d83fc47f28decf7a22ac0f037.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d3ef3e1349d84a7ba79a2e67f6d92a7a", "source": "vatex", "video_id": "XDc1n3TLc_w_000017_000027", "video_description": "A person dressed in an Incredible Hulk costume is outside, flexing and moving around, while a child is present and occasionally calls out.", "task": "AttributeRecognition", "clean_prompt": "A person dressed in a green Incredible Hulk costume is outside, flexing and moving around.", "clean_property": {"obj": "person", "attribute": "green"}, "target_prompt": "A person dressed in a red superhero costume is outside, flexing and moving around.", "target_property": {"obj": "person", "attribute": "dressed in a red superhero costume"}, "evaluation_question": "Is the person dressed in a **green** Incredible Hulk costume?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person dressed in a green Incredible Hulk costume is outside, flexing and moving around. (EL*)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1aed4bcbbdf544de9999cfd84383a312.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e28fd3ec2302497ab9d3a32a8bd042ad", "source": "vatex", "video_id": "s8QiIG1vmUA_000050_000060", "video_description": "A woman is holding a small baby who sneezes repeatedly while two women giggle.", "task": "ActionRecognition", "clean_prompt": "A woman laughing while holding a small baby.", "clean_property": {"obj": "woman", "action": "laughing", "target": null}, "target_prompt": "A woman crying while holding a small baby.", "target_property": {"obj": "woman", "action": "crying", "target": null}, "evaluation_question": "Is the woman **laughing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman laughing while holding a small baby. )(G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/79cd24c9f2334a298d85275c7ed25bb7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "41fa3c5bc7424c33a6433382e39db009", "source": "vatex", "video_id": "A4I-Qt0jT6k_000016_000026", "video_description": "A man is playing a full set of drums enthusiastically and rapidly in a dark room.", "task": "ObjectRecognition", "clean_prompt": "A man is playing a full set of drums enthusiastically and rapidly in a dark room.", "clean_property": {"obj": "drum set"}, "target_prompt": "A man is playing a grand piano enthusiastically and rapidly in a brightly lit room.", "target_property": {"obj": "piano"}, "evaluation_question": "Is the man playing a **drum set**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is playing a full set of drums enthusiastically and rapidly in a dark room. NL4Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0609db39d25946388a3372e25234bf78.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2f441adacb664a9d95bc134c5299a471", "source": "vatex", "video_id": "QEPGmSl4IlU_000082_000092", "video_description": "A man demonstrates how to fold paper into origami shapes on a wooden table.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrates how to fold red paper into origami shapes on a wooden table.", "clean_property": {"obj": "paper", "attribute": "red"}, "target_prompt": "A man demonstrates how to fold blue paper into origami shapes on a wooden table.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper being used in the demonstration **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to fold red paper into origami shapes on a wooden table. NK&,R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73e5ccb5f1d24c4c896959886cadc5ac.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c167089f800046e2be9b131a8da2b79d", "source": "vatex", "video_id": "5fE_TmvVPJc_000177_000187", "video_description": "A boy is outside demonstrating how to throw a card, explaining the technique and showing it to the camera.", "task": "ObjectRecognition", "clean_prompt": "A boy is outside demonstrating how to throw a card, explaining the technique and showing it to the camera.", "clean_property": {"obj": "card"}, "target_prompt": "A boy is outside demonstrating how to throw a frisbee, explaining the technique and showing it to the camera.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Is the object being thrown in the video a **card**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy is outside demonstrating how to throw a card, explaining the technique and showing it to the camera. FE%CE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d7dc1ae254aa404799d6c49e8c064727.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8be4b551e04b40638800e59d7919ff57", "source": "vatex", "video_id": "Qr1uroXxmIA_000029_000039", "video_description": "A man is practicing archery indoors, shooting arrows at multiple targets in a large room.", "task": "ObjectRecognition", "clean_prompt": "A man practicing archery indoors, shooting arrows at multiple targets in a large room.", "clean_property": {"obj": "arrow"}, "target_prompt": "A man practicing basketball indoors, shooting balls at multiple hoops in a large room.", "target_property": {"obj": "ball"}, "evaluation_question": "Is the object being shot in the video an **arrow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man practicing archery indoors, shooting arrows at multiple targets in a large room. M911V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d93743866c814c95a54faa21ed145ed3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d964756c38f49b0be2bfec4f5a49f41", "source": "vatex", "video_id": "F16EyuV_egA_000000_000010", "video_description": "A man demonstrates and explains proper hand placement and turning techniques on a car steering wheel, focusing on making a right turn.", "task": "SpatialUnderstanding", "clean_prompt": "A steering wheel farther from the camera than a person demonstrating proper hand placement and turning techniques.", "clean_property": {"obj_1": "steering wheel", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A steering wheel closer to the camera than a person demonstrating proper hand placement and turning techniques.", "target_property": {"obj_1": "steering wheel", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the steering wheel farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A steering wheel farther from the camera than a person demonstrating proper hand placement and turning techniques. .TZ@S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/70c0331d137c46d1aadc5f4f77ea3c2f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57f329ba2ff1435295a089cb53a76e79", "source": "vatex", "video_id": "zAO7HLux_I8_000025_000035", "video_description": "A man is demonstrating how to properly do push-ups in a gym setting.", "task": "ActionRecognition", "clean_prompt": "A person demonstrating how to properly do push-ups in a gym setting.", "clean_property": {"obj": "person", "action": "push up", "target": null}, "target_prompt": "A person demonstrating how to properly do squats in a gym setting.", "target_property": {"obj": "person", "action": "doing squats", "target": null}, "evaluation_question": "Is the person **doing push-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to properly do push-ups in a gym setting. FE7XA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/171f3c7950e34916b5a86640c62af874.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c8dd95b6236d441c8206d4fc365a0ddd", "source": "vatex", "video_id": "h5ta2cUhUhA_000030_000040", "video_description": "A man is demonstrating how to make balloon animals by blowing up a long blue balloon and twisting it into various shapes. He provides instructions and narrates the process, occasionally speaking in a high voice after inhaling helium from a balloon.", "task": "SpatialUnderstanding", "clean_prompt": "A balloon floating above a person demonstrating how to make balloon animals.", "clean_property": {"obj_1": "balloon", "relation": "below", "obj_2": "person"}, "target_prompt": "A balloon beside a person demonstrating how to make balloon animals.", "target_property": {"obj_1": "balloon", "relation": "beside", "obj_2": "person"}, "evaluation_question": "Is the balloon **below** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A balloon floating above a person demonstrating how to make balloon animals. ELQ95", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d9e7cfc1611f47c9bc819d5d8c3e115d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dcdd6bed273241e49b79c40fedfc8d9e", "source": "vatex", "video_id": "3YpPMnCb3O4_000123_000133", "video_description": "A man demonstrates how to copy an identification card using a photocopier.", "task": "Counting", "clean_prompt": "A man demonstrates how to copy three identification cards using a photocopier.", "clean_property": {"obj": "identification card", "count": "three"}, "target_prompt": "A man demonstrates how to copy one identification card using a photocopier.", "target_property": {"obj": "identification card", "count": "one"}, "evaluation_question": "Are there exactly **three** identification cards being copied?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to copy three identification cards using a photocopier. FE@#>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d93e7f9d64143d188552af9ee7de295.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "77a65e9c5c4b421ba29f3a1f14f70885", "source": "vatex", "video_id": "wIk-d2Top2w_000067_000077", "video_description": "A young boy is sitting at a table, playing with a green fidget spinner. He occasionally talks and looks into the camera.", "task": "Counting", "clean_prompt": "A young boy is sitting at a table, playing with five fidget spinners. He occasionally talks and looks into the camera.", "clean_property": {"obj": "fidget spinner", "count": "five"}, "target_prompt": "A young boy is sitting at a table, playing with one fidget spinner. He occasionally talks and looks into the camera.", "target_property": {"obj": "fidget spinner", "count": "one"}, "evaluation_question": "Are there exactly **five** fidget spinners on the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting at a table, playing with five fidget spinners. He occasionally talks and looks into the camera. >ITO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cece7c1b39eb440bb72815258fed4bbf.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6bf3a744b3e474ebd5b55ffd2aca1d2", "source": "vatex", "video_id": "-cqADbIiZ1Q_000129_000139", "video_description": "A baseball game is in progress with a pitcher pitching a softball underhand to a batter and a catcher in an orange uniform. An umpire is present behind home base.", "task": "SpatialUnderstanding", "clean_prompt": "An umpire standing to the left of a pitcher during a baseball game.", "clean_property": {"obj_1": "umpire", "relation": "left of", "obj_2": "pitcher"}, "target_prompt": "An umpire standing to the right of a pitcher during a baseball game.", "target_property": {"obj_1": "umpire", "relation": "right of", "obj_2": "pitcher"}, "evaluation_question": "Is the umpire to the **left** of the pitcher?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An umpire standing to the left of a pitcher during a baseball game. LY2(E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f3191c8238674adeb949054a595fb4dd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b03a02fee56497d8e90a58874251e9e", "source": "vatex", "video_id": "t0umsAjFES0_000007_000017", "video_description": "A family is gathered in a kitchen, with adults and children carving and cleaning out pumpkins on the floor.", "task": "ActionRecognition", "clean_prompt": "An adult carving a pumpkin in a kitchen.", "clean_property": {"obj": "adult", "action": "carving pumpkin", "target": null}, "target_prompt": "An adult throwing a pumpkin in a kitchen.", "target_property": {"obj": "adult", "action": "throwing pumpkin", "target": null}, "evaluation_question": "Is the adult **carving** a pumpkin?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult carving a pumpkin in a kitchen. FEYUE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/af044c4454ee4696b7ad82d5f49497f5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2da060261453400cb18849d8985631fc", "source": "vatex", "video_id": "yaUfx_tWHNs_000000_000010", "video_description": "A baby boy wearing a monkey bib is sitting and shaking his head 'no' in response to an adult talking to him.", "task": "AttributeRecognition", "clean_prompt": "A baby wearing a monkey bib is sitting and shaking his head 'no'.", "clean_property": {"obj": "baby", "attribute": "wearing monkey bib"}, "target_prompt": "A baby wearing a dinosaur bib is sitting and shaking his head 'no'.", "target_property": {"obj": "baby", "attribute": "wearing dinosaur bib"}, "evaluation_question": "Is the baby wearing a **monkey** bib?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby wearing a monkey bib is sitting and shaking his head 'no'. #ME%V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1508fa660e67407cb1b5e827eb61cc88.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "908760ac86574ea4bb5cf14c2182f075", "source": "vatex", "video_id": "GeG0c-priYo_000000_000010", "video_description": "A group of women in formal dresses are dancing the Macarena on a stage with disco lights and a band playing music.", "task": "Counting", "clean_prompt": "Two women in formal dresses dancing the Macarena on a stage with disco lights.", "clean_property": {"obj": "woman", "count": "two"}, "target_prompt": "Four women in casual outfits dancing the Macarena on a beach.", "target_property": {"obj": "woman", "count": "four"}, "evaluation_question": "Are there exactly **two** women dancing on the stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women in formal dresses dancing the Macarena on a stage with disco lights. 3/SL=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2449b330e2e847f0b5575c9f26aa86f8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7e7d1faf2af04959a86bb0b9fbd87de1", "source": "vatex", "video_id": "mKDfxhXHMA4_000080_000090", "video_description": "A woman is holding a large, coiled snake close to her chest while explaining its behavior.", "task": "SpatialUnderstanding", "clean_prompt": "A woman holding a large, coiled snake close to her chest while explaining its behavior.", "clean_property": {"obj_1": "woman", "relation": "above", "obj_2": "snake"}, "target_prompt": "A woman standing beside a large, coiled snake while explaining its behavior.", "target_property": {"obj_1": "woman", "relation": "beside", "obj_2": "snake"}, "evaluation_question": "Is the woman **above** the snake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman holding a large, coiled snake close to her chest while explaining its behavior. *8,RV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6c66f9f052974e8987d406bf3e090022.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "84972b0b8a3f4bf2b8f89156095238e2", "source": "vatex", "video_id": "rseoEvLeT4A_000039_000049", "video_description": "A woman and her daughter are sitting on a bench in a busy city street, feeding pigeons.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a pigeon.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "pigeon"}, "target_prompt": "A woman closer to the camera than a pigeon.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "pigeon"}, "evaluation_question": "Is the woman **farther from the camera than** the pigeon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a pigeon. ;SNY$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a3430a72fe44570a43b61dfbbf35698.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cdc10e2171941ebac846c0fb3a79050", "source": "vatex", "video_id": "uWLg33tanW8_000232_000242", "video_description": "A young girl is using a shower head to wash a smaller child in a bathtub.", "task": "ActionRecognition", "clean_prompt": "A girl washing hair in a bathtub.", "clean_property": {"obj": "girl", "action": "washing hair", "target": "child"}, "target_prompt": "A girl splashing water in a bathtub.", "target_property": {"obj": "girl", "action": "splashing water", "target": "child"}, "evaluation_question": "Is the girl **washing hair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl washing hair in a bathtub. UG7K>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/211a033f777044e69608e96f60419b91.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a0bec088c59e418fb5971d18e8045758", "source": "vatex", "video_id": "sNF7k-Wx7gk_000061_000071", "video_description": "A bull rider falls off a bull as it charges out of a stall. A rodeo clown distracts the bull to allow the rider to escape.", "task": "SpatialUnderstanding", "clean_prompt": "A rider positioned to the right of a rodeo clown as the bull charges out of the stall.", "clean_property": {"obj_1": "rider", "relation": "right of", "obj_2": "rodeo clown"}, "target_prompt": "A rider positioned to the left of a rodeo clown as the bull charges out of the stall.", "target_property": {"obj_1": "rider", "relation": "left of", "obj_2": "rodeo clown"}, "evaluation_question": "Is the rider to the **right** of the rodeo clown?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rider positioned to the right of a rodeo clown as the bull charges out of the stall. M1UUU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3dcf2c52766d40e99b0a8849aa844f83.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "160941a8dfb94b5b913910edd683fc1b", "source": "vatex", "video_id": "1G1P2hmFqpA_000008_000018", "video_description": "A person is riding a dog sled pulled by a team of dogs across a snowy field with mountains in the background.", "task": "Counting", "clean_prompt": "A person is riding a sled pulled by a team of six dogs across a snowy field with mountains in the background.", "clean_property": {"obj": "sled", "count": "six"}, "target_prompt": "A person is riding a sled pulled by a single dog across a snowy field with mountains in the background.", "target_property": {"obj": "sled", "count": "one"}, "evaluation_question": "Are there exactly **six** dogs pulling the sled?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is riding a sled pulled by a team of six dogs across a snowy field with mountains in the background. 74TZ9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ae3e1ff512ff43ad87d65e1d1fcade8e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "56a8490f35a24780b57b21af54235bac", "source": "vatex", "video_id": "CBx-7WJRHgo_000000_000010", "video_description": "A person attempts to ride a motocross bike across a rapidly moving stream but falls into the water.", "task": "AttributeRecognition", "clean_prompt": "A person attempting to ride a motocross bike across a rocky stream.", "clean_property": {"obj": "stream", "attribute": "rocky"}, "target_prompt": "A person attempting to ride a motocross bike across a calm stream.", "target_property": {"obj": "stream", "attribute": "calm"}, "evaluation_question": "Is the stream **rocky**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person attempting to ride a motocross bike across a rocky stream. EL@4T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d37b62a4eff4bf48ffdf299ea430531.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "134fac363ae84e00bd7c444c493f0c8b", "source": "vatex", "video_id": "iIl35DGzWio_000000_000010", "video_description": "A man is performing various jump rope exercises in a gym, demonstrating skillful and fancy jumps.", "task": "Counting", "clean_prompt": "Seven people performing various jump rope exercises in a gym.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people performing various jump rope exercises in a gym.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people performing in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people performing various jump rope exercises in a gym. \u00b7MZZV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a20a72fe14cd49239e6b6e57d600ec87.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "08a93997cb544919addad85fb0ebfb5a", "source": "vatex", "video_id": "yeO0bSqNdJc_000057_000067", "video_description": "A man is massaging a woman's feet while she lies on a bed. They are in a darkened bedroom. The woman turns on her side to go to sleep after the massage.", "task": "ActionRecognition", "clean_prompt": "A man is massaging a woman's feet while she lies on a bed in a darkened bedroom.", "clean_property": {"obj": "man", "action": "massaging feet", "target": "woman"}, "target_prompt": "A man is massaging another man's feet while they both sit on a couch in a brightly lit living room.", "target_property": {"obj": "man", "action": "massaging feet", "target": "man"}, "evaluation_question": "Is the man **massaging a woman's** feet?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is massaging a woman's feet while she lies on a bed in a darkened bedroom. SGJMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb24ebb6606540b991de27ad37b761ce.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "128750b9dce0479e9b19d8dee1c0f2b9", "source": "vatex", "video_id": "j41tqfbwWUY_000000_000010", "video_description": "A man, wearing a grey hoodie, is sitting on a couch demonstrating his knife sharpening skills by rapidly sharpening knives using a metal knife sharpener and clanging them together.", "task": "Counting", "clean_prompt": "Two people sitting on a couch, one wearing a grey hoodie, demonstrating knife sharpening skills.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person sitting on a couch, demonstrating knife sharpening skills.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people sitting on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people sitting on a couch, one wearing a grey hoodie, demonstrating knife sharpening skills. O*4*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24a0dd9d46c243c6837642a15185b892.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8e9315640aa24b82a4deb3c6338115a8", "source": "vatex", "video_id": "lDOd8Z0Vwbg_000236_000246", "video_description": "A person is demonstrating how to prepare and attach a fishing lure using various tools and materials.", "task": "SpatialUnderstanding", "clean_prompt": "A vice farther from the camera than a fishing lure.", "clean_property": {"obj_1": "vice", "relation": "farther from the camera than", "obj_2": "fishing lure"}, "target_prompt": "A vice closer to the camera than a fishing lure.", "target_property": {"obj_1": "vice", "relation": "closer to the camera than", "obj_2": "fishing lure"}, "evaluation_question": "Is the vice **farther from the camera than** the fishing lure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A vice farther from the camera than a fishing lure. FS0;E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/86f2ae0cd63047c789bc5e7a706cdd12.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90dfe199f693437fa9c848a564332c37", "source": "vatex", "video_id": "SfGVf0KEMcw_000027_000037", "video_description": "A woman is using an electric razor to shave a man's red beard while both are laughing.", "task": "AttributeRecognition", "clean_prompt": "A woman laughing while using an electric razor to shave a man's red beard.", "clean_property": {"obj": "woman", "attribute": "laughing"}, "target_prompt": "A woman crying while using an electric razor to shave a man's red beard.", "target_property": {"obj": "woman", "attribute": "crying"}, "evaluation_question": "Is the woman **laughing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman laughing while using an electric razor to shave a man's red beard. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f91e15dbcffa44f9b0222ff3e651137d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b957d9ca6cf945bb9c3fb67ff06b0408", "source": "vatex", "video_id": "9EZKYCAOAvk_000119_000129", "video_description": "A man is demonstrating and explaining how to clean a window sill using a spray bottle and a cloth.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth.", "clean_property": {"obj": "window", "attribute": "uPVC"}, "target_prompt": "A man is demonstrating how to clean a wooden window sill using a spray bottle and a cloth.", "target_property": {"obj": "window", "attribute": "wooden"}, "evaluation_question": "Is the window sill made of **uPVC**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to clean a uPVC window sill using a spray bottle and a cloth. LF&3S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40e6e977fbb64ada9e7b73d0c885d39f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0dc32754198f4aa7b7e0b932ac75a52f", "source": "vatex", "video_id": "U1TFKAjz1Mg_000000_000010", "video_description": "A baby boy is being fed a piece of sour candy by an adult, and he reacts with a sour face and shakes his head.", "task": "Counting", "clean_prompt": "Two babies are being fed sour candy by an adult, reacting with sour faces and shaking their heads.", "clean_property": {"obj": "baby", "count": "two"}, "target_prompt": "A baby is being fed sour candy by an adult, reacting with a sour face and shaking its head.", "target_property": {"obj": "baby", "count": "one"}, "evaluation_question": "Are there exactly **two** babies being fed sour candy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two babies are being fed sour candy by an adult, reacting with sour faces and shaking their heads. 8VZL+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef3a33fadced4f66a74583221aecd6ed.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "28d142d5f40a46b2ae0dc10e7974299f", "source": "vatex", "video_id": "BqqAEBbnD3Y_000000_000010", "video_description": "A child is moonwalking on ice skates outdoors on a frozen lake, wearing full winter gear.", "task": "Counting", "clean_prompt": "A child is moonwalking on ice skates outdoors on a frozen lake, wearing full winter gear, with five children joining in the fun.", "clean_property": {"obj": "child", "count": "five"}, "target_prompt": "A child is moonwalking on ice skates outdoors on a frozen lake, wearing full winter gear, alone.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **five** children on the frozen lake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is moonwalking on ice skates outdoors on a frozen lake, wearing full winter gear, with five children joining in the fun. $-=BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a63e7f7f59af4403acb8a1ae573bc50c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4673d59f67be47518cc13bad21ff3be5", "source": "vatex", "video_id": "1_upM1fAcag_000000_000010", "video_description": "A man in a gym is performing rope circle exercises using heavy ropes to work out his arms. The gym has a wooden floor.", "task": "AttributeRecognition", "clean_prompt": "A man in a gym performing rope circle exercises using heavy ropes on a wooden floor.", "clean_property": {"obj": "rope", "attribute": "heavy"}, "target_prompt": "A man in a gym performing rope circle exercises using light ropes on a wooden floor.", "target_property": {"obj": "rope", "attribute": "light"}, "evaluation_question": "Is the rope being used in the exercise **heavy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a gym performing rope circle exercises using heavy ropes on a wooden floor. G8PVA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e1d30702dd24abdb1a0463b67d9cd97.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f74c6cf8ba84443d85d3eaf94ffe3b9b", "source": "vatex", "video_id": "rDZa20STPUU_000340_000350", "video_description": "Two boys are playing a game of kickball in a grassy backyard. One boy rolls a blue ball to the other, who kicks it and runs towards a shed.", "task": "ActionRecognition", "clean_prompt": "A boy kicking a soccer ball in a grassy backyard.", "clean_property": {"obj": "boy", "action": "kicking soccer ball", "target": "ball"}, "target_prompt": "A boy throwing a soccer ball in a grassy backyard.", "target_property": {"obj": "boy", "action": "throwing soccer ball", "target": "ball"}, "evaluation_question": "Is the boy **kicking** a soccer ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy kicking a soccer ball in a grassy backyard. UG>#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5a21f2e0121646e99223c8eaedf89496.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7525402dd5274b5589ed9e3529e8d43a", "source": "vatex", "video_id": "0gtSAyvqcI8_000109_000119", "video_description": "A family with young children is in a living room, decorating and turning on the lights of a Christmas tree.", "task": "SpatialUnderstanding", "clean_prompt": "A Christmas tree farther from the camera than a family.", "clean_property": {"obj_1": "Christmas tree", "relation": "farther from the camera than", "obj_2": "family"}, "target_prompt": "A Christmas tree closer to the camera than a family.", "target_property": {"obj_1": "Christmas tree", "relation": "closer to the camera than", "obj_2": "family"}, "evaluation_question": "Is the Christmas tree **farther from the camera than** the family?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A Christmas tree farther from the camera than a family. =-PE.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce6750a6246a4ae4bcc1a5faa463ad82.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "be0a2b3103e24a43a17733a497487a1a", "source": "vatex", "video_id": "6QetWvqJCkU_000023_000033", "video_description": "A man in a jean outfit and hat is dancing to music in a garage with a guitar in the background.", "task": "ObjectRecognition", "clean_prompt": "A man dancing in a garage with a guitar in the background.", "clean_property": {"obj": "guitar"}, "target_prompt": "A man dancing in a garage with a drum in the background.", "target_property": {"obj": "drum"}, "evaluation_question": "Is there a **guitar** in the background of the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man dancing in a garage with a guitar in the background. VT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/572309cad5114feb83230e324225ebb4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9876d140d79a499cadde99a583fea9cb", "source": "vatex", "video_id": "eA7vqqy0j7c_000073_000083", "video_description": "A woman is demonstrating how to cut a baby's nails using small scissors.", "task": "SpatialUnderstanding", "clean_prompt": "A baby farther from the camera than scissors.", "clean_property": {"obj_1": "baby", "relation": "farther from the camera than", "obj_2": "scissors"}, "target_prompt": "A baby closer to the camera than scissors.", "target_property": {"obj_1": "baby", "relation": "closer to the camera than", "obj_2": "scissors"}, "evaluation_question": "Is the baby **farther from the camera than** the scissors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby farther from the camera than scissors. )?G%2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56035fe26f7347b3a1ff99cca4281fe0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2ae0c8e4ebf441bbfcba7bdbedfe01a", "source": "vatex", "video_id": "JQTZTmaD86Q_000020_000030", "video_description": "A young girl stands on a bathroom counter in front of a mirror, brushing her teeth while wearing pajamas and an Olympic medal. Music is playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A young girl brushing her teeth with a toothbrush in front of a mirror while wearing pajamas and an Olympic medal.", "clean_property": {"obj": "toothbrush"}, "target_prompt": "A young girl brushing her hair with a hairbrush in front of a mirror while wearing pajamas and an Olympic medal.", "target_property": {"obj": "hairbrush"}, "evaluation_question": "Is the girl using a **toothbrush** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl brushing her teeth with a toothbrush in front of a mirror while wearing pajamas and an Olympic medal. /!0D&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0f6160e69b944b4d8604ec4e77a2874f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "80a13d7b444542ff867f54481dbe8404", "source": "vatex", "video_id": "4m-dwtx_W6E_000034_000044", "video_description": "A man demonstrates how to tie a checkered tie while wearing a white shirt in his kitchen.", "task": "ActionRecognition", "clean_prompt": "A person tying a checkered tie in a kitchen.", "clean_property": {"obj": "person", "action": "tying necktie", "target": "tie"}, "target_prompt": "A person removing a checkered tie in a kitchen.", "target_property": {"obj": "person", "action": "removing necktie", "target": "tie"}, "evaluation_question": "Is the person **tying** a checkered tie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a checkered tie in a kitchen. ))!=-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df1eef7e082b4551a42813477ae49749.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "611d1d99b99c42c78cd9b4dda542713f", "source": "vatex", "video_id": "-HT5GP6F0js_000146_000156", "video_description": "A man is performing a sword swallowing act in front of an audience while a woman narrates about his training.", "task": "Counting", "clean_prompt": "A man is performing a sword swallowing act with seven swords in front of an audience, while a woman narrates about his training.", "clean_property": {"obj": "sword", "count": "seven"}, "target_prompt": "A man is performing a sword swallowing act with three swords in front of an audience, while a woman narrates about his training.", "target_property": {"obj": "sword", "count": "three"}, "evaluation_question": "Are there exactly **seven** swords in the act?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is performing a sword swallowing act with seven swords in front of an audience, while a woman narrates about his training. !/!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc96c918513141ba82a4c23a2f8a3a57.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb4e03345118436384b86ba204cb47aa", "source": "vatex", "video_id": "QIAzAZmZYGc_000018_000028", "video_description": "A man with glasses and a beard is sitting in a room, possibly a computer lab or office, reading a newspaper and making various facial expressions.", "task": "ActionRecognition", "clean_prompt": "A person reading a newspaper in a room.", "clean_property": {"obj": "person", "action": "reading newspaper", "target": null}, "target_prompt": "A person throwing a newspaper in a room.", "target_property": {"obj": "person", "action": "throwing newspaper", "target": null}, "evaluation_question": "Is the person **reading** a newspaper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person reading a newspaper in a room. VT'6R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5bab47ec7c34813ac4a15938d2d77c9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1e65e99a7f2c4c1b9c5df7eac415e78f", "source": "vatex", "video_id": "dVlbus5P-II_000020_000030", "video_description": "A little boy is playing outside in the snow, picking up snow and throwing it while running around.", "task": "ActionRecognition", "clean_prompt": "A boy throwing snowballs while playing outside in the snow.", "clean_property": {"obj": "boy", "action": "throwing snowballs", "target": null}, "target_prompt": "A boy building a snowman while playing outside in the snow.", "target_property": {"obj": "boy", "action": "building a snowman", "target": null}, "evaluation_question": "Is the boy **throwing snowballs**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy throwing snowballs while playing outside in the snow. .-SMC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e720c4772604ebc878c12b43b8a9ea9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ad0b46b264a4097b6bb676b68237ba1", "source": "vatex", "video_id": "4nDSYwcXvIo_000554_000564", "video_description": "Two young men are playing frisbee golf in a wooded area on a sunny day.", "task": "Counting", "clean_prompt": "Two young men are playing frisbee golf in a wooded area on a sunny day.", "clean_property": {"obj": "frisbee", "count": "two"}, "target_prompt": "One young man is playing frisbee golf in a wooded area on a sunny day.", "target_property": {"obj": "frisbee", "count": "one"}, "evaluation_question": "Are there exactly **two** young men playing frisbee golf?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young men are playing frisbee golf in a wooded area on a sunny day. ))?0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f388d910d4114301a03b86da0d823283.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "92e2a02c21644dd8941f976d25275bf1", "source": "vatex", "video_id": "nFxhcbR2W5k_000085_000095", "video_description": "A person is pouring oil from an orange jug into the engine of a car using a funnel while speaking in a foreign language.", "task": "AttributeRecognition", "clean_prompt": "A person is pouring oil from an orange jug into the engine of a car using a funnel.", "clean_property": {"obj": "jug", "attribute": "orange"}, "target_prompt": "A person is pouring oil from a blue jug into the engine of a car using a funnel.", "target_property": {"obj": "jug", "attribute": "blue"}, "evaluation_question": "Is the jug **orange**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is pouring oil from an orange jug into the engine of a car using a funnel. LY~LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d0c787db22174e78a5431fa26978274b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a9a6549465f44059aa10056b683fba75", "source": "vatex", "video_id": "hBsnCUPKM-s_000056_000066", "video_description": "A young girl is in her room, tearing various paper materials like newspaper ads, magazine pages, and flyers into pieces.", "task": "Counting", "clean_prompt": "Four girls in a room, tearing various paper materials like newspaper ads, magazine pages, and flyers into pieces.", "clean_property": {"obj": "girl", "count": "four"}, "target_prompt": "One girl in a room, tearing various paper materials like newspaper ads, magazine pages, and flyers into pieces.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **four** girls in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four girls in a room, tearing various paper materials like newspaper ads, magazine pages, and flyers into pieces. )*G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7480ef9ccfb841949e2b1ea22ae262be.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a0e422fba77424e8d955e313f5f5b8b", "source": "vatex", "video_id": "YbqVivLaWw4_000011_000021", "video_description": "A man is using a floor sanding machine to sand and finish a wooden floor or deck, removing old paint and stain.", "task": "AttributeRecognition", "clean_prompt": "A man using a sanding machine with attached, inflated bag to sand a wooden floor.", "clean_property": {"obj": "sanding machine", "attribute": "with attached, inflated bag"}, "target_prompt": "A man using a sanding machine without an attached bag to sand a wooden floor.", "target_property": {"obj": "sanding machine", "attribute": "without an attached bag"}, "evaluation_question": "Does the sanding machine have an **attached, inflated bag**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a sanding machine with attached, inflated bag to sand a wooden floor. !FENB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/505fa6b3e17944559e3341a2fc8b998b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "65fbfb7ab6644f89af43562f144cee50", "source": "vatex", "video_id": "2RXm04bP08U_000034_000044", "video_description": "A woman is placing laundry on the floor in front of an overflowing washing machine, using clothes to clean up bubbles leaking from the machine.", "task": "AttributeRecognition", "clean_prompt": "A woman is placing laundry on the floor in front of an overflowing washing machine, using clothes to clean up bubbles leaking from the machine.", "clean_property": {"obj": "washing machine", "attribute": "overflowing"}, "target_prompt": "A woman is placing laundry on the floor in front of a functioning properly washing machine.", "target_property": {"obj": "washing machine", "attribute": "functioning properly"}, "evaluation_question": "Is the washing machine **overflowing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is placing laundry on the floor in front of an overflowing washing machine, using clothes to clean up bubbles leaking from the machine. =P-BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de5ef087ae5946c28ead00a74fcc8833.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5bfe9c9b53b04fc3b1d0a5f21e7dd6d3", "source": "vatex", "video_id": "r6QEw8m4yu4_000020_000030", "video_description": "Two men are engaged in a playful sword fight using long white plastic pipes in a backyard setting.", "task": "AttributeRecognition", "clean_prompt": "Two men are engaged in a playful sword fight using long white plastic pipes in a backyard setting.", "clean_property": {"obj": "plastic pipe", "attribute": "white"}, "target_prompt": "Two men are engaged in a playful sword fight using long blue plastic pipes in a backyard setting.", "target_property": {"obj": "plastic pipe", "attribute": "blue"}, "evaluation_question": "Are the plastic pipes being used in the sword fight **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are engaged in a playful sword fight using long white plastic pipes in a backyard setting. ZRCEZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/042bca8f9e714a52a51e5c54f57946f3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03a73572a8a74f8aacfaed2f79630757", "source": "vatex", "video_id": "0JezC4KDo-k_000011_000021", "video_description": "A female athlete is lifting a heavy barbell above her head in a weightlifting competition, while a crowd watches and cheers.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a clean and jerk with a barbell in a weightlifting competition.", "clean_property": {"obj": "athlete", "action": "clean and jerk", "target": "barbell"}, "target_prompt": "An athlete lifting a dumbbell in a weightlifting competition.", "target_property": {"obj": "athlete", "action": "lifting", "target": "dumbbell"}, "evaluation_question": "Is the athlete **performing a clean and jerk** with a barbell?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a clean and jerk with a barbell in a weightlifting competition. *FCUV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14d661b300664cad9a83b17a0ec63943.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b00c4dcf109643faaf4b79c4ce4d370a", "source": "vatex", "video_id": "Wv-MexRjdwA_000030_000040", "video_description": "A man is using a special ergonomic paint roller to apply yellow paint to a wall while a woman talks about the process.", "task": "AttributeRecognition", "clean_prompt": "A man is using a special ergonomic paint roller to apply yellow paint to a wall while a woman talks about the process.", "clean_property": {"obj": "wall", "attribute": "yellow"}, "target_prompt": "A man is using a special ergonomic paint roller to apply blue paint to a wall while a woman talks about the process.", "target_property": {"obj": "wall", "attribute": "blue"}, "evaluation_question": "Is the wall being painted **yellow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using a special ergonomic paint roller to apply yellow paint to a wall while a woman talks about the process. FE((T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/58c8352eb0da43c19ad3f80d9d73d50a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e0fc15b5ca904538a69ef3a28b23e9d7", "source": "vatex", "video_id": "qeca1J0NVqo_000533_000543", "video_description": "A young boy is sitting on the floor demonstrating and explaining how to solve a Rubik's Cube.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on the floor demonstrating and explaining how to solve a Rubik's Cube.", "clean_property": {"obj": "Rubik's Cube"}, "target_prompt": "A young boy is sitting on the floor demonstrating and explaining how to solve a puzzle box.", "target_property": {"obj": "puzzle box"}, "evaluation_question": "Is the object being demonstrated a **Rubik's Cube**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting on the floor demonstrating and explaining how to solve a Rubik's Cube. FE)G1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8968c56ca920493bac4b7cd9a72b0f47.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f08119b2c3ad48a686c9a9b5f3dca86a", "source": "vatex", "video_id": "-qELlCDoieM_000024_000034", "video_description": "Three people wearing large, colorful head coverings and costumes are playing a dancing video game on an arcade machine.", "task": "SpatialUnderstanding", "clean_prompt": "An arcade machine to the right of a person playing a dancing video game.", "clean_property": {"obj_1": "arcade machine", "relation": "right of", "obj_2": "person"}, "target_prompt": "An arcade machine to the left of a person playing a dancing video game.", "target_property": {"obj_1": "arcade machine", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the arcade machine to the **right** of a person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An arcade machine to the right of a person playing a dancing video game. GNPC(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/96bd4bc04d5e47519e7c458996476b36.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "86d66010e5d64a3d8f2f627cc1711222", "source": "vatex", "video_id": "F-pS1w5dX3U_000014_000024", "video_description": "A man demonstrates how to install and use a Kaboom system in a toilet tank, including unboxing and attaching the device.", "task": "ActionRecognition", "clean_prompt": "A person unboxing a Kaboom system.", "clean_property": {"obj": "person", "action": "unboxing", "target": "kaboom system"}, "target_prompt": "A person throwing away a Kaboom system.", "target_property": {"obj": "person", "action": "throwing away", "target": "Kaboom system"}, "evaluation_question": "Is the person **unboxing** the Kaboom system?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person unboxing a Kaboom system. TYD;N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e8e609a0ca894f85935e986540abf0c5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9e0394bb129a48e2bb2c6c39d7963894", "source": "vatex", "video_id": "7cz4ipaR5nA_000393_000403", "video_description": "A man and a woman are outside arranging and transplanting various colorful flowers into pots, discussing color themes and giving a demonstration.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a pot.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "pot"}, "target_prompt": "A person standing to the right of a pot.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "pot"}, "evaluation_question": "Is the person to the **left** of the pot?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a pot. );&&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfc7f3d136b64a4c859c116114095ea3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4d5723754748406e8821c33fd3d7e56e", "source": "vatex", "video_id": "51jbjkaduZg_000000_000010", "video_description": "A man is ironing a garment on a bed, talking to a child, and accidentally burns his hand with the iron.", "task": "ActionRecognition", "clean_prompt": "A man ironing a garment on a bed while talking to a child.", "clean_property": {"obj": "man", "action": "ironing", "target": "garment"}, "target_prompt": "A man folding a garment on a bed while talking to a child.", "target_property": {"obj": "man", "action": "folding", "target": "garment"}, "evaluation_question": "Is the man **ironing** a garment?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man ironing a garment on a bed while talking to a child. F'');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61a54efdea6a4757a509036f910b5696.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "acf7bfe4e70b4ff58563073656ac18e0", "source": "vatex", "video_id": "dj7Uss0XyB4_000021_000031", "video_description": "A person is demonstrating how to cook eggs using a pan on low heat with a lid, with written instructions appearing on the screen.", "task": "ActionRecognition", "clean_prompt": "A person cooking eggs in a pan on low heat with a lid, with written instructions appearing on the screen.", "clean_property": {"obj": "person", "action": "cooking egg", "target": "egg"}, "target_prompt": "A person frying eggs in a pan on high heat with no lid, with written instructions appearing on the screen.", "target_property": {"obj": "person", "action": "frying egg", "target": "egg"}, "evaluation_question": "Is the person **cooking** eggs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cooking eggs in a pan on low heat with a lid, with written instructions appearing on the screen. >7SBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5815e413a82341debee4d2279f1a49f0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "53c7feb2d94d4de1812926003ee439eb", "source": "vatex", "video_id": "5hFBORyDwnw_000264_000274", "video_description": "A sports event is taking place in a large stadium with many spectators. Two teams are playing a game on the field, with people watching and recording the match.", "task": "Counting", "clean_prompt": "Seven coaches discussing strategies in a large stadium during a sports event.", "clean_property": {"obj": "coach", "count": "seven"}, "target_prompt": "Four coaches discussing strategies in a large stadium during a sports event.", "target_property": {"obj": "coach", "count": "four"}, "evaluation_question": "Are there exactly **seven** coaches discussing strategies in the stadium?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven coaches discussing strategies in a large stadium during a sports event. BS>D;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b971a1f313234128935162a241116d43.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d362a4e735044aa483286586b1f9c067", "source": "vatex", "video_id": "Z6pElcamfJE_000004_000014", "video_description": "A bartender is at a bar attempting to mix a drink using a cocktail shaker. During the process, the top of the shaker pops off, causing the drink to spill on him, and the crowd laughs.", "task": "Counting", "clean_prompt": "Two bartenders at a bar attempting to mix drinks using cocktail shakers.", "clean_property": {"obj": "bartender", "count": "two"}, "target_prompt": "A bartender at a bar attempting to mix a drink using a cocktail shaker.", "target_property": {"obj": "bartender", "count": "one"}, "evaluation_question": "Are there exactly **two** bartenders at the bar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two bartenders at a bar attempting to mix drinks using cocktail shakers. FEY=#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f0c11254b1e74d269d2976d0ce148e54.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "79e17f771b6e47be9ae0577f348a334e", "source": "vatex", "video_id": "5pjVeypYhgI_000000_000010", "video_description": "A young boy is jumping around a campsite while eating a hot dog, with an adult male nearby. They are near a campfire.", "task": "Counting", "clean_prompt": "Seven adults are gathered around a campfire, enjoying a picnic while a young boy jumps around eating a hot dog.", "clean_property": {"obj": "adult", "count": "seven"}, "target_prompt": "Three adults are gathered around a campfire, enjoying a picnic while a young boy jumps around eating a hot dog.", "target_property": {"obj": "adult", "count": "three"}, "evaluation_question": "Are there exactly **seven** adults around the campfire?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven adults are gathered around a campfire, enjoying a picnic while a young boy jumps around eating a hot dog. >L#FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/290264c25edb49178d6bef23368a7930.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c4fadc41dcb641019cf05a92feae90c1", "source": "vatex", "video_id": "WGv6N0I2dqE_000833_000843", "video_description": "A young man is sitting in a chair, showing and describing the marks and scratches on his leg after having hair removed by waxing.", "task": "Counting", "clean_prompt": "Three people sitting in chairs, discussing the marks and scratches on their legs after waxing.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting in a chair, showing and describing the marks and scratches on their leg after waxing.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting in chairs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people sitting in chairs, discussing the marks and scratches on their legs after waxing. VPZFC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1b0609a330c4b5fb4bdc2dc6a4760c4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aa17296dcec54ed28e06433bf9e076e9", "source": "vatex", "video_id": "WASSmFKNVc4_000189_000199", "video_description": "A woman with pink hair and glasses is seductively licking and sucking on a lollipop while music plays in the background.", "task": "ActionRecognition", "clean_prompt": "A person sucking on a lollipop while music plays in the background.", "clean_property": {"obj": "person", "action": "sucking lolly", "target": null}, "target_prompt": "A person eating ice cream while music plays in the background.", "target_property": {"obj": "person", "action": "eating ice cream", "target": null}, "evaluation_question": "Is the person **sucking** on a lollipop?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sucking on a lollipop while music plays in the background. VTBP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/80b8d98b094742a8938714a590c70dd5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a1ba125e8d1409b99e1d2891b500263", "source": "vatex", "video_id": "Z_xtupU1Orw_000000_000010", "video_description": "A group of young people are outside in the snow, engaging in a snowball fight, running, laughing, and shouting.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a snowball.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "snowball"}, "target_prompt": "A person standing to the left of a snowball.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "snowball"}, "evaluation_question": "Is the person to the **right** of a snowball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a snowball. ULWP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e0411682c2484e8d91c0a30e47ffeab0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90c6a8fbdebb4535bb0b25fb0ca105bd", "source": "vatex", "video_id": "kL2QzTURpYw_000011_000021", "video_description": "A young man in swimwear is at the beach, skipping rocks across the water.", "task": "AttributeRecognition", "clean_prompt": "A person wearing swim shorts is at the beach, skipping rocks across the water.", "clean_property": {"obj": "person", "attribute": "wearing swim shorts"}, "target_prompt": "A person wearing a wetsuit is at the beach, skipping rocks across the water.", "target_property": {"obj": "person", "attribute": "wearing a wetsuit"}, "evaluation_question": "Is the person wearing **swim shorts**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing swim shorts is at the beach, skipping rocks across the water. FEY3$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/621c82586c034a348b5a6b1cca39c8c7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0b765f44ca4947cf8b1fff247095280d", "source": "vatex", "video_id": "1rm5FMiDwH4_000174_000184", "video_description": "A woman is holding a dog on a table while another person bandages the dog's leg.", "task": "ObjectRecognition", "clean_prompt": "A veterinarian bandaging a dog's leg on a table.", "clean_property": {"obj": "veterinarian"}, "target_prompt": "A chef preparing a meal in a kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **veterinarian**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A veterinarian bandaging a dog's leg on a table. G)!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/72c6ff5d01654ade89f7cc3dac6147fd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e713a45502c4c198c847ef4d18ad157", "source": "vatex", "video_id": "UgENvE0ySvo_000027_000037", "video_description": "A man is riding a red motorcycle through a shallow body of water, such as a river or stream, while laughing.", "task": "Counting", "clean_prompt": "A man is riding a red motorcycle through a shallow body of water, such as a river or stream, while laughing with three splashes of water around him.", "clean_property": {"obj": "water", "count": "three"}, "target_prompt": "A man is riding a red motorcycle through a shallow body of water, such as a river or stream, while laughing with one splash of water around him.", "target_property": {"obj": "water", "count": "one"}, "evaluation_question": "Are there exactly **three** splashes of water around the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is riding a red motorcycle through a shallow body of water, such as a river or stream, while laughing with three splashes of water around him. +BSIT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/792e59a47ce047a49f2d421826db9a6e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2abd962c593947748cb031abd4043d0d", "source": "vatex", "video_id": "-ca2coODeew_000000_000010", "video_description": "A man is using a power washer to clean various parts of a large vehicle, including the front and back bumpers, at an auto service station.", "task": "Counting", "clean_prompt": "Three people are using a power washer to clean various parts of a large vehicle at an auto service station.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is using a power washer to clean a large vehicle at an auto service station.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people using the power washer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are using a power washer to clean various parts of a large vehicle at an auto service station. >BC$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e3e761e284a047db8ab9e04e5271a528.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd3793fab0ff45838a5561d05a676db4", "source": "vatex", "video_id": "t6BDCkIHqzQ_000014_000024", "video_description": "A skier is skiing downhill on a snowy mountain, maneuvering between green and yellow flags at high speed.", "task": "AttributeRecognition", "clean_prompt": "A skier maneuvering between green and yellow flags while skiing downhill on a snowy mountain.", "clean_property": {"obj": "flags", "attribute": "green and yellow"}, "target_prompt": "A skier maneuvering between red and blue flags while skiing downhill on a snowy mountain.", "target_property": {"obj": "flags", "attribute": "red and blue"}, "evaluation_question": "Are the flags green and yellow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skier maneuvering between green and yellow flags while skiing downhill on a snowy mountain. ))*E&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3eadb12524ce40898a5049f612da7584.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8f9375247784dcfbf2ad1df877d3abb", "source": "vatex", "video_id": "2YGIhoMqYwM_000015_000025", "video_description": "A woman is demonstrating to a child how to tie a shoelace on a red sneaker.", "task": "AttributeRecognition", "clean_prompt": "A woman is demonstrating to a child how to tie a shoelace on a red sneaker.", "clean_property": {"obj": "sneaker", "attribute": "red"}, "target_prompt": "A woman is demonstrating to a child how to tie a shoelace on a blue sneaker.", "target_property": {"obj": "sneaker", "attribute": "blue"}, "evaluation_question": "Is the sneaker **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating to a child how to tie a shoelace on a red sneaker. HLXIV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a05380a9dc94b7a896d89c298544028.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "946de5914f8241b59164e5c036b845b8", "source": "vatex", "video_id": "t-aPsebmI0Q_000084_000094", "video_description": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen or similar item.", "task": "ObjectRecognition", "clean_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen.", "clean_property": {"obj": "pen"}, "target_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a drumstick.", "target_property": {"obj": "drumstick"}, "evaluation_question": "Is the boy using a **pen** to create beats?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy is sitting at a table, creating rhythmic beats by tapping and scraping with a pen. ?W0DE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be85e53126be4db78bf51d3e14494498.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "adb44fb8c31f4215aaae0aa6484eba09", "source": "vatex", "video_id": "u9b8tQH6B7U_000073_000083", "video_description": "A woman is at a salon getting her nails done, including measuring and cleaning her fingernails.", "task": "Counting", "clean_prompt": "A woman is getting her nails done by six manicurists at a salon.", "clean_property": {"obj": "manicurist", "count": "six"}, "target_prompt": "A woman is getting her nails done by two manicurists at a salon.", "target_property": {"obj": "manicurist", "count": "two"}, "evaluation_question": "Are there exactly **six** manicurists at the salon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is getting her nails done by six manicurists at a salon. FE7@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eaa23289c0b140e3989d07b6b78ab9ae.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4472ade391eb409a95122a7c4fa22a14", "source": "vatex", "video_id": "rJk8fad5ZnU_000007_000017", "video_description": "A man is demonstrating and explaining how to use a pottery wheel to shape clay into pottery items like jars and bowls.", "task": "SpatialUnderstanding", "clean_prompt": "Clay farther from the camera than a person demonstrating pottery.", "clean_property": {"obj_1": "clay", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "Clay closer to the camera than a person demonstrating pottery.", "target_property": {"obj_1": "clay", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the clay **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Clay farther from the camera than a person demonstrating pottery. U%0@K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49a97b953b634bcea04bc16ad4398a58.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ea0488d39b994e63a024a54577f50178", "source": "vatex", "video_id": "lF3NtBTv2PA_000005_000015", "video_description": "A man is demonstrating a card trick by shuffling a deck of cards with one hand while music plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a deck of cards.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "deck of cards"}, "target_prompt": "A person standing to the right of a deck of cards.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "deck of cards"}, "evaluation_question": "Is the person to the **left** of a deck of cards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a deck of cards. LY-.J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ff00b41a2c43460e8f50fb0343e5c5f4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "429808d672344c03b72f3c0c4d59b58b", "source": "vatex", "video_id": "s8QgAwJxG7A_000011_000021", "video_description": "Two hockey teams are playing a competitive ice hockey match in an indoor arena with a crowd watching.", "task": "SpatialUnderstanding", "clean_prompt": "A hockey player farther from the camera than the crowd in an indoor arena.", "clean_property": {"obj_1": "hockey player", "relation": "farther from the camera than", "obj_2": "crowd"}, "target_prompt": "A hockey player closer to the camera than the crowd in an indoor arena.", "target_property": {"obj_1": "hockey player", "relation": "closer to the camera than", "obj_2": "crowd"}, "evaluation_question": "Is the hockey player **farther from the camera than** the crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A hockey player farther from the camera than the crowd in an indoor arena. FE&ZL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1806fdcc4e244a7ac90159af05489e1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8fe522f34164f2396218b5cef021f1b", "source": "vatex", "video_id": "5mgFRyRigvo_000012_000022", "video_description": "A young woman is sitting indoors, wearing green headphones, and playing a tune on a piccolo.", "task": "ObjectRecognition", "clean_prompt": "A young woman sitting indoors, wearing green headphones, and playing a tune on a piccolo.", "clean_property": {"obj": "person"}, "target_prompt": "A cat sitting indoors, playing with a ball of yarn.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman sitting indoors, wearing green headphones, and playing a tune on a piccolo. )!G*D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/253461b13f5e462fa3ac5fb15f5ed733.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b56b700644f84120980eed10b2f26253", "source": "vatex", "video_id": "R4Pyo8HH3HE_000015_000025", "video_description": "A person is climbing an ice wall using ice picks and snow gear, occasionally taking a rest.", "task": "ObjectRecognition", "clean_prompt": "A person climbing an ice wall using ice picks and snow gear, occasionally taking a rest.", "clean_property": {"obj": "ice pick"}, "target_prompt": "A person surfing on a beach with a surfboard.", "target_property": {"obj": "surfboard"}, "evaluation_question": "Is the person using an **ice pick** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person climbing an ice wall using ice picks and snow gear, occasionally taking a rest. M&FE7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/32f905406f494527927038ecc86e99e5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6592131d0b144c3ca66d0b0f6e5ed775", "source": "vatex", "video_id": "pFxLZU_uH40_000176_000186", "video_description": "A man is recording a promotional video about wine tasting, discussing wine pairings, and drinking wine at a table.", "task": "Counting", "clean_prompt": "A man is discussing wine pairings while holding two wine glasses at a table.", "clean_property": {"obj": "wine glass", "count": "two"}, "target_prompt": "A man is discussing wine pairings while holding four wine glasses at a table.", "target_property": {"obj": "wine glass", "count": "four"}, "evaluation_question": "Are there exactly **two** wine glasses on the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is discussing wine pairings while holding two wine glasses at a table. NG0BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5cf1c2cb7f8442dda40d1bb4c858dd18.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9e8d5e93038d415ba172e2d3862d1774", "source": "vatex", "video_id": "EadheBff1P0_000000_000010", "video_description": "A person is breaking a chocolate chip cookie in half to show its gooey caramel interior while talking about it.", "task": "Counting", "clean_prompt": "Three people breaking chocolate chip cookies in half to show their gooey caramel interiors while talking about it.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person breaking a chocolate chip cookie in half to show its gooey caramel interior while talking about it.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people breaking cookies?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people breaking chocolate chip cookies in half to show their gooey caramel interiors while talking about it. !');/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba738c8aaf014976a86a1396371276b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4759fe5efddc4e8cb6fb010bf9b13d7d", "source": "vatex", "video_id": "g3A5GvOgGqo_000000_000010", "video_description": "A group of people are in a large room. A young man in a grey top and blue jeans is performing, laughing, and pretending to cry while music plays in the background. He is jumping around and making distressed gestures.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a room, performing and making gestures.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "room"}, "target_prompt": "A person inside a room, performing and making gestures.", "target_property": {"obj_1": "person", "relation": "inside", "obj_2": "room"}, "evaluation_question": "Is the person **above** the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person above a room, performing and making gestures. F|\u00b7=2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/142a7bf85ee44421b0e289fd702f2205.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7abb497d9854c249e41c87cc774f55f", "source": "vatex", "video_id": "9qtZYavEN-o_000090_000100", "video_description": "A person is lying on a blue mat, demonstrating a leg raise exercise by lifting their legs over their head while keeping their back and arms on the floor.", "task": "Counting", "clean_prompt": "A person is lying on three blue mats, demonstrating a leg raise exercise by lifting their legs over their head while keeping their back and arms on the floor.", "clean_property": {"obj": "mat", "count": "three"}, "target_prompt": "A person is lying on one blue mat, demonstrating a leg raise exercise by lifting their legs over their head while keeping their back and arms on the floor.", "target_property": {"obj": "mat", "count": "one"}, "evaluation_question": "Are there exactly **three** blue mats being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is lying on three blue mats, demonstrating a leg raise exercise by lifting their legs over their head while keeping their back and arms on the floor. 3-;BJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b867c0efa46d45d69345fa58ef9a8fd9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3bea24de26bf4eceb6a4deb9aa6eca77", "source": "vatex", "video_id": "m2_qmRnjICE_000017_000027", "video_description": "A man in a black hoodie and trousers is picking apples in an orchard, carefully placing them in a bag and then into a wooden crate, while a narrator explains the process.", "task": "Counting", "clean_prompt": "Two people are picking apples in an orchard, carefully placing them in bags and then into wooden crates, while a narrator explains the process.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is picking apples in an orchard, carefully placing them in a bag and then into a wooden crate, while a narrator explains the process.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people picking apples in the orchard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are picking apples in an orchard, carefully placing them in bags and then into wooden crates, while a narrator explains the process. W%!'B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/92b4b04f59fc4113bd058ce7fbdd927e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3059044fabdb4e9896e689c883f9066e", "source": "vatex", "video_id": "r4sYfEcGrgg_000004_000014", "video_description": "A female athlete is participating in a javelin throw event at an outdoor track. She runs and throws the javelin with force while a group of people watches.", "task": "ObjectRecognition", "clean_prompt": "A female athlete is throwing a javelin while spectators watch her performance.", "clean_property": {"obj": "spectators"}, "target_prompt": "A female athlete is throwing a javelin while coaches observe her performance.", "target_property": {"obj": "coaches"}, "evaluation_question": "Are there **spectators** watching the athlete in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female athlete is throwing a javelin while spectators watch her performance. )*R%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e05139c90117480b8cf9de07c58c40a4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "459fc6be4c5b4619a95b4c34f82bad22", "source": "vatex", "video_id": "Xbg8y5fHOQw_000065_000075", "video_description": "A young woman is seated, talking on her cell phone while adjusting and playing with her hair.", "task": "Counting", "clean_prompt": "Two people are seated, with one talking on her cell phone while adjusting and playing with her hair.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is seated, talking on her cell phone while adjusting and playing with her hair.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people seated?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are seated, with one talking on her cell phone while adjusting and playing with her hair. UD.K(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/885d980a79b54f60bd11ec2c42614fb7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ba45131b3bd4c1c8d1c25a0db8c0d44", "source": "vatex", "video_id": "BnVdrJvsPsU_000213_000223", "video_description": "A woman is demonstrating and explaining how to apply eyeliner to the outer edge of her eyelid.", "task": "ActionRecognition", "clean_prompt": "A person putting on eyeliner while explaining the process.", "clean_property": {"obj": "person", "action": "putting on eyeliner", "target": null}, "target_prompt": "A person removing eyeliner while explaining the process.", "target_property": {"obj": "person", "action": "removing eyeliner", "target": null}, "evaluation_question": "Is the person **putting on** eyeliner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person putting on eyeliner while explaining the process. R)7TV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d910224c01764e4d876093549ef26f33.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46a1c674b1a64515a621e47e5bacad54", "source": "vatex", "video_id": "zfBWtZ7phDc_000002_000012", "video_description": "An older woman in a red top sneezes loudly and then walks into another room while a younger woman laughs.", "task": "Counting", "clean_prompt": "Three older women in red tops are chatting and laughing together.", "clean_property": {"obj": "older woman", "count": "three"}, "target_prompt": "An older woman in a red top is sitting alone and reading a book.", "target_property": {"obj": "older woman", "count": "one"}, "evaluation_question": "Are there exactly **three** older women in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three older women in red tops are chatting and laughing together. O7Z*D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/323c3174d32e4dfc9cdde664ecdb09a6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d42381534d5d4a1685e759b6d9300079", "source": "vatex", "video_id": "DauHQApK4po_000023_000033", "video_description": "A group of children, including a teenage boy, are outside on a road or sidewalk, breaking an electronic device by stomping, kicking, and throwing it while others watch and react.", "task": "ActionRecognition", "clean_prompt": "A child smashing a device on the sidewalk.", "clean_property": {"obj": "child", "action": "smashing", "target": "device"}, "target_prompt": "A child throwing a balloon on the sidewalk.", "target_property": {"obj": "child", "action": "throwing", "target": "balloon"}, "evaluation_question": "Is the child **smashing** a device?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child smashing a device on the sidewalk. ROWQD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad345f0d9cd44df1a8d147860f1b2f51.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7f9bf51e7e714845b8fe9c3847941fde", "source": "vatex", "video_id": "31rIxx-7KvQ_000040_000050", "video_description": "A man is indoors using a large belt sander machine to sharpen a knife blade.", "task": "AttributeRecognition", "clean_prompt": "A man using a large belt sander machine to sharpen a knife blade indoors.", "clean_property": {"obj": "machine", "attribute": "belt sander"}, "target_prompt": "A man using a large table saw machine to cut wood indoors.", "target_property": {"obj": "machine", "attribute": "table saw"}, "evaluation_question": "Is the machine being used a **belt sander**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a large belt sander machine to sharpen a knife blade indoors. &UFI(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f5714311cde443098a97ea19ec12b9c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "68ade61010be4dbcbb6b9a12c55bc872", "source": "vatex", "video_id": "SCSPFbJb1zA_000028_000038", "video_description": "A man attempts to ride a four-wheeled vehicle across a body of water, gets stuck, and dismounts while people off-camera comment.", "task": "SpatialUnderstanding", "clean_prompt": "A vehicle positioned to the left of a body of water.", "clean_property": {"obj_1": "vehicle", "relation": "left of", "obj_2": "water"}, "target_prompt": "A vehicle positioned to the right of a body of water.", "target_property": {"obj_1": "vehicle", "relation": "right of", "obj_2": "water"}, "evaluation_question": "Is the vehicle to the **left** of the body of water?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A vehicle positioned to the left of a body of water. ;EC\u00b7#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/506012fc75194e6ba82b1c9d80ba9faa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8c9272e830594ce8bba13538293da024", "source": "vatex", "video_id": "Zpb1kjnrbKc_001303_001313", "video_description": "A group of people are walking in a single file line down stairs inside a cave, holding onto a handrail.", "task": "AttributeRecognition", "clean_prompt": "A group of people walking down stairs inside a cave, holding onto a steel handrail.", "clean_property": {"obj": "handrail", "attribute": "steel"}, "target_prompt": "A group of people walking down stairs inside a cave, holding onto a wooden handrail.", "target_property": {"obj": "handrail", "attribute": "wooden"}, "evaluation_question": "Is the handrail made of **steel**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people walking down stairs inside a cave, holding onto a steel handrail. )?G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c20c8e091ed84a92b13d2b60fb5ba196.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "445d3277d2d24fcba8b6b7916ecab64b", "source": "vatex", "video_id": "8PooUyGdc20_000006_000016", "video_description": "A person is using a razor blade to cut and tear off very long fingernails.", "task": "ActionRecognition", "clean_prompt": "A person cutting their long fingernails with a razor blade.", "clean_property": {"obj": "person", "action": "cutting nails", "target": "fingernail"}, "target_prompt": "A person painting their fingernails with bright colors.", "target_property": {"obj": "person", "action": "painting nails", "target": "fingernail"}, "evaluation_question": "Is the person **cutting** their fingernails?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cutting their long fingernails with a razor blade. =7EET", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5482f63b4d174e09aa1fa098b9d516f4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ee7f7f68b3a4bc6af8af3f3dca3223d", "source": "vatex", "video_id": "JFpWn6Y2oxo_000000_000010", "video_description": "A person wearing a harness is climbing an indoor rock climbing wall with red and black grips, while a woman gives instructions from below.", "task": "SpatialUnderstanding", "clean_prompt": "A rock wall farther from the camera than the instructor.", "clean_property": {"obj_1": "rock wall", "relation": "farther from the camera than", "obj_2": "instructor"}, "target_prompt": "A rock wall closer to the camera than the instructor.", "target_property": {"obj_1": "rock wall", "relation": "closer to the camera than", "obj_2": "instructor"}, "evaluation_question": "Is the rock wall **farther from the camera than** the instructor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rock wall farther from the camera than the instructor. @!T@F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a7090d9bd1a4e0f9eeb5abda40c5720.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5ede2b7e24534330af0594b57ba37de6", "source": "vatex", "video_id": "_kQxazaUhMk_000001_000011", "video_description": "A person is carefully creating an oil-based painting using a small, fine-tipped paintbrush to add details and blend colors on a canvas.", "task": "Counting", "clean_prompt": "Four people are carefully creating an oil-based painting using small, fine-tipped paintbrushes to add details and blend colors on canvases.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is carefully creating an oil-based painting using a small, fine-tipped paintbrush to add details and blend colors on a canvas.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people creating paintings?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are carefully creating an oil-based painting using small, fine-tipped paintbrushes to add details and blend colors on canvases. FEY2@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6ba51dbf4074400a6ab6dad41c4aa50.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5f1045255e184ddd965445e5b4a3d309", "source": "vatex", "video_id": "w8LxZaGobGE_000017_000027", "video_description": "A woman performs a series of dives and flips off a diving board into a swimming pool during a diving competition, with spectators watching.", "task": "ObjectRecognition", "clean_prompt": "A woman performs a series of dives and flips off a diving board into a swimming pool during a diving competition.", "clean_property": {"obj": "pool"}, "target_prompt": "A woman performs a series of dives and flips off a diving board into the ocean during a competition.", "target_property": {"obj": "ocean"}, "evaluation_question": "Is the woman diving into a **pool**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman performs a series of dives and flips off a diving board into a swimming pool during a diving competition. HSIT4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb0da1a6aa6246a6b8e7a1a0cf03f575.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1f47d6e2fbf48848dfa3cec47532e7e", "source": "vatex", "video_id": "BeevuXU4xSM_000000_000010", "video_description": "A man is practicing shot put throwing techniques, spinning around and throwing the shot put in a marked area outdoors.", "task": "ObjectRecognition", "clean_prompt": "A man practicing shot put throwing techniques outdoors.", "clean_property": {"obj": "shot put"}, "target_prompt": "A man practicing javelin throwing techniques outdoors.", "target_property": {"obj": "javelin"}, "evaluation_question": "Is the man practicing **shot put** throwing techniques?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man practicing shot put throwing techniques outdoors. RV!@N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/82b34275c2024828b9184d523fd2bac1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7a206ee6d9d42dba95010300d8ae8a3", "source": "vatex", "video_id": "m9n5SLRXIKw_000015_000025", "video_description": "Two teenage boys are practicing a hip hop dance routine in a dance studio with a gridded floor.", "task": "AttributeRecognition", "clean_prompt": "Two teenage boys are practicing a hip hop dance routine on a floor with white tiles in a dance studio.", "clean_property": {"obj": "floor", "attribute": "white tiles"}, "target_prompt": "Two teenage boys are practicing a hip hop dance routine on a floor with black carpet in a dance studio.", "target_property": {"obj": "floor", "attribute": "black carpet"}, "evaluation_question": "Is the floor made of **white tiles**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teenage boys are practicing a hip hop dance routine on a floor with white tiles in a dance studio. SL(1|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de7f3c276953401b90574913ea93265e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2714c4c6843742ce902cb810af7f520d", "source": "vatex", "video_id": "6ryHWDodCgA_000017_000027", "video_description": "A boy is riding a hoverboard with lights in a living room while interacting with a girl who is sitting on a bench.", "task": "ActionRecognition", "clean_prompt": "A boy hoverboarding in a living room.", "clean_property": {"obj": "boy", "action": "hoverboarding", "target": null}, "target_prompt": "A boy falling in a living room.", "target_property": {"obj": "boy", "action": "falling", "target": null}, "evaluation_question": "Is the boy **hoverboarding**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy hoverboarding in a living room. ;JAB$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dbcae28d9b014216a8bb029628d94587.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2a92d226e5524e42b7de7a74d805e0d8", "source": "vatex", "video_id": "tIGde0O8Brk_000000_000010", "video_description": "A man performs a high jump over a bar, landing on a cushioned mat in an outdoor park setting.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a high jump in an outdoor park.", "clean_property": {"obj": "athlete", "action": "high jump", "target": null}, "target_prompt": "An athlete performing a long jump in an outdoor park.", "target_property": {"obj": "athlete", "action": "long jump", "target": null}, "evaluation_question": "Is the athlete **performing a high jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a high jump in an outdoor park. RP8OF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0958c7735a164fef905413ffe8198f18.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9c3738906c6643eab82d840d1ad5471c", "source": "vatex", "video_id": "XBSTK759bG8_000156_000166", "video_description": "A man in a gym demonstrates various stretching exercises against a wall while another man provides instructions.", "task": "Counting", "clean_prompt": "A man demonstrating stretching exercises against a wall with two other men providing instructions.", "clean_property": {"obj": "person_1", "count": "three"}, "target_prompt": "A man demonstrating stretching exercises against a wall alone.", "target_property": {"obj": "person_1", "count": "one"}, "evaluation_question": "Are there exactly **three** men in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating stretching exercises against a wall with two other men providing instructions. NGFE@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e9b0158a8564ebca356fefc0b956d22.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6421a46b8e37470c9a57f8fea40acebe", "source": "vatex", "video_id": "Ik_rwv6Rpkk_000069_000079", "video_description": "A woman is demonstrating how to fry thin slices of potatoes in boiling oil to make homemade chips on a stove top.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a pot.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "pot"}, "target_prompt": "A person standing to the right of a pot.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "pot"}, "evaluation_question": "Is the person to the **left** of the pot?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a pot. );&&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6d3f71c363da4df6a643d76ffb604821.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5cd843eb5c014f19bf40502c7c6986a1", "source": "vatex", "video_id": "VdQRM6elhno_000003_000013", "video_description": "A young boy is practicing high kicks in front of a camera, occasionally giving a thumbs-up.", "task": "SpatialUnderstanding", "clean_prompt": "A camera positioned to the left of a boy practicing high kicks.", "clean_property": {"obj_1": "camera", "relation": "left of", "obj_2": "boy"}, "target_prompt": "A camera positioned to the right of a boy practicing high kicks.", "target_property": {"obj_1": "camera", "relation": "right of", "obj_2": "boy"}, "evaluation_question": "Is the camera to the **left** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A camera positioned to the left of a boy practicing high kicks. .FEY)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18faf8defbcd4eb29e32c187d8213f93.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dffe2d47b2704311857efa789dbb9db3", "source": "vatex", "video_id": "OGQ32IHOmXo_000025_000035", "video_description": "A woman demonstrates how to fold a jacket and pack it in a suitcase to prevent wrinkling, then transfers it to a hanger.", "task": "Counting", "clean_prompt": "A woman demonstrates how to fold a jacket and pack it in three suitcases to prevent wrinkling, then transfers it to a hanger.", "clean_property": {"obj": "suitcase", "count": "three"}, "target_prompt": "A woman demonstrates how to fold a jacket and pack it in one suitcase to prevent wrinkling, then transfers it to a hanger.", "target_property": {"obj": "suitcase", "count": "one"}, "evaluation_question": "Are there exactly **three** suitcases being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to fold a jacket and pack it in three suitcases to prevent wrinkling, then transfers it to a hanger. )AQ|/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfec95dd110e4db992d78ec675d3745f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7df3b5de8e864360b86cdd3a42b29c96", "source": "vatex", "video_id": "PS7563aUphM_000000_000010", "video_description": "A man is applying lotion to a tattoo on his forearm using his finger.", "task": "AttributeRecognition", "clean_prompt": "A man applying white lotion to a tattoo on his forearm using his finger.", "clean_property": {"obj": "lotion", "attribute": "white"}, "target_prompt": "A man applying blue lotion to a tattoo on his forearm using his finger.", "target_property": {"obj": "lotion", "attribute": "blue"}, "evaluation_question": "Is the lotion being applied **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man applying white lotion to a tattoo on his forearm using his finger. U%|0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/056c91c8ff0f4503a62f7b61b90ba39e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3788e2c25f541a1a7269f5429cf04b3", "source": "vatex", "video_id": "lgUGVQ_jRos_000028_000038", "video_description": "Two young boys are smashing a broken guitar on a hard surface while a third boy watches in a park setting.", "task": "ActionRecognition", "clean_prompt": "A boy smashing a broken guitar on a hard surface in a park.", "clean_property": {"obj": "boy", "action": "smashing", "target": "guitar"}, "target_prompt": "A boy kicking a soccer ball on a grassy field in a park.", "target_property": {"obj": "boy", "action": "kicking", "target": "soccer ball"}, "evaluation_question": "Is the boy **smashing** a guitar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy smashing a broken guitar on a hard surface in a park. LY2PM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35b01bcea6d346e9be2ef9f8c88a7f74.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "698a17d4a62e47c18aff68e2a9412881", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a yoga mat in a room.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a yoga mat in a room.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person closer to the camera than the yoga mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a yoga mat in a room. FE'((", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e33d0a1a188d4dad8912a235aff8a9da.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7f5d812f418a495bad7b8566990f2305", "source": "vatex", "video_id": "5_QfMBXvkXE_000023_000033", "video_description": "A woman in her house demonstrates and explains how to safely use an iron, including checking the temperature and avoiding burns.", "task": "AttributeRecognition", "clean_prompt": "A blind person in her house demonstrates and explains how to safely use an iron, including checking the temperature and avoiding burns.", "clean_property": {"obj": "person", "attribute": "blind"}, "target_prompt": "A deaf person in her house demonstrates and explains how to safely use an iron, including checking the temperature and avoiding burns.", "target_property": {"obj": "person", "attribute": "deaf"}, "evaluation_question": "Is the person **blind** while demonstrating the use of the iron?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A blind person in her house demonstrates and explains how to safely use an iron, including checking the temperature and avoiding burns. &FE\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d391b703cfab43799e2920f0a92c1b6f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9a282d7e4994144a02a156ad1ef00af", "source": "vatex", "video_id": "u9b8tQH6B7U_000073_000083", "video_description": "A woman is at a salon getting her nails done, including measuring and cleaning her fingernails.", "task": "AttributeRecognition", "clean_prompt": "A woman is at a salon getting her nails done with metal nail tools, including measuring and cleaning her fingernails.", "clean_property": {"obj": "nail tools", "attribute": "metal"}, "target_prompt": "A woman is at a salon getting her nails done with plastic nail tools, including measuring and cleaning her fingernails.", "target_property": {"obj": "nail tools", "attribute": "plastic"}, "evaluation_question": "Are the nail tools being used in the salon made of **metal**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is at a salon getting her nails done with metal nail tools, including measuring and cleaning her fingernails. FE9RT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8dfd920bb7348efa0f7580776d782a5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "74c73283e1f4435098269c675bffda48", "source": "vatex", "video_id": "P02zv3sQE4I_000028_000038", "video_description": "A wheelchair basketball game is taking place between two teams in a gym. Players in wheelchairs are competing, passing, and shooting the ball. Dramatic music plays in the background, and text in a foreign language is displayed.", "task": "Counting", "clean_prompt": "Four players in wheelchairs are competing in a basketball game in a gym.", "clean_property": {"obj": "wheelchair", "count": "four"}, "target_prompt": "One player in a wheelchair is practicing shooting in an empty gym.", "target_property": {"obj": "wheelchair", "count": "one"}, "evaluation_question": "Are there exactly **four** players in wheelchairs competing in the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four players in wheelchairs are competing in a basketball game in a gym. @JSIF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24a8eb9b32774f71b096dc99a17855fa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "393ce8f7f4494f1da809ae3f7f6f378a", "source": "vatex", "video_id": "arB-2Wtvz10_000012_000022", "video_description": "A baby is on the floor, being encouraged by an adult to crawl towards a toy.", "task": "Counting", "clean_prompt": "Three adults encouraging a baby to crawl towards a toy on the floor.", "clean_property": {"obj": "adult", "count": "three"}, "target_prompt": "One adult encouraging a baby to crawl towards a toy on the floor.", "target_property": {"obj": "adult", "count": "one"}, "evaluation_question": "Are there exactly **three** adults encouraging the baby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three adults encouraging a baby to crawl towards a toy on the floor. LYCJZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/482629a4d7fc4e0c890fc0dcc358ac59.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1081778c7ccb4cce89d0d8c843239ca5", "source": "vatex", "video_id": "c0zKotiZDF8_000094_000104", "video_description": "A person is creating art using spray paint on a circular, metal object placed on a turntable. The person is wearing a protective mask while working outdoors.", "task": "ActionRecognition", "clean_prompt": "An artist spray painting on a circular, metal object placed on a turntable while wearing a protective mask outdoors.", "clean_property": {"obj": "artist", "action": "spray painting", "target": "metal object"}, "target_prompt": "An artist spray painting on a circular, wooden object placed on a turntable while wearing a protective mask outdoors.", "target_property": {"obj": "artist", "action": "spray painting", "target": "wooden object"}, "evaluation_question": "Is the artist spray painting on a **metal** object?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An artist spray painting on a circular, metal object placed on a turntable while wearing a protective mask outdoors. BISEE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49c4c810fef84e5ab622c6f08f2a8ab0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bb22306496b64f608c4f5851dc4c6888", "source": "vatex", "video_id": "5YNqhjkMywo_000005_000015", "video_description": "A young man in a room demonstrates how to bend a metal bar using his hands, knees, and leg, while tapping and breathing hard.", "task": "ActionRecognition", "clean_prompt": "A person bending a metal bar in a room.", "clean_property": {"obj": "person", "action": "bending metal", "target": "metal bar"}, "target_prompt": "A person breaking a metal bar in a room.", "target_property": {"obj": "person", "action": "breaking metal", "target": "metal bar"}, "evaluation_question": "Is the person **bending** a metal bar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person bending a metal bar in a room. LY%$J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d768b50b3aed45a1bcdbe1e0b8e49b94.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb0d000f5b184f258fca624e654ef00f", "source": "vatex", "video_id": "SCSSnsCBeDQ_000040_000050", "video_description": "A busy Middle-Eastern market with people in traditional attire buying and selling goods like figs and dates.", "task": "Counting", "clean_prompt": "Two people in traditional attire are buying figs and dates in a busy Middle-Eastern market.", "clean_property": {"obj": "goods", "count": "two"}, "target_prompt": "Two people in traditional attire are buying five different types of goods in a busy Middle-Eastern market.", "target_property": {"obj": "goods", "count": "five"}, "evaluation_question": "Are there exactly **two** goods being bought in the market?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in traditional attire are buying figs and dates in a busy Middle-Eastern market. X1BMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/91f0a2ed12af40a58aa6cd339e108f3e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cb4851a64c334a038ae74b01dc13a466", "source": "vatex", "video_id": "GQ_7SgqYYyo_000281_000291", "video_description": "A man is demonstrating and explaining how to properly use and calibrate beer taps in a bar.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a beer tap, demonstrating how to use it.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "tap"}, "target_prompt": "A person standing to the right of a beer tap, demonstrating how to use it.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "beer tap"}, "evaluation_question": "Is the person to the **left** of the beer tap?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a beer tap, demonstrating how to use it. LFV#X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3738a01b11f44a24a26ff317a98ebfd8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8038ab39b16d413d93cc84a0d0a15e57", "source": "vatex", "video_id": "p6TviZmyrDc_000063_000073", "video_description": "A woman is grooming a small white dog with curly hair on a grooming table, using scissors to trim and style the dog's fur.", "task": "ObjectRecognition", "clean_prompt": "A woman is grooming a small white dog with curly hair on a grooming table, using scissors to trim and style the dog's fur.", "clean_property": {"obj": "dog"}, "target_prompt": "A woman is grooming a small orange cat on a grooming table, using scissors to trim and style the cat's fur.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the animal being groomed in the video a **dog**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is grooming a small white dog with curly hair on a grooming table, using scissors to trim and style the dog's fur. 'U0PU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f9ceb47a0811485db9511fc86fc6f965.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42c0294025b04a11a8f309259390f929", "source": "vatex", "video_id": "wb875GGCiQc_000013_000023", "video_description": "A cricket game is taking place on a field where players are competing, and a batsman is dismissed by a fielder. The game ends in a tie with exciting plays.", "task": "ObjectRecognition", "clean_prompt": "A cricket player batting on a field during a game.", "clean_property": {"obj": "cricket player"}, "target_prompt": "A football player dribbling the ball on a field during a match.", "target_property": {"obj": "football player"}, "evaluation_question": "Is the player in the video a **cricket player**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cricket player batting on a field during a game. $'TRC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/944a6719baaf45478e7a103d8a339052.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bd8d8974bdeb4aaebdff73bcfae5b61b", "source": "vatex", "video_id": "-QEGWdqHq9s_000119_000129", "video_description": "A woman is sitting in a chair while a man shaves the side of her head using an electric shaver. The woman holds her hair to the side as the man trims along her hairline.", "task": "ObjectRecognition", "clean_prompt": "A woman is sitting in a chair while a man shaves the side of her head using an electric shaver.", "clean_property": {"obj": "chair"}, "target_prompt": "A woman is sitting on a sofa while a man shaves the side of her head using an electric shaver.", "target_property": {"obj": "sofa"}, "evaluation_question": "Is the woman sitting in a **chair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is sitting in a chair while a man shaves the side of her head using an electric shaver. FE/E=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/db4d10e7db3f4cac8a47274c5b8fc4b8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2a07a043728644b092021cd13c5197c3", "source": "vatex", "video_id": "PGKc4Ou3WI4_000090_000100", "video_description": "Two children, a boy and a girl, are running around a field with baskets, participating in an Easter egg hunt while adults look on.", "task": "SpatialUnderstanding", "clean_prompt": "A child farther from the camera than a basket in a field.", "clean_property": {"obj_1": "child", "relation": "farther from the camera than", "obj_2": "basket"}, "target_prompt": "A child closer to the camera than a basket in a field.", "target_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "basket"}, "evaluation_question": "Is the child **farther from the camera than** the basket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child farther from the camera than a basket in a field. -FE(G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b710b72811f949c0a7ffb869f87b9c07.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a7152c5335047aead072b3ca079f929", "source": "vatex", "video_id": "Oa--Wvh68-w_000198_000208", "video_description": "A group of people, including a man and two women, are sitting on benches outside, weaving baskets and discussing their project. Some hold completed baskets while others work on unfinished ones. The setting includes a wooden wall in the background.", "task": "ObjectRecognition", "clean_prompt": "A group of people sitting on benches outside, weaving baskets and discussing their project.", "clean_property": {"obj": "basket"}, "target_prompt": "A group of people sitting on benches outside, weaving hats and discussing their project.", "target_property": {"obj": "hat"}, "evaluation_question": "Are the people in the video weaving **baskets**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people sitting on benches outside, weaving baskets and discussing their project. FE0V@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8001e72fed104e9d8d53f0315efdb29e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "54dfaf693c1e449b9f1a87aac7c263a1", "source": "vatex", "video_id": "m2_qmRnjICE_000017_000027", "video_description": "A man in a black hoodie and trousers is picking apples in an orchard, carefully placing them in a bag and then into a wooden crate, while a narrator explains the process.", "task": "ActionRecognition", "clean_prompt": "A person picking apples in an orchard.", "clean_property": {"obj": "person", "action": "picking fruit", "target": "apple"}, "target_prompt": "A person throwing oranges in an orchard.", "target_property": {"obj": "person", "action": "throwing fruit", "target": "orange"}, "evaluation_question": "Is the person **picking** apples?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person picking apples in an orchard. -O7*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a107cd6d7e054658a88eccd2a13660b9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9fec44d1b39d4294a30d8033f2e9672c", "source": "vatex", "video_id": "5GF8c4n25mE_000000_000010", "video_description": "A young man performs a triple jump and a long jump at an athletics event on a track with spectators watching.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a long jump at an athletics event.", "clean_property": {"obj": "athlete", "action": "long jump", "target": null}, "target_prompt": "An athlete performing a high jump at an athletics event.", "target_property": {"obj": "athlete", "action": "high jump", "target": null}, "evaluation_question": "Is the athlete **performing a long jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a long jump at an athletics event. VGG4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e904b04da0884bfcb5952dbc45eff94b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aef09d0b5700483492a3f75f2dad6949", "source": "vatex", "video_id": "tTyPORsk3bk_000094_000104", "video_description": "A man is demonstrating and explaining how to calm and wash a small pug in a bathtub.", "task": "Counting", "clean_prompt": "A man is demonstrating how to calm and wash six dogs in a bathtub.", "clean_property": {"obj": "dog", "count": "six"}, "target_prompt": "A man is demonstrating how to calm and wash two dogs in a bathtub.", "target_property": {"obj": "dog", "count": "two"}, "evaluation_question": "Are there exactly **six** dogs in the bathtub?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to calm and wash six dogs in a bathtub. %BSD#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c06029c843024dda9e0081e90f17cc77.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "72f926cae58b43f1ae1b349f49947068", "source": "vatex", "video_id": "W3sMAuZgfKA_000071_000081", "video_description": "A baby boy is swinging back and forth in a baby swing at a park, with an adult occasionally pushing the swing.", "task": "ObjectRecognition", "clean_prompt": "An adult pushing a baby boy in a swing at a park.", "clean_property": {"obj": "adult"}, "target_prompt": "A child playing in a swing at a park.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person pushing the swing an **adult**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult pushing a baby boy in a swing at a park. !0D))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3febd3c29c43400d80049147a12942c5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1dbfadc903864a42b118ddd1e3cd4962", "source": "vatex", "video_id": "eTTol6npMj0_000000_000010", "video_description": "A young woman is sitting in her bedroom, yawning loudly with her mouth wide open, and making a two-tone moan sound. The camera captures her yawning and then pans away to the floor to the left.", "task": "ObjectRecognition", "clean_prompt": "A young woman sitting in her bedroom, yawning loudly with her mouth wide open.", "clean_property": {"obj": "person"}, "target_prompt": "A cat sitting in a bedroom, yawning loudly with its mouth wide open.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman sitting in her bedroom, yawning loudly with her mouth wide open. /'');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/68542fab23644fc9acac59fe7160b4ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b396a1f75e864edfb3c64a7d6fbe6c28", "source": "vatex", "video_id": "0DUtghm2U34_000106_000116", "video_description": "A large man in a red shirt is eating powdered donuts messily, with powdered sugar around his mouth, and sucking the powder off his thumb while holding a box.", "task": "SpatialUnderstanding", "clean_prompt": "A box closer to the camera than a person eating powdered donuts messily.", "clean_property": {"obj_1": "box", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A box further from the camera than a person eating powdered donuts messily.", "target_property": {"obj_1": "box", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the box closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A box closer to the camera than a person eating powdered donuts messily. !0D0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/781abcfdb04547109cc143c28ab91b17.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc423447ef974e908c1f1ebb10e9f661", "source": "vatex", "video_id": "-ORYjC-0F8I_000000_000010", "video_description": "A group of people are playing badminton in a gymnasium with multiple matches happening simultaneously.", "task": "ActionRecognition", "clean_prompt": "A player playing badminton in a gymnasium.", "clean_property": {"obj": "player", "action": "playing badminton", "target": null}, "target_prompt": "A player watching badminton in a gymnasium.", "target_property": {"obj": "player", "action": "watching badminton", "target": null}, "evaluation_question": "Is the player **playing** badminton?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A player playing badminton in a gymnasium. RL.RA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e9bf75ceebb14ff1b6d576ae64d36450.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac42efa2fbda415d9108beb7b21d6702", "source": "vatex", "video_id": "e7ft9fizUXQ_000078_000088", "video_description": "A person is creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques on a piece of paper.", "task": "ActionRecognition", "clean_prompt": "A person drawing a Christmas card with floral designs and the words 'Joy to the World' on a piece of paper.", "clean_property": {"obj": "person", "action": "drawing", "target": "paper"}, "target_prompt": "A person erasing a drawing on a piece of paper.", "target_property": {"obj": "person", "action": "erasing", "target": "paper"}, "evaluation_question": "Is the person **drawing** on the paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person drawing a Christmas card with floral designs and the words 'Joy to the World' on a piece of paper. HLFE7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba2c728032e64bd69018e755d1b3e197.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "667439960e6841cc8b96f9ad51b6dfb8", "source": "vatex", "video_id": "E3AcjYJVI8o_000012_000022", "video_description": "A man in a gym is performing battle rope exercises by kneeling on the floor and swinging two heavy ropes up and down.", "task": "AttributeRecognition", "clean_prompt": "A person wearing black exercise clothes performing battle rope exercises in a gym.", "clean_property": {"obj": "person", "attribute": "wearing black exercise clothes"}, "target_prompt": "A person wearing bright yellow exercise clothes performing battle rope exercises in a gym.", "target_property": {"obj": "person", "attribute": "wearing bright yellow exercise clothes"}, "evaluation_question": "Is the person wearing **black** exercise clothes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing black exercise clothes performing battle rope exercises in a gym. TM#XF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e3ad62b007a54570a53238bac0f96e1c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c310b506a2a0408fb4a54943ec2318f3", "source": "vatex", "video_id": "IOKQVcsNVk4_000080_000090", "video_description": "A group of three young boys are outside in the snow, dancing, playing, and interacting with the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the right of the camera.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "camera"}, "target_prompt": "A boy standing to the left of the camera.", "target_property": {"obj_1": "boy", "relation": "left of", "obj_2": "camera"}, "evaluation_question": "Is the boy to the **right** of the camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the right of the camera. )V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6f7d62ad9bae4ecab293180f89179f45.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb1c97d50851446aac93164350270669", "source": "vatex", "video_id": "R8G-LMSa1Ys_000000_000010", "video_description": "A young man is sitting in his home, smoking a hookah and blowing out smoke.", "task": "ObjectRecognition", "clean_prompt": "A young man is sitting in his home, smoking a hookah and blowing out smoke.", "clean_property": {"obj": "hookah"}, "target_prompt": "A young man is sitting in his home, smoking a cigarette and blowing out smoke.", "target_property": {"obj": "cigarette"}, "evaluation_question": "Is the young man smoking a **hookah**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is sitting in his home, smoking a hookah and blowing out smoke. FS$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/68f112cbd8f345efbdd1258b6fee04e2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "892d1a2c85464e00a308043521473f24", "source": "vatex", "video_id": "oV-x98Bs0i4_000010_000020", "video_description": "A person is preparing bread dough by placing it into a baking dish and scoring it with a tool.", "task": "AttributeRecognition", "clean_prompt": "A person scoring bread dough with a metal tool.", "clean_property": {"obj": "tool", "attribute": "metal"}, "target_prompt": "A person scoring bread dough with a wooden tool.", "target_property": {"obj": "tool", "attribute": "wooden"}, "evaluation_question": "Is the tool used for scoring the bread dough made of **metal**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person scoring bread dough with a metal tool. !B&);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6111c6abe1754faaa982d1ddfd07b38f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4cb9540213b497dbd1d53c75ddb12e7", "source": "vatex", "video_id": "x9FExBs3FiM_000043_000053", "video_description": "A high jump competition featuring several girls participating in the event, with a man narrating the highlights.", "task": "ActionRecognition", "clean_prompt": "A girl performing a high jump over a bar in a competition.", "clean_property": {"obj": "girl", "action": "high jump", "target": "bar"}, "target_prompt": "A girl performing a long jump into a sand pit.", "target_property": {"obj": "girl", "action": "long jump", "target": "sand pit"}, "evaluation_question": "Is the girl **performing a high jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing a high jump over a bar in a competition. Z-SL(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd76c92c5d7048a8b0964e0de866db49.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e8aa9229341541578aade1221d1c2e87", "source": "vatex", "video_id": "4kixfScXLX0_000067_000077", "video_description": "A family gathering where two children are playing Twister on the floor while adults watch, drink, and smoke.", "task": "ActionRecognition", "clean_prompt": "An adult smoking while watching children play Twister at a family gathering.", "clean_property": {"obj": "adult", "action": "smoking", "target": null}, "target_prompt": "An adult drinking while watching children play Twister at a family gathering.", "target_property": {"obj": "adult", "action": "drinking", "target": null}, "evaluation_question": "Is the adult **smoking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult smoking while watching children play Twister at a family gathering. UG7(I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5c9752fdff6467497788d250fce04ce.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cb29115cefa44c9eba08b1cf5b3d6a70", "source": "vatex", "video_id": "2C_cX7-K2UM_000083_000093", "video_description": "A group of people, including a man and several children, are in a wet, rocky area near a body of water. The children are playing and digging among the rocks, while the man films and walks around.", "task": "ObjectRecognition", "clean_prompt": "A group of people, including a man and several children, are playing near a body of water.", "clean_property": {"obj": "water"}, "target_prompt": "A group of people, including a man and several children, are gathered around a fire.", "target_property": {"obj": "fire"}, "evaluation_question": "Is the group of people near **water**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people, including a man and several children, are playing near a body of water. >$-SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfc0f4db18434d18a1f49a3824847ea0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ea8d9e977307462780bc770cf32514c7", "source": "vatex", "video_id": "Z_J6jTCim0Y_000002_000012", "video_description": "A man is sitting on a green couch, eating a wrapped food item, possibly a burrito, while watching television.", "task": "AttributeRecognition", "clean_prompt": "A man wearing all black clothing is sitting on a green couch, eating a wrapped food item while watching television.", "clean_property": {"obj": "man", "attribute": "wearing all black clothing"}, "target_prompt": "A man wearing bright yellow clothing is sitting on a green couch, eating a wrapped food item while watching television.", "target_property": {"obj": "man", "attribute": "wearing bright yellow clothing"}, "evaluation_question": "Is the man wearing **all black** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing all black clothing is sitting on a green couch, eating a wrapped food item while watching television. JMP3F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d5c7e145db22472d9eccdaf46b4ea5fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4b0476dbabeb4b3fad0f5348a8507abd", "source": "vatex", "video_id": "0Fd6dxtroLs_000024_000034", "video_description": "A man is demonstrating exercises using a sledgehammer, including doing push-ups while balancing on the hammer.", "task": "ActionRecognition", "clean_prompt": "A person doing push-ups while balancing on a sledgehammer.", "clean_property": {"obj": "person", "action": "push up", "target": null}, "target_prompt": "A person jumping while balancing on a sledgehammer.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **doing push-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person doing push-ups while balancing on a sledgehammer. !#W0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb26b8e38a52495f86e603a174d6e1aa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "86612a9aa4a34b3bbb5101606aeab0b0", "source": "vatex", "video_id": "7oXJdAq9Tio_000045_000055", "video_description": "A woman is outdoors demonstrating and explaining the creation of stone tools by chipping away at rocks using various tools, including a mallet and a piece of wood.", "task": "SpatialUnderstanding", "clean_prompt": "A tool farther from the camera than a person demonstrating stone tool creation outdoors.", "clean_property": {"obj_1": "tool", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A tool closer to the camera than a person demonstrating stone tool creation outdoors.", "target_property": {"obj_1": "tool", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the tool **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tool farther from the camera than a person demonstrating stone tool creation outdoors. )!0D\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/038ef81469d24a9d9cc794c814273b2a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "73c9be339cb646128f08cdef81fabcd1", "source": "vatex", "video_id": "AkFy3j-73JA_000018_000028", "video_description": "A young woman is ice skating at an indoor rink, performing spins and twirls.", "task": "Counting", "clean_prompt": "Three ice skaters performing spins and twirls at an indoor rink.", "clean_property": {"obj": "ice skater", "count": "three"}, "target_prompt": "One ice skater performing spins and twirls at an indoor rink.", "target_property": {"obj": "ice skater", "count": "one"}, "evaluation_question": "Are there exactly **three** ice skaters at the rink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three ice skaters performing spins and twirls at an indoor rink. FE7/9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/264433b07ec444239b33db2b2f395a21.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "86e2c82380844a6bb626dcefa2a9591b", "source": "vatex", "video_id": "4u41-OsKbcY_001144_001154", "video_description": "A woman demonstrates and explains the process of binding a book by stitching pages together using a needle and thread.", "task": "Counting", "clean_prompt": "A woman demonstrates the process of binding three books by stitching their pages together using a needle and thread.", "clean_property": {"obj": "book", "count": "three"}, "target_prompt": "A woman demonstrates the process of binding one book by stitching its pages together using a needle and thread.", "target_property": {"obj": "book", "count": "one"}, "evaluation_question": "Are there exactly **three** books being bound?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates the process of binding three books by stitching their pages together using a needle and thread. 96QEZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ea4d5578bed4bd2ab3332abf3d43d95.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "574f45286a7a4236bcb3b7cd86004fda", "source": "vatex", "video_id": "XXQZz6FuEYI_000183_000193", "video_description": "A man is in a gym demonstrating exercises using a sledgehammer, swinging it behind and in front of him.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer in a gym.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": null}, "target_prompt": "A person lifting a sledgehammer in a gym.", "target_property": {"obj": "person", "action": "lifting a sledgehammer", "target": null}, "evaluation_question": "Is the person **using** a sledgehammer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledgehammer in a gym. PD$S+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/283abc7e795d4119b333f6b797ec8722.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5565beb58afa4031bc62fae5e6d5c6ee", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "ActionRecognition", "clean_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "clean_property": {"obj": "person", "action": "playing laser tag", "target": null}, "target_prompt": "A person watching a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "target_property": {"obj": "person", "action": "watching a laser tag game", "target": null}, "evaluation_question": "Is the person **playing** laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain. =|R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a80f0a90696145009deeb01ae81037a0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2c45c10e91e3445fb42d04ef50417348", "source": "vatex", "video_id": "f-JzfOaiVOE_000076_000086", "video_description": "Several people are in a gym or court bouncing balls, including basketballs and medicine balls, as part of an exercise routine.", "task": "ObjectRecognition", "clean_prompt": "Several people are in a gym bouncing basketballs and medicine balls as part of an exercise routine.", "clean_property": {"obj": "person"}, "target_prompt": "Several animals are in a gym playing with balls as part of an exercise routine.", "target_property": {"obj": "animal"}, "evaluation_question": "Are the individuals in the video **people**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several people are in a gym bouncing basketballs and medicine balls as part of an exercise routine. =BSD#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/15f57cdc4c784becb574bf39de5016b3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cec547e7f4dc47bd95de2001a37681b6", "source": "vatex", "video_id": "k9oRxHgjBn0_000012_000022", "video_description": "A woman is performing ballet spins and dance moves in a studio, demonstrating different techniques and balance.", "task": "ActionRecognition", "clean_prompt": "A person pirouetting in a ballet studio.", "clean_property": {"obj": "person", "action": "pirouetting", "target": null}, "target_prompt": "A person break dancing in a ballet studio.", "target_property": {"obj": "person", "action": "break dancing", "target": null}, "evaluation_question": "Is the person **pirouetting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person pirouetting in a ballet studio. EET$J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6f84c91a41fb484f8a8be949ee745a9f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ff2e305c26bc4fc290ad2b9179f95e0c", "source": "vatex", "video_id": "MgSNvlS2d3A_000126_000136", "video_description": "A group of teenagers are outside on the grass, applying and removing wax strips from a boy's leg to remove hair.", "task": "Counting", "clean_prompt": "A group of teenagers are outside on the grass, applying and removing two wax strips from a boy's leg to remove hair.", "clean_property": {"obj": "wax strip", "count": "two"}, "target_prompt": "A group of teenagers are outside on the grass, applying and removing one wax strip from a boy's leg to remove hair.", "target_property": {"obj": "wax strip", "count": "one"}, "evaluation_question": "Are there exactly **two** wax strips being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of teenagers are outside on the grass, applying and removing two wax strips from a boy's leg to remove hair. ED9FA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/116eaa6f59ba4cdeb55032199dea3cb4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1518d01843bd4477bc38a1d771cad098", "source": "vatex", "video_id": "nauxZ_zt5bk_000103_000113", "video_description": "A man with long hair is sitting on a stool, playing a small, guitar-like string instrument, possibly a lute or banjo, using an amplifier.", "task": "SpatialUnderstanding", "clean_prompt": "A person sitting to the left of an amplifier, playing a small string instrument.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "amplifier"}, "target_prompt": "A person sitting to the right of an amplifier, playing a small string instrument.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "amplifier"}, "evaluation_question": "Is the person to the **left** of the amplifier?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting to the left of an amplifier, playing a small string instrument. .5SBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/897af0de00d6466e80cb76403650c64a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bff0c2076d6e499dab3fe4b9d59e8032", "source": "vatex", "video_id": "a5eMVl_mqjw_000044_000054", "video_description": "A woman is demonstrating how to apply nail polish at a table using various nail supplies.", "task": "ObjectRecognition", "clean_prompt": "A woman is demonstrating how to apply nail polish at a table using various nail supplies.", "clean_property": {"obj": "nail supplies"}, "target_prompt": "A woman is demonstrating how to style hair at a table using various hair supplies.", "target_property": {"obj": "hair supplies"}, "evaluation_question": "Is the woman using **nail supplies** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to apply nail polish at a table using various nail supplies. )SLG+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42f6a3a825cb46acaf2ebfd0138929e2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "916317b96cfa4ca6a1c99e635833a5d5", "source": "vatex", "video_id": "ICJjAbK4HAs_000005_000015", "video_description": "A man in khaki clothes is shaking a blue plastic container with a lid to coat food with bread crumbs.", "task": "ObjectRecognition", "clean_prompt": "A man in khaki clothes is shaking a blue plastic container with a lid to coat food with bread crumbs.", "clean_property": {"obj": "container"}, "target_prompt": "A man in khaki clothes is shaking a blue basket to coat food with bread crumbs.", "target_property": {"obj": "basket"}, "evaluation_question": "Is the object being shaken in the video a **container**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in khaki clothes is shaking a blue plastic container with a lid to coat food with bread crumbs. FE&G$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/880dc2d7b40047109264cc887198ad59.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81db16be2f5047779db8ad1e581335c5", "source": "vatex", "video_id": "JQTZTmaD86Q_000020_000030", "video_description": "A young girl stands on a bathroom counter in front of a mirror, brushing her teeth while wearing pajamas and an Olympic medal. Music is playing in the background.", "task": "AttributeRecognition", "clean_prompt": "A girl wearing pajamas is brushing her teeth in front of a mirror.", "clean_property": {"obj": "girl", "attribute": "wearing pajamas"}, "target_prompt": "A girl wearing a princess costume is brushing her teeth in front of a mirror.", "target_property": {"obj": "girl", "attribute": "wearing a princess costume"}, "evaluation_question": "Is the girl wearing **pajamas**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl wearing pajamas is brushing her teeth in front of a mirror. =LYSA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef1181945abf4538a8caad38e04cfde7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "076dac3593534308bba0a5c46da855aa", "source": "vatex", "video_id": "IkEmoLzENaQ_000013_000023", "video_description": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background.", "task": "ObjectRecognition", "clean_prompt": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background.", "clean_property": {"obj": "man"}, "target_prompt": "A woman and a man are sitting on a couch, talking animatedly while people chat in the background.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the main character in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are sitting on a couch, kissing passionately while people talk in the background. !':*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a804881b490e4fd88ffa5009f6b1b10a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a2a5856b90274876bbe40e748e1ee9c6", "source": "vatex", "video_id": "0qX6DKIW2jM_000089_000099", "video_description": "A bartender demonstrates how to pour a glass of beer from a tap, focusing on creating a foamy head.", "task": "ObjectRecognition", "clean_prompt": "A bartender demonstrates how to pour a glass of beer from a tap, focusing on creating a foamy head.", "clean_property": {"obj": "beer glass"}, "target_prompt": "A bartender demonstrates how to pour a glass of wine from a bottle, focusing on the aroma and color.", "target_property": {"obj": "wine glass"}, "evaluation_question": "Is the glass being poured in the video a **beer glass**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bartender demonstrates how to pour a glass of beer from a tap, focusing on creating a foamy head. /FOE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b023cbec1bd40d9a30ac241249fb473.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "91dd6580aef5429b8f3b0c2bc2434452", "source": "vatex", "video_id": "6J8DBs6aGU8_000001_000011", "video_description": "A woman is riding a camel through a vast desert landscape, wearing a blue headscarf and a grey dress. A man is leading the camel.", "task": "SpatialUnderstanding", "clean_prompt": "A woman riding a camel through a vast desert landscape, with the camel positioned to the right of her.", "clean_property": {"obj_1": "camel", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A woman riding a camel through a vast desert landscape, with the camel positioned to the left of her.", "target_property": {"obj_1": "camel", "relation": "left of", "obj_2": "woman"}, "evaluation_question": "Is the camel to the **right** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman riding a camel through a vast desert landscape, with the camel positioned to the right of her. YU*9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eac09aa708e7443c8e264d1dbc05af24.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3b8a5b2e1184f49ac03f5fa7fd48050", "source": "vatex", "video_id": "Hm2NmXK5U94_000013_000023", "video_description": "A young boy is sitting on a couch with his feet on a woman's lap. The woman is clipping the boy's toenails while he drinks from a large sippy cup.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on a couch with his feet on a woman's lap while he drinks from a large sippy cup.", "clean_property": {"obj": "sippy cup"}, "target_prompt": "A young boy is sitting on a couch with his feet on a woman's lap while he drinks from a large water bottle.", "target_property": {"obj": "water bottle"}, "evaluation_question": "Is the boy drinking from a **sippy cup**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting on a couch with his feet on a woman's lap while he drinks from a large sippy cup. MT\u00b7@A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2fa499f620e447b2bb20a6c9f2a1b4bf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afe90a68b6a64765a0c522f3ea081178", "source": "vatex", "video_id": "IBay_SsO2_M_000113_000123", "video_description": "A man in a suit presents an award to another man on stage in front of an applauding audience. The recipient steps up to the podium to deliver a speech.", "task": "SpatialUnderstanding", "clean_prompt": "An audience applauding to the left of a recipient on stage.", "clean_property": {"obj_1": "audience", "relation": "left of", "obj_2": "recipient"}, "target_prompt": "An audience applauding to the right of a recipient on stage.", "target_property": {"obj_1": "audience", "relation": "right of", "obj_2": "recipient"}, "evaluation_question": "Is the audience to the **left** of the recipient?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An audience applauding to the left of a recipient on stage. !0D=|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c2149790b58e459483ad2fdcfffed8a5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "652dad54cebe4ead934a3a224040d2ce", "source": "vatex", "video_id": "9F0fySfyvyQ_000084_000094", "video_description": "A group of children are participating in an Easter egg hunt outdoors, collecting colorful plastic eggs with the help of a woman.", "task": "AttributeRecognition", "clean_prompt": "A group of children participating in an Easter egg hunt outdoors, collecting colorful plastic eggs with the help of a woman.", "clean_property": {"obj": "egg", "attribute": "colorful"}, "target_prompt": "A group of children participating in an Easter egg hunt outdoors, collecting monochrome plastic eggs with the help of a woman.", "target_property": {"obj": "egg", "attribute": "monochrome"}, "evaluation_question": "Are the eggs being collected by the children **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children participating in an Easter egg hunt outdoors, collecting colorful plastic eggs with the help of a woman. AN*(!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf808d975fd74aa6bf9d3945b4d3dd46.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "184fde52c14d447c80a4a99924ddd602", "source": "vatex", "video_id": "KoY-HBCL_wg_000278_000288", "video_description": "A woman is demonstrating how to make balloon animals using a long pink balloon.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a pink balloon while demonstrating how to make balloon animals.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "balloon"}, "target_prompt": "A person standing to the left of a pink balloon while demonstrating how to make balloon animals.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "balloon"}, "evaluation_question": "Is the person to the **right** of a pink balloon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a pink balloon while demonstrating how to make balloon animals. \u00b7#|FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce3c9b7221a44e5cba72ef8c9bae4f3e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6a9fa09291d479b88071329950e5850", "source": "vatex", "video_id": "o4u6vezliVc_000021_000031", "video_description": "A man is sitting on the ground playing a didgeridoo on a busy street, while another man sits nearby drinking water.", "task": "AttributeRecognition", "clean_prompt": "A water drinker sitting on a chair or milk crate.", "clean_property": {"obj": "water drinker", "attribute": "sitting on a chair or milk crate"}, "target_prompt": "A water drinker standing on the street.", "target_property": {"obj": "water drinker", "attribute": "standing on the street"}, "evaluation_question": "Is the water drinker sitting on a **chair or milk crate**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A water drinker sitting on a chair or milk crate. RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c9085338b5634269b31e9ac0146bbd0f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f044c9904d6c4cb9978b6af70ea92487", "source": "vatex", "video_id": "yoOKaAjoC0w_000045_000055", "video_description": "A man is working in a woodworking workshop, using various machines to cut, sand, and plane pieces of wood.", "task": "AttributeRecognition", "clean_prompt": "A man working in a woodworking workshop using various machines to cut, sand, and plane pieces of wood.", "clean_property": {"obj": "machine", "attribute": "woodworking"}, "target_prompt": "A man working in a metalworking workshop using various machines to cut, shape, and finish pieces of metal.", "target_property": {"obj": "machine", "attribute": "metalworking"}, "evaluation_question": "Is the machine being used for **woodworking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man working in a woodworking workshop using various machines to cut, sand, and plane pieces of wood. ,UFSA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5cf584e0445407f9b655a37d2c45157.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3f7f1a6cbd3147a9a92a3f5499152665", "source": "vatex", "video_id": "ZoWgCBQc6wE_000002_000012", "video_description": "A man on horseback lassos a calf, dismounts, and ties the calf's legs.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a calf.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "calf"}, "target_prompt": "A man closer to the camera than a calf.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "calf"}, "evaluation_question": "Is the man **farther from the camera than** the calf?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a calf. #T>.E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/074889f94cf94d5ca7b4f0f997f7c4bc.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "966bdb5228a44a9dab1432cf90ff0ac4", "source": "vatex", "video_id": "_Ve2cyloT6o_000036_000046", "video_description": "A man is working on a vehicle, using various tools like a spray painter, sand blaster, and pressure washer to paint and clean the vehicle.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer on a vehicle.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "vehicle"}, "target_prompt": "A person repairing a vehicle.", "target_property": {"obj": "person", "action": "repairing a vehicle", "target": "vehicle"}, "evaluation_question": "Is the person **using a sledge hammer** on the vehicle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer on a vehicle. FG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6132a29b723a4d82a7de557da46a8e55.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0612bb6bd95a438db006852537dfa7c6", "source": "vatex", "video_id": "cheP4JKv25w_000000_000010", "video_description": "A young girl is sitting at a table, using a pencil to write and draw on a piece of paper or coloring book while talking to a woman.", "task": "Counting", "clean_prompt": "A young girl is sitting at a table, using three pencils to write and draw on a piece of paper while talking to a woman.", "clean_property": {"obj": "pencil", "count": "three"}, "target_prompt": "A young girl is sitting at a table, using one pencil to write and draw on a piece of paper while talking to a woman.", "target_property": {"obj": "pencil", "count": "one"}, "evaluation_question": "Are there exactly **three** pencils being used by the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is sitting at a table, using three pencils to write and draw on a piece of paper while talking to a woman. >BC2I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b223e513fd14a7fb75edbb0b7c47083.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd1911da60664026a829547d9d7eef7c", "source": "vatex", "video_id": "4VGwynLvXpM_000028_000038", "video_description": "A young boy wearing black headphones and a gray Superman shirt is playing a saxophone in a room.", "task": "Counting", "clean_prompt": "A boy playing a saxophone in a room, wearing black headphones and a gray Superman shirt.", "clean_property": {"obj": "boy", "count": "six"}, "target_prompt": "Six boys playing different musical instruments in a colorful room.", "target_property": {"obj": "boy", "count": "six"}, "evaluation_question": "Are there exactly **six** boys in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy playing a saxophone in a room, wearing black headphones and a gray Superman shirt. !0BI,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/88f613145e1a42a28b3dc93b8f6a732a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d30ce994d8584819861646fb0fc7925b", "source": "vatex", "video_id": "ATAmRUaNr3E_000053_000063", "video_description": "A man is indoors demonstrating dog training techniques with a dog on a leash, using treats as part of the training.", "task": "SpatialUnderstanding", "clean_prompt": "A treat positioned to the left of a dog.", "clean_property": {"obj_1": "treat", "relation": "left of", "obj_2": "dog"}, "target_prompt": "A treat positioned to the right of a dog.", "target_property": {"obj_1": "treat", "relation": "right of", "obj_2": "dog"}, "evaluation_question": "Is the treat to the **left** of the dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A treat positioned to the left of a dog. Q'GR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3dd7f718f9ee4c3986ec5c009927e946.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4fc98ead5b054d8397b3aa65486ea7e6", "source": "vatex", "video_id": "2snRWJ8ySO0_000000_000010", "video_description": "A young boy is standing in a town square, feeding pigeons. Some pigeons are perched on his arm, and one lands on his head. He is laughing happily.", "task": "Counting", "clean_prompt": "A young boy is standing in a town square, feeding two pigeons. Some pigeons are perched on his arm, and one lands on his head. He is laughing happily.", "clean_property": {"obj": "pigeon", "count": "two"}, "target_prompt": "A young boy is standing in a town square, feeding five pigeons. Some pigeons are perched on his arm, and one lands on his head. He is laughing happily.", "target_property": {"obj": "pigeon", "count": "five"}, "evaluation_question": "Are there exactly **two** pigeons being fed by the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is standing in a town square, feeding two pigeons. Some pigeons are perched on his arm, and one lands on his head. He is laughing happily. '''!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3eb98b1b344b4c0a846a0cefc9df3f4f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "730edd953d0942d9a1b05e04b68d3faa", "source": "vatex", "video_id": "1V_Njbc_dos_000256_000266", "video_description": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process.", "task": "ObjectRecognition", "clean_prompt": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process.", "clean_property": {"obj": "paper"}, "target_prompt": "A young boy is painting a picture of a woman's face on a canvas, while explaining the process.", "target_property": {"obj": "canvas"}, "evaluation_question": "Is the boy drawing on **paper**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is drawing a picture of a woman's face with a pencil on a white piece of paper, while explaining the process. FE+3T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/05f3ee66da414646a6cc25c6b00539d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "64c0dc155bcc41c48d5cf1fe7a8859db", "source": "vatex", "video_id": "VCX8Q4Q752A_000071_000081", "video_description": "A group of people are seated around a large circular table with a rotating Lazy Susan in the middle, dining on Asian cuisine. A server occasionally adds dishes to the table.", "task": "ObjectRecognition", "clean_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine.", "clean_property": {"obj": "server"}, "target_prompt": "A chef preparing dishes in a kitchen while a group of people waits at a table.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **server**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A server adding dishes to a table where a group of people is dining on Asian cuisine. BSQD.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f7d21220d544b75a4bf7c111ac363a4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "97ec15f3a2db42b1a099f4ec1717ef7f", "source": "vatex", "video_id": "_SDbgNgZUfU_000000_000010", "video_description": "A man is racing a small green lawn mower around a makeshift dirt track while a large crowd watches.", "task": "AttributeRecognition", "clean_prompt": "A man racing a small green lawn mower around a dirt track while a crowd watches.", "clean_property": {"obj": "vehicle", "attribute": "green"}, "target_prompt": "A man racing a small red lawn mower around a dirt track while a crowd watches.", "target_property": {"obj": "vehicle", "attribute": "red"}, "evaluation_question": "Is the vehicle a **green** lawn mower?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man racing a small green lawn mower around a dirt track while a crowd watches. NMC;$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b09fe30961774ed2b530cb40509b1d35.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "003561c5919e4e218a78378655a44b5f", "source": "vatex", "video_id": "4eKN5-BZFFw_000181_000191", "video_description": "A person is presenting a piece of homemade jewelry, a beaded bracelet with letters forming the phrase 'I LUV YOU', in front of a camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing farther from the camera than a beaded bracelet with letters forming the phrase 'I LUV YOU'.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "bracelet"}, "target_prompt": "A person standing closer to the camera than a beaded bracelet with letters forming the phrase 'I LUV YOU'.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "bracelet"}, "evaluation_question": "Is the person farther from the camera than the bracelet?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing farther from the camera than a beaded bracelet with letters forming the phrase 'I LUV YOU'. :FE-M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f28ab29d234d41cca372bc40512a2235.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8033f6fdc2f8457a958c8211e4c5fc11", "source": "vatex", "video_id": "B5U_KlU_TCI_000021_000031", "video_description": "A young woman with pigtails and heavy makeup is smoking a cigarette and exhaling smoke in a dark setting.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a cigarette in a dark setting.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "cigarette"}, "target_prompt": "A person standing to the right of a cigarette in a dark setting.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "cigarette"}, "evaluation_question": "Is the person to the **left** of the cigarette?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a cigarette in a dark setting. @HS8Y", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/432bc13ab7ff42469681c9e9bd540630.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a338923c4a4435f8096670b1cbb5851", "source": "vatex", "video_id": "fCuZH-QXUis_000815_000825", "video_description": "A scuba diver is underwater near a coral reef, interacting with a variety of colorful fish while wearing scuba gear.", "task": "ObjectRecognition", "clean_prompt": "A scuba diver is underwater near a coral reef, interacting with a variety of colorful fish while wearing scuba gear.", "clean_property": {"obj": "fish"}, "target_prompt": "A scuba diver is underwater near a coral reef, interacting with a shark while wearing scuba gear.", "target_property": {"obj": "shark"}, "evaluation_question": "Is the underwater creature in the video a **fish**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scuba diver is underwater near a coral reef, interacting with a variety of colorful fish while wearing scuba gear. !0D=W", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/508decb42ae84973ac86990d9a253a9c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3827e461c47a466ba7c4cb33b76db0a8", "source": "vatex", "video_id": "Zr7VBWsIaA0_000025_000035", "video_description": "A man demonstrates how to open oysters and clams using a special knife and a towel for safety.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrates how to open oysters and clams using a special knife and a towel for safety.", "clean_property": {"obj": "towel"}, "target_prompt": "A man demonstrates how to open oysters and clams using a special knife and a glove for safety.", "target_property": {"obj": "glove"}, "evaluation_question": "Is the man using a **towel** for safety?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to open oysters and clams using a special knife and a towel for safety. @.'VU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2422505522f24c42ac0339c60be04754.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5bc6699a8e414760b99b282c45947e22", "source": "vatex", "video_id": "LBu3cuvQEIw_000038_000048", "video_description": "A person is performing card tricks, including shuffling and demonstrating techniques, in a backyard.", "task": "ActionRecognition", "clean_prompt": "A person shuffling cards in a backyard.", "clean_property": {"obj": "person", "action": "shuffling cards", "target": null}, "target_prompt": "A person throwing cards in a backyard.", "target_property": {"obj": "person", "action": "throwing cards", "target": null}, "evaluation_question": "Is the person **shuffling** cards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shuffling cards in a backyard. NK4()", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5103e659725747a68fd1b52b29e544b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e293d943b45543ca9b344806a1963f07", "source": "vatex", "video_id": "BHsuHq_75Nw_000100_000110", "video_description": "A person is cooking a whole chicken on a rotisserie over an open fire in the woods during the day. The person uses a knife with a leather sheath to carve the chicken.", "task": "AttributeRecognition", "clean_prompt": "A person carving a whole chicken with a knife with a leather sheath over an open fire in the woods during the day.", "clean_property": {"obj": "knife", "attribute": "with leather sheath"}, "target_prompt": "A person carving a whole chicken with a knife with a plastic handle over an open fire in the woods during the day.", "target_property": {"obj": "knife", "attribute": "with plastic handle"}, "evaluation_question": "Is the knife being used **with a leather sheath**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person carving a whole chicken with a knife with a leather sheath over an open fire in the woods during the day. |BCSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b682f7cf57614a9abb5106d8a2aabe09.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3747aa768bd8465eabccc961a4cf29c2", "source": "vatex", "video_id": "brcO3B4ESy4_000018_000028", "video_description": "A person demonstrates how to make mini pizzas by rolling out dough, adding toppings like tomato sauce, cheese, and olives, and baking them in the oven.", "task": "Counting", "clean_prompt": "Two people demonstrating how to make mini pizzas by rolling out dough, adding toppings like tomato sauce, cheese, and olives, and baking them in the oven.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person demonstrating how to make mini pizzas by rolling out dough, adding toppings like tomato sauce, cheese, and olives, and baking them in the oven.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people demonstrating how to make mini pizzas?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people demonstrating how to make mini pizzas by rolling out dough, adding toppings like tomato sauce, cheese, and olives, and baking them in the oven. WNJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ba85059910e4e2da91ce5e295b05483.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46c2462630f34c2b8203ae879d85d72e", "source": "vatex", "video_id": "HNPfW3X41sI_000002_000012", "video_description": "A woman is using a microscope to look at an experiment while a man provides instructions and descriptions in the background.", "task": "Counting", "clean_prompt": "Five men providing instructions while a woman uses a microscope.", "clean_property": {"obj": "man", "count": "five"}, "target_prompt": "Two men providing instructions while a woman uses a microscope.", "target_property": {"obj": "man", "count": "two"}, "evaluation_question": "Are there exactly **five** men providing instructions?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five men providing instructions while a woman uses a microscope. ''!(|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dfc5fc8800e0462d998d5be0ef5f3e64.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9eaedd7e1e984b31b8d924a07554d1bd", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "ObjectRecognition", "clean_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "person"}, "target_prompt": "A woman is standing in the street using a sledge hammer to break up thick ice on the ground.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground. #BCUS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/af583068a5d8477db4e06a4e0989dbd5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "658014c85bdb4a3891dfc2e676e5e144", "source": "vatex", "video_id": "fBO4nVZ8IzI_000027_000037", "video_description": "A martial arts demonstration where children, including a girl and a boy, practice breaking wooden boards with their hands. The scene includes a teacher encouraging them and an audience watching.", "task": "ActionRecognition", "clean_prompt": "A child breaking wooden boards in a martial arts demonstration.", "clean_property": {"obj": "child", "action": "breaking boards", "target": "wooden board"}, "target_prompt": "A child breaking bricks in a martial arts demonstration.", "target_property": {"obj": "child", "action": "breaking bricks", "target": "brick"}, "evaluation_question": "Is the child **breaking boards**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child breaking wooden boards in a martial arts demonstration. ?E?1X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6e40a81fcbb34c52a66837179023b04c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a4922dc9014f4075beb48fce17c76c36", "source": "vatex", "video_id": "ayKOTk9EFjI_000000_000010", "video_description": "A young girl in a blue shirt and white shorts performs a handstand in a school gymnasium, sometimes shouting in joy or laughing.", "task": "SpatialUnderstanding", "clean_prompt": "A girl closer to the camera than a gym mat.", "clean_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "gym mat"}, "target_prompt": "A girl further from the camera than a gym mat.", "target_property": {"obj_1": "girl", "relation": "further from the camera than", "obj_2": "gym mat"}, "evaluation_question": "Is the girl **closer to the camera than** the gym mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl closer to the camera than a gym mat. \u00b7))!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/71c7dfb235904fe592fd5aa442cd1951.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "813b9ade66a6488a916d6d61457c3fca", "source": "vatex", "video_id": "iLNmg_zAa6Y_000009_000019", "video_description": "A person is riding a modified bicycle with skis attached instead of wheels down a snowy hill, performing jumps over snow ramps.", "task": "AttributeRecognition", "clean_prompt": "A person riding a bicycle with skis instead of wheels down a snowy hill, performing jumps over snow ramps.", "clean_property": {"obj": "bicycle", "attribute": "with skis instead of wheels"}, "target_prompt": "A person riding a bicycle with large wheels down a snowy hill, performing jumps over snow ramps.", "target_property": {"obj": "bicycle", "attribute": "with large wheels instead of skis"}, "evaluation_question": "Is the bicycle equipped with **skis** instead of wheels?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a bicycle with skis instead of wheels down a snowy hill, performing jumps over snow ramps. '''!;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a95592ea1be141fd924cfb8c02952150.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "226072e69131465486c2797ebacfe58d", "source": "vatex", "video_id": "_UyZpt0Qbnk_000008_000018", "video_description": "A man wearing a cowboy hat is juggling flaming objects in an outdoor setting in front of a crowd.", "task": "AttributeRecognition", "clean_prompt": "A man wearing a cowboy hat is juggling flaming objects on fire in an outdoor setting in front of a crowd.", "clean_property": {"obj": "flaming object", "attribute": "on fire"}, "target_prompt": "A man wearing a cowboy hat is juggling extinguished flaming objects in an outdoor setting in front of a crowd.", "target_property": {"obj": "flaming object", "attribute": "extinguished"}, "evaluation_question": "Are the flaming objects **on fire**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing a cowboy hat is juggling flaming objects on fire in an outdoor setting in front of a crowd. #@*JU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/47bba3d1c22344f39bcd8aed018cae35.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6357e33db4b44aecb5fb7840a85e73d6", "source": "vatex", "video_id": "C29kvQkzadQ_000017_000027", "video_description": "A man in a gym demonstrates a workout with free weights, performing standing front raises while music plays.", "task": "Counting", "clean_prompt": "Four people in a gym demonstrating a workout with free weights, performing standing front raises while music plays.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a gym demonstrating a workout with free weights, performing standing front raises while music plays.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a gym demonstrating a workout with free weights, performing standing front raises while music plays. !'Z%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f30b4c7e2112401ea90900aecc020915.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c697354a61a480ea862595f8514d54e", "source": "vatex", "video_id": "YhEbR_0bMz8_000000_000010", "video_description": "A girl in a laboratory or classroom setting is moving a microscope from one table to another, with a warning displayed about the correct way to handle a microscope.", "task": "AttributeRecognition", "clean_prompt": "A girl student moving a microscope in a laboratory.", "clean_property": {"obj": "girl", "attribute": "student"}, "target_prompt": "A girl artist painting in a studio.", "target_property": {"obj": "girl", "attribute": "artist"}, "evaluation_question": "Is the girl a **student**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl student moving a microscope in a laboratory. .'!|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/82ae1e66c929455d8c56fa946a7c141b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad94976a8f31444e85e38132734308f6", "source": "vatex", "video_id": "uFthK6DCwoc_000000_000010", "video_description": "A woman in a gym demonstrates various weightlifting exercises, including bent over dumbbell front raises and squats, using small hand weights.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating weightlifting exercises in a gym.", "clean_property": {"obj": "person"}, "target_prompt": "A child playing with toys in a living room.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating weightlifting exercises in a gym. A%W>|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67b0a80887ac4656b81318ccd84831e4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "24b81728cc5c4c6194fe9d0682206642", "source": "vatex", "video_id": "ZhlgZbh_EZI_000000_000010", "video_description": "A young man is riding a Segway down a neighborhood street, sometimes kneeling and moving at a fast speed.", "task": "ObjectRecognition", "clean_prompt": "A young man riding a Segway down a neighborhood street.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running down a neighborhood street.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man riding a Segway down a neighborhood street. F=))-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b36ec5e8ffb34372b87efd818da750f2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d508ce19220543b6ab23f33c3fc76918", "source": "vatex", "video_id": "LAqqJXdiNIo_000001_000011", "video_description": "A man is sitting in a cafe, smoking a hookah and attempting to blow smoke rings and shapes with the smoke.", "task": "ActionRecognition", "clean_prompt": "A person smoking a hookah in a cafe, attempting to blow smoke rings.", "clean_property": {"obj": "person", "action": "smoking hookah", "target": null}, "target_prompt": "A person drinking coffee in a cafe.", "target_property": {"obj": "person", "action": "drinking coffee", "target": null}, "evaluation_question": "Is the person **smoking a hookah**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person smoking a hookah in a cafe, attempting to blow smoke rings. FE;7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6545ddf6605b4eeeafa1fb6eaddbd403.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "207f44b4c0e946edbfd8c1c7005d2920", "source": "vatex", "video_id": "2MBgEM5mHms_000000_000010", "video_description": "A young man with long hair is playing an electric guitar in a room, demonstrating expert skills and fast-paced music.", "task": "ActionRecognition", "clean_prompt": "A person playing guitar in a room.", "clean_property": {"obj": "person", "action": "playing guitar", "target": null}, "target_prompt": "A person playing drums in a room.", "target_property": {"obj": "person", "action": "playing drums", "target": null}, "evaluation_question": "Is the person **playing guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing guitar in a room. RR>..", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6792949b66dc458abe1b272d9185b7ef.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a061b2fa9de045d196160b1a4cfa3f68", "source": "vatex", "video_id": "dvWWg9wCWY4_000209_000219", "video_description": "A group of people, including children and adults, are climbing and descending a rock climbing wall outdoors at a recreational site.", "task": "AttributeRecognition", "clean_prompt": "A person climbing a rock climbing wall with children and adults outdoors.", "clean_property": {"obj": "person", "attribute": "children"}, "target_prompt": "A person climbing indoors.", "target_property": {"obj": "person", "attribute": "climbing indoors"}, "evaluation_question": "Is the person climbing a rock climbing wall **outdoors**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person climbing a rock climbing wall with children and adults outdoors. >M$UI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1ab490cc39f497fa10f2c27dddf4fff.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1db4c14e5264781a09a9d60ee634c8e", "source": "vatex", "video_id": "m73EdlvDuiw_000045_000055", "video_description": "A man is demonstrating and explaining how to tie a complex knot using ropes at a table.", "task": "ActionRecognition", "clean_prompt": "A person tying a complex knot with a rope at a table.", "clean_property": {"obj": "person", "action": "tying knot (not on a tie)", "target": "rope"}, "target_prompt": "A person untying a knot with a rope at a table.", "target_property": {"obj": "person", "action": "untying knot", "target": "rope"}, "evaluation_question": "Is the person **tying** a knot?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a complex knot with a rope at a table. BSQL(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a40602963af41e894925193471ba2c4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ba17d2750d164700a7e4cfd782397800", "source": "vatex", "video_id": "th9TRkTPLE0_000072_000082", "video_description": "A man wearing glasses is using a circular saw to cut through a metal railing outdoors.", "task": "ActionRecognition", "clean_prompt": "A person using a circular saw to cut through a metal railing outdoors.", "clean_property": {"obj": "person", "action": "using circular saw", "target": "metal railing"}, "target_prompt": "A person using a chainsaw to cut through a wooden log outdoors.", "target_property": {"obj": "person", "action": "using a chainsaw", "target": "wooden log"}, "evaluation_question": "Is the person **using a circular saw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a circular saw to cut through a metal railing outdoors. -%|&-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b92a684f0052498b8e97e49adecaffdd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7eafb581186541339e830bb205f30d19", "source": "vatex", "video_id": "HfkPAd_x--o_000017_000027", "video_description": "A shirtless man in a bright white room is covering and uncovering his eyes with his hands, applying a men's eye product.", "task": "ObjectRecognition", "clean_prompt": "A shirtless man in a bright white room is covering and uncovering his eyes with his hands, applying a men's eye product.", "clean_property": {"obj": "person"}, "target_prompt": "A woman in a bright white room is covering and uncovering her eyes with her hands, applying a women's eye product.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A shirtless man in a bright white room is covering and uncovering his eyes with his hands, applying a men's eye product. LY+0J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/018bfe04f60c43ac9a38013146da6405.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fefe83c6a6684eddbfbcf9371b001514", "source": "vatex", "video_id": "4l_1fCrxV94_000000_000010", "video_description": "A street artist is creating art using spray paint on a canvas on a sidewalk in a city.", "task": "ObjectRecognition", "clean_prompt": "A street artist is creating art using spray paint on a canvas on a sidewalk in a city.", "clean_property": {"obj": "artist"}, "target_prompt": "A musician playing guitar on a sidewalk in a city.", "target_property": {"obj": "musician"}, "evaluation_question": "Is the person in the video an **artist**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A street artist is creating art using spray paint on a canvas on a sidewalk in a city. +FE9M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cbc89b4c18b46c6925120a2a2c51598.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "82117c964684463c9434b2052c263e6a", "source": "vatex", "video_id": "oX_R_BB8Jk4_000018_000028", "video_description": "A woman wearing sunglasses is outdoors, eating a sandwich while walking and talking. She is vlogging and occasionally taking selfie videos.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a sandwich.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "sandwich"}, "target_prompt": "A person standing to the right of a sandwich.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "sandwich"}, "evaluation_question": "Is the person to the **left** of a sandwich?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a sandwich. -TSL.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2dc583833bf4e7c9f663dd34d092c06.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "00dac96378cb47f29c425f60f6131219", "source": "vatex", "video_id": "7MDTe0xp2hc_000068_000078", "video_description": "A young girl is trying to jump rope while her younger brother interferes and imitates her efforts in a home setting near the stairs.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the left of a girl who is trying to jump rope.", "clean_property": {"obj_1": "boy", "relation": "left of", "obj_2": "girl"}, "target_prompt": "A boy standing to the right of a girl who is trying to jump rope.", "target_property": {"obj_1": "boy", "relation": "right of", "obj_2": "girl"}, "evaluation_question": "Is the boy to the **left** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the left of a girl who is trying to jump rope. ;9,MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3906d2fc7dfd401e8a1712b799f5880a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "82df4d70bf9748bf9daf0fd0f33746fd", "source": "vatex", "video_id": "0vriOSloUe0_000000_000010", "video_description": "A young woman is sitting nervously while a man, possibly a doctor, wearing white gloves, performs a procedure on her ear, causing her discomfort.", "task": "AttributeRecognition", "clean_prompt": "A man wearing white gloves is performing a procedure on a young woman's ear.", "clean_property": {"obj": "man", "attribute": "wearing white gloves"}, "target_prompt": "A man wearing black gloves is performing a procedure on a young woman's ear.", "target_property": {"obj": "man", "attribute": "wearing black gloves"}, "evaluation_question": "Is the man wearing **white** gloves?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing white gloves is performing a procedure on a young woman's ear. )*EY)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df122751a3364d3290673f9505afb92a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b28e8f548760437d85ece39c73f3f1c9", "source": "vatex", "video_id": "v6MBrnO1qyg_000010_000020", "video_description": "A person is kayaking on a river with large rocky banks and formations, navigating through a rocky coastline.", "task": "AttributeRecognition", "clean_prompt": "A person kayaking on a river with large rocky banks.", "clean_property": {"obj": "rock", "attribute": "large"}, "target_prompt": "A person kayaking on a river with small rocky banks.", "target_property": {"obj": "rock", "attribute": "small"}, "evaluation_question": "Are the banks of the river made of **large** rocks?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person kayaking on a river with large rocky banks. MT)FX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/186d6aa82aaa4250864a99f6a024a56d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0e2f4b5885a64d0395727d5855e2d4aa", "source": "vatex", "video_id": "T2bfRXRQaHg_000105_000115", "video_description": "A group of people are learning and demonstrating how to fold fabric into flower shapes.", "task": "AttributeRecognition", "clean_prompt": "A group of people are learning and demonstrating how to fold pink fabric into flower shapes.", "clean_property": {"obj": "fabric", "attribute": "pink"}, "target_prompt": "A group of people are learning and demonstrating how to fold blue fabric into flower shapes.", "target_property": {"obj": "fabric", "attribute": "blue"}, "evaluation_question": "Is the fabric being folded **pink**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people are learning and demonstrating how to fold pink fabric into flower shapes. FS'SS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b7b18f5a08142f3a615e1bf9ba548a7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5228a487fc56494ba5bee188b2904a3e", "source": "vatex", "video_id": "WB909WkQeuA_000000_000010", "video_description": "A young woman performs a back flip off a diving board into a swimming pool during a diving competition.", "task": "Counting", "clean_prompt": "Four divers performing synchronized dives into a swimming pool.", "clean_property": {"obj": "diver", "count": "four"}, "target_prompt": "A single diver performing a solo dive into a swimming pool.", "target_property": {"obj": "diver", "count": "one"}, "evaluation_question": "Are there exactly **four** divers performing synchronized dives?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four divers performing synchronized dives into a swimming pool. LYC\u00b7T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e04495b7dc2458f8260084089d8fc16.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2593c28dc8554bf7acc605979cc4cd74", "source": "vatex", "video_id": "emsAF8O2jAA_000002_000012", "video_description": "A person is shoveling snow off a wooden deck using a large yellow shovel while a border collie waits nearby.", "task": "ObjectRecognition", "clean_prompt": "A person is shoveling snow off a wooden deck using a large yellow shovel while a border collie waits nearby.", "clean_property": {"obj": "shovel"}, "target_prompt": "A person is raking leaves off a wooden deck while a border collie waits nearby.", "target_property": {"obj": "rake"}, "evaluation_question": "Is the person using a **shovel** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is shoveling snow off a wooden deck using a large yellow shovel while a border collie waits nearby. ))'!=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c42a58ad41a94bab8c9a32bae07cda43.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f5b2d79c2f0477fa3238648bc7caafb", "source": "vatex", "video_id": "fde0fnYJszI_000679_000689", "video_description": "A person is cooking scrambled eggs in a nonstick pan on a gas stove, using a spatula to stir and scoop the eggs.", "task": "ObjectRecognition", "clean_prompt": "A person is cooking scrambled eggs in a nonstick pan on a gas stove.", "clean_property": {"obj": "person"}, "target_prompt": "A cat is playing with a ball of yarn on the kitchen floor.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is cooking scrambled eggs in a nonstick pan on a gas stove. LFEFF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f946688c2644dc5b608959fa00aea0a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae6c483901274c968d69085de40a7fe5", "source": "vatex", "video_id": "f-aMZKU5V5M_000148_000158", "video_description": "A person is demonstrating how to make jewelry, specifically necklaces, using a hot glue gun and other materials like plastic, rope, and nail polish.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating how to make jewelry using a hot glue gun and various materials.", "clean_property": {"obj": "jewelry"}, "target_prompt": "A person demonstrating how to make furniture using a hot glue gun and various materials.", "target_property": {"obj": "furniture"}, "evaluation_question": "Is the object being made in the video **jewelry**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to make jewelry using a hot glue gun and various materials. QCKZ3", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab7fddd5cfc240e5953cee4cffe91044.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7ffc07d63b014c96b706f3f053a21891", "source": "vatex", "video_id": "cAaCIJBjWQA_000011_000021", "video_description": "A series of images and videos show people interacting with various industrial sewing machines at an event. A man is seen sewing with one of the machines, and a woman in a white t-shirt is also using a sewing machine.", "task": "SpatialUnderstanding", "clean_prompt": "A sewing machine closer to the camera than a person.", "clean_property": {"obj_1": "sewing machine", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A sewing machine further from the camera than a person.", "target_property": {"obj_1": "sewing machine", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the sewing machine **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sewing machine closer to the camera than a person. ~)!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ced88733089a448eaa0a99f9f3452f93.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "132591a4cebe4b9daa2ddb9943821c37", "source": "vatex", "video_id": "cbznHY8uOOE_000006_000016", "video_description": "A man is demonstrating and explaining how to perform exercises using an exercise ball, including balancing and pull-ins.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating exercises using an exercise ball, including balancing and pull-ins.", "clean_property": {"obj": "exercise ball"}, "target_prompt": "A man demonstrating exercises using a yoga mat, including stretching and poses.", "target_property": {"obj": "yoga mat"}, "evaluation_question": "Is the man using an **exercise ball** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating exercises using an exercise ball, including balancing and pull-ins. X|FEF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ccde671841d24c8da0eb6f6816e7a529.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d1df85377314d73a26f41b2b5f62ae7", "source": "vatex", "video_id": "sWBXuV7imP8_000012_000022", "video_description": "A man is using a handheld leaf blower to blow leaves in a large square area on a field.", "task": "ObjectRecognition", "clean_prompt": "A man using a handheld leaf blower to blow leaves in a large square area on a field.", "clean_property": {"obj": "leaf blower"}, "target_prompt": "A man using a vacuum cleaner to clean a large square area on a field.", "target_property": {"obj": "vacuum cleaner"}, "evaluation_question": "Is the man using a **leaf blower** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a handheld leaf blower to blow leaves in a large square area on a field. FE()M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ff52c93a4a149fc97875df028af5952.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b77353a0cf8e4a68a3b19d0a26142b19", "source": "vatex", "video_id": "1jIKAImNXBk_000000_000010", "video_description": "A boy is writing or drawing on the side of a blue phone booth with a black marker.", "task": "ActionRecognition", "clean_prompt": "A person tagging graffiti on the side of a blue phone booth.", "clean_property": {"obj": "person", "action": "tagging graffiti", "target": "phone booth"}, "target_prompt": "A person removing graffiti from a blue phone booth.", "target_property": {"obj": "person", "action": "removing graffiti", "target": "phone booth"}, "evaluation_question": "Is the person **tagging graffiti** on the phone booth?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tagging graffiti on the side of a blue phone booth. TZ$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab2e3b89414b4e46a9d246280b3a5e11.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e75fd2463d4a4905b50eb057e30711a2", "source": "vatex", "video_id": "7T5nKVJrP5U_000120_000130", "video_description": "A woman is using a sewing machine to sew a piece of blue fabric, then cuts the thread and moves the fabric to a table.", "task": "AttributeRecognition", "clean_prompt": "A woman is using a sewing machine to sew a piece of blue fabric.", "clean_property": {"obj": "fabric", "attribute": "blue"}, "target_prompt": "A woman is using a sewing machine to sew a piece of red fabric.", "target_property": {"obj": "fabric", "attribute": "red"}, "evaluation_question": "Is the fabric being sewn **blue**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using a sewing machine to sew a piece of blue fabric. P$=BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee0e3321ac9e410e9c50f0a7cde6018f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8d6c1dc6c91b4cd7a404d80f6efc6089", "source": "vatex", "video_id": "-4HEECqpLUQ_000094_000104", "video_description": "A woman is demonstrating and explaining how to fold a piece of grey fabric into a small shape.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a piece of grey fabric.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "fabric"}, "target_prompt": "A person closer to the camera than a piece of grey fabric.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "fabric"}, "evaluation_question": "Is the person farther from the camera than the piece of grey fabric?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a piece of grey fabric. ,,.FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/283d495116bc48a5939e7261d77ed29c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7e01e5aef0d4932a3310ec1e49b4175", "source": "vatex", "video_id": "onEA5oqJzjY_000060_000070", "video_description": "A person is using a power grinding tool to smooth and remove paint from various metal surfaces, including diamond plate and stainless steel, while wearing gloves.", "task": "ObjectRecognition", "clean_prompt": "A person using a power grinding tool to smooth and remove paint from metal surfaces.", "clean_property": {"obj": "person"}, "target_prompt": "A robot using a power grinding tool to smooth and remove paint from metal surfaces.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the object in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a power grinding tool to smooth and remove paint from metal surfaces. >4OAE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e1dd1e2bd44449f69194ae5ad102f5d1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8ca110c6cac54203a98168242aa1371e", "source": "vatex", "video_id": "AxMf6X5_A3A_000002_000012", "video_description": "A boy rides his bicycle from the sidewalk through the grass and falls.", "task": "ActionRecognition", "clean_prompt": "A boy riding a bike on the sidewalk.", "clean_property": {"obj": "boy", "action": "riding a bike", "target": null}, "target_prompt": "A boy falling off a bike.", "target_property": {"obj": "boy", "action": "falling off a bike", "target": null}, "evaluation_question": "Is the boy **riding** a bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy riding a bike on the sidewalk. PMSTP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ebb4e602272542a1a4b44cd5df1139c6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1798c800bc484aed9b6cf31f45c0427a", "source": "vatex", "video_id": "Unz7ZLYhEz4_000003_000013", "video_description": "A group of people, including a young man with blond hair, are in a kitchen discussing who will take a shot first. The young man takes a shot from a shot glass.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a shot glass in a kitchen.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "shot glass"}, "target_prompt": "A person further from the camera than a shot glass in a kitchen.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "shot glass"}, "evaluation_question": "Is the person **closer to the camera than** the shot glass?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a shot glass in a kitchen. -FOE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef174a58c14d4558a8ba178a3ac0f578.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce41f2f99f214f289224afb658569070", "source": "vatex", "video_id": "PjMBFaF-LDY_000202_000212", "video_description": "A woman is demonstrating various methods of cooking eggs, including frying and poaching, using a frying pan and a pot of water in a kitchen.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating how to cook an egg sunny side up in a frying pan.", "clean_property": {"obj": "egg", "attribute": "sunny side up"}, "target_prompt": "A woman demonstrating how to cook a boiled egg in a pot of water.", "target_property": {"obj": "egg", "attribute": "boiled"}, "evaluation_question": "Is the egg being cooked sunny side up?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to cook an egg sunny side up in a frying pan. XS$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cf1c1fd5f67649ddb22e1a921744ad50.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "228d09649c93472f8920ceae9ef03edb", "source": "vatex", "video_id": "RAcacx5bGFg_000000_000010", "video_description": "A young boy is driving a large red tractor with a canopy in a field, while a man walks beside him giving instructions.", "task": "SpatialUnderstanding", "clean_prompt": "A man walking to the right of a tractor in a field.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "tractor"}, "target_prompt": "A man walking to the left of a tractor in a field.", "target_property": {"obj_1": "man", "relation": "left of", "obj_2": "tractor"}, "evaluation_question": "Is the man to the **right** of the tractor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man walking to the right of a tractor in a field. BG#BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19a236b05f6540c39abfd665255f4a55.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7ad6267a7e744ffd95efb2a2788f3d88", "source": "vatex", "video_id": "C-hAzpBhjOE_000019_000029", "video_description": "A man in an orange sweatshirt is using a leaf blower to clear leaves from under a pavilion.", "task": "Counting", "clean_prompt": "Six people are gathered under a pavilion, with one of them using a leaf blower to clear leaves.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Three people are gathered under a pavilion, with one of them using a leaf blower to clear leaves.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **six** people under the pavilion?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people are gathered under a pavilion, with one of them using a leaf blower to clear leaves. >FEGC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73f73a3675f148cbb8082d119942f485.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0580f9822af44503a555fdce6172a283", "source": "vatex", "video_id": "2GAPlZ6gD8s_000038_000048", "video_description": "A young man is standing outside on a lawn, demonstrating various juggling techniques with three balls.", "task": "ActionRecognition", "clean_prompt": "A person juggling balls on a lawn.", "clean_property": {"obj": "person", "action": "juggling balls", "target": null}, "target_prompt": "A person juggling clubs on a lawn.", "target_property": {"obj": "person", "action": "juggling clubs", "target": null}, "evaluation_question": "Is the person **juggling balls**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person juggling balls on a lawn. %&FE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c1af93af085403fb2fb0f74b569eff7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31ca4da04f0d45c6bd303bc565a2e943", "source": "vatex", "video_id": "sGxujaBZWEI_000001_000011", "video_description": "A man is performing deadlifts in a busy gym, lifting a barbell with heavy weights up to his thighs and then lowering it back down in multiple repetitions.", "task": "AttributeRecognition", "clean_prompt": "A man is performing deadlifts in a busy gym, lifting a heavy barbell up to his thighs and then lowering it back down in multiple repetitions.", "clean_property": {"obj": "barbell", "attribute": "heavy"}, "target_prompt": "A man is performing deadlifts in a busy gym, lifting a light barbell up to his thighs and then lowering it back down in multiple repetitions.", "target_property": {"obj": "barbell", "attribute": "light"}, "evaluation_question": "Is the barbell being lifted **heavy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is performing deadlifts in a busy gym, lifting a heavy barbell up to his thighs and then lowering it back down in multiple repetitions. )!%|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef290bd438054210ac7324c2cef3f8bf.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a19abb5e090e4f79b5b2652814add43a", "source": "vatex", "video_id": "IgLTMmrT6Ts_000019_000029", "video_description": "An older man is assisting a young boy in using a power drill on a piece of wood, with a woman nearby cautioning them.", "task": "ActionRecognition", "clean_prompt": "An older man using a power drill to assist a young boy on a piece of wood.", "clean_property": {"obj": "older man", "action": "using a power drill", "target": "young boy"}, "target_prompt": "An older man using a hammer to assist a young boy on a piece of wood.", "target_property": {"obj": "older man", "action": "using a hammer", "target": "young boy"}, "evaluation_question": "Is the older man **using a power drill**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An older man using a power drill to assist a young boy on a piece of wood. ))*-&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f2f3d2091cc84066a9ba9d2fba2dca27.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "24737fd9e6b9472395ec4985e0eae864", "source": "vatex", "video_id": "SAHCw0f5Jgo_000108_000118", "video_description": "A group of people are using a rope to navigate through a body of water, ensuring safe passage across a stream or river.", "task": "AttributeRecognition", "clean_prompt": "A group of people using a rope to navigate through murky water.", "clean_property": {"obj": "water", "attribute": "murky"}, "target_prompt": "A group of people using a rope to navigate through clear water.", "target_property": {"obj": "water", "attribute": "clear"}, "evaluation_question": "Is the water murky?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people using a rope to navigate through murky water. 7S$DP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/faf42e8208c04488b8664039c022d490.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc60bc1e277f44f5804984c46fb0a5f9", "source": "vatex", "video_id": "W9YS0dYAQIw_000008_000018", "video_description": "A young boy is playing with a tennis ball inside a house. He picks up the ball, tosses it, and chases it while laughing.", "task": "ObjectRecognition", "clean_prompt": "A child playing with a tennis ball inside a house.", "clean_property": {"obj": "child"}, "target_prompt": "A dog playing with a tennis ball inside a house.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the object in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child playing with a tennis ball inside a house. BSQO7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d3694f55e5cd47d18c60dc87609ee1d8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1372a537e5f6487e908c8e76cc93a803", "source": "vatex", "video_id": "PerALwJ7XT4_000132_000142", "video_description": "A person demonstrates how to use a hole punching machine to punch holes in paper and bind them together.", "task": "SpatialUnderstanding", "clean_prompt": "A person demonstrating how to use a hole punching machine to punch holes in paper that is farther from the camera than the person.", "clean_property": {"obj_1": "paper", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A person demonstrating how to use a hole punching machine to punch holes in paper that is closer to the camera than the person.", "target_property": {"obj_1": "paper", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the paper farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to use a hole punching machine to punch holes in paper that is farther from the camera than the person. ))/!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5d90f36ef46a495cb60d1818bc187dda.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d938ecdde6b43d498fb3a0ecf21908a", "source": "vatex", "video_id": "e7ft9fizUXQ_000078_000088", "video_description": "A person is creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques on a piece of paper.", "task": "SpatialUnderstanding", "clean_prompt": "A person creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques, while a pen is placed on the table farther from the camera than the person.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "pen"}, "target_prompt": "A person creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques, while a pen is placed on the table closer to the camera than the person.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "pen"}, "evaluation_question": "Is the person farther from the camera than the pen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person creating a Christmas card with floral designs and the words 'Joy to the World' using calligraphy techniques, while a pen is placed on the table farther from the camera than the person. YG)(J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c8789b7cd0b44499408bfc7db181130.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5c137179fd8470d9d3f0d97b353a1ca", "source": "vatex", "video_id": "tTMD0YpVIpg_000118_000128", "video_description": "A woman is preparing and applying a homemade face scrub or mask to her face.", "task": "AttributeRecognition", "clean_prompt": "A woman applying a natural face scrub to her face.", "clean_property": {"obj": "face scrub", "attribute": "natural"}, "target_prompt": "A woman applying a chemical face scrub to her face.", "target_property": {"obj": "face scrub", "attribute": "chemical"}, "evaluation_question": "Is the face scrub **natural**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman applying a natural face scrub to her face. LY2#N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/767b6f1de35c416e8b4a2eb8b9c89b91.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e16463f75bd646f994925dca3c20badb", "source": "vatex", "video_id": "YcFRA_DU-KI_000018_000028", "video_description": "A woman is demonstrating and explaining how to clean and care for cowboy boots using a brush and cloth.", "task": "Counting", "clean_prompt": "A woman is demonstrating how to clean cowboy boots using a brush and four cloths.", "clean_property": {"obj": "cloth", "count": "four"}, "target_prompt": "A woman is demonstrating how to clean cowboy boots using a brush and one cloth.", "target_property": {"obj": "cloth", "count": "one"}, "evaluation_question": "Are there exactly **four** cloths being used to clean the cowboy boots?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to clean cowboy boots using a brush and four cloths. H|FEM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c8b16a3399894a6195b5a7d1ce22ab36.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c81ebe2a3339424c8024c2f9d81cc5e2", "source": "vatex", "video_id": "2KsKfc2TcEU_000063_000073", "video_description": "A woman is vacuuming the floor in a room, then turns off the vacuum cleaner and walks away, leaving it plugged in.", "task": "ObjectRecognition", "clean_prompt": "A woman is vacuuming the floor in a room.", "clean_property": {"obj": "person"}, "target_prompt": "A cat is playing with a ball of yarn in a room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is vacuuming the floor in a room. /!0CB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4388b74660684b7d8752fcefb1f6c605.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f25fbb1d89ce471084561afaf985f4b5", "source": "vatex", "video_id": "nCJz3cftWVA_000002_000012", "video_description": "A girl is walking on a tightrope outdoors, assisted by a boy who holds her hand for balance.", "task": "SpatialUnderstanding", "clean_prompt": "A girl walking to the right of a tightrope.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "tightrope"}, "target_prompt": "A girl walking to the left of a tightrope.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "tightrope"}, "evaluation_question": "Is the girl to the **right** of the tightrope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl walking to the right of a tightrope. R$X#8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5020d556ec104609a593864e5fd92215.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d51403ecb95d46f292ad9ffd8e981b45", "source": "vatex", "video_id": "nfN9LuxGUUo_000239_000249", "video_description": "A woman is demonstrating how to handle and separate her very curly, blonde hair.", "task": "Counting", "clean_prompt": "A woman demonstrating how to handle and separate her very curly, blonde hair with seven people watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman demonstrating how to handle and separate her very curly, blonde hair with three people watching her.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to handle and separate her very curly, blonde hair with seven people watching her. ML>.G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d4a1e47f23f4b77b4090e1bba9ae82c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "753042f8e0f14ae1b0a1e53dd5f6fc65", "source": "vatex", "video_id": "cHsOSosRVSs_000016_000026", "video_description": "A young girl runs into a kitchen, slips, and falls on the floor, crying out in pain.", "task": "Counting", "clean_prompt": "Five girls running into a kitchen, one of them slips and falls on the floor, crying out in pain.", "clean_property": {"obj": "girl", "count": "five"}, "target_prompt": "One girl running into a kitchen, slipping and falling on the floor, crying out in pain.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **five** girls running into the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five girls running into a kitchen, one of them slips and falls on the floor, crying out in pain. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f526c39e2ffb4875b8f7ed072059f7d9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7eb345a5296249798bdda5953f80ccc6", "source": "vatex", "video_id": "hdiAz0P4Iwo_000060_000070", "video_description": "A woman is laying on a mat while a personal trainer demonstrates stretching and flexibility exercises by holding and rotating her legs and ankles.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the right of a mat.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "mat"}, "target_prompt": "A woman standing to the left of a mat.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "mat"}, "evaluation_question": "Is the man to the **right** of a mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the right of a mat. FGX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/023750e954ff41189da3f54498eecb22.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed6dad35e65749d681cae6bac130abb2", "source": "vatex", "video_id": "M9sGALsPg-0_000000_000010", "video_description": "Three men are standing by a pool table, one of them makes music by blowing his nose, and all three start dancing to the beat.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a pool table.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "pool table"}, "target_prompt": "A man closer to the camera than a pool table.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "pool table"}, "evaluation_question": "Is the man **farther from the camera than** the pool table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a pool table. /!A%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f556df0e09d418cae1c796828da4161.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5b74eca3aee244c9ae6213988c3bb736", "source": "vatex", "video_id": "B9nnm3hoAis_000011_000021", "video_description": "A person demonstrates how to operate a table saw by turning it on and off, showing its functionality in a workshop setting.", "task": "ActionRecognition", "clean_prompt": "A person using a circular saw in a workshop.", "clean_property": {"obj": "person", "action": "using circular saw", "target": null}, "target_prompt": "A person using a hand saw in a workshop.", "target_property": {"obj": "person", "action": "using a hand saw", "target": null}, "evaluation_question": "Is the person **using a circular saw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a circular saw in a workshop. BSQ$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f7a449eb3b546129eaccf9e7fcee473.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5d88ef28ea584530a42d93222da647d6", "source": "vatex", "video_id": "U_u0hPg8wT8_000021_000031", "video_description": "A young man is in his bedroom, talking to a camera and playing an ocarina.", "task": "ActionRecognition", "clean_prompt": "A person playing an ocarina in a bedroom.", "clean_property": {"obj": "person", "action": "playing ocarina", "target": null}, "target_prompt": "A person playing guitar in a bedroom.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing an ocarina**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing an ocarina in a bedroom. FG.R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9dbe15a03380444baef90882f2a0385c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "589773ca6a1e403abd79c5c90b110ca6", "source": "vatex", "video_id": "KCQkHma1cHw_000000_000010", "video_description": "A group of men are playing beer pong in a garage, attempting to throw ping pong balls into cups. When a ball lands in a cup, the person drinks the contents.", "task": "ObjectRecognition", "clean_prompt": "A group of men playing beer pong in a garage, throwing ping pong balls into cups.", "clean_property": {"obj": "cup"}, "target_prompt": "A group of men playing basketball in a garage, throwing balls into baskets.", "target_property": {"obj": "basket"}, "evaluation_question": "Are the men throwing ping pong balls into **cups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of men playing beer pong in a garage, throwing ping pong balls into cups. W%HLB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d82771dd2a984b979a94c6f22b60fc82.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac1e3695b5fe4543ae812ee317ee4cdd", "source": "vatex", "video_id": "pFYbvFzOQVc_000028_000038", "video_description": "A young girl is practicing handstands and headstands in her living room, using the wall for support. She occasionally falls, crawls, and talks to the camera.", "task": "Counting", "clean_prompt": "A young girl is practicing handstands and headstands in her living room, using the wall for support, with six cameras capturing her movements.", "clean_property": {"obj": "camera", "count": "six"}, "target_prompt": "A young girl is practicing handstands and headstands in her living room, using the wall for support, with one camera capturing her movements.", "target_property": {"obj": "camera", "count": "one"}, "evaluation_question": "Are there exactly **six** cameras capturing her movements?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is practicing handstands and headstands in her living room, using the wall for support, with six cameras capturing her movements. EDJJJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/307d8e23c19148409a094dbc756b6345.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb862eb51ba849e39ac34861e7b1269d", "source": "vatex", "video_id": "EOZoWBUMN1U_000078_000088", "video_description": "A man is standing in a shallow river using a pumping machine with hoses to pump water.", "task": "AttributeRecognition", "clean_prompt": "A man standing in a shallow river using a pumping machine with long hoses to pump water.", "clean_property": {"obj": "hose", "attribute": "long"}, "target_prompt": "A man standing in a shallow river using a pumping machine with short hoses to pump water.", "target_property": {"obj": "hose", "attribute": "short"}, "evaluation_question": "Are the hoses being used by the man long?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing in a shallow river using a pumping machine with long hoses to pump water. >7\u00b7BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/719158b610e546339f32d0b4b175aa8c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a32c5c38c78f44ce93dfc12f32c4a272", "source": "vatex", "video_id": "FbpBmq5-a_A_000011_000021", "video_description": "A man and a boy are swinging back and forth on swings outside in a grassy area.", "task": "ActionRecognition", "clean_prompt": "A man swinging on a swing in a grassy area.", "clean_property": {"obj": "man", "action": "swinging on something", "target": null}, "target_prompt": "A man swinging on a trapeze.", "target_property": {"obj": "man", "action": "swinging on a trapeze", "target": null}, "evaluation_question": "Is the man **swinging on a swing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man swinging on a swing in a grassy area. RTMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1f0ed78301847c9856aafaa578a24ea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a121ddc2c564b3bb04b9819086fe4e5", "source": "vatex", "video_id": "5L0jGOL4luc_000006_000016", "video_description": "A group of adults and a young girl are sitting around a kitchen table playing dominoes, talking, and engaging in drinking games.", "task": "ActionRecognition", "clean_prompt": "An adult playing dominoes at a kitchen table.", "clean_property": {"obj": "adult", "action": "playing dominoes", "target": null}, "target_prompt": "An adult playing cards at a kitchen table.", "target_property": {"obj": "adult", "action": "playing cards", "target": null}, "evaluation_question": "Is the adult **playing dominoes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult playing dominoes at a kitchen table. FE,B$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb3172b9ac7343429d43a200a77d38f3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de7090816dbe45cea3179358c2ce7100", "source": "vatex", "video_id": "LAx9oAvCugA_000103_000113", "video_description": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing Monopoly.", "task": "AttributeRecognition", "clean_prompt": "Two young boys in monster costumes sitting at a dining room table playing Monopoly.", "clean_property": {"obj": "table", "attribute": "dining room"}, "target_prompt": "Two young boys in monster costumes sitting at an outdoor picnic table playing Monopoly.", "target_property": {"obj": "table", "attribute": "outdoor picnic"}, "evaluation_question": "Are the boys sitting at a **dining room** table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys in monster costumes sitting at a dining room table playing Monopoly. D|&=&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/72685c7e9ca74b40898fb82e21a9a27c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "71cbde6ea8f247fa8f7a10c05032a163", "source": "vatex", "video_id": "OI0sr6Q-NKM_000012_000022", "video_description": "A man is performing a one-handed handstand on a balancing device in a gymnasium.", "task": "ObjectRecognition", "clean_prompt": "A man is performing a one-handed handstand on a balancing device in a gymnasium.", "clean_property": {"obj": "balancing device"}, "target_prompt": "A man is performing a one-handed handstand on a trampoline in a gymnasium.", "target_property": {"obj": "trampoline"}, "evaluation_question": "Is the man performing on a **balancing device**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is performing a one-handed handstand on a balancing device in a gymnasium. ))|?D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4c814122edc54250985efaa17467f802.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7590298400db4784bc66835a32542232", "source": "vatex", "video_id": "qGfEiJEu0AM_000003_000013", "video_description": "A person is seated in a room, playing a guitar on their lap in a unique way that includes strumming, plucking, and tapping the guitar for percussion, while singing.", "task": "Counting", "clean_prompt": "A person is seated in a room, playing a guitar on their lap in a unique way that includes strumming, plucking, and tapping the guitar for percussion, while singing.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Two people are seated in a room, playing guitars on their laps in a unique way that includes strumming, plucking, and tapping the guitars for percussion, while singing.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is seated in a room, playing a guitar on their lap in a unique way that includes strumming, plucking, and tapping the guitar for percussion, while singing. '''!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c331b2ddb85495c951d69a1a2d70f23.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e11385b5db404280b44d63038396cdcb", "source": "vatex", "video_id": "EEHbRGcMLnk_000030_000040", "video_description": "A person is paddling a canoe or kayak in a waterway near a city, participating in a race with background music playing.", "task": "ActionRecognition", "clean_prompt": "A person paddling a canoe in a waterway near a city, participating in a race with background music playing.", "clean_property": {"obj": "person", "action": "canoeing or kayaking", "target": null}, "target_prompt": "A person swimming in a waterway near a city.", "target_property": {"obj": "person", "action": "swimming", "target": null}, "evaluation_question": "Is the person **paddling a canoe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person paddling a canoe in a waterway near a city, participating in a race with background music playing. ?)!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c32ac0e5b6646c48290d4cca9ecf4af.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "60eebebf667f42548b5064beb3f75d20", "source": "vatex", "video_id": "FX1DxRUsw6o_000337_000347", "video_description": "A man is demonstrating and explaining how to use various tools to work with wood, including a router, saw, and other mechanical hand tools.", "task": "ActionRecognition", "clean_prompt": "A person using a circular saw on a piece of wood.", "clean_property": {"obj": "person", "action": "using circular saw", "target": "wood"}, "target_prompt": "A person using a hammer on a piece of wood.", "target_property": {"obj": "person", "action": "using a hammer", "target": "wood"}, "evaluation_question": "Is the person **using a circular saw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a circular saw on a piece of wood. =FCEP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7bd907796fe144e183019dc5e6060fc8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6b12c9f272f5443b98c76d88d938fa68", "source": "vatex", "video_id": "BuN9L6Od7P4_000000_000010", "video_description": "A man in India uses an ATM machine by inserting his card while a woman waits behind him.", "task": "ActionRecognition", "clean_prompt": "A man using an ATM machine in India.", "clean_property": {"obj": "man", "action": "using atm", "target": null}, "target_prompt": "A man walking away from an ATM machine in India.", "target_property": {"obj": "man", "action": "walking away from atm", "target": null}, "evaluation_question": "Is the man **using** the ATM?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using an ATM machine in India. DPW)4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e3fb2b43bc9541aba1dd6076fa4502d7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bb71ac6ad2d2441e80f15c7ef0a791b9", "source": "vatex", "video_id": "r4sYfEcGrgg_000004_000014", "video_description": "A female athlete is participating in a javelin throw event at an outdoor track. She runs and throws the javelin with force while a group of people watches.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the left of a javelin.", "clean_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "javelin"}, "target_prompt": "An athlete standing to the right of a javelin.", "target_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "javelin"}, "evaluation_question": "Is the athlete to the **left** of the javelin?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete standing to the left of a javelin. UF\u00b7(M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fcfb77d1418047b2b8dad93b8c843801.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c88d6483b3bb47b18add913ea65886ef", "source": "vatex", "video_id": "q50mRGCvGQw_000015_000025", "video_description": "A young boy and an adult are playing a game of miniature chess on a bed. The boy occasionally says hi and interacts with the adult.", "task": "SpatialUnderstanding", "clean_prompt": "An adult sitting to the left of a child on a bed, playing a game of miniature chess.", "clean_property": {"obj_1": "adult", "relation": "left of", "obj_2": "child"}, "target_prompt": "An adult sitting to the right of a child on a bed, playing a game of miniature chess.", "target_property": {"obj_1": "adult", "relation": "right of", "obj_2": "child"}, "evaluation_question": "Is the adult sitting to the **left** of the child?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult sitting to the left of a child on a bed, playing a game of miniature chess. &#XSX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0279aec4e7f3471193c1018b202b4fc7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dc0531afa67d4b5885b0e347137df6f8", "source": "vatex", "video_id": "C-o3FYKKwFY_000023_000033", "video_description": "A boy in a red shirt is demonstrating and explaining how to juggle two white balls.", "task": "ActionRecognition", "clean_prompt": "A boy juggling two white balls in a red shirt.", "clean_property": {"obj": "boy", "action": "juggling balls", "target": null}, "target_prompt": "A boy throwing red balls in a red shirt.", "target_property": {"obj": "boy", "action": "throwing balls", "target": "red balls"}, "evaluation_question": "Is the boy **juggling** two white balls?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy juggling two white balls in a red shirt. !0BI,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd5c8455ca8a45dfbc01c1525aaf41dc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "28c51bfe6aa341d7a03ba666aaa34a18", "source": "vatex", "video_id": "8_1HELGfvXU_000106_000116", "video_description": "A man is demonstrating and explaining how to use a vacuum cleaner on a carpeted floor in an indoor setting.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to use a vacuum cleaner on a carpeted floor.", "clean_property": {"obj": "vacuum cleaner"}, "target_prompt": "A man demonstrating how to use a broom on a carpeted floor.", "target_property": {"obj": "broom"}, "evaluation_question": "Is the man using a **vacuum cleaner** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to use a vacuum cleaner on a carpeted floor. );1--", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc1aabf4b9404554aaf1f4f9b1af085f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c68a5e769a74486b8023ef8769078167", "source": "vatex", "video_id": "C0e62d1OUgA_000000_000010", "video_description": "A man is speaking at a podium while a woman interprets in sign language, making expressive faces. This is happening during a press conference or news event, with people watching and laughing in the background.", "task": "AttributeRecognition", "clean_prompt": "A man politician is speaking at a podium during a press conference, while a woman interprets in sign language.", "clean_property": {"obj": "man", "attribute": "politician"}, "target_prompt": "A woman activist is speaking at a podium during a press conference, while a man interprets in sign language.", "target_property": {"obj": "woman", "attribute": "activist"}, "evaluation_question": "Is the speaker a **man politician**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man politician is speaking at a podium during a press conference, while a woman interprets in sign language. MNPA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aa041cf663f745feb03638f0161a50b9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6ce99801394c4f46a3c7afcfa8f1337a", "source": "vatex", "video_id": "2xVH-79zc_U_000000_000010", "video_description": "A man is performing a shot put throw in an indoor facility while other men watch.", "task": "ObjectRecognition", "clean_prompt": "A man performing a shot put throw in an indoor facility while other men watch.", "clean_property": {"obj": "shot put"}, "target_prompt": "A man throwing a javelin in an outdoor stadium while other men watch.", "target_property": {"obj": "javelin"}, "evaluation_question": "Is the man performing a **shot put** throw?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing a shot put throw in an indoor facility while other men watch. RLSTM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ace3464f0e774e99bec1268f547eac9c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "38b1153837424ea2b193f2deb1ab349d", "source": "vatex", "video_id": "b-qLVLEjMcA_000011_000021", "video_description": "A group of young people, dressed in heavy winter clothing, are building a snowman in a snowy forest or park setting.", "task": "ObjectRecognition", "clean_prompt": "A group of young people building a snowman in a snowy park.", "clean_property": {"obj": "snowman"}, "target_prompt": "A group of young people building a sandcastle on the beach.", "target_property": {"obj": "sandcastle"}, "evaluation_question": "Are the young people building a **snowman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young people building a snowman in a snowy park. &=&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ef2b7ed941345c79cf6ee0766c5c1fa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4f35b3883b84140a7beaea0a2796b63", "source": "vatex", "video_id": "b8lFP6c6QYs_000013_000023", "video_description": "A person is using a sewing machine to stitch the outline of the United States onto a piece of black fabric.", "task": "ObjectRecognition", "clean_prompt": "A person is using a sewing machine to stitch the outline of the United States onto a piece of black fabric.", "clean_property": {"obj": "person"}, "target_prompt": "A robot is using a sewing machine to stitch the outline of the United States onto a piece of black fabric.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the person in the video using a sewing machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is using a sewing machine to stitch the outline of the United States onto a piece of black fabric. >G0BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8fc181bc6dac4656bf561e42bdf5949d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "08a75b54b16e45e68e27a90add7941eb", "source": "vatex", "video_id": "u05h5jyxAyQ_000009_000019", "video_description": "Two people are in a canoe on a lake, demonstrating how to turn and steer using paddles.", "task": "ActionRecognition", "clean_prompt": "A person canoeing on a lake, demonstrating how to turn and steer using paddles.", "clean_property": {"obj": "person", "action": "canoeing or kayaking", "target": null}, "target_prompt": "A person swimming in a lake.", "target_property": {"obj": "person", "action": "swimming", "target": null}, "evaluation_question": "Is the person **canoeing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person canoeing on a lake, demonstrating how to turn and steer using paddles. *TMTZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf1e7c4019494600af66f354e2aa6430.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3a58e70bc1974a5aaac26d0c66aa3e60", "source": "vatex", "video_id": "afjSa8mLtUg_000095_000105", "video_description": "A group of people are cross country skiing on a snowy, relatively flat surface on a sunny day. Music plays in the background.", "task": "AttributeRecognition", "clean_prompt": "A group of people cross country skiing on a snowy, relatively flat surface on a sunny day.", "clean_property": {"obj": "snow", "attribute": "relatively flat"}, "target_prompt": "A group of people cross country skiing on a snowy, steep and uneven surface on a sunny day.", "target_property": {"obj": "snow", "attribute": "steep and uneven"}, "evaluation_question": "Is the snow surface **relatively flat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people cross country skiing on a snowy, relatively flat surface on a sunny day. FEY)J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9da964d6fb5549fb955f64de67ac1a69.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8461eb13664428d8401b2c2e667a2ff", "source": "vatex", "video_id": "t3AQIPQsxy8_000023_000033", "video_description": "A girl is rapidly talking about and eating potato chips from a bag while showing it on a webcam.", "task": "ActionRecognition", "clean_prompt": "A person eating potato chips while talking rapidly on a webcam.", "clean_property": {"obj": "person", "action": "eating chips", "target": "potato chip"}, "target_prompt": "A person dancing with a potato chip in hand.", "target_property": {"obj": "person", "action": "dancing", "target": "potato chip"}, "evaluation_question": "Is the person **eating** potato chips?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person eating potato chips while talking rapidly on a webcam. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a69401ece19c4877b523734ea51caaea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bbf2842fa30f46ae8f6f64186ab71c57", "source": "vatex", "video_id": "f3Mhm3QYjok_000042_000052", "video_description": "A compilation of people talking to each other and interacting with phones, including answering calls and receiving text messages.", "task": "ActionRecognition", "clean_prompt": "A person texting on their phone while sitting on a park bench.", "clean_property": {"obj": "person", "action": "texting", "target": null}, "target_prompt": "A person talking to a friend while sitting on a park bench.", "target_property": {"obj": "person", "action": "talking", "target": "friend"}, "evaluation_question": "Is the person **texting** on their phone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person texting on their phone while sitting on a park bench. @EG70", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16129c9ff2a64d73b85adcf5930046af.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bdf3ad73abbe4d3abe5513230ce75d57", "source": "vatex", "video_id": "M12Cobhrzcc_000002_000012", "video_description": "A group of people are gathered around a red truck on a street. Some are sitting on the truck, including a woman on the cab, and others are standing around. The group is talking, and there is some singing and swaying.", "task": "Counting", "clean_prompt": "Seven people are gathered around a red truck on a street, some sitting on the truck and others standing, talking, singing, and swaying.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Four people are gathered around a blue truck on a beach, some sitting on the truck and others standing, talking, singing, and swaying.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **seven** people gathered around the truck?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are gathered around a red truck on a street, some sitting on the truck and others standing, talking, singing, and swaying. '''!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e157c5850a04a1db46fb10c6c83ba35.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de9b81fdce0942ba8aeea45277184d01", "source": "vatex", "video_id": "U98VA_cPo2U_000192_000202", "video_description": "A group of Asian senior citizens, dressed in black and wearing sunglasses, perform a choreographed dance routine in unison in a showroom or dance hall.", "task": "ObjectRecognition", "clean_prompt": "A group of Asian senior citizens, dressed in black and wearing sunglasses, perform a choreographed dance routine in unison in a showroom.", "clean_property": {"obj": "person"}, "target_prompt": "A group of Asian senior citizens, dressed in colorful outfits, play musical instruments in a showroom.", "target_property": {"obj": "musician"}, "evaluation_question": "Are the performers in the video **dancers**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of Asian senior citizens, dressed in black and wearing sunglasses, perform a choreographed dance routine in unison in a showroom. FE=C#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6462746b1a6a47eca6416aaae3a62170.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f883536053b04e8e819b774a45e92347", "source": "vatex", "video_id": "6XVUY3rdGtk_000000_000010", "video_description": "A woman is exercising outdoors on a court, using two heavy ropes to perform a workout by swinging them up and down.", "task": "AttributeRecognition", "clean_prompt": "A man who is a coach supervising a woman exercising outdoors on a court with heavy ropes.", "clean_property": {"obj": "man", "attribute": "coach"}, "target_prompt": "A man who is a spectator watching a woman exercising outdoors on a court with heavy ropes.", "target_property": {"obj": "man", "attribute": "spectator"}, "evaluation_question": "Is the man acting as a **coach** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man who is a coach supervising a woman exercising outdoors on a court with heavy ropes. NKP\u00b7Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a1f17649ead462c90e8bdd65bd5ea63.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8604764956247b7a6e40c8f5c0e62be", "source": "vatex", "video_id": "d-YUho_dHJE_000017_000027", "video_description": "A person is demonstrating how to properly cut and peel a red onion using a sharp knife, with instructions being narrated.", "task": "SpatialUnderstanding", "clean_prompt": "A knife closer to the camera than a person demonstrating how to cut and peel a red onion.", "clean_property": {"obj_1": "knife", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A knife further from the camera than a person demonstrating how to cut and peel a red onion.", "target_property": {"obj_1": "knife", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the knife **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A knife closer to the camera than a person demonstrating how to cut and peel a red onion. LY%D(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18f16c1bcd494f8cb2a881ee456ec49f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2c2d732e23c646a5b86c76ad224969e8", "source": "vatex", "video_id": "i_m_X5pwaMY_000015_000025", "video_description": "Two men are practicing curling outside in a snowy, wooded area. One man slides a puck along the ice while the other sweeps the path in front of it with a broom.", "task": "SpatialUnderstanding", "clean_prompt": "A broom farther from the camera than a person in a snowy, wooded area where two men are practicing curling.", "clean_property": {"obj_1": "broom", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A broom closer to the camera than a person in a snowy, wooded area where two men are practicing curling.", "target_property": {"obj_1": "broom", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the broom **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A broom farther from the camera than a person in a snowy, wooded area where two men are practicing curling. ZFXBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/675aaf2cb7724fcf98085028123689ec.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1caf006aec8a4904bf22043f630f1c9c", "source": "vatex", "video_id": "IFl8xnZ70oU_000055_000065", "video_description": "A young person is demonstrating how to shuffle a deck of cards, explaining the process while doing so.", "task": "ActionRecognition", "clean_prompt": "A person shuffling a deck of cards while explaining the process.", "clean_property": {"obj": "person", "action": "shuffling cards", "target": null}, "target_prompt": "A person throwing cards in the air.", "target_property": {"obj": "person", "action": "throwing cards", "target": null}, "evaluation_question": "Is the person **shuffling** cards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shuffling a deck of cards while explaining the process. ))!G%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba1ccf0267c442968ddfd59be4986e4d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "63f094087f694918ab4600e814599fa4", "source": "vatex", "video_id": "7AMkMqpQNwk_000773_000783", "video_description": "A group of construction workers are pouring and leveling a wet concrete floor inside a building using machinery and tools.", "task": "Counting", "clean_prompt": "Seven construction workers are pouring and leveling a wet concrete floor inside a building using machinery and tools.", "clean_property": {"obj": "construction worker", "count": "seven"}, "target_prompt": "Three construction workers are painting the walls of a building.", "target_property": {"obj": "construction worker", "count": "three"}, "evaluation_question": "Are there exactly **seven** construction workers pouring concrete in the building?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven construction workers are pouring and leveling a wet concrete floor inside a building using machinery and tools. >7BSF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/540c727194ab47788ee3a3b6fe8f2752.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b00b9bd610844a68bc5452f726a7faec", "source": "vatex", "video_id": "y8Ci9PHukIQ_000004_000014", "video_description": "A baby girl in a brown shirt plays on the floor with a yellow tennis ball, throwing it while her mother praises her. A man is also present, talking to the baby.", "task": "Counting", "clean_prompt": "Three babies playing on the floor with colorful toys.", "clean_property": {"obj": "baby", "count": "three"}, "target_prompt": "One baby playing on the floor with colorful toys.", "target_property": {"obj": "baby", "count": "one"}, "evaluation_question": "Are there exactly **three** babies playing on the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three babies playing on the floor with colorful toys. !3|!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cda1b04e46149b5ac25762055837106.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "80f1445663484c0a880593681afd29ae", "source": "vatex", "video_id": "D9QhY6ecmrw_000006_000016", "video_description": "A young man is demonstrating and explaining how to solve a Rubik's Cube, showing various techniques and strategies.", "task": "Counting", "clean_prompt": "Two young men demonstrating and explaining how to solve a Rubik's Cube, showing various techniques and strategies.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A young man demonstrating and explaining how to solve a Rubik's Cube, showing various techniques and strategies.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** young men demonstrating the Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young men demonstrating and explaining how to solve a Rubik's Cube, showing various techniques and strategies. ERS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/10fee92f1b4b401aa3ddf0373e574c23.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c50779f95934f0b9d882afed3e74957", "source": "vatex", "video_id": "egwQhuJeriI_000008_000018", "video_description": "Two men are playing a game of laser tag inside a house, using the environment for cover and simulating a gunfight.", "task": "ActionRecognition", "clean_prompt": "A person playing laser tag inside a house.", "clean_property": {"obj": "person", "action": "playing laser tag", "target": null}, "target_prompt": "A person watching a movie inside a house.", "target_property": {"obj": "person", "action": "watching a movie", "target": null}, "evaluation_question": "Is the person **playing laser tag**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing laser tag inside a house. MNP=:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef3cf240a49a4da4a2e58e700744bb05.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c5df0bd85cd48ae8345f81e1d172f34", "source": "vatex", "video_id": "2-cHlF42lek_000029_000039", "video_description": "A man is in a dim forest, throwing an axe at a tree. The axe sometimes sticks into the tree.", "task": "Counting", "clean_prompt": "A person in a dim forest is throwing an axe at a tree.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Six people in a bright field are throwing axes at targets.", "target_property": {"obj": "person", "count": "six"}, "evaluation_question": "Are there exactly **one** person throwing an axe in the forest?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in a dim forest is throwing an axe at a tree. 4BCXI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be29f1910cbd457595b80e87ab32359b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8898195d5f7a4545a62e44825313a24e", "source": "vatex", "video_id": "cfbHqJ9w63w_000013_000023", "video_description": "Two girls are playing outside in a field. One girl climbs into a wheelbarrow while the other girl prepares to push it.", "task": "SpatialUnderstanding", "clean_prompt": "A girl closer to the camera than another girl in a field.", "clean_property": {"obj_1": "girl_1", "relation": "closer to the camera than", "obj_2": "girl_2"}, "target_prompt": "A girl further from the camera than another girl in a field.", "target_property": {"obj_1": "girl_1", "relation": "further from the camera than", "obj_2": "girl_2"}, "evaluation_question": "Is the girl closer to the camera than the other girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl closer to the camera than another girl in a field. !'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb2959f3d8fa473db0ab4156b053c35b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "910f8dd059e94bb68ac43d405712113d", "source": "vatex", "video_id": "m0eEMxcqDu4_000000_000010", "video_description": "A group of girls are having a lively time in a bathroom. One girl is shaving her legs with a traditional razor while sitting on a bathtub. The atmosphere is joyful with disco music playing.", "task": "Counting", "clean_prompt": "Three girls are having a lively time in a bathroom, with one girl shaving her legs in a bathtub while disco music plays.", "clean_property": {"obj": "bathtub", "count": "three"}, "target_prompt": "One girl is having a lively time in a bathroom, shaving her legs in a bathtub while disco music plays.", "target_property": {"obj": "bathtub", "count": "one"}, "evaluation_question": "Are there exactly **three** bathtubs in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls are having a lively time in a bathroom, with one girl shaving her legs in a bathtub while disco music plays. EL?1F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4fd355f0a08a4657812d89edc04a1b93.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46e1ff9ec83a430f8cb0623a06df91d2", "source": "vatex", "video_id": "T8fXPNh7u_M_000000_000010", "video_description": "A woman is performing sit-ups on a yoga mat on a rooftop with a view of tall buildings.", "task": "ActionRecognition", "clean_prompt": "A person performing sit-ups on a yoga mat on a rooftop with a view of tall buildings.", "clean_property": {"obj": "person", "action": "situp", "target": null}, "target_prompt": "A person lying down on a yoga mat on a rooftop with a view of tall buildings.", "target_property": {"obj": "person", "action": "lying down", "target": null}, "evaluation_question": "Is the person **performing sit-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing sit-ups on a yoga mat on a rooftop with a view of tall buildings. >C,FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b663be8df6a84ceea812e2b08c6126e7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c6f3d4bdd92144da8772dc0721e7d9d4", "source": "vatex", "video_id": "WeMpnxtS0Sw_000057_000067", "video_description": "A person is chopping mushrooms on a cutting board and placing them into a pot while music plays.", "task": "ActionRecognition", "clean_prompt": "A person chopping mushrooms on a cutting board.", "clean_property": {"obj": "person", "action": "chopping vegetables", "target": "mushroom"}, "target_prompt": "A person frying mushrooms in a pan.", "target_property": {"obj": "person", "action": "frying vegetables", "target": "mushroom"}, "evaluation_question": "Is the person **chopping** mushrooms?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person chopping mushrooms on a cutting board. (27PO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8aa784429a37426191ab58ade430e69e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "451c7454b4ac4affb8d43dd32187e64d", "source": "vatex", "video_id": "BT4rOXKTVSQ_000017_000027", "video_description": "A group of three men are playing beer pong outside at night on a patio. They are laughing, giggling, and talking while throwing ping pong balls into plastic cups on a long table.", "task": "ActionRecognition", "clean_prompt": "A person playing beer pong outside at night on a patio.", "clean_property": {"obj": "person", "action": "playing beer pong", "target": null}, "target_prompt": "A person watching beer pong outside at night on a patio.", "target_property": {"obj": "person", "action": "watching beer pong", "target": null}, "evaluation_question": "Is the person **playing** beer pong?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing beer pong outside at night on a patio. RRWW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b157f8713cd4efca7f794cf945fc91d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd45d1386f2d4ffa98fec1f893e03239", "source": "vatex", "video_id": "YbqVivLaWw4_000011_000021", "video_description": "A man is using a floor sanding machine to sand and finish a wooden floor or deck, removing old paint and stain.", "task": "ActionRecognition", "clean_prompt": "A person sanding a wooden floor with a sanding machine.", "clean_property": {"obj": "person", "action": "sanding floor", "target": null}, "target_prompt": "A person painting a wall.", "target_property": {"obj": "person", "action": "painting wall", "target": null}, "evaluation_question": "Is the person **sanding** a wooden floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sanding a wooden floor with a sanding machine. LY>VG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8548824d03474b6e90c6b16341d540c7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7e59f19b1d9442aa72a588a1a841ebc", "source": "vatex", "video_id": "8hcCZOCKLpE_000094_000104", "video_description": "A man is practicing his golf swing on a golf course, wearing a light blue shirt and white pants. He hits golf balls down the range, demonstrating proper technique.", "task": "ObjectRecognition", "clean_prompt": "A golfer practicing his swing on a golf course.", "clean_property": {"obj": "golfer"}, "target_prompt": "A tennis player practicing his serve on a tennis court.", "target_property": {"obj": "tennis player"}, "evaluation_question": "Is the athlete in the video a **golfer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A golfer practicing his swing on a golf course. XNQS$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1df87ec42bea40b483b32980d5265c36.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7ea92494fd2d4b7db7e450fbb3a4529d", "source": "vatex", "video_id": "33dWGUc3bEA_000000_000010", "video_description": "A woman is in a men's store demonstrating how to tie a bow tie and a necktie on a mannequin and an assistant.", "task": "SpatialUnderstanding", "clean_prompt": "A bow tie farther from the camera than a mannequin in a men's store.", "clean_property": {"obj_1": "bow tie", "relation": "farther from the camera than", "obj_2": "mannequin"}, "target_prompt": "A bow tie closer to the camera than a mannequin in a men's store.", "target_property": {"obj_1": "bow tie", "relation": "closer to the camera than", "obj_2": "mannequin"}, "evaluation_question": "Is the bow tie **farther from the camera than** the mannequin?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bow tie farther from the camera than a mannequin in a men's store. MVJF%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/395604dc263e44beb9e10782123831c3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fba55144acf54877aaf6fe025e2e6354", "source": "vatex", "video_id": "R-CVFX7ZsfM_000000_000010", "video_description": "A group of people are seated at a table, carving pumpkins into jack-o-lanterns in a time-lapse video.", "task": "Counting", "clean_prompt": "Two people seated at a table, carving pumpkins into jack-o-lanterns in a time-lapse video.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "Four people seated at a table, carving pumpkins into jack-o-lanterns in a time-lapse video.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **two** people seated at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people seated at a table, carving pumpkins into jack-o-lanterns in a time-lapse video. =8HU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cacabd9cbbdb4d34a1602fd73440dffb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "531de713b3b14bcab3c7a8e0575fbd6a", "source": "vatex", "video_id": "eigyV8fkc0Q_000005_000015", "video_description": "A person is placing squares of food onto a conveyor belt, which moves through a machine that shrink-wraps each item in plastic.", "task": "AttributeRecognition", "clean_prompt": "A person is placing squares of food onto a conveyor belt.", "clean_property": {"obj": "food", "attribute": "square"}, "target_prompt": "A person is placing circles of food onto a conveyor belt.", "target_property": {"obj": "food", "attribute": "circular"}, "evaluation_question": "Are the pieces of food **square**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is placing squares of food onto a conveyor belt. 3.;JR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/efa3fb7a78da4f03858c9e785c3d25ae.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "249c164df4c0421b8438a9597df80505", "source": "vatex", "video_id": "zbIbjob4XF4_000087_000097", "video_description": "A man is water skiing on a lake, being pulled by a fast boat, zig-zagging back and forth and creating spumes of spray.", "task": "ActionRecognition", "clean_prompt": "A water skier water skiing on a lake.", "clean_property": {"obj": "water skier", "action": "water skiing", "target": null}, "target_prompt": "A water skier falling on a lake.", "target_property": {"obj": "water skier", "action": "falling", "target": null}, "evaluation_question": "Is the water skier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A water skier water skiing on a lake. UB9?.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7407fda050ea4d5fafa4fa4cbd632213.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0545d15821a642cf85462fd32df0b2cf", "source": "vatex", "video_id": "UKj1IafjpdA_000000_000010", "video_description": "A young child is outside shoveling snow with a toy shovel, laughing and playing near a tree and a house.", "task": "ActionRecognition", "clean_prompt": "A child shoveling snow outside with a toy shovel, laughing and playing near a tree and a house.", "clean_property": {"obj": "child", "action": "shoveling snow", "target": null}, "target_prompt": "A child building a snowman outside with a toy shovel, laughing and playing near a tree and a house.", "target_property": {"obj": "child", "action": "building a snowman", "target": null}, "evaluation_question": "Is the child **shoveling snow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child shoveling snow outside with a toy shovel, laughing and playing near a tree and a house. TS1RA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1290aa55d9a4479687d569a095c26087.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "761fc19f09434ec5b936bc8da57a4d0f", "source": "vatex", "video_id": "r-6DdJlhNT4_000009_000019", "video_description": "A person is holding a gong and striking it with a mallet, producing a resonating sound.", "task": "AttributeRecognition", "clean_prompt": "A person is holding a gong and striking it with a red stick mallet, producing a resonating sound.", "clean_property": {"obj": "mallet", "attribute": "red stick"}, "target_prompt": "A person is holding a gong and striking it with a blue stick mallet, producing a resonating sound.", "target_property": {"obj": "mallet", "attribute": "blue stick"}, "evaluation_question": "Is the mallet a **red** stick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is holding a gong and striking it with a red stick mallet, producing a resonating sound. G$MC\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aedd13c48754476f80fcc4e114065f00.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2ad14ce6570a4a1f8164a35d34d1d2ab", "source": "vatex", "video_id": "183zmnjVGUU_000000_000010", "video_description": "A female newscaster, Tyler Carter, is reporting on a string of residential burglaries in a town called Dublin. She is standing outside on a sidewalk in a neighborhood, speaking into a microphone about the increase in burglaries and the police response.", "task": "ObjectRecognition", "clean_prompt": "A female newscaster, Tyler Carter, is reporting on a string of residential burglaries in Dublin while standing on a sidewalk.", "clean_property": {"obj": "newscaster"}, "target_prompt": "A weather reporter is giving a forecast while standing on a sidewalk.", "target_property": {"obj": "weather reporter"}, "evaluation_question": "Is the person in the video a **newscaster**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female newscaster, Tyler Carter, is reporting on a string of residential burglaries in Dublin while standing on a sidewalk. ED.JE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3e502b16d8e45bdb6e5acbdbb24024d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "212ecf534d3c429ba1eb0434fca03162", "source": "vatex", "video_id": "Z2_Xy-rqaS0_000011_000021", "video_description": "A man in a black hoodie is throwing a playing card towards a door in slow motion.", "task": "AttributeRecognition", "clean_prompt": "A man in a black hoodie is throwing a playing card towards a white door in slow motion.", "clean_property": {"obj": "door", "attribute": "white"}, "target_prompt": "A man in a black hoodie is throwing a playing card towards a red door in slow motion.", "target_property": {"obj": "door", "attribute": "red"}, "evaluation_question": "Is the door **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a black hoodie is throwing a playing card towards a white door in slow motion. BT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b2e9da10ef684af6a4eef2e29870e18e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "146f0c9014b4483e8fc15a96e8ed2539", "source": "vatex", "video_id": "y7m8YsU2AGY_000006_000016", "video_description": "A little boy is sitting on a couch in the living room, laughing and wiggling around while a woman watches and talks to him.", "task": "ObjectRecognition", "clean_prompt": "A woman is watching a little boy sitting on a couch in the living room, laughing and wiggling around.", "clean_property": {"obj": "woman"}, "target_prompt": "A man is watching a little boy sitting on a couch in the living room, laughing and wiggling around.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person watching the boy a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is watching a little boy sitting on a couch in the living room, laughing and wiggling around. ''!?%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f4b6b48789a4d75b3820abfbb95327c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9812306d75824a05a598f177e3fac16b", "source": "vatex", "video_id": "Fg_Dne_sNaE_000009_000019", "video_description": "A man is performing the shot put event at an outdoor track and field competition, with a judge and spectators watching.", "task": "SpatialUnderstanding", "clean_prompt": "Spectators farther from the camera than the shot put.", "clean_property": {"obj_1": "spectators", "relation": "farther from the camera than", "obj_2": "shot put"}, "target_prompt": "Spectators closer to the camera than the shot put.", "target_property": {"obj_1": "spectators", "relation": "closer to the camera than", "obj_2": "shot put"}, "evaluation_question": "Are the spectators **farther from the camera than** the shot put?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Spectators farther from the camera than the shot put. UF.R!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d86041e8cac41af949453bb51acd784.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce3d904930e6433186dc5adb14510154", "source": "vatex", "video_id": "_bciTU-EiDk_000024_000034", "video_description": "A woman demonstrates and explains how a special latch works on an appliance door, specifically a refrigerator, including how to open and secure it.", "task": "SpatialUnderstanding", "clean_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door.", "clean_property": {"obj_1": "refrigerator", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A refrigerator further from the camera than a person demonstrating how to use a special latch on the refrigerator door.", "target_property": {"obj_1": "refrigerator", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the refrigerator **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A refrigerator closer to the camera than a person demonstrating how to use a special latch on the refrigerator door. QCK8O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98da5301146a4482aa40b0e928df2ee3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f01d7d1013be41ffa14a60f3d32c9c57", "source": "vatex", "video_id": "EraBmgB9U9Q_000010_000020", "video_description": "A little girl in a blue floral dress is outside watering the grass and plants with a blue and yellow plastic watering can.", "task": "ActionRecognition", "clean_prompt": "A girl watering plants outside with a blue and yellow watering can.", "clean_property": {"obj": "girl", "action": "watering plants", "target": null}, "target_prompt": "A girl playing with water outside.", "target_property": {"obj": "girl", "action": "playing with water", "target": null}, "evaluation_question": "Is the girl **watering plants**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl watering plants outside with a blue and yellow watering can. RLQZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40ea516e9bf946f4a5e525c9be987a43.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6386eb4e2db340c784d0b5830f079c72", "source": "vatex", "video_id": "MaP74kzZM-I_000000_000010", "video_description": "A woman is attempting to walk on a slackline set up in a backyard, with the assistance of a young man and a young woman holding her hands for balance.", "task": "SpatialUnderstanding", "clean_prompt": "A young woman farther from the camera than a slackline in a backyard.", "clean_property": {"obj_1": "young woman", "relation": "farther from the camera than", "obj_2": "slackline"}, "target_prompt": "A young woman closer to the camera than a slackline in a backyard.", "target_property": {"obj_1": "young woman", "relation": "closer to the camera than", "obj_2": "slackline"}, "evaluation_question": "Is the young woman farther from the camera than the slackline?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman farther from the camera than a slackline in a backyard. !AQ%F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9eb500040ad4bc5a23581d576879f1f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0566c7f5dbb14aeca8593e3f5376ab5f", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "ActionRecognition", "clean_prompt": "A waterskier water skiing beside a motorboat.", "clean_property": {"obj": "waterskier", "action": "water skiing", "target": null}, "target_prompt": "A waterskier falling into water beside a motorboat.", "target_property": {"obj": "waterskier", "action": "falling into water", "target": null}, "evaluation_question": "Is the waterskier **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A waterskier water skiing beside a motorboat. >@I|@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57d78a87dac248e6a9aec3a8c98dabba.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7a4d9ede7774facabc20f4bee57a3e6", "source": "vatex", "video_id": "5pjVeypYhgI_000000_000010", "video_description": "A young boy is jumping around a campsite while eating a hot dog, with an adult male nearby. They are near a campfire.", "task": "ActionRecognition", "clean_prompt": "A child eating a hot dog near a campfire.", "clean_property": {"obj": "child", "action": "eating hotdog", "target": null}, "target_prompt": "A child jumping near a campfire.", "target_property": {"obj": "child", "action": "jumping", "target": null}, "evaluation_question": "Is the child **eating** a hot dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child eating a hot dog near a campfire. \u00b7)/!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a7aebb298db3453592dcd26314c9347e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3084c8e10c0345d5bf8fb00846932ec7", "source": "vatex", "video_id": "kMkEy91rFqA_000001_000011", "video_description": "A butcher is preparing and displaying meat in a grocery store while talking about his experience and the meat selections.", "task": "ObjectRecognition", "clean_prompt": "A butcher is preparing and displaying meat in a grocery store while discussing his experience and the meat selections.", "clean_property": {"obj": "meat"}, "target_prompt": "A chef is preparing and displaying vegetables in a grocery store while discussing his experience and the vegetable selections.", "target_property": {"obj": "vegetables"}, "evaluation_question": "Is the butcher in the video preparing **meat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A butcher is preparing and displaying meat in a grocery store while discussing his experience and the meat selections. LYB1G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8ae59678ac07432bbfd2fbbcedff1cd6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0db2a515dfed4ec1a29bfb77904da46e", "source": "vatex", "video_id": "kmFC4sOQZ4c_000007_000017", "video_description": "A community event where people of various ages gather to clean up a natural area, including a riverbank, forest, and ocean. They pick up litter and place it into plastic bags.", "task": "ActionRecognition", "clean_prompt": "People picking up litter at a community event by the riverbank.", "clean_property": {"obj": "people", "action": "picking fruit", "target": "litter"}, "target_prompt": "People throwing litter into the river at a community event.", "target_property": {"obj": "people", "action": "throwing litter", "target": "river"}, "evaluation_question": "Are the people **picking** up litter?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "People picking up litter at a community event by the riverbank. /))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/137070a45c1248f1ad63c8099094ff72.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc9bcea664454b5fa49f93b77121c2a1", "source": "vatex", "video_id": "xfKDnu0XKsE_000019_000029", "video_description": "A woman is playing a pinball machine in a basement game room, laughing and adjusting her hair.", "task": "Counting", "clean_prompt": "Five people are gathered around a pinball machine in a basement game room, laughing and having fun.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "A person is playing a pinball machine in a basement game room, laughing and adjusting their hair.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people gathered around the pinball machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people are gathered around a pinball machine in a basement game room, laughing and having fun. U%Y)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/066f61c2190f4af4b17ff8f63f49dda1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "05b0a746a8cd49079c4cfc51dcdc4850", "source": "vatex", "video_id": "h5ta2cUhUhA_000030_000040", "video_description": "A man is demonstrating how to make balloon animals by blowing up a long blue balloon and twisting it into various shapes. He provides instructions and narrates the process, occasionally speaking in a high voice after inhaling helium from a balloon.", "task": "Counting", "clean_prompt": "A man is demonstrating how to make balloon animals with seven people watching him.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man is demonstrating how to make balloon animals with two people watching him.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to make balloon animals with seven people watching him. ,OC;N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b3cfa33835a4265ac2fbcc43343e7ae.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5dd7d380e57047baa274e0654f011567", "source": "vatex", "video_id": "sNBYqV4_dr0_000038_000048", "video_description": "A man is in his bathroom trimming and shaving his beard using an electric razor while looking into a mirror.", "task": "SpatialUnderstanding", "clean_prompt": "An electric razor farther from the camera than a mirror in a bathroom.", "clean_property": {"obj_1": "electric razor", "relation": "farther from the camera than", "obj_2": "mirror"}, "target_prompt": "An electric razor closer to the camera than a mirror in a bathroom.", "target_property": {"obj_1": "electric razor", "relation": "closer to the camera than", "obj_2": "mirror"}, "evaluation_question": "Is the electric razor **farther from the camera than** the mirror?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An electric razor farther from the camera than a mirror in a bathroom. FS\u00b7FQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9991553896a04878a1579b44f0094306.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c82b1e515d88480abd36a374f109f17a", "source": "vatex", "video_id": "eVE1HglKrU0_000081_000091", "video_description": "A group of people, including children and young men, are having fun in an inflatable bounce house. They are jumping, playing, and occasionally laying down and kicking the inflatable structure. A mom is watching the children.", "task": "SpatialUnderstanding", "clean_prompt": "A bounce house farther from the camera than a person.", "clean_property": {"obj_1": "bounce house", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A bounce house closer to the camera than a person.", "target_property": {"obj_1": "bounce house", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the bounce house **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bounce house farther from the camera than a person. \u00b79/?%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ca0eb617a00c4ad4860864b76f2566e8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3fd161aa34be4755baa5d31de1096563", "source": "vatex", "video_id": "u0e6NtVR7eM_000000_000010", "video_description": "A young man is dancing energetically in a room with a wooden floor, performing street dance moves to upbeat music.", "task": "ObjectRecognition", "clean_prompt": "A young man dancing energetically in a room with a wooden floor.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing energetically in a room with a wooden floor.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man dancing energetically in a room with a wooden floor. !T0S)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c106649f62d481ca1d8549903d2c669.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "253944fb1c4f44a99333ee91b4c56bdc", "source": "vatex", "video_id": "0SayN7fM7aE_000114_000124", "video_description": "Two young boys are sitting on the floor, folding clothes, including a blue shirt.", "task": "Counting", "clean_prompt": "Two young boys are sitting on the floor, folding clothes, including a blue shirt.", "clean_property": {"obj": "boy", "count": "six"}, "target_prompt": "Six boys are playing outside in a park, flying kites.", "target_property": {"obj": "boy", "count": "six"}, "evaluation_question": "Are there exactly **two** boys sitting on the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys are sitting on the floor, folding clothes, including a blue shirt. !0D))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/43974cacc0d645b0a1b93d8642a84a4b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4dbf99c276bf4d059c55362e7c600898", "source": "vatex", "video_id": "z3WlIafBi4o_000000_000010", "video_description": "A little boy in a bedroom throws a small basketball into a toy basketball hoop and successfully makes the shot.", "task": "ActionRecognition", "clean_prompt": "A boy shooting a basketball into a hoop.", "clean_property": {"obj": "boy", "action": "shooting basketball", "target": "hoop"}, "target_prompt": "A boy throwing a basketball onto the ground.", "target_property": {"obj": "boy", "action": "throwing basketball", "target": "ground"}, "evaluation_question": "Is the boy **shooting** a basketball into a hoop?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy shooting a basketball into a hoop. /!0YB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d78201b6e8be422cb39580e2804f5df1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "39973ca98c3b47e0a749e7e0364e769d", "source": "vatex", "video_id": "5I7b0ifBhQg_000028_000038", "video_description": "A mom wearing a fuzzy hat is playing with a baby, making it laugh by rubbing her head on the baby's belly, while the grandmother holds the baby.", "task": "ActionRecognition", "clean_prompt": "A mom tickling a baby while wearing a fuzzy hat.", "clean_property": {"obj": "mom", "action": "tickling", "target": "baby"}, "target_prompt": "A mom playing peek-a-boo with a baby while wearing a fuzzy hat.", "target_property": {"obj": "mom", "action": "playing peek-a-boo", "target": "baby"}, "evaluation_question": "Is the mom **tickling** the baby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A mom tickling a baby while wearing a fuzzy hat. MN)60", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/486320f625134de1adbd9f8a0a1bcdcf.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "401b23b5a04746c18bc5f1dd9e2676bf", "source": "vatex", "video_id": "83HNr75yyaA_000347_000357", "video_description": "A group of people, including children, are playing in the snow and building snowmen in a snowy field in a city.", "task": "ObjectRecognition", "clean_prompt": "A group of people, including children, are playing in the snow and building snowmen in a snowy field.", "clean_property": {"obj": "snowman"}, "target_prompt": "A group of people, including children, are building sandcastles on a beach.", "target_property": {"obj": "sandcastle"}, "evaluation_question": "Are the people in the video building **snowmen**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people, including children, are playing in the snow and building snowmen in a snowy field. !'!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b72e71cf67bf4931bfb46f86a5e56ee1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "103f96bc4d714943b056277d378a829d", "source": "vatex", "video_id": "Vl7YXD9uycc_000000_000010", "video_description": "A man is interviewing various individuals in costumes, including a person in a green full-body superhero costume, using a microphone.", "task": "AttributeRecognition", "clean_prompt": "An interviewee in a green full-body suit being interviewed with a microphone.", "clean_property": {"obj": "interviewee", "attribute": "green full-body suit"}, "target_prompt": "An interviewee in a red full-body suit being interviewed with a microphone.", "target_property": {"obj": "interviewee", "attribute": "red full-body suit"}, "evaluation_question": "Is the interviewee wearing a **green** full-body suit?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An interviewee in a green full-body suit being interviewed with a microphone. AN!'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38a4a71cb091408bbdf343b65f5528be.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d911d360c473443e96d073cc1fdf593c", "source": "vatex", "video_id": "n2qG2mrjDhc_000139_000149", "video_description": "A woman demonstrates how to use a hair pick and a head massager on her Afro hairstyle while speaking.", "task": "SpatialUnderstanding", "clean_prompt": "A head massager positioned to the left of a person demonstrating its use.", "clean_property": {"obj_1": "head massager", "relation": "left of", "obj_2": "person"}, "target_prompt": "A head massager positioned to the right of a person demonstrating its use.", "target_property": {"obj_1": "head massager", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the head massager to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A head massager positioned to the left of a person demonstrating its use. J@EAC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/88694d2f464947999a30795ccd325a98.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3d31bf919e784303b1c0c6dbfe3b2c82", "source": "vatex", "video_id": "8AKP9U_RRfc_000028_000038", "video_description": "A man in a blue shirt is cleaning a window pane using a squeegee inside a room.", "task": "ActionRecognition", "clean_prompt": "A person cleaning windows inside a room.", "clean_property": {"obj": "person", "action": "cleaning windows", "target": null}, "target_prompt": "A person breaking windows inside a room.", "target_property": {"obj": "person", "action": "breaking windows", "target": null}, "evaluation_question": "Is the person **cleaning** windows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning windows inside a room. )!(B=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/75cc264d3eba4d8aa1327995566a1a5d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5842d47959a24eb4b6abe716f3353888", "source": "vatex", "video_id": "t9CARd_35XI_000231_000241", "video_description": "A young person is explaining the placement of arrows in a target, pointing out where each arrow hit. The target is a piece of foam with multiple bull's eye targets, and arrows of various colors are sticking out of it.", "task": "SpatialUnderstanding", "clean_prompt": "An arrow positioned to the left of the target, which is a foam board with multiple bull's eye targets.", "clean_property": {"obj_1": "arrow", "relation": "left of", "obj_2": "target"}, "target_prompt": "An arrow positioned to the right of the target, which is a foam board with multiple bull's eye targets.", "target_property": {"obj_1": "arrow", "relation": "right of", "obj_2": "target"}, "evaluation_question": "Is the arrow to the **left** of the target?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An arrow positioned to the left of the target, which is a foam board with multiple bull's eye targets. LFY)G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a92b6a07b7874181a088afbd2a91dc2e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab294b1901d948f49a5b19b6f93edd08", "source": "vatex", "video_id": "Jf9t3eg8ovg_000049_000059", "video_description": "A young boy is sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "clean_property": {"obj": "rolling pin"}, "target_prompt": "A young boy is sitting at a table, using a spatula to mix ingredients in a bowl.", "target_property": {"obj": "spatula"}, "evaluation_question": "Is the boy using a **rolling pin** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients. ED@HY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/32556105ab6a4c9cacb820b40370a736.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c1b86d124cda4bb0b16c000887a09268", "source": "vatex", "video_id": "hKrM13_D6XU_000283_000293", "video_description": "A woman is demonstrating how to fold and wear a sari and a skirt, discussing their sizes.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating how to fold and wear a sari that is tri-colored with large polka dots.", "clean_property": {"obj": "sari", "attribute": "tri-colored with large polka dots"}, "target_prompt": "A woman demonstrating how to fold and wear a sari that is a solid color with small stripes.", "target_property": {"obj": "sari", "attribute": "solid color with small stripes"}, "evaluation_question": "Is the sari tri-colored with large polka dots?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to fold and wear a sari that is tri-colored with large polka dots. M)FE>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0e4e5bbeff994237a7d97feda4235a2b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5adace5e1b774d54b054038be43e7a62", "source": "vatex", "video_id": "V8bwMu1BFhw_000008_000018", "video_description": "A man is standing on a dock or pier, throwing large rocks and other objects into a body of water, attempting to skip them.", "task": "AttributeRecognition", "clean_prompt": "A man is standing on a dock, throwing large rocks into a body of water, attempting to skip them.", "clean_property": {"obj": "rock", "attribute": "large"}, "target_prompt": "A man is standing on a dock, throwing small rocks into a body of water, attempting to skip them.", "target_property": {"obj": "rock", "attribute": "small"}, "evaluation_question": "Is the man throwing **large** rocks into the water?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing on a dock, throwing large rocks into a body of water, attempting to skip them. G?FE&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/839c178b33ba46b784ea8354e8767f2d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "514e99fb7475437c9282d2918ffd1e8f", "source": "vatex", "video_id": "C5LlHOAxfc8_000003_000013", "video_description": "A bar scene with two bartenders working behind the bar, serving drinks to patrons. The bar has a pool table and a TV. Patrons are sitting and standing around the bar, enjoying the atmosphere with loud music playing.", "task": "ObjectRecognition", "clean_prompt": "Two bartenders serving drinks in a bar with a pool table in the background.", "clean_property": {"obj": "pool table"}, "target_prompt": "Two bartenders serving drinks in a bar with a foosball table in the background.", "target_property": {"obj": "foosball table"}, "evaluation_question": "Is there a **pool table** in the bar scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two bartenders serving drinks in a bar with a pool table in the background. $$JS8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b58a0e7d76744fd8bf4d55049cf0820.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f745cbf3713740dd8b21c2056a527129", "source": "vatex", "video_id": "RWuj_PJl-Ho_000000_000010", "video_description": "A young boy is sitting in a baby walker, eating food with his hands.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting in a baby walker, eating food with his hands.", "clean_property": {"obj": "food"}, "target_prompt": "A young boy is sitting in a baby walker, playing with toys.", "target_property": {"obj": "toys"}, "evaluation_question": "Is the boy in the video eating **food**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting in a baby walker, eating food with his hands. LY2YE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5f5759f56b7c4dd28e242e5d221e7ddf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad939b0eabfc47d9ad67c2103f3969e3", "source": "vatex", "video_id": "4lZlH-K15gI_000036_000046", "video_description": "A man is standing outside in a cold environment, wearing a jacket and a blue beanie, performing beatboxing with his mouth.", "task": "ObjectRecognition", "clean_prompt": "A man standing outside in a cold environment, wearing a jacket and a blue beanie, performing beatboxing.", "clean_property": {"obj": "person"}, "target_prompt": "A woman standing outside in a cold environment, wearing a jacket and a blue beanie, performing beatboxing.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing outside in a cold environment, wearing a jacket and a blue beanie, performing beatboxing. HL2FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73ebfed9c08c4b15a348bc4c6001384a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1cc56e701ff46c3b7aed1667fc45e0c", "source": "vatex", "video_id": "_ha6Y6511PM_000006_000016", "video_description": "A group of people are sitting in a kitchen, smoking hookah. A brunette woman is prominently featured, making funny faces as she exhales smoke.", "task": "ObjectRecognition", "clean_prompt": "A group of people sitting in a kitchen, smoking hookah, with a brunette woman making funny faces as she exhales smoke.", "clean_property": {"obj": "person"}, "target_prompt": "A cat sitting in a kitchen, playing with a hookah hose.", "target_property": {"obj": "cat"}, "evaluation_question": "Is there a **person** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people sitting in a kitchen, smoking hookah, with a brunette woman making funny faces as she exhales smoke. .AN!&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9eef4527d5644d8b799d29a30e53e93.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "67893f01f5ff45e5a2399370b9eabbd9", "source": "vatex", "video_id": "qWi8fYqLJwk_000000_000010", "video_description": "Two men are playing beer pong in a kitchen, using a ping pong ball that is lit on fire and throwing it into plastic cups at the end of a long table.", "task": "ActionRecognition", "clean_prompt": "A man playing beer pong in a kitchen.", "clean_property": {"obj": "man", "action": "playing beer pong", "target": null}, "target_prompt": "A man throwing a flaming ball into plastic cups in a kitchen.", "target_property": {"obj": "man", "action": "throwing a flaming ball", "target": "plastic cups"}, "evaluation_question": "Is the man **playing beer pong**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing beer pong in a kitchen. D|:&A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8474e04512b94ecb8fbdcfbed9a14ee4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46bc6d21338e4d3db5183deeac89805c", "source": "vatex", "video_id": "Qr6I4c8ssv0_000194_000204", "video_description": "A man is demonstrating the use of a pipe bending tool to bend pipes into rounded shapes. The demonstration includes various materials and shows pipes before and after bending.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating the use of a pipe bending tool to bend pipes with water flowing through them.", "clean_property": {"obj": "pipe", "attribute": "water"}, "target_prompt": "A man demonstrating the use of a pipe bending tool to bend empty pipes.", "target_property": {"obj": "pipe", "attribute": "empty"}, "evaluation_question": "Is there **water** flowing through the pipes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating the use of a pipe bending tool to bend pipes with water flowing through them. ));=4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7865ce1d0de744e2a13f7ecc4b093fd0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f36bba298c254de8a7aa0d7adda48acf", "source": "vatex", "video_id": "tEpRURa-1gQ_000000_000010", "video_description": "A person is washing a golden retriever dog outside in the sunlight, using a bucket of water. The dog is being positioned and pulled towards the bucket during the bath.", "task": "SpatialUnderstanding", "clean_prompt": "A bucket positioned to the left of a golden retriever dog being washed outside in the sunlight.", "clean_property": {"obj_1": "bucket", "relation": "left of", "obj_2": "dog"}, "target_prompt": "A bucket positioned to the right of a golden retriever dog being washed outside in the sunlight.", "target_property": {"obj_1": "bucket", "relation": "right of", "obj_2": "dog"}, "evaluation_question": "Is the bucket to the **left** of the golden retriever dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bucket positioned to the left of a golden retriever dog being washed outside in the sunlight. FE7,E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/383d131649eb4a908641de1c72ace2a3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1f92be5ed3f841718a67d5364c61eafe", "source": "vatex", "video_id": "iLNmg_zAa6Y_000009_000019", "video_description": "A person is riding a modified bicycle with skis attached instead of wheels down a snowy hill, performing jumps over snow ramps.", "task": "ObjectRecognition", "clean_prompt": "A person riding a modified bicycle with skis down a snowy hill, performing jumps over snow ramps.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running down a snowy hill, jumping over snow ramps.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a modified bicycle with skis down a snowy hill, performing jumps over snow ramps. >8%FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9d1a85273daf463d8a7870b6b2e18f24.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7f398b42eb6c4d839223f9edb84b3ec5", "source": "vatex", "video_id": "EvGkyGUuZnU_000026_000036", "video_description": "A man is demonstrating how to remove scratches and polish a metal bar using a power tool.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to remove scratches and polish a chrome metal bar using a power tool.", "clean_property": {"obj": "metal bar", "attribute": "chrome"}, "target_prompt": "A man is demonstrating how to remove scratches and polish a rusty metal bar using a power tool.", "target_property": {"obj": "metal bar", "attribute": "rusty"}, "evaluation_question": "Is the metal bar **chrome**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to remove scratches and polish a chrome metal bar using a power tool. U%|*:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e031288dfec64bcd905ddb50db695e53.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "efab3a46029046aa99bc7e0a29731fdd", "source": "vatex", "video_id": "4eKN5-BZFFw_000181_000191", "video_description": "A person is presenting a piece of homemade jewelry, a beaded bracelet with letters forming the phrase 'I LUV YOU', in front of a camera.", "task": "Counting", "clean_prompt": "A person is presenting a piece of homemade jewelry, a beaded bracelet with letters forming the phrase 'I LUV YOU', in front of a camera with five other people watching.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A person is presenting a piece of homemade jewelry, a beaded bracelet with letters forming the phrase 'I LUV YOU', in front of a camera with one other person watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is presenting a piece of homemade jewelry, a beaded bracelet with letters forming the phrase 'I LUV YOU', in front of a camera with five other people watching. FE-|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7129a5dd56f44e8781982d5558338da6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "30d6aeb6ac5a4fc49fb9189d91c84ef4", "source": "vatex", "video_id": "W6I7T8reRgs_000002_000012", "video_description": "A young man is performing jumping jacks on a lit basketball court at night. The area is fenced, and there is a logo for personal training displayed.", "task": "Counting", "clean_prompt": "Two young men performing jumping jacks on a lit basketball court at night.", "clean_property": {"obj": "court", "count": "two"}, "target_prompt": "One young man performing jumping jacks on a lit basketball court at night.", "target_property": {"obj": "court", "count": "one"}, "evaluation_question": "Are there exactly **two** basketball courts in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young men performing jumping jacks on a lit basketball court at night. N|3|!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a4f46febeed46aa9d0cb1b114b5d007.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "788accdd9dc347bfad225bf5b38589f1", "source": "vatex", "video_id": "zbYcyqQMzGs_000002_000012", "video_description": "A man in a vertically striped shirt and glasses plays a saxophone in his living room, sometimes stepping back from the camera.", "task": "ActionRecognition", "clean_prompt": "A person playing saxophone in a living room.", "clean_property": {"obj": "person", "action": "playing saxophone", "target": null}, "target_prompt": "A person playing guitar in a living room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing saxophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing saxophone in a living room. /!%|;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f0d05b72df3d4afa88299004ca6612af.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2f8ff6508a9f4336b7ed736b2e923441", "source": "vatex", "video_id": "uLnsz65ok80_000120_000130", "video_description": "A woman and three children are outside in the snow building a large snowman. The woman is filming while the children, two of whom are wearing snowsuits, work on the snowman. A girl without a coat watches and interacts with the others.", "task": "AttributeRecognition", "clean_prompt": "A child wearing a snowsuit is building a snowman with friends.", "clean_property": {"obj": "child", "attribute": "wearing snowsuit"}, "target_prompt": "A child wearing a summer dress is building a snowman with friends.", "target_property": {"obj": "child", "attribute": "wearing a summer dress"}, "evaluation_question": "Is the child wearing a **snowsuit**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child wearing a snowsuit is building a snowman with friends. )!D$=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ebbd22baf0ae4ddb82425549c8284aa1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "681ea641c13149d881a03f3d9eb9025a", "source": "vatex", "video_id": "Q7mzAT5xlwU_000023_000033", "video_description": "A young man is skillfully juggling dangerous items including an axe, a knife, and a lit torch at a renaissance festival. He is performing in front of an audience near a castle courtyard.", "task": "ObjectRecognition", "clean_prompt": "A young man is skillfully juggling a lit torch, an axe, and a knife at a renaissance festival in front of an audience near a castle courtyard.", "clean_property": {"obj": "lit torch"}, "target_prompt": "A young man is skillfully juggling a glowing lantern, an axe, and a knife at a renaissance festival in front of an audience near a castle courtyard.", "target_property": {"obj": "glowing lantern"}, "evaluation_question": "Is the young man juggling a **lit torch**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is skillfully juggling a lit torch, an axe, and a knife at a renaissance festival in front of an audience near a castle courtyard. HZFEO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/470d7011589343549e04c5531e8cafad.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "360bdc8a92b041a797719fab20357c71", "source": "vatex", "video_id": "YqhmNUVBVjc_000027_000037", "video_description": "A young man is sitting in a room, using his cell phone to play a game, read, and text, while making faces and talking about the autocorrect function.", "task": "Counting", "clean_prompt": "Two people in a room, one is sitting and using a cell phone to play a game, while the other is standing and talking about autocorrect.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person in a room, sitting and using a cell phone to play a game.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in a room, one is sitting and using a cell phone to play a game, while the other is standing and talking about autocorrect. )-FE/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c345885d8664449a5e1cb42d85ab3b0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cd02945b00540b3968fbaeecf1cf57e", "source": "vatex", "video_id": "5_xXj3SAX68_000117_000127", "video_description": "A woman in a home kitchen demonstrates a cooking procedure involving transferring vegetables from a pot to a colander using a slotted spoon, including an ice bath step.", "task": "AttributeRecognition", "clean_prompt": "A woman in a home kitchen demonstrates transferring green vegetables from a pot to a colander using a slotted spoon, including an ice bath step.", "clean_property": {"obj": "vegetables", "attribute": "green"}, "target_prompt": "A woman in a home kitchen demonstrates transferring red vegetables from a pot to a colander using a slotted spoon, including an ice bath step.", "target_property": {"obj": "vegetables", "attribute": "red"}, "evaluation_question": "Are the vegetables being transferred **green**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a home kitchen demonstrates transferring green vegetables from a pot to a colander using a slotted spoon, including an ice bath step. TY1FG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46cbfffcdd144f82ac009ca35ca7dfda.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3d0137792e5f41cca9259a8b1e073db0", "source": "vatex", "video_id": "51v-7Xxpy30_000066_000076", "video_description": "A man demonstrates how to unfold and ride a folding bike, explaining its benefits and features.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrates how to unfold and ride a bike with an adjustable seat, explaining its benefits and features.", "clean_property": {"obj": "bike", "attribute": "adjustable"}, "target_prompt": "A man demonstrates how to unfold and ride a bike with a fixed seat, explaining its benefits and features.", "target_property": {"obj": "bike", "attribute": "fixed seat"}, "evaluation_question": "Does the bike have an **adjustable** seat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to unfold and ride a bike with an adjustable seat, explaining its benefits and features. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3797935b97dd41968fe8e14011396c69.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "296a63608a8d47a78fba0e221a49908e", "source": "vatex", "video_id": "sbZQtqT59jk_000018_000028", "video_description": "A man is explaining the features and speed of a snowmobile parked in the snow in front of a large yellow building.", "task": "Counting", "clean_prompt": "Two people standing next to a snowmobile parked in the snow in front of a large yellow building, while one explains its features and speed.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person standing next to a snowmobile parked in the snow in front of a large yellow building, explaining its features and speed.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people next to the snowmobile?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people standing next to a snowmobile parked in the snow in front of a large yellow building, while one explains its features and speed. WN8U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a41186e5fcd44c3d8e010766ef2be32a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc65c8718dd449f586b99c7656fcf689", "source": "vatex", "video_id": "gNmBprKZKzc_000008_000018", "video_description": "A group of five young men are practicing soccer passing drills in a small, enclosed court while wearing blue uniforms. It is raining, and they are gradually moving in circles as they pass the ball.", "task": "AttributeRecognition", "clean_prompt": "A soccer player wearing blue uniforms practicing passing drills in the rain.", "clean_property": {"obj": "soccer player", "attribute": "wearing blue uniforms"}, "target_prompt": "A soccer player wearing red uniforms practicing passing drills in the rain.", "target_property": {"obj": "soccer player", "attribute": "wearing red uniforms"}, "evaluation_question": "Is the soccer player wearing **blue** uniforms?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A soccer player wearing blue uniforms practicing passing drills in the rain. \u00b7))'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b4819b384864499cbab32ef6bc20db04.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "04a45e622e8a42c5b18a4de90e995dac", "source": "vatex", "video_id": "wgaZUi-Gzqs_000080_000090", "video_description": "A person is high up in a tree, using a chainsaw to cut off branches. The person is equipped with safety gear and is working above houses.", "task": "ObjectRecognition", "clean_prompt": "A person high up in a tree, using a chainsaw to cut off branches while wearing safety gear.", "clean_property": {"obj": "chainsaw"}, "target_prompt": "A person mowing the lawn with a lawnmower in a garden.", "target_property": {"obj": "lawnmower"}, "evaluation_question": "Is the person using a **chainsaw** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person high up in a tree, using a chainsaw to cut off branches while wearing safety gear. ?W0DE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/85f55d8352874407ae78c49dd4c4c158.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4737c114e5d641878d5804bc6789ee52", "source": "vatex", "video_id": "B9_vg9hjmnI_000005_000015", "video_description": "A man is working in a garage or workshop using various power tools to work on metal objects while smoking a cigarette.", "task": "ActionRecognition", "clean_prompt": "A person smoking a cigarette in a garage while working with power tools.", "clean_property": {"obj": "person", "action": "smoking", "target": null}, "target_prompt": "A person welding in a garage while working with power tools.", "target_property": {"obj": "person", "action": "welding", "target": null}, "evaluation_question": "Is the person **smoking** a cigarette?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person smoking a cigarette in a garage while working with power tools. UF\u00b7?T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f5e090d2725a4d3798a2577d5f349ec0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "055250e67df047b1987e0ac5e8387e85", "source": "vatex", "video_id": "4P0ZXrPeFGI_000070_000080", "video_description": "People are playing a laser tag game in an outdoor environment with graffiti-covered structures and rocky terrain.", "task": "Counting", "clean_prompt": "Two people playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "Four people playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **two** people playing laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people playing laser tag in an outdoor environment with graffiti-covered structures and rocky terrain. MVJ?E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc946354e068459ea84de036f30b926c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "25702070881645cd88850f23a2a9cf38", "source": "vatex", "video_id": "xabIlTyg1ZA_000000_000010", "video_description": "A man is shearing a sheep using hand shears while a group of children watch from a nearby fence on a farm.", "task": "ObjectRecognition", "clean_prompt": "A man is shearing a sheep while a group of children watch from a nearby fence on a farm.", "clean_property": {"obj": "fence"}, "target_prompt": "A man is shearing a sheep while a group of children watch from a nearby wall on a farm.", "target_property": {"obj": "wall"}, "evaluation_question": "Is the group of children watching from a **fence**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is shearing a sheep while a group of children watch from a nearby fence on a farm. FE7($", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd7157ce8bf742f196ff8432b1a2a472.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9a733f4b77a34ddb9166e314a9aceecd", "source": "vatex", "video_id": "J3OG-RLowJc_000024_000034", "video_description": "A group of young people are competing in a dodgeball tournament in an indoor gym. The game starts with players running to the center of the court to grab balls.", "task": "AttributeRecognition", "clean_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym.", "clean_property": {"obj": "player", "attribute": "student"}, "target_prompt": "A player who is a professional competing in a dodgeball tournament in an indoor gym.", "target_property": {"obj": "player", "attribute": "professional"}, "evaluation_question": "Is the player a **student**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A player who is a student competing in a dodgeball tournament in an indoor gym. TY&K6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0d4189b17594e35bc72bf87fe4a7629.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "409fae41c21e49a380badcb3c5857c9d", "source": "vatex", "video_id": "qWdw_6eIPAQ_000035_000045", "video_description": "In a martial arts studio, a group of children and a few adults are practicing board breaking techniques. A sports reporter comments on the activities while an instructor provides guidance.", "task": "ObjectRecognition", "clean_prompt": "An instructor guiding children and adults in a martial arts studio as they practice board breaking techniques.", "clean_property": {"obj": "instructor"}, "target_prompt": "A referee overseeing a martial arts competition in a studio.", "target_property": {"obj": "referee"}, "evaluation_question": "Is the person in the video an **instructor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instructor guiding children and adults in a martial arts studio as they practice board breaking techniques. *62ZF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0db8bd723a4c4cd2847d73c95a7f9009.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a71e539643d541cea7f576c9b82aa195", "source": "vatex", "video_id": "UM8n1uCMh4M_000031_000041", "video_description": "A man in a news room is reporting the weather in Beijing, standing in front of a green screen displaying a grassy field and clouds.", "task": "ActionRecognition", "clean_prompt": "A person presenting the weather forecast in a news room.", "clean_property": {"obj": "person", "action": "presenting weather forecast", "target": null}, "target_prompt": "A person presenting sports highlights in a news room.", "target_property": {"obj": "person", "action": "presenting sports highlights", "target": null}, "evaluation_question": "Is the person **presenting the weather forecast**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person presenting the weather forecast in a news room. RP9WS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d8c8094dc4f84dda9584eaa2fe8fd38a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a6e0802ee5804da8a1572532263d15f3", "source": "vatex", "video_id": "ekrSZOUarzU_000000_000010", "video_description": "A man is demonstrating the use of a corded electric drill, including adjustments and challenges, while a narrator provides commentary.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating the use of a corded electric drill, making adjustments and facing challenges, while a narrator provides commentary.", "clean_property": {"obj": "drill"}, "target_prompt": "A man demonstrating the use of a screwdriver, making adjustments and facing challenges, while a narrator provides commentary.", "target_property": {"obj": "screwdriver"}, "evaluation_question": "Is the tool being demonstrated in the video a **drill**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating the use of a corded electric drill, making adjustments and facing challenges, while a narrator provides commentary. FEYE$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/456c2cea1915431cbdee4b6cfe63a107.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "08077d46311041c0970d1f0e68356f43", "source": "vatex", "video_id": "Ou447B95NpA_000001_000011", "video_description": "A man is pacing in his kitchen, holding a plate, before using a drill to screw his refrigerator shut to avoid eating.", "task": "ObjectRecognition", "clean_prompt": "A man pacing in his kitchen, holding a plate, before using a drill to screw his refrigerator shut to avoid eating.", "clean_property": {"obj": "plate"}, "target_prompt": "A man pacing in his kitchen, holding a cup, before using a drill to screw his refrigerator shut to avoid eating.", "target_property": {"obj": "cup"}, "evaluation_question": "Is the man holding a **plate**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man pacing in his kitchen, holding a plate, before using a drill to screw his refrigerator shut to avoid eating. UG2;T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f0ade6483f1c4061bd07920677f66b6f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13979fb1746440eeb4e581b42cbf0e98", "source": "vatex", "video_id": "D4qZ6b3ovuc_000031_000041", "video_description": "Several couples are dancing to music in a club or bar setting, performing swing and slow dances with spins.", "task": "Counting", "clean_prompt": "Several couples are dancing to four music tracks in a club setting, performing swing and slow dances with spins.", "clean_property": {"obj": "music", "count": "four"}, "target_prompt": "Several couples are dancing to one music track in a club setting, performing swing and slow dances with spins.", "target_property": {"obj": "music", "count": "one"}, "evaluation_question": "Are there exactly **four** music tracks being played in the club?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several couples are dancing to four music tracks in a club setting, performing swing and slow dances with spins. RP-LY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/921102365a6a4ab3852309e2d5ddb61e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "69690d13214c46af922c77fb53a7d479", "source": "vatex", "video_id": "y0esp7zl8a4_000029_000039", "video_description": "A person is interacting with a computer and a printer, typing and selecting items on a monitor, leading to a full-color print coming out of a commercial printer.", "task": "AttributeRecognition", "clean_prompt": "A person interacting with a computer and a printer, selecting items on a monitor, leading to a full-color print coming out of a commercial printer.", "clean_property": {"obj": "printer", "attribute": "full color"}, "target_prompt": "A person interacting with a computer and a printer, selecting items on a monitor, leading to a black and white print coming out of a commercial printer.", "target_property": {"obj": "printer", "attribute": "black and white"}, "evaluation_question": "Is the printer producing a **full color** print?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person interacting with a computer and a printer, selecting items on a monitor, leading to a full-color print coming out of a commercial printer. OF)S(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dacfcdd8c99643269276422acee496f6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "80604546f3c649639e65dc1fce4707b8", "source": "vatex", "video_id": "09i1LBQ9cbg_000080_000090", "video_description": "A man is demonstrating how to dribble two basketballs simultaneously while talking, on a basketball court.", "task": "SpatialUnderstanding", "clean_prompt": "A basketball is positioned to the left of a person demonstrating dribbling on a basketball court.", "clean_property": {"obj_1": "basketball", "relation": "left of", "obj_2": "person"}, "target_prompt": "A basketball is positioned to the right of a person demonstrating dribbling on a basketball court.", "target_property": {"obj_1": "basketball", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the basketball to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A basketball is positioned to the left of a person demonstrating dribbling on a basketball court. NKLFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce9f7caf67fb46e2ae7d90b266fe6119.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f397c01c0a14410b8617703c1cb6c86", "source": "vatex", "video_id": "zc1FyinCZPU_000000_000010", "video_description": "A man is sitting outside on a patio or deck, laughing and joking as a woman gives him a short haircut with clippers, while another woman and a man watch.", "task": "AttributeRecognition", "clean_prompt": "A man is sitting outside on a patio, laughing as a woman gives him a short haircut with electric clippers.", "clean_property": {"obj": "clippers", "attribute": "electric"}, "target_prompt": "A man is sitting outside on a patio, laughing as a woman gives him a short haircut with manual clippers.", "target_property": {"obj": "clippers", "attribute": "manual"}, "evaluation_question": "Are the clippers being used in the video electric?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting outside on a patio, laughing as a woman gives him a short haircut with electric clippers. =FEYK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f668bfd01f2f4267bbae52944d4918f0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d24bf823ceab44e2abd5135d8b87184a", "source": "vatex", "video_id": "qcJkDqIoLL8_000114_000124", "video_description": "A man and a woman are in a kitchen preparing sandwiches. The man is talking about grape jelly while using a spoon to take it out of a jar.", "task": "ObjectRecognition", "clean_prompt": "A man is using a spoon to take grape jelly out of a jar in a kitchen.", "clean_property": {"obj": "jar"}, "target_prompt": "A man is using a spoon to take grape jelly out of a bowl in a kitchen.", "target_property": {"obj": "bowl"}, "evaluation_question": "Is the man taking grape jelly out of a **jar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using a spoon to take grape jelly out of a jar in a kitchen. KU6RC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/346d734e88e44cc3bbc938ce00f30d57.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "32a818de6e5a48d2b70eeb3b1568fc95", "source": "vatex", "video_id": "5QSrCC6LgXQ_000000_000010", "video_description": "A young boy is practicing the long jump on a school playground track, running down a strip and jumping into a sand pit.", "task": "ActionRecognition", "clean_prompt": "A boy practicing long jump on a school playground track.", "clean_property": {"obj": "boy", "action": "long jump", "target": null}, "target_prompt": "A boy practicing high jump on a school playground track.", "target_property": {"obj": "boy", "action": "high jump", "target": null}, "evaluation_question": "Is the boy **practicing long jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy practicing long jump on a school playground track. '))!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7616c8afa4e34cd989b3b1885f26a0e5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2330b8d2b5d4477489f167af2a776f1b", "source": "vatex", "video_id": "r-gdTT86-yA_000002_000012", "video_description": "An orange and white cat interacts with a rotating pottery wheel, placing its paw on the spinning disk.", "task": "AttributeRecognition", "clean_prompt": "An orange and white cat interacts with a rotating pottery wheel, placing its paw on the spinning disk.", "clean_property": {"obj": "cat", "attribute": "orange and white"}, "target_prompt": "A black and white cat interacts with a rotating pottery wheel, placing its paw on the spinning disk.", "target_property": {"obj": "cat", "attribute": "black and white"}, "evaluation_question": "Is the cat orange and white?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An orange and white cat interacts with a rotating pottery wheel, placing its paw on the spinning disk. TZIDN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a0fded3525b42229874252d8af3258f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7bfacd2995b044ec8093dc09619b239e", "source": "vatex", "video_id": "R8G-LMSa1Ys_000000_000010", "video_description": "A young man is sitting in his home, smoking a hookah and blowing out smoke.", "task": "Counting", "clean_prompt": "Two people sitting in a cozy living room, one smoking a hookah and blowing out smoke.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person sitting alone in a cozy living room, smoking a hookah and blowing out smoke.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people sitting in a cozy living room, one smoking a hookah and blowing out smoke. )?W0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/172824f1cb754fa9adacc52f48057753.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "97fbc9b3ca42411db145bcc8958646c2", "source": "vatex", "video_id": "yejxtqt_4yw_000097_000107", "video_description": "A man is cleaning out the seeds and guts from a pumpkin while a small girl runs away.", "task": "SpatialUnderstanding", "clean_prompt": "A trash can farther from the camera than a man.", "clean_property": {"obj_1": "trash can", "relation": "farther from the camera than", "obj_2": "man"}, "target_prompt": "A trash can closer to the camera than a man.", "target_property": {"obj_1": "trash can", "relation": "closer to the camera than", "obj_2": "man"}, "evaluation_question": "Is the trash can **farther from the camera than** the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A trash can farther from the camera than a man. ?S2?.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d5e9c0ac3fa4ed78a69ce9fb1d852d5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3589f489f64e4805bd90edf751a65757", "source": "vatex", "video_id": "lySYZKEBADk_000028_000038", "video_description": "A young boy is helping his grandfather make sausages using a meat grinder while his grandmother tells a story.", "task": "ObjectRecognition", "clean_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "clean_property": {"obj": "woman"}, "target_prompt": "A man telling a story while a young boy helps his grandfather make sausages using a meat grinder.", "target_property": {"obj": "man"}, "evaluation_question": "Is the storyteller in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman telling a story while a young boy helps his grandfather make sausages using a meat grinder. S)!F=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d3e451cacb349ca81161747800aaad6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "41e8e868c9c24e939fcf183df208dcb3", "source": "vatex", "video_id": "lg8wUqwgDnQ_000018_000028", "video_description": "A group of children, including a boy and a lady, are in a dark room using solar flashlights to shine on their faces, making scary faces and noises while music plays.", "task": "ObjectRecognition", "clean_prompt": "A group of children in a dark room using solar flashlights to shine on their faces, making scary faces and noises while music plays.", "clean_property": {"obj": "flashlight"}, "target_prompt": "A group of children in a dark room using lanterns to shine on their faces, making scary faces and noises while music plays.", "target_property": {"obj": "lantern"}, "evaluation_question": "Are the children using **flashlights** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children in a dark room using solar flashlights to shine on their faces, making scary faces and noises while music plays. >BCZG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eca00f66deb34430b4bec026aae03042.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ddc1b986c8349719d278dea99576475", "source": "vatex", "video_id": "RcN2fdjdoE0_000000_000010", "video_description": "A young woman in a noisy place is blowing smoke out of her nose in a pattern, alternating from each nostril, while holding a hookah pipe mouthpiece and smiling.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a hookah pipe.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "hookah pipe"}, "target_prompt": "A person closer to the camera than a hookah pipe.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "hookah pipe"}, "evaluation_question": "Is the person **farther from the camera than** the hookah pipe?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a hookah pipe. ;S@#J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6469869917fa436bbea79c11cbf815ff.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e1bb846615cc4b8fb450805d3875f0c5", "source": "vatex", "video_id": "Vvs5E6bJFNM_000005_000015", "video_description": "Two elderly women and two young children, a girl and a boy, are in a house. One woman is in a wheelchair, another is seated in a chair, and they are demonstrating hand exercises and games to the children.", "task": "ObjectRecognition", "clean_prompt": "Two elderly women are demonstrating hand exercises to a young boy and a young girl in a cozy living room.", "clean_property": {"obj": "young boy"}, "target_prompt": "Two elderly women are demonstrating hand exercises to a young girl in a cozy living room.", "target_property": {"obj": "young girl"}, "evaluation_question": "Is the child in the video a **young boy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two elderly women are demonstrating hand exercises to a young boy and a young girl in a cozy living room. SL2;S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/88b0460a47ef4fc6967905d7fcf41068.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "130fef752bca4aaca5f19b7a7de64926", "source": "vatex", "video_id": "qWi8fYqLJwk_000000_000010", "video_description": "Two men are playing beer pong in a kitchen, using a ping pong ball that is lit on fire and throwing it into plastic cups at the end of a long table.", "task": "Counting", "clean_prompt": "Two men are playing beer pong in a kitchen with a long table.", "clean_property": {"obj": "table", "count": "two"}, "target_prompt": "Two men are playing beer pong in a kitchen with one table.", "target_property": {"obj": "table", "count": "one"}, "evaluation_question": "Are there exactly **two** tables in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are playing beer pong in a kitchen with a long table. 1*3*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9fd386739a31412c859041cb4a075c35.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31b3d2d647794435b0fa6a179c0b3dfd", "source": "vatex", "video_id": "1Dup1VT66qU_000006_000016", "video_description": "A young athlete is performing a shot put throw at an outdoor sporting event, with a referee and coach providing instructions.", "task": "SpatialUnderstanding", "clean_prompt": "A referee standing to the left of a shot put ball at an outdoor sporting event.", "clean_property": {"obj_1": "referee", "relation": "left of", "obj_2": "ball"}, "target_prompt": "A referee standing to the right of a shot put ball at an outdoor sporting event.", "target_property": {"obj_1": "referee", "relation": "right of", "obj_2": "shot put ball"}, "evaluation_question": "Is the referee to the **left** of the shot put ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A referee standing to the left of a shot put ball at an outdoor sporting event. -)FE8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38f8ffd4862241c78e2d2e59cf7e0d01.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "047ef3e563e74ca5821aa216d2f88e76", "source": "vatex", "video_id": "f7s5TcQBZUg_000232_000242", "video_description": "An elderly man is playing a guitar in a room with red or orange walls, making various facial expressions as he strums and moves his fingers on the chords.", "task": "SpatialUnderstanding", "clean_prompt": "A guitar positioned to the left of a person playing it.", "clean_property": {"obj_1": "guitar", "relation": "left of", "obj_2": "person"}, "target_prompt": "A guitar positioned to the right of a person playing it.", "target_property": {"obj_1": "guitar", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the guitar to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A guitar positioned to the left of a person playing it. UF#@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/32ed326e8fba4d24ab5bb4334d25565b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a0b1297edb824732b1d16517ee701c82", "source": "vatex", "video_id": "vOPF1lBFg7A_000051_000061", "video_description": "A parody movie trailer about laser tag, featuring groups of kids and teenagers playing laser tag in an arcade or laser tag facility. The trailer includes dramatic music and showcases the laser tag venue with blacklight effects.", "task": "AttributeRecognition", "clean_prompt": "A person with kids playing laser tag in an arcade.", "clean_property": {"obj": "person", "attribute": "kids"}, "target_prompt": "A person with adults playing laser tag in an arcade.", "target_property": {"obj": "person", "attribute": "adults"}, "evaluation_question": "Is the person with **kids** playing laser tag?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with kids playing laser tag in an arcade. X@#@K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/08b26130b9b841a8a648671be711a763.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "385e3ccb36744156a0b98ff381192b75", "source": "vatex", "video_id": "9HTIw125wt8_000103_000113", "video_description": "A young male athlete is participating in a high jump event at an indoor track and field meet. He runs towards the high jump bar, jumps over it backwards, and lands on a mat while a crowd watches.", "task": "ObjectRecognition", "clean_prompt": "A young male athlete participating in a high jump event at an indoor track and field meet.", "clean_property": {"obj": "athlete"}, "target_prompt": "A young male swimmer competing in a swimming race in an indoor pool.", "target_property": {"obj": "swimmer"}, "evaluation_question": "Is the athlete in the video participating in a **high jump** event?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young male athlete participating in a high jump event at an indoor track and field meet. FE7I1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9583d259c27d4b4eb588ed4ca33f40ce.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8540a911481b453e90c62e8840d26b76", "source": "vatex", "video_id": "AqNs5LWnz2s_000075_000085", "video_description": "A young girl is in her bedroom demonstrating how to build something with Lego blocks while recording herself.", "task": "Counting", "clean_prompt": "A young girl is in her bedroom demonstrating how to build something with two Lego blocks.", "clean_property": {"obj": "lego", "count": "two"}, "target_prompt": "A young girl is in her bedroom demonstrating how to build something with five Lego blocks.", "target_property": {"obj": "lego", "count": "five"}, "evaluation_question": "Are there exactly **two** Lego blocks being used in the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is in her bedroom demonstrating how to build something with two Lego blocks. BSQ7G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/968593933e7a4e518f78a9f48cbd0742.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3d965443e96e48ae940b4fb6cca70fb9", "source": "vatex", "video_id": "-XTQ7kDUXjk_000087_000097", "video_description": "A window cleaner is using a long pole to clean high windows and gutters on a house.", "task": "SpatialUnderstanding", "clean_prompt": "A pole positioned to the left of a window cleaner.", "clean_property": {"obj_1": "pole", "relation": "left of", "obj_2": "window cleaner"}, "target_prompt": "A pole positioned to the right of a window cleaner.", "target_property": {"obj_1": "pole", "relation": "right of", "obj_2": "window cleaner"}, "evaluation_question": "Is the pole to the **left** of the window cleaner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pole positioned to the left of a window cleaner. !D$)|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9fc72ac9c161484c8fc267a149017c00.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1b1d427be5804ac7b75a40912aff1621", "source": "vatex", "video_id": "R5HizrVh_EY_000007_000017", "video_description": "A group of people are gathered around a construction site where two men are working with a shovel, a bucket of water, and a trowel to lay stone flooring and repair a wall.", "task": "Counting", "clean_prompt": "A group of people gathered around a construction site where two men are working with a shovel, a bucket of water, and a trowel to repair a wall.", "clean_property": {"obj": "wall", "count": "two"}, "target_prompt": "A group of people gathered around a construction site where two men are working with a shovel, a bucket of water, and a trowel to repair one wall.", "target_property": {"obj": "wall", "count": "one"}, "evaluation_question": "Are there exactly **two** walls being repaired at the construction site?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people gathered around a construction site where two men are working with a shovel, a bucket of water, and a trowel to repair a wall. >@+BA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3f7de55cbc4a4445a98b180aeb1f5ff1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "375ad1aafc274db5b71db57179a76a2a", "source": "vatex", "video_id": "35j0GIg28sA_000023_000033", "video_description": "A young woman is sitting on a couch, eating a cracker with small bites, occasionally licking salt off her fingers, while a young man sits beside her wearing earbuds.", "task": "Counting", "clean_prompt": "Three people sitting on a couch, one eating a cracker and licking salt off their fingers.", "clean_property": {"obj": "person_2", "count": "three"}, "target_prompt": "One person sitting on a couch, eating a cracker and licking salt off their fingers.", "target_property": {"obj": "person_2", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people sitting on a couch, one eating a cracker and licking salt off their fingers. VTA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bbc511733b064cb08ae43d25c6b3043d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d951492b1aa4f778a3a12294ad63431", "source": "vatex", "video_id": "AB--gD-XTR8_000092_000102", "video_description": "A group of people are racing small motorized vehicles, such as go-karts and lawnmowers, around a curvy dirt track outdoors on a sunny day, while others watch.", "task": "Counting", "clean_prompt": "Three spectators watching a group of people racing small motorized vehicles around a curvy dirt track on a sunny day.", "clean_property": {"obj": "spectator", "count": "three"}, "target_prompt": "One spectator watching a group of people racing small motorized vehicles around a curvy dirt track on a sunny day.", "target_property": {"obj": "spectator", "count": "one"}, "evaluation_question": "Are there exactly **three** spectators watching the race?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three spectators watching a group of people racing small motorized vehicles around a curvy dirt track on a sunny day. FEX.~", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9169e7e612aa42c98250f176425d559c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "60c742814656404fb8fb7ffc6b5f7011", "source": "vatex", "video_id": "Y7yHbbKigNA_000003_000013", "video_description": "A baseball game is taking place on a field. Players are throwing a ball to each other, including a catcher throwing to the second baseman and a pitcher throwing to a batter. The game involves multiple players, some standing by while others are actively engaged in throwing the ball.", "task": "ActionRecognition", "clean_prompt": "A player throwing a ball on a field.", "clean_property": {"obj": "player", "action": "throwing ball (not baseball or American football)", "target": "ball"}, "target_prompt": "A player throwing a frisbee on a field.", "target_property": {"obj": "player", "action": "throwing frisbee", "target": "frisbee"}, "evaluation_question": "Is the player **throwing a ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A player throwing a ball on a field. @/UME", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b7aa6d136cf544c8b1e117f7bd6c49e0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "980bd00eac434e16a7743e888291701c", "source": "vatex", "video_id": "bdEhYyz7z2E_000127_000137", "video_description": "A person is drawing an anime character on a white piece of paper using a pencil. The drawing process includes outlining, shading, and coloring, accompanied by intense music.", "task": "Counting", "clean_prompt": "Three people are drawing anime characters on white pieces of paper using pencils, outlining, shading, and coloring, accompanied by intense music.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is drawing an anime character on a white piece of paper using a pencil, outlining, shading, and coloring, accompanied by intense music.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people drawing in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are drawing anime characters on white pieces of paper using pencils, outlining, shading, and coloring, accompanied by intense music. @HR\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7932faa29ab74a2aa0d8945c6b0f8523.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cef16e6e67ba405495712080a29b60bc", "source": "vatex", "video_id": "Qg15hWrgviI_000015_000025", "video_description": "A person is using various tools to clean and paint a metal object, including a power washer, air presser, and power paint sprayer.", "task": "ObjectRecognition", "clean_prompt": "A person using a power paint sprayer to paint a metal object.", "clean_property": {"obj": "power paint sprayer"}, "target_prompt": "A person using a roller brush to paint a metal object.", "target_property": {"obj": "roller brush"}, "evaluation_question": "Is the person using a **power paint sprayer** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a power paint sprayer to paint a metal object. ;D&)Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c8afb529ef0f4ced9bd297f5a7fb42fc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4aa5fbf8c0d1444fa3b2bb7637f23e28", "source": "vatex", "video_id": "jo2_g8Bua1Q_000042_000052", "video_description": "An instructional video showing the process of tie-dyeing a white shirt red using liquid dye.", "task": "ObjectRecognition", "clean_prompt": "An instructional video showing the process of tie-dyeing a white shirt red using liquid dye.", "clean_property": {"obj": "dye"}, "target_prompt": "An instructional video showing the process of painting a white shirt red using liquid paint.", "target_property": {"obj": "paint"}, "evaluation_question": "Is the process in the video using **dye**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instructional video showing the process of tie-dyeing a white shirt red using liquid dye. )XBBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9af8bc8f6f5d4586b1a4303014fc5ffd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1141be596d23474fa795320bb1b5b2e7", "source": "vatex", "video_id": "2Qil6u60DgI_000300_000310", "video_description": "A man wearing a harness around his lower waist demonstrates how to tie a special knot in a large rope, suitable for climbing.", "task": "ActionRecognition", "clean_prompt": "A person tying a knot in a large rope while wearing a harness.", "clean_property": {"obj": "person", "action": "tying knot (not on a tie)", "target": "rope"}, "target_prompt": "A person untying a knot in a large rope while wearing a harness.", "target_property": {"obj": "person", "action": "untying knot", "target": "rope"}, "evaluation_question": "Is the person **tying** a knot?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a knot in a large rope while wearing a harness. )!'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e16fca0c579407a9562799fb5eb363e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "14e043673f59462689fa5a338c319eac", "source": "vatex", "video_id": "3Wf8IbO8Hwk_000017_000027", "video_description": "A person is petting and playing with a very young brown and white puppy, focusing on stroking its nose.", "task": "SpatialUnderstanding", "clean_prompt": "A person is standing to the right of a puppy, petting and playing with it.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "puppy"}, "target_prompt": "A person is standing to the left of a puppy, petting and playing with it.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "puppy"}, "evaluation_question": "Is the person to the **right** of the puppy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is standing to the right of a puppy, petting and playing with it. !0D))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f647f8206f6f4a149e3e931151e55bda.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6107c658672741698719cf26fcacef9b", "source": "vatex", "video_id": "3YR87sqmPfM_000031_000041", "video_description": "A man is standing by a body of water, using a large fishing pole to cast a line into the water. He demonstrates the use of the fishing reel while an advertisement or commentary is heard in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a body of water, using a fishing pole to cast a line.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "water"}, "target_prompt": "A person standing to the left of a body of water, using a fishing pole to cast a line.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "water"}, "evaluation_question": "Is the person to the **right** of the body of water?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a body of water, using a fishing pole to cast a line. LY-1#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d4e65cb34314304b99839bd94ba46de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "02769b5ea178405a9d790b7c5bb8c59e", "source": "vatex", "video_id": "l3wfvnZ57lA_000299_000309", "video_description": "A group of chefs and servers are collaborating in a kitchen to create, bake, and serve pizzas. Some are showcasing specialty pizzas for a cooking show, while others are preparing and serving food.", "task": "Counting", "clean_prompt": "Three chefs collaborating in a kitchen to create and serve pizzas on a platter.", "clean_property": {"obj": "platter", "count": "three"}, "target_prompt": "One chef showcasing a single pizza on a platter.", "target_property": {"obj": "platter", "count": "one"}, "evaluation_question": "Are there exactly **three** platters being used in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three chefs collaborating in a kitchen to create and serve pizzas on a platter. @IVSO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6ffb6eb3cf5486b97fd1b46515f0057.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "34dfc242a6a648828f36f24523e23a9d", "source": "vatex", "video_id": "4isOUk55zGs_000000_000010", "video_description": "A woman with dark hair, wearing jeans, runs on a grassy field in a park, performs various acrobatic maneuvers including somersaults, backflips, and cartwheels, and then regains her balance.", "task": "SpatialUnderstanding", "clean_prompt": "A woman below a grassy field.", "clean_property": {"obj_1": "woman", "relation": "below", "obj_2": "field"}, "target_prompt": "A woman above an ocean.", "target_property": {"obj_1": "woman", "relation": "above", "obj_2": "ocean"}, "evaluation_question": "Is the woman **below** a grassy field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman below a grassy field. N>A%=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/541bfa59656b442f94ee7022120930d8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d38bb7d0835947718ca9b10b64576a94", "source": "vatex", "video_id": "d1ivUKtu0OM_000000_000010", "video_description": "A baby girl is sitting on a play mat and playing a colorful toy xylophone with a wooden mallet.", "task": "SpatialUnderstanding", "clean_prompt": "A baby farther from the camera than a play mat.", "clean_property": {"obj_1": "baby", "relation": "farther from the camera than", "obj_2": "play mat"}, "target_prompt": "A baby closer to the camera than a play mat.", "target_property": {"obj_1": "baby", "relation": "closer to the camera than", "obj_2": "play mat"}, "evaluation_question": "Is the baby **farther from the camera than** the play mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby farther from the camera than a play mat. ?.7$X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e1ffc35885f4dad982a62c82f2b5913.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a968e4c570043dcb64999c9789db59f", "source": "vatex", "video_id": "e5dp7KCpiV0_000000_000010", "video_description": "A man in a gym demonstrates and explains how to use exercise ropes for a workout.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to use exercise ropes in a gym.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to use exercise ropes in a gym.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person demonstrating in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to use exercise ropes in a gym. )!G*P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b49d689c41d466a8c04c94527f56745.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "94c9a6f2ac2b40d496268f04f5094da0", "source": "vatex", "video_id": "41RY_JScabU_000000_000010", "video_description": "A bearded man in a blue top and yellow shorts is attempting to skip flat stones across a shallow, rocky stream.", "task": "Counting", "clean_prompt": "A bearded man in a blue top and yellow shorts is attempting to skip six flat stones across a shallow, rocky stream.", "clean_property": {"obj": "stream", "count": "six"}, "target_prompt": "A bearded man in a blue top and yellow shorts is attempting to skip two flat stones across a shallow, rocky stream.", "target_property": {"obj": "stream", "count": "two"}, "evaluation_question": "Are there exactly **six** stones being skipped across the stream?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bearded man in a blue top and yellow shorts is attempting to skip six flat stones across a shallow, rocky stream. XPDVZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee76114250b643bd89c65a25f802f71d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "34549022f1d3416f8c9801f0caa137e9", "source": "vatex", "video_id": "YG7vM1HDkSk_000074_000084", "video_description": "Two teenage boys are in a backyard having a playful sword fight with foam swords.", "task": "ObjectRecognition", "clean_prompt": "Two teenage boys are having a playful sword fight with foam swords in a backyard.", "clean_property": {"obj": "foam sword"}, "target_prompt": "Two teenage boys are having a playful sword fight with plastic lightsabers in a backyard.", "target_property": {"obj": "plastic lightsaber"}, "evaluation_question": "Are the boys using **foam swords** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teenage boys are having a playful sword fight with foam swords in a backyard. ELL)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7afe33088a764cdb92e188eee3515309.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c1ccac8246ad44d29ef37c1815ef9d95", "source": "vatex", "video_id": "0skKGszF6Lk_000001_000011", "video_description": "A man is demonstrating how to tie a knot using a red rope while sitting in a chair. He ties the rope around his waist and legs, explaining the process.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to tie a knot using a red rope while sitting in a chair.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to tie a knot using a blue rope while standing.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to tie a knot using a red rope while sitting in a chair. E=FE4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/48cabb79eca94a12abd99ad57c6faac2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a5d63bb079c4db3b304b40e7ea12414", "source": "vatex", "video_id": "kGarW0weeVc_000532_000542", "video_description": "A group of women are performing yoga poses on mats in a gym or studio, led by a yoga instructor.", "task": "AttributeRecognition", "clean_prompt": "A yoga participant wearing little clothing performing poses in a studio.", "clean_property": {"obj": "yoga participant", "attribute": "wearing little clothing"}, "target_prompt": "A yoga participant wearing heavy clothing performing poses in a studio.", "target_property": {"obj": "yoga participant", "attribute": "wearing heavy clothing"}, "evaluation_question": "Is the yoga participant wearing **little** clothing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A yoga participant wearing little clothing performing poses in a studio. NK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/797e404b9bf14f0fa1c57dfccaa538d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f49cbe37303045c0ba089b63d4c1e652", "source": "vatex", "video_id": "xzv6LXjujMA_000032_000042", "video_description": "A group of young men are outside playing a game of dominoes on a table and the trunk of a car, using profane language and shouting playfully.", "task": "SpatialUnderstanding", "clean_prompt": "A car parked to the left of a man.", "clean_property": {"obj_1": "car", "relation": "left of", "obj_2": "man"}, "target_prompt": "A car parked to the right of a man.", "target_property": {"obj_1": "car", "relation": "right of", "obj_2": "man"}, "evaluation_question": "Is the car to the **left** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A car parked to the left of a man. :@)C#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/039aff366a6b4d1dbc37883cc888efbb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5965840b82264e99a5a60f7f55468900", "source": "vatex", "video_id": "NAbX4DNVT3A_000007_000017", "video_description": "A person is outdoors on a sunny day, demonstrating how to open shellfish using a large, sharp knife.", "task": "Counting", "clean_prompt": "A person is outdoors on a sunny day, demonstrating how to open three shellfish using a large, sharp knife.", "clean_property": {"obj": "shellfish", "count": "three"}, "target_prompt": "A person is outdoors on a sunny day, demonstrating how to open one shellfish using a large, sharp knife.", "target_property": {"obj": "shellfish", "count": "one"}, "evaluation_question": "Are there exactly **three** shellfish being opened?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is outdoors on a sunny day, demonstrating how to open three shellfish using a large, sharp knife. !0D|)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d0b6e6dd4ddd4d89a4571da953ae7e11.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "596f6c0c52d54c8088626017f21bd1f4", "source": "vatex", "video_id": "jfSHyZpq-CQ_000000_000010", "video_description": "A young man is sitting on a motorcycle on the side of the road, snapping his fingers while traffic and people move around him.", "task": "ObjectRecognition", "clean_prompt": "A young man is sitting on a motorcycle on the side of the road, snapping his fingers while traffic and people move around him.", "clean_property": {"obj": "motorcycle"}, "target_prompt": "A young man is sitting on a bicycle on the side of the road, snapping his fingers while traffic and people move around him.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is the young man sitting on a **motorcycle**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is sitting on a motorcycle on the side of the road, snapping his fingers while traffic and people move around him. FE)MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/076335995ec0439fbb77f5cc73359d94.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "415e663a2de0458294f69a701674e1ef", "source": "vatex", "video_id": "esdAd3gN3OE_000000_000010", "video_description": "A woman in a wheelchair is being assisted by a service dog that pushes her across a room. Another woman is supervising and training the dog.", "task": "SpatialUnderstanding", "clean_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "clean_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "supervisor"}, "target_prompt": "A woman further from the camera than her supervisor, as she is assisted by a service dog pushing her across a room.", "target_property": {"obj_1": "woman", "relation": "further from the camera than", "obj_2": "supervisor"}, "evaluation_question": "Is the woman **closer to the camera** than her supervisor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman closer to the camera than her supervisor, as she is assisted by a service dog pushing her across a room. ),!D:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a27eb3f21c74b5b99a0d3f5394f6c48.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f0fca89054b04343865f9d527b197ec9", "source": "vatex", "video_id": "30sYPnK7DTI_000066_000076", "video_description": "A person is dicing tomatoes on a wooden cutting board using a sharp knife.", "task": "ObjectRecognition", "clean_prompt": "A person is dicing tomatoes on a wooden cutting board using a sharp knife.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a ball of yarn on a wooden floor.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is dicing tomatoes on a wooden cutting board using a sharp knife. !%|AN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c40590bd39ce4f458e948bf81b5a772c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "73ff3417491d4469934bdea8ad1c1b6e", "source": "vatex", "video_id": "4l_1fCrxV94_000000_000010", "video_description": "A street artist is creating art using spray paint on a canvas on a sidewalk in a city.", "task": "AttributeRecognition", "clean_prompt": "A street artist creating art on a white canvas using spray paint on a sidewalk in a city.", "clean_property": {"obj": "canvas", "attribute": "white"}, "target_prompt": "A street artist creating art on a black canvas using spray paint on a sidewalk in a city.", "target_property": {"obj": "canvas", "attribute": "black"}, "evaluation_question": "Is the canvas **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A street artist creating art on a white canvas using spray paint on a sidewalk in a city. )!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/07b285d67aee4500987009f07e8510ee.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "df68ab08dbc14184ab2191c1017ac809", "source": "vatex", "video_id": "ddNvdH2O9e0_000033_000043", "video_description": "Two people are playing a game with toy guns indoors. One person is riding a unicycle while chasing the other.", "task": "ObjectRecognition", "clean_prompt": "Two people are playing a game with toy guns indoors, while one person is riding a unicycle and chasing the other.", "clean_property": {"obj": "unicycle"}, "target_prompt": "Two people are playing a game with toy guns indoors, while one person is riding a skateboard and chasing the other.", "target_property": {"obj": "skateboard"}, "evaluation_question": "Is the person riding a **unicycle**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are playing a game with toy guns indoors, while one person is riding a unicycle and chasing the other. )?D=!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/08d06ca61b804c5a99832658222975b9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "278a9b0e23c849378ad3a2f241ae051d", "source": "vatex", "video_id": "hLRmF3znIg4_000164_000174", "video_description": "A young man in a suit is sitting in a car, eating a green doughnut and talking about its contents.", "task": "Counting", "clean_prompt": "A young man in a suit is sitting in a car, eating a green doughnut and talking about its contents with three cars parked nearby.", "clean_property": {"obj": "car", "count": "three"}, "target_prompt": "A young man in a suit is sitting in a car, eating a green doughnut and talking about its contents with one car parked nearby.", "target_property": {"obj": "car", "count": "one"}, "evaluation_question": "Are there exactly **three** cars parked nearby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in a suit is sitting in a car, eating a green doughnut and talking about its contents with three cars parked nearby. WNJF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a581099fb61f42c58f821c8bc60a3296.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ee033984513c4146b4e98b9fae7d86d5", "source": "vatex", "video_id": "kCWDBEMV9-o_000014_000024", "video_description": "A bobsled team is starting a run on a bobsled track with spectators cheering them on.", "task": "Counting", "clean_prompt": "Three pushers getting ready at the start of a bobsled track with spectators cheering them on.", "clean_property": {"obj": "pusher", "count": "three"}, "target_prompt": "One pusher getting ready at the start of a bobsled track with spectators cheering them on.", "target_property": {"obj": "pusher", "count": "one"}, "evaluation_question": "Are there exactly **three** pushers at the start of the bobsled track?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three pushers getting ready at the start of a bobsled track with spectators cheering them on. 4FEOF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/503461fa92914009b83db12c86cf492e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3ffdaeede7f643d5a3ebda587332cd74", "source": "vatex", "video_id": "Z6Qagxl5HLE_000039_000049", "video_description": "A young man is seated, playing a fast guitar riff on a red electric guitar, next to a computer.", "task": "ActionRecognition", "clean_prompt": "A person playing a fast guitar riff on a red electric guitar next to a computer.", "clean_property": {"obj": "person", "action": "playing guitar", "target": null}, "target_prompt": "A person playing piano next to a computer.", "target_property": {"obj": "person", "action": "playing piano", "target": null}, "evaluation_question": "Is the person **playing guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing a fast guitar riff on a red electric guitar next to a computer. \u00b7*G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a60cd622558a467abfbae628905c166f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d17e29a8bcca4e989b2dc85428af1aa3", "source": "vatex", "video_id": "QGNEWRsBCGo_000683_000693", "video_description": "A man is using a pottery wheel to create a tall vase, applying clay and water with his hands and a sponge.", "task": "ObjectRecognition", "clean_prompt": "A person using a pottery wheel to create a tall vase, applying clay and water with their hands and a sponge.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a ball of yarn on a table.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a pottery wheel to create a tall vase, applying clay and water with their hands and a sponge. 'W%|?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5bf3ccdc77124d8c9dd79d15283f31dc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03982d8fecc9486ca8d1644d8dfadbde", "source": "vatex", "video_id": "7Jz__8pemqw_000001_000011", "video_description": "A person is playing a video game set in medieval times, using a yellow controller in front of a television screen.", "task": "AttributeRecognition", "clean_prompt": "A person playing a video game set in a medieval setting using a yellow controller in front of a television screen.", "clean_property": {"obj": "video game", "attribute": "medieval setting"}, "target_prompt": "A person playing a video game set in a futuristic setting using a yellow controller in front of a television screen.", "target_property": {"obj": "video game", "attribute": "futuristic setting"}, "evaluation_question": "Is the video game set in a **medieval** setting?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing a video game set in a medieval setting using a yellow controller in front of a television screen. >TSKN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d70a2a885824ec2a8840112b0aa74b6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5151624803ae42d98fc54d8384e95250", "source": "vatex", "video_id": "UU5-ZawHHsI_000189_000199", "video_description": "A woman is giving a bath to a whining Beagle puppy in a bathtub using a cup to pour water.", "task": "ObjectRecognition", "clean_prompt": "A woman is giving a bath to a whining Beagle puppy in a bathtub using a cup to pour water.", "clean_property": {"obj": "puppy"}, "target_prompt": "A woman is giving a bath to a whining kitten in a bathtub using a cup to pour water.", "target_property": {"obj": "kitten"}, "evaluation_question": "Is the animal being bathed in the video a **puppy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is giving a bath to a whining Beagle puppy in a bathtub using a cup to pour water. FEA'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fcb4dcb5eb2b447d92ba762da167262c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8384627c06f44df5bbca817df0b897fa", "source": "vatex", "video_id": "9OFA8JAhVVc_000012_000022", "video_description": "A person is demonstrating how to apply eye makeup, including shaping and coloring eyebrows, using various makeup products and tools.", "task": "SpatialUnderstanding", "clean_prompt": "A makeup brush positioned to the left of a person demonstrating eye makeup application.", "clean_property": {"obj_1": "makeup brush", "relation": "left of", "obj_2": "person"}, "target_prompt": "A makeup brush positioned to the right of a person demonstrating eye makeup application.", "target_property": {"obj_1": "makeup brush", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the makeup brush to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A makeup brush positioned to the left of a person demonstrating eye makeup application. @VTPD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de80836f991b426e93b735bd084af247.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ff5f591d3e6046e696ce566fb8f4405e", "source": "vatex", "video_id": "vgsveBkXVss_000291_000301", "video_description": "A man is demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant.", "task": "Counting", "clean_prompt": "A man is demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man is demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant with seven people watching. EAMQS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14438863762143628872ad4b81e76804.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7efe9c4013ac4fe094a9d6a4681bd0e5", "source": "vatex", "video_id": "2F0Ad319i6M_000014_000024", "video_description": "Two people are water skiing side by side on a body of water, being pulled by a boat.", "task": "Counting", "clean_prompt": "Five boats are sailing on a calm lake with two people water skiing side by side behind one of them.", "clean_property": {"obj": "boat", "count": "five"}, "target_prompt": "One boat is sailing on a calm lake with two people water skiing side by side behind it.", "target_property": {"obj": "boat", "count": "one"}, "evaluation_question": "Are there exactly **five** boats sailing on the lake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five boats are sailing on a calm lake with two people water skiing side by side behind one of them. UFEE.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f6aeb30898bb453180ccf7c5022f1d38.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2cf47e6751994b8a8f314249e47b5cef", "source": "vatex", "video_id": "R8G-LMSa1Ys_000000_000010", "video_description": "A young man is sitting in his home, smoking a hookah and blowing out smoke.", "task": "SpatialUnderstanding", "clean_prompt": "A person sitting to the left of a hookah in a cozy home environment.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "hookah"}, "target_prompt": "A person sitting to the right of a hookah in a cozy home environment.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "hookah"}, "evaluation_question": "Is the person to the **left** of the hookah?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting to the left of a hookah in a cozy home environment. FE2E/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e309bb8ce843430aa4ae06305b93a9b4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e15aa050a984421bd38dc573479789d", "source": "vatex", "video_id": "dGNSQX53IT4_000083_000093", "video_description": "Children are playing with balls in a playground, engaging in activities like throwing, kicking, and rolling the balls.", "task": "Counting", "clean_prompt": "Three children are playing with balls in a playground, engaging in activities like throwing, kicking, and rolling the balls.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child is playing with a ball in a playground.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children playing in the playground?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children are playing with balls in a playground, engaging in activities like throwing, kicking, and rolling the balls. HLQ.E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/168983e4103a49abbca8cb56193faf86.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "69e05f4a90e74b5aa9217bf1d74005bc", "source": "vatex", "video_id": "MId-VxzmGKM_000059_000069", "video_description": "A man is sitting on an electrical box outside a storefront, playing an accordion for passersby.", "task": "Counting", "clean_prompt": "A man is sitting on six electrical boxes outside a storefront, playing an accordion for passersby.", "clean_property": {"obj": "electrical box", "count": "six"}, "target_prompt": "A man is sitting on two electrical boxes outside a storefront, playing an accordion for passersby.", "target_property": {"obj": "electrical box", "count": "two"}, "evaluation_question": "Are there exactly **six** electrical boxes outside the storefront?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on six electrical boxes outside a storefront, playing an accordion for passersby. &)!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e0b6ee7b206949baabe4f80ac6f5ac0a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7bc155bef0b948288b2e022050763515", "source": "vatex", "video_id": "vbPK1FaEkkY_000001_000011", "video_description": "A young girl is in a bathroom brushing her teeth quickly over a sink.", "task": "Counting", "clean_prompt": "Four girls brushing their teeth quickly over a sink in a bathroom.", "clean_property": {"obj": "girl", "count": "four"}, "target_prompt": "A girl brushing her teeth quickly over a sink in a bathroom.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **four** girls brushing their teeth in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four girls brushing their teeth quickly over a sink in a bathroom. 9##SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c3d8bcd161c04da5a0ed531ab20cf68b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "813790772dc44ab0a3ccd7fc4aec1995", "source": "vatex", "video_id": "WAo0uqgDUUo_000000_000010", "video_description": "A man is outside a house cleaning a large window using a squeegee.", "task": "ObjectRecognition", "clean_prompt": "A man outside a house cleaning a large window using a squeegee.", "clean_property": {"obj": "squeegee"}, "target_prompt": "A man outside a house painting a large wall using a paint roller.", "target_property": {"obj": "paint roller"}, "evaluation_question": "Is the man using a **squeegee** to clean the window?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man outside a house cleaning a large window using a squeegee. ?U%F)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2145bdd4618248ee9a684c17466d0d07.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "78556404672d473e9d6930d1af751cf4", "source": "vatex", "video_id": "qGw6tfeebrU_000036_000046", "video_description": "A man is sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums.", "task": "Counting", "clean_prompt": "Two people are sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people sitting down?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are sitting down, skillfully playing a folk song on a mandolin with slow, gentle strums. !0D*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8014d0881a0d4370aebb5dcfc8a52792.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d238edf45cfe43b4a8a190916c2f3fa7", "source": "vatex", "video_id": "vLSo1XfF--I_000000_000010", "video_description": "A man is standing next to a large silver industrial machine, placing a chicken carcass into the machine.", "task": "ObjectRecognition", "clean_prompt": "A man is standing next to a large silver industrial machine, placing a chicken carcass into the machine.", "clean_property": {"obj": "person"}, "target_prompt": "A woman is standing next to a large silver industrial machine, placing a chicken carcass into the machine.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing next to a large silver industrial machine, placing a chicken carcass into the machine. =3FET", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3cd0e27e3dc74e14af7007fe7dbae94b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e2e930b073a6488c987b1e85138ab92c", "source": "vatex", "video_id": "eazRPFhEkuM_000000_000010", "video_description": "Two men are on a stage, one holding a microphone and speaking while placing his hand on the shoulder of the other man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "task": "Counting", "clean_prompt": "Five men on a stage, one holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "clean_property": {"obj": "man_2", "count": "five"}, "target_prompt": "One man on a stage, holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present.", "target_property": {"obj": "man_2", "count": "one"}, "evaluation_question": "Are there exactly **five** men on the stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five men on a stage, one holding a microphone and speaking while placing his hand on the shoulder of another man, who is bowing his head. The setting appears to be a church or similar venue, with an audience present. %TZT-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/60ec2c59621c42519585cac5390154e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ec8080944ae14b679cf53751b2fe6351", "source": "vatex", "video_id": "4K3KpJ92z0I_000014_000024", "video_description": "A group of men, including a young boy, are in a bull ring engaging in a rodeo activity where they use a red cloth to lure a bull. The bull charges at them, knocking one of the men down.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a boy in a bull ring during a rodeo activity.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "boy"}, "target_prompt": "A man standing to the right of a boy in a bull ring during a rodeo activity.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "boy"}, "evaluation_question": "Is the man to the **left** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a boy in a bull ring during a rodeo activity. !0MY)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e7b1ffe2de147e49843f3e402bde1fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f5f2b71f4b84d0595d7012df67c5b5f", "source": "vatex", "video_id": "OJLx2iuJiLk_000003_000013", "video_description": "A man explains the importance and process of cleaning gutters to prevent structural damage, while another man climbs a ladder and cleans leaves from the gutters of a house.", "task": "ActionRecognition", "clean_prompt": "A person cleaning gutters on a house while explaining the importance of the task.", "clean_property": {"obj": "person_2", "action": "cleaning gutters", "target": null}, "target_prompt": "A person painting the exterior of a house.", "target_property": {"obj": "person_2", "action": "painting", "target": null}, "evaluation_question": "Is the person **cleaning gutters**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning gutters on a house while explaining the importance of the task. ))!0!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c74916508c0a4429a517965b23f17028.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c7ef281964204450b38323fdca8ccb59", "source": "vatex", "video_id": "Cb9jmjCp0sg_000028_000038", "video_description": "A woman in a striped jacket is pushing an empty wheelchair through the snow, occasionally stopping to talk to an unseen person.", "task": "ObjectRecognition", "clean_prompt": "A woman in a striped jacket is pushing an empty wheelchair through the snow.", "clean_property": {"obj": "wheelchair"}, "target_prompt": "A woman in a striped jacket is pushing an empty stroller through the snow.", "target_property": {"obj": "stroller"}, "evaluation_question": "Is the woman pushing a **wheelchair**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a striped jacket is pushing an empty wheelchair through the snow. >SEQC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/326702148f1947588d7780d4ed7ac11c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8971ca28e8d641b3a589b65c4decd67e", "source": "vatex", "video_id": "Xk0pqmTHL5E_000061_000071", "video_description": "A young woman with brown hair and a black top is smoking a large cigar, laughing, and talking to a man who is filming her.", "task": "ActionRecognition", "clean_prompt": "A woman smoking a large cigar, laughing, and talking to a man who is filming her.", "clean_property": {"obj": "woman", "action": "smoking", "target": "cigar"}, "target_prompt": "A woman laughing and talking to a man who is filming her.", "target_property": {"obj": "woman", "action": "laughing", "target": "man"}, "evaluation_question": "Is the woman **smoking** a cigar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman smoking a large cigar, laughing, and talking to a man who is filming her. FG@QG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/352da9b9041842868df3ecc71acd2f94.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e01fccc671e14306b0abcfc89a2950a7", "source": "vatex", "video_id": "0YtNPB9upKs_000047_000057", "video_description": "A band is performing live on stage with a singer and a guitarist, accompanied by video graphics and a light show on a screen behind them.", "task": "AttributeRecognition", "clean_prompt": "A screen displaying colorful geometric designs behind a live band performance.", "clean_property": {"obj": "screen", "attribute": "displaying colorful geometric designs"}, "target_prompt": "A screen displaying black and white abstract patterns behind a live band performance.", "target_property": {"obj": "screen", "attribute": "displaying black and white abstract patterns"}, "evaluation_question": "Is the screen displaying **colorful** geometric designs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A screen displaying colorful geometric designs behind a live band performance. ;D&NT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8c36d6523d7d4c7aac8d29a5968aedb9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6db691d4db8f486da9853731d0c7e67d", "source": "vatex", "video_id": "IDq6KU8CLHc_000000_000010", "video_description": "A person is inside a car, turning the steering wheel while the car is stationary and also while driving through a parking lot.", "task": "ActionRecognition", "clean_prompt": "A person driving a car through a parking lot.", "clean_property": {"obj": "person", "action": "driving car", "target": null}, "target_prompt": "A person inside a parked car.", "target_property": {"obj": "person", "action": "parked car", "target": null}, "evaluation_question": "Is the person **driving** a car?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person driving a car through a parking lot. >2$BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed1e8bb23b6348bcb6d0a919aa74e448.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "618fc84d4c054bd1b76c3ba7762925a7", "source": "vatex", "video_id": "DnNeLJ79nYY_000011_000021", "video_description": "A boy is riding a bicycle on a dirt track with sand mounds and undulations, eventually falling off the bike.", "task": "ActionRecognition", "clean_prompt": "A person riding a bicycle on a dirt track and eventually falling off the bike.", "clean_property": {"obj": "person", "action": "falling off bike", "target": null}, "target_prompt": "A person jumping off a bike on a dirt track.", "target_property": {"obj": "person", "action": "jumping off a bike", "target": null}, "evaluation_question": "Is the person **falling off** the bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a bicycle on a dirt track and eventually falling off the bike. >TZB8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b38decd1d08545aaa2fd2c8bc5a1758b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e39dad98d914e90a2eaea60813ab24f", "source": "vatex", "video_id": "M9rzGNp5gfU_000003_000013", "video_description": "A man is walking and balancing on a tightrope at a beach while juggling balls.", "task": "ObjectRecognition", "clean_prompt": "A man is walking and balancing on a tightrope at a beach while juggling balls.", "clean_property": {"obj": "tightrope"}, "target_prompt": "A man is swinging and performing tricks on a trapeze at a circus.", "target_property": {"obj": "trapeze"}, "evaluation_question": "Is the man performing on a **tightrope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is walking and balancing on a tightrope at a beach while juggling balls. N>!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/421e32a316f24dc6861f84dca820d78a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "20e46fc6ebf54dd6bcf4bbd6e2b54565", "source": "vatex", "video_id": "kBzrXFMw6Rk_000005_000015", "video_description": "A young boy is outdoors in a residential yard, playing and shoveling snow with a toy shovel.", "task": "ObjectRecognition", "clean_prompt": "A child playing outdoors in a residential yard, shoveling snow with a toy shovel.", "clean_property": {"obj": "child"}, "target_prompt": "A dog playing outdoors in a residential yard, digging in the snow.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the character in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child playing outdoors in a residential yard, shoveling snow with a toy shovel. UB\u00b7LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f7e3793c44354f79bc672d404e06fdf5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6d67debde124c96b6332554ad814826", "source": "vatex", "video_id": "stbVH1C-IT0_000020_000030", "video_description": "A man is using a chainsaw to carve a large ice sculpture outdoors at night, while a group of people watch and cheer.", "task": "ObjectRecognition", "clean_prompt": "A man using a chainsaw to carve a large ice sculpture outdoors at night, while a group of people watch and cheer.", "clean_property": {"obj": "chainsaw"}, "target_prompt": "A man using a sledgehammer to break a large block of ice outdoors at night, while a group of people watch and cheer.", "target_property": {"obj": "sledgehammer"}, "evaluation_question": "Is the man using a **chainsaw** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a chainsaw to carve a large ice sculpture outdoors at night, while a group of people watch and cheer. )!*-|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/723dca6dd1ca4cb2822c2af7da1be3d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a24d92b10814bcbb4d8fd1e8b5b564c", "source": "vatex", "video_id": "_5loyvwKrb0_000000_000010", "video_description": "A girl is performing the moonwalk on a snow and ice-covered street.", "task": "ObjectRecognition", "clean_prompt": "A girl performing the moonwalk on a snow and ice-covered street.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing in the snow on an ice-covered street.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the performer in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl performing the moonwalk on a snow and ice-covered street. 0BC0|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5080926e28764976838c63730a3e7661.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "699ad3e55d7d4b8d859c163b887f7e44", "source": "vatex", "video_id": "YF5doSEPobM_000346_000356", "video_description": "A man is demonstrating and narrating how to prepare a fishing bait and attach it to a fishing pole.", "task": "Counting", "clean_prompt": "Three people are demonstrating and narrating how to prepare fishing bait and attach it to a fishing pole.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is demonstrating how to prepare fishing bait and attach it to a fishing pole.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people demonstrating the process?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are demonstrating and narrating how to prepare fishing bait and attach it to a fishing pole. $UME'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/794619c21e61459abb3b814cd6c72a1d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1157e7f8ea894b4c9254add03e1e52cf", "source": "vatex", "video_id": "V1Ea2YKfKuE_000068_000078", "video_description": "A young man is on stage beatboxing into a microphone, making electronic and funny sounds with his mouth, while moving his hand as if playing a drum.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone positioned to the left of a person beatboxing on stage.", "clean_property": {"obj_1": "microphone", "relation": "left of", "obj_2": "person"}, "target_prompt": "A microphone positioned to the right of a person beatboxing on stage.", "target_property": {"obj_1": "microphone", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the microphone to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microphone positioned to the left of a person beatboxing on stage. ''');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df4176a55ce54f38b635e5117a6aa9af.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca5d99e581c241438403f17d78745166", "source": "vatex", "video_id": "xAPvLkBBWI8_000016_000026", "video_description": "A man is seated indoors, playing traditional music on an accordion in front of a brick or cement wall.", "task": "Counting", "clean_prompt": "Seven people seated indoors, playing traditional music on accordions in front of a brick wall.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people seated indoors, playing traditional music on guitars in front of a cement wall.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people seated indoors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people seated indoors, playing traditional music on accordions in front of a brick wall. @EZFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/445175c5aae44cfe96a119c72ac6f761.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "49f2ae2629634d3eb77cf345d0e86061", "source": "vatex", "video_id": "kPnCg7l3me8_000002_000012", "video_description": "A girl with long hair is sitting at a wooden kitchen table playing Scrabble with others, laughing and covering her face with her hands while interacting with fellow players.", "task": "ObjectRecognition", "clean_prompt": "A girl with long hair is sitting at a wooden kitchen table playing Scrabble with others, laughing and covering her face with her hands while interacting with fellow players.", "clean_property": {"obj": "table"}, "target_prompt": "A girl with long hair is sitting on a sofa playing Scrabble with others, laughing and covering her face with her hands while interacting with fellow players.", "target_property": {"obj": "sofa"}, "evaluation_question": "Is the girl sitting at a **table**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl with long hair is sitting at a wooden kitchen table playing Scrabble with others, laughing and covering her face with her hands while interacting with fellow players. U%'),", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3782a1ea9695484d9f3bc0fe710d9a7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad7726df110545d4b7674d13877c4d29", "source": "vatex", "video_id": "X9zMOVnZmN0_000048_000058", "video_description": "A group of young women in black and pink costumes are performing a tap dance routine on stage in front of a large audience.", "task": "SpatialUnderstanding", "clean_prompt": "An audience to the right of a dancer performing on stage.", "clean_property": {"obj_1": "audience", "relation": "right of", "obj_2": "dancer"}, "target_prompt": "An audience to the left of a dancer performing on stage.", "target_property": {"obj_1": "audience", "relation": "left of", "obj_2": "dancer"}, "evaluation_question": "Is the audience to the **right** of the dancer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An audience to the right of a dancer performing on stage. UF.7!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c3184b4b1a3046b5b5775f6dd8105ae4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0249554207834fec88f9af5dea3f59e9", "source": "vatex", "video_id": "7oXJdAq9Tio_000045_000055", "video_description": "A woman is outdoors demonstrating and explaining the creation of stone tools by chipping away at rocks using various tools, including a mallet and a piece of wood.", "task": "ObjectRecognition", "clean_prompt": "A woman outdoors demonstrating the creation of stone tools by chipping away at rocks using a mallet and a piece of wood.", "clean_property": {"obj": "tool"}, "target_prompt": "A woman outdoors demonstrating the creation of toy tools by chipping away at colorful plastic.", "target_property": {"obj": "toy"}, "evaluation_question": "Is the woman demonstrating the creation of **stone tools**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman outdoors demonstrating the creation of stone tools by chipping away at rocks using a mallet and a piece of wood. %|?);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14f0d78b0a55432d816c2030e06b4049.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "84b62cdef35a4db29b8a21f319e1441e", "source": "vatex", "video_id": "PBgEIDzO1_4_000371_000381", "video_description": "A group of children are playing a game of kickball in a cul-de-sac on a sunny day.", "task": "Counting", "clean_prompt": "Five children are playing kickball in a cul-de-sac on a sunny day.", "clean_property": {"obj": "ball", "count": "five"}, "target_prompt": "One child is playing with a ball in a park on a cloudy day.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **five** balls being used in the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five children are playing kickball in a cul-de-sac on a sunny day. !0D*E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ae223a30dcb0456486c1fef26b15a9f8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6e81dec3bca45f79aa4691e14a26a65", "source": "vatex", "video_id": "rPKXxFIF8s4_000237_000247", "video_description": "A woman in a lab setting is using a microscope to examine a specimen and then provides instructions.", "task": "SpatialUnderstanding", "clean_prompt": "A microscope farther from the camera than a person in a lab setting.", "clean_property": {"obj_1": "microscope", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A microscope closer to the camera than a person in a lab setting.", "target_property": {"obj_1": "microscope", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the microscope **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microscope farther from the camera than a person in a lab setting. R)?95", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3fadaea7bea64c9c959a0c7189846a7b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bfa417d3e2e4488f80d131f96ac2dd55", "source": "vatex", "video_id": "vH-eCtxSJyg_000008_000018", "video_description": "A man in scuba diving gear is exploring underwater, using a sea scooter to navigate around a shipwreck and holding a flashlight.", "task": "ActionRecognition", "clean_prompt": "A diver scuba diving near a shipwreck.", "clean_property": {"obj": "diver", "action": "scuba diving", "target": null}, "target_prompt": "A diver free diving in a coral reef.", "target_property": {"obj": "diver", "action": "free diving", "target": null}, "evaluation_question": "Is the diver **scuba diving**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A diver scuba diving near a shipwreck. QFSFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/faf9e523d27d40f187dbe134e7dcba38.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a31f0b56c44e4199acca91111423fba2", "source": "vatex", "video_id": "bzawAHbQI68_000459_000469", "video_description": "Two women are sitting on an outdoor swing or bench, working together on a craft project involving weaving a basket using twigs and string. A baby in a stroller is nearby, making noises.", "task": "ActionRecognition", "clean_prompt": "A woman weaving a basket on an outdoor swing.", "clean_property": {"obj": "woman", "action": "weaving basket", "target": null}, "target_prompt": "A woman throwing a basket on an outdoor swing.", "target_property": {"obj": "woman", "action": "throwing a basket", "target": null}, "evaluation_question": "Is the woman **weaving** a basket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman weaving a basket on an outdoor swing. W*O))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a389e4936cdd4832928b447aec24029c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "25a613053f6642bb88df5a7c78076450", "source": "vatex", "video_id": "NZLydTq7Q98_000003_000013", "video_description": "A man in a blue top, wearing a baseball cap and sports equipment, is at an outdoor archery range holding a bow and arrow. He prepares to fire at a target and walks towards the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A bow positioned to the left of a person at an outdoor archery range.", "clean_property": {"obj_1": "bow", "relation": "left of", "obj_2": "person"}, "target_prompt": "A bow positioned to the right of a person at an outdoor archery range.", "target_property": {"obj_1": "bow", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the bow to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bow positioned to the left of a person at an outdoor archery range. ;W%B2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a2e9aa185de4f0cad45f8b30e033ba4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "11fecb1fb248446a8d1532a9386c0276", "source": "vatex", "video_id": "60lmG00V-1g_000022_000032", "video_description": "A woman in a gym is attempting to bend a metal pipe over her leg using a towel for protection.", "task": "ObjectRecognition", "clean_prompt": "A woman in a gym is attempting to bend a metal pipe over her leg using a towel for protection.", "clean_property": {"obj": "woman"}, "target_prompt": "A man in a gym is attempting to bend a metal pipe over his leg using a towel for protection.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a gym is attempting to bend a metal pipe over her leg using a towel for protection. >J@EZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc5f33e5f41049b78651601e7a3abc07.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7abfbeb0a2146ca8c34c147a386bad0", "source": "vatex", "video_id": "RjPp0ZPW0yc_000000_000010", "video_description": "A person is operating a large, orange-colored stationary saw in a workroom to cut a metal pipe.", "task": "ObjectRecognition", "clean_prompt": "A person operating a large, orange-colored stationary saw in a workroom to cut a metal pipe.", "clean_property": {"obj": "person"}, "target_prompt": "A robot operating a large, orange-colored stationary saw in a workroom to cut a metal pipe.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the operator of the saw a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person operating a large, orange-colored stationary saw in a workroom to cut a metal pipe. LY?EV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc8273f476794721b04b9c6078161ab5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "055ff79681bf44cda899706a561df994", "source": "vatex", "video_id": "4eXqdg_U-9A_000001_000011", "video_description": "A young athlete performs a pole vault at an outdoor track and field event, successfully clearing the bar, while spectators cheer.", "task": "ObjectRecognition", "clean_prompt": "A young athlete performs a pole vault at an outdoor track and field event, successfully clearing the bar, while spectators cheer.", "clean_property": {"obj": "athlete"}, "target_prompt": "A young swimmer dives into a pool at an outdoor swimming competition, while spectators cheer.", "target_property": {"obj": "swimmer"}, "evaluation_question": "Is the performer in the video an **athlete**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young athlete performs a pole vault at an outdoor track and field event, successfully clearing the bar, while spectators cheer. 9'SLX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c911641e0ef41088c83dcc504ace206.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "697534b5189a435db4dd9ca0d6a503a1", "source": "vatex", "video_id": "r9vWNjeDh7A_000153_000163", "video_description": "Two women are performing a musical piece in a music hall. One woman is singing while the other plays a stringed instrument, possibly a lute or banjo, while both are seated.", "task": "Counting", "clean_prompt": "Seven singers performing a musical piece in a music hall.", "clean_property": {"obj": "singer", "count": "seven"}, "target_prompt": "Three singers performing a musical piece in a music hall.", "target_property": {"obj": "singer", "count": "three"}, "evaluation_question": "Are there exactly **seven** singers performing in the music hall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven singers performing a musical piece in a music hall. @GMI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/342a729b3d884dbdb2f887430563640e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4fdeb1f78f646b584bb1c8d72affc6b", "source": "vatex", "video_id": "Oiu5EWCVjCw_000001_000011", "video_description": "Children are jumping and playing in an inflatable bounce house located outdoors, in various settings such as a backyard, garden, and park.", "task": "ObjectRecognition", "clean_prompt": "Children are jumping and playing in a bounce house outdoors.", "clean_property": {"obj": "bounce house"}, "target_prompt": "Children are jumping and playing on a trampoline outdoors.", "target_property": {"obj": "trampoline"}, "evaluation_question": "Are the children playing in a **bounce house**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Children are jumping and playing in a bounce house outdoors. ;D#$J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc202bae97204bd396fe436fe05a8d7a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f30c9ff1e38f49728cf784e92fa0fff5", "source": "vatex", "video_id": "9JoGtU00rAU_000000_000010", "video_description": "A young woman in a red tank top is demonstrating front shoulder raises with weights in a gym.", "task": "ObjectRecognition", "clean_prompt": "A young woman in a red tank top is demonstrating front shoulder raises with weights in a gym.", "clean_property": {"obj": "weights"}, "target_prompt": "A young woman in a red tank top is demonstrating front shoulder raises with a medicine ball in a gym.", "target_property": {"obj": "medicine ball"}, "evaluation_question": "Is the woman using **weights** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman in a red tank top is demonstrating front shoulder raises with weights in a gym. @LF\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b1a23efaaee46a0a7ce1302faaf43e4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "97a5a989543a4d7e8db65cc7c453bd09", "source": "vatex", "video_id": "wb875GGCiQc_000013_000023", "video_description": "A cricket game is taking place on a field where players are competing, and a batsman is dismissed by a fielder. The game ends in a tie with exciting plays.", "task": "ActionRecognition", "clean_prompt": "A cricket player playing cricket on a field.", "clean_property": {"obj": "cricket player", "action": "playing cricket", "target": null}, "target_prompt": "A cricket player watching cricket on a field.", "target_property": {"obj": "cricket player", "action": "watching cricket", "target": null}, "evaluation_question": "Is the cricket player **playing** cricket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cricket player playing cricket on a field. >RPEM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56d849c4e6e142a6b6b936360cc9618c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "68fb4607371f4618b27ffb0baa58f327", "source": "vatex", "video_id": "YEiHsVDxh3A_000029_000039", "video_description": "A person is drawing leaves and feathers on a piece of paper using a black pen or marker, with music playing in the background.", "task": "AttributeRecognition", "clean_prompt": "A person artist is drawing leaves and feathers on a piece of paper using a black pen, with music playing in the background.", "clean_property": {"obj": "person", "attribute": "artist"}, "target_prompt": "A person musician is playing a guitar in a park with music playing in the background.", "target_property": {"obj": "person", "attribute": "musician"}, "evaluation_question": "Is the person an **artist** drawing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person artist is drawing leaves and feathers on a piece of paper using a black pen, with music playing in the background. 2BC$@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a571f847d66c411a97abc7ea4297ceab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afb9ce84412a41e49445a0e21db97d8f", "source": "vatex", "video_id": "rseoEvLeT4A_000039_000049", "video_description": "A woman and her daughter are sitting on a bench in a busy city street, feeding pigeons.", "task": "Counting", "clean_prompt": "Three women sitting on a bench in a busy city street, feeding pigeons.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "A woman sitting alone on a bench in a busy city street, feeding pigeons.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women sitting on the bench?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women sitting on a bench in a busy city street, feeding pigeons. $BSG>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3030af32b08b4e14ace58df140475baa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2bf33a9f8e04b7da5b26213dd7832e2", "source": "vatex", "video_id": "0fwkAvo6wGI_000007_000017", "video_description": "A man is in a gym demonstrating and performing ab mat sit ups using a foam wedge or sit up pad under his back.", "task": "ActionRecognition", "clean_prompt": "A person performing sit-ups in a gym.", "clean_property": {"obj": "person", "action": "situp", "target": null}, "target_prompt": "A person doing push-ups in a gym.", "target_property": {"obj": "person", "action": "doing push-ups", "target": null}, "evaluation_question": "Is the person **performing sit-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing sit-ups in a gym. ))!D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aaed6e004b0c4e0cbbdf66f81e00f004.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "74e3a3ff009649a096c3dd0adebc36df", "source": "vatex", "video_id": "dSioS70MCs4_000001_000011", "video_description": "A young boy is sitting at a table, trying to blow out a trick candle on his birthday cake, while a man encourages him and laughs.", "task": "ObjectRecognition", "clean_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake.", "clean_property": {"obj": "man"}, "target_prompt": "A woman encouraging a young girl to blow out a trick candle on a birthday cake.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person encouraging the child a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man encouraging a young boy to blow out a trick candle on a birthday cake. !G*QB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eed024bd1a384cf28d589b3239b38a6c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4040c5d718b4d4da5614ce6c2905384", "source": "vatex", "video_id": "aJTF-3Gno6g_000006_000016", "video_description": "A woman is performing a slow sit-up exercise on the ground, repeatedly lying back and sitting up to touch her toes.", "task": "ActionRecognition", "clean_prompt": "A person performing a slow sit-up exercise on the ground.", "clean_property": {"obj": "person", "action": "situp", "target": null}, "target_prompt": "A person jumping in a gym.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **performing a sit-up**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing a slow sit-up exercise on the ground. !0*);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/19df9a219c03412f8e6b97bebf1a9d33.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f3df1f865c3a4a45bd0c01643b0e95f1", "source": "vatex", "video_id": "srH-dsRpg4k_000063_000073", "video_description": "Two women are in a science lab using a microscope and discussing its use. They encounter a problem and ask a lab assistant for help.", "task": "SpatialUnderstanding", "clean_prompt": "A lab assistant closer to the camera than a microscope.", "clean_property": {"obj_1": "lab assistant", "relation": "closer to the camera than", "obj_2": "microscope"}, "target_prompt": "A lab assistant further from the camera than a microscope.", "target_property": {"obj_1": "lab assistant", "relation": "further from the camera than", "obj_2": "microscope"}, "evaluation_question": "Is the lab assistant **closer to the camera than** the microscope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A lab assistant closer to the camera than a microscope. RTQ4P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67aa1b51dd8f40a2ac4bc1f4afcdc5fe.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99746622d2744d149acd0f21630d1ce4", "source": "vatex", "video_id": "ocVnAfqG8os_000007_000017", "video_description": "A man is holding a bottle of beer, speaking animatedly, and removes the cap with his elbow.", "task": "Counting", "clean_prompt": "Three people are gathered around, with one man holding a bottle of beer and speaking animatedly while removing the cap with his elbow.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is sitting alone at a table, quietly sipping a drink.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people present in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are gathered around, with one man holding a bottle of beer and speaking animatedly while removing the cap with his elbow. MF9V!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33d8c16097ec489db2a670090f9f8d35.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d49a0ca5d2bc466ebebba6ca655100b7", "source": "vatex", "video_id": "5cxhZUkNzeU_000000_000010", "video_description": "Two trapeze artists, a man and a woman, are practicing acrobatic maneuvers on a high trapeze structure with a net underneath. A coach is present, encouraging them.", "task": "ObjectRecognition", "clean_prompt": "Two trapeze artists practicing acrobatic maneuvers on a high trapeze structure with a net underneath.", "clean_property": {"obj": "net"}, "target_prompt": "Two trapeze artists practicing acrobatic maneuvers on a high trapeze structure with a trampoline underneath.", "target_property": {"obj": "trampoline"}, "evaluation_question": "Is there a **net** underneath the trapeze structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two trapeze artists practicing acrobatic maneuvers on a high trapeze structure with a net underneath. M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/854e65ce4b18453a9f8812654d635a10.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "27ff1006ca844037bb636da4d8509c19", "source": "vatex", "video_id": "0HEi6q3bGaw_000011_000021", "video_description": "A group of people on snowmobiles are talking to each other on a snow-covered terrain before riding off.", "task": "ObjectRecognition", "clean_prompt": "A group of people on snowmobiles talking to each other on a snow-covered terrain.", "clean_property": {"obj": "person"}, "target_prompt": "A group of animals on snowmobiles talking to each other on a snow-covered terrain.", "target_property": {"obj": "animal"}, "evaluation_question": "Are the individuals in the video **people**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people on snowmobiles talking to each other on a snow-covered terrain. @XFOM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d3a5df7b3e74dec8fb1b1a6db499ff1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca5fe666e80e432f9c9f1603dd7840fd", "source": "vatex", "video_id": "0TtUPcnpN2g_000018_000028", "video_description": "Two teenage boys are practicing mixed martial arts and boxing outside in a backyard, wearing boxing gloves.", "task": "AttributeRecognition", "clean_prompt": "Two teenage boys practicing mixed martial arts and boxing outside in a backyard, wearing boxing gloves.", "clean_property": {"obj": "teenage boy", "attribute": "teenage"}, "target_prompt": "Two teenage boys wearing karate gis practicing martial arts outside in a backyard.", "target_property": {"obj": "teenage boy", "attribute": "wearing a karate gi"}, "evaluation_question": "Are the boys wearing **boxing gloves**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teenage boys practicing mixed martial arts and boxing outside in a backyard, wearing boxing gloves. )!G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/610aef5419ec4612a5bd8c46dae03a66.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aebd861396824d5c926ff5e57d90ed64", "source": "vatex", "video_id": "axUFmA1cpws_000000_000010", "video_description": "A young man is practicing throwing a frisbee in a wooded area, preparing and making throwing motions.", "task": "Counting", "clean_prompt": "Four people practicing throwing a frisbee in a wooded area.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person practicing throwing a frisbee in a wooded area.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people practicing throwing a frisbee in the wooded area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people practicing throwing a frisbee in a wooded area. )!D&2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6bc4a813d397455cb36e6f56b3424b43.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b97d20c351274cbeaf7cf8a2d61b4ec1", "source": "vatex", "video_id": "Whfyh4v6Mkw_000001_000011", "video_description": "A group of people, including a woman and a child, are playing a game of Monopoly. They are handling cards and money, discussing the rules, and making transactions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a Monopoly board.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "Monopoly board"}, "target_prompt": "A person further from the camera than a Monopoly board.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "Monopoly board"}, "evaluation_question": "Is the person **closer to the camera than** the Monopoly board?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a Monopoly board. @TVH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/06145e5b595f410d922aa0dcd37bf700.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6ded1e7bda464c7b97f038957bd80296", "source": "vatex", "video_id": "52czNOVXfGY_000000_000010", "video_description": "A man is using a wood lathe machine to spin and carve a piece of wood into a cylindrical shape using a chiseling tool.", "task": "Counting", "clean_prompt": "Two people working together at a wood lathe machine to carve a piece of wood into a cylindrical shape using chiseling tools.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person working alone at a wood lathe machine to carve a piece of wood into a cylindrical shape using a chiseling tool.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people working at the wood lathe machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people working together at a wood lathe machine to carve a piece of wood into a cylindrical shape using chiseling tools. FE)GY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8a7854d30d847f5964618d6bb2e6686.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2628f9c0e790421cbb3fd491e913caa3", "source": "vatex", "video_id": "JclZ74kvXEI_000000_000010", "video_description": "A man is testing and preparing to use a heavy sledgehammer inside a garage.", "task": "ObjectRecognition", "clean_prompt": "A man is testing and preparing to use a heavy sledgehammer inside a garage.", "clean_property": {"obj": "person"}, "target_prompt": "A woman is testing and preparing to use a light hammer inside a workshop.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is testing and preparing to use a heavy sledgehammer inside a garage. =X=BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/547b1ae3307d4f578d631d7e23c23383.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3ca63268cc494a92b8edd4e670ae9c2b", "source": "vatex", "video_id": "XmP8CYWwSPk_000224_000234", "video_description": "A man is demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions. !W*9|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20ebcabf61824649b50473cc4ce4fc00.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e3819bfefcb3467c8a686e9171b9be19", "source": "vatex", "video_id": "wXmNSFXaAyY_000749_000759", "video_description": "A middle-aged couple and an older man sit around a rustic kitchen table. A woman waves at a camera while two men are talking.", "task": "Counting", "clean_prompt": "Four women sitting around a rustic kitchen table, one waving at the camera while two men are talking.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman sitting alone at a rustic kitchen table, waving at the camera.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women sitting around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four women sitting around a rustic kitchen table, one waving at the camera while two men are talking. U%AQ&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6a24a4ce17e49a396275463a38aebbd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0e2f3c45af604192862d890a3028c2a8", "source": "vatex", "video_id": "LbWxLu41_Fk_000085_000095", "video_description": "A woman with her eyes closed is brushing her hair with a soft bristle brush in her room.", "task": "ActionRecognition", "clean_prompt": "A person brushing their hair in a room.", "clean_property": {"obj": "person", "action": "brushing hair", "target": null}, "target_prompt": "A person cutting hair in a room.", "target_property": {"obj": "person", "action": "cutting hair", "target": null}, "evaluation_question": "Is the person **brushing** their hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person brushing their hair in a room. C|.&A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8c5f6e715414170a4ae27742346f6d5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e614a3e75e96490d86c902e059ffceb5", "source": "vatex", "video_id": "-ORYjC-0F8I_000000_000010", "video_description": "A group of people are playing badminton in a gymnasium with multiple matches happening simultaneously.", "task": "ObjectRecognition", "clean_prompt": "A group of people are playing badminton in a gymnasium, with a shuttlecock flying back and forth.", "clean_property": {"obj": "shuttlecock"}, "target_prompt": "A group of people are playing frisbee in a gymnasium, with a frisbee flying back and forth.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Is the object being used in the game a **shuttlecock**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people are playing badminton in a gymnasium, with a shuttlecock flying back and forth. FE/HC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24e90459fb7543a184103f1fa1fedc27.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "00ddffeb775a4e2b93e51672ff896676", "source": "vatex", "video_id": "3xI6BK_hKXs_000004_000014", "video_description": "A man is demonstrating and explaining how to perform arm stretching exercises in a room with a painting of a blossom tree.", "task": "ActionRecognition", "clean_prompt": "A person stretching their arm in a room with a painting of a blossom tree.", "clean_property": {"obj": "person", "action": "stretching arm", "target": null}, "target_prompt": "A person lifting their arm in a room with a painting of a blossom tree.", "target_property": {"obj": "person", "action": "lifting arm", "target": null}, "evaluation_question": "Is the person **stretching their arm**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stretching their arm in a room with a painting of a blossom tree. LF;3G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9b0a34cb7189454a8133c625eca38a89.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "77660aefd42340949a9324cf347cde50", "source": "vatex", "video_id": "vgsveBkXVss_000291_000301", "video_description": "A man is demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant.", "task": "ActionRecognition", "clean_prompt": "A person repairing a hole in a bicycle tire tube using glue and a sealant.", "clean_property": {"obj": "person", "action": "repairing puncture", "target": "tire tube"}, "target_prompt": "A person removing a tire from a bicycle.", "target_property": {"obj": "person", "action": "removing tire", "target": "bicycle"}, "evaluation_question": "Is the person **repairing a hole in a bicycle tire tube**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person repairing a hole in a bicycle tire tube using glue and a sealant. &''?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40564f025c3c4eb9a38304fdd2a28ce2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eacfe218613846ba85b79079d9c17821", "source": "vatex", "video_id": "yjtBhdBVtNM_000020_000030", "video_description": "A person base jumps from a cliff in a desert mountain setting, deploying a pink and purple parachute as they fall.", "task": "AttributeRecognition", "clean_prompt": "A person base jumping from a cliff in a desert mountain setting, deploying a pink and purple parachute.", "clean_property": {"obj": "parachute", "attribute": "pink and purple"}, "target_prompt": "A person base jumping from a cliff in a desert mountain setting, deploying a green and yellow parachute.", "target_property": {"obj": "parachute", "attribute": "green and yellow"}, "evaluation_question": "Is the parachute **pink and purple**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person base jumping from a cliff in a desert mountain setting, deploying a pink and purple parachute. !0DZB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9e12ee35724f48ca96b0d71fd26dd635.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d68f86b55cf642e1a3fdd33d110c73b9", "source": "vatex", "video_id": "jQjNdmkqHpg_000085_000095", "video_description": "A woman is demonstrating how to sew using a sewing machine, including preparing and cutting fabric.", "task": "ActionRecognition", "clean_prompt": "A person sewing fabric using a sewing machine.", "clean_property": {"obj": "person", "action": "sewing", "target": "fabric"}, "target_prompt": "A person cutting fabric on a table.", "target_property": {"obj": "person", "action": "cutting fabric", "target": "fabric"}, "evaluation_question": "Is the person **sewing** fabric?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sewing fabric using a sewing machine. DPV+V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c4df6c1b03014747831cb829ff5d20aa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c73a28f4148342ad905062016a99d407", "source": "vatex", "video_id": "1zXXjwcOXTs_000202_000212", "video_description": "A young boy demonstrates his double-jointed abilities by twisting and bending his arms in various directions while a man comments on his flexibility.", "task": "ActionRecognition", "clean_prompt": "A boy contorting his arms in various directions while a man comments on his flexibility.", "clean_property": {"obj": "boy", "action": "contorting", "target": null}, "target_prompt": "A boy jumping in various directions while a man comments on his energy.", "target_property": {"obj": "boy", "action": "jumping", "target": null}, "evaluation_question": "Is the boy **contorting** his arms?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy contorting his arms in various directions while a man comments on his flexibility. )!G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/81fb230da7464126803156719298aff5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7906113b4b074c29ad372c42842722ac", "source": "vatex", "video_id": "d7eFxeeCCiY_000000_000010", "video_description": "A man is eating a small white powdered donut in a house, occasionally looking at the camera.", "task": "Counting", "clean_prompt": "Three people sitting at a table, one of them is eating a small white powdered donut and occasionally looking at the camera.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting at a table, eating a small white powdered donut and occasionally looking at the camera.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people sitting at a table, one of them is eating a small white powdered donut and occasionally looking at the camera. !PFEA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ccb8f202287a4e16b1d2b58b5d703333.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6413d3b121b4b15883e2f5a69a571c9", "source": "vatex", "video_id": "yAMSkBo9nrM_000000_000010", "video_description": "A woman is holding a baby who is cooing, laughing, and smiling. The woman also laughs along with the baby.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the left of a baby who is cooing and laughing.", "clean_property": {"obj_1": "woman", "relation": "left of", "obj_2": "baby"}, "target_prompt": "A woman standing to the right of a baby who is cooing and laughing.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "baby"}, "evaluation_question": "Is the woman to the **left** of the baby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the left of a baby who is cooing and laughing. .BS)P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb908b9298d14cf383322ab06992cb2b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "054a0de764794c7388864d2d4b1e709a", "source": "vatex", "video_id": "s6neX_K5Pus_000015_000025", "video_description": "A man is performing various exercises with weights indoors, including push-ups and weighted rows on a blue mat.", "task": "SpatialUnderstanding", "clean_prompt": "Weights positioned to the left of a person performing exercises indoors.", "clean_property": {"obj_1": "weights", "relation": "left of", "obj_2": "person"}, "target_prompt": "Weights positioned to the right of a person performing exercises indoors.", "target_property": {"obj_1": "weights", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Are the weights to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Weights positioned to the left of a person performing exercises indoors. FE:\u00b7R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e9a039c0a34a4e5cb3a8a3204f74e454.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d601e94c34bf477a8c8876b91cc32f6e", "source": "vatex", "video_id": "kHFf8SKW7f4_000001_000011", "video_description": "An ice sculptor demonstrates his skills using a power tool to an audience indoors, possibly in a classroom or kitchen setting.", "task": "SpatialUnderstanding", "clean_prompt": "A power tool positioned to the left of an ice sculptor demonstrating his skills indoors.", "clean_property": {"obj_1": "power tool", "relation": "left of", "obj_2": "ice sculptor"}, "target_prompt": "A power tool positioned to the right of an ice sculptor demonstrating his skills indoors.", "target_property": {"obj_1": "power tool", "relation": "right of", "obj_2": "ice sculptor"}, "evaluation_question": "Is the power tool to the **left** of the ice sculptor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A power tool positioned to the left of an ice sculptor demonstrating his skills indoors. QCKZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aca38aa1b1154e42b5c5cbfcc6fa5cea.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6678233fb73a4171bf8ce43f97de6a26", "source": "vatex", "video_id": "gEmPrgTHGhU_000030_000040", "video_description": "A female weather reporter in a black dress and glasses is standing in front of a large, changing weather map, explaining the expected weather in Europe for the upcoming week.", "task": "Counting", "clean_prompt": "Two weather reporters in black dresses and glasses are standing in front of a large, changing weather map, explaining the expected weather in Europe for the upcoming week.", "clean_property": {"obj": "weather reporter", "count": "two"}, "target_prompt": "One weather reporter in a colorful outfit is standing in front of a large, changing weather map, explaining the expected weather in Asia for the upcoming week.", "target_property": {"obj": "weather reporter", "count": "one"}, "evaluation_question": "Are there exactly **two** weather reporters in front of the weather map?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two weather reporters in black dresses and glasses are standing in front of a large, changing weather map, explaining the expected weather in Europe for the upcoming week. =)DJU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfa6bdc60f454e0da4031980c14aaa76.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "04d9c808852a4d048049ae96b4f064a6", "source": "vatex", "video_id": "EnU69wUlwqk_000002_000012", "video_description": "A man in an office is using a photocopier to print large black circles on paper.", "task": "AttributeRecognition", "clean_prompt": "A man in an office using a photocopier to print large black circles on paper.", "clean_property": {"obj": "paper", "attribute": "with black circle"}, "target_prompt": "A man in an office using a photocopier to print large red squares on paper.", "target_property": {"obj": "paper", "attribute": "with red square"}, "evaluation_question": "Is the paper printed with **black circles**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in an office using a photocopier to print large black circles on paper. QXYMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9932f3fbf83c46ec978a9f2634d6dc61.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7e963a4a1044ffcb742d6589956eb85", "source": "vatex", "video_id": "N6-jotmJdsU_000021_000031", "video_description": "A group of swimmers, primarily women, are swimming laps in an Olympic-sized indoor pool, focusing on one woman in the first lane doing the front crawl.", "task": "ActionRecognition", "clean_prompt": "A swimmer swimming front crawl in an Olympic-sized indoor pool.", "clean_property": {"obj": "swimmer", "action": "swimming front crawl", "target": null}, "target_prompt": "A swimmer swimming backstroke in an Olympic-sized indoor pool.", "target_property": {"obj": "swimmer", "action": "swimming backstroke", "target": null}, "evaluation_question": "Is the swimmer **swimming front crawl**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A swimmer swimming front crawl in an Olympic-sized indoor pool. RR;(4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d3ff2fb81804f4fb8553e49af14e3f7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "172836c2aa674293ab13b9d244e0ec7d", "source": "vatex", "video_id": "8YJ9Pxj6BCc_000021_000031", "video_description": "A child rides a bike and a scooter down a hill, crashes at the bottom, while another child laughs.", "task": "Counting", "clean_prompt": "Two children riding a bike and a scooter down a hill, crashing at the bottom, while another child laughs.", "clean_property": {"obj": "child_3", "count": "two"}, "target_prompt": "One child riding a unicycle down a hill, crashing at the bottom, while another child laughs.", "target_property": {"obj": "child_3", "count": "one"}, "evaluation_question": "Are there exactly **two** children riding down the hill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children riding a bike and a scooter down a hill, crashing at the bottom, while another child laughs. OPBS\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/30d8bf0b6e344ef1900ad42a8e2fb47c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8bf7b15f853440cbbe4f83740786e1bd", "source": "vatex", "video_id": "jZqFMbAekqk_000002_000012", "video_description": "A preteen girl in a pink top is practicing archery in a backyard, shooting arrows at a target while a man assists her and a cat watches.", "task": "ObjectRecognition", "clean_prompt": "A preteen girl in a pink top is practicing archery in a backyard, shooting arrows at a target while a man assists her and a cat watches.", "clean_property": {"obj": "bow and arrow"}, "target_prompt": "A preteen girl in a pink top is practicing with a crossbow in a backyard, shooting bolts at a target while a man assists her and a cat watches.", "target_property": {"obj": "crossbow"}, "evaluation_question": "Is the girl practicing with a **bow and arrow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A preteen girl in a pink top is practicing archery in a backyard, shooting arrows at a target while a man assists her and a cat watches. MTF91", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bec257c233024a8e8f1082012d5ba4a5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "65846656aabe4d16a20c5fb8c6375f85", "source": "vatex", "video_id": "jfwiXsEWdjw_000083_000093", "video_description": "A man is in a bedroom demonstrating how to perform the moonwalk dance step.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a bed in a bedroom, demonstrating the moonwalk dance step.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "bed"}, "target_prompt": "A person standing to the right of a bed in a bedroom, demonstrating the moonwalk dance step.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "bed"}, "evaluation_question": "Is the person to the **left** of the bed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a bed in a bedroom, demonstrating the moonwalk dance step. SL#@M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a0c0c0eb56004dd2a02a5b6fb4b74803.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57f764f89c334833bbfad7bd97256494", "source": "vatex", "video_id": "_K9dxLwuR1w_000002_000012", "video_description": "A group of people are in a room where a person is unwrapping a paint roller and dipping it into a white bucket containing liquid nitrogen, with steam coming off the bucket. Others are watching and asking questions.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a paint roller in a room.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "paint roller"}, "target_prompt": "A person closer to the camera than a paint roller in a room.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "paint roller"}, "evaluation_question": "Is the person **farther from the camera than** the paint roller?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a paint roller in a room. B&FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2f8a0d43dab43f198ff3b1bf72f9767.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7b85735b67c14e69894e76ecb22cfeab", "source": "vatex", "video_id": "x9FExBs3FiM_000043_000053", "video_description": "A high jump competition featuring several girls participating in the event, with a man narrating the highlights.", "task": "SpatialUnderstanding", "clean_prompt": "A girl farther from the camera than a bar in a high jump competition.", "clean_property": {"obj_1": "girl", "relation": "farther from the camera than", "obj_2": "bar"}, "target_prompt": "A girl closer to the camera than a bar in a high jump competition.", "target_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "bar"}, "evaluation_question": "Is the girl **farther from the camera than** the bar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl farther from the camera than a bar in a high jump competition. FS-)G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73a0a3caf79c4aeb845e1add5a0c7bfa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0f7f61e6cb224dcaa19ec764bbe219c3", "source": "vatex", "video_id": "rEMOAQGni-M_000005_000015", "video_description": "An elderly woman is attempting to skip rope in a gym while a man narrates and instructs her.", "task": "ObjectRecognition", "clean_prompt": "An elderly woman is attempting to skip rope in a gym while a man narrates and instructs her.", "clean_property": {"obj": "woman"}, "target_prompt": "A young girl is attempting to skip rope in a gym while a man narrates and instructs her.", "target_property": {"obj": "young girl"}, "evaluation_question": "Is the person attempting to skip rope in the video an **elderly woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An elderly woman is attempting to skip rope in a gym while a man narrates and instructs her. )/U0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/db8ed6723da647f988dec01b6f0ebf0f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "72f1bef0bcf241b9a6f3eaa60a1b1c35", "source": "vatex", "video_id": "cbqnHGC43uY_000114_000124", "video_description": "A young man is outdoors in front of a building, demonstrating exercises using two heavy ropes.", "task": "AttributeRecognition", "clean_prompt": "A young man outdoors in front of a building demonstrating exercises using two heavy ropes.", "clean_property": {"obj": "rope", "attribute": "heavy"}, "target_prompt": "A young man outdoors in front of a building demonstrating exercises using two light ropes.", "target_property": {"obj": "rope", "attribute": "light"}, "evaluation_question": "Are the ropes being used by the young man **heavy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man outdoors in front of a building demonstrating exercises using two heavy ropes. >B!OH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a9804b97fe24902817a584c296a4b88.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5398990a76e44dd7b8f732b7a1f7e4e8", "source": "vatex", "video_id": "Y8iM5-EwRUI_000034_000044", "video_description": "A young blonde girl is bouncing and talking inside a bouncy castle outdoors, occasionally filming herself.", "task": "Counting", "clean_prompt": "Three girls bouncing and talking inside a bouncy castle outdoors.", "clean_property": {"obj": "girl", "count": "three"}, "target_prompt": "One girl bouncing and talking inside a bouncy castle outdoors.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **three** girls bouncing in the bouncy castle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls bouncing and talking inside a bouncy castle outdoors. !/!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d380df0a817f435088f53b6d4b608d5b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "94f84575c35d49fc8823cfba435fdec9", "source": "vatex", "video_id": "x6T2Wejr8W8_000024_000034", "video_description": "A woman is playing a saxophone while another woman dances in a kitchen.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of another woman in a kitchen, playing a saxophone while the other dances.", "clean_property": {"obj_1": "woman_2", "relation": "right of", "obj_2": "woman_1"}, "target_prompt": "A woman standing to the left of another woman in a kitchen, playing a saxophone while the other dances.", "target_property": {"obj_1": "woman_2", "relation": "left of", "obj_2": "woman_1"}, "evaluation_question": "Is the woman playing the saxophone to the **right** of the dancing woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the right of another woman in a kitchen, playing a saxophone while the other dances. FEY+V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/66cf5117b1624033b7a1df33ac7c890c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ba5af36c824544c5b6acc3e32a1b5791", "source": "vatex", "video_id": "7Eoaj1HBv28_000418_000428", "video_description": "A woman is demonstrating how to apply makeup, focusing on her eyebrows and eyelashes, while explaining the process.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to apply makeup, focusing on her eyebrows and eyelashes.", "clean_property": {"obj": "makeup product"}, "target_prompt": "A woman demonstrating how to apply a skincare product, focusing on her face and explaining the process.", "target_property": {"obj": "skincare product"}, "evaluation_question": "Is the product being demonstrated a **makeup product**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to apply makeup, focusing on her eyebrows and eyelashes. ED-JE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/75f683261ecc4da38ef0fb263f59bc4a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "af4553e14272455c807f004f001ce2c5", "source": "vatex", "video_id": "PerALwJ7XT4_000132_000142", "video_description": "A person demonstrates how to use a hole punching machine to punch holes in paper and bind them together.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to use a multi hole punching machine to punch holes in paper and bind them together.", "clean_property": {"obj": "hole punching machine", "attribute": "multi hole"}, "target_prompt": "A person demonstrating how to use a single hole punching machine to punch holes in paper and bind them together.", "target_property": {"obj": "hole punching machine", "attribute": "single hole"}, "evaluation_question": "Is the hole punching machine a **multi hole** type?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to use a multi hole punching machine to punch holes in paper and bind them together. )!0S1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/93f82ed39f9a4cd3b27bbe9d4a3cfc8c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2cffbaa89e114c638b0e266103d9fbde", "source": "vatex", "video_id": "C63df4k1nPo_000004_000014", "video_description": "A man is sitting on the ground outside, using a magnifying glass to focus sunlight and burn a design into a wood panel.", "task": "Counting", "clean_prompt": "A man is sitting on the ground outside, using a magnifying glass to focus sunlight and burn a design into seven wood panels.", "clean_property": {"obj": "wood panel", "count": "seven"}, "target_prompt": "A man is sitting on the ground outside, using a magnifying glass to focus sunlight and burn a design into three wood panels.", "target_property": {"obj": "wood panel", "count": "three"}, "evaluation_question": "Are there exactly **seven** wood panels being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting on the ground outside, using a magnifying glass to focus sunlight and burn a design into seven wood panels. &UFJU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec59dd2f251f4336a53f6a5f16026dc0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f3aaa6a834c14aa58a67ce1548487e96", "source": "vatex", "video_id": "b-qLVLEjMcA_000011_000021", "video_description": "A group of young people, dressed in heavy winter clothing, are building a snowman in a snowy forest or park setting.", "task": "Counting", "clean_prompt": "Three young people are building a snowman in a snowy forest.", "clean_property": {"obj": "snowman", "count": "three"}, "target_prompt": "One young person is building a snowman in a snowy park.", "target_property": {"obj": "snowman", "count": "one"}, "evaluation_question": "Are there exactly **three** snowmen being built?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three young people are building a snowman in a snowy forest. 4X%BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6d570314125840b1af08bb03fb26bda5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "757ebd565f2b42229244fc981e27d523", "source": "vatex", "video_id": "sH2LklWMKo4_000198_000208", "video_description": "A woman is demonstrating how to make and repair earrings using tools like pliers and wire cutters, attaching hooks and bending metal.", "task": "Counting", "clean_prompt": "A woman is using two tools to make and repair earrings.", "clean_property": {"obj": "tool", "count": "two"}, "target_prompt": "A woman is using four tools to make and repair earrings.", "target_property": {"obj": "tool", "count": "four"}, "evaluation_question": "Are there exactly **two** tools being used to make and repair earrings?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using two tools to make and repair earrings. ?%.R@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac5c94ee517d427e9c972bf5e5e52473.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "98b0365c03024f2aa6037e164352fc9a", "source": "vatex", "video_id": "3O4oABm4Jrs_000195_000205", "video_description": "A person is taking freshly baked cookies out of the oven and stacking them next to a jar of Nutella, with parchment paper in between.", "task": "AttributeRecognition", "clean_prompt": "A person is taking freshly baked cookies out of an open oven and stacking them next to a jar of Nutella, with parchment paper in between.", "clean_property": {"obj": "oven", "attribute": "open"}, "target_prompt": "A person is taking freshly baked cookies out of a closed oven and stacking them next to a jar of Nutella, with parchment paper in between.", "target_property": {"obj": "oven", "attribute": "closed"}, "evaluation_question": "Is the oven **open**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is taking freshly baked cookies out of an open oven and stacking them next to a jar of Nutella, with parchment paper in between. -FOE$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb73d96b796e4cdbaa9dfad57006580c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a92a3ca2cc6d4d2090f5bec71a4a5c7e", "source": "vatex", "video_id": "xgIaB0VojPI_000036_000046", "video_description": "A tour group is riding camels in a long line through a dusty desert, with a woman talking.", "task": "ObjectRecognition", "clean_prompt": "A tour group is riding camels in a long line through a dusty desert, with a woman talking.", "clean_property": {"obj": "camel"}, "target_prompt": "A tour group is riding horses in a long line through a dusty desert, with a woman talking.", "target_property": {"obj": "horse"}, "evaluation_question": "Is the tour group riding **camels**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tour group is riding camels in a long line through a dusty desert, with a woman talking. U9HT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4d97cb22a5174e16a34c7be773949f4f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a616b74f67a343feb80e55a925e0c925", "source": "vatex", "video_id": "aM4WyvYFP1k_000795_000805", "video_description": "A man is sitting on the floor in front of a brick fireplace, surrounded by multiple power tools, including drills, and discussing tool maintenance.", "task": "SpatialUnderstanding", "clean_prompt": "A drill positioned to the left of a brick fireplace.", "clean_property": {"obj_1": "drill", "relation": "left of", "obj_2": "fireplace"}, "target_prompt": "A drill positioned to the right of a brick fireplace.", "target_property": {"obj_1": "drill", "relation": "right of", "obj_2": "fireplace"}, "evaluation_question": "Is the drill to the **left** of the fireplace?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A drill positioned to the left of a brick fireplace. &UFYI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3993449c3a1740b8ba10992b97d9dd54.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aca10aab1f86476b93a9f4fb7c013a9c", "source": "vatex", "video_id": "pzmHPAP11qs_000037_000047", "video_description": "A person is spray painting graffiti on a street wall using silver, black, and white paint.", "task": "ActionRecognition", "clean_prompt": "A person spray painting graffiti on a street wall using silver, black, and white paint.", "clean_property": {"obj": "person", "action": "spray painting", "target": "wall"}, "target_prompt": "A person spray painting on a canvas using vibrant colors.", "target_property": {"obj": "person", "action": "spray painting", "target": "canvas"}, "evaluation_question": "Is the person **spray painting** on a **wall**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person spray painting graffiti on a street wall using silver, black, and white paint. |FE(M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2acebe647c1c482bbcde07c68b01bd53.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c8c14ea2e3fd45a992852a17c58a98e8", "source": "vatex", "video_id": "m73EdlvDuiw_000045_000055", "video_description": "A man is demonstrating and explaining how to tie a complex knot using ropes at a table.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to tie a complex knot using a rope at a table.", "clean_property": {"obj": "rope"}, "target_prompt": "A man demonstrating how to tie a complex knot using a chain at a table.", "target_property": {"obj": "chain"}, "evaluation_question": "Is the object being used to tie the knot a **rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to tie a complex knot using a rope at a table. #(@HY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fb4daa6aca64f3893a6e6aba2122621.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a45cfe05ffba464a8392976b9dc83a7c", "source": "vatex", "video_id": "IBay_SsO2_M_000113_000123", "video_description": "A man in a suit presents an award to another man on stage in front of an applauding audience. The recipient steps up to the podium to deliver a speech.", "task": "AttributeRecognition", "clean_prompt": "A presenter wearing a suit presents an award to another man on stage in front of an applauding audience.", "clean_property": {"obj": "presenter", "attribute": "wearing a suit"}, "target_prompt": "A presenter wearing casual clothes presents an award to another man on stage in front of an applauding audience.", "target_property": {"obj": "presenter", "attribute": "wearing casual clothes"}, "evaluation_question": "Is the presenter wearing a **suit**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A presenter wearing a suit presents an award to another man on stage in front of an applauding audience. 9%QS0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0256c6f9c2014e9d88146b9fb9f07d6a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "548365f9381c4e5cb549bb884e22dc54", "source": "vatex", "video_id": "QB2Fbbw4TmM_000262_000272", "video_description": "A young woman demonstrates and explains how to properly brush and groom a horse in a barn.", "task": "ActionRecognition", "clean_prompt": "A person grooming a horse in a barn.", "clean_property": {"obj": "person", "action": "grooming horse", "target": "horse"}, "target_prompt": "A person riding a horse in a barn.", "target_property": {"obj": "person", "action": "riding horse", "target": "horse"}, "evaluation_question": "Is the person **grooming** the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person grooming a horse in a barn. ;BV,(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f03dea814484679a15b806d74fdde88.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a916f87447014644add4bf7637c4ce17", "source": "vatex", "video_id": "mvCzUIx7li0_000020_000030", "video_description": "A person is using a sewing machine on a table to sew stacks of paper together.", "task": "ObjectRecognition", "clean_prompt": "A person is using a sewing machine on a table to sew stacks of paper together.", "clean_property": {"obj": "sewing machine"}, "target_prompt": "A person is using a printer on a table to print stacks of paper together.", "target_property": {"obj": "printer"}, "evaluation_question": "Is the object being used in the video a **sewing machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is using a sewing machine on a table to sew stacks of paper together. -SL,E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6813397ab1224681ae481b06ff88fea6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c0b85a40d694878a92618e08ff4c6fd", "source": "vatex", "video_id": "PCMOHhyNAZw_000020_000030", "video_description": "A young boy is sitting next to a replica cow, pretending to milk it into a bucket, while a man speaks to him in Spanish.", "task": "ActionRecognition", "clean_prompt": "A boy milking a cow into a bucket.", "clean_property": {"obj": "boy", "action": "milking cow", "target": null}, "target_prompt": "A boy riding a cow.", "target_property": {"obj": "boy", "action": "riding cow", "target": null}, "evaluation_question": "Is the boy **milking** the cow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy milking a cow into a bucket. )0*)!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b30e78e9190465da71733e90383861a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cc3252fe9884248b6eb93677f386324", "source": "vatex", "video_id": "6IV0gaQy1UE_000000_000010", "video_description": "An older man is talking to a small boy on a sidewalk when a woman runs up and throws water balloons at the man.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the right of a woman on a sidewalk.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A girl standing to the left of a man on a sidewalk.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the boy to the **right** of a woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the right of a woman on a sidewalk. FEH4@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7a6a305a22264d4589973631ae89162b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "970789941b7b43fbb5782cff3cd2aa4f", "source": "vatex", "video_id": "IyhDBSyWCYw_000013_000023", "video_description": "A man opens a door and steps outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. The scene transitions from a dark room to a beautiful outdoor setting with music playing.", "task": "ActionRecognition", "clean_prompt": "A man opening a door and stepping outside into a dream-like landscape with green fields, snowy mountains, and changing leaves.", "clean_property": {"obj": "man", "action": "opening door", "target": null}, "target_prompt": "A man closing a door and stepping back into a dark room.", "target_property": {"obj": "man", "action": "closing door", "target": null}, "evaluation_question": "Is the man **opening** a door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man opening a door and stepping outside into a dream-like landscape with green fields, snowy mountains, and changing leaves. @JSL\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dadb5179565647e084aa7794421e9e45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e37463f663464ba99f01b94ac61ae94f", "source": "vatex", "video_id": "VOUl3u_7Caw_000004_000014", "video_description": "In a snowy yard, a group of children and adults are playing and building a snowman. They pose and take pictures with the snowman.", "task": "AttributeRecognition", "clean_prompt": "A man holding a camera in a snowy yard while children and adults play and build a snowman.", "clean_property": {"obj": "man", "attribute": "holding camera"}, "target_prompt": "A man holding a smartphone in a snowy yard while children and adults play and build a snowman.", "target_property": {"obj": "man", "attribute": "holding a smartphone"}, "evaluation_question": "Is the man holding a **camera**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man holding a camera in a snowy yard while children and adults play and build a snowman. )*-'-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4815fbe3c1a3472abea04239e4d22f56.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "712755b187d84c30b3d9ff0ae115f568", "source": "vatex", "video_id": "7nl_MxNbWS4_000004_000014", "video_description": "A loud crowd at a concert is holding and passing a young man and a woman above them as they crowd surf.", "task": "ActionRecognition", "clean_prompt": "A man surfing in a crowd.", "clean_property": {"obj": "man", "action": "surfing crowd", "target": null}, "target_prompt": "A man crowd surfing over a woman.", "target_property": {"obj": "man", "action": "crowd surfing", "target": "woman"}, "evaluation_question": "Is the man **surfing** in a crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man surfing in a crowd. )/!R=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eaf02afe567f42ba843c12e8565dad9f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cf44efba6c6f4ec192c5e694d49b18dc", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "SpatialUnderstanding", "clean_prompt": "A shovel farther from the camera than the snow.", "clean_property": {"obj_1": "shovel", "relation": "farther from the camera than", "obj_2": "snow"}, "target_prompt": "A shovel closer to the camera than the snow.", "target_property": {"obj_1": "shovel", "relation": "closer to the camera than", "obj_2": "snow"}, "evaluation_question": "Is the shovel **farther from the camera than** the snow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A shovel farther from the camera than the snow. FS*\u00b7|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13a5c90b2e3c4185b8db13274721174c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed5c6bfc8d24422486dac34ef19c2435", "source": "vatex", "video_id": "4UDnIHZjJeI_000323_000333", "video_description": "A man is shaving a woman's head bald using a razor and shaving cream. The woman is happy and looks into the camera while the man, wearing a Planet Hollywood shirt, talks about the process.", "task": "ActionRecognition", "clean_prompt": "A man shaving a woman's head bald using a razor and shaving cream.", "clean_property": {"obj": "man", "action": "shaving head", "target": "woman"}, "target_prompt": "A man shaving another man's head bald using a razor and shaving cream.", "target_property": {"obj": "man", "action": "shaving head", "target": "man"}, "evaluation_question": "Is the man **shaving a woman's head**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man shaving a woman's head bald using a razor and shaving cream. >TZFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a84d7ff3730b4867bbcc4016197d1076.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "974d64444ec44a8590b212cfbe49ef97", "source": "vatex", "video_id": "rARKyYVoS0w_000254_000264", "video_description": "A group of people are working on refinishing a wooden floor in a house. One person is cleaning the floor by hand, another is using a floor sander, and others are using a floor scrubber and buffing machine. Electrical cords are visible, and the floor is being stained.", "task": "ObjectRecognition", "clean_prompt": "A group of people refinishing a wooden floor in a house.", "clean_property": {"obj": "group"}, "target_prompt": "A crowd of people enjoying a festival in a park.", "target_property": {"obj": "crowd"}, "evaluation_question": "Is the group of people in the video working on refinishing a wooden floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people refinishing a wooden floor in a house. LYU2;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8115b559bdc24e79b47d12542fc8d4e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "807ab65ea4234ef69bd1c5d2806c9628", "source": "vatex", "video_id": "mrKxoh6jWBU_000532_000542", "video_description": "A person is outdoors, carrying and displaying a white bucket full of small, dark-colored, dead fish. The person is preparing to bury the fish in the ground near water.", "task": "AttributeRecognition", "clean_prompt": "A person outdoors carrying a white bucket full of small, dark-colored, dead fish.", "clean_property": {"obj": "bucket", "attribute": "white"}, "target_prompt": "A person outdoors carrying a red bucket full of small, dark-colored, dead fish.", "target_property": {"obj": "bucket", "attribute": "red"}, "evaluation_question": "Is the bucket **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person outdoors carrying a white bucket full of small, dark-colored, dead fish. =HSTP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b53c231e2e54214bae81f406b5406cc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f09f8836cc04e748c8e5bcfafada18b", "source": "vatex", "video_id": "IYU0evCuCWg_000000_000010", "video_description": "A man is asleep in a chair in an office while another man plays a prank by placing a cookie in his mouth and then runs away.", "task": "SpatialUnderstanding", "clean_prompt": "A prankster standing to the left of a chair in an office.", "clean_property": {"obj_1": "prankster", "relation": "left of", "obj_2": "chair"}, "target_prompt": "A prankster standing to the right of a chair in an office.", "target_property": {"obj_1": "prankster", "relation": "right of", "obj_2": "chair"}, "evaluation_question": "Is the prankster to the **left** of the chair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A prankster standing to the left of a chair in an office. (VV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f951ff3e6c4405caf759abc575afcd5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0b29d108f6384acbbf7d904d25c4b920", "source": "vatex", "video_id": "Jf9t3eg8ovg_000049_000059", "video_description": "A young boy is sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "task": "Counting", "clean_prompt": "Two boys sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "clean_property": {"obj": "boy", "count": "two"}, "target_prompt": "A boy sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **two** boys sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys sitting at a table, rolling out dough with a wooden rolling pin on a floured surface, next to pizza ingredients. >DAK\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4d4753f548a43f59e2b3f5691dc68ce.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1bbabe1f6d0d47cc88a64b6016edff8b", "source": "vatex", "video_id": "aG7rjkh12Rw_000000_000010", "video_description": "A man is standing on the back of a car, using a sledgehammer to hit the roof of the car repeatedly.", "task": "ActionRecognition", "clean_prompt": "A person using a sledgehammer to hit the roof of a car.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "car"}, "target_prompt": "A person using a sledgehammer to hit a tree.", "target_property": {"obj": "person", "action": "using a sledgehammer", "target": "tree"}, "evaluation_question": "Is the person **using a sledgehammer** on a car?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledgehammer to hit the roof of a car. LYAM6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a4a962a9bf894d7fb07a6f4bf1aa7007.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "78b727f01aa84c84a1c9af8cdafd6012", "source": "vatex", "video_id": "1apesjwcwJ8_000015_000025", "video_description": "A group of young men are playing and practicing volleyball in a gym.", "task": "ObjectRecognition", "clean_prompt": "A group of young men are playing volleyball in a gym.", "clean_property": {"obj": "volleyball"}, "target_prompt": "A group of young men are playing basketball in a gym.", "target_property": {"obj": "basketball"}, "evaluation_question": "Are the young men playing **volleyball** in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young men are playing volleyball in a gym. MT.E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5567230a1ef04adb93453cff028d3091.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a325c0d07be6452dbb733a5bf7d1030a", "source": "vatex", "video_id": "sH2LklWMKo4_000198_000208", "video_description": "A woman is demonstrating how to make and repair earrings using tools like pliers and wire cutters, attaching hooks and bending metal.", "task": "ActionRecognition", "clean_prompt": "A person making jewelry by demonstrating how to create earrings using tools like pliers and wire cutters.", "clean_property": {"obj": "person", "action": "making jewelry", "target": "earring"}, "target_prompt": "A person selling earrings at a market.", "target_property": {"obj": "person", "action": "selling jewelry", "target": "earring"}, "evaluation_question": "Is the person **making** jewelry?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making jewelry by demonstrating how to create earrings using tools like pliers and wire cutters. ELIM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/96dc289f15cb4c319ecc9f5d57b919a7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "826558142a2449ed92971684ab0be3dc", "source": "vatex", "video_id": "7T5nKVJrP5U_000120_000130", "video_description": "A woman is using a sewing machine to sew a piece of blue fabric, then cuts the thread and moves the fabric to a table.", "task": "ObjectRecognition", "clean_prompt": "A woman using a sewing machine to sew a piece of blue fabric.", "clean_property": {"obj": "person"}, "target_prompt": "A child playing with colorful fabric on the floor.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman using a sewing machine to sew a piece of blue fabric. FEJV@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3482829b3de044b5b1c9246f7bd7e5e4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f864022486234ee1a1cfae06442abca2", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "Counting", "clean_prompt": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat, with six poles visible in the background.", "clean_property": {"obj": "pole", "count": "six"}, "target_prompt": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat, with two poles visible in the background.", "target_property": {"obj": "pole", "count": "two"}, "evaluation_question": "Are there exactly **six** poles visible in the background?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat, with six poles visible in the background. +FE'Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ef210f096a944a6b66fe00b8ac587ef.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d4942aaf457b4a07a8bbb78d3ddebaaf", "source": "vatex", "video_id": "GfuK2HltA-c_000000_000010", "video_description": "A young girl is lying down on a couch or pillow while an adult, possibly her caregiver or mother, comforts her by stroking her hair and forehead, and removing something from her forehead.", "task": "Counting", "clean_prompt": "Two young girls lying down on a couch while an adult comforts them by stroking their hair and foreheads.", "clean_property": {"obj": "young girl", "count": "two"}, "target_prompt": "A young girl lying down on a couch while an adult comforts her by stroking her hair and forehead.", "target_property": {"obj": "young girl", "count": "one"}, "evaluation_question": "Are there exactly **two** young girls lying down on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young girls lying down on a couch while an adult comforts them by stroking their hair and foreheads. ))*9!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7db850fd6e13468b9ad9311f02e91230.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "37040e9cc992485893123361caf9ad1c", "source": "vatex", "video_id": "YG0iQsVufQg_000044_000054", "video_description": "A man is sitting and talking while a woman stands behind him, massaging his shoulders in a massage center.", "task": "ActionRecognition", "clean_prompt": "A woman massaging a man's neck in a massage center.", "clean_property": {"obj": "woman", "action": "massaging neck", "target": "man"}, "target_prompt": "A woman giving a facial to a man in a spa.", "target_property": {"obj": "woman", "action": "giving a facial", "target": "man"}, "evaluation_question": "Is the woman **massaging** the man's neck?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman massaging a man's neck in a massage center. HSTLX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/65def8dd79d4433c83cb1736c2c04cd8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7fb8e393eb8443278aaa8f58221ad281", "source": "vatex", "video_id": "mvCzUIx7li0_000020_000030", "video_description": "A person is using a sewing machine on a table to sew stacks of paper together.", "task": "ActionRecognition", "clean_prompt": "A person sewing stacks of paper together using a sewing machine on a table.", "clean_property": {"obj": "person", "action": "sewing", "target": "paper"}, "target_prompt": "A person cutting fabric on a table.", "target_property": {"obj": "person", "action": "cutting", "target": "fabric"}, "evaluation_question": "Is the person **sewing** stacks of paper together?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sewing stacks of paper together using a sewing machine on a table. JOO-?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f470e7d00f4043029c84abe6a5391ebf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4c9f16438cd4f09b2162c478119da59", "source": "vatex", "video_id": "dgq48-TePBI_000068_000078", "video_description": "A man and a woman are sitting on a couch. The man is explaining the features and benefits of a video game controller, while the woman holds a microphone.", "task": "Counting", "clean_prompt": "A man and a woman are sitting on a couch, with two microphones in hand. The man is explaining the features and benefits of a video game controller.", "clean_property": {"obj": "microphone", "count": "two"}, "target_prompt": "A man and a woman are sitting on a couch, with one microphone in hand. The man is explaining the features and benefits of a video game controller.", "target_property": {"obj": "microphone", "count": "one"}, "evaluation_question": "Are there exactly **two** microphones in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are sitting on a couch, with two microphones in hand. The man is explaining the features and benefits of a video game controller. EVP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d2852de355d24cde88b2c7c79d00ea67.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4225f6828011459d97040bb7aea159fe", "source": "vatex", "video_id": "DvBIXiZEwpU_000009_000019", "video_description": "Two men are outside, one holding a snake and trying to get the other, who is nervous and scared, to hold or touch it.", "task": "AttributeRecognition", "clean_prompt": "A man who is nervous and scared is outside while another man holds a snake.", "clean_property": {"obj": "man_2", "attribute": "nervous"}, "target_prompt": "A confident man is outside while another man holds a snake.", "target_property": {"obj": "man_2", "attribute": "confident"}, "evaluation_question": "Is the man nervous and scared?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man who is nervous and scared is outside while another man holds a snake. @Z\u00b7?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d181c6bef9b34300b5fa3bc7e914a444.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a5647d82bcd4266a983b91a56275dc3", "source": "vatex", "video_id": "5UU3iRQW28U_000000_000010", "video_description": "A baby boy is sitting on his father's lap, eating a piece of cake with his hands, getting frosting all over his face.", "task": "ActionRecognition", "clean_prompt": "A baby eating cake with his hands.", "clean_property": {"obj": "baby", "action": "eating cake", "target": null}, "target_prompt": "A baby playing with toys.", "target_property": {"obj": "baby", "action": "playing with toys", "target": null}, "evaluation_question": "Is the baby **eating cake**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby eating cake with his hands. DPZ@I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d7daf059df6944e69f1981f284569ab6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "82f6151ba48a4444a7a0bbe3845adeb8", "source": "vatex", "video_id": "WCdlpVUrbWs_000019_000029", "video_description": "A young girl in a pink tutu is playing hopscotch and dancing in a dance studio with the guidance of an adult instructor dressed in black. The music 'Oh Susannah' is playing on the piano in the background.", "task": "Counting", "clean_prompt": "Three girls in pink tutus are playing hopscotch and dancing in a dance studio.", "clean_property": {"obj": "girl", "count": "three"}, "target_prompt": "One girl in a pink tutu is playing hopscotch in a dance studio.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **three** girls in the dance studio?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls in pink tutus are playing hopscotch and dancing in a dance studio. *$B+V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c5bfa5b63b74dc99539d8655a8e0962.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cc7318153ee745cfbf4aebef05fa0eeb", "source": "vatex", "video_id": "rJk8fad5ZnU_000007_000017", "video_description": "A man is demonstrating and explaining how to use a pottery wheel to shape clay into pottery items like jars and bowls.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating how to use a pottery wheel with wet clay.", "clean_property": {"obj": "clay", "attribute": "wet"}, "target_prompt": "A man demonstrating how to use a pottery wheel with dry clay.", "target_property": {"obj": "clay", "attribute": "dry"}, "evaluation_question": "Is the clay **wet** during the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to use a pottery wheel with wet clay. !0*(|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bef134e194574c04aa93f869159c65e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8f6864017a446d7a8f8745d631547ab", "source": "vatex", "video_id": "vk7ZsxvcvNo_000024_000034", "video_description": "A young boy is playing soccer in a yard, setting up and kicking a soccer ball into a goal net.", "task": "Counting", "clean_prompt": "A young boy is playing soccer in a yard, setting up and kicking a soccer ball into a goal net, aiming for three goals.", "clean_property": {"obj": "goal", "count": "three"}, "target_prompt": "A young boy is playing soccer in a yard, setting up and kicking a soccer ball into a goal net, aiming for one goal.", "target_property": {"obj": "goal", "count": "one"}, "evaluation_question": "Are there exactly **three** goals the boy is aiming for?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is playing soccer in a yard, setting up and kicking a soccer ball into a goal net, aiming for three goals. >WSIE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d60454718f2240e5aacc5623abc50d44.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "984f291ed5a243afbb6a6d68d23adef0", "source": "vatex", "video_id": "aPjbJ4ZNcVQ_000157_000167", "video_description": "A man and a young girl are sitting at a table in the kitchen, stirring and scooping cookie dough onto a baking tray. They occasionally wave and say hi to the camera.", "task": "AttributeRecognition", "clean_prompt": "A bowl that contains cookie dough on a kitchen table.", "clean_property": {"obj": "bowl", "attribute": "contains cookie dough"}, "target_prompt": "A bowl that contains salad on a kitchen table.", "target_property": {"obj": "bowl", "attribute": "contains salad"}, "evaluation_question": "Does the bowl contain **cookie dough**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bowl that contains cookie dough on a kitchen table. (FIZR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be70d458ea5649d783794276a647b283.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a726b3b30c604a459380de2f254ccd7f", "source": "vatex", "video_id": "1d4ZOE0y3e4_000275_000285", "video_description": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her.", "task": "ActionRecognition", "clean_prompt": "A girl folding clothes on a messy bed.", "clean_property": {"obj": "girl", "action": "folding clothes", "target": null}, "target_prompt": "A girl throwing clothes on a messy bed.", "target_property": {"obj": "girl", "action": "throwing clothes", "target": null}, "evaluation_question": "Is the girl **folding** clothes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl folding clothes on a messy bed. Z!':-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b5c4faad35e42a19dfa91822e209826.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1011ff6ba1cf4f3395fab76fd1c95300", "source": "vatex", "video_id": "T6vWb-9ILPE_000000_000010", "video_description": "Two men are working on a large clay pot on a spinning pottery wheel, shaping and adjusting it.", "task": "ObjectRecognition", "clean_prompt": "Two men are working on a large clay pot on a spinning pottery wheel, shaping and adjusting it.", "clean_property": {"obj": "clay pot"}, "target_prompt": "Two men are working on a large glass vase on a spinning pottery wheel, shaping and adjusting it.", "target_property": {"obj": "glass vase"}, "evaluation_question": "Is the object being shaped in the video a **clay pot**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are working on a large clay pot on a spinning pottery wheel, shaping and adjusting it. TY-S@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c1f2a5c62ab45f4b39e3cadeb1b9664.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9a215af8138a451b90a6bf1291e25ef7", "source": "vatex", "video_id": "PPVCtO8gGOs_000015_000025", "video_description": "A man is attempting to smoke a cigarette indoors, repeatedly coughing after taking puffs.", "task": "ActionRecognition", "clean_prompt": "A person smoking a cigarette indoors, coughing after taking puffs.", "clean_property": {"obj": "person", "action": "smoking", "target": "cigarette"}, "target_prompt": "A person vaping indoors, coughing after taking puffs.", "target_property": {"obj": "person", "action": "vaping", "target": "vape pen"}, "evaluation_question": "Is the person **smoking** a cigarette?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person smoking a cigarette indoors, coughing after taking puffs. HSBSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/12faf47f5bfb4a4899f290894832e776.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4f34e5086ec54c85a340e1bf33666f43", "source": "vatex", "video_id": "VOUl3u_7Caw_000004_000014", "video_description": "In a snowy yard, a group of children and adults are playing and building a snowman. They pose and take pictures with the snowman.", "task": "Counting", "clean_prompt": "Three children playing in a snowy yard, building a snowman and posing for pictures.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child playing in a snowy yard, building a snowman and posing for pictures.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children playing in the snowy yard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children playing in a snowy yard, building a snowman and posing for pictures. 08EZF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b99a8e0ac1eb42349d079418ea9accf3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "15f4e2f7ff83466a94365c07a0adead4", "source": "vatex", "video_id": "B5lAcaojk0E_000000_000010", "video_description": "A man is in a bathroom in front of a mirror, adjusting his hair and posing for the camera. A woman films him as he drools into the sink.", "task": "SpatialUnderstanding", "clean_prompt": "A camera positioned to the right of a mirror in a bathroom.", "clean_property": {"obj_1": "camera", "relation": "right of", "obj_2": "mirror"}, "target_prompt": "A camera positioned to the left of a mirror in a bathroom.", "target_property": {"obj_1": "camera", "relation": "left of", "obj_2": "mirror"}, "evaluation_question": "Is the camera to the **right** of the mirror?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A camera positioned to the right of a mirror in a bathroom. NKFCF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ccc75365e1d24bf2bb26a1806c6247d9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "db588dc009344702b716767400bb86f0", "source": "vatex", "video_id": "x6m12TincPk_000151_000161", "video_description": "A woman is in a bathroom using an electric razor to shave all the hair off her head.", "task": "ActionRecognition", "clean_prompt": "A person shaving their head in a bathroom.", "clean_property": {"obj": "person", "action": "shaving head", "target": null}, "target_prompt": "A person dying their hair blue in a bathroom.", "target_property": {"obj": "person", "action": "dying hair", "target": "blue"}, "evaluation_question": "Is the person **shaving their head**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shaving their head in a bathroom. 1*X/B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e564fb3107e7469e868e43bc5190dfc0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0275aaeb010940928e2e9777eb32c70c", "source": "vatex", "video_id": "dZyuSPDUWFs_000194_000204", "video_description": "A group of people, including young adults, are hiking and exploring a cave and its surrounding area, wearing helmets for safety.", "task": "ObjectRecognition", "clean_prompt": "A group of people hiking and exploring a cave, wearing helmets for safety.", "clean_property": {"obj": "cave"}, "target_prompt": "A group of people hiking and exploring a mountain, wearing helmets for safety.", "target_property": {"obj": "mountain"}, "evaluation_question": "Are the people exploring a **cave**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people hiking and exploring a cave, wearing helmets for safety. =BC=Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de0329f196ed478e942023d88b232451.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cfad3328a9424b34b28efe8e59612e2e", "source": "vatex", "video_id": "g63r5yW3WJY_000015_000025", "video_description": "A man is attempting a snowboarding trick, jumps into the air, and falls, narrowly missing a dog.", "task": "Counting", "clean_prompt": "Seven snowboarders attempting tricks on a snowy slope.", "clean_property": {"obj": "snowboarder", "count": "seven"}, "target_prompt": "One snowboarder attempting a trick on a snowy slope.", "target_property": {"obj": "snowboarder", "count": "one"}, "evaluation_question": "Are there exactly **seven** snowboarders on the slope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven snowboarders attempting tricks on a snowy slope. FEWV4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9af6d43ad67a4a0aa46d0dcfed8a1f18.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9e26a90d4604b05b05ea3de92a1a088", "source": "vatex", "video_id": "lDOd8Z0Vwbg_000236_000246", "video_description": "A person is demonstrating how to prepare and attach a fishing lure using various tools and materials.", "task": "Counting", "clean_prompt": "A person is demonstrating how to prepare and attach a fishing lure using three tools and materials.", "clean_property": {"obj": "tool", "count": "three"}, "target_prompt": "A person is demonstrating how to prepare and attach a fishing lure using one tool and materials.", "target_property": {"obj": "tool", "count": "one"}, "evaluation_question": "Are there exactly **three** tools being used in the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to prepare and attach a fishing lure using three tools and materials. RP!Q0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/08ecb870c51f4393a10c275727ef2753.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dc825a3ca99548a0910022becbb0b31e", "source": "vatex", "video_id": "NcACCCcY-_c_000015_000025", "video_description": "A man is demonstrating and explaining how to tie and lace up shoes, focusing on a specific knot technique.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a shoe while demonstrating how to tie it.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "shoe"}, "target_prompt": "A person standing to the left of a shoe while demonstrating how to tie it.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "shoe"}, "evaluation_question": "Is the person to the **right** of the shoe?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a shoe while demonstrating how to tie it. FE@D!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d3a5b6dc0074f50b6a3b6d246131fe6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "66ecdbe4be34448fabf1b16f2dc7411b", "source": "vatex", "video_id": "r7B2l4qXtNw_000005_000015", "video_description": "A man is jumping rope in slow motion outside in his yard, wearing athletic wear including a black shirt, blue shorts, and tennis shoes.", "task": "ActionRecognition", "clean_prompt": "A person skipping rope in slow motion outside in a yard.", "clean_property": {"obj": "person", "action": "skipping rope", "target": null}, "target_prompt": "A person running in a park.", "target_property": {"obj": "person", "action": "running", "target": "park"}, "evaluation_question": "Is the person **skipping rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person skipping rope in slow motion outside in a yard. #G%%/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f80e7fe2278c4248a036f3602bb49d33.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "583bc38ac703488bad8187aee77dfe08", "source": "vatex", "video_id": "e6-cKJGV99A_000082_000092", "video_description": "A woman is demonstrating and explaining how to properly brush a child's teeth using an electric toothbrush.", "task": "ActionRecognition", "clean_prompt": "A woman demonstrating how to properly brush a child's teeth using an electric toothbrush.", "clean_property": {"obj": "woman", "action": "brushing teeth", "target": "child"}, "target_prompt": "A woman demonstrating how to properly brush a dog's teeth using an electric toothbrush.", "target_property": {"obj": "woman", "action": "brushing teeth", "target": "dog"}, "evaluation_question": "Is the woman demonstrating how to brush a child's teeth?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to properly brush a child's teeth using an electric toothbrush. 1-=BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4942f4aa1edc48d4b20b9f70ea78b547.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8ce522c5fa83455184c259207929dc8b", "source": "vatex", "video_id": "OzFRhoqFAwA_000026_000036", "video_description": "A man is demonstrating and instructing how to perform squats using a red medicine ball in a field.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to perform squats using a red medicine ball in a field.", "clean_property": {"obj": "ball"}, "target_prompt": "A man demonstrating how to perform squats using a kettlebell in a field.", "target_property": {"obj": "kettlebell"}, "evaluation_question": "Is the object being used by the man a **medicine ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to perform squats using a red medicine ball in a field. -)!FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a27793d59174414daa8c7b29023bf8f6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b022cd933efa4b1e830215eb3c17670b", "source": "vatex", "video_id": "s3jFgtaouNQ_000000_000010", "video_description": "A man is standing outdoors while a woman in a tracksuit and earphones jogs in slow motion on the sidewalk behind him. A kid is also present, smiling at the camera, while romantic music plays.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a kid outdoors.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "kid"}, "target_prompt": "A man standing to the right of a kid outdoors.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "kid"}, "evaluation_question": "Is the man to the **left** of the kid?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a kid outdoors. VPZ>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/09e952b35c6849bcb8cf8b4427c1c932.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8bc5b1a2d47f4af8957412fa6d5fd7d7", "source": "vatex", "video_id": "yA_rP7LbTO8_000035_000045", "video_description": "A woman is teaching a group of students about the value of coins using a worksheet and a touch money math key.", "task": "SpatialUnderstanding", "clean_prompt": "A boy farther from the camera than a teacher who is explaining a worksheet.", "clean_property": {"obj_1": "boy", "relation": "farther from the camera than", "obj_2": "teacher"}, "target_prompt": "A boy closer to the camera than a teacher who is explaining a worksheet.", "target_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "teacher"}, "evaluation_question": "Is the boy **farther from the camera than** the teacher?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy farther from the camera than a teacher who is explaining a worksheet. LY-2T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64a46a1b008b4939ab3b7438d607dd0a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab0c77a9022243d49e17be040a1e5fa9", "source": "vatex", "video_id": "XJD7RqdAQLw_000001_000011", "video_description": "A little boy is outdoors at a gas station, pumping gas into a vehicle while talking to a man.", "task": "Counting", "clean_prompt": "Seven men at a gas station, with one of them talking to a little boy who is pumping gas.", "clean_property": {"obj": "man", "count": "seven"}, "target_prompt": "Four men at a gas station, with one of them talking to a little boy who is pumping gas.", "target_property": {"obj": "man", "count": "four"}, "evaluation_question": "Are there exactly **seven** men at the gas station?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven men at a gas station, with one of them talking to a little boy who is pumping gas. V&81H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c16cccf3a7984ec4a518e9352aa4dbb1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "92a7ea8316804e1badb49f6e9f7d3afa", "source": "vatex", "video_id": "2QWzPnu90Kc_000220_000230", "video_description": "A person is on the roof of a house, inspecting and cleaning the gutters by removing leaves and dirt. They are also giving instructions about roof inspection and maintenance.", "task": "ObjectRecognition", "clean_prompt": "A person on the roof of a house, inspecting and cleaning the gutters while a trash can is nearby.", "clean_property": {"obj": "trash can"}, "target_prompt": "A person on the roof of a house, inspecting and cleaning the gutters while a recycling bin is nearby.", "target_property": {"obj": "recycling bin"}, "evaluation_question": "Is there a **trash can** present in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person on the roof of a house, inspecting and cleaning the gutters while a trash can is nearby. 8EVIL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/860ca1de5f8d47afa5965c3e6d53729a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "28f2a45a9e814043acd975093bc0a4a0", "source": "vatex", "video_id": "4ilyKmcgOOg_000000_000010", "video_description": "A person is abseiling down the side of a tall brown building using rock climbing equipment, while others watch from the top of the building. The scene takes place on a cloudy day.", "task": "ActionRecognition", "clean_prompt": "A person abseiling down the side of a tall brown building.", "clean_property": {"obj": "person", "action": "abseiling", "target": null}, "target_prompt": "A person bungee jumping off a tall brown building.", "target_property": {"obj": "person", "action": "bungee jumping", "target": null}, "evaluation_question": "Is the person **abseiling** down the building?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person abseiling down the side of a tall brown building. =R@VG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a16848461cd24afa86b93e394b15abfb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7182ec2218f487d8feccebe38025d89", "source": "vatex", "video_id": "0NezYkEdfMQ_000016_000026", "video_description": "A woman demonstrates how to fold clothes and store them in a drawer, with music playing in the background. The process is shown in a fast forward or time-lapse motion.", "task": "Counting", "clean_prompt": "Two people folding clothes and storing them in a drawer, with music playing in the background.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person folding clothes and storing them in a drawer, with music playing in the background.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people folding clothes in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people folding clothes and storing them in a drawer, with music playing in the background. 8PDVH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6a09c847540944f1b6b0409ad7c5bb67.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b4ff743b1bd2423d9f96e5562ba090e1", "source": "vatex", "video_id": "RRsPuL0uSLk_000002_000012", "video_description": "A woman with long blond hair stands in front of two men, cracking her knuckles and challenging them to a fight. The men are armed with tools and appear threatening.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing farther from the camera than two men, cracking her knuckles and challenging them to a fight.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "men"}, "target_prompt": "A woman standing closer to the camera than two men, cracking her knuckles and challenging them to a fight.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "men"}, "evaluation_question": "Is the woman farther from the camera than the men?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing farther from the camera than two men, cracking her knuckles and challenging them to a fight. ')!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7944e544f9f147ccac1ad90685548bfe.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03ab7bb0e74945238a22a104b0517fe7", "source": "vatex", "video_id": "yOLcO75Mc98_000026_000036", "video_description": "A woman is in a kitchen demonstrating how to make chocolate chip cookies by mixing ingredients and baking them.", "task": "ObjectRecognition", "clean_prompt": "A woman is in a kitchen mixing ingredients in a bowl to make chocolate chip cookies.", "clean_property": {"obj": "bowl"}, "target_prompt": "A woman is in a kitchen mixing ingredients in a pan to make chocolate chip cookies.", "target_property": {"obj": "pan"}, "evaluation_question": "Is the woman mixing ingredients in a **bowl**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is in a kitchen mixing ingredients in a bowl to make chocolate chip cookies. HYFE7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f6dc0eb3f21f4385b75eaf304f084aec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a25063d01514c2eba1bec750c4a6294", "source": "vatex", "video_id": "qk3YzucfVl4_000092_000102", "video_description": "A woman is having her eyes measured and tested by an optometrist using a device. The optometrist demonstrates the procedure while a narrator explains.", "task": "ObjectRecognition", "clean_prompt": "A woman having her eyes measured by an optometrist using a device.", "clean_property": {"obj": "woman"}, "target_prompt": "A man having his eyes measured by an optometrist using a device.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person having their eyes measured a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman having her eyes measured by an optometrist using a device. )FSSK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/50f90f3ddbc4466497970ee441aebbcd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ddd246c29d3f4fe78c901b0b28f67125", "source": "vatex", "video_id": "Sq82j_WAYTg_000000_000010", "video_description": "A man is riding a segway with a lawn mower attached, cutting grass across a yard.", "task": "ActionRecognition", "clean_prompt": "A person using a segway with a lawn mower attached, cutting grass across a yard.", "clean_property": {"obj": "person", "action": "using segway", "target": null}, "target_prompt": "A person racing on a segway in a park.", "target_property": {"obj": "person", "action": "racing", "target": "segway"}, "evaluation_question": "Is the person **using a segway with a lawn mower**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a segway with a lawn mower attached, cutting grass across a yard. ;F)2S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4fb5eb698533454298a7db70b03ad030.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0cb668ca2df343c1a940ad35b722bac3", "source": "vatex", "video_id": "SE98Q0WpRps_000096_000106", "video_description": "A man is standing in a house with his dog, holding a leash, and talking about his book on dog training. The scene transitions to show the book while he continues to talk off-camera.", "task": "SpatialUnderstanding", "clean_prompt": "A dog standing to the right of a man holding a leash in a house.", "clean_property": {"obj_1": "dog", "relation": "right of", "obj_2": "man"}, "target_prompt": "A cat standing to the left of a woman in a house.", "target_property": {"obj_1": "cat", "relation": "left of", "obj_2": "woman"}, "evaluation_question": "Is the dog to the **right** of a man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dog standing to the right of a man holding a leash in a house. FEA,$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/66b37430413644efa4b9a6a4b2a25d3a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "680a974d2d904c3da7d73e3075bd6e75", "source": "vatex", "video_id": "AFzMNrdZQr0_000024_000034", "video_description": "A young girl is learning to drink and eat from a cup with the help of her mother.", "task": "AttributeRecognition", "clean_prompt": "A young girl is learning to drink from a red cup with the help of her mother.", "clean_property": {"obj": "cup", "attribute": "red"}, "target_prompt": "A young girl is learning to drink from a blue cup with the help of her mother.", "target_property": {"obj": "cup", "attribute": "blue"}, "evaluation_question": "Is the cup **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is learning to drink from a red cup with the help of her mother. *(J'V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b225b7c7fa24c1dbcc753d64227f825.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fde96b4a5a0b45a188c5a2a1a4d4338e", "source": "vatex", "video_id": "jzOndFOIECw_000001_000011", "video_description": "A man with a mustache, wearing a black top and having curly hair, is sitting in a room and smoking a cigarette.", "task": "AttributeRecognition", "clean_prompt": "A person with curly hair sitting in a room and smoking a cigarette.", "clean_property": {"obj": "person", "attribute": "curly hair"}, "target_prompt": "A person bald sitting in a room and smoking a cigarette.", "target_property": {"obj": "person", "attribute": "bald"}, "evaluation_question": "Is the person depicted in the video **curly-haired**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with curly hair sitting in a room and smoking a cigarette. FEMV@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f35df90f003848e2b6c934b1ac8b15ee.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "95cfd767d61841a3a7efbc637e9b164c", "source": "vatex", "video_id": "MBEDYxjnUIY_000280_000290", "video_description": "A group of people, including a man and two women, are tending to a horse's leg injuries by applying ointment and bandages.", "task": "AttributeRecognition", "clean_prompt": "A group of people tending to an injured horse by applying ointment and bandages.", "clean_property": {"obj": "horse", "attribute": "injured"}, "target_prompt": "A group of people tending to a healthy horse.", "target_property": {"obj": "horse", "attribute": "healthy"}, "evaluation_question": "Is the horse **injured**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people tending to an injured horse by applying ointment and bandages. 9BEZF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d27d1d43f8914f43880779b3d3e339bb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e49e787c239e407ba7f586ed7b49c4fb", "source": "vatex", "video_id": "JFWsCM8WE-w_000000_000010", "video_description": "A man is splitting a log into smaller pieces using an axe, a wedge, and a sledgehammer, while a child laughs off-screen.", "task": "ActionRecognition", "clean_prompt": "A child laughing off-screen while a man splits a log.", "clean_property": {"obj": "child", "action": "laughing", "target": null}, "target_prompt": "A child crying off-screen while a man splits a log.", "target_property": {"obj": "child", "action": "crying", "target": null}, "evaluation_question": "Is the child **laughing** off-screen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child laughing off-screen while a man splits a log. S/!%D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfa75076131f4921a46f83d467e0bcf8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a234a1fdac3d4c78b69f7d891dd819e5", "source": "vatex", "video_id": "vbPK1FaEkkY_000001_000011", "video_description": "A young girl is in a bathroom brushing her teeth quickly over a sink.", "task": "ActionRecognition", "clean_prompt": "A girl brushing her teeth quickly over a sink in a bathroom.", "clean_property": {"obj": "girl", "action": "brushing teeth", "target": null}, "target_prompt": "A girl washing her hands in a bathroom.", "target_property": {"obj": "girl", "action": "washing hands", "target": null}, "evaluation_question": "Is the girl **brushing her teeth**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl brushing her teeth quickly over a sink in a bathroom. D-=BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/10866863d78b4302a355d4ee1e42aaed.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2472b859de40426dacf2df117c427b74", "source": "vatex", "video_id": "8Ky5s84mDFU_000046_000056", "video_description": "A group of people, including a man and two boys, are playing with a blue ball in an open field. The ball is thrown high into the air and across the field, with participants catching and throwing it back and forth.", "task": "ObjectRecognition", "clean_prompt": "A group of people playing with a blue ball in an open field.", "clean_property": {"obj": "ball"}, "target_prompt": "A group of people playing with a frisbee in an open field.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Is the object being played with a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people playing with a blue ball in an open field. LY4,J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d999c832c1584695b08fc157278ad017.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7e6937cbd8c143c0890b52e700c27ab7", "source": "vatex", "video_id": "_PynuSWitdM_000398_000408", "video_description": "A man is camping and places a cast iron pot on an open fire pit, with a dog following him.", "task": "AttributeRecognition", "clean_prompt": "A man camping places a black pot on an open fire pit, with a dog following him.", "clean_property": {"obj": "pot", "attribute": "black"}, "target_prompt": "A man camping places a red pot on an open fire pit, with a dog following him.", "target_property": {"obj": "pot", "attribute": "red"}, "evaluation_question": "Is the pot **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man camping places a black pot on an open fire pit, with a dog following him. R$J.\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67fcb8f23ea0453cbc9e6870914062d9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5a13ee83b934e7fb7fc4d316ec69f3a", "source": "vatex", "video_id": "XDc1n3TLc_w_000017_000027", "video_description": "A person dressed in an Incredible Hulk costume is outside, flexing and moving around, while a child is present and occasionally calls out.", "task": "SpatialUnderstanding", "clean_prompt": "A person dressed in an Incredible Hulk costume is standing to the left of a child who is calling out.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "child"}, "target_prompt": "A person dressed in an Incredible Hulk costume is standing to the right of a child who is calling out.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "child"}, "evaluation_question": "Is the person dressed in an Incredible Hulk costume to the **left** of the child?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person dressed in an Incredible Hulk costume is standing to the left of a child who is calling out. ;C&MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fab9ce17d74b44509e03bf3779d49e66.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8aeff990f14240b2b5383d47c724254a", "source": "vatex", "video_id": "42tR0bQ0oTk_000009_000019", "video_description": "A man is getting baptized in a church while the congregation cheers him on. People are worshiping, praying, and listening to a sermon. The atmosphere is lively with music, clapping, and expressions of praise.", "task": "ActionRecognition", "clean_prompt": "A congregation singing joyfully in a church.", "clean_property": {"obj": "congregation", "action": "singing", "target": null}, "target_prompt": "A congregation shouting loudly in a church.", "target_property": {"obj": "congregation", "action": "shouting", "target": null}, "evaluation_question": "Is the congregation **singing** joyfully?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A congregation singing joyfully in a church. ;D$AK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/837c68a104724daaa861c585b331c3b4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cbaaf245a55a4106bb304e08a7ec9d16", "source": "vatex", "video_id": "t573KgLsuNA_000009_000019", "video_description": "A young boy in a winter cap and hoodie is demonstrating how to ride a unicycle on a street and driveway.", "task": "Counting", "clean_prompt": "Five boys in winter caps and hoodies demonstrating how to ride unicycles on a street and driveway.", "clean_property": {"obj": "boy", "count": "five"}, "target_prompt": "One boy in a winter cap and hoodie demonstrating how to ride a unicycle on a street.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **five** boys demonstrating how to ride unicycles?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five boys in winter caps and hoodies demonstrating how to ride unicycles on a street and driveway. VP@LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c23fcfbb125441c85e1da5893b70b0c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7894a42070b5466fab349609c47c4bd6", "source": "vatex", "video_id": "u4eXGXXeoxo_000082_000092", "video_description": "A man is running on a treadmill in the center of a living room, lifting his knees high, pointing his toes, and bending his elbows. The treadmill is set at a high speed and inclined, and the video is shown in slow motion.", "task": "ActionRecognition", "clean_prompt": "A person running on a treadmill in a living room.", "clean_property": {"obj": "person", "action": "running on treadmill", "target": null}, "target_prompt": "A person walking on a treadmill in a living room.", "target_property": {"obj": "person", "action": "walking on treadmill", "target": null}, "evaluation_question": "Is the person **running** on the treadmill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person running on a treadmill in a living room. ))!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/25eb4e60839e4ff0967eb7868f7134fb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a7cb2fa855c54e90a51bbbd299eacc5f", "source": "vatex", "video_id": "42tR0bQ0oTk_000009_000019", "video_description": "A man is getting baptized in a church while the congregation cheers him on. People are worshiping, praying, and listening to a sermon. The atmosphere is lively with music, clapping, and expressions of praise.", "task": "AttributeRecognition", "clean_prompt": "A congregation that is enthusiastic while a man is getting baptized in a church.", "clean_property": {"obj": "congregation", "attribute": "enthusiastic"}, "target_prompt": "A congregation that is disinterested while a man is getting baptized in a church.", "target_property": {"obj": "congregation", "attribute": "disinterested"}, "evaluation_question": "Is the congregation **enthusiastic** during the baptism?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A congregation that is enthusiastic while a man is getting baptized in a church. BQIVA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b073fdb485744b4a81b0157561fd614.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e9f8a7c582b149f09025f20d597d86e4", "source": "vatex", "video_id": "t9A0ceBCzng_000004_000014", "video_description": "A man is sitting at a table playing a stringed instrument, possibly a lute or an odd-shaped guitar.", "task": "ActionRecognition", "clean_prompt": "A person playing guitar at a table.", "clean_property": {"obj": "person", "action": "playing guitar", "target": null}, "target_prompt": "A person singing at a table.", "target_property": {"obj": "person", "action": "singing", "target": null}, "evaluation_question": "Is the person **playing guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing guitar at a table. T3*4B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0bf645e006aa467896337d775a68bbec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "638e63ad90b74363b16e9ad465438069", "source": "vatex", "video_id": "9AeWKJVrXLo_000000_000010", "video_description": "A man in a black suit is conducting an auction at a real estate seminar, speaking into a microphone while another man operates slides on stage. The event takes place in front of an audience, with information displayed on a screen beside the speaker.", "task": "Counting", "clean_prompt": "A man in a black suit is conducting an auction at a real estate seminar, speaking into a microphone while three screens display information beside him.", "clean_property": {"obj": "screen", "count": "three"}, "target_prompt": "A man in a black suit is conducting an auction at a real estate seminar, speaking into a microphone while one screen displays information beside him.", "target_property": {"obj": "screen", "count": "one"}, "evaluation_question": "Are there exactly **three** screens displaying information beside the speaker?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a black suit is conducting an auction at a real estate seminar, speaking into a microphone while three screens display information beside him. ?G*WB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7478daf2dcb34124b67bb2805b961f81.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "15933a789e92402bb9a3ceba63d1d051", "source": "vatex", "video_id": "qd1c-9pdPyk_000039_000049", "video_description": "A man is working indoors on a woodworking project using various power tools, including a sander, circular saw, jig saw, and reciprocating saw.", "task": "Counting", "clean_prompt": "A man is working indoors on a woodworking project using six tools, including a sander, circular saw, jig saw, and reciprocating saw.", "clean_property": {"obj": "tools", "count": "six"}, "target_prompt": "A man is working indoors on a woodworking project using three tools, including a sander and a circular saw.", "target_property": {"obj": "tools", "count": "three"}, "evaluation_question": "Are there exactly **six** tools being used in the woodworking project?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is working indoors on a woodworking project using six tools, including a sander, circular saw, jig saw, and reciprocating saw. LY1;S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f860b1ada7ce4cdf86f7b82194879b2d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d003f4f19bc431084474f6c00aa060a", "source": "vatex", "video_id": "J9xSHM190hU_000004_000014", "video_description": "A pole vaulter is practicing at night under a spotlight, running with a pole and vaulting over a horizontal bar onto a mat.", "task": "SpatialUnderstanding", "clean_prompt": "A pole vaulter is positioned to the right of a horizontal bar, practicing under a spotlight at night.", "clean_property": {"obj_1": "pole vaulter", "relation": "right of", "obj_2": "bar"}, "target_prompt": "A pole vaulter is positioned to the left of a horizontal bar, practicing under a spotlight at night.", "target_property": {"obj_1": "pole vaulter", "relation": "left of", "obj_2": "bar"}, "evaluation_question": "Is the pole vaulter to the **right** of the bar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pole vaulter is positioned to the right of a horizontal bar, practicing under a spotlight at night. ))'!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce7d771230c14300996e3be2d3f99a2b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d6f16744f93e459bad221022b0c00fae", "source": "vatex", "video_id": "MAfGLNFxXds_000676_000686", "video_description": "In a church setting, a man is washing another man's feet with a white towel during a religious ceremony. A group of people are present, some praying and quoting scripture.", "task": "AttributeRecognition", "clean_prompt": "A man washing another man's feet with a white towel in a church setting during a religious ceremony.", "clean_property": {"obj": "towel", "attribute": "white"}, "target_prompt": "A man washing another man's feet with a red towel in a church setting during a religious ceremony.", "target_property": {"obj": "towel", "attribute": "red"}, "evaluation_question": "Is the towel **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man washing another man's feet with a white towel in a church setting during a religious ceremony. Q%BS%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ddefed131c3d4ac2b457e838bc3bbcfc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a16f67b4d9a14dd9bdf2156f17d4cf49", "source": "vatex", "video_id": "nWq29IA5Vv8_000043_000053", "video_description": "A man is feeding a small bird directly from his mouth while holding it on his hand.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a bird.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "bird"}, "target_prompt": "A man closer to the camera than a bird.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "bird"}, "evaluation_question": "Is the man **farther from the camera than** the bird?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a bird. )G*D)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0266282c561a40438f8133fd61d1c533.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f66c15ae8394e1aa4f370c26654786e", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "Counting", "clean_prompt": "A man demonstrating how to shovel snow from a driveway with six people watching.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A man demonstrating how to shovel snow from a driveway with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to shovel snow from a driveway with six people watching. X.LFS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/81d27123f9824ba3bf2b52575d46312b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "90c34a1ac29a4d7aaa17e33f36012603", "source": "vatex", "video_id": "d7eFxeeCCiY_000000_000010", "video_description": "A man is eating a small white powdered donut in a house, occasionally looking at the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a donut.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "donut"}, "target_prompt": "A person closer to the camera than a donut.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "donut"}, "evaluation_question": "Is the person farther from the camera than a donut?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a donut. \u00b7F)?B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42a360d26ba94fd28f5e8941bba6cc06.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "98d7fb6ac7ce45758a4bfa08b69ee6f0", "source": "vatex", "video_id": "laJ_8v7lo3I_000138_000148", "video_description": "Two young girls are performing a karaoke song on stage, each holding a microphone.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone farther from the camera than a girl on stage performing karaoke.", "clean_property": {"obj_1": "microphone", "relation": "farther from the camera than", "obj_2": "girl"}, "target_prompt": "A microphone closer to the camera than a girl on stage performing karaoke.", "target_property": {"obj_1": "microphone", "relation": "closer to the camera than", "obj_2": "girl"}, "evaluation_question": "Is the microphone **farther from the camera than** the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microphone farther from the camera than a girl on stage performing karaoke. )))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f46f6b27886340718bf9f00aac32c5ba.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d085ea0a87684d2b9138eb22e12d1111", "source": "vatex", "video_id": "s8DfflCKuO4_000122_000132", "video_description": "A woman in a dress is demonstrating how to wrap and decorate gifts, including a roll of toilet paper, using Christmas-themed decorations and ribbons.", "task": "Counting", "clean_prompt": "A woman in a dress is wrapping six gifts using Christmas-themed decorations and ribbons.", "clean_property": {"obj": "gift", "count": "six"}, "target_prompt": "A woman in a dress is wrapping three gifts using Halloween-themed decorations and ribbons.", "target_property": {"obj": "gift", "count": "three"}, "evaluation_question": "Are there exactly **six** gifts being wrapped?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a dress is wrapping six gifts using Christmas-themed decorations and ribbons. !'G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6f47c16cbda044ff8c582f6af17cd8b9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4355532bb7b842b5a340f7db7359fdef", "source": "vatex", "video_id": "R9VF3gdf_Hk_000005_000015", "video_description": "A woman demonstrates how to fold a square white piece of paper in half, explaining the process and making a nice crease.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a square white piece of paper while demonstrating how to fold it in half.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "paper"}, "target_prompt": "A person standing to the left of a square white piece of paper while demonstrating how to fold it in half.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "paper"}, "evaluation_question": "Is the person to the **right** of the square white piece of paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a square white piece of paper while demonstrating how to fold it in half. -FE3G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/893620caabd04fd2b9e58a7afe1d2b9c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21805d0ac6df4099b66d3bb557eefc70", "source": "vatex", "video_id": "-S7s8fqYspc_000017_000027", "video_description": "Three women are dancing together in a dimly lit apartment at night, moving side to side and around the room to music.", "task": "Counting", "clean_prompt": "Two women are dancing together in a dimly lit apartment at night, moving side to side and around the room to music.", "clean_property": {"obj": "apartment", "count": "two"}, "target_prompt": "One woman is dancing alone in a brightly lit apartment during the day.", "target_property": {"obj": "apartment", "count": "one"}, "evaluation_question": "Are there exactly **two** women dancing in the apartment?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women are dancing together in a dimly lit apartment at night, moving side to side and around the room to music. !TZS\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/137f4dc75d2c455e8aca92a7458bbbbe.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6631af959e0541569f8a0cff69181a2e", "source": "vatex", "video_id": "urQP3t9vhNg_000020_000030", "video_description": "A man is demonstrating rollerblading techniques, including turning and stopping, while other people watch. He performs sharp turns and skates back and forth on a road.", "task": "Counting", "clean_prompt": "A man is demonstrating rollerblading techniques while seven onlookers watch.", "clean_property": {"obj": "onlookers", "count": "seven"}, "target_prompt": "A man is demonstrating rollerblading techniques while three onlookers watch.", "target_property": {"obj": "onlookers", "count": "three"}, "evaluation_question": "Are there exactly **seven** onlookers watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating rollerblading techniques while seven onlookers watch. 4F:C%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b523db202db54c4f8a66f7edf0dccb44.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4d7c0700b54641fc9b1e2c9cabb9f5d3", "source": "vatex", "video_id": "KFF_zkxtOh8_000104_000114", "video_description": "A woman is demonstrating how to style her hair using a round brush and a blow dryer, explaining the steps for a blowout.", "task": "ActionRecognition", "clean_prompt": "A person curling hair with a round brush and a blow dryer.", "clean_property": {"obj": "person", "action": "curling hair", "target": null}, "target_prompt": "A person straightening hair with a flat iron.", "target_property": {"obj": "person", "action": "straightening hair", "target": null}, "evaluation_question": "Is the person **curling** hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person curling hair with a round brush and a blow dryer. SL(A#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5d012df671de4ef4841178ec14ec7be3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9be6138adb67453c97f772fc99fe838f", "source": "vatex", "video_id": "2s6u2UagD44_000045_000055", "video_description": "A family and their dog are at the beach. A girl is digging a hole in the sand while a man talks to a woman and two girls. The beach is wet and muddy.", "task": "AttributeRecognition", "clean_prompt": "A girl kneeling and digging a hole in the sand at the beach.", "clean_property": {"obj": "girl", "attribute": "kneeling"}, "target_prompt": "A girl standing and looking at the ocean at the beach.", "target_property": {"obj": "girl", "attribute": "standing"}, "evaluation_question": "Is the girl kneeling?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl kneeling and digging a hole in the sand at the beach. =XPBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35447afc84964af3ae6223d9b6d10ee1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f80c6da999824798bb1422ed2b25a609", "source": "vatex", "video_id": "8H6PoVJHiBk_000000_000010", "video_description": "A man is demonstrating and performing push-ups in a gym while another man observes and provides guidance.", "task": "ObjectRecognition", "clean_prompt": "A man is demonstrating and performing push-ups in a gym while another man observes and provides guidance.", "clean_property": {"obj": "person_2"}, "target_prompt": "A woman is demonstrating and performing push-ups in a gym while another woman observes and provides guidance.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person performing push-ups in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating and performing push-ups in a gym while another man observes and provides guidance. /SL\u00b7#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0be5381bfa3c43d4abb12f452d6ac075.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2a5d187fb9324a56b198fcc4d6b155b3", "source": "vatex", "video_id": "kpSzc3d6cD0_000072_000082", "video_description": "A woman is grooming a brown horse using a brush in an outdoor stable or ranch setting.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a horse in an outdoor stable.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "horse"}, "target_prompt": "A person closer to the camera than a horse in an outdoor stable.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "horse"}, "evaluation_question": "Is the person **farther from the camera than** the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a horse in an outdoor stable. ))!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64aecf67548a4a09af1a8d0495fd4142.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0cabb6f6986446f78be3b40c73c76951", "source": "vatex", "video_id": "G571V9l2iT4_000095_000105", "video_description": "A young man is demonstrating how to properly tie and untie a necktie in a room.", "task": "ActionRecognition", "clean_prompt": "A person tying a necktie in a room.", "clean_property": {"obj": "person", "action": "tying necktie", "target": null}, "target_prompt": "A person untying a necktie in a room.", "target_property": {"obj": "person", "action": "untie necktie", "target": null}, "evaluation_question": "Is the person **tying** a necktie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a necktie in a room. HL-CW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc183f1dbde8455a934cb3da34b9a527.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4cab0a8daa5b4cd99a5f86abd9e3a39f", "source": "vatex", "video_id": "8IO0UDCb2vk_000076_000086", "video_description": "A man in winter gear, including a black and blue jacket, green pants, ski mask, and goggles, is snowboarding down a snowy mountain. He is using a selfie stick to film himself while hip-hop music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A person snowboarding down a snowy mountain while filming himself with a selfie stick.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing in the snow.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person snowboarding down a snowy mountain while filming himself with a selfie stick. =)D2X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7571bc44bbff4b5b9e93bdf176b87c32.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6aaf3e25bf9e467db8e78278e63658fa", "source": "vatex", "video_id": "heRgEoIeSxo_000015_000025", "video_description": "A young girl is sitting in her room, holding a phone and texting. Text bubbles appear on the screen as she types and reacts to messages.", "task": "ObjectRecognition", "clean_prompt": "A young girl is sitting in her room, holding a phone and texting.", "clean_property": {"obj": "phone"}, "target_prompt": "A young girl is sitting in her room, holding a tablet and browsing the internet.", "target_property": {"obj": "tablet"}, "evaluation_question": "Is the girl holding a **phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is sitting in her room, holding a phone and texting. ))!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cf0759eab96d41fcb820387f010028e0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2a8538904344214b632f19d16e7c362", "source": "vatex", "video_id": "WFHuy4Cv5qY_000116_000126", "video_description": "A woman is in a kitchen demonstrating how to cook scrambled eggs and place them on toast.", "task": "AttributeRecognition", "clean_prompt": "A woman chef demonstrating how to cook scrambled eggs and place them on toast.", "clean_property": {"obj": "woman", "attribute": "chef"}, "target_prompt": "A woman baker demonstrating how to bake a cake.", "target_property": {"obj": "woman", "attribute": "baker"}, "evaluation_question": "Is the woman a **chef**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman chef demonstrating how to cook scrambled eggs and place them on toast. *U0UU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a4f79ee4967d44e0a4a97c27d10398ad.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1f3acd227d81414e8a6ce1fe5192b253", "source": "vatex", "video_id": "81FISupw6KA_000000_000010", "video_description": "A man is in a gym working out on a lat pull down machine, adjusting weights and performing triceps exercises.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a lat pull down machine in a gym.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "lat pull down machine"}, "target_prompt": "A person closer to the camera than a lat pull down machine in a gym.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "lat pull down machine"}, "evaluation_question": "Is the person **farther from the camera than** the lat pull down machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a lat pull down machine in a gym. PD97T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1cdeee05ae914ace8284fd7059942a09.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "926728bf8a544042bf383c962d20d19a", "source": "vatex", "video_id": "aviyQnf06MI_000126_000136", "video_description": "A bearded man is exercising his arms using a pulley system on a weight lifting machine in front of a mirror at a gym.", "task": "ObjectRecognition", "clean_prompt": "A bearded man is exercising his arms using a pulley system on a weight lifting machine in front of a mirror at a gym.", "clean_property": {"obj": "mirror"}, "target_prompt": "A bearded man is exercising his arms using a pulley system on a weight lifting machine in front of a window at a gym.", "target_property": {"obj": "window"}, "evaluation_question": "Is the man exercising in front of a **mirror**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bearded man is exercising his arms using a pulley system on a weight lifting machine in front of a mirror at a gym. F''?:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2ab411f747ae401a85a45b907a60206a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "588473d6d9fa4c2cb0885af1bee05e4a", "source": "vatex", "video_id": "1d4ZOE0y3e4_000275_000285", "video_description": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while a fan blows air on her.", "task": "Counting", "clean_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while seven fans blow air on her.", "clean_property": {"obj": "fan", "count": "seven"}, "target_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while two fans blow air on her.", "target_property": {"obj": "fan", "count": "two"}, "evaluation_question": "Are there exactly **seven** fans blowing air on her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is sitting on a messy bed, folding clothes and placing them into a large suitcase while seven fans blow air on her. )BSDQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d47644fef6884d8e8519db8e228e93a2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c0138bb202a94b1bafd2e96f6090709b", "source": "vatex", "video_id": "NfqSmHuofN0_000066_000076", "video_description": "Two girls are sitting on a black couch in a large, high-tech room, wearing headphones and watching television.", "task": "Counting", "clean_prompt": "Three girls are sitting on a black couch in a large, high-tech room, wearing headphones and watching television.", "clean_property": {"obj": "couch", "count": "three"}, "target_prompt": "One girl is sitting on a red couch in a cozy living room, reading a book.", "target_property": {"obj": "couch", "count": "one"}, "evaluation_question": "Are there exactly **three** girls sitting on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls are sitting on a black couch in a large, high-tech room, wearing headphones and watching television. EHO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b14ecf88b4844d83a0f72457b6309b51.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "127f160c97a1422b807db24bd4dc65a6", "source": "vatex", "video_id": "X3mtDsWXRmo_000145_000155", "video_description": "A man is playing a drum set in his room, wearing a blue hat and using drumsticks.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a drum set in a room.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "drum set"}, "target_prompt": "A person closer to the camera than a drum set in a room.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "drum set"}, "evaluation_question": "Is the person farther from the camera than the drum set?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a drum set in a room. BSQ;Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/934f73eab9d14565adf267001ec1ab56.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "66bfa725ce7949d29deb548238650f5f", "source": "vatex", "video_id": "k0euT5ZLKBM_000042_000052", "video_description": "A family is carving pumpkins together. A woman demonstrates carving techniques to a boy, who is drawing and cutting a scary face on a pumpkin. A man and the boy are scooping out the insides of the pumpkin while discussing the jack-o-lantern.", "task": "Counting", "clean_prompt": "A woman demonstrates carving techniques to a boy, who is drawing and cutting a scary face on a pumpkin. Seven boys are scooping out the insides of the pumpkin while discussing the jack-o-lantern.", "clean_property": {"obj": "boy", "count": "seven"}, "target_prompt": "A woman demonstrates carving techniques to a boy, who is drawing and cutting a scary face on a pumpkin. Three boys are scooping out the insides of the pumpkin while discussing the jack-o-lantern.", "target_property": {"obj": "boy", "count": "three"}, "evaluation_question": "Are there exactly **seven** boys scooping out the insides of the pumpkin?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates carving techniques to a boy, who is drawing and cutting a scary face on a pumpkin. Seven boys are scooping out the insides of the pumpkin while discussing the jack-o-lantern. \u00b7FEO@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d3a870830bb4b8da8fcdee6b4c025cf.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b867c57de1664c1cb50967805b8176a6", "source": "vatex", "video_id": "fde0fnYJszI_000679_000689", "video_description": "A person is cooking scrambled eggs in a nonstick pan on a gas stove, using a spatula to stir and scoop the eggs.", "task": "SpatialUnderstanding", "clean_prompt": "A stove farther from the camera than an egg.", "clean_property": {"obj_1": "stove", "relation": "farther from the camera than", "obj_2": "egg"}, "target_prompt": "A stove closer to the camera than an egg.", "target_property": {"obj_1": "stove", "relation": "closer to the camera than", "obj_2": "egg"}, "evaluation_question": "Is the stove **farther from the camera than** the egg?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A stove farther from the camera than an egg. ;JJVO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f1229aae0024763b814fef3fb6fbcf8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cc334026c849461fb27864b38822b7f9", "source": "vatex", "video_id": "4VGwynLvXpM_000028_000038", "video_description": "A young boy wearing black headphones and a gray Superman shirt is playing a saxophone in a room.", "task": "ActionRecognition", "clean_prompt": "A boy playing a saxophone in a room.", "clean_property": {"obj": "boy", "action": "playing saxophone", "target": null}, "target_prompt": "A boy playing guitar in a room.", "target_property": {"obj": "boy", "action": "playing guitar", "target": null}, "evaluation_question": "Is the boy **playing** a saxophone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy playing a saxophone in a room. FE\u00b7V@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e002d5c460049d0a446b018815d3fa7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2ff187946e624a66a429b41c282c9023", "source": "vatex", "video_id": "Y5OvEb9zcgQ_000029_000039", "video_description": "A man is demonstrating and performing kite surfing on the ocean, using a single water ski and a kite. He is showing how to maintain control while being pulled by a parachute.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating kite surfing on the ocean using a single water ski.", "clean_property": {"obj": "water ski", "attribute": "single"}, "target_prompt": "A man demonstrating kite surfing on the ocean using double water skis.", "target_property": {"obj": "water ski", "attribute": "double"}, "evaluation_question": "Is the man using a **single** water ski?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating kite surfing on the ocean using a single water ski. @XQI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76fe3d6dbb584d1aaa8d92db709768c3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b3f5ef38f21b4667a7b56665247bcde9", "source": "vatex", "video_id": "mKDfxhXHMA4_000080_000090", "video_description": "A woman is holding a large, coiled snake close to her chest while explaining its behavior.", "task": "Counting", "clean_prompt": "A woman is holding two snakes close to her chest while explaining their behavior.", "clean_property": {"obj": "snake", "count": "two"}, "target_prompt": "A woman is holding one snake close to her chest while explaining its behavior.", "target_property": {"obj": "snake", "count": "one"}, "evaluation_question": "Are there exactly **two** snakes being held by the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is holding two snakes close to her chest while explaining their behavior. NKYE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c178be2500dd4dd5ad9a98dc580ad0d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cde9c7fda8234f75988d8b2258e887a1", "source": "vatex", "video_id": "NwDCShpRrMk_000000_000010", "video_description": "A group of people, including three individuals, are walking together on a snowy path, wearing boots and winter clothing.", "task": "Counting", "clean_prompt": "Four people walking together on a snowy path, wearing boots and winter clothing.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person walking alone on a snowy path, wearing boots and winter clothing.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people walking on the snowy path?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people walking together on a snowy path, wearing boots and winter clothing. ZFVEV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ca3c6fd3025e4b789f6b018ab757cea3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21624511fa874060808e811f013c258a", "source": "vatex", "video_id": "2Xk8Ax1rQcA_000000_000010", "video_description": "A person demonstrates how to sharpen a pencil using a manual pencil sharpener.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to sharpen a pencil using a manual pencil sharpener.", "clean_property": {"obj": "pencil sharpener", "attribute": "manual"}, "target_prompt": "A person demonstrating how to sharpen a pencil using an electric pencil sharpener.", "target_property": {"obj": "pencil sharpener", "attribute": "electric"}, "evaluation_question": "Is the pencil sharpener **manual**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to sharpen a pencil using a manual pencil sharpener. NK6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6b3d2a7f30449b997009fcabea27fbc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fbe1407ffe36480da50004225ba53d5e", "source": "vatex", "video_id": "9HTIw125wt8_000103_000113", "video_description": "A young male athlete is participating in a high jump event at an indoor track and field meet. He runs towards the high jump bar, jumps over it backwards, and lands on a mat while a crowd watches.", "task": "ActionRecognition", "clean_prompt": "An athlete participating in a high jump event at an indoor track and field meet.", "clean_property": {"obj": "athlete", "action": "high jump", "target": null}, "target_prompt": "An athlete participating in a long jump event at an indoor track and field meet.", "target_property": {"obj": "athlete", "action": "long jump", "target": null}, "evaluation_question": "Is the athlete **participating in a high jump** event?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete participating in a high jump event at an indoor track and field meet. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba824ae478844e2b9c2a231916f29750.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b21f15a187ae4c2a9a331889c04ba788", "source": "vatex", "video_id": "HJyq6PywM3U_000098_000108", "video_description": "A woman is demonstrating how to clean a toilet using a toilet brush and cleaning solution in a bathroom.", "task": "ActionRecognition", "clean_prompt": "A person cleaning a toilet in a bathroom.", "clean_property": {"obj": "person", "action": "cleaning toilet", "target": null}, "target_prompt": "A person cleaning the floor in a bathroom.", "target_property": {"obj": "person", "action": "cleaning floor", "target": null}, "evaluation_question": "Is the person **cleaning the toilet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning a toilet in a bathroom. !G*$B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a3858f0fefdd4fcab704f58d220c476b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7f09d4ddaed64a2f90e05ad0cf77e5e3", "source": "vatex", "video_id": "kHFf8SKW7f4_000001_000011", "video_description": "An ice sculptor demonstrates his skills using a power tool to an audience indoors, possibly in a classroom or kitchen setting.", "task": "ObjectRecognition", "clean_prompt": "An ice sculptor demonstrates his skills using a power tool to an audience indoors.", "clean_property": {"obj": "power tool"}, "target_prompt": "An ice sculptor demonstrates his skills using a paintbrush to an audience indoors.", "target_property": {"obj": "paintbrush"}, "evaluation_question": "Is the sculptor using a **power tool** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An ice sculptor demonstrates his skills using a power tool to an audience indoors. FE#XF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a9da13ebfcd4475a3bd3514281c551c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9de68f1fad264c4591932f09140247c7", "source": "vatex", "video_id": "RJ3fS6JkG2A_000109_000119", "video_description": "Two teams of hockey players are playing an ice hockey game in a stadium with music in the background. The game begins with a face-off as the referee drops the puck.", "task": "ObjectRecognition", "clean_prompt": "A referee dropping the puck to start a hockey game.", "clean_property": {"obj": "referee"}, "target_prompt": "A goalkeeper preparing for a penalty shot in a hockey game.", "target_property": {"obj": "goalkeeper"}, "evaluation_question": "Is the official in the video a **referee**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A referee dropping the puck to start a hockey game. ;3-SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fdf351fcf0e34e7b97b2cb28b499c85a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca447c262071442fb33a40bbcf83f8d1", "source": "vatex", "video_id": "qLA4yb5wAfE_000049_000059", "video_description": "A facility where leather is being prepared and inspected. A man and a woman walk through the factory, examining leather hanging and drying.", "task": "Counting", "clean_prompt": "Six people walking through a leather factory, examining leather hanging and drying.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Three people walking through a leather factory, examining leather hanging and drying.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **six** people walking through the leather factory?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people walking through a leather factory, examining leather hanging and drying. +FEMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64202640580644169b948413ea308cd2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0428979325804b0894b956cf302ea7d6", "source": "vatex", "video_id": "SCW-y8Slkuo_000000_000010", "video_description": "A group of boys are sitting around a desk in a classroom. One boy is tapping pencils on the desk to create a beat while another boy is singing or rapping. Other boys are sitting around, listening and participating in the musical activity.", "task": "ObjectRecognition", "clean_prompt": "A group of boys are sitting around a desk in a classroom, with one boy tapping pencils on the desk to create a beat while another boy is singing.", "clean_property": {"obj": "pencil"}, "target_prompt": "A group of boys are sitting around a desk in a classroom, with one boy tapping on a drum to create a beat while another boy is singing.", "target_property": {"obj": "drum"}, "evaluation_question": "Is the boy tapping on a **pencil**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of boys are sitting around a desk in a classroom, with one boy tapping pencils on the desk to create a beat while another boy is singing. TFEAA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/02c79d656cfd411ea346d986f99b9249.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e4461c97c3d4cd9beeda384398c5917", "source": "vatex", "video_id": "vwj04OqdYNk_000039_000049", "video_description": "A young girl demonstrates and explains how to use an asthma inhaler, occasionally flailing her arms playfully.", "task": "ActionRecognition", "clean_prompt": "A girl using an inhaler while playfully flailing her arms.", "clean_property": {"obj": "girl", "action": "using inhaler", "target": null}, "target_prompt": "A girl playing with a toy while flailing her arms.", "target_property": {"obj": "girl", "action": "playing with a toy", "target": null}, "evaluation_question": "Is the girl **using an inhaler**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl using an inhaler while playfully flailing her arms. 9@>1Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1a5522912f534676ae912a9f4b234f84.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46f39feb8a1549a9b8781e777533383d", "source": "vatex", "video_id": "9y1oMFLcwqs_000154_000164", "video_description": "A group of people, including two kids and a man, are building a snowman in a snowy field. One person is carrying a large snowball towards the others, while a woman is laughing in the background.", "task": "Counting", "clean_prompt": "Three kids building a snowman in a snowy field.", "clean_property": {"obj": "kid", "count": "three"}, "target_prompt": "One kid building a snowman in a snowy field.", "target_property": {"obj": "kid", "count": "one"}, "evaluation_question": "Are there exactly **three** kids building the snowman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three kids building a snowman in a snowy field. R|3F)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/29f93e92e121461aac68de654fd7fad5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1f5e0d3eeac43d9945eca74e9bfd7ef", "source": "vatex", "video_id": "vBMEK5jojD0_000067_000077", "video_description": "A woman in a dimly lit room appears to be crying and sniffling, then blows her nose with a tissue.", "task": "AttributeRecognition", "clean_prompt": "A person who appears to have a cold is crying and sniffling in a dimly lit room.", "clean_property": {"obj": "person", "attribute": "appears to have a cold"}, "target_prompt": "A person who appears to be happy is smiling and laughing in a brightly lit room.", "target_property": {"obj": "person", "attribute": "appears to be happy"}, "evaluation_question": "Is the person appearing to have a **cold**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who appears to have a cold is crying and sniffling in a dimly lit room. LPOZE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8cc97dd78a3a49f8abac7438cfdf4d1a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d553e6404f864a5b841134e28fd59e6b", "source": "vatex", "video_id": "XkM820TdELw_000009_000019", "video_description": "A commercial showcases a man using a machine to clean and sand hardwood floors, leaving them dust-free. The advertisement highlights a company's floor cleaning and finishing services.", "task": "ObjectRecognition", "clean_prompt": "A man using a machine to clean and sand hardwood floors.", "clean_property": {"obj": "man"}, "target_prompt": "A woman using a machine to clean and sand hardwood floors.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person using the machine a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a machine to clean and sand hardwood floors. ''?)*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/894e7db949794c4297e5d59acb0e1100.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a7e0d72780c840d8bf02c776614db3f4", "source": "vatex", "video_id": "R0oJNG1OsZ4_000000_000010", "video_description": "A bald man is sitting in a dark room, playing a small wind instrument, possibly a flute or ocarina, using his mouth and hands to produce a haunting tune.", "task": "Counting", "clean_prompt": "Seven people in a dark room, one of them is playing a small wind instrument, possibly a flute or ocarina, producing a haunting tune.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people in a brightly lit room, one of them is playing a guitar, producing a lively tune.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people in a dark room, one of them is playing a small wind instrument, possibly a flute or ocarina, producing a haunting tune. #HR-U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f75034080fdd401ea833868ee896bdc2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "646d46c58af6407ea98f64c26b9fbfd7", "source": "vatex", "video_id": "aXdAu4g7dAA_000000_000010", "video_description": "Two males are in a room, one tackles the other onto a bed.", "task": "Counting", "clean_prompt": "Three males are in a room, one tackles another onto a bed.", "clean_property": {"obj": "male_2", "count": "three"}, "target_prompt": "One male is in a room, sitting on a bed.", "target_property": {"obj": "male_2", "count": "one"}, "evaluation_question": "Are there exactly **three** males in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three males are in a room, one tackles another onto a bed. @BC@2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1c1585aa083d43e398f62e63c2fb6b35.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9167b4632ef84bff8b69068c1d073a9c", "source": "vatex", "video_id": "x6T2Wejr8W8_000024_000034", "video_description": "A woman is playing a saxophone while another woman dances in a kitchen.", "task": "AttributeRecognition", "clean_prompt": "A woman playing a saxophone in a kitchen while another woman dances.", "clean_property": {"obj": "woman_1", "attribute": "playing saxophone"}, "target_prompt": "A woman playing a violin in a kitchen while another woman dances.", "target_property": {"obj": "woman_1", "attribute": "playing violin"}, "evaluation_question": "Is the woman playing a **saxophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman playing a saxophone in a kitchen while another woman dances. '!G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/872d52ea346b406497d93cf5114b32c4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "58d4982ba2bb4220b4fc5ca7c6d604bc", "source": "vatex", "video_id": "0MC18taIzNU_000005_000015", "video_description": "In a classroom, two kids are using pens to create beats by drumming on their desks, while other students are present.", "task": "Counting", "clean_prompt": "Four kids drumming on their desks in a classroom.", "clean_property": {"obj": "desk", "count": "four"}, "target_prompt": "One kid drumming on a desk in a classroom.", "target_property": {"obj": "desk", "count": "one"}, "evaluation_question": "Are there exactly **four** desks being drummed on in the classroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four kids drumming on their desks in a classroom. /@RCV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2597b404344d469e96df89979770b3a1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03b12c7399344161b4f40b16e163055c", "source": "vatex", "video_id": "o-ctR6-CsCI_000078_000088", "video_description": "A man, who is a news reporter, and a bartender are at a bar. The man is holding a microphone and they are both enjoying drinks together.", "task": "ObjectRecognition", "clean_prompt": "A bartender serving drinks to a news reporter at a bar.", "clean_property": {"obj": "bartender"}, "target_prompt": "A chef preparing a meal in a restaurant kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **bartender**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bartender serving drinks to a news reporter at a bar. !#B%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dab1134dd2284153bae240719e9fbf76.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f8ca929f000463fb7cac7552e7f7d25", "source": "vatex", "video_id": "F-YLCbT_Vns_000000_000010", "video_description": "A blonde woman in a gym is using a weight machine to perform exercises targeting her upper body, including front arm pull-ups and forward raises.", "task": "ObjectRecognition", "clean_prompt": "A blonde woman in a gym is using a weight machine to perform exercises targeting her upper body.", "clean_property": {"obj": "weight machine"}, "target_prompt": "A blonde woman in a gym is running on a treadmill to improve her fitness.", "target_property": {"obj": "treadmill"}, "evaluation_question": "Is the woman using a **weight machine** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A blonde woman in a gym is using a weight machine to perform exercises targeting her upper body. !0DZV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1858f6d85aa4cc1ac3ebf312ec937a4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2600950b187d46de963daca8e4e577bc", "source": "vatex", "video_id": "r6QEw8m4yu4_000020_000030", "video_description": "Two men are engaged in a playful sword fight using long white plastic pipes in a backyard setting.", "task": "ObjectRecognition", "clean_prompt": "Two men are engaged in a playful sword fight using long white plastic pipes in a backyard setting.", "clean_property": {"obj": "person"}, "target_prompt": "Two women are engaged in a playful sword fight using long white plastic pipes in a backyard setting.", "target_property": {"obj": "woman"}, "evaluation_question": "Are the participants in the video **men**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are engaged in a playful sword fight using long white plastic pipes in a backyard setting. @K''", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8fc0ce2e773a4e389ed22fca518b6a96.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "25251924c2c94a3d8b42d4f953caa862", "source": "vatex", "video_id": "DOtYZKD81A4_000000_000010", "video_description": "A person is baking chocolate chip cookies and muffins using unconventional methods, such as baking on the underside of a pan and using a microwave.", "task": "ActionRecognition", "clean_prompt": "A person baking chocolate chip cookies using unconventional methods.", "clean_property": {"obj": "person", "action": "baking cookies", "target": "cookie dough"}, "target_prompt": "A person burning cookie dough in a microwave.", "target_property": {"obj": "person", "action": "burning cookies", "target": "cookie dough"}, "evaluation_question": "Is the person **baking cookies**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person baking chocolate chip cookies using unconventional methods. SL=\u00b7R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0573b13943184f728476918e0ad10d45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "41657a1201fd482d8324a88f954d9f6b", "source": "vatex", "video_id": "f5ahf8XwzSw_000008_000018", "video_description": "A girls' volleyball game is taking place in a school gym. The teams are getting into position, and a player is preparing to serve the ball.", "task": "ObjectRecognition", "clean_prompt": "A volleyball player is preparing to serve the ball in a school gym during a girls' volleyball game.", "clean_property": {"obj": "volleyball player"}, "target_prompt": "A basketball player is preparing to shoot the ball in a school gym during a girls' basketball game.", "target_property": {"obj": "basketball player"}, "evaluation_question": "Is the player in the video a **volleyball player**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A volleyball player is preparing to serve the ball in a school gym during a girls' volleyball game. PLFEK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35506806b35244ae96d6f17b1127a1fb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "984053543da5455aa1d948d3d3a40a3a", "source": "vatex", "video_id": "q4IByVNoML4_000128_000138", "video_description": "A man is demonstrating and explaining how to tie various knots, including a square knot, using a rope.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to tie various knots using a thick rope.", "clean_property": {"obj": "rope", "attribute": "thick"}, "target_prompt": "A man is demonstrating how to tie various knots using a thin rope.", "target_property": {"obj": "rope", "attribute": "thin"}, "evaluation_question": "Is the rope being used thick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to tie various knots using a thick rope. 68CKV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2753b82f0167417baa2237f81cc0a743.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "67ddec9dbd80454c96e622941721000b", "source": "vatex", "video_id": "G4gp1gApVVE_000058_000068", "video_description": "A person demonstrates various techniques for folding napkins into decorative shapes on a table.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrates various techniques for folding napkins into decorative shapes on a table.", "clean_property": {"obj": "napkin"}, "target_prompt": "A person demonstrates various techniques for arranging a tablecloth on a table.", "target_property": {"obj": "tablecloth"}, "evaluation_question": "Is the object being folded in the video a **napkin**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrates various techniques for folding napkins into decorative shapes on a table. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4bdf8702faf649d3a4a1d92c17c171b4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3521cc7cc2e74ce29690557547029656", "source": "vatex", "video_id": "jOC7hIYc9hY_000003_000013", "video_description": "A woman is instructing on how to write the letter 'K' using a blue marker on a whiteboard.", "task": "Counting", "clean_prompt": "A woman is instructing on how to write the letter 'K' using a blue marker on three whiteboards.", "clean_property": {"obj": "whiteboard", "count": "three"}, "target_prompt": "A woman is instructing on how to write the letter 'K' using a blue marker on one whiteboard.", "target_property": {"obj": "whiteboard", "count": "one"}, "evaluation_question": "Are there exactly **three** whiteboards being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is instructing on how to write the letter 'K' using a blue marker on three whiteboards. $FOS6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1078543b1de24e1787eb5c41509ee2ea.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "68f3d845f55c4c3abd171147b25026b4", "source": "vatex", "video_id": "2HiDlFDURVs_000019_000029", "video_description": "A baby is sitting in a kitchen, playing with a green whistle by blowing it, while an adult laughs and records the moment.", "task": "AttributeRecognition", "clean_prompt": "An adult laughing while recording a baby playing with a green whistle in the kitchen.", "clean_property": {"obj": "adult", "attribute": "laughing"}, "target_prompt": "An adult crying while recording a baby playing with a green whistle in the kitchen.", "target_property": {"obj": "adult", "attribute": "crying"}, "evaluation_question": "Is the adult **laughing** while recording?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult laughing while recording a baby playing with a green whistle in the kitchen. -XSBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/09ef848a8b6f4252b689cc93c9abe5a9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2134e5aab69e4342ae43f389eaad4c88", "source": "vatex", "video_id": "5iLZs5BDXrk_000209_000219", "video_description": "A man with glasses stands in front of a digital board, discussing math and financial calculations in Portuguese and Spanish.", "task": "ActionRecognition", "clean_prompt": "A person testifying in front of a digital board.", "clean_property": {"obj": "person", "action": "testifying", "target": null}, "target_prompt": "A person debating in front of a digital board.", "target_property": {"obj": "person", "action": "debating", "target": null}, "evaluation_question": "Is the person **testifying**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person testifying in front of a digital board. VT#R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e055aa2dbcb0416784dd6384435c9661.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f72552611b0c4b4b8c5eb26fb6d78cc6", "source": "vatex", "video_id": "4d6Ch7lhz5w_000000_000010", "video_description": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "task": "ObjectRecognition", "clean_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking.", "clean_property": {"obj": "hair dryer"}, "target_prompt": "A man is in a kitchen using a toaster to toast bread while singing and speaking.", "target_property": {"obj": "toaster"}, "evaluation_question": "Is the man using a **hair dryer** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is in a bathroom using a hair dryer to dry his hair and body while singing and speaking. 8MOEZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b817b7d62ba842fe9d7a5f887b7ebe75.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2152ac04b4244be69ea04730ac6a7ddd", "source": "vatex", "video_id": "dbJujs8UPFI_000000_000010", "video_description": "A young man in a turquoise shirt is practicing knife throwing in a field or park-like area. He runs, jumps, and throws a knife at a wooden target, celebrating when he hits the target.", "task": "Counting", "clean_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice.", "clean_property": {"obj": "target", "count": "two"}, "target_prompt": "A young man in a turquoise shirt is practicing knife throwing at a single wooden target in a park.", "target_property": {"obj": "target", "count": "one"}, "evaluation_question": "Are there exactly **two** targets in the park?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in a turquoise shirt is practicing knife throwing at a wooden target in a park, celebrating when he hits the target twice. SBSFB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/104bfaf77f374472b2c28ceae0bae0e0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c460b947f7a4c5086c715bec2e9ad79", "source": "vatex", "video_id": "O-Hy9k_Kf3c_000019_000029", "video_description": "A man in a suit and tie is demonstrating and explaining how to make balloon animals, including shaping a balloon into an elephant.", "task": "ActionRecognition", "clean_prompt": "A person making balloon shapes at a party.", "clean_property": {"obj": "person", "action": "making balloon shapes", "target": "balloon"}, "target_prompt": "A person popping balloon shapes at a party.", "target_property": {"obj": "person", "action": "popping balloon shapes", "target": "balloon"}, "evaluation_question": "Is the person **making** balloon shapes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making balloon shapes at a party. )))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ab50b109f87b417eb25f9450b00e9ef8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c932e74e1e84f319a370b51b3f222a2", "source": "vatex", "video_id": "48gF4_ZaHYU_000000_000010", "video_description": "A baby is crawling on the floor towards a colorful soccer ball.", "task": "ObjectRecognition", "clean_prompt": "A baby is crawling on the floor towards a colorful soccer ball.", "clean_property": {"obj": "baby"}, "target_prompt": "A puppy is crawling on the floor towards a colorful soccer ball.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the animal in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is crawling on the floor towards a colorful soccer ball. !B*3U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd143df5de9e4e43a63d866bba18da16.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9261e098bf964025979be61dc9152113", "source": "vatex", "video_id": "eC57cPqt5VU_000018_000028", "video_description": "Three couples are performing a synchronized, lively Charleston dance routine on a wooden dance floor in a studio setting.", "task": "Counting", "clean_prompt": "Seven couples are performing a synchronized, lively Charleston dance routine on a wooden dance floor in a studio setting.", "clean_property": {"obj": "dance floor", "count": "seven"}, "target_prompt": "Three couples are performing a synchronized, lively Charleston dance routine on a colorful dance floor in a vibrant outdoor setting.", "target_property": {"obj": "dance floor", "count": "three"}, "evaluation_question": "Are there exactly **seven** couples on the dance floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven couples are performing a synchronized, lively Charleston dance routine on a wooden dance floor in a studio setting. >BC4T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f53ac2a924f7461eb5cc17704ea625ac.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc2bd76f83564eecbe16f160bc864a71", "source": "vatex", "video_id": "j3gkkOVrtH8_000017_000027", "video_description": "A young boy is playfully using a metal head massager on a woman's head, making comical facial expressions.", "task": "AttributeRecognition", "clean_prompt": "A young boy is playfully using a metal head massager on a woman's head, making comical facial expressions.", "clean_property": {"obj": "head massager", "attribute": "metal"}, "target_prompt": "A young boy is playfully using a plastic head massager on a woman's head, making comical facial expressions.", "target_property": {"obj": "head massager", "attribute": "plastic"}, "evaluation_question": "Is the head massager made of **metal**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is playfully using a metal head massager on a woman's head, making comical facial expressions. FEXSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4598eae7ddbc4c3784ea80afdd29c657.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c087ea623fd945849d679f4ee702132d", "source": "vatex", "video_id": "D9QhY6ecmrw_000006_000016", "video_description": "A young man is demonstrating and explaining how to solve a Rubik's Cube, showing various techniques and strategies.", "task": "ActionRecognition", "clean_prompt": "A person playing with a Rubik's Cube, demonstrating various techniques.", "clean_property": {"obj": "person", "action": "playing rubiks cube", "target": null}, "target_prompt": "A person throwing a Rubik's Cube.", "target_property": {"obj": "person", "action": "throwing a Rubik's Cube", "target": null}, "evaluation_question": "Is the person **playing** with a Rubik's Cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing with a Rubik's Cube, demonstrating various techniques. OT\u00b7?E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/feb61c9f491e4ddfb1b9002dda4d059b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31be525e09b44459ab2862d9333abc43", "source": "vatex", "video_id": "baEoQJbrqP0_000143_000153", "video_description": "A cowboy in a rodeo arena is participating in a calf roping competition. He ropes a calf, ties its legs, and then returns to his horse.", "task": "SpatialUnderstanding", "clean_prompt": "A calf to the right of a cowboy in a rodeo arena.", "clean_property": {"obj_1": "calf", "relation": "right of", "obj_2": "cowboy"}, "target_prompt": "A calf to the left of a cowboy in a rodeo arena.", "target_property": {"obj_1": "calf", "relation": "left of", "obj_2": "cowboy"}, "evaluation_question": "Is the calf to the **right** of the cowboy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A calf to the right of a cowboy in a rodeo arena. W%U!B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bda5e88fe92f45d285ca684fe2863f8f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d958fefd2ea3499ca09d4112e0dac13c", "source": "vatex", "video_id": "f48POlM6Hzg_000081_000091", "video_description": "A trainer is guiding a man in an orange top on how to use a weight machine for arm exercises in a gym.", "task": "ObjectRecognition", "clean_prompt": "A trainer is guiding a man in an orange top on how to use a weight machine for arm exercises in a gym.", "clean_property": {"obj": "trainer"}, "target_prompt": "A yoga instructor is guiding a woman in a blue top on how to perform a yoga pose in a studio.", "target_property": {"obj": "yoga instructor"}, "evaluation_question": "Is the person in the video a **trainer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A trainer is guiding a man in an orange top on how to use a weight machine for arm exercises in a gym. ,BCQW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a9e8445ba9384f8996f0295a654fb01c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2dbb0c57557492d9298f1cb4620c6ba", "source": "vatex", "video_id": "_coN0M7JWg4_000003_000013", "video_description": "A group of men are working together to build a brick wall using mortar and bricks. Some men are standing on a scaffold platform, pouring mortar, while others are mixing it on the ground.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the right of a mortar.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "mortar"}, "target_prompt": "A man standing to the left of a mortar.", "target_property": {"obj_1": "man", "relation": "left of", "obj_2": "mortar"}, "evaluation_question": "Is the man to the **right** of the mortar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the right of a mortar. @|SR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2938352d5be54ef1b7d450b8dbbe233f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c5b5ef4b0bc1445ca9d4a2b494ee2159", "source": "vatex", "video_id": "1sVu94u4bm0_000042_000052", "video_description": "Two men are in a bathroom, whistling harmoniously like birds while one dries his hair and face with a towel.", "task": "ActionRecognition", "clean_prompt": "A person whistling in a bathroom.", "clean_property": {"obj": "person", "action": "whistling", "target": null}, "target_prompt": "A person singing a song in a bathroom.", "target_property": {"obj": "person", "action": "singing", "target": "song"}, "evaluation_question": "Is the person **whistling**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person whistling in a bathroom. >;S\u00b70", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/771f1cb826ce410c86791ced0434919b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b1243f6993d34142bcaab9c9646f07ef", "source": "vatex", "video_id": "0aSmZ91nawo_000060_000070", "video_description": "Two women are involved in an exercise demonstration. One woman is holding a baby while squeezing a red exercise ball between her legs, and the other woman is instructing the exercise.", "task": "ObjectRecognition", "clean_prompt": "A woman holding a baby while squeezing a red exercise ball between her legs, with another woman instructing the exercise.", "clean_property": {"obj": "baby"}, "target_prompt": "A woman holding a puppy while squeezing a red exercise ball between her legs, with another woman instructing the exercise.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the woman holding a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman holding a baby while squeezing a red exercise ball between her legs, with another woman instructing the exercise. >%BSA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1d74ebb2490c4b5cb690b6aa0e30203b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c5bbe9cb1d844899a7c519e829db80e3", "source": "vatex", "video_id": "-iruowAZ8Fw_000580_000590", "video_description": "A woman, acting as a massage therapist, is giving a professional back massage to another person lying face down on a massage table. The therapist applies oil or lotion to her hands before massaging the client's back. Acoustic guitar music plays in the background.", "task": "Counting", "clean_prompt": "A woman is giving a professional back massage to a client lying face down on one of four massage tables, applying oil to her hands before starting the massage, with acoustic guitar music playing in the background.", "clean_property": {"obj": "massage table", "count": "four"}, "target_prompt": "A woman is giving a professional back massage to a client lying face down on one massage table, applying oil to her hands before starting the massage, with acoustic guitar music playing in the background.", "target_property": {"obj": "massage table", "count": "one"}, "evaluation_question": "Are there exactly **four** massage tables in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is giving a professional back massage to a client lying face down on one of four massage tables, applying oil to her hands before starting the massage, with acoustic guitar music playing in the background. LFE&C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3df815a6560c4f4aad802bd42b0a3199.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "855dbf1ba19c4fb1a4e008985a24178c", "source": "vatex", "video_id": "14J5Jix2IFc_000000_000010", "video_description": "A young African American man is sitting in a room by himself, playing a song on a trumpet while wearing a Nike shirt.", "task": "ActionRecognition", "clean_prompt": "A person playing trumpet in a room.", "clean_property": {"obj": "person", "action": "playing trumpet", "target": null}, "target_prompt": "A person playing guitar in a room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing trumpet in a room. R%D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be73cb181a854cf7b85b532e849257ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a5911e5426444b483df48f24444be13", "source": "vatex", "video_id": "-50SqYJdxL8_000347_000357", "video_description": "A person is demonstrating flintknapping techniques to shape and shine a dark rock using another rock, with narration explaining the process.", "task": "Counting", "clean_prompt": "A person is demonstrating flintknapping techniques with three small rocks, shaping and shining a dark rock using another rock, while explaining the process.", "clean_property": {"obj": "small rock", "count": "three"}, "target_prompt": "A person is demonstrating flintknapping techniques with one large boulder, shaping and shining it using another rock, while explaining the process.", "target_property": {"obj": "large boulder", "count": "one"}, "evaluation_question": "Are there exactly **three** small rocks being used in the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating flintknapping techniques with three small rocks, shaping and shining a dark rock using another rock, while explaining the process. TYQ@U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0224db8a698441a9a676ec1a9f37ef2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "38ae6f262ba7476ab8f1b5fda2d18b10", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "clean_property": {"obj": "paper"}, "target_prompt": "A person demonstrating painting by creating a colorful landscape on a canvas using a brush.", "target_property": {"obj": "canvas"}, "evaluation_question": "Is the person using **paper** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper. C/!))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0dba68c8a0f648a48a30ea9fb98e6f18.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "24f0d06647404eb0afae8e5181abdf25", "source": "vatex", "video_id": "5Ka89vMcQyc_000000_000010", "video_description": "A young boy in a blue shirt rides a bicycle over a small ramp in a suburban street, making a jump and landing.", "task": "ActionRecognition", "clean_prompt": "A boy jumping on a bicycle in a suburban street.", "clean_property": {"obj": "boy", "action": "jumping bicycle", "target": null}, "target_prompt": "A boy falling off a bicycle in a suburban street.", "target_property": {"obj": "boy", "action": "falling off bicycle", "target": null}, "evaluation_question": "Is the boy **jumping** on the bicycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy jumping on a bicycle in a suburban street. XFC@P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/27a62c8e8cff41bd9eddeb2e069f82c6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6ac11e7668fa4c1289820c0b167870db", "source": "vatex", "video_id": "5I6SExMZdvw_000009_000019", "video_description": "Two men are riding Segways indoors, with one man spinning in circles with assistance from the other.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a Segway.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "Segway"}, "target_prompt": "A person closer to the camera than a Segway.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "Segway"}, "evaluation_question": "Is the person **farther from the camera than** the Segway?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a Segway. ))''!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/069483aa71eb49c48031deb371b789d4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "61cfc103447f469bb2cf7126b04af907", "source": "vatex", "video_id": "sNBYqV4_dr0_000038_000048", "video_description": "A man is in his bathroom trimming and shaving his beard using an electric razor while looking into a mirror.", "task": "Counting", "clean_prompt": "Two people in a bathroom trimming and shaving their beards using electric razors while looking into mirrors.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person in a bathroom trimming and shaving his beard using an electric razor while looking into a mirror.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in a bathroom trimming and shaving their beards using electric razors while looking into mirrors. 7WR,H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb1f2524c8bb40dfb63e975901099526.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab0b4fcb820a41bcbdd92aed866396d1", "source": "vatex", "video_id": "7s1oCiXTpek_000000_000010", "video_description": "A young child is in a classroom writing notes on paper with a red pen while holding a phone. Other children are talking in the background.", "task": "ActionRecognition", "clean_prompt": "A child writing notes on paper in a classroom.", "clean_property": {"obj": "child", "action": "writing", "target": "paper"}, "target_prompt": "A child drawing on a canvas in an art studio.", "target_property": {"obj": "child", "action": "drawing", "target": "canvas"}, "evaluation_question": "Is the child **writing** on paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child writing notes on paper in a classroom. !AQ!V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7f517769b6a4eec8cf4864605e37ef5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b748034a2b7b489ea60d085876abb62a", "source": "vatex", "video_id": "3onYzggNVk8_000000_000010", "video_description": "A group of children are playing ice hockey on an ice rink, with one young boy prominently moving the puck while wearing hockey gear. Spectators are watching the game.", "task": "ObjectRecognition", "clean_prompt": "A group of children playing ice hockey on an ice rink, with one young boy moving the puck while wearing hockey gear.", "clean_property": {"obj": "child"}, "target_prompt": "A group of adults playing ice hockey on an ice rink, with one man moving the puck while wearing hockey gear.", "target_property": {"obj": "adult"}, "evaluation_question": "Is there a **child** playing ice hockey in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children playing ice hockey on an ice rink, with one young boy moving the puck while wearing hockey gear. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b48bad82af74d7a8101e04109977157.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99ca6e9f495f4eb58b506608d275ebbb", "source": "vatex", "video_id": "yjtBhdBVtNM_000020_000030", "video_description": "A person base jumps from a cliff in a desert mountain setting, deploying a pink and purple parachute as they fall.", "task": "ActionRecognition", "clean_prompt": "A person base jumping from a cliff in a desert mountain setting, deploying a pink and purple parachute as they fall.", "clean_property": {"obj": "person", "action": "base jumping", "target": null}, "target_prompt": "A person skydiving from an airplane over a tropical beach.", "target_property": {"obj": "person", "action": "skydiving", "target": null}, "evaluation_question": "Is the person **base jumping**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person base jumping from a cliff in a desert mountain setting, deploying a pink and purple parachute as they fall. KMV/?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dcebb88e119e43bda397c0dc283c1f12.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b626936acac845a9a28cea7d67bd2921", "source": "vatex", "video_id": "zgHQsd5Mgec_000024_000034", "video_description": "A woman is leading a horse by its reins across an enclosed outdoor area, walking towards the camera.", "task": "AttributeRecognition", "clean_prompt": "A woman leading a black horse by its reins across an enclosed outdoor area, walking towards the camera.", "clean_property": {"obj": "horse", "attribute": "black"}, "target_prompt": "A woman leading a white horse by its reins across an enclosed outdoor area, walking towards the camera.", "target_property": {"obj": "horse", "attribute": "white"}, "evaluation_question": "Is the horse **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman leading a black horse by its reins across an enclosed outdoor area, walking towards the camera. >BCBZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6d525cb810724136b0fa06fc63078d27.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "244945cd12eb4737aa9fdaa193053b1c", "source": "vatex", "video_id": "EgEal38NxQY_000013_000023", "video_description": "A young boy is riding a mechanical bull outside at night, with music playing in the background. He raises his hand above his head while being spun around.", "task": "SpatialUnderstanding", "clean_prompt": "A boy closer to the camera than a mechanical bull.", "clean_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "mechanical bull"}, "target_prompt": "A boy further from the camera than a mechanical bull.", "target_property": {"obj_1": "boy", "relation": "further from the camera than", "obj_2": "mechanical bull"}, "evaluation_question": "Is the boy **closer to the camera than** the mechanical bull?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy closer to the camera than a mechanical bull. ''))!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c634dccc991646f0b0467e37ec372043.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9ecca2e15e6043e88fb409f316cbb78e", "source": "vatex", "video_id": "cid7HhG8TH0_000085_000095", "video_description": "Two young children, a boy and a girl, are having a water balloon fight outside near an inflatable swimming pool. They are in their swimsuits, grabbing water balloons from the pool and throwing them at each other while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "Two young children are having a water balloon fight outside near an inflatable swimming pool.", "clean_property": {"obj": "balloon"}, "target_prompt": "Two young children are playing with a beach ball outside near an inflatable swimming pool.", "target_property": {"obj": "beach ball"}, "evaluation_question": "Are the children playing with **water balloons**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young children are having a water balloon fight outside near an inflatable swimming pool. SL>4.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c11cb7df67d44318b81319af13b05c5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6109fca0cc34d259a608ee7e19cb1df", "source": "vatex", "video_id": "6BdzOSFXqiA_000009_000019", "video_description": "A large group of people are skating and dancing on an ice rink, enjoying music and laughing.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of an ice rink.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "ice rink"}, "target_prompt": "A person standing to the right of an ice rink.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "ice rink"}, "evaluation_question": "Is the person to the **left** of the ice rink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of an ice rink. )''!R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/85e37fc6baf644d08e7826ab14c0c21d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3ecdf6da42e649078d2acb83d759b6d5", "source": "vatex", "video_id": "th9TRkTPLE0_000072_000082", "video_description": "A man wearing glasses is using a circular saw to cut through a metal railing outdoors.", "task": "AttributeRecognition", "clean_prompt": "A man wearing glasses is using an electric circular saw to cut through a metal railing outdoors.", "clean_property": {"obj": "circular saw", "attribute": "electric"}, "target_prompt": "A man wearing glasses is using a manual circular saw to cut through a metal railing outdoors.", "target_property": {"obj": "circular saw", "attribute": "manual"}, "evaluation_question": "Is the circular saw **electric**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing glasses is using an electric circular saw to cut through a metal railing outdoors. )FEY@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a44f8a72a8b54a7e8c941da5d77602ee.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "76430ee1f7ab4578a096e09db3553707", "source": "vatex", "video_id": "N1J1AgIV0dE_000051_000061", "video_description": "A person from fire rescue demonstrates how to tie various complex knots using a large orange rope.", "task": "ObjectRecognition", "clean_prompt": "A person from fire rescue demonstrates how to tie various complex knots using a large orange rope.", "clean_property": {"obj": "person"}, "target_prompt": "A robot demonstrating how to tie various complex knots using a large orange rope.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the demonstrator in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person from fire rescue demonstrates how to tie various complex knots using a large orange rope. =AR'U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9c4b056ee0c541e6b104b2622fa51a88.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc12ec646a1f48b6ab980cde7e94695f", "source": "vatex", "video_id": "aP6H0P0fchE_000000_000010", "video_description": "A man and a woman are seated at a table in a restaurant. The man presents a ring in a jewelry box to the woman by sliding it across the table.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a jewelry box.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "jewelry box"}, "target_prompt": "A man closer to the camera than a jewelry box.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "jewelry box"}, "evaluation_question": "Is the man **farther from the camera than** the jewelry box?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a jewelry box. )\u00b7G*E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c1f43d6d3134330aeb32af3018f2500.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9917afb4a4a446db0afce9323d1e56a", "source": "vatex", "video_id": "fGhmbpcqqu8_000016_000026", "video_description": "A man is practicing his golf swing on a golf course, hitting a golf ball with a club and watching where it goes.", "task": "Counting", "clean_prompt": "A man practicing his golf swing with four golf clubs on a golf course.", "clean_property": {"obj": "golf club", "count": "four"}, "target_prompt": "A man practicing his golf swing with one golf club on a golf course.", "target_property": {"obj": "golf club", "count": "one"}, "evaluation_question": "Are there exactly **four** golf clubs being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man practicing his golf swing with four golf clubs on a golf course. )?G*G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/08e6ee5d23a34207af2fa13a585e7913.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f782c5852d3640eebead2fd73bb36850", "source": "vatex", "video_id": "7aqST6yt4mA_000013_000023", "video_description": "A man and a woman are sitting on a couch discussing and comparing different types of cell phones, including a Blackberry with a keyboard and a modern Android phone with a touchscreen.", "task": "Counting", "clean_prompt": "Five women sitting on a couch discussing different types of cell phones.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman sitting on a couch discussing cell phones.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women sitting on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women sitting on a couch discussing different types of cell phones. QR%%0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed3190a371944654abbfdb46ca8941ac.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31887521469f46459d57a8e5245042eb", "source": "vatex", "video_id": "V4ynfFv-EqE_000021_000031", "video_description": "A bald man in a white shirt is beatboxing and dancing in a colorful, well-lit room, possibly a television show stage, while holding a microphone.", "task": "ObjectRecognition", "clean_prompt": "A bald man in a white shirt beatboxing and dancing in a colorful, well-lit room.", "clean_property": {"obj": "person"}, "target_prompt": "A woman beatboxing and dancing in a colorful, well-lit room.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the performer in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bald man in a white shirt beatboxing and dancing in a colorful, well-lit room. ?'G*U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f21f1de5ae1c43c2ae395fe4a1e87157.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad096c713c1a4900a3ec4c75dc0e4f23", "source": "vatex", "video_id": "9lWWueOKL6Y_000025_000035", "video_description": "A woman is demonstrating a crafting technique using a dog-shaped cookie cutter to needle felt a pink wool dog design onto a sweater.", "task": "AttributeRecognition", "clean_prompt": "A woman is demonstrating a crafting technique using a dog-shaped cookie cutter to needle felt a pink wool dog design onto a sweater.", "clean_property": {"obj": "cookie cutter", "attribute": "dog-shaped"}, "target_prompt": "A woman is demonstrating a crafting technique using a star-shaped cookie cutter to needle felt a pink wool star design onto a sweater.", "target_property": {"obj": "cookie cutter", "attribute": "star-shaped"}, "evaluation_question": "Is the cookie cutter **dog-shaped**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating a crafting technique using a dog-shaped cookie cutter to needle felt a pink wool dog design onto a sweater. SL18O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fe42a33d565244bdbbf6aeda7942a9ec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b59b9f0ac1964d8ea38441c585d41c1c", "source": "vatex", "video_id": "StPYHQh2yuI_000023_000033", "video_description": "A horse auction is taking place in a large meeting hall. A man is handling a white horse on stage while an auctioneer calls for bids from the audience.", "task": "SpatialUnderstanding", "clean_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction.", "clean_property": {"obj_1": "handler", "relation": "farther from the camera than", "obj_2": "audience"}, "target_prompt": "A handler closer to the camera than the audience in a large meeting hall during a horse auction.", "target_property": {"obj_1": "handler", "relation": "closer to the camera than", "obj_2": "audience"}, "evaluation_question": "Is the handler farther from the camera than the audience?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A handler farther from the camera than the audience in a large meeting hall during a horse auction. )&)!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33be677c9916438a9dec43db7753fa24.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c107ee73a054103a71b331130f6131e", "source": "vatex", "video_id": "7MyTgwfQ7IU_000032_000042", "video_description": "A person in a robot costume is performing a robot dance in a warehouse or factory setting.", "task": "ObjectRecognition", "clean_prompt": "A person in a robot costume is performing a robot dance in a warehouse.", "clean_property": {"obj": "person"}, "target_prompt": "An animal performing a dance in a warehouse.", "target_property": {"obj": "animal"}, "evaluation_question": "Is the performer in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in a robot costume is performing a robot dance in a warehouse. BSZUK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4c5fcad763e442ae8cf2b53b7b43c669.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d6c6b83364514dfbabd2a56a62fa77ae", "source": "vatex", "video_id": "n1NdNyY2T_w_000187_000197", "video_description": "Two men are competing in a sheep shearing contest in front of a large crowd seated in bleachers.", "task": "ActionRecognition", "clean_prompt": "A shearer shearing sheep in front of a large crowd.", "clean_property": {"obj": "shearer", "action": "shearing sheep", "target": "sheep"}, "target_prompt": "A shearer shearing goats in front of a large crowd.", "target_property": {"obj": "shearer", "action": "shearing sheep", "target": "goats"}, "evaluation_question": "Is the shearer **shearing sheep**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A shearer shearing sheep in front of a large crowd. XR9GB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4bba644d7e844301a48174227c69aab4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f3d76b79145432c855f1739ba8a5685", "source": "vatex", "video_id": "OFCEoK9pTNc_000013_000023", "video_description": "A man is demonstrating how to make a cheese sandwich using white bread and American cheese.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to make a cheese sandwich using white bread and American cheese.", "clean_property": {"obj": "cheese", "attribute": "American"}, "target_prompt": "A man is demonstrating how to make a cheese sandwich using white bread and cheddar cheese.", "target_property": {"obj": "cheese", "attribute": "cheddar"}, "evaluation_question": "Is the cheese used in the sandwich **American**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to make a cheese sandwich using white bread and American cheese. ))!D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a37664f769a4efbb964c497918efc89.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c13fe5e171e643979c1d86dc973fbd83", "source": "vatex", "video_id": "_dVS8WB3HCc_000000_000010", "video_description": "A worker is performing maintenance on a tall glass skyscraper, walking on the ledge and entering through an open window.", "task": "ObjectRecognition", "clean_prompt": "A worker performing maintenance on a tall glass skyscraper, walking on the ledge and entering through an open window.", "clean_property": {"obj": "worker"}, "target_prompt": "An artist painting a mural on the side of a tall building.", "target_property": {"obj": "artist"}, "evaluation_question": "Is the person in the video a **worker**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A worker performing maintenance on a tall glass skyscraper, walking on the ledge and entering through an open window. OF)SN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b1e60975618c431db38f292b4a905a8b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b9718bfb4bfd48b49b4b56d0a56f7dde", "source": "vatex", "video_id": "nF7ymCE2KQA_000009_000019", "video_description": "An actor dressed as Abraham Lincoln is giving a speech to a large crowd of people outdoors, discussing a battle.", "task": "SpatialUnderstanding", "clean_prompt": "An actor dressed as Abraham Lincoln is closer to the camera than a crowd of people while giving a speech outdoors.", "clean_property": {"obj_1": "actor", "relation": "closer to the camera than", "obj_2": "crowd"}, "target_prompt": "An actor dressed as Abraham Lincoln is further from the camera than a crowd of people while giving a speech outdoors.", "target_property": {"obj_1": "actor", "relation": "further from the camera than", "obj_2": "crowd"}, "evaluation_question": "Is the actor closer to the camera than the crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An actor dressed as Abraham Lincoln is closer to the camera than a crowd of people while giving a speech outdoors. R=!':", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/62451239bd7f4c528502f9af71efa76b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5b1461fedd0c43cea4d2f1873463e48b", "source": "vatex", "video_id": "8GcGjOTkccQ_000001_000011", "video_description": "A little boy attempts to hit a baseball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "task": "ObjectRecognition", "clean_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying.", "clean_property": {"obj": "ball"}, "target_prompt": "A little boy attempts to fly a kite on a windy day, but the kite gets stuck in a tree.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object the boy is trying to hit a **ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A little boy attempts to hit a ball with a bat, misses, and falls down concrete stairs, injuring himself and crying. SLJR|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ea53ec60fc6b46099e5c99657286d0c1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "84decc1b6bae4afb92fe34279e589dd0", "source": "vatex", "video_id": "53C61ZUEbSo_000063_000073", "video_description": "A young girl is demonstrating and explaining the features of a mini microscope, speaking in a foreign language.", "task": "Counting", "clean_prompt": "A young girl is demonstrating and explaining the features of a mini microscope, with seven people watching her attentively.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A young girl is demonstrating and explaining the features of a mini microscope, with three people watching her attentively.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is demonstrating and explaining the features of a mini microscope, with seven people watching her attentively. UG3BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38c64568ead44611bd7048ca5cdda922.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f5642a1472a24455a04d5beadb99b35b", "source": "vatex", "video_id": "s5DsShZWZME_000015_000025", "video_description": "A young boy wearing a cap rides a unicycle down the street while playing a small guitar on a sunny day.", "task": "SpatialUnderstanding", "clean_prompt": "A guitar to the left of a unicycle.", "clean_property": {"obj_1": "guitar", "relation": "left of", "obj_2": "unicycle"}, "target_prompt": "A guitar to the right of a unicycle.", "target_property": {"obj_1": "guitar", "relation": "right of", "obj_2": "unicycle"}, "evaluation_question": "Is the guitar to the **left** of a unicycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A guitar to the left of a unicycle. ;DJJ$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c04e129b4d874db491dbacd5205be7db.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d568267f6514a0dab718461c974a3c3", "source": "vatex", "video_id": "9iDxYw5NvuM_000161_000171", "video_description": "A group of people are playing a game of baseball in a large field with a cheering crowd.", "task": "SpatialUnderstanding", "clean_prompt": "A baseball player standing to the left of a baseball.", "clean_property": {"obj_1": "baseball player", "relation": "left of", "obj_2": "baseball"}, "target_prompt": "A baseball player standing to the right of a baseball.", "target_property": {"obj_1": "baseball player", "relation": "right of", "obj_2": "baseball"}, "evaluation_question": "Is the baseball player to the **left** of a baseball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baseball player standing to the left of a baseball. UF\u00b7>R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c2cc511dedc4317aaeafb1a333215b0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "53179d0918144d55aa12c569dc0785a0", "source": "vatex", "video_id": "m4-dmxE3nUU_000000_000010", "video_description": "A young boy is attempting to do push-ups on a rug while another older boy sits on the floor watching and cheering him on.", "task": "ActionRecognition", "clean_prompt": "A young boy doing push-ups on a rug while an older boy cheers him on.", "clean_property": {"obj": "young boy", "action": "push up", "target": null}, "target_prompt": "A young boy jumping on a rug while an older boy cheers him on.", "target_property": {"obj": "young boy", "action": "jumping", "target": null}, "evaluation_question": "Is the young boy **doing push-ups**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy doing push-ups on a rug while an older boy cheers him on. FEYIO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c994dc6fc8b4ec9be51bab10c5ec74f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aef1b6cd6c564acfae0d2ed41b25aa44", "source": "vatex", "video_id": "ho39MylZfM0_000000_000010", "video_description": "A woman in a purple sports bra with tattoos is stretching her arms in a living room.", "task": "Counting", "clean_prompt": "Six people are stretching their arms in a living room.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Three people are stretching their arms in a living room.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **six** people stretching their arms in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people are stretching their arms in a living room. VT,R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e64f3d85378a429986b2749292000638.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5fd10e03b064e2d802adeb7efa2c081", "source": "vatex", "video_id": "3YR87sqmPfM_000031_000041", "video_description": "A man is standing by a body of water, using a large fishing pole to cast a line into the water. He demonstrates the use of the fishing reel while an advertisement or commentary is heard in the background.", "task": "Counting", "clean_prompt": "A man is standing by a body of water, using a large fishing pole to cast a line into the water, with six fish swimming nearby.", "clean_property": {"obj": "water", "count": "six"}, "target_prompt": "A man is standing by a body of water, using a large fishing pole to cast a line into the water, with three fish swimming nearby.", "target_property": {"obj": "water", "count": "three"}, "evaluation_question": "Are there exactly **six** fish swimming nearby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing by a body of water, using a large fishing pole to cast a line into the water, with six fish swimming nearby. AN*L!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dd9066127fd4f56ae09ba94c0bd9316.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c276d4fb150479b9b19729a676fdb23", "source": "vatex", "video_id": "h9m7Jsw5vrw_000046_000056", "video_description": "A man is performing push-ups in a gymnasium while being guided by a trainer on proper form.", "task": "ObjectRecognition", "clean_prompt": "A man performing push-ups in a gymnasium while being guided by a trainer.", "clean_property": {"obj": "person"}, "target_prompt": "A woman performing yoga in a park while being guided by an instructor.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing push-ups in a gymnasium while being guided by a trainer. !0!D|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4fb1bfc1659043a7a962b23637fae0f7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5e63b2d13822486facd904f107e7a954", "source": "vatex", "video_id": "vLSo1XfF--I_000000_000010", "video_description": "A man is standing next to a large silver industrial machine, placing a chicken carcass into the machine.", "task": "AttributeRecognition", "clean_prompt": "A man is standing next to a large silver industrial machine, placing a chicken carcass into the machine.", "clean_property": {"obj": "machine", "attribute": "silver"}, "target_prompt": "A man is standing next to a large red industrial machine, placing a chicken carcass into the machine.", "target_property": {"obj": "machine", "attribute": "red"}, "evaluation_question": "Is the machine **silver**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing next to a large silver industrial machine, placing a chicken carcass into the machine. %XSL)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4be006bb9874b36a6bd055403819582.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae2f796d8326438db2fbb018bff8b433", "source": "vatex", "video_id": "9ALCrxTtYr4_000261_000271", "video_description": "A person is sitting on the ground using various tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "task": "Counting", "clean_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "clean_property": {"obj": "tool", "count": "three"}, "target_prompt": "A person is sitting on the ground using one tool to trim and complete a woven structure made of vegetation, shaped like a Christmas tree.", "target_property": {"obj": "tool", "count": "one"}, "evaluation_question": "Are there exactly **three** tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is sitting on the ground using three tools to trim and complete a woven structure made of vegetation, shaped like a Christmas tree. !0D\u00b7)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8492fd8b5ef44f04b437131324dfacbe.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "53e0d0ed61774eb09e3ef0f4a19f77ca", "source": "vatex", "video_id": "ZivLjy2uzRo_000016_000026", "video_description": "A man is in a bar, rinsing a glass in a sink full of water and then filling it with beer from a tap.", "task": "AttributeRecognition", "clean_prompt": "A man rinsing a glass in a sink full of water and then filling it with beer from a tap.", "clean_property": {"obj": "glass", "attribute": "drinking"}, "target_prompt": "A man looking at a broken glass on the bar counter.", "target_property": {"obj": "glass", "attribute": "broken"}, "evaluation_question": "Is the glass being used for drinking?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man rinsing a glass in a sink full of water and then filling it with beer from a tap. 7EZYF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/247ba177b1d34f5eb10cd1da2a82e1a7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4332d13aba514ed89bae214bb66a6dbc", "source": "vatex", "video_id": "f9R3_O_PSls_000044_000054", "video_description": "In a professional office, a man with glasses is sitting in a chair and using a knife to skin a pineapple over a trash can.", "task": "ObjectRecognition", "clean_prompt": "A man with glasses is sitting in a chair and using a knife to skin a pineapple over a trash can.", "clean_property": {"obj": "pineapple"}, "target_prompt": "A man with glasses is sitting in a chair and using a knife to skin a watermelon over a trash can.", "target_property": {"obj": "watermelon"}, "evaluation_question": "Is the man skinning a **pineapple**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man with glasses is sitting in a chair and using a knife to skin a pineapple over a trash can. ELLQS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c3586f9b81a34d97befa63abcb6e0a47.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2524a9f7bbcb480da94ab2b2ab8ffbb9", "source": "vatex", "video_id": "C-I8dXj6lGw_000000_000010", "video_description": "Two teams are playing lacrosse on a grassy field with spectators watching.", "task": "Counting", "clean_prompt": "Six nets are set up on a grassy field where two teams are playing lacrosse with spectators watching.", "clean_property": {"obj": "net", "count": "six"}, "target_prompt": "Two nets are set up on a sandy beach where two teams are playing beach volleyball with spectators watching.", "target_property": {"obj": "net", "count": "two"}, "evaluation_question": "Are there exactly **six** nets set up on the field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six nets are set up on a grassy field where two teams are playing lacrosse with spectators watching. /@EZF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6046c0960da48e0a70b300f2fee2dcd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d5bfcc91427647789526975d544e7fd1", "source": "vatex", "video_id": "P9yYOqAbXeE_000000_000010", "video_description": "A young girl in a bedroom demonstrates her skill with a fidget spinner by spinning it and balancing it on her forehead.", "task": "AttributeRecognition", "clean_prompt": "A girl wearing a jean jacket is demonstrating her skill with a fidget spinner in her bedroom.", "clean_property": {"obj": "girl", "attribute": "wearing a jean jacket"}, "target_prompt": "A girl wearing a pink dress is demonstrating her skill with a fidget spinner in her bedroom.", "target_property": {"obj": "girl", "attribute": "wearing a pink dress"}, "evaluation_question": "Is the girl wearing a **jean jacket**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl wearing a jean jacket is demonstrating her skill with a fidget spinner in her bedroom. 86FE%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01308d5b41464dc4b96b8499a19fcacb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8b4575f502fa4678a5551c6d69367228", "source": "vatex", "video_id": "4FfdMPt4ja0_000015_000025", "video_description": "A man is at a wine tasting, smelling and describing the scent of wine in a glass.", "task": "AttributeRecognition", "clean_prompt": "A man at a wine tasting, smelling and describing the scent of wine in a wine glass that contains wine.", "clean_property": {"obj": "wine glass", "attribute": "contains wine"}, "target_prompt": "A man at a wine tasting, smelling and describing the scent of wine in a wine glass that contains water.", "target_property": {"obj": "wine glass", "attribute": "contains water"}, "evaluation_question": "Does the wine glass contain **wine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man at a wine tasting, smelling and describing the scent of wine in a wine glass that contains wine. !'W%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/007dbc8e10284f02bc44b3ddc8b9e080.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd62700c8f534350a481598224a1b599", "source": "vatex", "video_id": "PKt38LvoAuU_000011_000021", "video_description": "A person is skiing down a snow-covered path lined with trees, while being encouraged by a friend.", "task": "ObjectRecognition", "clean_prompt": "A skier skiing down a snow-covered path lined with trees, while being encouraged by a friend.", "clean_property": {"obj": "skier"}, "target_prompt": "A snowboarder snowboarding down a snow-covered path lined with trees, while being encouraged by a friend.", "target_property": {"obj": "snowboarder"}, "evaluation_question": "Is the person in the video a **skier**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skier skiing down a snow-covered path lined with trees, while being encouraged by a friend. LUFIE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8bbe18bb378b48958264b3778416c630.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "443145fd067e43e698feb467432a6f09", "source": "vatex", "video_id": "UgEAu_Ld9D8_000052_000062", "video_description": "A woman is riding a mechanical bull at an outdoor fair or carnival, with the bull moving slowly back and forth.", "task": "AttributeRecognition", "clean_prompt": "A woman riding a mechanical bull that is moving slowly back and forth at an outdoor fair.", "clean_property": {"obj": "mechanical bull", "attribute": "slow"}, "target_prompt": "A woman riding a mechanical bull that is moving fast at an outdoor fair.", "target_property": {"obj": "mechanical bull", "attribute": "fast"}, "evaluation_question": "Is the mechanical bull moving **slowly**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman riding a mechanical bull that is moving slowly back and forth at an outdoor fair. '!SL*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a4f931ea2a524fe6ac9855f3525faad8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "af7b650071c045f7b9ce8f41219d1489", "source": "vatex", "video_id": "VZIcu3ibJew_000085_000095", "video_description": "A person is lying down while a technician pierces their ear and installs jewelry.", "task": "ActionRecognition", "clean_prompt": "A technician getting a piercing on a person.", "clean_property": {"obj": "technician", "action": "getting a piercing", "target": "person"}, "target_prompt": "A technician removing a piercing from a person.", "target_property": {"obj": "technician", "action": "removing a piercing", "target": "person"}, "evaluation_question": "Is the technician **getting** a piercing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A technician getting a piercing on a person. ''!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9557c3802bd949eaabde5b975ec635be.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "533919d883714fe0a4b72278d1d3b285", "source": "vatex", "video_id": "CVomytAd7-0_000020_000030", "video_description": "A person is sitting cross-legged on a tile floor, using two small knives to sharpen each other by rubbing them together.", "task": "ObjectRecognition", "clean_prompt": "A person sitting cross-legged on a tile floor, using two small knives to sharpen each other by rubbing them together.", "clean_property": {"obj": "knife"}, "target_prompt": "A person sitting cross-legged on a tile floor, using two small swords to sharpen each other by rubbing them together.", "target_property": {"obj": "sword"}, "evaluation_question": "Is the object being used in the video a **knife**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting cross-legged on a tile floor, using two small knives to sharpen each other by rubbing them together. =2?FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6df0707563f7435189e4bfa1d7b3a7fb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "476863f28b1c45cf9c7d65d843ca75c0", "source": "vatex", "video_id": "1vnr8-bq9io_000002_000012", "video_description": "A young girl is in a house watching television, then starts throwing a tantrum by jumping up and down, screaming, and crying. An adult, possibly her parent, is seated nearby and talking to her.", "task": "Counting", "clean_prompt": "A young girl is in a house watching television, with three televisions in the room, then starts throwing a tantrum by jumping up and down, screaming, and crying. An adult, possibly her parent, is seated nearby and talking to her.", "clean_property": {"obj": "television", "count": "three"}, "target_prompt": "A young girl is in a house watching television, with one television in the room, then starts throwing a tantrum by jumping up and down, screaming, and crying. An adult, possibly her parent, is seated nearby and talking to her.", "target_property": {"obj": "television", "count": "one"}, "evaluation_question": "Are there exactly **three** televisions in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is in a house watching television, with three televisions in the room, then starts throwing a tantrum by jumping up and down, screaming, and crying. An adult, possibly her parent, is seated nearby and talking to her. @BMFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce4a3373d4fb47828202a9f1c6a71b42.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5ce6844c4365494c9684b4bdd8b8239f", "source": "vatex", "video_id": "3Utbg9HZ-ms_000008_000018", "video_description": "In a room, two teenage boys are sleeping in a bed while another teenage boy brushes the hair of one of the sleeping boys.", "task": "ActionRecognition", "clean_prompt": "A teenage boy combing his hair in a room.", "clean_property": {"obj": "teenage boy", "action": "combing hair", "target": "teenage boy"}, "target_prompt": "A teenage boy shaving in a room.", "target_property": {"obj": "teenage boy", "action": "shaving", "target": "teenage boy"}, "evaluation_question": "Is the teenage boy **combing** his hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenage boy combing his hair in a room. )\u00b7G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c536ac18ca6f49dd805369e4b41c2880.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "adc52a7787064d3489e07637951dbd29", "source": "vatex", "video_id": "jODN7qCOn1U_000004_000014", "video_description": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "task": "ObjectRecognition", "clean_prompt": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "clean_property": {"obj": "tool"}, "target_prompt": "Multiple children are playing with various toys in a colorful playroom.", "target_property": {"obj": "toy"}, "evaluation_question": "Are the people in the video using **tools**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander. FS7CK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/909f8db937e94c829f2329b7b5de5fac.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bde57e2c4eca49629ffe4954a5b8e866", "source": "vatex", "video_id": "1u9OGTJcMEw_000011_000021", "video_description": "A group of people are watching a polo match on a green field with horses and players. An announcer is speaking through a loudspeaker, and some spectators are taking pictures and filming the event.", "task": "SpatialUnderstanding", "clean_prompt": "An announcer standing to the left of a polo player on a green field.", "clean_property": {"obj_1": "announcer", "relation": "left of", "obj_2": "polo player"}, "target_prompt": "An announcer standing to the right of a polo player on a green field.", "target_property": {"obj_1": "announcer", "relation": "right of", "obj_2": "polo player"}, "evaluation_question": "Is the announcer to the **left** of the polo player?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An announcer standing to the left of a polo player on a green field. SL,8I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6051fecd30f40859c2d61570a42ee19.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e7e3532775e434ea3bf24a1ddd096e0", "source": "vatex", "video_id": "sGxujaBZWEI_000001_000011", "video_description": "A man is performing deadlifts in a busy gym, lifting a barbell with heavy weights up to his thighs and then lowering it back down in multiple repetitions.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a barbell in a busy gym.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "barbell"}, "target_prompt": "A person further from the camera than a barbell in a busy gym.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "barbell"}, "evaluation_question": "Is the person **closer to the camera** than the barbell?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a barbell in a busy gym. SL2\u00b7@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c627b54078544950a81b5a10f92f6fe1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "26550672b57c4d199a31f3e1ebbb34e5", "source": "vatex", "video_id": "a1SASZM2epM_000015_000025", "video_description": "Two volleyball teams are playing a match in a gymnasium with a referee overseeing the game.", "task": "Counting", "clean_prompt": "Six volleyball players are playing a match in a gymnasium with a referee overseeing the game.", "clean_property": {"obj": "volleyball player", "count": "six"}, "target_prompt": "Four volleyball players are playing a match in a beach setting with a referee overseeing the game.", "target_property": {"obj": "volleyball player", "count": "four"}, "evaluation_question": "Are there exactly **six** volleyball players in the match?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six volleyball players are playing a match in a gymnasium with a referee overseeing the game. .YVHU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/399d331a49c94f929ea3b9bf3e5e9899.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bac842679e684de4b64ca9fac5eec3fd", "source": "vatex", "video_id": "jsltYtLEKoY_000005_000015", "video_description": "A man performs a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth.", "task": "ObjectRecognition", "clean_prompt": "A man performing a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth.", "clean_property": {"obj": "sword"}, "target_prompt": "A man performing a fire-breathing act, where he breathes fire from a stick, does a push-up, and then puts the stick down.", "target_property": {"obj": "fire-breathing stick"}, "evaluation_question": "Is the object being used in the act a **sword**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth. #&MEG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc1f94ced73e4b879e97de300ccdd975.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "71aa6e308a6742f8a716e7eb51fbf363", "source": "vatex", "video_id": "bhWFbwj7z6o_000005_000015", "video_description": "An older man holding a Civil War-era rifle is talking to a young boy at a historical reenactment event, possibly set in the 1800s, with an outdoor market setting.", "task": "AttributeRecognition", "clean_prompt": "A young boy with black skin is talking to an older man holding a Civil War-era rifle at a historical reenactment event.", "clean_property": {"obj": "young boy", "attribute": "black"}, "target_prompt": "A young boy with white skin is talking to an older man holding a Civil War-era rifle at a historical reenactment event.", "target_property": {"obj": "young boy", "attribute": "white"}, "evaluation_question": "Is the young boy's skin color **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy with black skin is talking to an older man holding a Civil War-era rifle at a historical reenactment event. FEY@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/733177602699472e96375ffffc59d00f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b6be8aa266394e158bc6f122417d2300", "source": "vatex", "video_id": "A0e7Z55s8pE_000008_000018", "video_description": "A man is on a ladder attempting to remove snow from a roof. The snow suddenly slides off, causing both the man and the ladder to fall into the snow below.", "task": "AttributeRecognition", "clean_prompt": "A man on a ladder attempting to remove snow from a snow-covered roof.", "clean_property": {"obj": "roof", "attribute": "snow-covered"}, "target_prompt": "A man on a ladder attempting to remove snow from a sunny roof.", "target_property": {"obj": "roof", "attribute": "sunny"}, "evaluation_question": "Is the roof **snow-covered**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man on a ladder attempting to remove snow from a snow-covered roof. =$VBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b85ff885b4846f29f105e7acf8a6d25.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "928944ce5a9d411dba6f6147c66796ad", "source": "vatex", "video_id": "3vH5mnAy98Y_000016_000026", "video_description": "A man is juggling illuminated balls of various colors, including red and green, in the middle of a street at night.", "task": "AttributeRecognition", "clean_prompt": "A man juggling illuminated balls that are red and green in the middle of a street at night.", "clean_property": {"obj": "ball", "attribute": "red and green"}, "target_prompt": "A man juggling illuminated balls that are blue and yellow in the middle of a street at night.", "target_property": {"obj": "ball", "attribute": "blue and yellow"}, "evaluation_question": "Are the balls being juggled red and green?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man juggling illuminated balls that are red and green in the middle of a street at night. SL$BB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1253539906d44b33b8af6fa116f8d69c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1fff55b43ebf40a6b64ee382402429a5", "source": "vatex", "video_id": "0KlDkV-Sf4Y_000002_000012", "video_description": "A man in a yellow shirt is standing by a body of water, preparing to cast his extremely long fishing pole into the water.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a fishing pole.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "fishing pole"}, "target_prompt": "A person standing to the left of a fishing pole.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "fishing pole"}, "evaluation_question": "Is the person to the **right** of a fishing pole?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a fishing pole. @JMO>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9962e5cf67fb4472a62d5f222f3f4ff5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1bb694c8c513413f9413bc9a1d85995e", "source": "vatex", "video_id": "gfhwUQLUImc_000026_000036", "video_description": "A person is demonstrating how to mix ingredients for a recipe using an electric mixer in a glass bowl on a table.", "task": "Counting", "clean_prompt": "Three people are demonstrating how to mix ingredients for a recipe using an electric mixer in a glass bowl on a table.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is demonstrating how to mix ingredients for a recipe using an electric mixer in a glass bowl on a table.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people demonstrating the recipe?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are demonstrating how to mix ingredients for a recipe using an electric mixer in a glass bowl on a table. M-CBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35eccf6a3dee469aa37d00d185cbc676.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd06c5816a314431886f15f5becb1d68", "source": "vatex", "video_id": "aZq9W61seMw_000009_000019", "video_description": "A woman is practicing fencing and sword fighting skills indoors, seemingly dueling with herself while yelling and talking about various topics.", "task": "SpatialUnderstanding", "clean_prompt": "A sword positioned to the left of a person practicing fencing indoors.", "clean_property": {"obj_1": "sword", "relation": "left of", "obj_2": "person"}, "target_prompt": "A sword positioned to the right of a person practicing fencing indoors.", "target_property": {"obj_1": "sword", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the sword to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sword positioned to the left of a person practicing fencing indoors. QCK2F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f59f464f4a7347859f44b3903dffb0ec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dad3513e396645cf947ca8a0e2468654", "source": "vatex", "video_id": "3zvLRj6m5a8_000000_000010", "video_description": "A person is demonstrating how to slice a salmon fillet into thin pieces on a cutting board, presumably for sushi.", "task": "AttributeRecognition", "clean_prompt": "A person is demonstrating how to slice a salmon fillet into thin pieces on a cutting board.", "clean_property": {"obj": "salmon", "attribute": "fillet"}, "target_prompt": "A person is demonstrating how to prepare a whole salmon on a cutting board.", "target_property": {"obj": "salmon", "attribute": "whole"}, "evaluation_question": "Is the person slicing a **fillet** of salmon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to slice a salmon fillet into thin pieces on a cutting board. >BC?2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6dd79cb1bd12429a90dc67fb9461e7de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ee960ede9bf742908d8a4b44dbd1edb1", "source": "vatex", "video_id": "S1LSTV7gFR8_000306_000316", "video_description": "A woman is demonstrating how to make and adjust a bow tie using a sewing machine and Velcro.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a sewing machine.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "sewing machine"}, "target_prompt": "A person standing to the left of a sewing machine.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "sewing machine"}, "evaluation_question": "Is the person to the **right** of the sewing machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a sewing machine. '))!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6d185150f734a09a034bbc8c922e950.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8e903c7d9fb9457bb7c5f21ccfe63151", "source": "vatex", "video_id": "aC_3rmjvSxk_000042_000052", "video_description": "A man is fishing with his hands by a lake while another man films the activity. A young boy is also present, sitting at the edge of the lake.", "task": "Counting", "clean_prompt": "Three men fishing by a lake, with one filming the activity.", "clean_property": {"obj": "man", "count": "three"}, "target_prompt": "One man fishing by a lake.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **three** men fishing by the lake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three men fishing by a lake, with one filming the activity. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e60638f2a3354f609b6723cb326dfd5b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9fdeb647b2c849268991de8dd54396bb", "source": "vatex", "video_id": "AvYsSjCHUjo_000147_000157", "video_description": "A person is lying in bed, practicing writing the English alphabet in cursive and calligraphy styles in a notebook.", "task": "ActionRecognition", "clean_prompt": "A person writing the English alphabet in cursive and calligraphy styles in a notebook while lying in bed.", "clean_property": {"obj": "person", "action": "writing", "target": "notebook"}, "target_prompt": "A person drawing on a canvas while sitting at a table.", "target_property": {"obj": "person", "action": "drawing", "target": "canvas"}, "evaluation_question": "Is the person **writing** in a notebook?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person writing the English alphabet in cursive and calligraphy styles in a notebook while lying in bed. QCK90", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/972b1afda5074013bbb1c879932aa8e9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e06a2185f66c47c89c1c370b22b6b795", "source": "vatex", "video_id": "5379yXlh9og_000000_000010", "video_description": "A male athlete is practicing and performing long jump and triple jump on an outdoor track, landing in a sand pit.", "task": "SpatialUnderstanding", "clean_prompt": "An athlete standing to the right of a sand pit.", "clean_property": {"obj_1": "athlete", "relation": "right of", "obj_2": "sand pit"}, "target_prompt": "An athlete standing to the left of a sand pit.", "target_property": {"obj_1": "athlete", "relation": "left of", "obj_2": "sand pit"}, "evaluation_question": "Is the athlete to the **right** of the sand pit?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete standing to the right of a sand pit. @@TVU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d746d9496cf94768a3e9591494aa83d3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46f43ae26f1d46f4956a6741b27fbcf6", "source": "vatex", "video_id": "TtHPzsTmMHU_000000_000010", "video_description": "A man and a woman are arranging flowers in a warehouse. The man is creating floral displays and bouquets, while the woman assists by unwrapping flowers.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse.", "clean_property": {"obj_1": "flowers", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A woman standing to the left of a bouquet of flowers in a warehouse.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "flowers"}, "evaluation_question": "Is the woman to the **right** of the bouquet of flowers?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the right of a bouquet of flowers in a warehouse. FE()O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c651afcc3f894eaf9a0d91d1432807a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1bb36b0f5c5747a5bbb091f8acfe22d8", "source": "vatex", "video_id": "nfN9LuxGUUo_000239_000249", "video_description": "A woman is demonstrating how to handle and separate her very curly, blonde hair.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than her very curly, blonde hair while demonstrating how to handle and separate it.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "hair"}, "target_prompt": "A person further from the camera than her very curly, blonde hair while demonstrating how to handle and separate it.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "hair"}, "evaluation_question": "Is the person closer to the camera than her very curly, blonde hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than her very curly, blonde hair while demonstrating how to handle and separate it. &FE\u00b7V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d6aba47b21547369e415a4540f68f47.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "05d7835bd573414baf39cce0b3934349", "source": "vatex", "video_id": "--Yxppif_Vc_000007_000017", "video_description": "A baby is laying on its back indoors, laughing as an adult, presumably the father, plays with and tickles the baby, making funny noises.", "task": "ObjectRecognition", "clean_prompt": "A baby is laying on its back indoors, laughing as an adult plays with and tickles the baby.", "clean_property": {"obj": "baby"}, "target_prompt": "A puppy is playing on its back indoors, being tickled by an adult.", "target_property": {"obj": "puppy"}, "evaluation_question": "Is the main subject in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is laying on its back indoors, laughing as an adult plays with and tickles the baby. >N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bbe23acae1bb48a49b5239228f381583.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e27ac7d75274d0baff66222854c0679", "source": "vatex", "video_id": "hnWLonR3uN8_000052_000062", "video_description": "A man demonstrates the quality of food products by slicing carrots into thin portions using a sharp kitchen knife on a wooden cutting board.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrates the quality of food products by slicing carrots into thin portions using a sharp kitchen knife on a wooden cutting board.", "clean_property": {"obj": "cutting board", "attribute": "wooden"}, "target_prompt": "A man demonstrates the quality of food products by slicing carrots into thin portions using a sharp kitchen knife on a plastic cutting board.", "target_property": {"obj": "cutting board", "attribute": "plastic"}, "evaluation_question": "Is the cutting board **wooden**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates the quality of food products by slicing carrots into thin portions using a sharp kitchen knife on a wooden cutting board. E.7YU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ceece4d5459a4294a356296860a4ab4c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7fd8f0829d1341348a8865ce23132b36", "source": "vatex", "video_id": "U98VA_cPo2U_000192_000202", "video_description": "A group of Asian senior citizens, dressed in black and wearing sunglasses, perform a choreographed dance routine in unison in a showroom or dance hall.", "task": "AttributeRecognition", "clean_prompt": "A group of Asian senior citizens, dressed in black and wearing sunglasses, perform a choreographed dance routine in unison in a showroom.", "clean_property": {"obj": "person", "attribute": "senior"}, "target_prompt": "A group of Asian young adults, dressed in colorful outfits, perform a choreographed dance routine in unison in a vibrant outdoor setting.", "target_property": {"obj": "person", "attribute": "young adult"}, "evaluation_question": "Are the dancers senior citizens?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of Asian senior citizens, dressed in black and wearing sunglasses, perform a choreographed dance routine in unison in a showroom. FE0EA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d38fe4c174d14063b62a64a94a09d618.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de9b3c43ffc94e9799a09e22fae0bf50", "source": "vatex", "video_id": "P6QK0ZzH2yY_000000_000010", "video_description": "In a busy commercial kitchen, a group of chefs are preparing sushi by placing rice on seaweed, sprinkling seasoning, and assembling sushi rolls.", "task": "ActionRecognition", "clean_prompt": "A chef making sushi in a busy commercial kitchen.", "clean_property": {"obj": "chef", "action": "making sushi", "target": null}, "target_prompt": "A chef frying noodles in a busy commercial kitchen.", "target_property": {"obj": "chef", "action": "frying noodles", "target": null}, "evaluation_question": "Is the chef **making sushi**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef making sushi in a busy commercial kitchen. XSS|G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8031ba85a4a945989fffeef296321854.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "add0fec6f53b408cb2a6ac967b4b1768", "source": "vatex", "video_id": "dc37eol9tns_000000_000010", "video_description": "A young boy is in his room, quickly solving a Rubik's cube and showing tricks with it.", "task": "ObjectRecognition", "clean_prompt": "A young boy is quickly solving a Rubik's cube in his room and showing tricks with it.", "clean_property": {"obj": "rubik's cube"}, "target_prompt": "A young boy is quickly solving a puzzle box in his room and showing tricks with it.", "target_property": {"obj": "puzzle box"}, "evaluation_question": "Is the object being solved in the video a **Rubik's cube**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is quickly solving a Rubik's cube in his room and showing tricks with it. TZBSD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8218cc9043b546eebf379bf0bad829de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d49e5f142234518afa0c9be293e68b2", "source": "vatex", "video_id": "X0tG5hbo9AI_000034_000044", "video_description": "A man is helping a young child, who is wearing a harness, jump on a trampoline. The child is strapped with bungee cords for safety.", "task": "ObjectRecognition", "clean_prompt": "A man is helping a young child, who is wearing a harness, jump on a trampoline.", "clean_property": {"obj": "harness"}, "target_prompt": "A man is helping a young child, who is using a swing, play in a park.", "target_property": {"obj": "swing"}, "evaluation_question": "Is the child using a **harness** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is helping a young child, who is wearing a harness, jump on a trampoline. VG-LY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0eec2081870441098b237f3ed8a292f4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f274aa5f295c4e599b3cb069cfcb26e0", "source": "vatex", "video_id": "WASt2JwMglY_000002_000012", "video_description": "An animation of a circling globe is shown followed by a title card.", "task": "ObjectRecognition", "clean_prompt": "An animation of a circling globe is shown followed by a title card.", "clean_property": {"obj": "globe"}, "target_prompt": "An animation of a circling cube is shown followed by a title card.", "target_property": {"obj": "cube"}, "evaluation_question": "Is the object in the animation a **globe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An animation of a circling globe is shown followed by a title card. !))*D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c5cf4f258434827b623da779b96669a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "97286c455ae448859ac0ae0b068b4123", "source": "vatex", "video_id": "yGs9BsfNA14_000000_000010", "video_description": "A man is standing beside a bicycle, using a screwdriver to adjust the gears on the spinning rear wheel.", "task": "ActionRecognition", "clean_prompt": "A person repairing a puncture on a bicycle wheel.", "clean_property": {"obj": "person", "action": "repairing puncture", "target": "wheel"}, "target_prompt": "A person removing a wheel from a bicycle.", "target_property": {"obj": "person", "action": "removing a wheel", "target": "bicycle"}, "evaluation_question": "Is the person **repairing a puncture** on the wheel?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person repairing a puncture on a bicycle wheel. Y''?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0044e67e1e7a46a18c3983d03f79bfbd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5b5df194d5a24b3b91fac403dfe7ca4e", "source": "vatex", "video_id": "2FlVNwpozfI_000004_000014", "video_description": "A man in a white shirt stands behind a bar with a shelf full of liquor, demonstrating how to use a handheld device to remove bottle caps while talking to the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing farther from the camera than a bottle.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "bottle"}, "target_prompt": "A person standing closer to the camera than a bottle.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "bottle"}, "evaluation_question": "Is the person farther from the camera than the bottle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing farther from the camera than a bottle. ELLM.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fdaf5efb1a5c437a9ec7a5f11acdb3f5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f8a4ff7566f4aadbe522ef80e1bb6da", "source": "vatex", "video_id": "7nl_MxNbWS4_000004_000014", "video_description": "A loud crowd at a concert is holding and passing a young man and a woman above them as they crowd surf.", "task": "Counting", "clean_prompt": "Seven men crowd surfing at a loud concert.", "clean_property": {"obj": "man", "count": "seven"}, "target_prompt": "Three women crowd surfing at a loud concert.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **seven** men crowd surfing at the concert?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven men crowd surfing at a loud concert. FE(EX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bbf5e2bbfc304fc3bfc82c841690840a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ae6cf45916d940128a7ad53df5d87a89", "source": "vatex", "video_id": "6FEc3KIklew_000032_000042", "video_description": "A young man is barefoot skiing on water, performing stunts while holding onto a boat in motion.", "task": "ObjectRecognition", "clean_prompt": "A young man barefoot skiing on water, performing stunts while holding onto a boat.", "clean_property": {"obj": "person"}, "target_prompt": "A woman barefoot skiing on water, performing stunts while holding onto a boat.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **young man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man barefoot skiing on water, performing stunts while holding onto a boat. FEK8)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/549fde7ae4dd446e8611bef45b4b0d2e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3bc162dde9c14650a19202e19124558c", "source": "vatex", "video_id": "9JoGtU00rAU_000000_000010", "video_description": "A young woman in a red tank top is demonstrating front shoulder raises with weights in a gym.", "task": "SpatialUnderstanding", "clean_prompt": "Weights positioned to the left of a person demonstrating front shoulder raises in a gym.", "clean_property": {"obj_1": "weights", "relation": "left of", "obj_2": "person"}, "target_prompt": "Weights positioned to the right of a person demonstrating front shoulder raises in a gym.", "target_property": {"obj_1": "weights", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Are the weights to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Weights positioned to the left of a person demonstrating front shoulder raises in a gym. *SL8V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/72bd132cada7416389c2996885d71f21.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "39bb756f35f74d5d8ad17a9cab8f93d5", "source": "vatex", "video_id": "lCea4HWl1Cs_000225_000235", "video_description": "Two men are playing badminton indoors on a green court, wearing blue shirts. They hit a shuttlecock back and forth over a net.", "task": "SpatialUnderstanding", "clean_prompt": "A net positioned to the left of a player on a green badminton court.", "clean_property": {"obj_1": "net", "relation": "left of", "obj_2": "player"}, "target_prompt": "A net positioned to the right of a player on a green badminton court.", "target_property": {"obj_1": "net", "relation": "right of", "obj_2": "player"}, "evaluation_question": "Is the net to the **left** of the player?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A net positioned to the left of a player on a green badminton court. !3BCX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b389e18352ed4f86b35ca227d02cd330.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d12c4d135a2346589feaca5b031c0c9b", "source": "vatex", "video_id": "Wv-MexRjdwA_000030_000040", "video_description": "A man is using a special ergonomic paint roller to apply yellow paint to a wall while a woman talks about the process.", "task": "ActionRecognition", "clean_prompt": "A person using a paint roller to apply yellow paint to a wall.", "clean_property": {"obj": "person", "action": "using a paint roller", "target": "wall"}, "target_prompt": "A person splashing paint on the floor.", "target_property": {"obj": "person", "action": "splashing paint", "target": "floor"}, "evaluation_question": "Is the person **using a paint roller** on a wall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a paint roller to apply yellow paint to a wall. SL\u00b71G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0f6260e188c04f42858c86d885ffc968.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e2864a683edd48a7b0c00d8407704bbd", "source": "vatex", "video_id": "cbznHY8uOOE_000006_000016", "video_description": "A man is demonstrating and explaining how to perform exercises using an exercise ball, including balancing and pull-ins.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating exercises using an exercise ball, including balancing and pull-ins, who is muscular.", "clean_property": {"obj": "person", "attribute": "muscular"}, "target_prompt": "A person demonstrating exercises using an exercise ball, including balancing and pull-ins, who is slim.", "target_property": {"obj": "person", "attribute": "slim"}, "evaluation_question": "Is the person **muscular**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating exercises using an exercise ball, including balancing and pull-ins, who is muscular. TZ&FA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d3a8209ad29400bb8997207b32c643d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f920fde21dd6414aa32b7743b641d4d1", "source": "vatex", "video_id": "l7xq8S8KeaE_000010_000020", "video_description": "A father playfully tries to get his young child to smell his feet, causing the child to laugh and crawl away.", "task": "ObjectRecognition", "clean_prompt": "A father playfully tries to get his young child to smell his feet, causing the child to laugh and crawl away.", "clean_property": {"obj": "father"}, "target_prompt": "A mother playfully tries to get her young child to smell her feet, causing the child to laugh and crawl away.", "target_property": {"obj": "mother"}, "evaluation_question": "Is the parent in the video a **father**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A father playfully tries to get his young child to smell his feet, causing the child to laugh and crawl away. )%D))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c79c8f4dea24ff6b536a840c0301590.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8b6066b5187f4a7a916a0c309bd94e47", "source": "vatex", "video_id": "WASt2JwMglY_000002_000012", "video_description": "An animation of a circling globe is shown followed by a title card.", "task": "AttributeRecognition", "clean_prompt": "An animation of a circling globe with a graphic design.", "clean_property": {"obj": "globe", "attribute": "graphic"}, "target_prompt": "An animation of a circling globe with a photographic design.", "target_property": {"obj": "globe", "attribute": "photographic"}, "evaluation_question": "Is the globe depicted with a **graphic** design?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An animation of a circling globe with a graphic design. SL%)/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fa1d8e8e67f34077809a9d1b66e43001.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fda5f59d6ba642f99e766d15fd46c009", "source": "vatex", "video_id": "dcdA8z2NKXo_000097_000107", "video_description": "A young woman is in a dark room, talking into the camera while occasionally touching her hair and resting her chin on her hand.", "task": "ActionRecognition", "clean_prompt": "A person laughing in a dark room.", "clean_property": {"obj": "person", "action": "laughing", "target": null}, "target_prompt": "A person crying in a dark room.", "target_property": {"obj": "person", "action": "crying", "target": null}, "evaluation_question": "Is the person **laughing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person laughing in a dark room. /!?0P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/713b7b3d184041269797400fd66469db.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e169c8f525e543aca8bb9527bc491108", "source": "vatex", "video_id": "jGVsvr1kbBI_000002_000012", "video_description": "A group of bartenders, both men and women, are behind a bar preparing and pouring drinks for customers. They are wearing red shirts and are working in a busy, crowded bar environment.", "task": "AttributeRecognition", "clean_prompt": "A group of bartenders preparing and pouring alcoholic drinks in a busy bar.", "clean_property": {"obj": "drink", "attribute": "alcoholic"}, "target_prompt": "A group of bartenders preparing and pouring non-alcoholic drinks in a busy bar.", "target_property": {"obj": "drink", "attribute": "non-alcoholic"}, "evaluation_question": "Are the drinks being prepared by the bartenders **alcoholic**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of bartenders preparing and pouring alcoholic drinks in a busy bar. WN8V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/da7412cb76ed4a759efe3bcc1476d4f3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb77318d7e0e4165b583e67666879267", "source": "vatex", "video_id": "6yueEUn_lM4_000000_000010", "video_description": "A baby is laying on a blanket, giggling and making cooing sounds while attempting to crawl. An adult is present, speaking to the baby.", "task": "AttributeRecognition", "clean_prompt": "A baby is laying on a blanket, giggling and making cooing sounds while attempting to crawl.", "clean_property": {"obj": "baby", "attribute": "infant"}, "target_prompt": "A toddler is playing with toys on a carpet, laughing and trying to stand up.", "target_property": {"obj": "baby", "attribute": "toddler"}, "evaluation_question": "Is the subject in the video a **baby**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is laying on a blanket, giggling and making cooing sounds while attempting to crawl. EAMQM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/885d98211fc547f5b897a381bf117c82.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c56615203b554c7b9d80da84fef16309", "source": "vatex", "video_id": "he1xcCOIVH8_000015_000025", "video_description": "A young boy is in a bathroom, using an electric razor to shave his head, resulting in a large bald patch. He laughs at the outcome.", "task": "SpatialUnderstanding", "clean_prompt": "A boy farther from the camera than an electric razor in a bathroom.", "clean_property": {"obj_1": "boy", "relation": "farther from the camera than", "obj_2": "electric razor"}, "target_prompt": "A boy closer to the camera than an electric razor in a bathroom.", "target_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "electric razor"}, "evaluation_question": "Is the boy **farther from the camera than** the electric razor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy farther from the camera than an electric razor in a bathroom. UF&NZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/871ca093d46446b1ae8b17f8992be910.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "928d87cd27134312bcd167a8e79b72a4", "source": "vatex", "video_id": "vbcMYuFhIJI_000067_000077", "video_description": "A man wearing a welding mask and safety gear is welding a piece of metal inside a building, with sparks flying around.", "task": "SpatialUnderstanding", "clean_prompt": "A welding tool farther from the camera than a person wearing a welding mask and safety gear, welding a piece of metal inside a building.", "clean_property": {"obj_1": "welding tool", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A welding tool closer to the camera than a person wearing a welding mask and safety gear, welding a piece of metal inside a building.", "target_property": {"obj_1": "welding tool", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the welding tool **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A welding tool farther from the camera than a person wearing a welding mask and safety gear, welding a piece of metal inside a building. CO)!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee9c57686cc348cea8749fa0ec1a0c48.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6691d05187d146a3bd6c79372b1cbf06", "source": "vatex", "video_id": "U2PPeWWDSgM_000033_000043", "video_description": "A person is using a traditional printing press to print and stamp cards and paper objects. The person manually places the paper into the machine, which automatically stamps or imprints them.", "task": "ActionRecognition", "clean_prompt": "A person using a bagging machine to package items.", "clean_property": {"obj": "person", "action": "using bagging machine", "target": null}, "target_prompt": "A person operating a sewing machine to create fabric items.", "target_property": {"obj": "person", "action": "operating a sewing machine", "target": null}, "evaluation_question": "Is the person **using a bagging machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a bagging machine to package items. =S49R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d482c92bd43b48d1b4dff3fb915c155d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c6348738b9454549a7209dc621a455bf", "source": "vatex", "video_id": "jGVsvr1kbBI_000002_000012", "video_description": "A group of bartenders, both men and women, are behind a bar preparing and pouring drinks for customers. They are wearing red shirts and are working in a busy, crowded bar environment.", "task": "Counting", "clean_prompt": "Four bartenders in red shirts are behind a bar preparing and pouring drinks for customers in a busy, crowded bar environment.", "clean_property": {"obj": "bar", "count": "four"}, "target_prompt": "One bartender in a red shirt is behind a bar preparing and pouring drinks for customers in a quiet, empty bar environment.", "target_property": {"obj": "bar", "count": "one"}, "evaluation_question": "Are there exactly **four** bartenders behind the bar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four bartenders in red shirts are behind a bar preparing and pouring drinks for customers in a busy, crowded bar environment. #TS/E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4b64c9533b744d70ba681f1cd885e95f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d659a7a92154cc1a45ef4fc35b4f0cc", "source": "vatex", "video_id": "U1TFKAjz1Mg_000000_000010", "video_description": "A baby boy is being fed a piece of sour candy by an adult, and he reacts with a sour face and shakes his head.", "task": "AttributeRecognition", "clean_prompt": "A baby boy is being fed a piece of sour candy by an adult, and he reacts with a sour face and shakes his head.", "clean_property": {"obj": "candy", "attribute": "sour"}, "target_prompt": "A baby boy is being fed a piece of sweet candy by an adult, and he smiles happily.", "target_property": {"obj": "candy", "attribute": "sweet"}, "evaluation_question": "Is the candy being fed to the baby boy **sour**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby boy is being fed a piece of sour candy by an adult, and he reacts with a sour face and shakes his head. FE(N", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b34b9f23a7374a368daad8b32d3d218e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f680d07775034202a3437489d9bd60c7", "source": "vatex", "video_id": "xBbE1E5A8FA_000313_000323", "video_description": "Two young women in costumes and Halloween makeup are sitting cross-legged on the ground, talking and laughing with each other.", "task": "ActionRecognition", "clean_prompt": "A person laughing with a friend in Halloween costumes.", "clean_property": {"obj": "person", "action": "laughing", "target": null}, "target_prompt": "A person crying alone in a dark room.", "target_property": {"obj": "person", "action": "crying", "target": null}, "evaluation_question": "Is the person **laughing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person laughing with a friend in Halloween costumes. AQ!/?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14dd87b9433745ef8484bc3c9e0387cb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e91b7d78585d4a458e3298b1fa16852f", "source": "vatex", "video_id": "33dWGUc3bEA_000000_000010", "video_description": "A woman is in a men's store demonstrating how to tie a bow tie and a necktie on a mannequin and an assistant.", "task": "ActionRecognition", "clean_prompt": "A woman tying a necktie on a mannequin in a men's store.", "clean_property": {"obj": "woman", "action": "tying necktie", "target": "mannequin"}, "target_prompt": "A woman removing a necktie from a mannequin in a men's store.", "target_property": {"obj": "woman", "action": "removing necktie", "target": "mannequin"}, "evaluation_question": "Is the woman **tying** a necktie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman tying a necktie on a mannequin in a men's store. EBS7R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13d6b302d0bb41769b9427d776cc6fe3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c9ee682290e4432abc4b9f7abd95484b", "source": "vatex", "video_id": "0m0-Q0zz_-c_000112_000122", "video_description": "A man in a suit is demonstrating how to tie a bow tie using his leg as a model, providing instructions on the proper technique.", "task": "ActionRecognition", "clean_prompt": "A person tying a bow tie using their leg as a model.", "clean_property": {"obj": "person", "action": "tying bow tie", "target": null}, "target_prompt": "A person removing a bow tie using their leg as a model.", "target_property": {"obj": "person", "action": "removing bow tie", "target": null}, "evaluation_question": "Is the person **tying** a bow tie?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a bow tie using their leg as a model. ))!0P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cea3142799724a03a37c169df1197ed1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "620bdf4179d647b8a71867120affb832", "source": "vatex", "video_id": "j41tqfbwWUY_000000_000010", "video_description": "A man, wearing a grey hoodie, is sitting on a couch demonstrating his knife sharpening skills by rapidly sharpening knives using a metal knife sharpener and clanging them together.", "task": "SpatialUnderstanding", "clean_prompt": "A knife to the left of a knife sharpener.", "clean_property": {"obj_1": "knife", "relation": "left of", "obj_2": "knife sharpener"}, "target_prompt": "A knife to the right of a knife sharpener.", "target_property": {"obj_1": "knife", "relation": "right of", "obj_2": "knife sharpener"}, "evaluation_question": "Is the knife to the **left** of the knife sharpener?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A knife to the left of a knife sharpener. FE.!T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7567e7803774033875ee8ff621d10ba.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "762f9a746d64443aa644f2f32f657761", "source": "vatex", "video_id": "-vOIoARsw-U_000007_000017", "video_description": "A young person is climbing a large rope ladder in a climbing gym, wearing a safety harness. An adult man is giving tips.", "task": "Counting", "clean_prompt": "Two adult men giving tips to a young person climbing a large rope ladder in a climbing gym, wearing a safety harness.", "clean_property": {"obj": "adult man", "count": "two"}, "target_prompt": "One adult man giving tips to a young person climbing a large rope ladder in a climbing gym, wearing a safety harness.", "target_property": {"obj": "adult man", "count": "one"}, "evaluation_question": "Are there exactly **two** adult men giving tips?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two adult men giving tips to a young person climbing a large rope ladder in a climbing gym, wearing a safety harness. )?'B:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/137fa2ca5a324f639766b05d7169825d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afef52bb823b417893277c45b33436e4", "source": "vatex", "video_id": "YblpmT2EQDo_000168_000178", "video_description": "An elderly man is sitting on a wooden chair in a kitchen, playing a tune on an accordion.", "task": "Counting", "clean_prompt": "Five people are gathered in a kitchen, watching an elderly man play a tune on an accordion while sitting on a wooden chair.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person is sitting in a kitchen, playing a tune on an accordion.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people are gathered in a kitchen, watching an elderly man play a tune on an accordion while sitting on a wooden chair. \u00b7)?5*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24b72a25903141f6bdce6ca2643e52f0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4cbe1b67352e469fbf18b89cbb990ec4", "source": "vatex", "video_id": "ZbI_bpw83Pc_000007_000017", "video_description": "Two men are outdoors under a tent, demonstrating how to play a didgeridoo. One man blows into the didgeridoo while the other helps hold it up. They pause to smile at the camera and speak a few words in a foreign language.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a didgeridoo.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "didgeridoo"}, "target_prompt": "A person closer to the camera than a didgeridoo.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "didgeridoo"}, "evaluation_question": "Is the person **farther from the camera than** the didgeridoo?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a didgeridoo. ELNWS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb6e2ee4864a42f49f819678b0a62489.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "65a7a7a3dd2243c695f6fb7a935d784f", "source": "vatex", "video_id": "9dyOMEVd9GM_000000_000010", "video_description": "Two young women are dancing to the Macarena indoors, with music playing in the background.", "task": "Counting", "clean_prompt": "Two young women are dancing to the Macarena indoors, with music playing in the background.", "clean_property": {"obj": "dancer", "count": "two"}, "target_prompt": "Four dancers performing a choreographed routine in a brightly lit studio.", "target_property": {"obj": "dancer", "count": "four"}, "evaluation_question": "Are there exactly **two** dancers in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young women are dancing to the Macarena indoors, with music playing in the background. W*&H)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cbb762416f1641b48e20855aa7a86e45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "caf6be5844dd4b6389f5eb56f1352767", "source": "vatex", "video_id": "jo2_g8Bua1Q_000042_000052", "video_description": "An instructional video showing the process of tie-dyeing a white shirt red using liquid dye.", "task": "AttributeRecognition", "clean_prompt": "An instructional video showing the process of tie-dyeing a white shirt red using liquid dye.", "clean_property": {"obj": "dye", "attribute": "red"}, "target_prompt": "An instructional video showing the process of tie-dyeing a white shirt blue using liquid dye.", "target_property": {"obj": "dye", "attribute": "blue"}, "evaluation_question": "Is the dye used in the video **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instructional video showing the process of tie-dyeing a white shirt red using liquid dye. )XBBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/68c7b43fa206443fa2537a8c1cc767ce.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7213711d0d949e4b07b911c760f5b9d", "source": "vatex", "video_id": "Tauh87viFFw_000058_000068", "video_description": "A young woman and a young man are engaging in a playful tickling game while speaking Spanish.", "task": "ActionRecognition", "clean_prompt": "A woman tickling a man while they are laughing and speaking Spanish.", "clean_property": {"obj": "woman", "action": "tickling", "target": "man"}, "target_prompt": "A woman poking a man while they are laughing and speaking Spanish.", "target_property": {"obj": "woman", "action": "poking", "target": "man"}, "evaluation_question": "Is the woman **tickling** the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman tickling a man while they are laughing and speaking Spanish. !G*$)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/689f9ed18f0449c8a0ec4506bfada661.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2b0ca22495d84cedaf053c52dc99a6e2", "source": "vatex", "video_id": "va3txyK3Xck_000552_000562", "video_description": "A person is demonstrating knitting techniques, including casting off, using green or teal yarn and needles, with opera music playing in the background.", "task": "ActionRecognition", "clean_prompt": "A person demonstrating knitting techniques with green yarn and needles.", "clean_property": {"obj": "person", "action": "knitting", "target": null}, "target_prompt": "A person demonstrating crocheting techniques with green yarn and hooks.", "target_property": {"obj": "person", "action": "crocheting", "target": null}, "evaluation_question": "Is the person **knitting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating knitting techniques with green yarn and needles. LY%K(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a22045fc6344deab870421e12ff37cc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "89d1e214d9924f7d96c780165d0fd55d", "source": "vatex", "video_id": "IB4wGDBbkIk_000061_000071", "video_description": "A woman is sitting in a chair at a salon, receiving a cosmetic procedure on her eyebrows, which includes wiping, applying makeup, and tweezing.", "task": "ActionRecognition", "clean_prompt": "A cosmetologist waxing eyebrows on a woman in a salon.", "clean_property": {"obj": "cosmetologist", "action": "waxing eyebrows", "target": "woman"}, "target_prompt": "A cosmetologist applying facial masks on a woman in a salon.", "target_property": {"obj": "cosmetologist", "action": "applying facial masks", "target": "woman"}, "evaluation_question": "Is the cosmetologist **waxing eyebrows**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cosmetologist waxing eyebrows on a woman in a salon. 38S1R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2760cf1c01a345bba2a569ad38179807.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "945d7009856449f79fb8e6567cf08af7", "source": "vatex", "video_id": "3ShSvGhFUcc_000030_000040", "video_description": "A young boy is at a salon, sitting in a chair with his head over a sink, getting his hair washed by a stylist.", "task": "ActionRecognition", "clean_prompt": "A stylist washing a child's hair at a salon.", "clean_property": {"obj": "stylist", "action": "washing hair", "target": "child"}, "target_prompt": "A stylist cutting a child's hair at a salon.", "target_property": {"obj": "stylist", "action": "cutting hair", "target": "child"}, "evaluation_question": "Is the stylist **washing** the child's hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A stylist washing a child's hair at a salon. EL@@J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9b3ad711727845debaf5278befc8b47d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5e230fe8f19c4bc0992600679deae640", "source": "vatex", "video_id": "qLA4yb5wAfE_000049_000059", "video_description": "A facility where leather is being prepared and inspected. A man and a woman walk through the factory, examining leather hanging and drying.", "task": "AttributeRecognition", "clean_prompt": "A facility where leather is drying, with a man and a woman inspecting the leather hanging in the factory.", "clean_property": {"obj": "leather", "attribute": "drying"}, "target_prompt": "A facility where leather is wet, with a man and a woman inspecting the leather hanging in the factory.", "target_property": {"obj": "leather", "attribute": "wet"}, "evaluation_question": "Is the leather **drying** in the facility?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A facility where leather is drying, with a man and a woman inspecting the leather hanging in the factory. +SL>M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57929a4141024db189037500b9f71c7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "106d4753a786429fa528c3276b27dd03", "source": "vatex", "video_id": "m2zCweE1HVg_000019_000029", "video_description": "A shirtless man pranks a sleeping man by putting shaving cream on his face and waking him up.", "task": "SpatialUnderstanding", "clean_prompt": "A sleeping man to the left of a prankster.", "clean_property": {"obj_1": "sleeping man", "relation": "left of", "obj_2": "prankster"}, "target_prompt": "A sleeping man to the right of a prankster.", "target_property": {"obj_1": "sleeping man", "relation": "right of", "obj_2": "prankster"}, "evaluation_question": "Is the sleeping man to the **left** of the prankster?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sleeping man to the left of a prankster. DG$QV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5b88789459a347de91841740325758b9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac22601c332f4148924483f029e33012", "source": "vatex", "video_id": "sIp1Eyi0DaM_000001_000011", "video_description": "A person opens a can of BGI beer, pours it into a glass, and places the can next to the glass. The glass becomes frosty as the beer is poured. The scene is set in an Asian country and is part of a beer advertisement.", "task": "Counting", "clean_prompt": "Two people enjoying a can of BGI beer, pouring it into a glass, and placing the can next to the glass. The glass becomes frosty as the beer is poured, set in an Asian country.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person enjoying a can of BGI beer, pouring it into a glass, and placing the can next to the glass. The glass becomes frosty as the beer is poured, set in an Asian country.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people enjoying the beer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people enjoying a can of BGI beer, pouring it into a glass, and placing the can next to the glass. The glass becomes frosty as the beer is poured, set in an Asian country. PG@BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/34587ad56a3c455199c12241340ab979.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c05c20991714433b34fa18c853be1c9", "source": "vatex", "video_id": "eCJQXspc-wc_000007_000017", "video_description": "A man is performing pushups indoors using a weight ball for support, alternating hands on the ball and the floor.", "task": "ObjectRecognition", "clean_prompt": "A man performing pushups indoors using a weight ball for support, alternating hands on the ball and the floor.", "clean_property": {"obj": "weight ball"}, "target_prompt": "A man performing pushups indoors using an exercise mat for support, alternating hands on the mat and the floor.", "target_property": {"obj": "exercise mat"}, "evaluation_question": "Is the man using a **weight ball** for support?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing pushups indoors using a weight ball for support, alternating hands on the ball and the floor. HP7BA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/62270d13614b4d41a5671bc8abf0002d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "48008e5310fc49c29a5135d7c6a8937d", "source": "vatex", "video_id": "3GgZd2Klrzc_000039_000049", "video_description": "A person is carefully walking down a steep, snow-covered hill, making deep tracks in the snow.", "task": "ActionRecognition", "clean_prompt": "A person walking through snow on a steep hill.", "clean_property": {"obj": "person", "action": "walking through snow", "target": null}, "target_prompt": "A person running through snow on a flat surface.", "target_property": {"obj": "person", "action": "running through snow", "target": null}, "evaluation_question": "Is the person **walking** through snow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person walking through snow on a steep hill. ELLMJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd91469d207a40ec8fa4be6557526ba5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ac7daa54d6d48efb4336d52ab2900c2", "source": "vatex", "video_id": "LAx9oAvCugA_000103_000113", "video_description": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing Monopoly.", "task": "ActionRecognition", "clean_prompt": "A boy playing Monopoly at a dining room table.", "clean_property": {"obj": "boy", "action": "playing monopoly", "target": null}, "target_prompt": "A boy watching a movie in a living room.", "target_property": {"obj": "boy", "action": "watching a movie", "target": null}, "evaluation_question": "Is the boy **playing Monopoly**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy playing Monopoly at a dining room table. LY%\u00b7E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6230de49a97c4b2390e1a140e3547244.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f0448746533d4e51bda8c412e5712608", "source": "vatex", "video_id": "D9SLYYEAEf8_000000_000010", "video_description": "A woman is sitting on a couch holding a baby who is laughing while a man counts money next to them.", "task": "ActionRecognition", "clean_prompt": "A man counting money next to a woman sitting on a couch holding a laughing baby.", "clean_property": {"obj": "man", "action": "counting money", "target": "money"}, "target_prompt": "A man throwing money next to a woman sitting on a couch holding a laughing baby.", "target_property": {"obj": "man", "action": "throwing money", "target": "money"}, "evaluation_question": "Is the man **counting** money?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man counting money next to a woman sitting on a couch holding a laughing baby. LY%QM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c0fc41bbac704f0e9467652ea96a4d3c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "23df7d1370284dcda42ab8834f259124", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "clean_property": {"obj": "pen", "attribute": "black"}, "target_prompt": "A person demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a red pen on a sheet of paper.", "target_property": {"obj": "pen", "attribute": "red"}, "evaluation_question": "Is the pen being used to write in **black** ink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper. ''');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b7db8f396c9949d9a9b9448a4f812a57.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c2d2312de27741b3819bf25158959ba2", "source": "vatex", "video_id": "CV8xjFND9X8_000034_000044", "video_description": "A man is demonstrating how to clean a toilet using a motorized brush attached to an electric drill.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating how to clean a toilet using a blue brush attached to an electric drill.", "clean_property": {"obj": "brush", "attribute": "blue"}, "target_prompt": "A man is demonstrating how to clean a toilet using a red brush attached to an electric drill.", "target_property": {"obj": "brush", "attribute": "red"}, "evaluation_question": "Is the brush being used to clean the toilet **blue**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to clean a toilet using a blue brush attached to an electric drill. FS7G(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c3d3f2bfa2a4b89836dad5850b90d74.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d3ab6bb610094e45a4a37c149137c0ff", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "AttributeRecognition", "clean_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "ice", "attribute": "thick"}, "target_prompt": "A man is standing in the street using a sledge hammer to break up thin ice on the ground.", "target_property": {"obj": "ice", "attribute": "thin"}, "evaluation_question": "Is the ice **thick** on the ground?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing in the street using a sledge hammer to break up thick ice on the ground. BG,SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f22ff25ec3448ddbf0cb59df20df7dd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b909cd2050624861aabe8e76aae2b3e2", "source": "vatex", "video_id": "aAIJuq6SPgo_000045_000055", "video_description": "A teenage girl is practicing basketball dribbling and passing techniques on an indoor basketball court, with a coach providing instructions.", "task": "ObjectRecognition", "clean_prompt": "A teenage girl is practicing basketball dribbling and passing techniques on an indoor basketball court.", "clean_property": {"obj": "basketball"}, "target_prompt": "A teenage girl is practicing soccer dribbling and passing techniques on an indoor soccer field.", "target_property": {"obj": "soccer ball"}, "evaluation_question": "Is the object being practiced with in the video a **basketball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenage girl is practicing basketball dribbling and passing techniques on an indoor basketball court. LY;(O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fc04f46423041c792b6ea3cce46d44b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "77c67c25c269478aa3cbc651372f28ff", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "ObjectRecognition", "clean_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway.", "clean_property": {"obj": "person"}, "target_prompt": "A woman wearing summer clothing demonstrates how to shovel sand from a beach.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway. @RVH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef8e218247074bdb9effacd574e1ce7c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "954397b2f9de435b8e0bc4048b6e3250", "source": "vatex", "video_id": "1NRsoJAsd6c_000000_000010", "video_description": "A shirtless man is playing a trumpet indoors, performing various musical notes and scales.", "task": "ObjectRecognition", "clean_prompt": "A shirtless man playing a trumpet indoors.", "clean_property": {"obj": "person"}, "target_prompt": "A woman playing a violin indoors.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the musician in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A shirtless man playing a trumpet indoors. R%(0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2ddc1dbc2d034068bc1ab444bb9f75e6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a1a168787d34418b8bf55a51d7ee671f", "source": "vatex", "video_id": "WbGgHu9LLIg_000132_000142", "video_description": "A person is kayaking down a choppy, muddy river, sometimes under a bridge, accompanied by a partner and a dog.", "task": "ObjectRecognition", "clean_prompt": "A person kayaking down a choppy, muddy river with a partner and a dog.", "clean_property": {"obj": "river"}, "target_prompt": "A person kayaking in a calm ocean with a partner and a dog.", "target_property": {"obj": "ocean"}, "evaluation_question": "Is the water in the video a **river**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person kayaking down a choppy, muddy river with a partner and a dog. HTSVS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4253e52ffa244eb7968f4128709f8bed.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0ec4fd4b98c84b159e5a00545620de62", "source": "vatex", "video_id": "S0nrc6Ov2uE_000000_000010", "video_description": "A woman is standing in a field holding a large black balloon with white designs, which she pops.", "task": "ObjectRecognition", "clean_prompt": "A woman standing in a field holding a large black balloon with white designs, which she pops.", "clean_property": {"obj": "person"}, "target_prompt": "A child playing in a park with a colorful kite.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing in a field holding a large black balloon with white designs, which she pops. FE1B@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb85fc55861f4bfebb48a4188749ecbd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb6c662503ee4a66b522ad7582ee7ae9", "source": "vatex", "video_id": "EDdp5B7bHaQ_000001_000011", "video_description": "A bearded man is winking and moving his head to the music while looking at the camera.", "task": "ActionRecognition", "clean_prompt": "A person winking and moving his head to the music while looking at the camera.", "clean_property": {"obj": "person", "action": "winking", "target": null}, "target_prompt": "A person smiling and moving his head to the music while looking at the camera.", "target_property": {"obj": "person", "action": "smiling", "target": null}, "evaluation_question": "Is the person **winking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person winking and moving his head to the music while looking at the camera. )))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1658a406c9194a66b6142fc6c247853a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cd2ccf414194dfd8f59ba62edfc2364", "source": "vatex", "video_id": "J1z3hJpWE-k_000014_000024", "video_description": "A person is using various power tools to polish and smooth the surface of a marble or granite counter or table.", "task": "AttributeRecognition", "clean_prompt": "A person using power tools to polish a granite counter.", "clean_property": {"obj": "counter", "attribute": "granite"}, "target_prompt": "A person using power tools to polish a wooden counter.", "target_property": {"obj": "counter", "attribute": "wooden"}, "evaluation_question": "Is the counter made of **granite**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using power tools to polish a granite counter. FEI'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/48b2f3c58a0b48d5b4afdea7d548f0a2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac58004e4edc445f82951d7b94e9a90f", "source": "vatex", "video_id": "8PjrBLV_Mk4_000030_000040", "video_description": "A young boy is sliding down a blue water slide during the daytime, holding his nose as he approaches a pool. He slows down and scoots to reach the pool, where a woman is present.", "task": "ActionRecognition", "clean_prompt": "A boy water sliding down a blue slide into a pool during the daytime.", "clean_property": {"obj": "boy", "action": "water sliding", "target": null}, "target_prompt": "A boy jumping on a trampoline.", "target_property": {"obj": "boy", "action": "jumping", "target": "trampoline"}, "evaluation_question": "Is the boy **water sliding**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy water sliding down a blue slide into a pool during the daytime. !/BC%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/768e88171fdc462fa7afe249850adb27.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "be4f62cf39a54e65ac04b58b8233824e", "source": "vatex", "video_id": "7AMkMqpQNwk_000773_000783", "video_description": "A group of construction workers are pouring and leveling a wet concrete floor inside a building using machinery and tools.", "task": "ActionRecognition", "clean_prompt": "A construction worker laying concrete inside a building.", "clean_property": {"obj": "construction worker", "action": "laying concrete", "target": null}, "target_prompt": "A construction worker demolishing concrete inside a building.", "target_property": {"obj": "construction worker", "action": "demolishing concrete", "target": null}, "evaluation_question": "Is the construction worker **laying** concrete?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A construction worker laying concrete inside a building. %C)FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4df28b6d52394f0b85cd2d619b5a87ec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3de7cac514b04c54b5ca5cad383b4708", "source": "vatex", "video_id": "yL1Htb_D1cs_000080_000090", "video_description": "A toddler is repeatedly poking the belly button of a person lying on the floor, causing both to laugh.", "task": "ObjectRecognition", "clean_prompt": "A toddler is poking the belly button of a person lying on the floor, causing both to laugh.", "clean_property": {"obj": "person"}, "target_prompt": "A toddler is poking the belly button of a dog lying on the floor, causing both to laugh.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the object being poked in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A toddler is poking the belly button of a person lying on the floor, causing both to laugh. FE#0V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/da41886349cf4bf28440ba0e72dd0505.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afe680d2b8164553b0a43715a96edc4d", "source": "vatex", "video_id": "jOC7hIYc9hY_000003_000013", "video_description": "A woman is instructing on how to write the letter 'K' using a blue marker on a whiteboard.", "task": "AttributeRecognition", "clean_prompt": "A woman is instructing on how to write the letter 'K' using a blue marker on a whiteboard.", "clean_property": {"obj": "marker", "attribute": "blue"}, "target_prompt": "A woman is instructing on how to write the letter 'K' using a red marker on a whiteboard.", "target_property": {"obj": "marker", "attribute": "red"}, "evaluation_question": "Is the woman using a **blue** marker?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is instructing on how to write the letter 'K' using a blue marker on a whiteboard. !0D=B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/48327235bcad46c498e71f2cec99da08.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d4815ce1026249f0ac8105a8a6452c9b", "source": "vatex", "video_id": "z4k7AbUZMsc_000031_000041", "video_description": "A woman is demonstrating how to tie a scarf or bandana into a bow on her head.", "task": "SpatialUnderstanding", "clean_prompt": "A scarf positioned to the right of a person demonstrating how to tie it into a bow on her head.", "clean_property": {"obj_1": "scarf", "relation": "right of", "obj_2": "person"}, "target_prompt": "A scarf positioned to the left of a person demonstrating how to tie it into a bow on her head.", "target_property": {"obj_1": "scarf", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the scarf to the **right** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scarf positioned to the right of a person demonstrating how to tie it into a bow on her head. EZSVJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/942ac8ed8ac142368e41bc5323f22426.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "935838a4994543e0a0b666a58a037a3d", "source": "vatex", "video_id": "q2ZBVyR1k-U_000021_000031", "video_description": "A man in a beekeeper's suit is interacting with another man who is drinking from a cup. They are in the back of a truck.", "task": "Counting", "clean_prompt": "A man in a beekeeper's suit is interacting with another man who is drinking from four cups in the back of a truck.", "clean_property": {"obj": "cup", "count": "four"}, "target_prompt": "A man in a beekeeper's suit is interacting with another man who is drinking from one cup in the back of a truck.", "target_property": {"obj": "cup", "count": "one"}, "evaluation_question": "Are there exactly **four** cups being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a beekeeper's suit is interacting with another man who is drinking from four cups in the back of a truck. =7PDL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0cef0868cf4c4ddbbd1967b55616bb21.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "350a2ba3e4964ad99cf3a77403d6e5ab", "source": "vatex", "video_id": "mg4eMlZSbVI_000212_000222", "video_description": "A woman is demonstrating how to make a snowman doll using a white sock, adding features like eyes and a hat on a kitchen table.", "task": "ActionRecognition", "clean_prompt": "A person making a snowman doll using a white sock on a kitchen table.", "clean_property": {"obj": "person", "action": "making snowman", "target": "snowman doll"}, "target_prompt": "A person destroying a snowman doll on a kitchen table.", "target_property": {"obj": "person", "action": "destroying snowman", "target": "snowman doll"}, "evaluation_question": "Is the person **making** a snowman doll?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making a snowman doll using a white sock on a kitchen table. TY#MJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bde7e2579b67402aa9542a2b3f60ac78.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c79a1a1769dd42d0b407895ed6dca67a", "source": "vatex", "video_id": "5GiYmhZWDYw_000048_000058", "video_description": "A person demonstrates how to tie a ribbon into a bow, using a dark-colored ribbon around a white bar or metal pole, ensuring it stays firm without unraveling.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrates how to tie a ribbon into a bow around a metal bar.", "clean_property": {"obj": "bar", "attribute": "metal"}, "target_prompt": "A person demonstrates how to tie a ribbon into a bow around a wooden bar.", "target_property": {"obj": "bar", "attribute": "wooden"}, "evaluation_question": "Is the bar made of **metal**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrates how to tie a ribbon into a bow around a metal bar. :)FEI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/96669ee4b0f64036ba36a00c3e707426.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab631cd2e1a14816b6d201de688be266", "source": "vatex", "video_id": "dcdA8z2NKXo_000097_000107", "video_description": "A young woman is in a dark room, talking into the camera while occasionally touching her hair and resting her chin on her hand.", "task": "Counting", "clean_prompt": "A young woman is in a dark room, talking into the camera while occasionally touching her hair and resting her chin on her hand, with three cameras capturing her from different angles.", "clean_property": {"obj": "camera", "count": "three"}, "target_prompt": "A young woman is in a dark room, talking into the camera while occasionally touching her hair and resting her chin on her hand, with one camera capturing her.", "target_property": {"obj": "camera", "count": "one"}, "evaluation_question": "Are there exactly **three** cameras capturing her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman is in a dark room, talking into the camera while occasionally touching her hair and resting her chin on her hand, with three cameras capturing her from different angles. HLSWT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1c44a7965cdd42a481bdc5b9a56e3155.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2d4de281d9ce4328bc63088b31c56271", "source": "vatex", "video_id": "I6ZWirFRwg8_000012_000022", "video_description": "A man on a ladder is picking and cutting fruit from a tall tree and tossing it to another person on the ground.", "task": "Counting", "clean_prompt": "Two men on a ladder are picking and cutting fruit from a tall tree and tossing it to another person on the ground.", "clean_property": {"obj": "man_2", "count": "two"}, "target_prompt": "One man on a ladder is picking and cutting fruit from a tall tree and tossing it to another person on the ground.", "target_property": {"obj": "man_2", "count": "one"}, "evaluation_question": "Are there exactly **two** men on the ladder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men on a ladder are picking and cutting fruit from a tall tree and tossing it to another person on the ground. W%|*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9be21cac95fa438bbf50f342c9468958.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "283c63ed09ba42039bf926d886142469", "source": "vatex", "video_id": "5vA-kP3C-WY_000303_000313", "video_description": "A man in red pants performs a breakdancing solo in a dance studio, surrounded by a group of people watching and clapping.", "task": "ObjectRecognition", "clean_prompt": "A dancer performing a breakdancing solo in a dance studio.", "clean_property": {"obj": "dancer"}, "target_prompt": "A singer performing a solo in a dance studio.", "target_property": {"obj": "singer"}, "evaluation_question": "Is the performer in the video a **dancer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dancer performing a breakdancing solo in a dance studio. !0O0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f88361986b7646db9b693fcf584107b3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6da3acb8f7cd43dd84778f9849d73afe", "source": "vatex", "video_id": "_18IUInkoEY_000009_000019", "video_description": "A man in a green shirt with 'Nigeria' written on it runs down a track and performs a long jump into a sand pit, while a crowd of spectators claps and cheers.", "task": "ActionRecognition", "clean_prompt": "An athlete performing a long jump into a sand pit.", "clean_property": {"obj": "athlete", "action": "long jump", "target": null}, "target_prompt": "An athlete performing a high jump.", "target_property": {"obj": "athlete", "action": "high jump", "target": null}, "evaluation_question": "Is the athlete **performing a long jump**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a long jump into a sand pit. Y1|LF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a32c8e4cc89f4bfa864940b1ad4fb15a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3dcc5393877c4c8e85d582f939dec985", "source": "vatex", "video_id": "yIWVQlozVrA_000052_000062", "video_description": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on a sheet of paper.", "task": "Counting", "clean_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper.", "clean_property": {"obj": "paper", "count": "three"}, "target_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on one sheet of paper.", "target_property": {"obj": "paper", "count": "one"}, "evaluation_question": "Are there exactly **three** sheets of paper being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating calligraphy by writing 'Happy Birthday' in decorative cursive and print using a black pen on three sheets of paper. =S@JJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dcd8c3e158f4ebea79bb8bb9198db23.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d06d20bb4c2c484e9552edf50ec6020e", "source": "vatex", "video_id": "oCOFLIpsaVA_000235_000245", "video_description": "A professional chef is demonstrating how to make a sushi roll on a cooking show set in front of a live audience.", "task": "AttributeRecognition", "clean_prompt": "A chef demonstrating how to make a sushi roll in front of a live audience.", "clean_property": {"obj": "chef", "attribute": "Asian"}, "target_prompt": "A chef demonstrating how to make pasta in front of a live audience.", "target_property": {"obj": "chef", "attribute": "Italian"}, "evaluation_question": "Is the chef demonstrating how to make sushi?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef demonstrating how to make a sushi roll in front of a live audience. =BC+G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a4dbea568bc48a8b9f679bac1ae4720.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ceedd6c882414758bb3be5418a6f7f55", "source": "vatex", "video_id": "e-rVEXeqeWQ_000446_000456", "video_description": "A child is assembling a structure using various colored and shaped Lego pieces.", "task": "Counting", "clean_prompt": "Two children assembling a structure using various colored and shaped Lego pieces.", "clean_property": {"obj": "child", "count": "two"}, "target_prompt": "A child assembling a structure using various colored and shaped Lego pieces.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **two** children assembling the structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children assembling a structure using various colored and shaped Lego pieces. ))!W*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bc8582f710134a269ad47c046f1700d4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "994e2a0283a540f7b4752c64373b15c3", "source": "vatex", "video_id": "5ACA2s0Xq5U_000030_000040", "video_description": "A little boy with a cast on his arm is attempting to brush his teeth while his mother gives him instructions. The boy walks around the room with a toothbrush in his mouth.", "task": "AttributeRecognition", "clean_prompt": "A boy with a cast on his arm is attempting to brush his teeth while his mother gives him instructions.", "clean_property": {"obj": "boy", "attribute": "cast on arm"}, "target_prompt": "A boy wearing a superhero costume is attempting to brush his teeth while his mother gives him instructions.", "target_property": {"obj": "boy", "attribute": "wearing a superhero costume"}, "evaluation_question": "Is the boy wearing a **cast** on his arm?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy with a cast on his arm is attempting to brush his teeth while his mother gives him instructions. EL4FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e6e19e00b449473ca2514a5737d18cdc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "866e93ab90de4b92a4728f88bb1b8ed2", "source": "vatex", "video_id": "9rO_pbRPvYk_000054_000064", "video_description": "A person wearing a life vest is water skiing on a single ski behind a motor boat on a large body of water.", "task": "ActionRecognition", "clean_prompt": "A person water skiing on a single ski behind a motor boat on a large body of water.", "clean_property": {"obj": "person", "action": "water skiing", "target": null}, "target_prompt": "A person snowboarding on a snowy mountain.", "target_property": {"obj": "person", "action": "snowboarding", "target": null}, "evaluation_question": "Is the person **water skiing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person water skiing on a single ski behind a motor boat on a large body of water. /SL,R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/acfc0cf68e78447b879a5ebb4064e56b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e066450c44cf4c2796a02d137135df74", "source": "vatex", "video_id": "3jwFcMjSEOA_000000_000010", "video_description": "A person is demonstrating how to prepare for rock climbing by tying knots and attaching ropes using carabiners.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating how to tie knots and attach ropes using carabiners for rock climbing.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing with ropes and carabiners in a park.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to tie knots and attach ropes using carabiners for rock climbing. '!%|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/487680eabf904ee6b3c047478d6e28e1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "956bd99e79e74f7cb5962812d817c9ca", "source": "vatex", "video_id": "hmRfB4ubBZM_000000_000010", "video_description": "A man uses a power drill to make a hole in a coconut and inserts a straw for drinking.", "task": "Counting", "clean_prompt": "Three people using power drills to make holes in coconuts and inserting straws for drinking.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person using a power drill to make a hole in a coconut and inserting a straw for drinking.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people using power drills in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people using power drills to make holes in coconuts and inserting straws for drinking. UG7,E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1030a143dfc241eebd50db771fafd56e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1504d4e23e25474c8aecc1cd52a5b481", "source": "vatex", "video_id": "7TmunkUlVtE_000000_000010", "video_description": "A person is in a kitchen carving a pumpkin. They cut open the pumpkin, clean out the seeds, and draw a design on it with a marker before carving.", "task": "AttributeRecognition", "clean_prompt": "A person in a kitchen carving a pumpkin, using a black marker to draw a design on it.", "clean_property": {"obj": "marker", "attribute": "black"}, "target_prompt": "A person in a kitchen carving a pumpkin, using a red marker to draw a design on it.", "target_property": {"obj": "marker", "attribute": "red"}, "evaluation_question": "Is the person using a **black** marker?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in a kitchen carving a pumpkin, using a black marker to draw a design on it. FEYEG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fe213050131842199b42509f1fc30b39.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e3b339dc13f4019b39b37e1dc403f6f", "source": "vatex", "video_id": "b1x_oZ11U0Y_000016_000026", "video_description": "A large group of people are playing various percussion instruments, including xylophones, maracas, and drums, outside in a parking lot or street.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the left of an instrument.", "clean_property": {"obj_1": "musician", "relation": "left of", "obj_2": "instrument"}, "target_prompt": "A musician standing to the right of an instrument.", "target_property": {"obj_1": "musician", "relation": "right of", "obj_2": "instrument"}, "evaluation_question": "Is the musician to the **left** of an instrument?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician standing to the left of an instrument. ,FEY@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c0bd2aa570a84b33bdc219d8a9ba65a8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0100224b615745db816695dab455c3a1", "source": "vatex", "video_id": "7BUM5wYubKY_000403_000413", "video_description": "A young boy is outside demonstrating how to make bruschetta by placing sliced tomatoes and basil on a piece of bread.", "task": "ActionRecognition", "clean_prompt": "A woman preparing a salad with fresh vegetables.", "clean_property": {"obj": "woman", "action": "preparing salad", "target": "chicken"}, "target_prompt": "A woman cooking chicken in a kitchen.", "target_property": {"obj": "woman", "action": "cooking chicken", "target": "chicken"}, "evaluation_question": "Is the woman **preparing a salad**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman preparing a salad with fresh vegetables. RT#$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e3943e57e324478890b4a1255adfbd1b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d5831ae1c3004373b70e983bcc3c0fd7", "source": "vatex", "video_id": "99zDLR2acf4_000003_000013", "video_description": "A group of people are at a track and field event in the rain. A girl prepares, runs, and throws a javelin into a grassy field while others walk around the track and watch.", "task": "AttributeRecognition", "clean_prompt": "A girl prepares, runs, and throws a javelin into a grassy field while others walk around the track and watch.", "clean_property": {"obj": "field", "attribute": "grassy"}, "target_prompt": "A girl prepares, runs, and throws a javelin into a sandy field while others walk around the track and watch.", "target_property": {"obj": "field", "attribute": "sandy"}, "evaluation_question": "Is the field **grassy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl prepares, runs, and throws a javelin into a grassy field while others walk around the track and watch. ))!*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/22a0b6e2db6c477dbd90ecb6c479ab55.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1338de345d8c4e9d9f400c755301a6ba", "source": "vatex", "video_id": "O0hGDQEgmBA_000002_000012", "video_description": "A person is demonstrating the process of making a ceramic bowl using a pottery wheel, clay, and various tools.", "task": "ObjectRecognition", "clean_prompt": "A person is demonstrating the process of making a ceramic bowl using a pottery wheel.", "clean_property": {"obj": "person"}, "target_prompt": "A robot is demonstrating the process of making a ceramic bowl using a pottery wheel.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the demonstrator in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating the process of making a ceramic bowl using a pottery wheel. HSI@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d3f89be9fc6b45ae9ab00a9ae016d2b7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "06097ca9f2804afbbb13b47e5fc1c48f", "source": "vatex", "video_id": "k79HofPYIgY_000001_000011", "video_description": "A man in a gym is performing squats with a barbell loaded with heavy weights on his shoulders, assisted by two spotters.", "task": "SpatialUnderstanding", "clean_prompt": "A spotter standing to the left of a person performing squats in a gym.", "clean_property": {"obj_1": "spotter", "relation": "left of", "obj_2": "person"}, "target_prompt": "A spotter standing to the right of a person performing squats in a gym.", "target_property": {"obj_1": "spotter", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the spotter to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A spotter standing to the left of a person performing squats in a gym. 6%SLF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed034b957af8433499c2a36fd3fb05fe.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f0276da429a24dd49faf00311e36856d", "source": "vatex", "video_id": "1FzpGH11fxM_000001_000011", "video_description": "An overhead view of a golf course is shown, where several men, including the founder and chief instructors, are playing golf. An older man examines a younger golfer performing a stroke.", "task": "SpatialUnderstanding", "clean_prompt": "An instructor standing to the left of a country club.", "clean_property": {"obj_1": "instructor", "relation": "left of", "obj_2": "country club"}, "target_prompt": "An instructor standing to the right of a country club.", "target_property": {"obj_1": "instructor", "relation": "right of", "obj_2": "country club"}, "evaluation_question": "Is the instructor to the **left** of the country club?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instructor standing to the left of a country club. @@X(P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/89c487b35ac94a8aa3661064712059ec.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "912569fc4b724c9780b2264b7d323afc", "source": "vatex", "video_id": "1Ddy4W31UYQ_000019_000029", "video_description": "A man is trimming and shaving his beard and mustache using an electric razor with a guard, in front of a mirror.", "task": "Counting", "clean_prompt": "A man is trimming and shaving his beard and mustache using two electric razors with guards, in front of a mirror.", "clean_property": {"obj": "electric razor", "count": "two"}, "target_prompt": "A man is trimming and shaving his beard and mustache using one electric razor with a guard, in front of a mirror.", "target_property": {"obj": "electric razor", "count": "one"}, "evaluation_question": "Are there exactly **two** electric razors being used in front of the mirror?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is trimming and shaving his beard and mustache using two electric razors with guards, in front of a mirror. #BAMJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/75134d43f5394ccaad9c45529ffb56f1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9a13e3a480f249c89ff2c8131e8e0990", "source": "vatex", "video_id": "rzp5pdijkpk_000110_000120", "video_description": "Two people are walking through a snowy trail. One person diverges from the path, making an S-shaped path, while the other follows a straight line.", "task": "ObjectRecognition", "clean_prompt": "Two people are walking through a snowy trail, one making an S-shaped path while the other follows a straight line.", "clean_property": {"obj": "trail"}, "target_prompt": "Two people are walking alongside a flowing river, one diverging from the bank while the other stays close to the water's edge.", "target_property": {"obj": "river"}, "evaluation_question": "Are the people walking through a **trail**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are walking through a snowy trail, one making an S-shaped path while the other follows a straight line. =FEP$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/894253b9a73a47c6b778f87759954eeb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e7a1644cbf0400c98daf450bf4186fa", "source": "vatex", "video_id": "GlYbO6kcaBo_000077_000087", "video_description": "A man is skillfully playing an electric guitar, moving along the fretboard and playing various chords.", "task": "Counting", "clean_prompt": "Four people are gathered around a campfire, singing and playing acoustic guitars.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is sitting alone on a park bench, playing an acoustic guitar.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people gathered around the campfire?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are gathered around a campfire, singing and playing acoustic guitars. &))?0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/624d8bea421d4452a60bc755f802fd0a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b168138564c4a7a8afea5de21d9383b", "source": "vatex", "video_id": "DCjbM212h_8_000007_000017", "video_description": "A person is demonstrating how to cut chicken on a cutting board using a sharp knife.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to cut raw chicken on a cutting board using a sharp knife.", "clean_property": {"obj": "chicken", "attribute": "raw"}, "target_prompt": "A person demonstrating how to cut cooked chicken on a cutting board using a sharp knife.", "target_property": {"obj": "chicken", "attribute": "cooked"}, "evaluation_question": "Is the chicken **raw**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to cut raw chicken on a cutting board using a sharp knife. FE)XA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ca86d33045147eba407a905f8c8857f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21a69fde98b5498586845344557075c3", "source": "vatex", "video_id": "r56uijT7L3E_000000_000010", "video_description": "A young man is jumping on a trampoline in a backyard, performing various flips including backflips and a double backflip.", "task": "ActionRecognition", "clean_prompt": "A person bouncing on a trampoline in a backyard.", "clean_property": {"obj": "person", "action": "bouncing on trampoline", "target": null}, "target_prompt": "A person falling off a trampoline in a backyard.", "target_property": {"obj": "person", "action": "falling off trampoline", "target": null}, "evaluation_question": "Is the person **bouncing** on the trampoline?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person bouncing on a trampoline in a backyard. =F#RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f696a18a56c4cc185ec953fa08f21a5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0fa33161848f4103bb214bf5a52a7516", "source": "vatex", "video_id": "r37kasSsIUY_000039_000049", "video_description": "An older man is demonstrating how to hit a golf ball from a difficult position on a small hill at a golf course. He provides instructions and demonstrates the swing technique, including missing the first swing and then hitting the ball with medium force.", "task": "ActionRecognition", "clean_prompt": "A person demonstrating golf chipping on a small hill at a golf course.", "clean_property": {"obj": "person", "action": "golf chipping", "target": "golf ball"}, "target_prompt": "A person demonstrating golf driving on a flat area at a golf course.", "target_property": {"obj": "person", "action": "golf driving", "target": "golf ball"}, "evaluation_question": "Is the person **golf chipping**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating golf chipping on a small hill at a golf course. LY1T$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b2387443c7a483a8e8fa5c5162e95c5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "216a217eb52a4681a6b9aac1b56bbeec", "source": "vatex", "video_id": "7hRinJ_HSF8_000016_000026", "video_description": "A man is cleaning a large glass window outside using professional equipment, including a brush, soap, and a squeegee.", "task": "Counting", "clean_prompt": "A man is cleaning a large glass window outside using seven brushes, soap, and a squeegee.", "clean_property": {"obj": "brush", "count": "seven"}, "target_prompt": "A man is cleaning a large glass window outside using three brushes, soap, and a squeegee.", "target_property": {"obj": "brush", "count": "three"}, "evaluation_question": "Are there exactly **seven** brushes being used to clean the window?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is cleaning a large glass window outside using seven brushes, soap, and a squeegee. $LYYV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b0fa668a2bc948558f64eb009647e3ed.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4946af91832044ddb246c81df8b57b15", "source": "vatex", "video_id": "NbcK-OXxlLg_000030_000040", "video_description": "A group of children, including a young boy in a red hat, are building a large sand castle on the beach near the water on a sunny day.", "task": "ActionRecognition", "clean_prompt": "A child building a sandcastle on the beach.", "clean_property": {"obj": "child", "action": "building sandcastle", "target": null}, "target_prompt": "A child destroying a sandcastle on the beach.", "target_property": {"obj": "child", "action": "destroying sandcastle", "target": null}, "evaluation_question": "Is the child **building** a sandcastle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child building a sandcastle on the beach. R$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/660793676c754aa8b1a92864dc7f6604.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8c72941ba6a1416d8ef200961cb67c71", "source": "vatex", "video_id": "bFxACj0QkTE_000014_000024", "video_description": "A man is using a spray gun to paint the ceiling of a large room.", "task": "SpatialUnderstanding", "clean_prompt": "A spray gun closer to the camera than a person painting the ceiling of a large room.", "clean_property": {"obj_1": "spray gun", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A spray gun further from the camera than a person painting the ceiling of a large room.", "target_property": {"obj_1": "spray gun", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the spray gun **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A spray gun closer to the camera than a person painting the ceiling of a large room. ');!F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d2f773bf93d549eaba88144fc6ee2140.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "17a3127d9d384900a7619934873d9da5", "source": "vatex", "video_id": "79I2uVCxlO4_000166_000176", "video_description": "A police officer is speaking with civilians, including a child and a woman, while they pet his German Shepherd police dog.", "task": "SpatialUnderstanding", "clean_prompt": "A dog farther from the camera than a civilian.", "clean_property": {"obj_1": "dog", "relation": "farther from the camera than", "obj_2": "civilian"}, "target_prompt": "A dog closer to the camera than a civilian.", "target_property": {"obj_1": "dog", "relation": "closer to the camera than", "obj_2": "civilian"}, "evaluation_question": "Is the dog **farther from the camera than** the civilian?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dog farther from the camera than a civilian. 'G*CB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/48a2e6243d6e4d3299efc0a52900a4d0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "431e39f5ac0e46898fb8afbee0ecd443", "source": "vatex", "video_id": "WRbuGFoxj4Y_000013_000023", "video_description": "A young boy with blonde hair is sitting on a table, peeling and eating an orange.", "task": "ObjectRecognition", "clean_prompt": "A young boy with blonde hair is sitting at a table, peeling and eating an orange.", "clean_property": {"obj": "orange"}, "target_prompt": "A young boy with blonde hair is sitting at a table, peeling and eating an apple.", "target_property": {"obj": "apple"}, "evaluation_question": "Is the boy peeling and eating an **orange**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy with blonde hair is sitting at a table, peeling and eating an orange. K4G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/836288e2aff54e1087e95dd4ba80bc5c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "47c50fb902664776857cbdc9cb5d846c", "source": "vatex", "video_id": "L9DHrUYTKWU_000000_000010", "video_description": "A woman is using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "task": "Counting", "clean_prompt": "Two women using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "clean_property": {"obj": "woman", "count": "two"}, "target_prompt": "One woman using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **two** women on the front porch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women using a hairdryer to blow dry a young girl's hair on the front porch of a house. >HSEJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5afbcb915b0e49fda9f0f7b8b9906e2e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8c81b06197a54daf9dc5fa10389db264", "source": "vatex", "video_id": "P_0DGpySlPY_000013_000023", "video_description": "A person is using a small handheld vacuum cleaner to clean various parts of the interior of a car, including the floor, sides, and back seat.", "task": "ActionRecognition", "clean_prompt": "A person vacuuming the floor of a car interior.", "clean_property": {"obj": "person", "action": "vacuuming floor", "target": null}, "target_prompt": "A person cleaning the windows of a car interior.", "target_property": {"obj": "person", "action": "cleaning windows", "target": null}, "evaluation_question": "Is the person **vacuuming** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person vacuuming the floor of a car interior. ,LFS0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/adbdf1333ca246b898b3982b0de087b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d3759d5a68f74c1f8a7d0bbbae5c858e", "source": "vatex", "video_id": "3Qdz1LR3IdI_000000_000010", "video_description": "A street vendor is making snow cones by shaving ice from a large block using a metal scraper, while a group of people watch.", "task": "ObjectRecognition", "clean_prompt": "A street vendor is making snow cones by shaving ice from a large block using a metal scraper.", "clean_property": {"obj": "vendor"}, "target_prompt": "A chef is preparing gourmet dishes in a busy kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **vendor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A street vendor is making snow cones by shaving ice from a large block using a metal scraper. FE=%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f5ae72fdec6a495eaf84a0cce07498bf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eeb42b9ebb2f44cabbf85db76aef54b9", "source": "vatex", "video_id": "NotZAhTOhuY_000000_000010", "video_description": "A young man in a t-shirt and green shorts performs a back flip in a backyard with a wooden fence.", "task": "SpatialUnderstanding", "clean_prompt": "A fence farther from the camera than a person performing a back flip in a backyard.", "clean_property": {"obj_1": "fence", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A fence closer to the camera than a person performing a back flip in a backyard.", "target_property": {"obj_1": "fence", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the fence **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A fence farther from the camera than a person performing a back flip in a backyard. ;TZ$X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/744931b398574aa3afe150229090a873.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d6142a3d0d5140789ed241ad61d92f90", "source": "vatex", "video_id": "X16P9KvmJ4k_000000_000010", "video_description": "A person is demonstrating how to peel a pineapple using a knife. The person is wearing pink gloves and is cutting the pineapple quickly at an outdoor table.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrating how to peel a pineapple at an outdoor table while wearing pink gloves.", "clean_property": {"obj": "person"}, "target_prompt": "A chef demonstrating how to peel a mango at an outdoor table while wearing blue gloves.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the person in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to peel a pineapple at an outdoor table while wearing pink gloves. UMTEA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/86ba2e65ddcf41b0b26730658e1ac115.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "690a37ab044144458570d5fa521eb6e2", "source": "vatex", "video_id": "HnBTadnbmlY_000519_000529", "video_description": "A young man wearing a helmet is skateboarding downhill on a wet road in the woods, followed by a car that is recording the activity.", "task": "ObjectRecognition", "clean_prompt": "A young man wearing a helmet is skateboarding downhill on a wet road in the woods.", "clean_property": {"obj": "person"}, "target_prompt": "A woman wearing a helmet is riding a bicycle uphill on a dry road in the city.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man wearing a helmet is skateboarding downhill on a wet road in the woods. -HW%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7296697dc7354efa9d175b8675a4fd90.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f560b1bba8a4311885f090bd7db9b0f", "source": "vatex", "video_id": "UX6-6Y66dpE_000442_000452", "video_description": "In a commercial kitchen, a chef is demonstrating and instructing a group of culinary students on how to cook eggs over hard and other recipes.", "task": "ObjectRecognition", "clean_prompt": "A chef demonstrating how to cook eggs over hard on a stove in a commercial kitchen.", "clean_property": {"obj": "stove"}, "target_prompt": "A chef demonstrating how to cook eggs over hard on a grill in a commercial kitchen.", "target_property": {"obj": "grill"}, "evaluation_question": "Is the cooking being done on a **stove**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef demonstrating how to cook eggs over hard on a stove in a commercial kitchen. !F9!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2908d40949d248978991b5a5ed214251.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6636a07c4bcc4e27862ee375944d677b", "source": "vatex", "video_id": "ZCYqCA7Jad4_000007_000017", "video_description": "A person with their face covered is spray painting graffiti on a brick wall and then runs away.", "task": "AttributeRecognition", "clean_prompt": "A person with their face covered is spray painting graffiti on a red brick wall and then runs away.", "clean_property": {"obj": "brick wall", "attribute": "red"}, "target_prompt": "A person with their face covered is spray painting graffiti on a blue brick wall and then runs away.", "target_property": {"obj": "brick wall", "attribute": "blue"}, "evaluation_question": "Is the brick wall **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with their face covered is spray painting graffiti on a red brick wall and then runs away. FE+,E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/efb162ad8598476fb9541f6af6480628.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "146e2e8229e34ce295aa22da0a5e817b", "source": "vatex", "video_id": "PePaUt8OROE_000028_000038", "video_description": "A person is outdoors practicing axe throwing at a wooden target, which is an old door. The person throws an axe at the target and then approaches it to examine the result.", "task": "AttributeRecognition", "clean_prompt": "A person practicing axe throwing at a wooden target.", "clean_property": {"obj": "target", "attribute": "wooden"}, "target_prompt": "A person practicing axe throwing at a metal target.", "target_property": {"obj": "target", "attribute": "metal"}, "evaluation_question": "Is the target made of **wood**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing axe throwing at a wooden target. Q@NGS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/94fd28e6d8ce4e03baf5690c3b90064c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13c1b0c505b149339200714529708732", "source": "vatex", "video_id": "ygAPJh9wMmM_000038_000048", "video_description": "A person is skateboarding down a street at night, wearing a helmet, with cars parked along the roadside.", "task": "Counting", "clean_prompt": "A person is skateboarding down a street at night, wearing a helmet, with three cars parked along the roadside.", "clean_property": {"obj": "car", "count": "three"}, "target_prompt": "A person is skateboarding down a street at night, wearing a helmet, with one car parked along the roadside.", "target_property": {"obj": "car", "count": "one"}, "evaluation_question": "Are there exactly **three** cars parked along the roadside?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is skateboarding down a street at night, wearing a helmet, with three cars parked along the roadside. /EEPH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/613a5ab3dd244de28a02f54185b4a777.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4fc750cdd0e4ba4841d70909ea9870f", "source": "vatex", "video_id": "tKSUnPvW6qY_000022_000032", "video_description": "Two couples are involved in kissing. One couple, a man and a woman, are kissing with the woman sometimes pushing the man away. The other couple is seen kissing on a television screen or in a movie still.", "task": "ObjectRecognition", "clean_prompt": "A woman is kissing a man, sometimes playfully pushing him away.", "clean_property": {"obj": "woman"}, "target_prompt": "A man is kissing another man, sometimes playfully pushing him away.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person involved in the kiss a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is kissing a man, sometimes playfully pushing him away. QR))%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f99c29a09c24925a8ee7924b01a9657.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13aea19009df410aa7d2491ec4cff20c", "source": "vatex", "video_id": "HcfF0yaE2gk_000044_000054", "video_description": "A person is holding a knife menacingly.", "task": "AttributeRecognition", "clean_prompt": "A person holding a mini marshmallow with a knife menacingly.", "clean_property": {"obj": "marshmallow", "attribute": "mini"}, "target_prompt": "A person holding a giant marshmallow with a knife menacingly.", "target_property": {"obj": "marshmallow", "attribute": "giant"}, "evaluation_question": "Is the marshmallow **mini**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person holding a mini marshmallow with a knife menacingly. )?G%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bdba528410ab4c33831c9b3fec412cc8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5530489febf44767b3f12b22a458a677", "source": "vatex", "video_id": "W6I7T8reRgs_000002_000012", "video_description": "A young man is performing jumping jacks on a lit basketball court at night. The area is fenced, and there is a logo for personal training displayed.", "task": "ObjectRecognition", "clean_prompt": "A young man performing jumping jacks on a lit basketball court at night.", "clean_property": {"obj": "person"}, "target_prompt": "A woman performing yoga on a beach at sunrise.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **young man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man performing jumping jacks on a lit basketball court at night. LA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d03cdd95b0ec4630abdecb4631b7767c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "518154f275f74b58b303cc2a2cc9580f", "source": "vatex", "video_id": "bdCJ69JY2ro_000078_000088", "video_description": "A woman is washing a large dog in a bathtub using soap, while a man stands behind her, talking and offering guidance.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the right of a woman who is washing a large dog in a bathtub.", "clean_property": {"obj_1": "man", "relation": "right of", "obj_2": "woman"}, "target_prompt": "A man standing to the left of a woman who is washing a large dog in a bathtub.", "target_property": {"obj_1": "man", "relation": "left of", "obj_2": "woman"}, "evaluation_question": "Is the man to the **right** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the right of a woman who is washing a large dog in a bathtub. FEA(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9c4277ca94e449338f69f9e6e73e93e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "96992b1c693f42c787b90637686e52a6", "source": "vatex", "video_id": "uDEm3XS7aEk_000002_000012", "video_description": "A young child is making a cooking tutorial video, demonstrating how to cut a large mushroom into even strips using a small knife.", "task": "ObjectRecognition", "clean_prompt": "A child making a cooking tutorial video, demonstrating how to cut a large mushroom into even strips using a small knife.", "clean_property": {"obj": "child"}, "target_prompt": "An adult making a cooking tutorial video, demonstrating how to cut a large mushroom into even strips using a small knife.", "target_property": {"obj": "adult"}, "evaluation_question": "Is the person in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child making a cooking tutorial video, demonstrating how to cut a large mushroom into even strips using a small knife. ))!B*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/83bbef75564248ce8ec9114f7310b033.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de95c73f4e0a45f487892593edd0d8a7", "source": "vatex", "video_id": "jp55UfpAAxQ_000021_000031", "video_description": "A young child is being bathed by a woman, who pours water over the child's head, causing the child to cry. The bath takes place in a raised tub or sink, possibly outdoors.", "task": "ActionRecognition", "clean_prompt": "A child crying while being bathed by a woman outdoors.", "clean_property": {"obj": "child", "action": "crying", "target": null}, "target_prompt": "A child laughing while being bathed by a woman outdoors.", "target_property": {"obj": "child", "action": "laughing", "target": null}, "evaluation_question": "Is the child **crying**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child crying while being bathed by a woman outdoors. RV'+G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e670a796ccc4229938960163d5e48bd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c96dc57cd814afbb0fb5847910df2b7", "source": "vatex", "video_id": "k9oRxHgjBn0_000012_000022", "video_description": "A woman is performing ballet spins and dance moves in a studio, demonstrating different techniques and balance.", "task": "AttributeRecognition", "clean_prompt": "A person in casual wear performing ballet spins in a studio.", "clean_property": {"obj": "person", "attribute": "in casual wear"}, "target_prompt": "A person in formal wear performing ballet spins in a studio.", "target_property": {"obj": "person", "attribute": "in formal wear"}, "evaluation_question": "Is the person in **casual** wear?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in casual wear performing ballet spins in a studio. FEA/O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/54715a1c90f0442d966326b0b36c872a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1a94fd9225dc4b299032c5cd91af99f3", "source": "vatex", "video_id": "E-gaCwIVipE_001233_001243", "video_description": "A young man with long, shoulder-length hair is sitting in a chair while a teenage girl uses a flat iron to straighten his hair. They are in a bedroom, and there is conversation happening in the background.", "task": "ActionRecognition", "clean_prompt": "A teenage girl ironing a young man's hair in a bedroom.", "clean_property": {"obj": "teenage girl", "action": "ironing hair", "target": "young man"}, "target_prompt": "A teenage girl curling a young man's hair in a bedroom.", "target_property": {"obj": "teenage girl", "action": "curling hair", "target": "young man"}, "evaluation_question": "Is the teenage girl **ironing** the young man's hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenage girl ironing a young man's hair in a bedroom. .2(OT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/89bba432d47a42e9adb36f1b0bec0d4c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a1a893b19a2a4fcfa6b35dd5b7a2d534", "source": "vatex", "video_id": "TgGQ6awU5HE_000033_000043", "video_description": "A man is demonstrating how to tie and untie various knots, including a slip knot, using a rope attached to a pole.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a pole while demonstrating how to tie knots with a rope.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "pole"}, "target_prompt": "A person standing to the right of a pole while demonstrating how to tie knots with a rope.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "pole"}, "evaluation_question": "Is the person to the **left** of the pole?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a pole while demonstrating how to tie knots with a rope. 'C%|)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/726e5d68fadd4b2aa52279dfcc380f8b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "461fb38af7ad4c5c92549bcacbd46c2e", "source": "vatex", "video_id": "-D5KTtjxubY_000174_000184", "video_description": "A man is sitting on a large exercise ball, demonstrating and explaining exercises while swaying his hips and shifting his torso.", "task": "ObjectRecognition", "clean_prompt": "A man sitting on a large exercise ball, demonstrating and explaining exercises while swaying his hips and shifting his torso.", "clean_property": {"obj": "person"}, "target_prompt": "A woman sitting on a large exercise ball, demonstrating and explaining exercises while swaying her hips and shifting her torso.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sitting on a large exercise ball, demonstrating and explaining exercises while swaying his hips and shifting his torso. !@9VU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/94d4bbedd8d34aedaf82e975040b8247.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac9b02a5670e453480fd3b212785db9f", "source": "vatex", "video_id": "OcJ6fkoWEq0_000004_000014", "video_description": "A woman in a pink dress sings karaoke with a microphone in a store or restaurant setting, while a group of people gather around, cheering, clapping, and talking loudly.", "task": "ObjectRecognition", "clean_prompt": "A woman in a pink dress sings karaoke with a microphone in a store while a group of people gathers around, cheering and clapping.", "clean_property": {"obj": "microphone"}, "target_prompt": "A woman in a pink dress plays guitar in a store while a group of people gathers around, cheering and clapping.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the woman using a **microphone** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a pink dress sings karaoke with a microphone in a store while a group of people gathers around, cheering and clapping. =FE.U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/638adfe1a61a458b84fcc4d88f8c7da9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "441cef049c68478fa220f5a7b5633c70", "source": "vatex", "video_id": "iheIju_enig_000000_000010", "video_description": "A woman is performing a dumbbell exercise routine in a living room while a man provides commentary.", "task": "SpatialUnderstanding", "clean_prompt": "A dumbbell farther from the camera than a woman in a living room.", "clean_property": {"obj_1": "dumbbell", "relation": "farther from the camera than", "obj_2": "woman"}, "target_prompt": "A dumbbell closer to the camera than a woman in a living room.", "target_property": {"obj_1": "dumbbell", "relation": "closer to the camera than", "obj_2": "woman"}, "evaluation_question": "Is the dumbbell **farther from the camera than** the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A dumbbell farther from the camera than a woman in a living room. '');'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3299d19c1e724eff9ae91d66c7a20374.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d5e2ed74d315460b82c87e80b54c156c", "source": "vatex", "video_id": "xzLthRwnBQI_000055_000065", "video_description": "A woman is using a power tool with a buffing attachment to polish various pieces of jewelry, including a ring, brooch, and bracelet, while giving verbal instructions.", "task": "Counting", "clean_prompt": "A woman is using two power tools with buffing attachments to polish various pieces of jewelry.", "clean_property": {"obj": "power tool", "count": "two"}, "target_prompt": "A woman is using one power tool with a buffing attachment to polish various pieces of jewelry.", "target_property": {"obj": "power tool", "count": "one"}, "evaluation_question": "Are there exactly **two** power tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using two power tools with buffing attachments to polish various pieces of jewelry. UF\u00b7O.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fcdab4e29e874dfa90244dc5828fe6ef.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b849b3316ee145989217a6c1a81242b6", "source": "vatex", "video_id": "VGeZLZJdxBg_000022_000032", "video_description": "A group of people, including women, are stomping grapes with their bare feet in barrels and buckets during a local event with live music.", "task": "ActionRecognition", "clean_prompt": "A person stomping grapes in a barrel during a local event.", "clean_property": {"obj": "person", "action": "stomping grapes", "target": null}, "target_prompt": "A person dancing in a barrel during a local event.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **stomping grapes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stomping grapes in a barrel during a local event. GAA(.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b769a5d64694b719c3a74587a8aa209.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "416c87417f9d47f6b11a034c087e3346", "source": "vatex", "video_id": "xnwYls4tz48_000003_000013", "video_description": "A group of people, including women and girls, are making homemade pizzas at a kitchen table, adding various toppings like cheese and sauce.", "task": "ObjectRecognition", "clean_prompt": "A group of people making homemade pizzas at a kitchen table.", "clean_property": {"obj": "table"}, "target_prompt": "A group of people making homemade pizzas at a kitchen counter.", "target_property": {"obj": "counter"}, "evaluation_question": "Is the group making pizzas at a **table**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people making homemade pizzas at a kitchen table. 0BC@|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bd81ff2bbb70454ab47910460303b3f2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fe757d9dbad740f2a156d6d8abdf2e95", "source": "vatex", "video_id": "FpyGyZfkBMo_000176_000186", "video_description": "A man wearing a safety mask and apron is demonstrating how to repair a sandal using an electric machine.", "task": "AttributeRecognition", "clean_prompt": "A man wearing a safety mask and apron is demonstrating how to repair a sandal using an electric machine.", "clean_property": {"obj": "machine", "attribute": "electric"}, "target_prompt": "A man wearing a safety mask and apron is demonstrating how to repair a sandal using a manual machine.", "target_property": {"obj": "machine", "attribute": "manual"}, "evaluation_question": "Is the machine being used in the video an **electric** machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing a safety mask and apron is demonstrating how to repair a sandal using an electric machine. -*G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e27a2ed71bc24ae8900ca7b7e0417080.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e8f830b4bf094283a31f396b40550e13", "source": "vatex", "video_id": "DJ6EhnhrQsg_000000_000010", "video_description": "Two children, a boy and a girl, are in a bathroom or locker room drying their hair with white blow dryers.", "task": "ObjectRecognition", "clean_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers.", "clean_property": {"obj": "blow dryer"}, "target_prompt": "Two children, a boy and a girl, are in a bathroom using hair straighteners to style their hair.", "target_property": {"obj": "hair straightener"}, "evaluation_question": "Are the children using **blow dryers** to dry their hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children, a boy and a girl, are in a bathroom drying their hair with white blow dryers. >RAO6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1f4827fef48f45bebf182f2daf269797.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d7936265106d42a2afa4717e3134ba21", "source": "vatex", "video_id": "b8mlAeW6oIQ_000028_000038", "video_description": "A person is chopping wood using a small axe on a large stump outdoors.", "task": "ActionRecognition", "clean_prompt": "A person chopping wood using a small axe on a large stump outdoors.", "clean_property": {"obj": "person", "action": "chopping wood", "target": "wood"}, "target_prompt": "A person sawing wood on a large stump outdoors.", "target_property": {"obj": "person", "action": "sawing wood", "target": "wood"}, "evaluation_question": "Is the person **chopping** wood?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person chopping wood using a small axe on a large stump outdoors. V+OAE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eaa9603591fb442595fe96f1ae3fc7e1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "843b86e32c514451a5863f25cee4a089", "source": "vatex", "video_id": "4Umxg5FkYyw_000031_000041", "video_description": "A group of people are at a ski resort on a snowy hill, some skiing and some snowboarding. One person on a snowboard is laughing at a skier who has fallen. The scene is set on a cloudy day with a chair lift nearby.", "task": "Counting", "clean_prompt": "Seven chair lifts operating at a ski resort on a snowy hill.", "clean_property": {"obj": "chair lift", "count": "seven"}, "target_prompt": "Three chair lifts operating at a ski resort on a snowy hill.", "target_property": {"obj": "chair lift", "count": "three"}, "evaluation_question": "Are there exactly **seven** chair lifts operating at the ski resort?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven chair lifts operating at a ski resort on a snowy hill. 6BC2V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b89c3e4f101b47368b2617fc736d4a4d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "67700d1df8b242fc8e10722ac0445043", "source": "vatex", "video_id": "Y4Ty7vfjImY_000013_000023", "video_description": "A woman is in her bedroom demonstrating how to curl her long blonde hair using a curling iron and hairspray.", "task": "Counting", "clean_prompt": "Two women in a bedroom demonstrating how to curl their long blonde hair using curling irons and hairspray.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A woman in a bedroom demonstrating how to curl her long blonde hair using a curling iron and hairspray.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** women in the bedroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women in a bedroom demonstrating how to curl their long blonde hair using curling irons and hairspray. !1C%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dea7f0c7655348e598e0fbf2d6398b3f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb599c2431424d47a0097ffedf14cb1a", "source": "vatex", "video_id": "YnojwIPsH0g_000000_000010", "video_description": "A person attempts to perform a jump on a scooter at a skate park, but crashes upon landing.", "task": "SpatialUnderstanding", "clean_prompt": "A scooter farther from the camera than a ramp in a skate park.", "clean_property": {"obj_1": "scooter", "relation": "farther from the camera than", "obj_2": "ramp"}, "target_prompt": "A scooter closer to the camera than a ramp in a skate park.", "target_property": {"obj_1": "scooter", "relation": "closer to the camera than", "obj_2": "ramp"}, "evaluation_question": "Is the scooter **farther from the camera than** the ramp?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scooter farther from the camera than a ramp in a skate park. ))!%F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ec2e5a799b844c4bed53d98b88e90b4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cc87830279d845b29272fa4636270e0d", "source": "vatex", "video_id": "r5zzY8oiwRE_000015_000025", "video_description": "A man and a boy are practicing baseball on an outdoor field. The boy is at the batter's plate, and the man runs over to give him a high five.", "task": "AttributeRecognition", "clean_prompt": "A man who is a coach is helping a boy practice baseball on an outdoor field.", "clean_property": {"obj": "man", "attribute": "coach"}, "target_prompt": "A man who is a referee is overseeing a baseball game on an outdoor field.", "target_property": {"obj": "man", "attribute": "referee"}, "evaluation_question": "Is the man a **coach**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man who is a coach is helping a boy practice baseball on an outdoor field. !/!%/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f925e9cf08e748d5aa9cedc141768b36.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "da19a2763bec40db812081aae24ce318", "source": "vatex", "video_id": "hW2ZI3zp74I_000190_000200", "video_description": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night. The truck is slowly driving down a road, with workers walking around and behind it, bringing garbage cans to the back.", "task": "ObjectRecognition", "clean_prompt": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night.", "clean_property": {"obj": "worker"}, "target_prompt": "Firefighters are extinguishing a fire in a residential area at night.", "target_property": {"obj": "firefighter"}, "evaluation_question": "Are the workers in the video **garbage truck workers**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Garbage truck workers are collecting and loading garbage into the back of a garbage truck at night. G&FET", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/84bcc4167e384340bd6270308e50c077.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "96545ea77aeb415f8c411c27658d7ed4", "source": "vatex", "video_id": "vgsveBkXVss_000291_000301", "video_description": "A man is demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant.", "clean_property": {"obj": "tire tube"}, "target_prompt": "A man demonstrating how to repair a hole in a car tire using glue and a sealant.", "target_property": {"obj": "car tire"}, "evaluation_question": "Is the object being repaired in the video a **bicycle tire tube**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to repair a hole in a bicycle tire tube using glue and a sealant. SG$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2830b3ad86274d7ea33f239850c95544.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2f6ea1255e9456c931a966b6de1bd91", "source": "vatex", "video_id": "_TxYl6Sgy3A_000000_000010", "video_description": "A man with curly hair is playing a lute in a church for an audience.", "task": "ActionRecognition", "clean_prompt": "A musician playing a lute in a church.", "clean_property": {"obj": "musician", "action": "playing lute", "target": null}, "target_prompt": "A musician singing in a church.", "target_property": {"obj": "musician", "action": "singing", "target": null}, "evaluation_question": "Is the musician **playing a lute**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician playing a lute in a church. SF9/?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a40c4f71face49c5bdffa45f3a1c3de4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac85ea38fcca4957bf74d97565f8ad79", "source": "vatex", "video_id": "KgQ7p-NBkpg_000001_000011", "video_description": "A young woman is in a gym performing a squat clean and split jerk with a heavy barbell, lifting it from the floor to over her head.", "task": "AttributeRecognition", "clean_prompt": "A young woman in a gym performing a squat clean and split jerk with a heavy barbell.", "clean_property": {"obj": "barbell", "attribute": "heavy"}, "target_prompt": "A young woman in a gym performing a squat clean and split jerk with a light barbell.", "target_property": {"obj": "barbell", "attribute": "light"}, "evaluation_question": "Is the barbell **heavy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman in a gym performing a squat clean and split jerk with a heavy barbell. -@NRA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/99d30d281f624bf18210d43304207dd3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d49f1777c2b54cc3a85d70d5fe663945", "source": "vatex", "video_id": "NXdLU5LM7cQ_000007_000017", "video_description": "A young woman and a young man are taking turns drinking shots of liquor from tall shot glasses on a city street in broad daylight.", "task": "Counting", "clean_prompt": "A young woman and a young man are taking turns drinking two shots of liquor from tall shot glasses on a city street in broad daylight.", "clean_property": {"obj": "shot glass", "count": "two"}, "target_prompt": "A young woman and a young man are taking turns drinking one shot of liquor from a tall shot glass on a city street in broad daylight.", "target_property": {"obj": "shot glass", "count": "one"}, "evaluation_question": "Are there exactly **two** shot glasses being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman and a young man are taking turns drinking two shots of liquor from tall shot glasses on a city street in broad daylight. )))=,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/774dd361cd0940a990a755982d92bedd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1e40637a5f4a49b8abeeeea7246b317a", "source": "vatex", "video_id": "BnVdrJvsPsU_000213_000223", "video_description": "A woman is demonstrating and explaining how to apply eyeliner to the outer edge of her eyelid.", "task": "Counting", "clean_prompt": "A woman is demonstrating and explaining how to apply eyeliner to the outer edge of her eyelid with seven people watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman is demonstrating and explaining how to apply eyeliner to the outer edge of her eyelid with two people watching her.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating and explaining how to apply eyeliner to the outer edge of her eyelid with seven people watching her. -SL/$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/051c103130674dd9b8ef0a097b7a8bc0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "207c954d085549e7b08355140a379cb7", "source": "vatex", "video_id": "VYpmVK7fCY4_000000_000010", "video_description": "Two men demonstrate and discuss car seat hacks, including swinging and spinning a child in a car seat.", "task": "ObjectRecognition", "clean_prompt": "Two men demonstrating car seat hacks while swinging and spinning a child in a car seat.", "clean_property": {"obj": "child"}, "target_prompt": "Two men demonstrating car seat hacks while swinging and spinning a dog in a car seat.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the object being swung and spun in the car seat a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men demonstrating car seat hacks while swinging and spinning a child in a car seat. Q'UAM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67bd27f01c1a42de922545bf386e0278.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d577ae1b8b104428a4e1535ebb43d274", "source": "vatex", "video_id": "1M_ehUdQbpE_000000_000010", "video_description": "A young man in a red shirt and headband is spray painting graffiti on a cement wall outdoors while music plays.", "task": "ActionRecognition", "clean_prompt": "A person tagging graffiti on a cement wall outdoors.", "clean_property": {"obj": "person", "action": "tagging graffiti", "target": "wall"}, "target_prompt": "A person cleaning graffiti off a cement wall outdoors.", "target_property": {"obj": "person", "action": "cleaning graffiti", "target": "wall"}, "evaluation_question": "Is the person **tagging** graffiti?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tagging graffiti on a cement wall outdoors. ED%FB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e51cbf20b1c476084555a7368e3dabd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "63972086ab54402f9162b32a5a40fa56", "source": "vatex", "video_id": "jCd7wi4ygf0_000089_000099", "video_description": "A young male athlete is performing a high jump on a track and field setup, with a woman commentating on the event.", "task": "SpatialUnderstanding", "clean_prompt": "A commentator standing to the right of an athlete performing a high jump on a track and field setup.", "clean_property": {"obj_1": "commentator", "relation": "right of", "obj_2": "athlete"}, "target_prompt": "A commentator standing to the left of an athlete performing a high jump on a track and field setup.", "target_property": {"obj_1": "commentator", "relation": "left of", "obj_2": "athlete"}, "evaluation_question": "Is the commentator to the **right** of the athlete?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A commentator standing to the right of an athlete performing a high jump on a track and field setup. FE@+>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c5cad6f8acfd4997a4bad49a096ae7bd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e6dffcf961d847e3b4b5944a5f2c2836", "source": "vatex", "video_id": "qHw1Qr2ouWo_000020_000030", "video_description": "A group of people, including a woman in a green hat, are participating in an oyster shucking competition on a stage with a judge observing.", "task": "ActionRecognition", "clean_prompt": "A person shucking oysters on a stage during a competition.", "clean_property": {"obj": "person", "action": "shucking oysters", "target": null}, "target_prompt": "A person eating oysters on a stage during a competition.", "target_property": {"obj": "person", "action": "eating oysters", "target": null}, "evaluation_question": "Is the person **shucking** oysters?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shucking oysters on a stage during a competition. SL.SN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3a3f71c69c64a6a9bea02f6bf0754a2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c18db891cbc448db7271d6df98475d6", "source": "vatex", "video_id": "gTJkX00FNVI_000121_000131", "video_description": "A young boy is using a marker to create graffiti on an interior wall of a room.", "task": "Counting", "clean_prompt": "Four boys using markers to create graffiti on an interior wall of a room.", "clean_property": {"obj": "boy", "count": "four"}, "target_prompt": "Two girls using paintbrushes to create a mural on an exterior wall of a building.", "target_property": {"obj": "girl", "count": "two"}, "evaluation_question": "Are there exactly **four** boys creating graffiti on the wall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four boys using markers to create graffiti on an interior wall of a room. ))!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ced2e782f8494d528d5f6c7ee6792396.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3d51c42b087747368b19bffdf1440ee8", "source": "vatex", "video_id": "V18XWMwhP8M_000000_000010", "video_description": "A woman is in a car at a drive-thru ATM, using the machine to withdraw cash and retrieve her bank card.", "task": "ActionRecognition", "clean_prompt": "A person using an ATM at a drive-thru.", "clean_property": {"obj": "person", "action": "using atm", "target": null}, "target_prompt": "A person walking away from an ATM at a drive-thru.", "target_property": {"obj": "person", "action": "walking away from ATM", "target": null}, "evaluation_question": "Is the person **using** the ATM?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using an ATM at a drive-thru. !'))V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d19adcb9207d4330942aafcd8c381dd7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d256fbbf43bf44068d82963e3f5d9199", "source": "vatex", "video_id": "e0zfZDAXyEo_000002_000012", "video_description": "A man wearing a horse head mask and shorts is playing an electric guitar outdoors near a graffiti-covered wall.", "task": "Counting", "clean_prompt": "A man wearing a horse head mask and shorts is playing five electric guitars outdoors near a graffiti-covered wall.", "clean_property": {"obj": "guitar", "count": "five"}, "target_prompt": "A man wearing a horse head mask and shorts is playing one electric guitar outdoors near a graffiti-covered wall.", "target_property": {"obj": "guitar", "count": "one"}, "evaluation_question": "Are there exactly **five** electric guitars being played?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing a horse head mask and shorts is playing five electric guitars outdoors near a graffiti-covered wall. TS..?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1dbd92b20b7c429e90a9870d06faf5d4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "976c62c4cf1c43df9e572c1a9102d4a4", "source": "vatex", "video_id": "1FBqdsOeraI_000362_000372", "video_description": "A person is using a large knife to chop various food items, including yellow fruit and garlic, into small cubes on a wooden cutting board.", "task": "AttributeRecognition", "clean_prompt": "A person is chopping yellow fruit and garlic into small cubes on a wooden cutting board.", "clean_property": {"obj": "food", "attribute": "yellow fruit"}, "target_prompt": "A person is chopping red vegetable and garlic into small cubes on a wooden cutting board.", "target_property": {"obj": "food", "attribute": "red vegetable"}, "evaluation_question": "Is the person chopping **yellow fruit**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is chopping yellow fruit and garlic into small cubes on a wooden cutting board. 3BSNE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6fbd5ac371ca47029f767ce8b2fec7e5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5a66980f6f4b48ecb2fdcc33297dd816", "source": "vatex", "video_id": "eAz-jW31Iq8_000205_000215", "video_description": "A man is demonstrating how to shuffle a deck of cards on a table, occasionally chatting with another man.", "task": "ObjectRecognition", "clean_prompt": "A man is demonstrating how to shuffle a deck of cards on a table.", "clean_property": {"obj": "deck of cards"}, "target_prompt": "A man is demonstrating how to play chess with chess pieces on a table.", "target_property": {"obj": "chess pieces"}, "evaluation_question": "Is the object being shuffled in the video a **deck of cards**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to shuffle a deck of cards on a table. 5DE*)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf7c9fa19de941b3b968d8538069b389.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "77b9116fe01e47e5a227c4430df40d83", "source": "vatex", "video_id": "49Ab7GEUFyo_000003_000013", "video_description": "A small child is in a bathroom brushing their teeth with a yellow toothbrush while standing at a sink.", "task": "Counting", "clean_prompt": "A child is in a bathroom brushing their teeth with a yellow toothbrush while standing at a sink.", "clean_property": {"obj": "child", "count": "five"}, "target_prompt": "A child is in a bathroom brushing their teeth with a yellow toothbrush while standing at a sink.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **five** children in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is in a bathroom brushing their teeth with a yellow toothbrush while standing at a sink. >BADJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee53cd8e652d4791bd3d682cf6aeb6d9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "829be53e4e42471d88e182c3e202d4b5", "source": "vatex", "video_id": "ahn2ZIUSa2Y_000006_000016", "video_description": "A man is practicing calf roping outdoors with a horse. He captures a calf by throwing a lasso, ties its legs, and walks away.", "task": "Counting", "clean_prompt": "A man practicing calf roping outdoors with four horses.", "clean_property": {"obj": "horse", "count": "four"}, "target_prompt": "A man practicing calf roping outdoors with one horse.", "target_property": {"obj": "horse", "count": "one"}, "evaluation_question": "Are there exactly **four** horses present in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man practicing calf roping outdoors with four horses. MV+*@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e502b5a09caa46ba95188c3ff4d34e3e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "53add0ff037e4f7d97d6ba813e55d3cb", "source": "vatex", "video_id": "NZLydTq7Q98_000003_000013", "video_description": "A man in a blue top, wearing a baseball cap and sports equipment, is at an outdoor archery range holding a bow and arrow. He prepares to fire at a target and walks towards the camera.", "task": "Counting", "clean_prompt": "Three people at an outdoor archery range, with one man in a blue top, wearing a baseball cap and sports equipment, preparing to fire at a target.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person at an outdoor archery range, preparing to fire at a target.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people at the outdoor archery range?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people at an outdoor archery range, with one man in a blue top, wearing a baseball cap and sports equipment, preparing to fire at a target. OFU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/299939a9673b4b37b4b99a0e151a9a45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "52b401415ff0464580585f7cc229a2eb", "source": "vatex", "video_id": "pKHzmL4p5Ao_000000_000010", "video_description": "Two men open a door and discuss the importance of acquiring skills for a job while smiling and talking to the camera.", "task": "ActionRecognition", "clean_prompt": "A person opening a door and discussing skills for a job.", "clean_property": {"obj": "person", "action": "opening door", "target": null}, "target_prompt": "A person closing a door and discussing skills for a job.", "target_property": {"obj": "person", "action": "closing door", "target": null}, "evaluation_question": "Is the person **opening** a door?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person opening a door and discussing skills for a job. G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/74746efde80d4c21aeb59591996f1fef.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0e0cfc29ce214ea2a16dd4aefcd54eab", "source": "vatex", "video_id": "PBui9niyfvI_000172_000182", "video_description": "A man is sitting on the floor of a bedroom playing Monopoly with a young child. He occasionally lifts up a card and smiles.", "task": "ActionRecognition", "clean_prompt": "A man playing Monopoly on the floor of a bedroom.", "clean_property": {"obj": "man", "action": "playing monopoly", "target": null}, "target_prompt": "A man playing chess on the floor of a bedroom.", "target_property": {"obj": "man", "action": "playing chess", "target": null}, "evaluation_question": "Is the man **playing Monopoly**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man playing Monopoly on the floor of a bedroom. LFYE#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/adb5faee662441618bde0d6d8ec29b70.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8f3f7f280f1462e81d666fa06657759", "source": "vatex", "video_id": "4-giuyB2Gk0_000205_000215", "video_description": "Several construction workers are working on a building project at a construction site with a crane moving back and forth.", "task": "ObjectRecognition", "clean_prompt": "Several construction workers are working on a building project at a construction site with a crane moving back and forth.", "clean_property": {"obj": "construction worker"}, "target_prompt": "Several chefs are preparing meals in a busy kitchen with pots and pans sizzling on the stove.", "target_property": {"obj": "chef"}, "evaluation_question": "Are there **construction workers** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several construction workers are working on a building project at a construction site with a crane moving back and forth. ELIM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/511f268b60af46e49c0b7dd071ca1806.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "02df2de92eed4c8e9f52a1b049d3c99f", "source": "vatex", "video_id": "L9DHrUYTKWU_000000_000010", "video_description": "A woman is using a hairdryer to blow dry a young girl's hair on the front porch of a house.", "task": "ActionRecognition", "clean_prompt": "A woman blowdrying a girl's hair on the front porch of a house.", "clean_property": {"obj": "woman", "action": "blowdrying hair", "target": "girl"}, "target_prompt": "A woman curling a girl's hair on the front porch of a house.", "target_property": {"obj": "woman", "action": "curling hair", "target": "girl"}, "evaluation_question": "Is the woman **blowdrying** the girl's hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman blowdrying a girl's hair on the front porch of a house. G&LF/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7e9cba0d104b4e7bbeead74bf36a7787.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "da9aa2f80c41431899ba9c17067c34ba", "source": "vatex", "video_id": "ofnDF6Ci03M_000041_000051", "video_description": "Two women are interacting playfully outdoors. One woman is sitting on a sofa with her eyes closed, while the other woman stands before her, placing her elbow near the seated woman's mouth.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a sofa.", "clean_property": {"obj_1": "woman_2", "relation": "farther from the camera than", "obj_2": "sofa"}, "target_prompt": "A woman closer to the camera than a sofa.", "target_property": {"obj_1": "woman_2", "relation": "closer to the camera than", "obj_2": "sofa"}, "evaluation_question": "Is the woman **farther from the camera than** the sofa?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a sofa. LF.,G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7440ef223008475dbf91b3b03f6b201b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2f7c266167864d9f9ddca20b98bb1b6d", "source": "vatex", "video_id": "WBgBSxunVrs_000000_000010", "video_description": "A person is demonstrating how to knit using blue knitting needles and cream-colored yarn.", "task": "ActionRecognition", "clean_prompt": "A person knitting with blue knitting needles and cream-colored yarn.", "clean_property": {"obj": "person", "action": "knitting", "target": null}, "target_prompt": "A person crocheting with colorful yarn.", "target_property": {"obj": "person", "action": "crocheting", "target": null}, "evaluation_question": "Is the person **knitting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person knitting with blue knitting needles and cream-colored yarn. ;7TSC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/01e5ea2eb689421bae3332b20bce7c08.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4d65138fb9724c8780f4e2e40d3f120c", "source": "vatex", "video_id": "fwPFrdBrkto_000002_000012", "video_description": "A large group of people are dancing and singing energetically to Gospel music during a church service.", "task": "Counting", "clean_prompt": "A large group of people are dancing and singing energetically to two Gospel music songs during a church service.", "clean_property": {"obj": "music", "count": "two"}, "target_prompt": "A large group of people are dancing and singing energetically to one Gospel music song during a church service.", "target_property": {"obj": "music", "count": "one"}, "evaluation_question": "Are there exactly **two** Gospel music songs being played during the church service?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A large group of people are dancing and singing energetically to two Gospel music songs during a church service. LYT+I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/be23d821486b4b9581fc37de85eb4d06.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "28fd3c582c204c03af65fa584d3474c6", "source": "vatex", "video_id": "5_xXj3SAX68_000117_000127", "video_description": "A woman in a home kitchen demonstrates a cooking procedure involving transferring vegetables from a pot to a colander using a slotted spoon, including an ice bath step.", "task": "Counting", "clean_prompt": "Three women in a home kitchen demonstrating a cooking procedure.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "A woman in a home kitchen demonstrating a cooking procedure.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women in a home kitchen demonstrating a cooking procedure. X.TDM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cbbea0d2c4df46d1a608bf509e848897.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b969de3c12914acfb371cab1f8943427", "source": "vatex", "video_id": "-wrnx4pGDIs_000042_000052", "video_description": "A group of female cheerleaders in red uniforms perform a synchronized dance routine on a gymnasium floor in front of a live audience.", "task": "SpatialUnderstanding", "clean_prompt": "An audience farther from the camera than a cheerleader performing a synchronized dance routine in a gymnasium.", "clean_property": {"obj_1": "audience", "relation": "farther from the camera than", "obj_2": "cheerleader"}, "target_prompt": "An audience closer to the camera than a cheerleader performing a synchronized dance routine in a gymnasium.", "target_property": {"obj_1": "audience", "relation": "closer to the camera than", "obj_2": "cheerleader"}, "evaluation_question": "Is the audience **farther from the camera than** the cheerleader?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An audience farther from the camera than a cheerleader performing a synchronized dance routine in a gymnasium. !*U%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/122c7bbda39c420cb30f8b368e871ed5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1a1a9720b5334a5c8c00d9b5458b9f52", "source": "vatex", "video_id": "17Gjt3E3w80_000089_000099", "video_description": "A young woman is in a dark space, using a flashlight to intermittently light her face while lip-syncing to music.", "task": "SpatialUnderstanding", "clean_prompt": "A flashlight farther from the camera than a person in a dark space.", "clean_property": {"obj_1": "flashlight", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A flashlight closer to the camera than a person in a dark space.", "target_property": {"obj_1": "flashlight", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the flashlight **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A flashlight farther from the camera than a person in a dark space. ''?);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ebcf9ffdf0374502875e483ffe220f30.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de2d9a7fa6f54da6b1b50a9ae8c63cbe", "source": "vatex", "video_id": "l8qplp0g7C8_000005_000015", "video_description": "A young Asian male is in a gym performing weightlifting exercises, including deadlifts and squats, with a barbell in front of a mirror.", "task": "AttributeRecognition", "clean_prompt": "A young Asian male is in a gym performing weightlifting exercises with a heavy barbell in front of a mirror.", "clean_property": {"obj": "barbell", "attribute": "heavy"}, "target_prompt": "A young Asian male is in a gym performing weightlifting exercises with a light barbell in front of a mirror.", "target_property": {"obj": "barbell", "attribute": "light"}, "evaluation_question": "Is the barbell **heavy**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young Asian male is in a gym performing weightlifting exercises with a heavy barbell in front of a mirror. !0D0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5455cc74c52546899d5673012f54adb9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d9c8b4f4c001475e9c834a1871c36eba", "source": "vatex", "video_id": "0Jhq7ceS0lk_000001_000011", "video_description": "A little girl in a pink top is inflating a yellow balloon using her nose and then smiles.", "task": "ActionRecognition", "clean_prompt": "A girl inflating a yellow balloon using her nose and then smiles.", "clean_property": {"obj": "girl", "action": "inflating balloons", "target": "balloon"}, "target_prompt": "A girl popping a yellow balloon and laughing.", "target_property": {"obj": "girl", "action": "popping balloons", "target": "balloon"}, "evaluation_question": "Is the girl **inflating** a balloon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl inflating a yellow balloon using her nose and then smiles. 9EAS$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7786e118dbbd4c97a1867a45cb7ab118.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "95695a501e5a495e8f5de758e1fba09a", "source": "vatex", "video_id": "YcFuODvX85U_000002_000012", "video_description": "A man is skillfully dicing pineapple slices into small pieces using a large chef knife on a cutting board in a kitchen.", "task": "ActionRecognition", "clean_prompt": "A person cutting pineapple on a cutting board in a kitchen.", "clean_property": {"obj": "person", "action": "cutting pineapple", "target": null}, "target_prompt": "A person slicing watermelon on a cutting board in a kitchen.", "target_property": {"obj": "person", "action": "slicing watermelon", "target": null}, "evaluation_question": "Is the person **cutting pineapple**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cutting pineapple on a cutting board in a kitchen. .RP\u00b7'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24c435dd89434115bb7b5ef109dc537d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7b3671f1894543e48ef02af075168462", "source": "vatex", "video_id": "j8cVhLi_N1I_000054_000064", "video_description": "A young girl rides a hoverboard, explaining its features and origin while maneuvering over grass and pavement.", "task": "SpatialUnderstanding", "clean_prompt": "A girl riding a hoverboard, explaining its features and origin while maneuvering over grass and pavement, positioned to the right of the hoverboard.", "clean_property": {"obj_1": "girl", "relation": "right of", "obj_2": "hoverboard"}, "target_prompt": "A girl riding a hoverboard, explaining its features and origin while maneuvering over grass and pavement, positioned to the left of the hoverboard.", "target_property": {"obj_1": "girl", "relation": "left of", "obj_2": "hoverboard"}, "evaluation_question": "Is the girl to the **right** of the hoverboard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl riding a hoverboard, explaining its features and origin while maneuvering over grass and pavement, positioned to the right of the hoverboard. LY+)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/666d2270e43a4922a8dae22df9d9f183.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d76b5fc8249849a4810e9c3862527bf2", "source": "vatex", "video_id": "cqL8A6sznp8_000458_000468", "video_description": "A woman is demonstrating various methods of cooking eggs, including frying, poaching, and boiling, using a pan and a spoon.", "task": "Counting", "clean_prompt": "A woman is using two spoons to demonstrate various methods of cooking eggs.", "clean_property": {"obj": "spoon", "count": "two"}, "target_prompt": "A woman is using one spoon to demonstrate various methods of cooking eggs.", "target_property": {"obj": "spoon", "count": "one"}, "evaluation_question": "Are there exactly **two** spoons being used in the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using two spoons to demonstrate various methods of cooking eggs. ;E8$0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2cfc9514d5db4362a3b37073d93d9324.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ad69ac2472a4a809a62a4eb2bed032a", "source": "vatex", "video_id": "stbVH1C-IT0_000020_000030", "video_description": "A man is using a chainsaw to carve a large ice sculpture outdoors at night, while a group of people watch and cheer.", "task": "SpatialUnderstanding", "clean_prompt": "Onlookers standing to the left of an ice sculpture.", "clean_property": {"obj_1": "onlookers", "relation": "left of", "obj_2": "ice sculpture"}, "target_prompt": "Onlookers standing to the right of an ice sculpture.", "target_property": {"obj_1": "onlookers", "relation": "right of", "obj_2": "ice sculpture"}, "evaluation_question": "Are the onlookers to the **left** of the ice sculpture?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Onlookers standing to the left of an ice sculpture. FE$R!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d1067fd0f7042eab0f38948556f7fe7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "098b48248ea44201ade5c4f2a698d98c", "source": "vatex", "video_id": "UmbJQOAl5mQ_000013_000023", "video_description": "A performer is demonstrating fire-breathing tricks in front of an engaged audience at a carnival-like outdoor setting.", "task": "ActionRecognition", "clean_prompt": "A performer breathing fire in front of an engaged audience at a carnival-like outdoor setting.", "clean_property": {"obj": "performer", "action": "breathing fire", "target": null}, "target_prompt": "A performer juggling fire in front of an engaged audience at a carnival-like outdoor setting.", "target_property": {"obj": "performer", "action": "juggling fire", "target": null}, "evaluation_question": "Is the performer **breathing fire**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A performer breathing fire in front of an engaged audience at a carnival-like outdoor setting. PFE;A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/816dcbaa6b774bceb35035ab80081131.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b7e11b07cebb43e3a12f7590c840ab3e", "source": "vatex", "video_id": "hBhyqgseghA_000008_000018", "video_description": "A young woman is jumping rope in slow motion with a big smile on her face, wearing pink pants and barefoot, while dance music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A young woman is jumping rope in slow motion with a big smile on her face, wearing pink pants and barefoot.", "clean_property": {"obj": "person"}, "target_prompt": "A dog jumping in slow motion with a big smile on its face, wearing a colorful bandana.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman is jumping rope in slow motion with a big smile on her face, wearing pink pants and barefoot. G%Q9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/12a76c1a7437403b88b7ea4ded32ae98.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c6bf639618f6400bb014a3a1bd1bd3f9", "source": "vatex", "video_id": "JrStedTM6Kw_000123_000133", "video_description": "A woman is demonstrating how to knead a ball of dough in her hands while speaking in a foreign language.", "task": "SpatialUnderstanding", "clean_prompt": "A woman demonstrating how to knead a ball of dough in her hands while a person is standing to the right of her.", "clean_property": {"obj_1": "dough", "relation": "right of", "obj_2": "person"}, "target_prompt": "A woman demonstrating how to knead a ball of dough in her hands while a person is standing to the left of her.", "target_property": {"obj_1": "dough", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the dough to the **right** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to knead a ball of dough in her hands while a person is standing to the right of her. BSQGI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f7fe9c33ba4745e1afd5dd64b63c2da3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c8c501de7064dc7a04e2df4db15ac27", "source": "vatex", "video_id": "zUempCKuG_c_000000_000010", "video_description": "A young woman is outside, blowing bubbles with bubble gum while interacting with a tablet.", "task": "ActionRecognition", "clean_prompt": "A person looking at their phone outside.", "clean_property": {"obj": "person", "action": "looking at phone", "target": null}, "target_prompt": "A person playing with bubbles outside.", "target_property": {"obj": "person", "action": "playing with bubbles", "target": null}, "evaluation_question": "Is the person **looking at their phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person looking at their phone outside. XD;MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b2f1f9714e1c4163af4ac4bd0b9cde1f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3f7f0989c0714bde8ac1a72f78e01bd7", "source": "vatex", "video_id": "wRgpPfvaLZ8_000139_000149", "video_description": "A group of young men are setting up and playing a game of beer pong in a kitchen. They are adjusting cups on a table and using a ping pong ball.", "task": "ObjectRecognition", "clean_prompt": "A person setting up and playing a game of beer pong in a kitchen.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a ping pong ball in a kitchen.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person setting up and playing a game of beer pong in a kitchen. !D$),", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac97265596314af29d3ba3073df59590.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3a0373cbdb414cb591ecb27c64ca48c4", "source": "vatex", "video_id": "9uokR1lv3mo_000000_000010", "video_description": "A boy is demonstrating and performing backflips on a mattress while his friend cheers him on in a dimly lit room.", "task": "ActionRecognition", "clean_prompt": "A boy performing a backflip on a mattress while his friend cheers him on in a dimly lit room.", "clean_property": {"obj": "boy", "action": "backflip (human)", "target": null}, "target_prompt": "A boy falling off a mattress while his friend cheers him on in a dimly lit room.", "target_property": {"obj": "boy", "action": "falling", "target": null}, "evaluation_question": "Is the boy **performing a backflip**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy performing a backflip on a mattress while his friend cheers him on in a dimly lit room. R&FE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f187410760441a8aa95892b221d0b54.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5cff5e2d1a974dac8142b58ccf92aac9", "source": "vatex", "video_id": "Z3BeONGMTsQ_000000_000010", "video_description": "A group of young children are playing a game of football on a grassy field, wearing helmets and uniforms. They are being watched by family and spectators.", "task": "Counting", "clean_prompt": "A group of six children playing football on a grassy field.", "clean_property": {"obj": "football", "count": "six"}, "target_prompt": "A group of two children playing football on a sandy beach.", "target_property": {"obj": "football", "count": "two"}, "evaluation_question": "Are there exactly **six** children playing football on the grassy field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of six children playing football on a grassy field. >5Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f7f42049d26c4ccd90861b676e677525.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d5d8c43f39754752ae7ebcd0d2934ac9", "source": "vatex", "video_id": "u0e6NtVR7eM_000000_000010", "video_description": "A young man is dancing energetically in a room with a wooden floor, performing street dance moves to upbeat music.", "task": "Counting", "clean_prompt": "Three people dancing energetically in a room with a wooden floor.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person dancing energetically in a room with a wooden floor.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people dancing in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people dancing energetically in a room with a wooden floor. @IP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ee873852ec704a39874af6c5ea84380c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "302447fff890481d91103a1182c5b828", "source": "vatex", "video_id": "4DVx18w-rmk_000038_000048", "video_description": "A young boy is demonstrating card throwing tricks, repeatedly holding and throwing a playing card towards the camera.", "task": "AttributeRecognition", "clean_prompt": "A boy wearing shorts is demonstrating card throwing tricks.", "clean_property": {"obj": "boy", "attribute": "wearing shorts"}, "target_prompt": "A boy wearing a superhero costume is demonstrating card throwing tricks.", "target_property": {"obj": "boy", "attribute": "wearing a superhero costume"}, "evaluation_question": "Is the boy wearing **shorts**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy wearing shorts is demonstrating card throwing tricks. RR.E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38519a45c00b432db3ab5277bcba1480.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1b4cbe0c32448bc840f2f5aab3abea4", "source": "vatex", "video_id": "9EZKYCAOAvk_000119_000129", "video_description": "A man is demonstrating and explaining how to clean a window sill using a spray bottle and a cloth.", "task": "ObjectRecognition", "clean_prompt": "A man is cleaning a window sill using a spray bottle and a cloth.", "clean_property": {"obj": "window"}, "target_prompt": "A man is cleaning a door using a spray bottle and a cloth.", "target_property": {"obj": "door"}, "evaluation_question": "Is the man cleaning a **window**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is cleaning a window sill using a spray bottle and a cloth. )VREZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/122829a7ae774336b15ac662947399c9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "09ffccdc350b49e9afb12b83f571df25", "source": "vatex", "video_id": "95YJMSMrrFY_000000_000010", "video_description": "A teenage boy participates in a long jump competition at a track and field meet. He runs on a track and jumps into a pit of sand, where a woman measures the distance.", "task": "ObjectRecognition", "clean_prompt": "A woman measuring the distance of a long jump at a track and field meet.", "clean_property": {"obj": "woman"}, "target_prompt": "A man measuring the distance of a long jump at a track and field meet.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person measuring the distance a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman measuring the distance of a long jump at a track and field meet. ''?)/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4e4fa32695184456803b85eee583432f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a34cc0b2939a45b79f7056ed71d52538", "source": "vatex", "video_id": "USn563lPuYU_000071_000081", "video_description": "A man is using a tool to seal glass bottles with caps, occasionally talking to another person.", "task": "ObjectRecognition", "clean_prompt": "A man sealing glass bottles with caps while talking to another person.", "clean_property": {"obj": "bottle"}, "target_prompt": "A man sealing jars with lids while talking to another person.", "target_property": {"obj": "jar"}, "evaluation_question": "Is the man sealing **bottles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sealing glass bottles with caps while talking to another person. FE5$A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f03c057aa8444d51bb5555c5d113bd0e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "300a4f3297e040febe73fcdcb3139858", "source": "vatex", "video_id": "6EI0O8yrnWI_000000_000010", "video_description": "A group of people, including kids and teenagers, are playing badminton in an indoor gymnasium with two nets. There are multiple games happening simultaneously.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a racket in an indoor gymnasium where people are playing badminton.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "racket"}, "target_prompt": "A person further from the camera than a racket in an indoor gymnasium where people are playing badminton.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "racket"}, "evaluation_question": "Is the person **closer to the camera than** the racket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a racket in an indoor gymnasium where people are playing badminton. !0D*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6db7aeb26059474e9e997260b54ce04c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "26830ae8455f445b8e4b53daec4f1ef0", "source": "vatex", "video_id": "h0zxrUPIapI_000000_000010", "video_description": "A man in a royal, historical costume is speaking to an audience in an outdoor theater setting.", "task": "SpatialUnderstanding", "clean_prompt": "A person speaking to an audience in an outdoor theater setting, positioned farther from the camera than the audience.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "audience"}, "target_prompt": "A person speaking to an audience in an outdoor theater setting, positioned closer to the camera than the audience.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "audience"}, "evaluation_question": "Is the person **farther from the camera than** the audience?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person speaking to an audience in an outdoor theater setting, positioned farther from the camera than the audience. ''!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73eb326ef7154a8f9b0663aaf1faa467.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8230a7cb6ed44672919f0b0ce0699487", "source": "vatex", "video_id": "Ca78lDSy4to_000122_000132", "video_description": "A person is demonstrating how to fold a piece of white paper into an origami design on a table.", "task": "AttributeRecognition", "clean_prompt": "A person is demonstrating how to fold a piece of white paper into an origami design on a table.", "clean_property": {"obj": "paper", "attribute": "white"}, "target_prompt": "A person is demonstrating how to fold a piece of blue paper into an origami design on a table.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper being used in the demonstration **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to fold a piece of white paper into an origami design on a table. SLXBK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0fd564dbe33f4102af51b34bb2e3ba3a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "75d14adc8b0e4de58eaa60f06ad152c6", "source": "vatex", "video_id": "B65AIrPb29U_000000_000010", "video_description": "A woman is lying in a hospital bed with an oxygen mask on her face. She is waking up and moving slightly, surrounded by family members, including a girl who talks to another person about the woman's condition.", "task": "ObjectRecognition", "clean_prompt": "A woman lying in a hospital bed with an oxygen mask, waking up and surrounded by family members.", "clean_property": {"obj": "woman"}, "target_prompt": "A man lying in a hospital bed with an oxygen mask, waking up and surrounded by family members.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person in the hospital bed a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman lying in a hospital bed with an oxygen mask, waking up and surrounded by family members. GNAA)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9b0b451742cd4fdeaed2885d31ee4bf4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "748cbf15f85042f09b20943de4227383", "source": "vatex", "video_id": "xqB7XzNAWGA_000071_000081", "video_description": "A person is using colored pencils to draw and color on a piece of paper, sharpening the pencils as needed.", "task": "AttributeRecognition", "clean_prompt": "A person is using colored pencils to draw and color on a piece of white paper, sharpening the pencils as needed.", "clean_property": {"obj": "paper", "attribute": "white"}, "target_prompt": "A person is using colored pencils to draw and color on a piece of blue paper, sharpening the pencils as needed.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is using colored pencils to draw and color on a piece of white paper, sharpening the pencils as needed. U%U*U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8d328c2b98f4e5e9277edba25193a70.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a3990b71e16401baad2fe4b78428166", "source": "vatex", "video_id": "AbL-AXmlmmM_000008_000018", "video_description": "A young boy is driving and steering a riding lawnmower with an older man sitting behind him, guiding and teaching him in a grassy field.", "task": "Counting", "clean_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field, with four boys playing nearby.", "clean_property": {"obj": "boy", "count": "four"}, "target_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field.", "target_property": {"obj": "boy", "count": "one"}, "evaluation_question": "Are there exactly **four** boys playing nearby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy driving a riding lawnmower with an older man sitting behind him in a grassy field, with four boys playing nearby. ICA|K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/82f8ee34fa15442b9e0fd06dcc2a9891.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ab87084eea514148b96dcaf5d8ef7eca", "source": "vatex", "video_id": "u8ErD1FXV74_000019_000029", "video_description": "A group of young kids and adults are playing football on a field in a large stadium. The kids are running, kicking field goals, and trying to catch balls while adults watch and play with them. A man in a red shirt is involved in the activities.", "task": "Counting", "clean_prompt": "A man in a red shirt is playing football with a group of kids on a field.", "clean_property": {"obj": "man in red shirt", "count": "six"}, "target_prompt": "Six men in blue shirts are playing football on a field.", "target_property": {"obj": "man in blue shirt", "count": "six"}, "evaluation_question": "Is there exactly **one** man in a red shirt playing football?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a red shirt is playing football with a group of kids on a field. !AQ*&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/03254f82d25f429e9860eedc76ae07e9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aab792b32299403c898b47a3041316da", "source": "vatex", "video_id": "pcbkfqgaJk8_000000_000010", "video_description": "Two young girls are lying down side by side, sneezing one after the other, while filming themselves.", "task": "ActionRecognition", "clean_prompt": "A girl sneezing while lying down.", "clean_property": {"obj": "girl", "action": "sneezing", "target": null}, "target_prompt": "A girl laughing while lying down.", "target_property": {"obj": "girl", "action": "laughing", "target": null}, "evaluation_question": "Is the girl **sneezing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl sneezing while lying down. RL,X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b1ded49f769b423e93cd97b8c247aa5f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "102c96f94a744a108fe761f382a9be7a", "source": "vatex", "video_id": "nfH0p_KAHSk_000029_000039", "video_description": "A young girl is riding a camel in the desert, assisted by a man who adjusts her saddle and gives instructions.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a camel in the desert.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "camel"}, "target_prompt": "A man closer to the camera than a camel in the desert.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "camel"}, "evaluation_question": "Is the man **farther from the camera than** the camel?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a camel in the desert. ))!G*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/15bcb697fb6d4f64b7ee7b156cdcf1e9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9830809db5ac47f79f207273994bd7ba", "source": "vatex", "video_id": "Xdxpo_ZxA04_000064_000074", "video_description": "A man is demonstrating and explaining various leg stretching exercises on a yoga mat in a room.", "task": "ActionRecognition", "clean_prompt": "A person stretching their leg on a yoga mat in a room.", "clean_property": {"obj": "person", "action": "stretching leg", "target": null}, "target_prompt": "A person jumping on a yoga mat in a room.", "target_property": {"obj": "person", "action": "jumping", "target": null}, "evaluation_question": "Is the person **stretching their leg**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stretching their leg on a yoga mat in a room. !0UDF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a0a728c22da942babe7d346f3a559991.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b988889498de4ee59087dee63302ee6e", "source": "vatex", "video_id": "blb_4I5nsek_000000_000010", "video_description": "A small child is at home, repeatedly blowing their nose into a small piece of tissue and occasionally looking at it.", "task": "ObjectRecognition", "clean_prompt": "A small child at home blowing their nose into a tissue.", "clean_property": {"obj": "child"}, "target_prompt": "A cat playing with a ball of yarn at home.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A small child at home blowing their nose into a tissue. QRL0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/720397f6ca3b458593b9b3c81c1facb8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7efcf3fada784e179d0244bdd4244f4a", "source": "vatex", "video_id": "a1SASZM2epM_000015_000025", "video_description": "Two volleyball teams are playing a match in a gymnasium with a referee overseeing the game.", "task": "ActionRecognition", "clean_prompt": "A volleyball player playing volleyball in a gymnasium.", "clean_property": {"obj": "volleyball player", "action": "playing volleyball", "target": null}, "target_prompt": "A volleyball player sitting on the bench in a gymnasium.", "target_property": {"obj": "volleyball player", "action": "sitting on the bench", "target": null}, "evaluation_question": "Is the volleyball player **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A volleyball player playing volleyball in a gymnasium. ))!D/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bedcdde739de4f1ba3a7afd8f254f0ba.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "506dba0095e94d80a7415ffca1e58576", "source": "vatex", "video_id": "70vgdqht6JU_000000_000010", "video_description": "A man is performing arm exercises with small dumbbells in his living room.", "task": "ActionRecognition", "clean_prompt": "A person performing front raises with small dumbbells in a living room.", "clean_property": {"obj": "person", "action": "front raises", "target": null}, "target_prompt": "A person squatting in a living room.", "target_property": {"obj": "person", "action": "squatting", "target": null}, "evaluation_question": "Is the person **performing front raises**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing front raises with small dumbbells in a living room. DK*))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/82499c69c46e4e8b814ace0ed3141ef4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cc5996500679438a88838480ea617e90", "source": "vatex", "video_id": "9JoGtU00rAU_000000_000010", "video_description": "A young woman in a red tank top is demonstrating front shoulder raises with weights in a gym.", "task": "ActionRecognition", "clean_prompt": "A person performing front raises with weights in a gym.", "clean_property": {"obj": "person", "action": "front raises", "target": "weights"}, "target_prompt": "A person performing side raises with dumbbells in a gym.", "target_property": {"obj": "person", "action": "side raises", "target": "dumbbells"}, "evaluation_question": "Is the person **performing front raises** with weights?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing front raises with weights in a gym. LFY$E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c882f1976ec4f4ab9cb8ed55955005f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6633dc1a79eb4d8a966598c04e875791", "source": "vatex", "video_id": "nld6SJ5bqA8_000002_000012", "video_description": "A young boy is seated at a table with a birthday cake in front of him. His family sings 'Happy Birthday' as he blows out the candles on an Elmo-themed cake.", "task": "ObjectRecognition", "clean_prompt": "A young boy is seated at a table with a birthday cake in front of him as his family sings 'Happy Birthday'.", "clean_property": {"obj": "cake"}, "target_prompt": "A young boy is seated at a table with a pizza in front of him as his family sings 'Happy Birthday'.", "target_property": {"obj": "pizza"}, "evaluation_question": "Is the object in front of the boy a **cake**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is seated at a table with a birthday cake in front of him as his family sings 'Happy Birthday'. ''?)*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f80658e04c6d4a14b3d29499ed7a787d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "153e222a2f7648debdbacd6f4940008b", "source": "vatex", "video_id": "2QyifbCgNuo_000154_000164", "video_description": "Two news anchors are discussing a sports event involving a serviceman who is also a pole vaulter. The segment includes footage of a person pole vaulting over a high bar and landing on a mat.", "task": "AttributeRecognition", "clean_prompt": "A pole vaulter who is a serviceman vaulting over a high bar.", "clean_property": {"obj": "pole vaulter", "attribute": "serviceman"}, "target_prompt": "A pole vaulter wearing a superhero costume vaulting over a high bar.", "target_property": {"obj": "pole vaulter", "attribute": "wearing a superhero costume"}, "evaluation_question": "Is the pole vaulter a **serviceman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pole vaulter who is a serviceman vaulting over a high bar. JRU)>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aabbbb24e38f4e7f9965fead40892239.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "79da82017f14459c89685ac4a160c5e1", "source": "vatex", "video_id": "OGQ32IHOmXo_000025_000035", "video_description": "A woman demonstrates how to fold a jacket and pack it in a suitcase to prevent wrinkling, then transfers it to a hanger.", "task": "SpatialUnderstanding", "clean_prompt": "A hanger positioned to the right of a person demonstrating how to fold a jacket.", "clean_property": {"obj_1": "hanger", "relation": "right of", "obj_2": "person"}, "target_prompt": "A hanger positioned to the left of a person demonstrating how to fold a jacket.", "target_property": {"obj_1": "hanger", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the hanger to the **right** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A hanger positioned to the right of a person demonstrating how to fold a jacket. ))'!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8e1c3c51ee814a81bef38bc4f15eb13f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "53599ec0b899455aa7caa686ea09ba81", "source": "vatex", "video_id": "T7JBwJrPl8k_000070_000080", "video_description": "A small white dog is being dried with a towel by a person after a bath.", "task": "ObjectRecognition", "clean_prompt": "A small white dog is being dried with a towel by a person after a bath.", "clean_property": {"obj": "towel"}, "target_prompt": "A small white dog is being wrapped in a blanket by a person after a bath.", "target_property": {"obj": "blanket"}, "evaluation_question": "Is the object being used to dry the dog a **towel**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A small white dog is being dried with a towel by a person after a bath. @JSV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cead55dc6896497a932053fba4ce275e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0b1cfd026ae54718bc7cbcb33f81c2e0", "source": "vatex", "video_id": "Emwoyf1aorI_000027_000037", "video_description": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "clean_property": {"obj": "knitting needles"}, "target_prompt": "A woman demonstrates how to crochet using a crochet hook and yarn, providing a step-by-step guide.", "target_property": {"obj": "crochet hook"}, "evaluation_question": "Is the woman using **knitting needles** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide. LY%;P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ecc64511d20f4e81b48256376831fe0f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8fa38eccddc5433282da18c1f988ca76", "source": "vatex", "video_id": "B3yH6gdtZy4_000210_000220", "video_description": "A woman demonstrates and instructs on how to curl hair using a flat iron on a young girl in a bathroom setting.", "task": "Counting", "clean_prompt": "Two girls in a bathroom, one demonstrating how to curl hair using a flat iron on the other.", "clean_property": {"obj": "girl", "count": "two"}, "target_prompt": "A girl in a bathroom, demonstrating how to curl hair using a flat iron.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **two** girls in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two girls in a bathroom, one demonstrating how to curl hair using a flat iron on the other. -!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/021368be6e8b48309a0c231bca49b3a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5782975344a9448ca68291a3e1c3c8f9", "source": "vatex", "video_id": "WAo0uqgDUUo_000000_000010", "video_description": "A man is outside a house cleaning a large window using a squeegee.", "task": "ActionRecognition", "clean_prompt": "A person cleaning windows outside a house.", "clean_property": {"obj": "person", "action": "cleaning windows", "target": "window"}, "target_prompt": "A person painting walls outside a house.", "target_property": {"obj": "person", "action": "painting walls", "target": "wall"}, "evaluation_question": "Is the person **cleaning windows**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning windows outside a house. LZ$AN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba57a884115e46d0a36502dbf2db9472.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc119c56b1424ba48d5308c91160db78", "source": "vatex", "video_id": "BJ3-1nz8P90_000001_000011", "video_description": "A woman is giving a bath to a large, light brown and white dog on cement steps outside a building.", "task": "AttributeRecognition", "clean_prompt": "A woman smiling while giving a bath to a large, light brown and white dog on cement steps outside a building.", "clean_property": {"obj": "woman", "attribute": "smiling"}, "target_prompt": "A woman frowning while giving a bath to a large, light brown and white dog on cement steps outside a building.", "target_property": {"obj": "woman", "attribute": "frowning"}, "evaluation_question": "Is the woman **smiling** while giving the bath?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman smiling while giving a bath to a large, light brown and white dog on cement steps outside a building. 0BC2%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5d27a3104fba45c3aebbe6b06dfe7954.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a89a83c70a5441686ca9f19f7094840", "source": "vatex", "video_id": "-asB1gNPw38_000136_000146", "video_description": "A man in cycling gear, wearing a helmet, is riding a bicycle at high speeds on a busy road, trying to keep up with other bikers.", "task": "Counting", "clean_prompt": "Two bikers riding bicycles at high speeds on a busy road.", "clean_property": {"obj": "biker", "count": "two"}, "target_prompt": "One biker riding a bicycle at high speeds on a busy road.", "target_property": {"obj": "biker", "count": "one"}, "evaluation_question": "Are there exactly **two** bikers riding on the road?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two bikers riding bicycles at high speeds on a busy road. >TS49", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1f29daa801b6413d80fef2a8f0ae41a0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f085c6fe168546198ce9610e753503d2", "source": "vatex", "video_id": "-Bb_zut9Ciw_000021_000031", "video_description": "A man is standing on the shore of a large body of water, such as an ocean or lake, using a long fishing rod to cast a line in an attempt to catch fish. The footage is recorded in slow motion.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing farther from the camera than a fishing rod on the shore of a large body of water.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "fishing rod"}, "target_prompt": "A person standing closer to the camera than a fishing rod on the shore of a large body of water.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "fishing rod"}, "evaluation_question": "Is the person farther from the camera than the fishing rod?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing farther from the camera than a fishing rod on the shore of a large body of water. &FEZQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f6b25adabfc44c5b8f09ccb73b820cd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6cd43fd1bd3e4bb8a86ed1761a425df5", "source": "vatex", "video_id": "h1Ftl9t0rhA_000006_000016", "video_description": "A man is demonstrating how to tie a knot using a string and a silver ring, which is hanging from another string.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to tie a knot using a string and a silver ring.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to tie a knot using a string and a silver ring.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to tie a knot using a string and a silver ring. R=))-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6dfd387ab194613b6601e438455a2db.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13b795ce7c7d4b2eadbb828dc2e390a7", "source": "vatex", "video_id": "Y5mgnkJRecs_000034_000044", "video_description": "Two men in formal Scottish dress are standing on a beach. One man is playing the bagpipes while the other stands beside him.", "task": "Counting", "clean_prompt": "Six men in formal Scottish dress are standing on a beach. One man is playing the bagpipes while the others stand beside him.", "clean_property": {"obj": "man", "count": "six"}, "target_prompt": "Three men in casual beachwear are playing frisbee on the sand.", "target_property": {"obj": "man", "count": "three"}, "evaluation_question": "Are there exactly **six** men in formal Scottish dress on the beach?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six men in formal Scottish dress are standing on a beach. One man is playing the bagpipes while the others stand beside him. >8CFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc5426f69e6445aa9c96fd215520be7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "55ff61b332db44068e9701015b356681", "source": "vatex", "video_id": "kfDeEcbwdYY_000000_000010", "video_description": "A group of teenage girl volleyball players in red and black uniforms are playing a volleyball match in a large indoor gym. The players are on a volleyball court, hitting the ball back and forth over a net, with some players coming in and out of the game. The teams are preparing for the match, with players standing still and getting ready to serve.", "task": "ActionRecognition", "clean_prompt": "A volleyball player playing volleyball in a large indoor gym.", "clean_property": {"obj": "volleyball player", "action": "playing volleyball", "target": "volleyball"}, "target_prompt": "A volleyball player cheering in a large indoor gym.", "target_property": {"obj": "volleyball player", "action": "cheering", "target": "volleyball"}, "evaluation_question": "Is the volleyball player **playing** volleyball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A volleyball player playing volleyball in a large indoor gym. =S#TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d9f430373a4241e1b89cad3ee3c761cf.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9969456a7bec4045ab8b72e51eb0ff9a", "source": "vatex", "video_id": "PE3pN-tvfmM_000000_000010", "video_description": "A person is performing a handstand on a wooden or gym floor while music plays.", "task": "ActionRecognition", "clean_prompt": "A person standing on hands on a wooden floor while music plays.", "clean_property": {"obj": "person", "action": "standing on hands", "target": null}, "target_prompt": "A person doing a backflip on a wooden floor while music plays.", "target_property": {"obj": "person", "action": "doing a backflip", "target": null}, "evaluation_question": "Is the person **standing on hands**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing on hands on a wooden floor while music plays. ;D#K@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3854d3083d6b45f2b3d8e34156874ae0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4069cd192e034c95b34fa041a37db27f", "source": "vatex", "video_id": "LevshcEdCsU_000113_000123", "video_description": "A man is eating a messy meal and drinking a beverage, making a mess, while a woman laughs.", "task": "AttributeRecognition", "clean_prompt": "A man is a sloppy eater, making a mess while eating a meal and drinking a beverage, while a woman laughs.", "clean_property": {"obj": "man", "attribute": "sloppy eater"}, "target_prompt": "A man is a neat eater, carefully enjoying a meal and sipping a beverage, while a woman smiles.", "target_property": {"obj": "man", "attribute": "neat eater"}, "evaluation_question": "Is the man a **sloppy** eater?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is a sloppy eater, making a mess while eating a meal and drinking a beverage, while a woman laughs. W%(\u00b7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8a65473fc884f54be1d14ab3f1f60aa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ef9080f2482450cbf0e61e6f77cc7b3", "source": "vatex", "video_id": "aDNE7rWDFA4_000197_000207", "video_description": "A person is creating artwork of a black aquatic mammal, likely a dolphin, on a piece of pink paper using various tools and techniques including drawing and painting.", "task": "Counting", "clean_prompt": "A person is creating artwork of a black aquatic mammal, likely a dolphin, on four pieces of pink paper using various tools and techniques including drawing and painting.", "clean_property": {"obj": "paper", "count": "four"}, "target_prompt": "A person is creating artwork of a black aquatic mammal, likely a dolphin, on one piece of pink paper using various tools and techniques including drawing and painting.", "target_property": {"obj": "paper", "count": "one"}, "evaluation_question": "Are there exactly **four** pieces of pink paper being used in the artwork?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is creating artwork of a black aquatic mammal, likely a dolphin, on four pieces of pink paper using various tools and techniques including drawing and painting. LFY(M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bad1cd1b6097414f843318f3cfe79598.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f25186b978f24d89bbe4394853fbd875", "source": "vatex", "video_id": "c8N9aqGstfg_000132_000142", "video_description": "A woman is in a kitchen demonstrating how to make and bake jumbo chocolate chip cookies, explaining the process, temperature, and time required. She takes the cookies out of the oven and places them on a tray.", "task": "SpatialUnderstanding", "clean_prompt": "A tray positioned to the left of a person in a kitchen demonstrating how to make jumbo chocolate chip cookies.", "clean_property": {"obj_1": "tray", "relation": "left of", "obj_2": "person"}, "target_prompt": "A tray positioned to the right of a person in a kitchen demonstrating how to make jumbo chocolate chip cookies.", "target_property": {"obj_1": "tray", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the tray to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tray positioned to the left of a person in a kitchen demonstrating how to make jumbo chocolate chip cookies. W%!))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c31a7d18a3904d4f8b33532d81c54f98.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "961d60cb72044604a9b2ce453c39355a", "source": "vatex", "video_id": "PCMOHhyNAZw_000020_000030", "video_description": "A young boy is sitting next to a replica cow, pretending to milk it into a bucket, while a man speaks to him in Spanish.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting next to a replica cow, pretending to milk it into a bucket, while a man speaks to him in Spanish.", "clean_property": {"obj": "cow"}, "target_prompt": "A young boy is sitting next to a replica horse, pretending to ride it while a man speaks to him in Spanish.", "target_property": {"obj": "horse"}, "evaluation_question": "Is the boy pretending to milk a **cow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting next to a replica cow, pretending to milk it into a bucket, while a man speaks to him in Spanish. PL,OT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dfea787b8b1945c9bffe63ff84091f94.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "98a210b596de4a76aa22d0fccc7ac5f7", "source": "vatex", "video_id": "TnDlF_KaiY4_000044_000054", "video_description": "A group of children are playing inside an inflatable bouncy house, throwing and holding inflatable balls, and occasionally falling.", "task": "SpatialUnderstanding", "clean_prompt": "A child farther from the camera than a ball inside an inflatable bouncy house.", "clean_property": {"obj_1": "child", "relation": "farther from the camera than", "obj_2": "ball"}, "target_prompt": "A child closer to the camera than a ball inside an inflatable bouncy house.", "target_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "ball"}, "evaluation_question": "Is the child **farther from the camera than** the ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child farther from the camera than a ball inside an inflatable bouncy house. BSQ2(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/58a06739e9ad4ce39f36804b359f5567.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5928c0994e324fadba47e386ffc62232", "source": "vatex", "video_id": "Z5w-wkrjHuw_000345_000355", "video_description": "A large group of people, mostly young, are roller skating in a rink. They are skating in circles, holding hands, and talking to each other, creating a lively and social atmosphere.", "task": "Counting", "clean_prompt": "A large group of people roller skating in a rink with seven skaters holding hands and talking to each other.", "clean_property": {"obj": "rink", "count": "seven"}, "target_prompt": "A large group of people roller skating in a rink with three skaters holding hands and talking to each other.", "target_property": {"obj": "rink", "count": "three"}, "evaluation_question": "Are there exactly **seven** skaters in the rink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A large group of people roller skating in a rink with seven skaters holding hands and talking to each other. *GHYC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a36cd3952cde45c2b2caf3102309f7b3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0be6e5fcf2a141fa96de38689c59c23d", "source": "vatex", "video_id": "JBz7PUxDyE4_000035_000045", "video_description": "A man is demonstrating exercises using battle ropes on a green turf field, focusing on core strengthening.", "task": "SpatialUnderstanding", "clean_prompt": "Battle ropes farther from the camera than a person demonstrating exercises on a green turf field.", "clean_property": {"obj_1": "battle ropes", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "Battle ropes closer to the camera than a person demonstrating exercises on a green turf field.", "target_property": {"obj_1": "battle ropes", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Are the battle ropes **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Battle ropes farther from the camera than a person demonstrating exercises on a green turf field. FAC.Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ae6e5b94b9a546d1b017918c38634266.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "15c4421001734cfbb9811cccab0ced55", "source": "vatex", "video_id": "-TAr0OegNok_000000_000010", "video_description": "A man is performing a handstand on a moving hoverboard as he travels down an empty street.", "task": "Counting", "clean_prompt": "Four people watching a man performing a handstand on a moving hoverboard as he travels down an empty street.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person watching a man performing a handstand on a moving hoverboard as he travels down an empty street.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people watching a man performing a handstand on a moving hoverboard as he travels down an empty street. FE-L'", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f88050f8ffd437186a1bbe9057cd04d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c02768a6078a4493bcfc4aeecd8c940e", "source": "vatex", "video_id": "K0WOzuD4-oc_000017_000027", "video_description": "A man is playing pranks on people in public using a fake snake, causing them to react in surprise and fear.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a fake snake, playing a prank on passersby.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "fake snake"}, "target_prompt": "A person standing to the left of a fake snake, playing a prank on passersby.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "fake snake"}, "evaluation_question": "Is the person to the **right** of a fake snake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a fake snake, playing a prank on passersby. ?'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/902a5165d3ef4bf085ae435791591903.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ef2bb8315c5e4eec9e7e5a3531c8829a", "source": "vatex", "video_id": "uMusUcJgA2E_000058_000068", "video_description": "A man is grooming his beard using a comb and an electric trimmer.", "task": "Counting", "clean_prompt": "A man is grooming his beard using three combs and an electric trimmer.", "clean_property": {"obj": "comb", "count": "three"}, "target_prompt": "A man is grooming his beard using one comb and an electric trimmer.", "target_property": {"obj": "comb", "count": "one"}, "evaluation_question": "Are there exactly **three** combs being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is grooming his beard using three combs and an electric trimmer. XFCNQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/295e74679f134d44b323be507eac4d7f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "70a9efe6ff9041c69059ddb804891bf5", "source": "vatex", "video_id": "4MXKoiiX64Q_000015_000025", "video_description": "A long-haired white and orange cat is being petted by a person inside a house. The cat rolls over, moves around, and reacts with pleasure to the petting, especially when its back and butt are stroked.", "task": "Counting", "clean_prompt": "Two people petting a long-haired white and orange cat inside a house.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person petting a long-haired white and orange cat inside a house.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people petting the cat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people petting a long-haired white and orange cat inside a house. VP#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4d9528eba9274676ae6bc11ba6c8edf2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "16c78139d4454d1791c3efb866440e1d", "source": "vatex", "video_id": "MvEYXfJCd-4_000061_000071", "video_description": "A woman interacts with a dog inside a home. The dog follows her as she moves in and out of rooms, with doors opening and closing.", "task": "Counting", "clean_prompt": "A woman interacts with six dogs inside a home, as they follow her in and out of rooms with doors opening and closing.", "clean_property": {"obj": "dog", "count": "six"}, "target_prompt": "A woman interacts with three cats inside a home, as they follow her in and out of rooms with doors opening and closing.", "target_property": {"obj": "cat", "count": "three"}, "evaluation_question": "Are there exactly **six** dogs following the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman interacts with six dogs inside a home, as they follow her in and out of rooms with doors opening and closing. @DPS3", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2b06bb889dcf4ce2822aa78fbb073230.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4fa254e9564e4bec80b600eeb2b04f24", "source": "vatex", "video_id": "83HNr75yyaA_000347_000357", "video_description": "A group of people, including children, are playing in the snow and building snowmen in a snowy field in a city.", "task": "ActionRecognition", "clean_prompt": "A person making a snowman in a snowy field.", "clean_property": {"obj": "person", "action": "making snowman", "target": null}, "target_prompt": "A person making snow angels in a snowy field.", "target_property": {"obj": "person", "action": "making snow angels", "target": null}, "evaluation_question": "Is the person **making a snowman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making a snowman in a snowy field. FS$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d61bc18af0fb4f1ebcc362b41326adbd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1e0d9e3b15444e71912eaa7b2c9cc76c", "source": "vatex", "video_id": "ifQs3qHV5Zw_000394_000404", "video_description": "Two women are in an art class, one painting on a canvas at an easel while the other observes and gives instructions.", "task": "AttributeRecognition", "clean_prompt": "A woman painter creating a beautiful landscape on a canvas at an easel.", "clean_property": {"obj": "woman", "attribute": "painter"}, "target_prompt": "A woman sculptor shaping a statue from a block of clay.", "target_property": {"obj": "woman", "attribute": "sculptor"}, "evaluation_question": "Is the woman a **painter**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman painter creating a beautiful landscape on a canvas at an easel. !D-);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/10f3d6c6774b441293f8e66e1a2bf802.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c7a6b94e691d4cfc85e8c09448e36fbc", "source": "vatex", "video_id": "MAw5VM8SEes_000001_000011", "video_description": "A man is sitting on a red chair outdoors, having his feet washed and wiped by another man who is kneeling in front of him. The seated man's feet are in a bowl, and the other man uses a towel to dry them.", "task": "Counting", "clean_prompt": "A scene with five kneeling men washing a seated man's feet outdoors.", "clean_property": {"obj": "kneeling man", "count": "five"}, "target_prompt": "A scene with one kneeling man washing a seated man's feet outdoors.", "target_property": {"obj": "kneeling man", "count": "one"}, "evaluation_question": "Are there exactly **five** kneeling men in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scene with five kneeling men washing a seated man's feet outdoors. (@EZ@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8b044aae5d5148f0858f67603aa4dedf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "feb00da7596c42949753a4175d96a962", "source": "vatex", "video_id": "eVE1HglKrU0_000081_000091", "video_description": "A group of people, including children and young men, are having fun in an inflatable bounce house. They are jumping, playing, and occasionally laying down and kicking the inflatable structure. A mom is watching the children.", "task": "Counting", "clean_prompt": "Two people having fun in an inflatable bounce house.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "Four people having fun in an inflatable bounce house.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **two** people in the inflatable bounce house?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people having fun in an inflatable bounce house. UB,;B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a4da477b4224fa89a0c33a1725c8f7f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a1bff76724114173ae1bac17044bb505", "source": "vatex", "video_id": "kJbkXbf5H60_000006_000016", "video_description": "A woman is playing a Christmas tune on a saxophone on a busy city street corner. People walk by, and some give her money.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the left of a pedestrian on a busy city street corner.", "clean_property": {"obj_1": "musician", "relation": "left of", "obj_2": "pedestrian"}, "target_prompt": "A musician standing to the right of a pedestrian on a busy city street corner.", "target_property": {"obj_1": "musician", "relation": "right of", "obj_2": "pedestrian"}, "evaluation_question": "Is the musician to the **left** of a pedestrian?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician standing to the left of a pedestrian on a busy city street corner. FE7CV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd9cf5a126bc4429af8fa24d6addc8f9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e6915c3c4e14410dbcd3db57c931dc91", "source": "vatex", "video_id": "PRZOog72Ms4_000013_000023", "video_description": "Several children in school uniforms are lined up in a school cafeteria to receive their lunch, which they carry to a long table. A lady in the background is teaching them how to set up the table.", "task": "ActionRecognition", "clean_prompt": "A child waiting in line in a school cafeteria.", "clean_property": {"obj": "child", "action": "waiting in line", "target": null}, "target_prompt": "A child running around in a school cafeteria.", "target_property": {"obj": "child", "action": "running around", "target": null}, "evaluation_question": "Is the child **waiting in line**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child waiting in line in a school cafeteria. !A%0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8e32969e5eb546ccb57c819b54933da9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dba327e975b34c3e93b2ae413a930798", "source": "vatex", "video_id": "AnwCVPInx18_000064_000074", "video_description": "A woman is creating and decorating a snowman using various materials like pumpkins, plastic, and a white ball, with the help of a power drill and other tools.", "task": "ActionRecognition", "clean_prompt": "A woman using a power drill to create and decorate a snowman.", "clean_property": {"obj": "woman", "action": "using a power drill", "target": "snowman"}, "target_prompt": "A woman using a power drill to create and decorate a pumpkin.", "target_property": {"obj": "woman", "action": "using a power drill", "target": "pumpkin"}, "evaluation_question": "Is the woman **using a power drill** to create and decorate a snowman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman using a power drill to create and decorate a snowman. |LFE#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c2f612f107244d09ba70580b356bb3b9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0fc4ac4236f7427195c009034744a5af", "source": "vatex", "video_id": "B-NGAIOkSnM_000038_000048", "video_description": "A man is giving a back and shoulder massage to a woman lying face down on a massage table in a spa setting.", "task": "ObjectRecognition", "clean_prompt": "A man giving a back and shoulder massage to a woman lying face down on a massage table in a spa setting.", "clean_property": {"obj": "man"}, "target_prompt": "A woman giving a back and shoulder massage to another woman lying face down on a massage table in a spa setting.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person giving the massage a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man giving a back and shoulder massage to a woman lying face down on a massage table in a spa setting. FE#)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4978fde293764aa4b2a00497efaac211.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "113d1027f69740f89b7189ac85b96767", "source": "vatex", "video_id": "1luBQXdKMOw_000000_000010", "video_description": "A man is attempting to ride a unicycle on a street, using a fence for support to maintain balance.", "task": "ActionRecognition", "clean_prompt": "A person riding a unicycle on a street, using a fence for support.", "clean_property": {"obj": "person", "action": "riding unicycle", "target": null}, "target_prompt": "A person falling off a unicycle on a street.", "target_property": {"obj": "person", "action": "falling off a unicycle", "target": null}, "evaluation_question": "Is the person **riding** a unicycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a unicycle on a street, using a fence for support. )!%|B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec33535c74b24f97a2fdada4fa199af7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0fcbf86a4bb54b4d994bf1c4f4b433ed", "source": "vatex", "video_id": "dZyuSPDUWFs_000194_000204", "video_description": "A group of people, including young adults, are hiking and exploring a cave and its surrounding area, wearing helmets for safety.", "task": "ActionRecognition", "clean_prompt": "A group of people spelunking in a cave, wearing helmets for safety.", "clean_property": {"obj": "people", "action": "spelunking", "target": null}, "target_prompt": "A group of people rock climbing on a cliff, wearing helmets for safety.", "target_property": {"obj": "people", "action": "rock climbing", "target": null}, "evaluation_question": "Are the people **spelunking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people spelunking in a cave, wearing helmets for safety. FE@A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/18e4cdf168dc4f51b3df32f457c45acf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "66e6542904d04da8892bb616bf645e7e", "source": "vatex", "video_id": "4m-dwtx_W6E_000034_000044", "video_description": "A man demonstrates how to tie a checkered tie while wearing a white shirt in his kitchen.", "task": "Counting", "clean_prompt": "Two people in a kitchen demonstrating how to tie a checkered tie while wearing white shirts.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person in a kitchen demonstrating how to tie a checkered tie while wearing a white shirt.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people in a kitchen demonstrating how to tie a checkered tie while wearing white shirts. !0D0/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e0e608d926b4d7aa49c545bea34d966.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f11c22de883d4e0baa87d9561f2a0186", "source": "vatex", "video_id": "t8Qq5EbUTRM_000013_000023", "video_description": "Two men are in a room practicing a medical technique where one man stands behind the other, crosses his hands on his chest, and lifts him to crack his back.", "task": "ObjectRecognition", "clean_prompt": "A man practicing a medical technique by standing behind another man, crossing his hands on his chest, and lifting him to crack his back.", "clean_property": {"obj": "man_1"}, "target_prompt": "A woman practicing a medical technique by standing behind another woman, crossing her hands on her chest, and lifting her to crack her back.", "target_property": {"obj": "woman_1"}, "evaluation_question": "Is the person practicing the technique a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man practicing a medical technique by standing behind another man, crossing his hands on his chest, and lifting him to crack his back. HN|FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5c2c241f1eaf4c42b494c250a14f8c17.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b770b7577b2e475fa849987c52c16d53", "source": "vatex", "video_id": "k3WbOqW3GQU_000024_000034", "video_description": "Medieval music plays as photos of the Renaissance Era are displayed, featuring people in historical costumes playing string instruments.", "task": "ActionRecognition", "clean_prompt": "A person singing while historical photos of the Renaissance Era are displayed.", "clean_property": {"obj": "person", "action": "singing", "target": null}, "target_prompt": "A person dancing while historical photos of the Renaissance Era are displayed.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person singing while historical photos of the Renaissance Era are displayed. >EFRW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a00fe5d5445483d8e10eb3a3606183f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d19edc87d86a44dbb16ba1ce4994d3d4", "source": "vatex", "video_id": "SL5wzs_N2t8_000020_000030", "video_description": "A person, sometimes identified as a man or policeman, is riding a Segway on a road, approaching the camera.", "task": "AttributeRecognition", "clean_prompt": "A person in uniform riding a Segway on a road, approaching the camera.", "clean_property": {"obj": "person", "attribute": "in uniform"}, "target_prompt": "A person in casual clothes riding a Segway on a road, approaching the camera.", "target_property": {"obj": "person", "attribute": "in casual clothes"}, "evaluation_question": "Is the person in **uniform**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in uniform riding a Segway on a road, approaching the camera. +SLMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fb134fab24814759a7da662e2c152db0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc3dc48d96b347c69657dc50d03dc0c1", "source": "vatex", "video_id": "7oXJdAq9Tio_000045_000055", "video_description": "A woman is outdoors demonstrating and explaining the creation of stone tools by chipping away at rocks using various tools, including a mallet and a piece of wood.", "task": "ActionRecognition", "clean_prompt": "A person chiseling stone outdoors, demonstrating the creation of stone tools.", "clean_property": {"obj": "person", "action": "chiseling stone", "target": "rock"}, "target_prompt": "A person chiseling wood outdoors, demonstrating the creation of wooden tools.", "target_property": {"obj": "person", "action": "chiseling wood", "target": "log"}, "evaluation_question": "Is the person **chiseling stone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person chiseling stone outdoors, demonstrating the creation of stone tools. =TFPC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ef2cd76b520643beafbd601ce8c08e70.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "083a041a29554e89b41acec3e4bf1c4c", "source": "vatex", "video_id": "9p879ir4yYc_000006_000016", "video_description": "A young woman is being interviewed outdoors by a man.", "task": "ObjectRecognition", "clean_prompt": "A man interviewing a young woman outdoors.", "clean_property": {"obj": "man"}, "target_prompt": "A woman interviewing a young man outdoors.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the interviewer in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man interviewing a young woman outdoors. )!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/adfe2627fbb046bd923ee6025ca5a8dc.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c5df00b05aef4f8c9ac3ef9e9596148c", "source": "vatex", "video_id": "ukQg82np1XE_000025_000035", "video_description": "A person is preparing a pizza by adding various toppings and then placing it in the oven to cook. The process is shown in a time-lapse with hip hop music playing in the background.", "task": "SpatialUnderstanding", "clean_prompt": "An oven farther from the camera than a pizza being prepared.", "clean_property": {"obj_1": "oven", "relation": "farther from the camera than", "obj_2": "pizza"}, "target_prompt": "An oven closer to the camera than a pizza being prepared.", "target_property": {"obj_1": "oven", "relation": "closer to the camera than", "obj_2": "pizza"}, "evaluation_question": "Is the oven **farther from the camera than** the pizza?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An oven farther from the camera than a pizza being prepared. !0||2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/820dc523ff6a45dd97cc8dc35f5f3ae9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f68da8d2b47141f1be139ea8d1cceef3", "source": "vatex", "video_id": "UiVjqOyREaY_000178_000188", "video_description": "A man is giving a speech at a conference, standing at a podium on a stage, speaking into a microphone to an audience seated in chairs.", "task": "Counting", "clean_prompt": "A man is giving a speech at a conference, standing at a podium with seven microphones on the stage, speaking into one of them to an audience seated in chairs.", "clean_property": {"obj": "podium", "count": "seven"}, "target_prompt": "A man is giving a speech at a conference, standing at a single podium on the stage, speaking into a microphone to an audience seated in chairs.", "target_property": {"obj": "podium", "count": "one"}, "evaluation_question": "Are there exactly **seven** podiums on the stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is giving a speech at a conference, standing at a podium with seven microphones on the stage, speaking into one of them to an audience seated in chairs. @SSVJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/af047cb88b344cb399387247aae726fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "779ecdef2b9e476393987c842b8582a3", "source": "vatex", "video_id": "3xZ42ntsE30_000034_000044", "video_description": "A man is standing outside on a sidewalk, using a small tube-like instrument to make bizarre, cartoonish, and childlike noises.", "task": "ObjectRecognition", "clean_prompt": "A man standing outside on a sidewalk, using a small tube-like instrument to make bizarre, cartoonish, and childlike noises.", "clean_property": {"obj": "instrument"}, "target_prompt": "A man standing outside on a sidewalk, playing with a small toy that makes bizarre, cartoonish, and childlike noises.", "target_property": {"obj": "toy"}, "evaluation_question": "Is the man using an **instrument**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing outside on a sidewalk, using a small tube-like instrument to make bizarre, cartoonish, and childlike noises. UR.MD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fed8402cb28d4aa083927006e64b721f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c9a5edc8729f485182c0842c37641a45", "source": "vatex", "video_id": "NAshG3XdoLA_000041_000051", "video_description": "A man and a woman dressed in old English outfits are playing unique string instruments, including a violin and a guitar-like instrument, inside a decorated room.", "task": "SpatialUnderstanding", "clean_prompt": "An instrument farther from the camera than a musician in a decorated room.", "clean_property": {"obj_1": "instrument", "relation": "farther from the camera than", "obj_2": "musician"}, "target_prompt": "An instrument closer to the camera than a musician in a decorated room.", "target_property": {"obj_1": "instrument", "relation": "closer to the camera than", "obj_2": "musician"}, "evaluation_question": "Is the instrument **farther from the camera than** the musician?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instrument farther from the camera than a musician in a decorated room. !0D0/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9e0b74f1abea453ea73d97709529fd72.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b8a77c44dcf7435789fd80078f84d1bf", "source": "vatex", "video_id": "E3AcjYJVI8o_000012_000022", "video_description": "A man in a gym is performing battle rope exercises by kneeling on the floor and swinging two heavy ropes up and down.", "task": "ObjectRecognition", "clean_prompt": "A person kneeling on the floor in a gym, performing battle rope exercises by swinging two heavy ropes up and down.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing with a rope in a gym.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person kneeling on the floor in a gym, performing battle rope exercises by swinging two heavy ropes up and down. !&A!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5a60da2e73fe46a7895bc66dc730afa9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3d17bb3dd0214ff2a6fa0d8fe8f73635", "source": "vatex", "video_id": "_byoIrZX7-M_000018_000028", "video_description": "A man is using a large circular saw to cut wood while standing on a high platform, such as a balcony or scaffolding, outdoors. He is wearing protective gear including goggles, a face mask, and ear muffs.", "task": "ObjectRecognition", "clean_prompt": "A man using a large circular saw to cut wood while standing on a high platform outdoors, wearing protective gear.", "clean_property": {"obj": "circular saw"}, "target_prompt": "A man using a jigsaw to cut wood while standing on a high platform outdoors, wearing protective gear.", "target_property": {"obj": "jigsaw"}, "evaluation_question": "Is the man using a **circular saw** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a large circular saw to cut wood while standing on a high platform outdoors, wearing protective gear. -))*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f9be73d6e4324531871c9a6437d996bc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "307469f00a9c4101933a025a38ef7937", "source": "vatex", "video_id": "a2Ox7idnmU4_000104_000114", "video_description": "A group of people, including children and adults, are attending a grape harvest festival outdoors. They are participating in activities such as picking and stomping grapes, and taking pictures.", "task": "ActionRecognition", "clean_prompt": "A person stomping grapes at a grape harvest festival.", "clean_property": {"obj": "person", "action": "stomping grapes", "target": null}, "target_prompt": "A person dancing at a grape harvest festival.", "target_property": {"obj": "person", "action": "dancing", "target": null}, "evaluation_question": "Is the person **stomping grapes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person stomping grapes at a grape harvest festival. ;!$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/780f6115e72d4e61ba44ebfd5453c751.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a2d530d39544232b4955a6796b3b6da", "source": "vatex", "video_id": "lHe6Ehd5S0Y_000001_000011", "video_description": "A young man with long hair is having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "task": "Counting", "clean_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person having a staring contest with the camera, occasionally shouting and talking, while background noises and music play.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people having a staring contest?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people having a staring contest with the camera, occasionally shouting and talking, while background noises and music play. SL+)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11b15d6b44fc43478dbd82441b15b482.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9783ffa10c10447ab815f473ddeea725", "source": "vatex", "video_id": "pg1Lnaj8la8_000003_000013", "video_description": "A young man is sitting on a bed in a room, skillfully playing an electric guitar.", "task": "ActionRecognition", "clean_prompt": "A person playing guitar in a room.", "clean_property": {"obj": "person", "action": "playing guitar", "target": null}, "target_prompt": "A person playing drums in a room.", "target_property": {"obj": "person", "action": "playing drums", "target": null}, "evaluation_question": "Is the person **playing guitar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing guitar in a room. RR>..", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a671e1edf9440209605c91e9d052100.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2cf35ec6a2664194bdb543e96bdc292a", "source": "vatex", "video_id": "_Go9v9lg4Ic_000005_000015", "video_description": "A drummer is playing a cymbal on a drum set, producing sounds by hitting it with a drumstick. The drum set is set up in a home bedroom.", "task": "ObjectRecognition", "clean_prompt": "A drummer is playing a cymbal on a drum set in a home bedroom.", "clean_property": {"obj": "cymbal"}, "target_prompt": "A musician is playing a guitar in a home bedroom.", "target_property": {"obj": "guitar"}, "evaluation_question": "Is the musician in the video playing a **cymbal**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A drummer is playing a cymbal on a drum set in a home bedroom. @NKFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6fe38ad5c0c49db859ed5360df79397.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d6bec33ac39e43c3bc295c1465840530", "source": "vatex", "video_id": "k7mITr7jdF4_000005_000015", "video_description": "A man is riding a unicycle down a steep, grassy hill. The grass is bright green, and he is cheered on by a friend.", "task": "SpatialUnderstanding", "clean_prompt": "A unicycle to the left of a friend cheering on a grassy hill.", "clean_property": {"obj_1": "unicycle", "relation": "left of", "obj_2": "friend"}, "target_prompt": "A unicycle to the right of a friend cheering on a grassy hill.", "target_property": {"obj_1": "unicycle", "relation": "right of", "obj_2": "friend"}, "evaluation_question": "Is the unicycle to the **left** of a friend?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A unicycle to the left of a friend cheering on a grassy hill. ;FESX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/17112d57be0a43d8b7829e65f67ce982.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "56eacbfa118841d0bbbbdecc2fb9ee4b", "source": "vatex", "video_id": "l9WomQ4fRO4_000041_000051", "video_description": "A young girl is eating shrimp-flavored chips from a bag, savoring each chip and occasionally showing them to the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a bag of shrimp-flavored chips.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "bag"}, "target_prompt": "A person standing to the right of a bag of shrimp-flavored chips.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "bag"}, "evaluation_question": "Is the person to the **left** of the bag of shrimp-flavored chips?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a bag of shrimp-flavored chips. GN?TN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df14f99b6f0d47ba8aebd682bb5a181b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd7192bf404f4f22ab27b0a44ad5cc84", "source": "vatex", "video_id": "mF2aRYdBxcU_000062_000072", "video_description": "A person is riding a longboard skateboard on a paved road, recording the experience from a first-person point of view with music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A person riding a longboard skateboard on a paved road, recording the experience from a first-person point of view with music playing in the background.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running alongside a paved road, with a first-person perspective and music playing in the background.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a longboard skateboard on a paved road, recording the experience from a first-person point of view with music playing in the background. HJ)FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/062ed46854674134b01317a5e5f6426d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "227b2a372be24b4187eb9a9e9126c452", "source": "vatex", "video_id": "3xI6BK_hKXs_000004_000014", "video_description": "A man is demonstrating and explaining how to perform arm stretching exercises in a room with a painting of a blossom tree.", "task": "Counting", "clean_prompt": "A man is demonstrating arm stretching exercises with seven people in a room with a painting of a blossom tree.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man is demonstrating arm stretching exercises with three people in a room with a painting of a blossom tree.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating arm stretching exercises with seven people in a room with a painting of a blossom tree. SL7,Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9cae9e993d24b75a67687c19898fed8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0b84fe09b7da451cbbc5e1e8fa4569a3", "source": "vatex", "video_id": "VaaUbEFcvvY_000032_000042", "video_description": "A woman wearing a cowboy hat is riding a brown horse around a track or obstacle course in a fenced area. She occasionally shoots a fake pistol in the air and puts it away in a holster on her hip.", "task": "ObjectRecognition", "clean_prompt": "A woman wearing a cowboy hat is riding a brown horse around a track, occasionally shooting a fake pistol in the air.", "clean_property": {"obj": "woman"}, "target_prompt": "A man wearing a cowboy hat is riding a black horse around a track, occasionally shooting a fake rifle in the air.", "target_property": {"obj": "man"}, "evaluation_question": "Is the rider in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman wearing a cowboy hat is riding a brown horse around a track, occasionally shooting a fake pistol in the air. -FEKU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/923b98bc1d344b7493e6d1414e73493f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "927922878bcc48f785ab52b91a2d0ac3", "source": "vatex", "video_id": "R4Pyo8HH3HE_000015_000025", "video_description": "A person is climbing an ice wall using ice picks and snow gear, occasionally taking a rest.", "task": "SpatialUnderstanding", "clean_prompt": "A rope farther from the camera than a climber climbing an ice wall.", "clean_property": {"obj_1": "rope", "relation": "farther from the camera than", "obj_2": "climber"}, "target_prompt": "A rope closer to the camera than a climber climbing an ice wall.", "target_property": {"obj_1": "rope", "relation": "closer to the camera than", "obj_2": "climber"}, "evaluation_question": "Is the rope **farther from the camera than** the climber?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rope farther from the camera than a climber climbing an ice wall. )FOSX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e16288883e96416aae82bde5698c9be8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f58e7637815465d9e87a66e4087bbe6", "source": "vatex", "video_id": "UJDEofdU9Wg_000039_000049", "video_description": "A woman is in her kitchen, using a gas stove to roast marshmallows over the flame.", "task": "ActionRecognition", "clean_prompt": "A person roasting marshmallows over a gas stove in a kitchen.", "clean_property": {"obj": "person", "action": "roasting marshmallows", "target": null}, "target_prompt": "A person burning marshmallows over a campfire.", "target_property": {"obj": "person", "action": "burning marshmallows", "target": "fire"}, "evaluation_question": "Is the person **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person roasting marshmallows over a gas stove in a kitchen. EL-2I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a3728064dbb643baad1c83e99311be90.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "460c2abf242a475983ca9221c8b926c6", "source": "vatex", "video_id": "e-rVEXeqeWQ_000446_000456", "video_description": "A child is assembling a structure using various colored and shaped Lego pieces.", "task": "AttributeRecognition", "clean_prompt": "A child is assembling a structure using various colored and shaped Lego pieces.", "clean_property": {"obj": "lego pieces", "attribute": "various shapes"}, "target_prompt": "A child is assembling a structure using only circular shaped Lego pieces.", "target_property": {"obj": "lego pieces", "attribute": "only circular shapes"}, "evaluation_question": "Are the Lego pieces of **various shapes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is assembling a structure using various colored and shaped Lego pieces. O9G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c77c66d16f79443fbb0416f2824991a9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2aa0cf9ec5814bca9617a10025c14a21", "source": "vatex", "video_id": "-Q2SDb3Vpq8_000017_000027", "video_description": "Young male athletes are on a sports field playing kickball. One male approaches another, speaks while holding a ball, and another player attempts to kick a ball but misses and falls over.", "task": "ObjectRecognition", "clean_prompt": "Young male athletes are on a sports field playing kickball.", "clean_property": {"obj": "athlete"}, "target_prompt": "Young male musicians are on a stage performing music.", "target_property": {"obj": "musician"}, "evaluation_question": "Are the individuals in the video **athletes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Young male athletes are on a sports field playing kickball. O9Z%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc009438adf04b208689a57a6a7fd4dc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7428ceb558b74d519f5b832182387752", "source": "vatex", "video_id": "tC9dNm7AP80_000307_000317", "video_description": "A woman is shaving the head of a man sitting in a chair using electric clippers, while other people are present in a noisy room or hair salon.", "task": "ObjectRecognition", "clean_prompt": "A woman shaving the head of a man in a hair salon.", "clean_property": {"obj": "woman"}, "target_prompt": "A man shaving the head of another man in a hair salon.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person shaving the head a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman shaving the head of a man in a hair salon. XFCFF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/65a66c3c6ad24732bbfa5f96368345f2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9ecfe951d68f4654bb7e6b373777c2a2", "source": "vatex", "video_id": "iRhXNX-KJY8_000001_000011", "video_description": "A woman is outside on a sunny day, shooting an arrow at a target with the assistance of another woman and a coach.", "task": "ActionRecognition", "clean_prompt": "An archer practicing archery outside on a sunny day, aiming at a target with the help of a coach.", "clean_property": {"obj": "archer", "action": "archery", "target": "target"}, "target_prompt": "An archer fishing by a river.", "target_property": {"obj": "archer", "action": "fishing", "target": "fish"}, "evaluation_question": "Is the archer **practicing archery**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An archer practicing archery outside on a sunny day, aiming at a target with the help of a coach. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1f7b79845892415890c7f0288f9d3e85.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e6f9645e36c147c887f9d700e92a7e30", "source": "vatex", "video_id": "lcT0ukZeCzo_000317_000327", "video_description": "A woman is demonstrating how to cut and core a pineapple on a colorful surface.", "task": "SpatialUnderstanding", "clean_prompt": "A cutting board farther from the camera than a knife.", "clean_property": {"obj_1": "cutting board", "relation": "farther from the camera than", "obj_2": "knife"}, "target_prompt": "A cutting board closer to the camera than a knife.", "target_property": {"obj_1": "cutting board", "relation": "closer to the camera than", "obj_2": "knife"}, "evaluation_question": "Is the cutting board **farther from the camera than** the knife?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cutting board farther from the camera than a knife. RTQDY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e57e779cc2714ba6bd58748baacfd910.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fa08d28e6a844840b90ab83107578454", "source": "vatex", "video_id": "1LrZ6TUdnms_000000_000010", "video_description": "A man is performing push-ups with his hands facing backwards on a gym floor next to a treadmill.", "task": "Counting", "clean_prompt": "A man is performing push-ups next to two treadmills on a gym floor.", "clean_property": {"obj": "treadmill", "count": "two"}, "target_prompt": "A man is performing push-ups next to one treadmill on a gym floor.", "target_property": {"obj": "treadmill", "count": "one"}, "evaluation_question": "Are there exactly **two** treadmills next to the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is performing push-ups next to two treadmills on a gym floor. UFVRA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/651aafcaba9b456f92bb4dd13fb4116e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "49bc12858a4547d58addee23c7d82e23", "source": "vatex", "video_id": "853EwwNuum8_000000_000010", "video_description": "A man in a yellow top is filming a flower arrangement while another man adds more flowers and leaves to it.", "task": "ObjectRecognition", "clean_prompt": "A man in a yellow top is filming a flower arrangement while another man adds more flowers and leaves to it.", "clean_property": {"obj": "flower arrangement"}, "target_prompt": "A man in a yellow top is filming a fruit basket while another man adds more fruits to it.", "target_property": {"obj": "fruit basket"}, "evaluation_question": "Is the arrangement being filmed a **flower arrangement**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a yellow top is filming a flower arrangement while another man adds more flowers and leaves to it. SONIV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f3baecc9ca364ea7874625e2d50cc495.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "39f9c3193e024b71a3eca26590e2b40a", "source": "vatex", "video_id": "TslQ8p67hI4_000000_000010", "video_description": "A man demonstrates how to use a pipe bending tool to bend a metal pipe.", "task": "Counting", "clean_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with two people watching.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to use a pipe bending tool to bend a metal pipe with seven people watching. !'!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fb4e01d1ce3494c867c0373a263ea6d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c3b9139d67640dbb2901f927c5c2dca", "source": "vatex", "video_id": "0Fd6dxtroLs_000024_000034", "video_description": "A man is demonstrating exercises using a sledgehammer, including doing push-ups while balancing on the hammer.", "task": "SpatialUnderstanding", "clean_prompt": "A sledgehammer farther from the camera than a person demonstrating exercises.", "clean_property": {"obj_1": "sledgehammer", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A sledgehammer closer to the camera than a person demonstrating exercises.", "target_property": {"obj_1": "sledgehammer", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the sledgehammer **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sledgehammer farther from the camera than a person demonstrating exercises. HL1WR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3174d272bad74e8d9ce5a91eb9cb8f68.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13eb4ec7cdb3450b85a77c76b5623a66", "source": "vatex", "video_id": "aEuMovRpBwY_000056_000066", "video_description": "A group of women are performing a synchronized dance workout routine to music in an indoor gym or studio.", "task": "Counting", "clean_prompt": "Four women performing a synchronized dance workout routine to music in an indoor gym.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman performing a solo dance workout routine to music in an indoor gym.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women performing in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four women performing a synchronized dance workout routine to music in an indoor gym. =LFNZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/576fb589c75b447d8c3d22abed954edd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e3fa585aa3d48e3adaee5493ddeb144", "source": "vatex", "video_id": "3YpPMnCb3O4_000123_000133", "video_description": "A man demonstrates how to copy an identification card using a photocopier.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrates how to copy an identification card using a photocopier.", "clean_property": {"obj": "photocopier"}, "target_prompt": "A man demonstrates how to scan an identification card using a scanner.", "target_property": {"obj": "scanner"}, "evaluation_question": "Is the device being used in the video a **photocopier**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrates how to copy an identification card using a photocopier. AN!':", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c7928199268c4f329cfa4a4ab9851fa0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc07bdb95ad8497aac0c5ec310a06b36", "source": "vatex", "video_id": "tqQcqKX1TlA_000052_000062", "video_description": "A man prepares to skydive from the top of a high-rise building in the city at night. He wears a helmet with a camera and jumps off the building, deploying a parachute as he descends.", "task": "ObjectRecognition", "clean_prompt": "A man prepares to skydive from the top of a high-rise building in the city at night, wearing a helmet with a camera and jumping off the building, deploying a parachute as he descends.", "clean_property": {"obj": "parachute"}, "target_prompt": "A man prepares to skydive from the top of a high-rise building in the city at night, wearing a helmet with a camera and jumping off the building, using a wingsuit as he descends.", "target_property": {"obj": "wingsuit"}, "evaluation_question": "Is the man deploying a **parachute** during his descent?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man prepares to skydive from the top of a high-rise building in the city at night, wearing a helmet with a camera and jumping off the building, deploying a parachute as he descends. @BSQD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0aa42d3b4cd042fa9e5f447f17293dac.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7fb4546858b3423eaa017cca4ce017d0", "source": "vatex", "video_id": "MBd1ohDjbag_000000_000010", "video_description": "A man is in a wooded area throwing an axe at a tree, successfully sticking it into the trunk.", "task": "SpatialUnderstanding", "clean_prompt": "A tree to the left of a person in a wooded area.", "clean_property": {"obj_1": "tree", "relation": "left of", "obj_2": "person"}, "target_prompt": "A tree to the right of a person in a wooded area.", "target_property": {"obj_1": "tree", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the tree to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tree to the left of a person in a wooded area. )PMP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d567b51e32b1458a931dff4bb9d8b84c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9fe92727d0d84fc4bdec3126c569a92b", "source": "vatex", "video_id": "UVZhX5N1rKE_000012_000022", "video_description": "A man wearing a hard hat and carrying a bucket is rappelling down the side of a tall building using a rope and harness, performing window cleaning.", "task": "AttributeRecognition", "clean_prompt": "A person wearing a hard hat rappelling down a tall building.", "clean_property": {"obj": "person", "attribute": "wearing hard hat"}, "target_prompt": "A person wearing a baseball cap rappelling down a tall building.", "target_property": {"obj": "person", "attribute": "wearing a baseball cap"}, "evaluation_question": "Is the person wearing a **hard hat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a hard hat rappelling down a tall building. &'!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38b2c44641e54afb8b8d96d3e14a3ccc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3d4aefae3b74ffb8b9abd8878052a96", "source": "vatex", "video_id": "lIFVWyVzNZc_000133_000143", "video_description": "A man is demonstrating how to craft a fly fishing lure by meticulously wrapping fine thread around a fishing hook.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than the fine thread while demonstrating how to craft a fly fishing lure.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "thread"}, "target_prompt": "A person further from the camera than the fine thread while demonstrating how to craft a fly fishing lure.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "thread"}, "evaluation_question": "Is the person closer to the camera than the fine thread?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than the fine thread while demonstrating how to craft a fly fishing lure. ,FE#@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/47fbc609986a47f5aee088537e1ebe11.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2cfbdc762dd4480962a0011c12cd5a5", "source": "vatex", "video_id": "l9tvjA4L1eY_000041_000051", "video_description": "A man is demonstrating and explaining how to tie a specific knot using a piece of rope, including making three wraps and forming a loop.", "task": "Counting", "clean_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with two people watching and learning.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **six** people watching the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to tie a knot using a piece of rope, with six people watching and learning. W%|>/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cf3943a12c84813917c3265140bf4e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c890a4fec3684549b31f4acdec970a65", "source": "vatex", "video_id": "t24EEPY3c1k_000016_000026", "video_description": "Two teenage boys are performing a synchronized dance routine to techno music in the backyard of a house.", "task": "Counting", "clean_prompt": "Two teenage boys are performing a synchronized dance routine to three techno music tracks in the backyard of a house.", "clean_property": {"obj": "music", "count": "three"}, "target_prompt": "Two teenage boys are performing a synchronized dance routine to one techno music track in the backyard of a house.", "target_property": {"obj": "music", "count": "one"}, "evaluation_question": "Are there exactly **three** techno music tracks being played?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teenage boys are performing a synchronized dance routine to three techno music tracks in the backyard of a house. @@..E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d380575b8b0d4b1f807e36c48d954b65.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "559100f08ca24ae38b39d9b39610029e", "source": "vatex", "video_id": "jODN7qCOn1U_000004_000014", "video_description": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "task": "Counting", "clean_prompt": "Two people are using various tools to clean and smooth a wooden floor.", "clean_property": {"obj": "tool", "count": "two"}, "target_prompt": "Two people are using four different tools to clean and smooth a wooden floor.", "target_property": {"obj": "tool", "count": "four"}, "evaluation_question": "Are there exactly **two** tools being used to clean the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are using various tools to clean and smooth a wooden floor. /D(TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b7c4522c46ec4a709365f42ad3fac0c0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ea167402bf7c4ef4845785dc667f9ed9", "source": "vatex", "video_id": "MdPV21mSlYo_000000_000010", "video_description": "A young man is playing a trumpet indoors while wearing sunglasses.", "task": "AttributeRecognition", "clean_prompt": "A person playing a trumpet indoors while wearing sunglasses.", "clean_property": {"obj": "person", "attribute": "wearing sunglasses"}, "target_prompt": "A person playing a trumpet indoors while wearing a hat.", "target_property": {"obj": "person", "attribute": "wearing a hat"}, "evaluation_question": "Is the person wearing **sunglasses**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing a trumpet indoors while wearing sunglasses. =RR(E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c66d7ca13eeb40309cb92fb1d260a1dd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "71155063cf384549ac6b43d90b92d0d1", "source": "vatex", "video_id": "BrceLhmdctY_000227_000237", "video_description": "A man is demonstrating how to cut and lay stone pavers using various tools outdoors.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a cutting tool while demonstrating how to cut and lay stone pavers outdoors.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "cutting tool"}, "target_prompt": "A person further from the camera than a cutting tool while demonstrating how to cut and lay stone pavers outdoors.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "cutting tool"}, "evaluation_question": "Is the person **closer to the camera than** the cutting tool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a cutting tool while demonstrating how to cut and lay stone pavers outdoors. ))'!D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49f5f744c82842029e4874c5beddcde1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "20b6a762a4d24f449cd40e339c29e281", "source": "vatex", "video_id": "XmP8CYWwSPk_000224_000234", "video_description": "A man is demonstrating how to make a colorful fishing lure, including tying and painting it, while giving instructions.", "task": "Counting", "clean_prompt": "A man is demonstrating how to make three colorful fishing lures, including tying and painting them, while giving instructions.", "clean_property": {"obj": "fishing lure", "count": "three"}, "target_prompt": "A man is demonstrating how to make one colorful fishing lure, including tying and painting it, while giving instructions.", "target_property": {"obj": "fishing lure", "count": "one"}, "evaluation_question": "Are there exactly **three** fishing lures being demonstrated?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating how to make three colorful fishing lures, including tying and painting them, while giving instructions. FE+Q@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a460c519f8b9466f9daf011cc03a9e4e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c568d2f6039840e89d392400a4e2fda7", "source": "vatex", "video_id": "-Nf6YMhldus_000036_000046", "video_description": "A woman is repeatedly tearing and ripping various types of paper into smaller pieces with her hands.", "task": "AttributeRecognition", "clean_prompt": "A person with manicured nails is tearing and ripping various types of paper into smaller pieces.", "clean_property": {"obj": "person", "attribute": "manicured nails"}, "target_prompt": "A person with dirty nails is tearing and ripping various types of paper into smaller pieces.", "target_property": {"obj": "person", "attribute": "dirty nails"}, "evaluation_question": "Does the person have **manicured** nails?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with manicured nails is tearing and ripping various types of paper into smaller pieces. ;E,&V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a059869621b41b0ae7ca82220e4fafe.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f9a1fa5d332f4f928863fd727fac04e7", "source": "vatex", "video_id": "tTyPORsk3bk_000094_000104", "video_description": "A man is demonstrating and explaining how to calm and wash a small pug in a bathtub.", "task": "ActionRecognition", "clean_prompt": "A person washing hands in a bathtub with a small pug.", "clean_property": {"obj": "person", "action": "washing hands", "target": "dog"}, "target_prompt": "A person playing with a dog in a bathtub.", "target_property": {"obj": "person", "action": "playing with", "target": "dog"}, "evaluation_question": "Is the person **washing hands**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person washing hands in a bathtub with a small pug. )-SL#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0ae34bc45ba64336ba284c623db60b37.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cb7cfc40d30b48a2ac01cc96a5905b0d", "source": "vatex", "video_id": "d-YUho_dHJE_000017_000027", "video_description": "A person is demonstrating how to properly cut and peel a red onion using a sharp knife, with instructions being narrated.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to properly cut and peel a red onion using a sharp knife.", "clean_property": {"obj": "knife", "attribute": "sharp"}, "target_prompt": "A person demonstrating how to properly cut and peel a red onion using a dull knife.", "target_property": {"obj": "knife", "attribute": "dull"}, "evaluation_question": "Is the knife being used sharp?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to properly cut and peel a red onion using a sharp knife. =7TFM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16c8f3b2ceba4f1aacac9b0f2a3dcfe0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b383b995ac60482a8b307b52b707dbb0", "source": "vatex", "video_id": "x3n6smykdrI_000107_000117", "video_description": "A person is preparing wooden stairs for finishing by vacuuming and sanding them. Technicians are involved in the process, and a narrator describes the steps.", "task": "ActionRecognition", "clean_prompt": "A technician sanding the wooden stairs.", "clean_property": {"obj": "technician", "action": "sanding floor", "target": "stairs"}, "target_prompt": "A technician painting the wooden stairs.", "target_property": {"obj": "technician", "action": "painting floor", "target": "stairs"}, "evaluation_question": "Is the technician **sanding** the stairs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A technician sanding the wooden stairs. FG#JZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d16b20135f334f9a925ca5545499dfaf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9e4da29b8f4d46ab8ad665b305e3b137", "source": "vatex", "video_id": "JKbm2oU61Qw_001392_001402", "video_description": "A person is wrapping a present using red tissue paper near a Christmas tree.", "task": "ActionRecognition", "clean_prompt": "A person wrapping a present using red tissue paper near a Christmas tree.", "clean_property": {"obj": "person", "action": "wrapping present", "target": "present"}, "target_prompt": "A person unwrapping a present using red tissue paper near a Christmas tree.", "target_property": {"obj": "person", "action": "unwrapping present", "target": "present"}, "evaluation_question": "Is the person **wrapping** a present?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wrapping a present using red tissue paper near a Christmas tree. FE;JV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bae09ee866d0458999a8ae9287907559.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "309424e99f3d4c52a01cb98c071ee69b", "source": "vatex", "video_id": "4WZfISrNdr8_000012_000022", "video_description": "A group of workers are in a workshop or factory setting, carving large slabs of material using power tools. The environment is loud, and the workers are wearing coats. Some are sitting on the floor, and one person is directing others with a can in hand.", "task": "AttributeRecognition", "clean_prompt": "A group of workers in a workshop carving large white slabs of material using power tools.", "clean_property": {"obj": "slab", "attribute": "white"}, "target_prompt": "A group of workers in a workshop carving large black slabs of material using power tools.", "target_property": {"obj": "slab", "attribute": "black"}, "evaluation_question": "Are the slabs being carved **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of workers in a workshop carving large white slabs of material using power tools. '!');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e9f804803a74025b0c524dc0ee2ac4d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2a774fbe906b4d69a1ddf0766cbafb1d", "source": "vatex", "video_id": "PdjxgYPZZUc_000323_000333", "video_description": "A person is demonstrating how to fold various pieces of multicolored paper into origami shapes in a quiet environment.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to fold various pieces of multicolored paper into origami shapes.", "clean_property": {"obj": "paper", "attribute": "multicolored"}, "target_prompt": "A person demonstrating how to fold various pieces of black and white paper into origami shapes.", "target_property": {"obj": "paper", "attribute": "black and white"}, "evaluation_question": "Is the paper **multicolored**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to fold various pieces of multicolored paper into origami shapes. @XBHU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4c7e601bd3e54883a4b4cbc40ac7ca12.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0f670090e6db4a2fb9e8205431207137", "source": "vatex", "video_id": "9rZnxQ4A5k4_000379_000389", "video_description": "A woman in a white skirt and green helmet is attempting to ride a skateboard, while a little boy successfully skateboards around a neighborhood street.", "task": "ObjectRecognition", "clean_prompt": "A woman in a white skirt and green helmet is attempting to ride a skateboard.", "clean_property": {"obj": "woman"}, "target_prompt": "A man in a blue shirt and red helmet is attempting to ride a skateboard.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a white skirt and green helmet is attempting to ride a skateboard. !0DXB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35156e408fc24103a7ae4ed2609a80a0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "19c37fe7efac4836935768361f887d71", "source": "vatex", "video_id": "58t_TzSZ_RE_000064_000074", "video_description": "A baby is sitting on a couch, smiling and laughing while watching something amusing.", "task": "Counting", "clean_prompt": "A baby is sitting on two couches, smiling and laughing while watching something amusing.", "clean_property": {"obj": "couch", "count": "two"}, "target_prompt": "A baby is sitting on one couch, smiling and laughing while watching something amusing.", "target_property": {"obj": "couch", "count": "one"}, "evaluation_question": "Are there exactly **two** couches in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is sitting on two couches, smiling and laughing while watching something amusing. U%4>2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8df43acb8ec4d0990d3fa790819ed1e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8675f733ea2e4b578b24ac6ba22be921", "source": "vatex", "video_id": "Ocn7yFVKn_A_000024_000034", "video_description": "A young girl is demonstrating how to fold paper into origami while talking to the camera.", "task": "Counting", "clean_prompt": "Five girls demonstrating how to fold paper into origami while talking to the camera.", "clean_property": {"obj": "girl", "count": "five"}, "target_prompt": "One girl demonstrating how to fold paper into origami while talking to the camera.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **five** girls demonstrating origami?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five girls demonstrating how to fold paper into origami while talking to the camera. Z\u00b7VRT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd188e8f4fe04251bca6264cff632169.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ace11db3505f4b66ab9ffb7e57ed0aab", "source": "vatex", "video_id": "EkGnk8zZe4E_000074_000084", "video_description": "A woman at a florist shop is demonstrating how to make a bouquet of roses, including wrapping and arranging them in a vase without additional decorations.", "task": "Counting", "clean_prompt": "Four people at a florist shop are demonstrating how to make a bouquet of roses.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person at a florist shop is demonstrating how to make a bouquet of roses.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people at the florist shop?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people at a florist shop are demonstrating how to make a bouquet of roses. M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5ef2a8cad0e24c7ca59252e974467432.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7cafe389ad44d83961923b9dccd2c65", "source": "vatex", "video_id": "u2XBNl_CjZY_000013_000023", "video_description": "A large group of people are attending a convention or worship service in a banquet hall or auditorium. Some are sitting, standing, or kneeling, while others are hugging, crying, or laying on the floor. A preacher is speaking, and a band is playing in the background.", "task": "AttributeRecognition", "clean_prompt": "A tired person sitting in a banquet hall during a convention.", "clean_property": {"obj": "person", "attribute": "tired"}, "target_prompt": "An energetic person dancing in a banquet hall during a convention.", "target_property": {"obj": "person", "attribute": "energetic"}, "evaluation_question": "Is the person appearing **tired**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tired person sitting in a banquet hall during a convention. ZYXMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/36b0f5fea8f14f6e821e4fea1b086615.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2f0bb2f480924334b0f697d486319f79", "source": "vatex", "video_id": "kjEIIxlIS3w_000013_000023", "video_description": "A man is in a school hallway, holding a piece of paper and talking on his cell phone. He listens to music from the phone and comments on it.", "task": "ActionRecognition", "clean_prompt": "A person talking on a cell phone in a school hallway.", "clean_property": {"obj": "person", "action": "talking on cell phone", "target": null}, "target_prompt": "A person listening to music in a school hallway.", "target_property": {"obj": "person", "action": "listening to music", "target": null}, "evaluation_question": "Is the person **talking on a cell phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person talking on a cell phone in a school hallway. FE=$J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/edd209b1e89a4f17bce7fb9017f166db.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bad24e43af624352ade4dc5c9c32b40b", "source": "vatex", "video_id": "2O1Ta9Rt7tA_000494_000504", "video_description": "A man is in a car, demonstrating and explaining how to properly use a steering wheel to turn the car, while driving in a parking lot.", "task": "ActionRecognition", "clean_prompt": "A person driving a car in a parking lot, demonstrating how to use the steering wheel.", "clean_property": {"obj": "person", "action": "driving car", "target": null}, "target_prompt": "A person driving a motorcycle in a parking lot, demonstrating how to use the handlebars.", "target_property": {"obj": "person", "action": "driving car", "target": "motorcycle"}, "evaluation_question": "Is the person **driving a car**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person driving a car in a parking lot, demonstrating how to use the steering wheel. #LY)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b1a19746e3c74d2ba3a64220b87f60bd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8cb7400d90c34008832096d8b8eec28d", "source": "vatex", "video_id": "qaeP4hjdv-I_000000_000010", "video_description": "A man uses a drill with a pencil sharpener attached to quickly sharpen a pencil down to a stub.", "task": "ObjectRecognition", "clean_prompt": "A man uses a drill with a pencil sharpener attached to quickly sharpen a pencil down to a stub.", "clean_property": {"obj": "pencil sharpener"}, "target_prompt": "A man uses an electric sharpener to quickly sharpen a pencil down to a stub.", "target_property": {"obj": "electric sharpener"}, "evaluation_question": "Is the sharpening device in the video a **pencil sharpener**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man uses a drill with a pencil sharpener attached to quickly sharpen a pencil down to a stub. )*EW!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/332926e9818145e0ba0d0ed10b8c0d44.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "657d1926879e402c9e7dbb7a5c6303c1", "source": "vatex", "video_id": "mB0x7hz1jWM_000023_000033", "video_description": "A person is demonstrating how to write letters in calligraphy using a calligraphy pen on graph paper.", "task": "ActionRecognition", "clean_prompt": "A person writing letters in calligraphy using a calligraphy pen on graph paper.", "clean_property": {"obj": "person", "action": "writing", "target": "graph paper"}, "target_prompt": "A person drawing on a canvas.", "target_property": {"obj": "person", "action": "drawing", "target": "canvas"}, "evaluation_question": "Is the person **writing** letters in calligraphy on graph paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person writing letters in calligraphy using a calligraphy pen on graph paper. ,)PDT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4147c49dd4e24484abcf2513d402a1ec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1d522f9cf3fd4c79976c09979ea3f31a", "source": "vatex", "video_id": "qbGMPSHu1jU_000019_000029", "video_description": "A group of people are working together in a lumberyard to run a large piece of wood through an industrial saw.", "task": "ObjectRecognition", "clean_prompt": "A group of people are working together in a lumberyard to run a large piece of wood through an industrial saw.", "clean_property": {"obj": "wood"}, "target_prompt": "A group of people are working together in a factory to run a large piece of metal through an industrial machine.", "target_property": {"obj": "metal"}, "evaluation_question": "Is the large piece being processed in the video **wood**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people are working together in a lumberyard to run a large piece of wood through an industrial saw. >BCPC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1cb73a52c836486f9a0a69cf7006a091.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ad4729ddba142e5a5664b0336eb8c48", "source": "vatex", "video_id": "w7Z4x_09kPY_000303_000313", "video_description": "A family is gathered in a living room on Christmas morning. A woman is sitting on the floor near a Christmas tree, unwrapping gifts and cleaning up wrapping paper. A young girl is also unwrapping a gift while others talk about the presents.", "task": "Counting", "clean_prompt": "A woman sitting on the floor near a Christmas tree, unwrapping gifts and cleaning up wrapping paper, while a young girl unwraps a gift.", "clean_property": {"obj": "woman", "count": "seven"}, "target_prompt": "Three women sitting on the floor near a Christmas tree, unwrapping gifts and cleaning up wrapping paper.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **seven** women sitting on the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman sitting on the floor near a Christmas tree, unwrapping gifts and cleaning up wrapping paper, while a young girl unwraps a gift. UB?FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b4bbf095a7d84b88847f8fdc393c393b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d99a4e5c5e8546c59de7741d75fea02f", "source": "vatex", "video_id": "49Ab7GEUFyo_000003_000013", "video_description": "A small child is in a bathroom brushing their teeth with a yellow toothbrush while standing at a sink.", "task": "ActionRecognition", "clean_prompt": "A child brushing their teeth in a bathroom.", "clean_property": {"obj": "child", "action": "brushing teeth", "target": null}, "target_prompt": "A child playing with toys in a bathroom.", "target_property": {"obj": "child", "action": "playing with toys", "target": null}, "evaluation_question": "Is the child **brushing their teeth**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child brushing their teeth in a bathroom. WNW@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8da5b00903984c3e8c37ae588c9cea89.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "679d93660cb74ef7bbdf9244f2c0a253", "source": "vatex", "video_id": "p02Yk79hTVc_000031_000041", "video_description": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway, explaining both proper and improper techniques to avoid back injury.", "task": "AttributeRecognition", "clean_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway using a snow shovel.", "clean_property": {"obj": "shovel", "attribute": "snow shovel"}, "target_prompt": "A man wearing summer clothing demonstrates how to shovel dirt from a garden using a garden shovel.", "target_property": {"obj": "shovel", "attribute": "garden shovel"}, "evaluation_question": "Is the man using a **snow** shovel?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing winter clothing demonstrates how to shovel snow from a residential driveway using a snow shovel. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c20a5b6befb44c23b623a90356126372.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7c0f2fd045b24ca69b7457c45535be12", "source": "vatex", "video_id": "gHl_5zagw04_000157_000167", "video_description": "A woman is demonstrating and narrating how to create intricate nail designs on another woman's fingernails using various colors and patterns.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating how to create intricate nail designs on another woman's fingernails using various colors and patterns.", "clean_property": {"obj": "nail polish", "attribute": "intricate design"}, "target_prompt": "A woman demonstrating how to apply simple solid color nail polish on another woman's fingernails.", "target_property": {"obj": "nail polish", "attribute": "simple solid color"}, "evaluation_question": "Are the nail designs being created **intricate**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to create intricate nail designs on another woman's fingernails using various colors and patterns. >BS\u00b7C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2835eaf217134b7f9d84611c49103893.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e670fffba0cf473e83943f1af76efcca", "source": "vatex", "video_id": "u8iT_yLKpNs_000000_000010", "video_description": "A baby is sitting on the floor playing with a toy xylophone, making noises and occasionally rolling it around.", "task": "ObjectRecognition", "clean_prompt": "A baby is sitting on the floor playing with a toy xylophone, making noises and occasionally rolling it around.", "clean_property": {"obj": "xylophone"}, "target_prompt": "A baby is sitting on the floor playing with a toy drum, making noises and occasionally rolling it around.", "target_property": {"obj": "drum"}, "evaluation_question": "Is the baby playing with a **xylophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is sitting on the floor playing with a toy xylophone, making noises and occasionally rolling it around. FEI=L", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/58e81b8a0c5f41f9b20382d6a358228b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2701f379a4c94138a6812370dfa87863", "source": "vatex", "video_id": "n4Lh325FdGM_000000_000010", "video_description": "A tattoo artist is performing a belly button piercing on a woman in a piercing parlor.", "task": "ObjectRecognition", "clean_prompt": "A tattoo artist is using clamps while performing a belly button piercing on a woman in a piercing parlor.", "clean_property": {"obj": "clamps"}, "target_prompt": "A tattoo artist is using scissors while performing a belly button piercing on a woman in a piercing parlor.", "target_property": {"obj": "scissors"}, "evaluation_question": "Is the tattoo artist using **clamps** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tattoo artist is using clamps while performing a belly button piercing on a woman in a piercing parlor. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/25f5dd20a0e64ef393112cd1a35fc537.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1748c6d9b964f54b0d8c5f8cca02758", "source": "vatex", "video_id": "iEi8heT5GH8_000100_000110", "video_description": "A woman demonstrates the use of a facial scrub, washing her face with a washcloth while looking in a mirror. The scene includes a discussion of the facial scrub's key ingredients and an infomercial about the product.", "task": "AttributeRecognition", "clean_prompt": "A woman is using a facial scrub while looking in a round mirror.", "clean_property": {"obj": "mirror", "attribute": "round"}, "target_prompt": "A woman is using a facial scrub while looking in a square mirror.", "target_property": {"obj": "mirror", "attribute": "square"}, "evaluation_question": "Is the mirror round?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using a facial scrub while looking in a round mirror. E()SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc423f01fced4da6b0d0f2bef768e47b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aeced4e96f5c4809b55583f357a9e7c1", "source": "vatex", "video_id": "B5lAcaojk0E_000000_000010", "video_description": "A man is in a bathroom in front of a mirror, adjusting his hair and posing for the camera. A woman films him as he drools into the sink.", "task": "ObjectRecognition", "clean_prompt": "A man is in a bathroom in front of a mirror, adjusting his hair and posing for the camera while drooling into the sink.", "clean_property": {"obj": "sink"}, "target_prompt": "A man is in a bathroom in front of a mirror, adjusting his hair and posing for the camera while drooling into the toilet.", "target_property": {"obj": "toilet"}, "evaluation_question": "Is the man drooling into a **sink**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is in a bathroom in front of a mirror, adjusting his hair and posing for the camera while drooling into the sink. .'G*E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d269b7d31c57475dad51b67653b83348.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "93f1b7093d7b456bb9ced2e4007a4277", "source": "vatex", "video_id": "O6d9BTFwzI4_000019_000029", "video_description": "A man is building a snowman in the snow, rolling large snowballs and stacking them to form the snowman. The process is shown in a time-lapse with light, jazzy comedic music playing.", "task": "ObjectRecognition", "clean_prompt": "A man building a snowman in the snow.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing in the snow.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man building a snowman in the snow. @IMGV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1ba1924073ab4d2ba799b61d581c4213.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "de5dc0de80f04b09bbb22cb71ae8e78d", "source": "vatex", "video_id": "WuyNEyKYwG0_000019_000029", "video_description": "A man in a gym or warehouse setting demonstrates a squat exercise, starting from a squatting position with arms outstretched and then standing up.", "task": "Counting", "clean_prompt": "Four people in a gym demonstrating a squat exercise together.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a gym demonstrating a squat exercise.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a gym demonstrating a squat exercise together. =2@#F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d5b0d6d57578480e83f028cb72318c7c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3516afacabe94c9190fd4e027a104a27", "source": "vatex", "video_id": "2H2hmK0xG0A_000000_000010", "video_description": "In a classroom, two teenage boys clash their heads together while the rest of the class watches.", "task": "ObjectRecognition", "clean_prompt": "In a classroom, two teenage boys clash their heads together while the rest of the class watches.", "clean_property": {"obj": "classroom"}, "target_prompt": "In a playground, two teenage boys clash their heads together while the rest of the children watch.", "target_property": {"obj": "playground"}, "evaluation_question": "Is the setting of the video a **classroom**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "In a classroom, two teenage boys clash their heads together while the rest of the class watches. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f339775e6170451ca249cb0688e4ae8e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b3bc5433b0f14432abee074c96e684e9", "source": "vatex", "video_id": "B8a2_ZCxVyQ_000000_000010", "video_description": "A young boy, wearing an orange shirt, is at a gas station pumping gas into a car under the supervision of an adult.", "task": "SpatialUnderstanding", "clean_prompt": "A gas pump farther from the camera than a car.", "clean_property": {"obj_1": "gas pump", "relation": "farther from the camera than", "obj_2": "car"}, "target_prompt": "A gas pump closer to the camera than a car.", "target_property": {"obj_1": "gas pump", "relation": "closer to the camera than", "obj_2": "car"}, "evaluation_question": "Is the gas pump **farther from the camera than** the car?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A gas pump farther from the camera than a car. ;T)FX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/165b2470d1db4506a3e4636b84dac866.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "578f5bed51a740009739a2a768204be1", "source": "vatex", "video_id": "7UQWpt6_CHI_000244_000254", "video_description": "A choir of men in matching tan suits is performing in a church. The lead singer holds a microphone while the group sings and claps their hands.", "task": "ActionRecognition", "clean_prompt": "A lead singer singing in a church with a choir of men in matching tan suits.", "clean_property": {"obj": "lead singer", "action": "singing", "target": null}, "target_prompt": "A lead singer rapping in a nightclub with a group of dancers.", "target_property": {"obj": "lead singer", "action": "rapping", "target": null}, "evaluation_question": "Is the lead singer **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A lead singer singing in a church with a choir of men in matching tan suits. VH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f9208206349749f5aa8e36a8e28b1c9e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d974b3d1a486476099a1b35d9452f118", "source": "vatex", "video_id": "MjCsB5RM1Zg_000004_000014", "video_description": "A young boy is sitting on a step or floor, holding a toothbrush and brushing his teeth while a woman instructs him.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on a step, holding a toothbrush and brushing his teeth while a woman instructs him.", "clean_property": {"obj": "toothbrush"}, "target_prompt": "A young boy is sitting on a step, holding a hairbrush and brushing his hair while a woman instructs him.", "target_property": {"obj": "hairbrush"}, "evaluation_question": "Is the boy holding a **toothbrush**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting on a step, holding a toothbrush and brushing his teeth while a woman instructs him. U%|0&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f5554d9feee047d180671c25ce8ca3f3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81844a5be43d4f98b26378ae423a18ed", "source": "vatex", "video_id": "w70REJeQqOI_000040_000050", "video_description": "A person is lying on a bed, wiggling their toes and cracking their knuckles.", "task": "Counting", "clean_prompt": "Two people lying on a bed, wiggling their toes and cracking their knuckles.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person lying on a bed, wiggling their toes and cracking their knuckles.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people lying on the bed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people lying on a bed, wiggling their toes and cracking their knuckles. !'G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/400e6f453ace46c3b8f01d58c0f9551b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46c2bbcfa1d04f07a81763b8dd0d2126", "source": "vatex", "video_id": "5ILkwhgwtkQ_000120_000130", "video_description": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background.", "clean_property": {"obj": "paper airplane"}, "target_prompt": "A young boy is sitting on the floor of a bedroom, folding a colorful piece of paper into a kite while music plays in the background.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the object being folded in the video a **paper airplane**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting on the floor of a bedroom, folding a blue piece of paper into a paper airplane while music plays in the background. LYSWK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61abea11768049de8948f504da45cdae.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "69f7490d575b4e46b69994584c5a3d4a", "source": "vatex", "video_id": "5fwdWjjehSk_000041_000051", "video_description": "A woman is demonstrating how to correctly perform lunges on a yoga mat in a home gym area.", "task": "SpatialUnderstanding", "clean_prompt": "A yoga mat closer to the camera than a person demonstrating lunges in a home gym area.", "clean_property": {"obj_1": "yoga mat", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A yoga mat further from the camera than a person demonstrating lunges in a home gym area.", "target_property": {"obj_1": "yoga mat", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the yoga mat closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A yoga mat closer to the camera than a person demonstrating lunges in a home gym area. )!G%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1ec2f930a8e48198e2427938e8eb1f8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3c1f3b3c5a1f48928ee81f4323afd4db", "source": "vatex", "video_id": "54WpMo_Oisc_000037_000047", "video_description": "A young man in a dress shirt is demonstrating how to tie a necktie while filming himself.", "task": "AttributeRecognition", "clean_prompt": "A young man in a dress shirt demonstrating how to tie a black tie.", "clean_property": {"obj": "tie", "attribute": "black"}, "target_prompt": "A young man in a dress shirt demonstrating how to tie a red tie.", "target_property": {"obj": "tie", "attribute": "red"}, "evaluation_question": "Is the tie being demonstrated **black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in a dress shirt demonstrating how to tie a black tie. )?W%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7a0193365124726b65240d3dd8fd887.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3c5f9ca43f4c404492dd3fe8ae756536", "source": "vatex", "video_id": "aC_3rmjvSxk_000042_000052", "video_description": "A man is fishing with his hands by a lake while another man films the activity. A young boy is also present, sitting at the edge of the lake.", "task": "AttributeRecognition", "clean_prompt": "A table filled with food.", "clean_property": {"obj": "table", "attribute": "filled with food"}, "target_prompt": "A table empty.", "target_property": {"obj": "table", "attribute": "empty"}, "evaluation_question": "Is the table **filled with food**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A table filled with food. U3FE.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/575faa983cd448d9a25df1ba1813024d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "52a4943e29c141c78153f9a2b4cca11b", "source": "vatex", "video_id": "IFdBkcy-f-I_000116_000126", "video_description": "A man with red hair is standing on a porch, demonstrating and explaining how to use a bow and arrow, including how to nock an arrow on a recurve bow.", "task": "AttributeRecognition", "clean_prompt": "A man with red hair is standing on a porch, demonstrating and explaining how to use a recurve bow and arrow.", "clean_property": {"obj": "bow", "attribute": "recurve"}, "target_prompt": "A man with red hair is standing on a porch, demonstrating and explaining how to use a compound bow and arrow.", "target_property": {"obj": "bow", "attribute": "compound"}, "evaluation_question": "Is the man demonstrating a **recurve** bow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man with red hair is standing on a porch, demonstrating and explaining how to use a recurve bow and arrow. U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/da21dcb6ea724fe5b8391b5f01aaa824.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6792c0874b4f41c1bb386f333c9f4dd6", "source": "vatex", "video_id": "-4ql_DsxVhY_000000_000010", "video_description": "A worker is using an industrial floor machine to sand and polish a concrete floor in a construction setting.", "task": "AttributeRecognition", "clean_prompt": "A worker using an industrial floor machine to sand and polish a concrete floor.", "clean_property": {"obj": "floor", "attribute": "concrete"}, "target_prompt": "A worker using an industrial floor machine to sand and polish a wooden floor.", "target_property": {"obj": "floor", "attribute": "wooden"}, "evaluation_question": "Is the floor being polished **concrete**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A worker using an industrial floor machine to sand and polish a concrete floor. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a5cc049a04d4baa90b35c7764f6e8e8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a5c81adcf60846b4b9390c71b688c3e2", "source": "vatex", "video_id": "dGNTOn_sisg_000089_000099", "video_description": "A young child is in a kitchen demonstrating how to prepare cookie dough on baking trays. There are mounds of dough on a baking tray on a counter, and the child is giving instructions while another person places balls of brown dough on a tray. The child talks about the process and occasionally eats some dough.", "task": "Counting", "clean_prompt": "A young child is demonstrating how to prepare cookie dough on two baking trays in a kitchen.", "clean_property": {"obj": "baking tray", "count": "two"}, "target_prompt": "A young child is demonstrating how to prepare cookie dough on one baking tray in a kitchen.", "target_property": {"obj": "baking tray", "count": "one"}, "evaluation_question": "Are there exactly **two** baking trays in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young child is demonstrating how to prepare cookie dough on two baking trays in a kitchen. ONDLV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/423100e650094e21b268db0405dbed91.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "123636f9f0d14a909e73e196f4d5cfed", "source": "vatex", "video_id": "q7kPw2pdB30_000020_000030", "video_description": "A group of drummers play their drums rapidly in a circle while a man crawls and dances on the ground in the center.", "task": "Counting", "clean_prompt": "A crowd of seven drummers playing their drums rapidly in a circle while a man crawls and dances on the ground in the center.", "clean_property": {"obj": "crowd", "count": "seven"}, "target_prompt": "A crowd of three drummers playing their drums slowly in a line while a man stands still in the center.", "target_property": {"obj": "crowd", "count": "three"}, "evaluation_question": "Are there exactly **seven** drummers in the crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd of seven drummers playing their drums rapidly in a circle while a man crawls and dances on the ground in the center. #MJ@K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/37c250a3b7be47d8a9ca24abc55b199e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5be008f300b04982b12698859ee688a1", "source": "vatex", "video_id": "71qRCvVL8wM_000029_000039", "video_description": "A man is pretending to have a phone conversation by playing two different characters, switching back and forth between them, using exaggerated facial expressions.", "task": "Counting", "clean_prompt": "A man is pretending to have a phone conversation by playing two different characters, switching back and forth between them, using exaggerated facial expressions.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A man is pretending to have a phone conversation by playing one character, using exaggerated facial expressions.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** characters being portrayed in the conversation?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is pretending to have a phone conversation by playing two different characters, switching back and forth between them, using exaggerated facial expressions. )?'!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f2dcf37efa17489e83a37b08e5552411.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4083b35d48964916990829e56070c19d", "source": "vatex", "video_id": "aXzZfGsfSWQ_000004_000014", "video_description": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility, while a man talks and a cameraman records.", "task": "AttributeRecognition", "clean_prompt": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility.", "clean_property": {"obj": "woman", "attribute": "wearing animal ears and tail"}, "target_prompt": "A woman wearing a superhero costume bends backwards, demonstrating flexibility.", "target_property": {"obj": "woman", "attribute": "wearing a superhero costume"}, "evaluation_question": "Is the woman wearing a costume with **animal ears and tail**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility. !0\u00b7'-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f996a532fa5c4dabbb96bb3ce647c840.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fc856f10f3f74fd2809957bdbccb1c72", "source": "vatex", "video_id": "5bZp4aplp_A_000132_000142", "video_description": "A large group of people, including men and children, are playing dodgeball in a gym. Multiple games are happening simultaneously.", "task": "AttributeRecognition", "clean_prompt": "A person playing dodgeball with children in a gym.", "clean_property": {"obj": "person", "attribute": "children"}, "target_prompt": "A person playing dodgeball with adults in a gym.", "target_property": {"obj": "person", "attribute": "playing dodgeball with adults"}, "evaluation_question": "Is the person playing dodgeball with **children**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing dodgeball with children in a gym. KM!':", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/da8b0a15d0264cf3b78c940f08af57de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2f0fa7aa211b4678b0dd00a8e2d72576", "source": "vatex", "video_id": "Pz3JbG-BMn4_000002_000012", "video_description": "A person is rappelling down a rocky cliff using a climbing rope.", "task": "ObjectRecognition", "clean_prompt": "A person rappelling down a rocky cliff using a climbing rope.", "clean_property": {"obj": "rope"}, "target_prompt": "A person swinging from a tree branch.", "target_property": {"obj": "swing"}, "evaluation_question": "Is the person using a **climbing rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person rappelling down a rocky cliff using a climbing rope. 'W*))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/23d6940241f84431a1568fe0ad66c8cf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "65dd989ef4a54e76af006c2f41cfe4c4", "source": "vatex", "video_id": "mcMqVzsTkkU_000051_000061", "video_description": "A man is performing stunts and walking on a tightrope across a deep canyon, high above the ground, with mountains in the background.", "task": "AttributeRecognition", "clean_prompt": "A man performing stunts and walking on a tightrope high above a deep canyon with mountains in the background.", "clean_property": {"obj": "tightrope", "attribute": "high"}, "target_prompt": "A man performing stunts and walking on a tightrope low above a flat field with trees in the background.", "target_property": {"obj": "tightrope", "attribute": "low"}, "evaluation_question": "Is the tightrope high above the ground?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing stunts and walking on a tightrope high above a deep canyon with mountains in the background. V@GFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c10677bab1a4c1faa490f018759d7b5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e34e62d78b6a41a8872a1ee5c57e2f97", "source": "vatex", "video_id": "Fx3vWgjENJg_000055_000065", "video_description": "A group of young female gymnasts perform gymnastics routines, including flips and handsprings, on a mat in front of an audience and judges. A coach stands at the end of the mat to spot the gymnasts.", "task": "Counting", "clean_prompt": "Three coaches standing at the end of the mat while young female gymnasts perform routines.", "clean_property": {"obj": "coach", "count": "three"}, "target_prompt": "One coach standing at the end of the mat while young female gymnasts perform routines.", "target_property": {"obj": "coach", "count": "one"}, "evaluation_question": "Are there exactly **three** coaches standing at the end of the mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three coaches standing at the end of the mat while young female gymnasts perform routines. )!A-&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64a9c6cea76a462daec0f0e12c37a8a0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "629532eaced5433ea47a45252069eeff", "source": "vatex", "video_id": "P-jVydhduoU_001268_001278", "video_description": "A woman, likely a lawyer, is standing at a desk in a courtroom, expressively speaking and defending a case in front of a judge and an audience.", "task": "ActionRecognition", "clean_prompt": "A woman testifying expressively in a courtroom.", "clean_property": {"obj": "woman", "action": "testifying", "target": null}, "target_prompt": "A woman arguing a case in a courtroom.", "target_property": {"obj": "woman", "action": "arguing", "target": "case"}, "evaluation_question": "Is the woman **testifying**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman testifying expressively in a courtroom. >7BSG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4cf1a785e9094590b35396dad6700a0c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2d7e143ba024476d938796827741e225", "source": "vatex", "video_id": "hfvayTDNZuo_000003_000013", "video_description": "A group of people, including a man in a blue snow suit, are cross-country skiing down a snowy trail in a forest. The trail is covered with snow and has tracks from previous skiers. A child chatters in the background while a bystander observes.", "task": "AttributeRecognition", "clean_prompt": "A skier wearing a blue snow suit is cross-country skiing down a snowy trail in a forest.", "clean_property": {"obj": "skier", "attribute": "wearing blue snow suit"}, "target_prompt": "A skier wearing a red snow suit is cross-country skiing down a snowy trail in a forest.", "target_property": {"obj": "skier", "attribute": "wearing a red snow suit"}, "evaluation_question": "Is the skier wearing a **blue** snow suit?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skier wearing a blue snow suit is cross-country skiing down a snowy trail in a forest. =L|FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e901e2c43e8f473ebf976032e7a9a008.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b8da0127ff624fd19165a5e467b6cb2b", "source": "vatex", "video_id": "xqj8-q4-Jvw_000014_000024", "video_description": "Two young girls are playing in a snowy yard. One girl is shoveling snow while the other, a baby girl, is crawling in the snow. Their mother is present, commenting on their play.", "task": "ActionRecognition", "clean_prompt": "A girl shoveling snow in a snowy yard.", "clean_property": {"obj": "girl_1", "action": "shoveling snow", "target": null}, "target_prompt": "A girl building a snowman in a snowy yard.", "target_property": {"obj": "girl_1", "action": "building a snowman", "target": null}, "evaluation_question": "Is the girl **shoveling snow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl shoveling snow in a snowy yard. :OC@R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/af50faac93fd465280d1c52e98cd7a3a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "43973e96075e4701ade7a2796838d2ab", "source": "vatex", "video_id": "rebLaC9N6fw_000047_000057", "video_description": "A man is texting and talking to himself using his iPhone while another man is in the kitchen pouring a liquid into a flask.", "task": "ObjectRecognition", "clean_prompt": "A man is texting and talking to himself using his iPhone while another man is in the kitchen pouring coffee into a flask.", "clean_property": {"obj": "coffee"}, "target_prompt": "A man is texting and talking to himself using his iPhone while another man is in the kitchen pouring tea into a flask.", "target_property": {"obj": "tea"}, "evaluation_question": "Is the liquid being poured into the flask **coffee**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is texting and talking to himself using his iPhone while another man is in the kitchen pouring coffee into a flask. ELLQS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3a77bd129dd149338749c7fc4adbacde.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "deb080399c7248d7b2cd4b60fa516b8d", "source": "vatex", "video_id": "C-d8Qjl7OIs_000002_000012", "video_description": "A man with glasses and a surprised expression is sitting in a chair at home, blowing out a single candle on a cake while others compliment him.", "task": "Counting", "clean_prompt": "A man with glasses and a surprised expression is sitting in a chair at home, blowing out a single candle on a cake while seven others compliment him.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A man with glasses and a surprised expression is sitting in a chair at home, blowing out a single candle on a cake while three others compliment him.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people complimenting him?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man with glasses and a surprised expression is sitting in a chair at home, blowing out a single candle on a cake while seven others compliment him. =LFE|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/44224a957ded4b2f88ceec94c7c8160f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b7e6fdb5236442c885e8049743e4ccf0", "source": "vatex", "video_id": "aZq9W61seMw_000009_000019", "video_description": "A woman is practicing fencing and sword fighting skills indoors, seemingly dueling with herself while yelling and talking about various topics.", "task": "ObjectRecognition", "clean_prompt": "A woman practicing fencing and sword fighting skills indoors, dueling with herself while talking about various topics.", "clean_property": {"obj": "person"}, "target_prompt": "A robot practicing fencing and sword fighting skills indoors, dueling with itself while talking about various topics.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman practicing fencing and sword fighting skills indoors, dueling with herself while talking about various topics. ?)!F-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e5623683b41f40f4b2a2b12afe0e93d5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a3bcbbaaaede4f88965be4e51c87074b", "source": "vatex", "video_id": "L47aWT2v7PQ_000000_000010", "video_description": "In a large box store, a man kneels down in the middle of an aisle to tie his shoe and then performs a moonwalk dance down the aisle.", "task": "ActionRecognition", "clean_prompt": "A person moon walking down the aisle of a large box store.", "clean_property": {"obj": "person", "action": "moon walking", "target": null}, "target_prompt": "A person running down the aisle of a large box store.", "target_property": {"obj": "person", "action": "running", "target": null}, "evaluation_question": "Is the person **moon walking**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person moon walking down the aisle of a large box store. LY4$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/47d34f7f7f6443bca31d0150a2b6b058.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4206f31b21904450a730bc26a4603af5", "source": "vatex", "video_id": "0-jlmF47DS4_000153_000163", "video_description": "A woman is sitting in a bedroom, talking to the camera, making an announcement, and waving goodbye.", "task": "SpatialUnderstanding", "clean_prompt": "A person sitting to the left of the camera in a bedroom, talking and waving goodbye.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "camera"}, "target_prompt": "A person sitting to the right of the camera in a bedroom, talking and waving goodbye.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "camera"}, "evaluation_question": "Is the person to the **left** of the camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting to the left of the camera in a bedroom, talking and waving goodbye. FS@E1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eff7a7b94241490ab7be8f1b65b85bd8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f84caf913f14778be7ccda44357a71a", "source": "vatex", "video_id": "OOxphqMuui8_000011_000021", "video_description": "A sushi chef is preparing sushi in a kitchen, using fresh ingredients and wearing gloves.", "task": "SpatialUnderstanding", "clean_prompt": "A chef standing to the left of a sushi.", "clean_property": {"obj_1": "chef", "relation": "left of", "obj_2": "sushi"}, "target_prompt": "A chef standing to the right of a sushi.", "target_property": {"obj_1": "chef", "relation": "right of", "obj_2": "sushi"}, "evaluation_question": "Is the chef to the **left** of the sushi?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef standing to the left of a sushi. LY;FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d5a4078b437540cb98f833e9f2a48c0b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3241eef23a8e414798e9b33dea16eb08", "source": "vatex", "video_id": "kBjslZs3JlU_000045_000055", "video_description": "A woman is featured in a refrigerator advertisement. She opens a smart refrigerator, takes a green apple from a bowl inside, closes the fridge, and smiles. The advertisement includes images of different refrigerators and is set to music.", "task": "ObjectRecognition", "clean_prompt": "A woman opens a smart refrigerator, takes a green apple from a bowl inside, closes the fridge, and smiles.", "clean_property": {"obj": "refrigerator"}, "target_prompt": "A woman opens a smart oven, takes a freshly baked pie out, closes the oven, and smiles.", "target_property": {"obj": "oven"}, "evaluation_question": "Is the woman interacting with a **refrigerator**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman opens a smart refrigerator, takes a green apple from a bowl inside, closes the fridge, and smiles. LY2;S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e313d229671b438d8bea9e4d348273e1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e8e7911c0c7b4d969d7b79e23c4baee9", "source": "vatex", "video_id": "P_rpMCioUDs_000000_000010", "video_description": "A man and a woman are having a heated discussion about their inability to conceive a baby.", "task": "ActionRecognition", "clean_prompt": "A woman arguing with a man about their inability to conceive a baby.", "clean_property": {"obj": "woman", "action": "arguing", "target": "man"}, "target_prompt": "A woman laughing with a man about their inability to conceive a baby.", "target_property": {"obj": "woman", "action": "laughing", "target": "man"}, "evaluation_question": "Is the woman **arguing** with the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman arguing with a man about their inability to conceive a baby. DYE5)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ecbcd580b4ca4c66bf701ce8c574a559.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "94ed69b3009b4cf69a952c389bcdc221", "source": "vatex", "video_id": "45xZbSPyjYY_000009_000019", "video_description": "A young woman is making sandwiches in a kitchen using a time-lapse effect, with music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A young woman making sandwiches in a kitchen using a time-lapse effect.", "clean_property": {"obj": "sandwich"}, "target_prompt": "A young woman preparing a salad in a kitchen using a time-lapse effect.", "target_property": {"obj": "salad"}, "evaluation_question": "Is the woman making **sandwiches** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman making sandwiches in a kitchen using a time-lapse effect. ))!0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78508b7c90d14a7b843ca3cd4d9f1752.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "30dbfbe9a47e4d598fa9dad9c6b856bb", "source": "vatex", "video_id": "lcO0X5KwBsY_000101_000111", "video_description": "A group of school children are creating a chalk mural on an outdoor wall. The process is shown in a time-lapse.", "task": "ActionRecognition", "clean_prompt": "A group of children drawing a chalk mural on an outdoor wall.", "clean_property": {"obj": "children", "action": "drawing", "target": "wall"}, "target_prompt": "A group of children painting on a canvas.", "target_property": {"obj": "children", "action": "painting", "target": "canvas"}, "evaluation_question": "Are the children **drawing** on the wall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children drawing a chalk mural on an outdoor wall. >BSDJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2267cd53e2844099b398a89d8649aa5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8f3a6e1fdeab4fd7a6c3ccaa1f02aecd", "source": "vatex", "video_id": "aYew9G2osTo_000000_000010", "video_description": "Two young men are having a playful pillow fight in a living room. During the fight, one of the men gets hit hard and falls onto a couch, after which the other jumps on top of him.", "task": "ActionRecognition", "clean_prompt": "A person having a pillow fight in a living room.", "clean_property": {"obj": "person", "action": "pillow fight", "target": null}, "target_prompt": "A person wrestling with a friend in a living room.", "target_property": {"obj": "person", "action": "wrestling", "target": "friend"}, "evaluation_question": "Is the person **having a pillow fight**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person having a pillow fight in a living room. !0D0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76dc20992dbf45748368c462c212d5e9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "408b740cc3bf4a12b62b4016bcde09b1", "source": "vatex", "video_id": "MjCsB5RM1Zg_000004_000014", "video_description": "A young boy is sitting on a step or floor, holding a toothbrush and brushing his teeth while a woman instructs him.", "task": "ActionRecognition", "clean_prompt": "A boy brushing his teeth while a woman instructs him.", "clean_property": {"obj": "boy", "action": "brushing teeth", "target": null}, "target_prompt": "A boy playing with toys while a woman instructs him.", "target_property": {"obj": "boy", "action": "playing with toys", "target": null}, "evaluation_question": "Is the boy **brushing his teeth**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy brushing his teeth while a woman instructs him. RY.92", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eac620b74a0849ea8603d42bc4b409d3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dc9863a007fd4df2844d8f269925248d", "source": "vatex", "video_id": "b2VwJXLsqNI_000022_000032", "video_description": "A young man is water skiing beside a motorboat, holding onto a pole extending from the boat. He eventually lets go and falls into the water.", "task": "SpatialUnderstanding", "clean_prompt": "A waterskier farther from the camera than a motorboat.", "clean_property": {"obj_1": "waterskier", "relation": "farther from the camera than", "obj_2": "motorboat"}, "target_prompt": "A waterskier closer to the camera than a motorboat.", "target_property": {"obj_1": "waterskier", "relation": "closer to the camera than", "obj_2": "motorboat"}, "evaluation_question": "Is the waterskier **farther from the camera than** the motorboat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A waterskier farther from the camera than a motorboat. ;J,UK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f57e042bfe8a44e4886712d526fb16ab.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9dd4bbaca0314d8f90d9b840e7812872", "source": "vatex", "video_id": "N9T8Nj_splo_000033_000043", "video_description": "A woman is performing a series of kicking and lunging exercises in a studio for an online vlog.", "task": "AttributeRecognition", "clean_prompt": "A person wearing all black is performing kicking and lunging exercises in a studio.", "clean_property": {"obj": "person", "attribute": "wearing all black"}, "target_prompt": "A person wearing bright colors is performing kicking and lunging exercises in a studio.", "target_property": {"obj": "person", "attribute": "wearing bright colors"}, "evaluation_question": "Is the person wearing **all black**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing all black is performing kicking and lunging exercises in a studio. /FEY$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cfff1ae8080e4eb2a9feca2b7e6b252f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6108c0cba3184795a225f60fd126e6d8", "source": "vatex", "video_id": "8hwt4z7alvw_000055_000065", "video_description": "A young man is beatboxing into a microphone in a white room, making musical noises with his mouth and throat while looking into the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A microphone closer to the camera than a person beatboxing in a white room.", "clean_property": {"obj_1": "microphone", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A microphone further from the camera than a person beatboxing in a white room.", "target_property": {"obj_1": "microphone", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the microphone closer to the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A microphone closer to the camera than a person beatboxing in a white room. ?U%UU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b7d4232e53c741e6aa87ec43e3f62c34.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8391a006b5774767958d42e9e5d67a76", "source": "vatex", "video_id": "E3AcjYJVI8o_000012_000022", "video_description": "A man in a gym is performing battle rope exercises by kneeling on the floor and swinging two heavy ropes up and down.", "task": "ActionRecognition", "clean_prompt": "A person performing battle rope training in a gym.", "clean_property": {"obj": "person", "action": "battle rope training", "target": null}, "target_prompt": "A person performing battle rope training with heavy ropes in a park.", "target_property": {"obj": "person", "action": "battle rope training", "target": "heavy ropes"}, "evaluation_question": "Is the person **in a gym**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing battle rope training in a gym. NK7\u00b7@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/273b7c77e3b54a558648bc84d5b712b9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f516ccdbec8c428487ef0bc69c9f5f16", "source": "vatex", "video_id": "y9BBTObIGp0_000000_000010", "video_description": "A young man is visiting the Roger Williams Zoo, filming himself as he tours the zoo and observes giraffes in an enclosed outdoor area.", "task": "Counting", "clean_prompt": "A young man is visiting a zoo and filming himself as he observes three giraffes in an enclosed outdoor area.", "clean_property": {"obj": "zoo", "count": "three"}, "target_prompt": "A young man is visiting a zoo and filming himself as he observes one giraffe in an enclosed outdoor area.", "target_property": {"obj": "zoo", "count": "one"}, "evaluation_question": "Are there exactly **three** giraffes in the enclosed outdoor area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is visiting a zoo and filming himself as he observes three giraffes in an enclosed outdoor area. @JJJR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/43528a160c24412895f60e72b4f42ced.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1c514de323d469cb6abb7d73dc457be", "source": "vatex", "video_id": "Kh7SEzWU0hU_000003_000013", "video_description": "A young man is demonstrating how to use a video game controller, including holding it upside down, while talking to the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a video game controller.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "controller"}, "target_prompt": "A person closer to the camera than a video game controller.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "video game controller"}, "evaluation_question": "Is the person **farther from the camera than** the video game controller?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a video game controller. FS|E#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20b037d6a8e34d18ad4076553dc7d051.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0219487ddf9d43bca7372e82549c11f4", "source": "vatex", "video_id": "-Bb_zut9Ciw_000021_000031", "video_description": "A man is standing on the shore of a large body of water, such as an ocean or lake, using a long fishing rod to cast a line in an attempt to catch fish. The footage is recorded in slow motion.", "task": "Counting", "clean_prompt": "A man is standing on the shore with two fishing rods, casting lines into the water in slow motion.", "clean_property": {"obj": "water", "count": "two"}, "target_prompt": "A man is standing on the shore with one fishing rod, casting a line into the water in slow motion.", "target_property": {"obj": "water", "count": "one"}, "evaluation_question": "Are there exactly **two** fishing rods being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing on the shore with two fishing rods, casting lines into the water in slow motion. =P9BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a0b61861b6041949f27a9e56ba3cc9e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0cbdf6b8bbd34f4aab3eadb1a7cb9773", "source": "vatex", "video_id": "Fa0CjjLuN54_000073_000083", "video_description": "A person demonstrates how to tie a bow with a ribbon and then trims the excess with scissors. The ribbon is sometimes described as blue and sometimes as purple, and the demonstration is accompanied by music.", "task": "Counting", "clean_prompt": "Three people demonstrating how to tie a bow with a ribbon.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person demonstrating how to tie a bow with a ribbon.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people demonstrating how to tie a bow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people demonstrating how to tie a bow with a ribbon. =3BC$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7439b265a1c440358dbf5bd426955188.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f922bd6498f548a291ea8ac354cc8dd7", "source": "vatex", "video_id": "EIxjnqaxgpA_000169_000179", "video_description": "A large group of children and youth perform a cultural dance routine in a gymnasium in front of a large crowd. The performance includes cheerleaders, gymnasts, and large costumed figures resembling women. The audience is engaged and chanting along.", "task": "SpatialUnderstanding", "clean_prompt": "Costumed figures standing to the left of a performer in a gymnasium.", "clean_property": {"obj_1": "costumed figures", "relation": "left of", "obj_2": "performer"}, "target_prompt": "Costumed figures standing to the right of a performer in a gymnasium.", "target_property": {"obj_1": "costumed figures", "relation": "right of", "obj_2": "performer"}, "evaluation_question": "Are the costumed figures to the **left** of the performer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Costumed figures standing to the left of a performer in a gymnasium. FE>S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fce5bf61ba44444eb0f3f06420453a31.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "32eb28d515fe45af801157b7ab6fe09c", "source": "vatex", "video_id": "ll7c0Y0p5dw_000000_000010", "video_description": "A boy performs a magic trick where he appears to pull a smartphone from a computer screen into his hand.", "task": "Counting", "clean_prompt": "A boy performs a magic trick where he appears to pull a smartphone from a computer screen into his hand, with five boys watching in amazement.", "clean_property": {"obj": "boy", "count": "five"}, "target_prompt": "A girl performs a magic trick where she appears to pull a smartphone from a computer screen into her hand, with three girls watching in amazement.", "target_property": {"obj": "girl", "count": "three"}, "evaluation_question": "Are there exactly **five** boys watching the magic trick?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy performs a magic trick where he appears to pull a smartphone from a computer screen into his hand, with five boys watching in amazement. FE)P$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aabbd5ebdff54969a86f07bc310be560.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cc65e11032a04c618b109efc8a416591", "source": "vatex", "video_id": "JfGAJe_sS4s_000000_000010", "video_description": "A man in blue is jogging on a sidewalk during a fun run, passing by a crowd of bystanders who cheer and greet him.", "task": "ObjectRecognition", "clean_prompt": "A jogger in blue is jogging on a sidewalk during a fun run, passing by a crowd of bystanders who cheer and greet him.", "clean_property": {"obj": "jogger"}, "target_prompt": "A biker in blue is riding on a sidewalk during a fun run, passing by a crowd of bystanders who cheer and greet him.", "target_property": {"obj": "biker"}, "evaluation_question": "Is the person in the video a **jogger**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A jogger in blue is jogging on a sidewalk during a fun run, passing by a crowd of bystanders who cheer and greet him. P.FEP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49f649e6e0d048dbba4b555c3df26162.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c7d40f86da2e4b3abf41aba7172772a9", "source": "vatex", "video_id": "oRrwzU5iADM_000025_000035", "video_description": "A young man opens a refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "task": "ObjectRecognition", "clean_prompt": "A young man opens a refrigerator door in a living room.", "clean_property": {"obj": "person"}, "target_prompt": "A cat opens a refrigerator door in a living room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man opens a refrigerator door in a living room. AQ!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95729737dca84cb9b3f4d7f55b4d421b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e5d1babc37284c70ae14879b8f1510f3", "source": "vatex", "video_id": "aXzZfGsfSWQ_000004_000014", "video_description": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility, while a man talks and a cameraman records.", "task": "ActionRecognition", "clean_prompt": "A woman bending back in a costume with animal ears and a tail.", "clean_property": {"obj": "woman", "action": "bending back", "target": null}, "target_prompt": "A woman standing straight in a costume with animal ears and a tail.", "target_property": {"obj": "woman", "action": "standing straight", "target": null}, "evaluation_question": "Is the woman **bending back**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman bending back in a costume with animal ears and a tail. LYPZV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b88194246554491fae6a29141e5b6ba6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "01d0c8aa1633452c96fc7a76fae0b9d9", "source": "vatex", "video_id": "hBsnCUPKM-s_000056_000066", "video_description": "A young girl is in her room, tearing various paper materials like newspaper ads, magazine pages, and flyers into pieces.", "task": "ActionRecognition", "clean_prompt": "A girl ripping paper in her room.", "clean_property": {"obj": "girl", "action": "ripping paper", "target": null}, "target_prompt": "A girl throwing paper in her room.", "target_property": {"obj": "girl", "action": "throwing paper", "target": null}, "evaluation_question": "Is the girl **ripping** paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl ripping paper in her room. SLNBC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0ce5dead1b474e2290596e446723b6a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5424df4961c344bfbcbabf6da8ea556b", "source": "vatex", "video_id": "qOFTd1vMPug_000000_000010", "video_description": "A young woman runs down the sidewalk and leaps into the arms of a man, and they embrace.", "task": "ObjectRecognition", "clean_prompt": "A young woman runs down the sidewalk and leaps into the arms of a man, and they embrace.", "clean_property": {"obj": "man"}, "target_prompt": "A young man runs down the sidewalk and leaps into the arms of a woman, and they embrace.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person the woman leaps into the arms of a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman runs down the sidewalk and leaps into the arms of a man, and they embrace. !D\u00b7))", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6a96b6b611a048148a8502d580ec3bd4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad97b0dd4c0e4ffc963c6f101c173715", "source": "vatex", "video_id": "7MyTgwfQ7IU_000032_000042", "video_description": "A person in a robot costume is performing a robot dance in a warehouse or factory setting.", "task": "ActionRecognition", "clean_prompt": "A person in a robot costume is performing a robot dance in a warehouse.", "clean_property": {"obj": "person", "action": "robot dancing", "target": null}, "target_prompt": "A person in a robot costume is performing a robot dance in a futuristic city.", "target_property": {"obj": "person", "action": "robot dancing", "target": "a futuristic city"}, "evaluation_question": "Is the person **dancing in a warehouse**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in a robot costume is performing a robot dance in a warehouse. SL1Y$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8c422aabf42e4bd3b32030013901bbe5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "02a4db19470c4994b4637818d83ef3b2", "source": "vatex", "video_id": "udRzaqScwas_000005_000015", "video_description": "Two women dressed in 1920s flapper outfits perform a dance routine, including the Charleston, in a black painted room.", "task": "Counting", "clean_prompt": "Six dancers performing a dance routine in a black painted room.", "clean_property": {"obj": "dancer", "count": "six"}, "target_prompt": "One dancer performing a solo routine in a brightly lit room.", "target_property": {"obj": "dancer", "count": "one"}, "evaluation_question": "Are there exactly **six** dancers in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six dancers performing a dance routine in a black painted room. U!0=B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d4bea1392c534cb7be7dbdeee8cb2d75.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2babb008d9c641cba18a1ac30e0891e6", "source": "vatex", "video_id": "_9qZTCSg6o4_000000_000010", "video_description": "A little girl is lifting a barbell with light weights in a living room while her father instructs and encourages her.", "task": "Counting", "clean_prompt": "A little girl is lifting two barbells with light weights in a living room while her father instructs and encourages her.", "clean_property": {"obj": "barbell", "count": "two"}, "target_prompt": "A little girl is lifting one barbell with light weights in a living room while her father instructs and encourages her.", "target_property": {"obj": "barbell", "count": "one"}, "evaluation_question": "Are there exactly **two** barbells being lifted by the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A little girl is lifting two barbells with light weights in a living room while her father instructs and encourages her. 0BC2@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1486e5c75d894da9a331bd400be72dc2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6e3764acac614bcb9f9375afbf364384", "source": "vatex", "video_id": "49lGjg-CSNE_000095_000105", "video_description": "A man in a workshop is using various tools to work on metal pieces, including grinding, cutting, and welding, while wearing protective gear.", "task": "SpatialUnderstanding", "clean_prompt": "Sparks closer to the camera than a grinder in a workshop.", "clean_property": {"obj_1": "sparks", "relation": "closer to the camera than", "obj_2": "grinder"}, "target_prompt": "Sparks further from the camera than a grinder in a workshop.", "target_property": {"obj_1": "sparks", "relation": "further from the camera than", "obj_2": "grinder"}, "evaluation_question": "Are the sparks **closer to the camera than** the grinder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Sparks closer to the camera than a grinder in a workshop. FCPV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c5a4abee76bc4145a1a535976dc51df2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "592400da944a43a483d6c46dac5079c3", "source": "vatex", "video_id": "SQv9pldxS-8_000005_000015", "video_description": "A woman is sleeping with her head on a pillow. A man holds her nose closed, causing her to wake up.", "task": "AttributeRecognition", "clean_prompt": "A woman is sleeping with her head on a pillow.", "clean_property": {"obj": "woman", "attribute": "sleeping"}, "target_prompt": "A woman is laughing joyfully.", "target_property": {"obj": "woman", "attribute": "laughing"}, "evaluation_question": "Is the woman **sleeping**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is sleeping with her head on a pillow. DYNXF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2e16b152c94f4f52b504bda4685b5df8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b348fd042c9345cbbb135da46f208bcc", "source": "vatex", "video_id": "krmuNJrZ36A_000000_000010", "video_description": "A large group of people, including men and boys, are participating in a military reenactment on a grassy field. The men are dressed in historic military uniforms and carrying rifles, while the boys are in white shirts carrying sticks. The scene involves preparation and role-playing of a battle.", "task": "SpatialUnderstanding", "clean_prompt": "A rifle positioned to the right of a man in a military uniform.", "clean_property": {"obj_1": "rifle", "relation": "right of", "obj_2": "man"}, "target_prompt": "A sword positioned to the left of a man in a military uniform.", "target_property": {"obj_1": "sword", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the rifle to the **right** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A rifle positioned to the right of a man in a military uniform. UMGL7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e850c790d88f4a0bba9db7c4a2dbdf08.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7a297b814a2b4896973c94e145e13248", "source": "vatex", "video_id": "YtsAKuSraLY_000041_000051", "video_description": "A man is shoveling snow from a deck and porch, occasionally talking about the shovel he is using.", "task": "ActionRecognition", "clean_prompt": "A person shoveling snow from a deck and porch.", "clean_property": {"obj": "person", "action": "shoveling snow", "target": null}, "target_prompt": "A person building a snowman in a snowy yard.", "target_property": {"obj": "person", "action": "building a snowman", "target": null}, "evaluation_question": "Is the person **shoveling snow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shoveling snow from a deck and porch. )!D&:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/12ab5e177ecf41ed93506403f764b90b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d90df70d82ee4f99bb62ea4af88aa1b1", "source": "vatex", "video_id": "eAz-jW31Iq8_000205_000215", "video_description": "A man is demonstrating how to shuffle a deck of cards on a table, occasionally chatting with another man.", "task": "SpatialUnderstanding", "clean_prompt": "A person above a table demonstrating how to shuffle a deck of cards.", "clean_property": {"obj_1": "person", "relation": "above", "obj_2": "table"}, "target_prompt": "A person beside a table demonstrating how to shuffle a deck of cards.", "target_property": {"obj_1": "person", "relation": "beside", "obj_2": "table"}, "evaluation_question": "Is the person **above** the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person above a table demonstrating how to shuffle a deck of cards. -%QP%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cd9dfc1151c4c0b987abcc6cc3b3061.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bb6000b0195d4a4583584ea69a5ffd2c", "source": "vatex", "video_id": "Qd6preKIxgU_000083_000093", "video_description": "A young girl is using a microscope, adjusting it, and explaining the process.", "task": "ObjectRecognition", "clean_prompt": "A young girl is using a microscope, adjusting it, and explaining the process.", "clean_property": {"obj": "microscope"}, "target_prompt": "A young girl is using a telescope, adjusting it, and explaining the process.", "target_property": {"obj": "telescope"}, "evaluation_question": "Is the girl using a **microscope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is using a microscope, adjusting it, and explaining the process. UMPL(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cc6e133c84a646be8c55fa9b86fea7e8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d637a54256e347409f5b8abce21094b2", "source": "vatex", "video_id": "QP3cjM6o6N8_000017_000027", "video_description": "A group of people are practicing field hockey, taking turns shooting balls at a goalie who attempts to block the shots. A coach is present, providing instructions.", "task": "ObjectRecognition", "clean_prompt": "A coach instructing a group of people practicing field hockey.", "clean_property": {"obj": "coach"}, "target_prompt": "A referee overseeing a group of people practicing field hockey.", "target_property": {"obj": "referee"}, "evaluation_question": "Is the person in the video a **coach**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A coach instructing a group of people practicing field hockey. EU7)V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d06c27db4c644c6bab343b2879ace1a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3e93967b2d9b430eb5a14b82f1ad8297", "source": "vatex", "video_id": "gG3wpCeYogQ_000009_000019", "video_description": "A man is sitting at a kitchen table playing a mandolin-like stringed instrument while reading sheet music.", "task": "Counting", "clean_prompt": "A man is sitting at a kitchen table playing a mandolin-like stringed instrument while reading three sheets of music.", "clean_property": {"obj": "sheet music", "count": "three"}, "target_prompt": "A man is sitting at a kitchen table playing a mandolin-like stringed instrument while reading one sheet of music.", "target_property": {"obj": "sheet music", "count": "one"}, "evaluation_question": "Are there exactly **three** sheets of music being read?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is sitting at a kitchen table playing a mandolin-like stringed instrument while reading three sheets of music. MT\u00b7OU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a44666631a9446b599f6e6de84de5967.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fae44aeb145f4e508a7338e7e81af3cf", "source": "vatex", "video_id": "cMzZorMsRdY_000000_000010", "video_description": "A young girl is repeatedly licking a red lollipop and smiling, while other people are talking in the background.", "task": "ActionRecognition", "clean_prompt": "A girl sucking a lollipop and smiling.", "clean_property": {"obj": "girl", "action": "sucking lolly", "target": "lollipop"}, "target_prompt": "A girl throwing a lollipop and smiling.", "target_property": {"obj": "girl", "action": "throwing lollipop", "target": "lollipop"}, "evaluation_question": "Is the girl **sucking** a lollipop?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl sucking a lollipop and smiling. ))/!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/589d16cfcb5d43a287f201c1e3336ccd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac1df1db5e814227a36b3a52e3091f35", "source": "vatex", "video_id": "1tQ7dY4K_zk_000106_000116", "video_description": "A man in a button-down shirt uses a red cloth to clean his face and blow his nose.", "task": "AttributeRecognition", "clean_prompt": "A man using a red cloth to clean his face and blow his nose.", "clean_property": {"obj": "cloth", "attribute": "red"}, "target_prompt": "A man using a blue cloth to clean his face and blow his nose.", "target_property": {"obj": "cloth", "attribute": "blue"}, "evaluation_question": "Is the cloth being used by the man **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a red cloth to clean his face and blow his nose. &|&XN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/561ca57e8b864b2b8a22e3b1adbcc73c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3b9a094c00914dba9c41601a0c619033", "source": "vatex", "video_id": "iJT_k-VD08k_000010_000020", "video_description": "A man in a yellow vest demonstrates how to make a sling for another man's arm using a piece of cloth. The second man is seated in a chair while the first man practices bandaging skills.", "task": "ObjectRecognition", "clean_prompt": "A man in a yellow vest demonstrates how to make a sling for another man's arm using a piece of cloth.", "clean_property": {"obj": "person_1"}, "target_prompt": "A woman in a red vest demonstrates how to make a sling for another person's arm using a piece of cloth.", "target_property": {"obj": "woman_1"}, "evaluation_question": "Is the demonstrator in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a yellow vest demonstrates how to make a sling for another man's arm using a piece of cloth. 3MVAM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/398ba9f057e6484ea8e82a99e0cf6f0b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e02b59411bc64b9c8538cd5e71bc2f12", "source": "vatex", "video_id": "RIz7nXX6RpI_000081_000091", "video_description": "A group of people are inside an airplane, preparing to skydive.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of an airplane.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "airplane"}, "target_prompt": "A person standing to the left of an airplane.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "airplane"}, "evaluation_question": "Is the person to the **right** of the airplane?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of an airplane. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1767bc5c06584784b16892844ee7d6bf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0500b158d6604a4dad0a0d34320e4df0", "source": "vatex", "video_id": "KoY-HBCL_wg_000278_000288", "video_description": "A woman is demonstrating how to make balloon animals using a long pink balloon.", "task": "ActionRecognition", "clean_prompt": "A person tying a knot on a long pink balloon.", "clean_property": {"obj": "person", "action": "tying knot (not on a tie)", "target": "balloon"}, "target_prompt": "A person tying a knot on a gift box.", "target_property": {"obj": "person", "action": "tying knot (not on a tie)", "target": "gift box"}, "evaluation_question": "Is the person **tying a knot on a balloon**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tying a knot on a long pink balloon. )&&&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/185813d02aa54a948eb32a718516d837.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "21b7ffd2c4d6431c85cac6e9cae3122f", "source": "vatex", "video_id": "1olz6MxMmEc_000043_000053", "video_description": "A man is lying in a muddy area, stands up, and walks towards the camera, adjusting it.", "task": "Counting", "clean_prompt": "Two men are lying in a muddy area, then they stand up and walk towards the camera, adjusting it.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "A man is lying in a muddy area, then he stands up and walks towards the camera, adjusting it.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men in the muddy area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are lying in a muddy area, then they stand up and walk towards the camera, adjusting it. U=H!U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c68f57a66de343ffb2a155d65d991185.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bccb1a03391e40ba93eef41318afe3be", "source": "vatex", "video_id": "79McozJ3Gos_000008_000018", "video_description": "A race event is taking place on a dirt track with various vehicles including four-wheelers, go-karts, and motorcycles. An announcer is describing the action while spectators watch.", "task": "AttributeRecognition", "clean_prompt": "A go-kart racing on a dirt track during a race event.", "clean_property": {"obj": "vehicle", "attribute": "go-kart"}, "target_prompt": "A motorcycle racing on a dirt track during a race event.", "target_property": {"obj": "vehicle", "attribute": "motorcycle"}, "evaluation_question": "Is the vehicle a **go-kart**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A go-kart racing on a dirt track during a race event. EV#XM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f6a3640681344ffb240ca47c076a162.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad70b7156c864d2190f5ef74a84fbcf7", "source": "vatex", "video_id": "0lg0_CVvLGU_000010_000020", "video_description": "A large group of people are snowboarding down a snowy slope at night, with one man falling down during the activity.", "task": "ActionRecognition", "clean_prompt": "A snowboarder snowboarding down a snowy slope at night.", "clean_property": {"obj": "snowboarder", "action": "snowboarding", "target": null}, "target_prompt": "A snowboarder falling down on a snowy slope at night.", "target_property": {"obj": "snowboarder", "action": "falling", "target": null}, "evaluation_question": "Is the snowboarder **snowboarding**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A snowboarder snowboarding down a snowy slope at night. RL)#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/38da5a48bbdb4fec956588bf1220ba57.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e651d11d8f34b6c9ec6aee8aace376b", "source": "vatex", "video_id": "48gF4_ZaHYU_000000_000010", "video_description": "A baby is crawling on the floor towards a colorful soccer ball.", "task": "AttributeRecognition", "clean_prompt": "A baby crawling on the floor towards a colorful soccer ball.", "clean_property": {"obj": "ball", "attribute": "colorful"}, "target_prompt": "A baby crawling on the floor towards a monochrome soccer ball.", "target_property": {"obj": "ball", "attribute": "monochrome"}, "evaluation_question": "Is the soccer ball **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby crawling on the floor towards a colorful soccer ball. NV+;?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/73f1c6e7859e4b13bbd1974c9a56460e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d07b0a37342e4200bbf82c02b424ed0a", "source": "vatex", "video_id": "lh6UOcm7Mak_000010_000020", "video_description": "A young boy is performing somersaults and cartwheels in a living room in front of a TV, and gives a thumbs up after completing the moves.", "task": "ActionRecognition", "clean_prompt": "A boy somersaulting in a living room.", "clean_property": {"obj": "boy", "action": "somersaulting", "target": null}, "target_prompt": "A boy jumping in a living room.", "target_property": {"obj": "boy", "action": "jumping", "target": null}, "evaluation_question": "Is the boy **somersaulting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy somersaulting in a living room. ))!0&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1242355ceaca496caa76713560c457bf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dffd6da494504c988bd1d6a65215cb07", "source": "vatex", "video_id": "7cz4ipaR5nA_000393_000403", "video_description": "A man and a woman are outside arranging and transplanting various colorful flowers into pots, discussing color themes and giving a demonstration.", "task": "AttributeRecognition", "clean_prompt": "A man and a woman outside arranging and transplanting various colorful flowers into pots.", "clean_property": {"obj": "flower", "attribute": "various colors"}, "target_prompt": "A man and a woman outside arranging and transplanting monochrome flowers into pots.", "target_property": {"obj": "flower", "attribute": "monochrome"}, "evaluation_question": "Are the flowers being arranged and transplanted in **various colors**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman outside arranging and transplanting various colorful flowers into pots. )\u00b7U%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7cb121fd56c94aaaad0632568fe90500.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e7976e16c26041f89aa518b66605a788", "source": "vatex", "video_id": "pB9p3f25RpA_000000_000010", "video_description": "A man in a hooded jacket is spray painting graffiti on a wall in a tunnel. He takes out a can of red spray paint from his backpack and begins to paint. The area is under a bridge with garbage in a muddy puddle on the ground.", "task": "ActionRecognition", "clean_prompt": "A person spray painting graffiti on a wall in a tunnel.", "clean_property": {"obj": "person", "action": "spray painting", "target": "wall"}, "target_prompt": "A person cleaning a wall in a tunnel.", "target_property": {"obj": "person", "action": "cleaning", "target": "wall"}, "evaluation_question": "Is the person **spray painting** on the wall?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person spray painting graffiti on a wall in a tunnel. ))!0!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/324235b40d9546b999f955ba5c04cf6d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "157d3b9b12b64524a4c4d4798aa253ba", "source": "vatex", "video_id": "kBAI99LSGh4_000002_000012", "video_description": "Two men in yellow shirts and black shorts are demonstrating soccer techniques on a field in front of an audience, including children.", "task": "Counting", "clean_prompt": "Three children in the audience watching two men in yellow shirts and black shorts demonstrating soccer techniques on a field.", "clean_property": {"obj": "audience", "count": "three"}, "target_prompt": "Five children in the audience watching two men in yellow shirts and black shorts demonstrating soccer techniques on a field.", "target_property": {"obj": "audience", "count": "five"}, "evaluation_question": "Are there exactly **three** children in the audience?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children in the audience watching two men in yellow shirts and black shorts demonstrating soccer techniques on a field. LY1(J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1bfc9cd6e4434c5e80491d7ed69e410a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cd7342234a504ade9f79f2bd83bf5d31", "source": "vatex", "video_id": "7VUQg_VVUgQ_000004_000014", "video_description": "Two women are riding horses along a narrow, rocky dirt path. One woman waves while riding, and they are having a great time.", "task": "Counting", "clean_prompt": "Six women riding horses along a narrow, rocky dirt path, with one woman waving and all having a great time.", "clean_property": {"obj": "woman", "count": "six"}, "target_prompt": "Three women riding bicycles along a narrow, rocky dirt path, with one woman waving and all having a great time.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** women riding horses along the path?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six women riding horses along a narrow, rocky dirt path, with one woman waving and all having a great time. $FOE\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c89d6cf72c54b35a114e157fbdce78b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb66a93191404528ad6b40516fb6f10b", "source": "vatex", "video_id": "EAaP5vjgg0U_000033_000043", "video_description": "A young boy is playing with a toy train and a snake-like toy on the floor of a bedroom.", "task": "AttributeRecognition", "clean_prompt": "A young boy is playing with a toy train, Thomas The Tank Engine, and a snake-like toy on the floor of a bedroom.", "clean_property": {"obj": "train", "attribute": "Thomas The Tank Engine"}, "target_prompt": "A young boy is playing with a futuristic spaceship and a snake-like toy on the floor of a bedroom.", "target_property": {"obj": "train", "attribute": "a futuristic spaceship"}, "evaluation_question": "Is the boy playing with **Thomas The Tank Engine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is playing with a toy train, Thomas The Tank Engine, and a snake-like toy on the floor of a bedroom. TS0R\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/209f65b4a9f14d439891068a39bde5a9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e3939d9228445c9b1541a6a93c8d35a", "source": "vatex", "video_id": "0DUtghm2U34_000106_000116", "video_description": "A large man in a red shirt is eating powdered donuts messily, with powdered sugar around his mouth, and sucking the powder off his thumb while holding a box.", "task": "AttributeRecognition", "clean_prompt": "A person with a large build in a red shirt eating powdered donuts messily.", "clean_property": {"obj": "person", "attribute": "large"}, "target_prompt": "A person with a small build eating powdered donuts messily.", "target_property": {"obj": "person", "attribute": "small"}, "evaluation_question": "Is the person described as **large**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with a large build in a red shirt eating powdered donuts messily. YKDZV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac564a3aa2a247e690f7afbff2f5d851.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "625cbb3109e04dd49cd6f7dadf35f3b5", "source": "vatex", "video_id": "qBr-NyZ3-OU_000166_000176", "video_description": "A person is painting an abstract outdoor scene on a canvas using a palette of paints, primarily yellow, with a brush and occasionally using their fingers.", "task": "Counting", "clean_prompt": "A person is painting an abstract outdoor scene on a canvas using three brushes and a palette of paints, primarily yellow, with their fingers.", "clean_property": {"obj": "brush", "count": "three"}, "target_prompt": "A person is painting an abstract outdoor scene on a canvas using one brush and a palette of paints, primarily yellow, with their fingers.", "target_property": {"obj": "brush", "count": "one"}, "evaluation_question": "Are there exactly **three** brushes being used in the painting?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is painting an abstract outdoor scene on a canvas using three brushes and a palette of paints, primarily yellow, with their fingers. >@(XF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8ca651b8bf2d409c8d03e81cc2228293.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c7cbf4b6e3540ee94f6a0d6485e3ff8", "source": "vatex", "video_id": "hahlep725ig_000025_000035", "video_description": "A man is demonstrating how to fill glass bottles with beer using a hose and a machine, and discussing the capping process. The bottles are placed in green crates.", "task": "ActionRecognition", "clean_prompt": "A person pouring beer from a hose into glass bottles placed in green crates.", "clean_property": {"obj": "person", "action": "pouring beer", "target": "bottle"}, "target_prompt": "A person sipping beer from a glass.", "target_property": {"obj": "person", "action": "sipping beer", "target": "glass"}, "evaluation_question": "Is the person **pouring** beer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person pouring beer from a hose into glass bottles placed in green crates. )!0CB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8ffd63ad7dbb452ab39dc4047a4c33e4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "474f27d77a5841429a2dcf6566526688", "source": "vatex", "video_id": "VGeZLZJdxBg_000022_000032", "video_description": "A group of people, including women, are stomping grapes with their bare feet in barrels and buckets during a local event with live music.", "task": "ObjectRecognition", "clean_prompt": "A group of people stomping grapes in barrels during a local event with live music.", "clean_property": {"obj": "barrel"}, "target_prompt": "A group of people stomping grapes in buckets during a local event with live music.", "target_property": {"obj": "bucket"}, "evaluation_question": "Are the people stomping grapes in **barrels**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people stomping grapes in barrels during a local event with live music. TZFES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ae82be4023b4f02a1be30d4797cdeca.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d66291444864d6183bde87aa327c568", "source": "vatex", "video_id": "Y8Ac0C4Gfu0_000100_000110", "video_description": "A young woman is demonstrating and explaining how to play golf, including chipping and putting a golf ball on a golf course.", "task": "SpatialUnderstanding", "clean_prompt": "A golf ball closer to the camera than a person on a golf course.", "clean_property": {"obj_1": "golf ball", "relation": "closer to the camera than", "obj_2": "person"}, "target_prompt": "A golf ball further from the camera than a person on a golf course.", "target_property": {"obj_1": "golf ball", "relation": "further from the camera than", "obj_2": "person"}, "evaluation_question": "Is the golf ball **closer to the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A golf ball closer to the camera than a person on a golf course. )!G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3237727ecbd64580b9e4165dba72820d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "27d7697aeb9b48bab3f4a6f0c63e4902", "source": "vatex", "video_id": "Y2Y8uhqwBUs_000015_000025", "video_description": "A man is unboxing a package wrapped in plastic, showing its contents to the camera.", "task": "ObjectRecognition", "clean_prompt": "A man unboxing a package wrapped in plastic, showing its contents to the camera.", "clean_property": {"obj": "package"}, "target_prompt": "A man unboxing a gift wrapped in colorful paper, showing its contents to the camera.", "target_property": {"obj": "gift"}, "evaluation_question": "Is the object being unboxed a **package**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man unboxing a package wrapped in plastic, showing its contents to the camera. NKF$F", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b2ce9f0977a84f87bb9c6a74ea68e4d2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce9018d290bf41c0b91202f1154a223d", "source": "vatex", "video_id": "eOW7A8Lg0T4_000111_000121", "video_description": "A man and a woman are in an arena practicing bullfighting techniques with a young bull using red capes.", "task": "ActionRecognition", "clean_prompt": "A person practicing bull fighting techniques in an arena with a young bull.", "clean_property": {"obj": "person", "action": "bull fighting", "target": "bull"}, "target_prompt": "A person running away from a bull in an arena.", "target_property": {"obj": "person", "action": "running away from", "target": "bull"}, "evaluation_question": "Is the person **bull fighting**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing bull fighting techniques in an arena with a young bull. ;J#;S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3fc265b2fb43415da3b0d91fb35428a5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4dcf7f3bf4ea483ab4aeeb755835487d", "source": "vatex", "video_id": "FLhNVUgSHNQ_000031_000041", "video_description": "A young man is riding a skateboard down a road, performing tricks and adjusting his hat.", "task": "ObjectRecognition", "clean_prompt": "A young man riding a skateboard down a road, performing tricks and adjusting his hat.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running down a road, playing with a ball and wagging its tail.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man riding a skateboard down a road, performing tricks and adjusting his hat. WZH%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/40b68e5bbf624995b31a2a0a0fa6ba58.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "17ebee72085041bf90dce7dba24887ce", "source": "vatex", "video_id": "4QM_nO2YWCo_000073_000083", "video_description": "Two young boys are playing with toy laser guns in a house, engaging in a game that involves shooting each other. The toys light up and make noise. The setting includes a living room and a staircase.", "task": "ObjectRecognition", "clean_prompt": "Two young boys are playing with toy laser guns in a house, engaging in a game that involves shooting each other.", "clean_property": {"obj": "toy gun"}, "target_prompt": "Two young boys are playing with toy swords in a house, engaging in a game that involves fighting each other.", "target_property": {"obj": "toy sword"}, "evaluation_question": "Are the boys playing with **toy laser guns**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys are playing with toy laser guns in a house, engaging in a game that involves shooting each other. Z@VRN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b7c0b272b0d4602bf2c7ed81eccfb90.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2f0b3f440404887b4958bda92bb60f3", "source": "vatex", "video_id": "FpkEF-Wrc0g_000004_000014", "video_description": "A class of young ballerinas, led by an instructor, practice ballet in a circle while wearing tutus.", "task": "SpatialUnderstanding", "clean_prompt": "A ballerina standing to the left of an instructor.", "clean_property": {"obj_1": "ballerina", "relation": "left of", "obj_2": "instructor"}, "target_prompt": "A ballerina standing to the right of an instructor.", "target_property": {"obj_1": "ballerina", "relation": "right of", "obj_2": "instructor"}, "evaluation_question": "Is the ballerina to the **left** of the instructor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A ballerina standing to the left of an instructor. )BSS9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fbf75ccebaa489bba7e13926380cac0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "059dd00736c8481ab4d5af3ea3ddc066", "source": "vatex", "video_id": "l6YSTcfgEw8_000027_000037", "video_description": "A man wearing a hat is walking around his house, looking in every room, and eventually squats down in front of a dresser.", "task": "SpatialUnderstanding", "clean_prompt": "A man standing to the left of a dresser.", "clean_property": {"obj_1": "dresser", "relation": "left of", "obj_2": "man"}, "target_prompt": "A man standing to the right of a dresser.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "dresser"}, "evaluation_question": "Is the man to the **left** of the dresser?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man standing to the left of a dresser. FE\u00b7.E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/483465c02fe74c5f87d1c237c04a99a5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3bd78ec25c0b4018bd306a5ca0915ec5", "source": "vatex", "video_id": "i--HTK1hiBs_000008_000018", "video_description": "A man, possibly a chef, is demonstrating and instructing on the proper technique to slice a piece of steak against the grain using a large knife on a cutting board.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to slice steak against the grain on a cutting board.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to slice steak against the grain on a cutting board.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to slice steak against the grain on a cutting board. ))!0*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6086aefc903445d5b094771813520803.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7dd0c7fa7d643659d801648af167741", "source": "vatex", "video_id": "5b3B-tuyYiA_000070_000080", "video_description": "A heavyset, bearded man, who appears slightly drunk, is having his chest hair removed using clear tape in a lively environment where people are talking loudly.", "task": "ActionRecognition", "clean_prompt": "A man waxing his chest in a lively environment.", "clean_property": {"obj": "man", "action": "waxing chest", "target": null}, "target_prompt": "A man shaving his chest in a quiet environment.", "target_property": {"obj": "man", "action": "shaving chest", "target": null}, "evaluation_question": "Is the man **waxing** his chest?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man waxing his chest in a lively environment. ))!%/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f236dd40168e455e961c2e2679c5fd01.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "49bfe2f1c53c496985de66d72a9e6ade", "source": "vatex", "video_id": "dYEPXMdxGVU_000015_000025", "video_description": "A group of women and other people are playing a game of kickball in a park on a grassy field.", "task": "Counting", "clean_prompt": "Three women playing kickball in a park on a grassy field.", "clean_property": {"obj": "ball", "count": "three"}, "target_prompt": "One woman playing kickball in a park on a sandy beach.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **three** women playing kickball in the park?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women playing kickball in a park on a grassy field. >;J)X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1b68e3e1ae3a44d28c1ff084aa050677.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3153b91b171c41bda85afb5202d55385", "source": "vatex", "video_id": "6LRgQW0n2LA_000065_000075", "video_description": "A person is carving letters into a wooden board using precision tools, while an announcer describes the process.", "task": "Counting", "clean_prompt": "A person is carving letters into a wooden board with seven precision tools, while an announcer describes the process.", "clean_property": {"obj": "wooden board", "count": "seven"}, "target_prompt": "A person is carving letters into a wooden board with three precision tools, while an announcer describes the process.", "target_property": {"obj": "wooden board", "count": "three"}, "evaluation_question": "Are there exactly **seven** precision tools being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is carving letters into a wooden board with seven precision tools, while an announcer describes the process. FE|)L", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/30cc54e554b941a680e31b5da4e4dd6a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ff1f9d935dc2440bb04f263b18e489e7", "source": "vatex", "video_id": "VjKnZ1LlubE_000065_000075", "video_description": "A group of dancers, both male and female, perform an artistic dance on a stage. They are dressed in white and dance in sync to classical music under a spotlight in a dimly lit room.", "task": "ObjectRecognition", "clean_prompt": "A group of dancers performing an artistic dance on a stage under a spotlight.", "clean_property": {"obj": "stage"}, "target_prompt": "A cat playing on a stage under a spotlight.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the performance on the stage by a group of **dancers**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of dancers performing an artistic dance on a stage under a spotlight. !0K0U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7f6b0fa3053143589f00977cd18af3c2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "204792ad656b4dfc9ea1e4ed638a7e9c", "source": "vatex", "video_id": "wsR8fc9pBR4_000007_000017", "video_description": "A person is preparing to roast a marshmallow by placing it on a stick and holding it over coals outdoors.", "task": "ActionRecognition", "clean_prompt": "A person roasting marshmallows over coals outdoors.", "clean_property": {"obj": "person", "action": "roasting marshmallows", "target": null}, "target_prompt": "A person eating marshmallows outdoors.", "target_property": {"obj": "person", "action": "eating marshmallows", "target": null}, "evaluation_question": "Is the person **roasting** marshmallows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person roasting marshmallows over coals outdoors. SL)IV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6812f07506b2424298d962b9e0722a2a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2d9a2bbeb0214cd39c1b1e48469aaa1e", "source": "vatex", "video_id": "S72BJD-UxP8_000075_000085", "video_description": "A person is creating art by burning designs into a large piece of wood using controlled fire and electricity.", "task": "AttributeRecognition", "clean_prompt": "A person creating art by burning designs into wood using controlled fire.", "clean_property": {"obj": "fire", "attribute": "controlled"}, "target_prompt": "A person creating art by burning designs into wood using uncontrolled fire.", "target_property": {"obj": "fire", "attribute": "uncontrolled"}, "evaluation_question": "Is the fire being used **controlled**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person creating art by burning designs into wood using controlled fire. NK@)Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/679557d3f4a3444ea1a0507b05843413.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "565e27dccc414dd78126e25967719969", "source": "vatex", "video_id": "qbHfTvZWlrA_000093_000103", "video_description": "A person is attempting to split a green apple open by repeatedly striking it with their hand on a paved surface.", "task": "AttributeRecognition", "clean_prompt": "A person attempting to split a green apple open by striking it with their hand on a paved surface.", "clean_property": {"obj": "apple", "attribute": "green"}, "target_prompt": "A person attempting to split a red apple open by striking it with their hand on a paved surface.", "target_property": {"obj": "apple", "attribute": "red"}, "evaluation_question": "Is the apple **green**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person attempting to split a green apple open by striking it with their hand on a paved surface. =TZCJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb35efb4ad4d4fbcb1cec200cb0c4448.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9abcdc854f0e4f438bf6065f4ec63a14", "source": "vatex", "video_id": "9vttVIYnQpQ_000000_000010", "video_description": "A woman is grooming a small dog using an electric razor on a kitchen counter with music playing in the background.", "task": "ActionRecognition", "clean_prompt": "A woman trimming a dog's beard on a kitchen counter.", "clean_property": {"obj": "woman", "action": "trimming or shaving beard", "target": "dog"}, "target_prompt": "A woman washing a dog on a kitchen counter.", "target_property": {"obj": "woman", "action": "washing dog", "target": "dog"}, "evaluation_question": "Is the woman **trimming** the dog's beard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman trimming a dog's beard on a kitchen counter. X2-GG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42348d5f47db4395a242acd6b355fcaa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "be383bcbbc8d4ae0bdd8f357a22d59eb", "source": "vatex", "video_id": "hLMg94-5BNQ_000006_000016", "video_description": "A young boy is in a living room, using a camera to record himself and the television. He watches a kids show on TV, occasionally talking and interacting with the camera.", "task": "AttributeRecognition", "clean_prompt": "A television showing a kids show in a living room.", "clean_property": {"obj": "television", "attribute": "showing kids show"}, "target_prompt": "A television showing a documentary in a living room.", "target_property": {"obj": "television", "attribute": "showing a documentary"}, "evaluation_question": "Is the television showing a **kids show**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A television showing a kids show in a living room. RP%QX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9115d95a8d545fdbd76a88ed02ad617.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "02420d49032a4827972283f0badfb038", "source": "vatex", "video_id": "IhLf4VqGmvw_000003_000013", "video_description": "A group of people, including children, are on a beach collecting live fish that have washed up on the shore and placing them into containers.", "task": "AttributeRecognition", "clean_prompt": "A group of people collecting live fish on a beach.", "clean_property": {"obj": "fish", "attribute": "live"}, "target_prompt": "A group of people collecting dead fish on a beach.", "target_property": {"obj": "fish", "attribute": "dead"}, "evaluation_question": "Are the fish being collected **live**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people collecting live fish on a beach. FE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e312a028880b4c9199a9ddf7928991f1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "494d5a729e134c65ae91c2968a81993e", "source": "vatex", "video_id": "t6BDCkIHqzQ_000014_000024", "video_description": "A skier is skiing downhill on a snowy mountain, maneuvering between green and yellow flags at high speed.", "task": "ObjectRecognition", "clean_prompt": "A skier skiing downhill on a snowy mountain, using ski poles to maneuver between green and yellow flags at high speed.", "clean_property": {"obj": "ski poles"}, "target_prompt": "A snowboarder snowboarding downhill on a snowy mountain, maneuvering between green and yellow flags at high speed.", "target_property": {"obj": "snowboard"}, "evaluation_question": "Is the skier in the video using **ski poles**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skier skiing downhill on a snowy mountain, using ski poles to maneuver between green and yellow flags at high speed. FEYO|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bb5db58b40304484bc932ecc909ff2b4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2a275359541410fbd17e182831b98fc", "source": "vatex", "video_id": "nTI5QpazQlo_000020_000030", "video_description": "A man is in a kitchen demonstrating and using an electric pencil sharpener to sharpen pencils.", "task": "AttributeRecognition", "clean_prompt": "A man in a kitchen demonstrating and using an electric pencil sharpener to sharpen pencils.", "clean_property": {"obj": "pencil sharpener", "attribute": "electric"}, "target_prompt": "A man in a kitchen demonstrating and using a manual pencil sharpener to sharpen pencils.", "target_property": {"obj": "pencil sharpener", "attribute": "manual"}, "evaluation_question": "Is the pencil sharpener **electric**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a kitchen demonstrating and using an electric pencil sharpener to sharpen pencils. !1U%U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bed76b79794f47439752251e085cb4f1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1db0768dc92549f9919a2123f7130537", "source": "vatex", "video_id": "y8Jm7bfTM5g_000007_000017", "video_description": "A man is feeding a group of large birds, including pelicans, on a beach using food from a bag. A woman is filming and talking excitedly.", "task": "Counting", "clean_prompt": "A woman is filming five large birds being fed on a beach.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "A woman is filming two large birds being fed on a beach.", "target_property": {"obj": "woman", "count": "two"}, "evaluation_question": "Are there exactly **five** women filming on the beach?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is filming five large birds being fed on a beach. ELLG>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1e8026482cfc4d2f891fed7dfcc51b65.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "004e2aae490c443aa0a90e985a1a09d2", "source": "vatex", "video_id": "6Z2BB-P41Mw_000085_000095", "video_description": "A little girl is in a room with a little boy, upset and yelling because she was called a loser by the boy. They are having a conversation at home.", "task": "SpatialUnderstanding", "clean_prompt": "A boy standing to the right of a girl in a room, having a conversation.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "girl"}, "target_prompt": "A boy standing to the left of a girl in a room, having a conversation.", "target_property": {"obj_1": "boy", "relation": "left of", "obj_2": "girl"}, "evaluation_question": "Is the boy to the **right** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy standing to the right of a girl in a room, having a conversation. ?+.FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5adf33ea0b5e4ca0857e6db5c4ddf5bd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5e09a279b67e4648b32af74827c7b70f", "source": "vatex", "video_id": "y8Jm7bfTM5g_000007_000017", "video_description": "A man is feeding a group of large birds, including pelicans, on a beach using food from a bag. A woman is filming and talking excitedly.", "task": "AttributeRecognition", "clean_prompt": "A man wearing a charcoal jacket is feeding a group of large birds on a beach.", "clean_property": {"obj": "man", "attribute": "wearing a charcoal jacket"}, "target_prompt": "A man wearing a bright yellow raincoat is feeding a group of large birds on a beach.", "target_property": {"obj": "man", "attribute": "wearing a bright yellow raincoat"}, "evaluation_question": "Is the man wearing a **charcoal** jacket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing a charcoal jacket is feeding a group of large birds on a beach. ))GFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/15b081502a48453295929019dd46d8c6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "485465a46c4b466db1c37c14c8b87191", "source": "vatex", "video_id": "qndaTp5y_a0_000115_000125", "video_description": "A woman is running down a snowy path, timing herself with a digital watch.", "task": "Counting", "clean_prompt": "A woman is running down a snowy path, timing herself with two digital watches.", "clean_property": {"obj": "watch", "count": "two"}, "target_prompt": "A woman is running down a snowy path, timing herself with one digital watch.", "target_property": {"obj": "watch", "count": "one"}, "evaluation_question": "Are there exactly **two** digital watches being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is running down a snowy path, timing herself with two digital watches. =J?RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/044d65eff6424b54a43f8363efb28aae.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "efaeec9324ff432c812bbf272e93683b", "source": "vatex", "video_id": "e5qBwONhahU_000000_000010", "video_description": "A young man is riding a skateboard down a city sidewalk. Another young man appears and looks at the camera.", "task": "Counting", "clean_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background.", "clean_property": {"obj": "branch", "count": "three"}, "target_prompt": "A young man is riding a skateboard down a city sidewalk with one branch in the background.", "target_property": {"obj": "branch", "count": "one"}, "evaluation_question": "Are there exactly **three** branches in the background?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is riding a skateboard down a city sidewalk with three branches in the background. M9L*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2dcc50f6b61841acbc043f2c1c753305.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "07edb4e7b7f14ff0aee453f86fab1b94", "source": "vatex", "video_id": "Sd8kFKTS_44_000110_000120", "video_description": "A man is in a gym demonstrating and performing lunges while holding weights in each hand.", "task": "AttributeRecognition", "clean_prompt": "A man demonstrating lunges while holding dumbbells in each hand.", "clean_property": {"obj": "weights", "attribute": "dumbbells"}, "target_prompt": "A man demonstrating lunges while holding kettlebells in each hand.", "target_property": {"obj": "weights", "attribute": "kettlebells"}, "evaluation_question": "Is the man holding **dumbbells** while demonstrating lunges?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating lunges while holding dumbbells in each hand. )?W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8f3d66f3cae9422485ebe9a35f5fba80.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f2af571df1eb4bdc9385a7df65834ce8", "source": "vatex", "video_id": "SBOx3KAoAcQ_000004_000014", "video_description": "People, including men and boys, are performing flips, jumps, and other tricks on trampolines in a trampoline park with music playing.", "task": "ActionRecognition", "clean_prompt": "A person performing a backflip in a trampoline park.", "clean_property": {"obj": "person", "action": "backflip (human)", "target": null}, "target_prompt": "A person performing a frontflip in a trampoline park.", "target_property": {"obj": "person", "action": "frontflip (human)", "target": null}, "evaluation_question": "Is the person **performing a backflip**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person performing a backflip in a trampoline park. =P%BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76dadfb893bc4c22a4fbf27907471450.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd5537e4d231481e8614e9f2d9e40adb", "source": "vatex", "video_id": "CEUpjs4NWBc_000045_000055", "video_description": "A woman is giving a massage to a client, focusing on the neck and back, while discussing the use of massage oils and tonics.", "task": "Counting", "clean_prompt": "Four women giving massages to clients, focusing on their necks and backs, while discussing the use of massage oils and tonics.", "clean_property": {"obj": "woman", "count": "four"}, "target_prompt": "One woman giving a massage to a client, focusing on the neck and back, while discussing the use of massage oils and tonics.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **four** women giving massages?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four women giving massages to clients, focusing on their necks and backs, while discussing the use of massage oils and tonics. NP*9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7ce1a6ab4fcc4f159787fe15f654cb02.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81707d95024846e3837328b830b19791", "source": "vatex", "video_id": "3Wf8IbO8Hwk_000017_000027", "video_description": "A person is petting and playing with a very young brown and white puppy, focusing on stroking its nose.", "task": "Counting", "clean_prompt": "Four people are petting and playing with a very young brown and white puppy, focusing on stroking its nose.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is petting and playing with a very young brown and white puppy, focusing on stroking its nose.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people playing with the puppy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are petting and playing with a very young brown and white puppy, focusing on stroking its nose. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de9de945d4504a85a1828940959e2020.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d1e8dca083334bd9822c0c970558ede6", "source": "vatex", "video_id": "7rPXR4duVqE_000000_000010", "video_description": "A bald man stands on a porch, drinks alcohol from a bottle, and spits it towards a lit lighter, creating a large flame.", "task": "AttributeRecognition", "clean_prompt": "A bald man on a porch drinking from a bottle that contains Bacardi 151.", "clean_property": {"obj": "bottle", "attribute": "contains Bacardi 151"}, "target_prompt": "A bald man on a porch drinking from a bottle that contains water.", "target_property": {"obj": "bottle", "attribute": "contains water"}, "evaluation_question": "Is the bottle containing **Bacardi 151**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A bald man on a porch drinking from a bottle that contains Bacardi 151. =S7BB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9641dae92b3441fbbd8ae8767f858b46.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "22e1568e9d9d4127afc9c176e5ccd4b2", "source": "vatex", "video_id": "p-IeEYYy6qQ_000004_000014", "video_description": "A little boy is holding onto a couch, shaking his head 'no' while a woman talks to him.", "task": "ObjectRecognition", "clean_prompt": "A woman is talking to a little boy who is shaking his head 'no' while holding onto a couch.", "clean_property": {"obj": "woman"}, "target_prompt": "A man is talking to a little boy who is shaking his head 'no' while holding onto a couch.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person talking to the little boy a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is talking to a little boy who is shaking his head 'no' while holding onto a couch. >BC3M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8132ce93e01b4154afc6d7f77e1e5f5d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8deb7a17c6e64a0bb836e775430c8dc1", "source": "vatex", "video_id": "70vgdqht6JU_000000_000010", "video_description": "A man is performing arm exercises with small dumbbells in his living room.", "task": "Counting", "clean_prompt": "Four people performing arm exercises with small dumbbells in a living room.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person performing arm exercises with small dumbbells in a living room.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people performing exercises in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people performing arm exercises with small dumbbells in a living room. !WB*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/74e5ab1db3f24bafa530141f2e519522.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d2e84ef9f70b4ae0ae12f89a6752ce50", "source": "vatex", "video_id": "BFfOzTssqX4_000000_000010", "video_description": "A young girl is in her bedroom, facing the camera, talking and eating a powdered donut.", "task": "ActionRecognition", "clean_prompt": "A girl eating a powdered donut in her bedroom.", "clean_property": {"obj": "girl", "action": "eating doughnuts", "target": "donut"}, "target_prompt": "A girl playing with a toy in her bedroom.", "target_property": {"obj": "girl", "action": "playing with toys", "target": "toy"}, "evaluation_question": "Is the girl **eating** a donut?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl eating a powdered donut in her bedroom. 0TXBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c78d4a5cf964a39b0e8d286abdea144.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "72cfcdca1e834baf87a55ef97216c408", "source": "vatex", "video_id": "aCSZ3XChrh4_000006_000016", "video_description": "A child is sitting in a salon chair, leaning back with their head over a sink, while a woman washes their hair using shampoo.", "task": "ObjectRecognition", "clean_prompt": "A child is sitting in a salon chair, leaning back with their head over a sink, while a woman washes their hair using shampoo.", "clean_property": {"obj": "sink"}, "target_prompt": "A child is sitting in a bathtub while a woman washes their hair using shampoo.", "target_property": {"obj": "bathtub"}, "evaluation_question": "Is the child leaning over a **sink**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is sitting in a salon chair, leaning back with their head over a sink, while a woman washes their hair using shampoo. MJWS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7b68ab1dac7240f782d7795fa40233d1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4b703b894e87456c868aa7dc04e5c4e4", "source": "vatex", "video_id": "XcUdqUv6rss_000000_000010", "video_description": "A young man is practicing field goal kicking on a football field, aiming to kick the ball between the uprights and into the net.", "task": "SpatialUnderstanding", "clean_prompt": "A net positioned to the left of a goal post on a football field.", "clean_property": {"obj_1": "net", "relation": "left of", "obj_2": "goal post"}, "target_prompt": "A net positioned to the right of a goal post on a football field.", "target_property": {"obj_1": "net", "relation": "right of", "obj_2": "goal post"}, "evaluation_question": "Is the net to the **left** of the goal post?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A net positioned to the left of a goal post on a football field. 9%SLN", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4a2321c3bda642818236b75cb86f9468.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "344d10c939294c3fb674f96ec85d82ba", "source": "vatex", "video_id": "s-bHUbr-4p8_000001_000011", "video_description": "A female athlete is participating in an indoor track event, performing long jump and triple jump maneuvers while onlookers watch.", "task": "ObjectRecognition", "clean_prompt": "A female athlete is performing long jump and triple jump maneuvers while onlookers watch.", "clean_property": {"obj": "onlookers"}, "target_prompt": "A female athlete is performing long jump and triple jump maneuvers while coaches watch.", "target_property": {"obj": "coaches"}, "evaluation_question": "Are the spectators in the video **onlookers**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female athlete is performing long jump and triple jump maneuvers while onlookers watch. QCKZC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3e51f965246e4470964425f2399d0be3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f5e11b89d84747699385345d742eb0bd", "source": "vatex", "video_id": "KHHmcaqHH6I_000073_000083", "video_description": "A man is demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "task": "Counting", "clean_prompt": "Seven people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people gathered around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are gathered around a table, demonstrating and explaining techniques for pouring, swirling, and evaluating wine. OT)PT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c10d4025d15e4224b3c375b573a975a6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bbc3b2230fdb4c97b3f1c4d8ce1a911f", "source": "vatex", "video_id": "kxbUUbwO-6o_000382_000392", "video_description": "A man is demonstrating how to work on a car engine, specifically focusing on removing a stuck cap from the engine compartment while explaining the process.", "task": "Counting", "clean_prompt": "Four people working on a car engine, with one man demonstrating how to remove a stuck cap while explaining the process.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person working on a car engine, demonstrating how to remove a stuck cap while explaining the process.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people working on the car engine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people working on a car engine, with one man demonstrating how to remove a stuck cap while explaining the process. FE+Q\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5cea42090c3746b185053258180c5b74.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a6cedfe0ff5d4727ab09aa25a447d889", "source": "vatex", "video_id": "PWPcYEaGYRU_000001_000011", "video_description": "Martial arts students are practicing breaking wooden boards in a gym setting. Instructors hold the boards while students perform various techniques to break them.", "task": "ActionRecognition", "clean_prompt": "A student breaking boards in a gym.", "clean_property": {"obj": "student", "action": "breaking boards", "target": "board"}, "target_prompt": "A student kicking boards in a gym.", "target_property": {"obj": "student", "action": "kicking boards", "target": "board"}, "evaluation_question": "Is the student **breaking** boards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A student breaking boards in a gym. F/!?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9872ab565545402ea59ab035da7d05f9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd98eeedbd414274b23292863b7f6b5d", "source": "vatex", "video_id": "cm66wB7giOM_000000_000010", "video_description": "A group of people, including children, are playing kickball in a grassy field. The game involves rolling, kicking, and catching the ball.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a ball in a grassy field.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "ball"}, "target_prompt": "A person closer to the camera than a ball in a grassy field.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "ball"}, "evaluation_question": "Is the person **farther from the camera than** the ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a ball in a grassy field. RR%D)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0cb26544a66446bf9578c0dfc753275f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bfc420ce946144a3b9604e629356b827", "source": "vatex", "video_id": "MBPInWTFtgQ_000199_000209", "video_description": "A person is sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands.", "task": "AttributeRecognition", "clean_prompt": "A person is sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands.", "clean_property": {"obj": "o-ring", "attribute": "amber-colored"}, "target_prompt": "A person is sitting at a table, examining and rotating a blue-colored, round, plastic o-ring in their hands.", "target_property": {"obj": "o-ring", "attribute": "blue-colored"}, "evaluation_question": "Is the o-ring **amber-colored**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is sitting at a table, examining and rotating an amber-colored, round, plastic o-ring in their hands. EBSQF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df1ba277ee32475687bd43554996bb82.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b680c514160d4a6d91ba6c76f3484e3e", "source": "vatex", "video_id": "Fg-xNvFjJJI_000000_000010", "video_description": "A person is being pulled by a team of dogs through the woods on a wheeled contraption, which resembles a modified bicycle or sled.", "task": "AttributeRecognition", "clean_prompt": "A person being pulled by a team of dogs through the woods on a wheeled contraption, which resembles a modified bicycle.", "clean_property": {"obj": "wheeled contraption", "attribute": "modified bicycle"}, "target_prompt": "A person being pulled by a team of dogs through the woods on a motorized scooter.", "target_property": {"obj": "wheeled contraption", "attribute": "motorized scooter"}, "evaluation_question": "Is the wheeled contraption a **modified bicycle**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person being pulled by a team of dogs through the woods on a wheeled contraption, which resembles a modified bicycle. =8BC+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bab947b9497b4beb9403efa286ba1d13.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5ae3815fe30947019d05c333c68d1ea3", "source": "vatex", "video_id": "nfH0p_KAHSk_000029_000039", "video_description": "A young girl is riding a camel in the desert, assisted by a man who adjusts her saddle and gives instructions.", "task": "ActionRecognition", "clean_prompt": "A girl riding a camel in the desert.", "clean_property": {"obj": "girl", "action": "riding camel", "target": null}, "target_prompt": "A girl running beside a camel in the desert.", "target_property": {"obj": "girl", "action": "running beside camel", "target": null}, "evaluation_question": "Is the girl **riding** a camel?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl riding a camel in the desert. )PTJ@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7688b82732044c949940f2389ffb05dd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca99a0a03b04411695941ba608c63f69", "source": "vatex", "video_id": "0YWVgaLT5GM_000060_000070", "video_description": "A long-haired man is standing in a studio, wearing headphones and singing into a microphone on a stand.", "task": "Counting", "clean_prompt": "A long-haired man is standing in a studio, wearing headphones and singing into three microphones on stands.", "clean_property": {"obj": "microphone", "count": "three"}, "target_prompt": "A long-haired man is standing in a studio, wearing headphones and singing into one microphone on a stand.", "target_property": {"obj": "microphone", "count": "one"}, "evaluation_question": "Are there exactly **three** microphones in the studio?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A long-haired man is standing in a studio, wearing headphones and singing into three microphones on stands. ?J0BI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11610ee57044457b8083b1a2632f9c50.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f86b503c4c96483986b8e67a2ca6ee0e", "source": "vatex", "video_id": "UX6-6Y66dpE_000442_000452", "video_description": "In a commercial kitchen, a chef is demonstrating and instructing a group of culinary students on how to cook eggs over hard and other recipes.", "task": "SpatialUnderstanding", "clean_prompt": "A culinary student closer to the camera than a stove in a commercial kitchen.", "clean_property": {"obj_1": "culinary student", "relation": "closer to the camera than", "obj_2": "stove"}, "target_prompt": "A culinary student further from the camera than a stove in a commercial kitchen.", "target_property": {"obj_1": "culinary student", "relation": "further from the camera than", "obj_2": "stove"}, "evaluation_question": "Is the culinary student **closer to the camera than** the stove?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A culinary student closer to the camera than a stove in a commercial kitchen. RL96", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/09eebf669e2f437fb2cbb50fcd04a302.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "145ceacb361142b78dd5b08726b8e0dd", "source": "vatex", "video_id": "_kmIF87nOmE_000018_000028", "video_description": "A scuba diver is performing somersaults and flips underwater in an indoor swimming pool.", "task": "ActionRecognition", "clean_prompt": "A scuba diver somersaulting underwater in an indoor swimming pool.", "clean_property": {"obj": "scuba diver", "action": "somersaulting", "target": null}, "target_prompt": "A scuba diver swimming in a straight line underwater in an indoor swimming pool.", "target_property": {"obj": "scuba diver", "action": "swimming in a straight line", "target": null}, "evaluation_question": "Is the scuba diver **somersaulting** underwater?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scuba diver somersaulting underwater in an indoor swimming pool. P&FES", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/53bccde7ddc24dfabae339e627f57b6e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afefa62930ad48b0b8152e9382e12731", "source": "vatex", "video_id": "-iruowAZ8Fw_000580_000590", "video_description": "A woman, acting as a massage therapist, is giving a professional back massage to another person lying face down on a massage table. The therapist applies oil or lotion to her hands before massaging the client's back. Acoustic guitar music plays in the background.", "task": "ObjectRecognition", "clean_prompt": "A woman acting as a massage therapist is giving a professional back massage to a client on a massage table.", "clean_property": {"obj": "massage therapist"}, "target_prompt": "A yoga instructor guiding a group of people in a yoga class.", "target_property": {"obj": "yoga instructor"}, "evaluation_question": "Is the person in the video a **massage therapist**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman acting as a massage therapist is giving a professional back massage to a client on a massage table. SBB;E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64a7d453f2774010a8c9a39d2b7d6a33.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "96f258989d914dd486d48e057109be79", "source": "vatex", "video_id": "V7UHgYDwg24_000006_000016", "video_description": "Several couples are swing dancing in a large room with a mirrored wall, accompanied by swing music.", "task": "AttributeRecognition", "clean_prompt": "Several couples are swing dancing in a large room with a mirrored wall, accompanied by swing music, featuring a paired dancer.", "clean_property": {"obj": "dancer", "attribute": "paired"}, "target_prompt": "Several dancers are performing solo in a large room with a mirrored wall, accompanied by swing music.", "target_property": {"obj": "dancer", "attribute": "solo"}, "evaluation_question": "Are the dancers performing in pairs?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several couples are swing dancing in a large room with a mirrored wall, accompanied by swing music, featuring a paired dancer. ET+K\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9eaa77f6445e4fd6bd11b23c30761440.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "590f6d45c2ae4f45997e1aee06425692", "source": "vatex", "video_id": "oLVxjvNTTVw_000057_000067", "video_description": "A person is demonstrating how to create balloon animals, including a balloon dog, using various techniques and colors of balloons.", "task": "ActionRecognition", "clean_prompt": "A person making balloon shapes, demonstrating how to create balloon animals.", "clean_property": {"obj": "person", "action": "making balloon shapes", "target": null}, "target_prompt": "A person popping balloon shapes, demonstrating the effects of balloon animals.", "target_property": {"obj": "person", "action": "popping balloon shapes", "target": null}, "evaluation_question": "Is the person **making** balloon shapes?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making balloon shapes, demonstrating how to create balloon animals. ))!X3", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad7fd40e0c32439f8d4a89d277998868.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a89c1cd357854cd291011c6c1115e258", "source": "vatex", "video_id": "P-jVydhduoU_001268_001278", "video_description": "A woman, likely a lawyer, is standing at a desk in a courtroom, expressively speaking and defending a case in front of a judge and an audience.", "task": "AttributeRecognition", "clean_prompt": "A woman wearing a dark blue shirt is standing at a desk in a courtroom, expressively speaking and defending a case.", "clean_property": {"obj": "woman", "attribute": "wearing a dark blue shirt"}, "target_prompt": "A woman wearing a bright red dress is standing at a desk in a courtroom, expressively speaking and defending a case.", "target_property": {"obj": "woman", "attribute": "wearing a bright red dress"}, "evaluation_question": "Is the woman wearing a **dark blue shirt**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman wearing a dark blue shirt is standing at a desk in a courtroom, expressively speaking and defending a case. IVEHD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ecaa5ae5790d468ebd6c309145e9cde1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bd71e266c0954f2bb5935829b7eae2ee", "source": "vatex", "video_id": "BtWYzApEncw_000183_000193", "video_description": "Two teenage girls are sitting on a couch, chewing bubblegum and attempting to blow bubbles in front of a camera.", "task": "ObjectRecognition", "clean_prompt": "Two teenage girls are sitting on a couch, chewing bubblegum and attempting to blow bubbles in front of a camera.", "clean_property": {"obj": "camera"}, "target_prompt": "Two teenage girls are sitting on a couch, chewing bubblegum and attempting to blow bubbles in front of a microphone.", "target_property": {"obj": "microphone"}, "evaluation_question": "Are the girls attempting to blow bubbles in front of a **camera**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teenage girls are sitting on a couch, chewing bubblegum and attempting to blow bubbles in front of a camera. LFE+O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/091d69f12d154cb488b3cdecb4ec1fd0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "551fce2289bc4077af8eb43591f81f83", "source": "vatex", "video_id": "QsErsEl9qL8_000018_000028", "video_description": "A group of people are involved in a rappelling activity on a hillside. One person is rappelling down while others are holding ropes to support and guide them. The setting is outdoors, possibly in a forest or on a cliffside.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than the hillside.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "hillside"}, "target_prompt": "A person closer to the camera than the hillside.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "hillside"}, "evaluation_question": "Is the person **farther from the camera than** the hillside?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than the hillside. OT)!7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b75fae8b937c4f899fce8c9d435f45db.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "94b801edcc0348b490c8b34ff7b1a9dd", "source": "vatex", "video_id": "rfM1NFHgTaY_000338_000348", "video_description": "A woman is using wire cutters to cut wire and then threads beads and other objects onto it as part of an art craft.", "task": "SpatialUnderstanding", "clean_prompt": "Wire cutters farther from the camera than a person using them.", "clean_property": {"obj_1": "wire cutters", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "Wire cutters closer to the camera than a person using them.", "target_property": {"obj_1": "wire cutters", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Are the wire cutters **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Wire cutters farther from the camera than a person using them. DP+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2be1064edf534b928b680fcdf71d05a4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "886b1deed09f49f1abaca473e32a407a", "source": "vatex", "video_id": "_QxCm-caLQE_000025_000035", "video_description": "A person is filling a glass with beer from a tap indoors, creating a large foam head.", "task": "SpatialUnderstanding", "clean_prompt": "A tap farther from the camera than a glass of beer being filled indoors.", "clean_property": {"obj_1": "tap", "relation": "farther from the camera than", "obj_2": "beer"}, "target_prompt": "A tap closer to the camera than a glass of beer being filled indoors.", "target_property": {"obj_1": "tap", "relation": "closer to the camera than", "obj_2": "beer"}, "evaluation_question": "Is the tap farther from the camera than the glass of beer?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tap farther from the camera than a glass of beer being filled indoors. FE7G@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/aa5280581dc14f42a530135cfa53a4bc.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9202f42873ce4e6d8a631c9029f18b3d", "source": "vatex", "video_id": "LW0ck77OMTM_000033_000043", "video_description": "A person is grooming a small, black and white miniature horse outdoors using a brush. The horse is standing near a barbed wire fence.", "task": "Counting", "clean_prompt": "A person is grooming six miniature horses outdoors using a brush.", "clean_property": {"obj": "horse", "count": "six"}, "target_prompt": "A person is grooming two miniature horses outdoors using a brush.", "target_property": {"obj": "horse", "count": "two"}, "evaluation_question": "Are there exactly **six** miniature horses being groomed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is grooming six miniature horses outdoors using a brush. FEZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e097d6dc54994f85ae4a189edffba8fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c74cebfdbb744abe955c8ad1bb999574", "source": "vatex", "video_id": "MyIecl0syug_000073_000083", "video_description": "A group of people, including children, are playing and sledding in a snow-filled hilly field. Some are carrying sleds, while others are sledding down a hill. The scene is outdoors in a park with snow covering the ground.", "task": "AttributeRecognition", "clean_prompt": "A person playing with children in a snow-filled hilly field.", "clean_property": {"obj": "person", "attribute": "children"}, "target_prompt": "A person playing with dogs in a snow-filled hilly field.", "target_property": {"obj": "person", "attribute": "playing with dogs"}, "evaluation_question": "Is the person playing with **children**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing with children in a snow-filled hilly field. FEA)#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5e3f171b5e27487b8d2cb8afc9c6a4e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b6a5aeebd140451ebde61a5b588eb107", "source": "vatex", "video_id": "nZt6VHJ73Ls_000010_000020", "video_description": "A group of children and teenagers are riding sleds down a snowy hill, taking turns and expressing excitement.", "task": "Counting", "clean_prompt": "Six sledders riding down a snowy hill, taking turns and expressing excitement.", "clean_property": {"obj": "sledder", "count": "six"}, "target_prompt": "Three sledders riding down a snowy hill, taking turns and expressing excitement.", "target_property": {"obj": "sledder", "count": "three"}, "evaluation_question": "Are there exactly **six** sledders riding down the hill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six sledders riding down a snowy hill, taking turns and expressing excitement. @@0BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/661df11450cd4bad89586c7b9d6383aa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "27132bb605bb4497abe6cc7bdf807639", "source": "vatex", "video_id": "_SUeogHI5rg_000043_000053", "video_description": "A man is on a golf course making an instructional video about golfing techniques, including how to hit a ball to land just short of the green and how to putt.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to hit a golf ball on a golf course.", "clean_property": {"obj": "golf ball"}, "target_prompt": "A man demonstrating how to hit a tennis ball on a tennis court.", "target_property": {"obj": "tennis ball"}, "evaluation_question": "Is the object being hit in the video a **golf ball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to hit a golf ball on a golf course. N(/?|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/20157a9c4428424b80eb16071e1cf140.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca13178dcef6447a8759482864c228f6", "source": "vatex", "video_id": "eVE1HglKrU0_000081_000091", "video_description": "A group of people, including children and young men, are having fun in an inflatable bounce house. They are jumping, playing, and occasionally laying down and kicking the inflatable structure. A mom is watching the children.", "task": "ObjectRecognition", "clean_prompt": "A group of people, including children and young men, are having fun in an inflatable bounce house.", "clean_property": {"obj": "person"}, "target_prompt": "A group of dogs playing in an inflatable bounce house.", "target_property": {"obj": "dog"}, "evaluation_question": "Are there **people** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people, including children and young men, are having fun in an inflatable bounce house. FE(TZ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb548b5707374a8a9979693f7492fefd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b4962402107f4677bbb5960c5a01392c", "source": "vatex", "video_id": "qB9XxN1wrLE_000033_000043", "video_description": "A man on a golf course is demonstrating and explaining how to properly hit a golf ball, including stance, lining up the shot, and swinging the club.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to properly hit a golf ball on a golf course.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating how to properly hit a golf ball on a golf course.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to properly hit a golf ball on a golf course. )%D|%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f18b131b56b74a04891c81da335f5e37.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f05d20bd38fb4aec9decedae46f9c3cc", "source": "vatex", "video_id": "dNUxmjY8sfQ_000006_000016", "video_description": "A group of people, including a bartender, are demonstrating how to properly pour beer from a tap into glasses at a brewery.", "task": "SpatialUnderstanding", "clean_prompt": "A beer tap located to the left of a glass.", "clean_property": {"obj_1": "beer tap", "relation": "left of", "obj_2": "glass"}, "target_prompt": "A beer tap located to the right of a glass.", "target_property": {"obj_1": "beer tap", "relation": "right of", "obj_2": "glass"}, "evaluation_question": "Is the beer tap to the **left** of the glass?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A beer tap located to the left of a glass. .))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/df99d67b11a24cce84ee688f53ac3d11.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3f3bde1d0ac94ffa978dfaf3b9056561", "source": "vatex", "video_id": "c66eIbgvwxE_000000_000010", "video_description": "A group of people, including men and construction workers, are participating in a food eating competition outdoors in a parking lot. Spectators, including adults and children, gather around tables to watch the contest, which involves eating hot dogs and pizza. There is noise in the background, indicating a lively event.", "task": "AttributeRecognition", "clean_prompt": "A contestant who is a construction worker participating in a food eating competition outdoors.", "clean_property": {"obj": "contestant", "attribute": "construction worker"}, "target_prompt": "A contestant who is a chef participating in a food eating competition outdoors.", "target_property": {"obj": "contestant", "attribute": "chef"}, "evaluation_question": "Is the contestant a **construction worker**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A contestant who is a construction worker participating in a food eating competition outdoors. '';!%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cca80f40ae84db393d0b8498efb1b5f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "264cbc38b85b4eeeac3164f7fcf44ecc", "source": "vatex", "video_id": "NEH1HLP5nPM_000217_000227", "video_description": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with multiple panes of glass.", "task": "Counting", "clean_prompt": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with four panes of glass.", "clean_property": {"obj": "window", "count": "four"}, "target_prompt": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with one pane of glass.", "target_property": {"obj": "window", "count": "one"}, "evaluation_question": "Are there exactly **four** panes of glass in the window?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is using an electric drill to drill holes into a wall inside a building, near a large window with four panes of glass. ++LFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e6c58d16ac6d4e75a548469a27820274.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2e36b3288d494b75b6c150b407ccbcc4", "source": "vatex", "video_id": "p4N1Fqffhpg_000023_000033", "video_description": "A cymbal player from a marching band performs flashy tricks and moves with cymbals on a football field, while other band members watch.", "task": "ActionRecognition", "clean_prompt": "A cymbal player playing cymbals on a football field.", "clean_property": {"obj": "cymbal player", "action": "playing cymbals", "target": null}, "target_prompt": "A cymbal player spinning cymbals on a football field.", "target_property": {"obj": "cymbal player", "action": "spinning cymbals", "target": null}, "evaluation_question": "Is the cymbal player **playing** cymbals?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cymbal player playing cymbals on a football field. SL?4S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ec5d52ea3a634b65b46e8a0f4374f433.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "896877518eb7487d9ed668f6b8d09473", "source": "vatex", "video_id": "eAz-jW31Iq8_000205_000215", "video_description": "A man is demonstrating how to shuffle a deck of cards on a table, occasionally chatting with another man.", "task": "ActionRecognition", "clean_prompt": "A person shuffling a deck of cards on a table.", "clean_property": {"obj": "person", "action": "shuffling cards", "target": "deck of cards"}, "target_prompt": "A person throwing a deck of cards on a table.", "target_property": {"obj": "person", "action": "throwing cards", "target": "deck of cards"}, "evaluation_question": "Is the person **shuffling** cards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person shuffling a deck of cards on a table. LY@MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c3e96f7df6a94e13aa630402b0690c6c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bad90e0fca15482bbaabb3a313c88f20", "source": "vatex", "video_id": "JMyCoStRMFg_000006_000016", "video_description": "In a sand-lined outdoor arena, a cowboy on horseback chases and lassoes a calf, then jumps off the horse to tie the calf.", "task": "ObjectRecognition", "clean_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena.", "clean_property": {"obj": "calf"}, "target_prompt": "A cowboy on horseback chases and lassoes a sheep in a sand-lined outdoor arena.", "target_property": {"obj": "sheep"}, "evaluation_question": "Is the animal being chased in the video a **calf**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cowboy on horseback chases and lassoes a calf in a sand-lined outdoor arena. F-!'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c00ff397385b4cf492404854fee44dc2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0a54277329ab45bca37f5257de5c882b", "source": "vatex", "video_id": "-XTQ7kDUXjk_000087_000097", "video_description": "A window cleaner is using a long pole to clean high windows and gutters on a house.", "task": "ObjectRecognition", "clean_prompt": "A window cleaner is using a long pole to clean high windows and gutters on a house.", "clean_property": {"obj": "window cleaner"}, "target_prompt": "A gardener using a long pole to trim high branches and maintain the garden.", "target_property": {"obj": "gardener"}, "evaluation_question": "Is the person in the video a **window cleaner**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A window cleaner is using a long pole to clean high windows and gutters on a house. Q?;)R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b3254dad70e5487f993ce5f9755c3b50.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cdd21ee9622448579662613ec0934754", "source": "vatex", "video_id": "xCYKZAZdUfQ_000138_000148", "video_description": "A man is lying on an exercise mat outdoors, demonstrating leg stretches using a resistance band.", "task": "ObjectRecognition", "clean_prompt": "A man lying on an exercise mat outdoors, demonstrating leg stretches using a resistance band.", "clean_property": {"obj": "mat"}, "target_prompt": "A man lying on a bench outdoors, demonstrating leg stretches using a resistance band.", "target_property": {"obj": "bench"}, "evaluation_question": "Is the man lying on an **exercise mat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man lying on an exercise mat outdoors, demonstrating leg stretches using a resistance band. MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56493e7f3a934bdd9336f484573246bb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e9cf99f5df10432489c2eb16634dfbc1", "source": "vatex", "video_id": "e3uc4YfI9jA_000000_000010", "video_description": "A young boy is swimming in the ocean, catches a fish with his bare hands, and yells to his father about his catch.", "task": "ActionRecognition", "clean_prompt": "A boy catching fish in the ocean.", "clean_property": {"obj": "boy", "action": "catching fish", "target": "fish"}, "target_prompt": "A boy throwing fish in the ocean.", "target_property": {"obj": "boy", "action": "throwing fish", "target": "fish"}, "evaluation_question": "Is the boy **catching** fish?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy catching fish in the ocean. RL;?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/691f4d25eecf47dbaec7d35e78340bac.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9eb29fce621c4d56b4138af6f59f77a3", "source": "vatex", "video_id": "qdKnAq7KQ5c_000085_000095", "video_description": "A woman is sitting at a table, folding and ironing a cloth napkin.", "task": "Counting", "clean_prompt": "Two women sitting at a table, folding and ironing cloth napkins.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A woman sitting at a table, folding and ironing a cloth napkin.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** women sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women sitting at a table, folding and ironing cloth napkins. )|4//", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b45a97a47e0840d293aafc8cf6f7876b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e8ccd3fdbd92487abc25945791b44182", "source": "vatex", "video_id": "IBay_SsO2_M_000113_000123", "video_description": "A man in a suit presents an award to another man on stage in front of an applauding audience. The recipient steps up to the podium to deliver a speech.", "task": "ActionRecognition", "clean_prompt": "A presenter giving an award to a recipient on stage in front of an applauding audience.", "clean_property": {"obj": "presenter", "action": "giving or receiving award", "target": "recipient"}, "target_prompt": "A presenter taking an award back from a recipient on stage in front of an applauding audience.", "target_property": {"obj": "presenter", "action": "taking an award back", "target": "recipient"}, "evaluation_question": "Is the presenter **giving** an award to the recipient?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A presenter giving an award to a recipient on stage in front of an applauding audience. %BSD|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/de12d9059d884038993cde0e9efc5028.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "70d41dfe8b284437a42ac0b7a7bc4949", "source": "vatex", "video_id": "352eUp-RrsU_000110_000120", "video_description": "A woman is in a beauty salon getting her eyebrows waxed by a beautician using wax strips. She is happy with the results.", "task": "Counting", "clean_prompt": "Five beauticians working in a busy beauty salon, each attending to different clients.", "clean_property": {"obj": "beautician", "count": "five"}, "target_prompt": "One beautician working alone in a quiet beauty salon.", "target_property": {"obj": "beautician", "count": "one"}, "evaluation_question": "Are there exactly **five** beauticians in the salon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five beauticians working in a busy beauty salon, each attending to different clients. VT60V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98e4cfa7fa324ad190ea464de1aeabdb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8cb234bd156455ba42d82647892a0f6", "source": "vatex", "video_id": "yJf9kzzvdMY_000000_000010", "video_description": "An elderly woman and a small boy are playing with maracas in a home kitchen.", "task": "AttributeRecognition", "clean_prompt": "A small boy playing with maracas in a home kitchen.", "clean_property": {"obj": "boy", "attribute": "small"}, "target_prompt": "A large boy playing with maracas in a home kitchen.", "target_property": {"obj": "boy", "attribute": "large"}, "evaluation_question": "Is the boy **small**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A small boy playing with maracas in a home kitchen. )LZ%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1520701f8d2b41d8a8b4fa278527cc7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7bf3129d9561450ba0fef3e6bebd0797", "source": "vatex", "video_id": "oPtf4Cl3Swk_000488_000498", "video_description": "A woman wearing a cap is using a sewing machine to sew black fabric in a home setting.", "task": "ActionRecognition", "clean_prompt": "A person sewing black fabric on a sewing machine in a home setting.", "clean_property": {"obj": "person", "action": "sewing", "target": "fabric"}, "target_prompt": "A person cutting red fabric in a home setting.", "target_property": {"obj": "person", "action": "cutting fabric", "target": "red fabric"}, "evaluation_question": "Is the person **sewing** black fabric?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sewing black fabric on a sewing machine in a home setting. EZIVI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/63811740d6284af58848ed5f5cb19dd8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "59142036f4714f6fa743cb331c98e874", "source": "vatex", "video_id": "5JDEfU5vrts_000035_000045", "video_description": "A young boy is outside in the front yard of a home, working on building and trimming a snowman using a stick.", "task": "ObjectRecognition", "clean_prompt": "A young boy is outside in the front yard of a home, working on building and trimming a snowman using a stick.", "clean_property": {"obj": "stick"}, "target_prompt": "A young boy is outside in the front yard of a home, playing with a ball.", "target_property": {"obj": "ball"}, "evaluation_question": "Is the boy using a **stick** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is outside in the front yard of a home, working on building and trimming a snowman using a stick. =FE8H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ba7d865d834846cb9e2fcd131fa81faf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8a6edcffeafa470f90ee15025badb47d", "source": "vatex", "video_id": "9qx4OljmURU_000113_000123", "video_description": "A woman is demonstrating how to decorate a Christmas tree with various ornaments while sitting next to it.", "task": "AttributeRecognition", "clean_prompt": "A woman is decorating a Christmas tree with various ornaments.", "clean_property": {"obj": "tree", "attribute": "decorated"}, "target_prompt": "A woman is sitting next to a bare tree.", "target_property": {"obj": "tree", "attribute": "bare"}, "evaluation_question": "Is the tree **decorated** with ornaments?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is decorating a Christmas tree with various ornaments. )G%F)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/25b322c52a7645588841e8f108e5c56f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "427b92c2561c4e1cbb9a6634632aaf40", "source": "vatex", "video_id": "hJ07ncKOBR0_000031_000041", "video_description": "A young boy is sitting at a table with a pile of potato chips on a paper towel. He is eating the chips and talking.", "task": "ActionRecognition", "clean_prompt": "A boy eating chips at a table.", "clean_property": {"obj": "boy", "action": "eating chips", "target": null}, "target_prompt": "A boy playing with toys at a table.", "target_property": {"obj": "boy", "action": "playing with toys", "target": null}, "evaluation_question": "Is the boy **eating chips**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy eating chips at a table. >I@.9", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4eac3126717145c08bf2dcdfbb80825a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f02dbee9b3c4190ab4397064ab3fcf8", "source": "vatex", "video_id": "0jbpGIvCQPM_000000_000010", "video_description": "A girl is practicing softball pitching and catching inside a gymnasium, using a mitt and a softball.", "task": "ObjectRecognition", "clean_prompt": "A girl practicing softball pitching and catching inside a gymnasium, using a mitt and a softball.", "clean_property": {"obj": "mitt"}, "target_prompt": "A girl practicing softball pitching and catching inside a gymnasium, using a bat and a softball.", "target_property": {"obj": "bat"}, "evaluation_question": "Is the girl using a **mitt** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl practicing softball pitching and catching inside a gymnasium, using a mitt and a softball. W%!:\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/66667e5c1f2048899b9b64cc52828689.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e5d072d579d241f0ab5d5d53d5db0220", "source": "vatex", "video_id": "_gPhYONNqoY_000013_000023", "video_description": "A woman is demonstrating how to clean and polish a pair of stylish black high heels using a hand-held brush.", "task": "ObjectRecognition", "clean_prompt": "A woman is demonstrating how to clean and polish a pair of stylish black high heels using a hand-held brush.", "clean_property": {"obj": "brush"}, "target_prompt": "A woman is demonstrating how to clean and polish a pair of stylish black high heels using a sponge.", "target_property": {"obj": "sponge"}, "evaluation_question": "Is the woman using a **brush** to clean the high heels?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to clean and polish a pair of stylish black high heels using a hand-held brush. U%H9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/edbf953a6cce41659e588730bcf68a33.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "551af98c883948fba8818f6ce700df03", "source": "vatex", "video_id": "-PIDdASWlas_000000_000010", "video_description": "A woman is entertaining a baby by tossing a bottle in the air and catching it, making the baby laugh.", "task": "Counting", "clean_prompt": "Two women entertaining a baby by tossing a bottle in the air and catching it, making the baby laugh.", "clean_property": {"obj": "woman", "count": "two"}, "target_prompt": "One woman entertaining a baby by tossing a bottle in the air and catching it, making the baby laugh.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **two** women entertaining the baby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women entertaining a baby by tossing a bottle in the air and catching it, making the baby laugh. I+)!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/27fc961651604920b6cc6187ed560161.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c963b1616d494a55949df149b0e24f9f", "source": "vatex", "video_id": "ZbI_bpw83Pc_000007_000017", "video_description": "Two men are outdoors under a tent, demonstrating how to play a didgeridoo. One man blows into the didgeridoo while the other helps hold it up. They pause to smile at the camera and speak a few words in a foreign language.", "task": "Counting", "clean_prompt": "Two men are outdoors under a tent, demonstrating how to play a didgeridoo.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "Four people are outdoors under a tent, demonstrating how to play a didgeridoo.", "target_property": {"obj": "person", "count": "four"}, "evaluation_question": "Are there exactly **two** men demonstrating the didgeridoo?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are outdoors under a tent, demonstrating how to play a didgeridoo. )!D=!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d7029423e2948c18be6635411e97df8.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bb7cb0d9d10c414e950cef8088ab4065", "source": "vatex", "video_id": "3LV9AjlJ-5A_000417_000427", "video_description": "A woman demonstrates how to apply makeup using a brush, starting by dabbing makeup on her hand to show the color before applying it to her face.", "task": "Counting", "clean_prompt": "A woman demonstrates how to apply makeup using a brush, starting by dabbing makeup on her hand to show the color before applying it to her face with six different makeup products.", "clean_property": {"obj": "makeup", "count": "six"}, "target_prompt": "A woman demonstrates how to apply makeup using a brush, starting by dabbing makeup on her hand to show the color before applying it to her face with three different makeup products.", "target_property": {"obj": "makeup", "count": "three"}, "evaluation_question": "Are there exactly **six** different makeup products being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to apply makeup using a brush, starting by dabbing makeup on her hand to show the color before applying it to her face with six different makeup products. ;BCJJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6e9bc8e6d8ef409cbabb626bb486db97.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c963b50b57bf47b6804edd8e7cf1bd99", "source": "vatex", "video_id": "cuRpebukhx8_000097_000107", "video_description": "Two turkeys are in a grass field pecking at each other while being observed by a person from a hunting blind.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a hunting blind, observing two turkeys in a grass field.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "hunting blind"}, "target_prompt": "A person standing to the left of a hunting blind, observing two turkeys in a grass field.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "hunting blind"}, "evaluation_question": "Is the person to the **right** of the hunting blind?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a hunting blind, observing two turkeys in a grass field. XBS+@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46695b590e6e4a69ae3217ced30bccc7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6daa429ae8bd440d87a2ce677bd21f88", "source": "vatex", "video_id": "m9n5SLRXIKw_000015_000025", "video_description": "Two teenage boys are practicing a hip hop dance routine in a dance studio with a gridded floor.", "task": "Counting", "clean_prompt": "Two teenage boys are practicing a hip hop dance routine on a gridded floor in a dance studio.", "clean_property": {"obj": "floor", "count": "two"}, "target_prompt": "Two teenage boys are practicing a hip hop dance routine on a single floor in a dance studio.", "target_property": {"obj": "floor", "count": "one"}, "evaluation_question": "Are there exactly **two** floors in the dance studio?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two teenage boys are practicing a hip hop dance routine on a gridded floor in a dance studio. !0D\u00b7B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/075ba7c57c264cbcb233722b5a3cd92a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c374a3c529a54352b5a444638d116504", "source": "vatex", "video_id": "CAQ1X0ObODw_000031_000041", "video_description": "A baby is laying down, shaking its head side to side as an adult interacts with it by speaking and touching its face.", "task": "ActionRecognition", "clean_prompt": "A baby shaking its head side to side while an adult interacts with it.", "clean_property": {"obj": "baby", "action": "shaking head", "target": null}, "target_prompt": "A baby laughing while an adult interacts with it.", "target_property": {"obj": "baby", "action": "laughing", "target": null}, "evaluation_question": "Is the baby **shaking its head**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby shaking its head side to side while an adult interacts with it. TZ;T\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c9fd4cc13dd4357b10b8390c6988add.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f6512f54f3934cfa83c6c92bd5dd6cba", "source": "vatex", "video_id": "83ifrji71ds_000065_000075", "video_description": "A young woman wearing headphones is sitting indoors, smoking from a pipe or vape, and blowing smoke rings.", "task": "ActionRecognition", "clean_prompt": "A person sitting indoors, smoking from a pipe and blowing smoke rings.", "clean_property": {"obj": "person", "action": "smoking pipe", "target": null}, "target_prompt": "A person sitting indoors, playing guitar.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **smoking from a pipe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting indoors, smoking from a pipe and blowing smoke rings. SL|LV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/835d1bde3ade4fc68c2379c9965c3144.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bde3ddc3938a476080bd78f47a8759e8", "source": "vatex", "video_id": "L2-RwmuQ6-4_000033_000043", "video_description": "A man and a woman, both dressed in company logos, are sitting together at a table discussing three payment options while facing the camera.", "task": "ActionRecognition", "clean_prompt": "A woman talking on a cell phone.", "clean_property": {"obj": "woman", "action": "talking on cell phone", "target": null}, "target_prompt": "A woman walking in a park.", "target_property": {"obj": "woman", "action": "walking in a park", "target": null}, "evaluation_question": "Is the woman **talking on a cell phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman talking on a cell phone. MV*.", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a204aae900848d78391fd1f992c2b39.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e683ad09405a42d2a12a05cff0b1f2e1", "source": "vatex", "video_id": "za5iFp6zMo4_000001_000011", "video_description": "A man is sitting on a rolling stool and being pulled around a shop or garage by various power equipment, including a leaf blower, snow blower, and lawn mower.", "task": "ActionRecognition", "clean_prompt": "A person using a power drill in a workshop.", "clean_property": {"obj": "person", "action": "using a power drill", "target": null}, "target_prompt": "A person operating a chainsaw in a workshop.", "target_property": {"obj": "person", "action": "operating a chainsaw", "target": null}, "evaluation_question": "Is the person **using a power drill**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a power drill in a workshop. NEFL*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8303643f3b9a405da0e2fcc5a3db7bcb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f6d7054261a4a0c8c078b84e5d0cfaa", "source": "vatex", "video_id": "sAtugMHcHE0_000000_000010", "video_description": "Two young boys are playing and demonstrating how to sharpen a pencil using a nose-shaped pencil sharpener inside a room.", "task": "ActionRecognition", "clean_prompt": "A boy sharpening a pencil using a nose-shaped pencil sharpener inside a room.", "clean_property": {"obj": "boy", "action": "sharpening pencil", "target": "nose sharpener"}, "target_prompt": "A boy throwing a pencil at a nose-shaped pencil sharpener inside a room.", "target_property": {"obj": "boy", "action": "throwing pencil", "target": "nose sharpener"}, "evaluation_question": "Is the boy **sharpening** a pencil?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy sharpening a pencil using a nose-shaped pencil sharpener inside a room. @JSI1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c7db9b64791e439f89aeb628f6c757a9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c09f7682267447c826cdebda3c92528", "source": "vatex", "video_id": "WOTM_pnTrpM_000033_000043", "video_description": "A group of spectators watch various motorized vehicles, including go-karts, lawnmowers, and ATVs, race around a circular dirt track.", "task": "ObjectRecognition", "clean_prompt": "A group of spectators watch various motorized vehicles racing around a circular dirt track.", "clean_property": {"obj": "vehicle"}, "target_prompt": "A group of spectators watch various bicycles racing around a circular dirt track.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Are the vehicles in the video **motorized**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of spectators watch various motorized vehicles racing around a circular dirt track. '''!A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0662e632323d49fb966b29ca02fefb1e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cca7cd1d0cec4110a049de3820a98ab2", "source": "vatex", "video_id": "qQg2_PHIMaQ_000637_000647", "video_description": "A woman is demonstrating a sewing technique using a metal tool to punch fabric on a foam pad. The camera falls over during the demonstration.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a metal tool while demonstrating a sewing technique.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "metal tool"}, "target_prompt": "A person standing to the right of a metal tool while demonstrating a sewing technique.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "metal tool"}, "evaluation_question": "Is the person to the **left** of the metal tool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a metal tool while demonstrating a sewing technique. ''))!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c1e1c01555dc4979afe889db746bacd4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6707160a3bbe4681a1c78d3d62aa496d", "source": "vatex", "video_id": "M6ykllLdpQA_000019_000029", "video_description": "A toddler is sitting on a bed, shaking her head, and then staring into the camera.", "task": "SpatialUnderstanding", "clean_prompt": "A toddler sitting to the left of a camera.", "clean_property": {"obj_1": "toddler", "relation": "left of", "obj_2": "camera"}, "target_prompt": "A toddler sitting to the right of a camera.", "target_property": {"obj_1": "toddler", "relation": "right of", "obj_2": "camera"}, "evaluation_question": "Is the toddler to the **left** of the camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A toddler sitting to the left of a camera. UB>RC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a2f20dedeb8f4d30824fb83c97b4c401.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ec2a4a60dbf4ce5b4cf55b4396cb3c0", "source": "vatex", "video_id": "xduuz2Uttvw_000026_000036", "video_description": "A group of men, part of a university percussion band, are playing cymbals in a line. They are wearing uniforms and performing as part of a drum line, with some members occasionally stepping out to interact with each other using their cymbals.", "task": "SpatialUnderstanding", "clean_prompt": "A musician standing to the right of a cymbal.", "clean_property": {"obj_1": "musician", "relation": "right of", "obj_2": "cymbal"}, "target_prompt": "A musician standing to the left of a cymbal.", "target_property": {"obj_1": "musician", "relation": "left of", "obj_2": "cymbal"}, "evaluation_question": "Is the musician to the **right** of a cymbal?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician standing to the right of a cymbal. .)!0P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6ead5580b36446fd924e6ef48ecd65bc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "06be87b72b4a46da99520278869c66ac", "source": "vatex", "video_id": "ObE1EygmVTg_000068_000078", "video_description": "A woman on an ice rink is attempting to play hockey, discussing her experience while trying to hit a puck with a hockey stick. She is wearing hockey gear and is encouraged by a man.", "task": "Counting", "clean_prompt": "A woman on an ice rink is attempting to play hockey, discussing her experience while trying to hit a puck with a hockey stick. She is wearing hockey gear and is encouraged by a man.", "clean_property": {"obj": "woman", "count": "six"}, "target_prompt": "Three women on an ice rink are attempting to play hockey, discussing their experiences while trying to hit a puck with hockey sticks.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **six** women on the ice rink?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman on an ice rink is attempting to play hockey, discussing her experience while trying to hit a puck with a hockey stick. She is wearing hockey gear and is encouraged by a man. NZPOE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d75e7c658ed54a5aaceda1311f729150.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "239ac51c5655470babde2e7be147abf9", "source": "vatex", "video_id": "-0sNYhpevoU_000000_000010", "video_description": "A man with black hair and a receding hairline is massaging his own head in a kitchen.", "task": "AttributeRecognition", "clean_prompt": "A person with a receding hairline massaging his own head in a kitchen.", "clean_property": {"obj": "person", "attribute": "receding hairline"}, "target_prompt": "A person with a full head of hair massaging his own head in a kitchen.", "target_property": {"obj": "person", "attribute": "full head of hair"}, "evaluation_question": "Does the person have a **receding** hairline?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with a receding hairline massaging his own head in a kitchen. &LFVV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f4c5c922ef414ff5a0b404be4ca52235.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b735a028810441fbb9cf5e2db6cd2a51", "source": "vatex", "video_id": "53C61ZUEbSo_000063_000073", "video_description": "A young girl is demonstrating and explaining the features of a mini microscope, speaking in a foreign language.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a microscope, demonstrating its features.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "microscope"}, "target_prompt": "A person further from the camera than a microscope, demonstrating its features.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "microscope"}, "evaluation_question": "Is the person closer to the camera than the microscope?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a microscope, demonstrating its features. Y))'!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4771439e5423475589981db91b352f39.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c4e4dc73cf42439688deb4b3167b2631", "source": "vatex", "video_id": "zeMgyQybSfs_000311_000321", "video_description": "A person is water skiing on a lake, being towed by a motor boat. The person is holding onto a rope attached to the boat and is wearing a GoPro camera.", "task": "ObjectRecognition", "clean_prompt": "A person water skiing on a lake, being towed by a motor boat.", "clean_property": {"obj": "person"}, "target_prompt": "A child playing on the shore of a lake.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video water skiing?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person water skiing on a lake, being towed by a motor boat. ))'.%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7c8af196113642e0ba8c8d5e1d57adc7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0020d73bb3a4422d8d221c2b0790de5b", "source": "vatex", "video_id": "8DVERAUOlro_000000_000010", "video_description": "A teenage girl with a long ponytail is practicing high kicks in a room, kicking her leg up in the air repeatedly from different angles.", "task": "ActionRecognition", "clean_prompt": "A person practicing high kicks in a room.", "clean_property": {"obj": "person", "action": "high kick", "target": null}, "target_prompt": "A person performing a spinning kick in a room.", "target_property": {"obj": "person", "action": "spinning kick", "target": null}, "evaluation_question": "Is the person **practicing high kicks**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing high kicks in a room. VT'4R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/697d610ecc5a410ba71cda812a5d1881.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3d5d0ab97e4841b8b5f1a47c4f530a8f", "source": "vatex", "video_id": "Q7lQz_-v40g_000043_000053", "video_description": "Two young Asian girls are in a living room, listening to music and dancing. They are pretending to sneeze and cough as part of a game or song.", "task": "ActionRecognition", "clean_prompt": "A girl singing in a living room.", "clean_property": {"obj": "girl", "action": "singing", "target": null}, "target_prompt": "A girl dancing in a living room.", "target_property": {"obj": "girl", "action": "dancing", "target": null}, "evaluation_question": "Is the girl **singing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl singing in a living room. JYDZB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8475b18e9a3841afb911967b20755d18.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d070cf3147744ef19d1891ed840daea4", "source": "vatex", "video_id": "h0zxrUPIapI_000000_000010", "video_description": "A man in a royal, historical costume is speaking to an audience in an outdoor theater setting.", "task": "ObjectRecognition", "clean_prompt": "A man in a royal, historical costume is speaking to an audience in an outdoor theater setting.", "clean_property": {"obj": "audience"}, "target_prompt": "A man in a royal, historical costume is speaking to a crowd in an outdoor theater setting.", "target_property": {"obj": "crowd"}, "evaluation_question": "Is the audience in the video referred to as an **audience**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a royal, historical costume is speaking to an audience in an outdoor theater setting. @!J@!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6ccbd7693d744fc81993de94b92d60d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "666563b8afed4d9c83fa0a83c1bd53f9", "source": "vatex", "video_id": "D-dJ--BP2yY_000021_000031", "video_description": "An athlete performs a pole vault, running down a track and using a pole to jump over a bar.", "task": "ObjectRecognition", "clean_prompt": "An athlete performing a pole vault on a track.", "clean_property": {"obj": "track"}, "target_prompt": "An athlete performing a dive into a swimming pool.", "target_property": {"obj": "swimmer"}, "evaluation_question": "Is the athlete performing on a **track**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An athlete performing a pole vault on a track. !0!&&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6a54576faed4648b210bd69b8415079.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb9c4aa13af44f10837ead746033e5fe", "source": "vatex", "video_id": "Ybx599BRfeU_000071_000081", "video_description": "A woman, wearing a hijab, is in the bathroom brushing the teeth of a small child who is sitting on her lap.", "task": "ObjectRecognition", "clean_prompt": "A woman in a hijab is brushing the teeth of a small child sitting on her lap in the bathroom.", "clean_property": {"obj": "child"}, "target_prompt": "A woman in a hijab is brushing the teeth of a dog sitting on her lap in the bathroom.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the child being brushed in the video a **small child**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a hijab is brushing the teeth of a small child sitting on her lap in the bathroom. LFY)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3702ef727aff4c9f8ae4f32f2cebe607.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b96eca0981904774bc36c11ad595c868", "source": "vatex", "video_id": "l3axslccUQk_000102_000112", "video_description": "A person is drawing a face on a canvas, labeling each part, while music plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a canvas, drawing a face and labeling each part while music plays in the background.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "canvas"}, "target_prompt": "A person standing to the left of a canvas, drawing a face and labeling each part while music plays in the background.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "canvas"}, "evaluation_question": "Is the person to the **right** of the canvas?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a canvas, drawing a face and labeling each part while music plays in the background. SL+;S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2a93b4ae93444c8ead5d87384561c64d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5cc04ab2d59c4cd3b5b1f6b91a66d3db", "source": "vatex", "video_id": "4QM_nO2YWCo_000073_000083", "video_description": "Two young boys are playing with toy laser guns in a house, engaging in a game that involves shooting each other. The toys light up and make noise. The setting includes a living room and a staircase.", "task": "ActionRecognition", "clean_prompt": "A boy playing laser tag in a living room.", "clean_property": {"obj": "boy", "action": "playing laser tag", "target": null}, "target_prompt": "A boy watching TV in a living room.", "target_property": {"obj": "boy", "action": "watching TV", "target": null}, "evaluation_question": "Is the boy **playing laser tag**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy playing laser tag in a living room. G>G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c0f7f58128c4ce289647c65abf58416.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42b00140dcee4fcc98761f0091ef1955", "source": "vatex", "video_id": "Ien8bNFSvFY_000111_000121", "video_description": "A person is folding blue paper into origami whales of different sizes while music plays in the background.", "task": "AttributeRecognition", "clean_prompt": "A person folding blue paper into origami whales of different sizes while music plays in the background.", "clean_property": {"obj": "whale", "attribute": "origami"}, "target_prompt": "A person creating metal whales of different sizes while music plays in the background.", "target_property": {"obj": "whale", "attribute": "made of metal"}, "evaluation_question": "Are the whales made of **paper**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding blue paper into origami whales of different sizes while music plays in the background. DP$H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e8b2bdf7fb1946ddb7d9b442607a839f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3e8518c419744155b6e65ecb7be2368e", "source": "vatex", "video_id": "rRPF3HUrANA_000005_000015", "video_description": "A man wearing a black shirt with white stripes is chewing gum and playing with it by stretching it out of his mouth and then pulling it back in.", "task": "ActionRecognition", "clean_prompt": "A person chewing gum and playing with it by stretching it out of his mouth and then pulling it back in.", "clean_property": {"obj": "person", "action": "chewing gum", "target": null}, "target_prompt": "A person blowing bubbles with gum.", "target_property": {"obj": "person", "action": "blowing bubbles", "target": null}, "evaluation_question": "Is the person **chewing gum**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person chewing gum and playing with it by stretching it out of his mouth and then pulling it back in. 6BC2@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9a8ee999e9ff47cba9458dabfc979e4c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8576ecab6f2f4a4cb8d51f5411967bce", "source": "vatex", "video_id": "Y8Ac0C4Gfu0_000100_000110", "video_description": "A young woman is demonstrating and explaining how to play golf, including chipping and putting a golf ball on a golf course.", "task": "AttributeRecognition", "clean_prompt": "A young woman demonstrating how to play golf with a pitching wedge.", "clean_property": {"obj": "golf club", "attribute": "pitching wedge"}, "target_prompt": "A young woman demonstrating how to play golf with a driver.", "target_property": {"obj": "golf club", "attribute": "driver"}, "evaluation_question": "Is the woman using a **pitching wedge**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman demonstrating how to play golf with a pitching wedge. @WL,R", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc615988002e42378b30454b5af2ed88.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f0187e1373f444119d013a61c13d5117", "source": "vatex", "video_id": "98SISSDIh-o_000012_000022", "video_description": "A girls' field hockey team is practicing drills and playing a practice game on a large outdoor field.", "task": "Counting", "clean_prompt": "Three coaches are guiding a girls' field hockey team as they practice drills and play a practice game on a large outdoor field.", "clean_property": {"obj": "coach", "count": "three"}, "target_prompt": "One coach is guiding a girls' field hockey team as they practice drills and play a practice game on a large outdoor field.", "target_property": {"obj": "coach", "count": "one"}, "evaluation_question": "Are there exactly **three** coaches guiding the team?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three coaches are guiding a girls' field hockey team as they practice drills and play a practice game on a large outdoor field. AN.!)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fbd969c1dd9d42a682d54610087b15fe.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8710f8a16fde4a8aafbb85f316880820", "source": "vatex", "video_id": "r9vWNjeDh7A_000153_000163", "video_description": "Two women are performing a musical piece in a music hall. One woman is singing while the other plays a stringed instrument, possibly a lute or banjo, while both are seated.", "task": "AttributeRecognition", "clean_prompt": "Two women performing a musical piece in a music hall, one singing while the other plays a stringed instrument, possibly a lute or banjo.", "clean_property": {"obj": "stringed instrument", "attribute": "lute or banjo"}, "target_prompt": "Two women performing a musical piece in a music hall, one singing while the other plays an electric guitar.", "target_property": {"obj": "stringed instrument", "attribute": "electric guitar"}, "evaluation_question": "Is the stringed instrument being played a **lute or banjo**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women performing a musical piece in a music hall, one singing while the other plays a stringed instrument, possibly a lute or banjo. !D=!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1c232169c6d94e1eba77760ef62134bd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2f1aaf59faf44399a1d36436f6120fe0", "source": "vatex", "video_id": "tlPLdpJF86g_000046_000056", "video_description": "A large group of people, including children, are singing Christmas carols while standing in a formation resembling a Christmas tree. They are swaying back and forth on a pyramid-shaped platform outdoors.", "task": "ActionRecognition", "clean_prompt": "A singer singing Christmas carols outdoors with a large group of people.", "clean_property": {"obj": "singer", "action": "singing", "target": null}, "target_prompt": "A singer dancing outdoors with a large group of people.", "target_property": {"obj": "singer", "action": "dancing", "target": null}, "evaluation_question": "Is the singer **singing** Christmas carols?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A singer singing Christmas carols outdoors with a large group of people. QCK9I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/acf9d9281b524e999b2b316f2d28ec21.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a18bde1c9c644b01b65c3712cc0c5a19", "source": "vatex", "video_id": "WQ58WGN0208_000016_000026", "video_description": "A man is demonstrating how to carve pumpkins into jack-o'-lanterns using stencils, markers, and knives, with music playing in the background.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating how to carve pumpkins using a marker.", "clean_property": {"obj": "marker"}, "target_prompt": "A man demonstrating how to paint pumpkins using a paintbrush.", "target_property": {"obj": "paintbrush"}, "evaluation_question": "Is the man using a **marker** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating how to carve pumpkins using a marker. F/M!)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f4f69953b4144c568fc7f5157634c272.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1340c04ae1c642908d5b44998f75edc6", "source": "vatex", "video_id": "bdCJ69JY2ro_000078_000088", "video_description": "A woman is washing a large dog in a bathtub using soap, while a man stands behind her, talking and offering guidance.", "task": "AttributeRecognition", "clean_prompt": "A woman wearing an apron is washing a large dog in a bathtub.", "clean_property": {"obj": "woman", "attribute": "wearing apron"}, "target_prompt": "A woman wearing a swimsuit is washing a large dog in a bathtub.", "target_property": {"obj": "woman", "attribute": "wearing a swimsuit"}, "evaluation_question": "Is the woman wearing an **apron**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman wearing an apron is washing a large dog in a bathtub. MT$XG", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a6f8b6a658b24fc181db0a4e2a6d0276.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "470435c5f0ca46fa9708e864072f89c6", "source": "vatex", "video_id": "jVy0lNWp2xw_000004_000014", "video_description": "A group of people are in a wooded area, shoveling dirt into a sifting device held by others, who rock it to sift the dirt.", "task": "Counting", "clean_prompt": "Six people are in a wooded area, shoveling dirt into a sifting device held by others, who rock it to sift the dirt.", "clean_property": {"obj": "person", "count": "six"}, "target_prompt": "Three people are in a sandy beach area, shoveling sand into a sifting device held by others, who rock it to sift the sand.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **six** people in the wooded area?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six people are in a wooded area, shoveling dirt into a sifting device held by others, who rock it to sift the dirt. >#0BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7314df812c8e42789d10c158d779ed68.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a6e848aa7e1b4a43a744a3adb509fd19", "source": "vatex", "video_id": "UfFHCnV2N90_000024_000034", "video_description": "A person practices calligraphy by writing the word 'October' on a piece of white paper using a green pen.", "task": "AttributeRecognition", "clean_prompt": "A person practicing calligraphy by writing the word 'October' on a piece of white paper using a green pen.", "clean_property": {"obj": "paper", "attribute": "white"}, "target_prompt": "A person practicing calligraphy by writing the word 'October' on a piece of blue paper using a green pen.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing calligraphy by writing the word 'October' on a piece of white paper using a green pen. AQ!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb646fb4bd5344c0a781c22757dbae99.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6674a20c9f7b4e32aa15439c5a187696", "source": "vatex", "video_id": "Cb9jmjCp0sg_000028_000038", "video_description": "A woman in a striped jacket is pushing an empty wheelchair through the snow, occasionally stopping to talk to an unseen person.", "task": "Counting", "clean_prompt": "A woman in a striped jacket is pushing seven empty wheelchairs through the snow, occasionally stopping to talk to an unseen person.", "clean_property": {"obj": "wheelchair", "count": "seven"}, "target_prompt": "A woman in a striped jacket is pushing three empty wheelchairs through the snow, occasionally stopping to talk to an unseen person.", "target_property": {"obj": "wheelchair", "count": "three"}, "evaluation_question": "Are there exactly **seven** wheelchairs being pushed through the snow?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a striped jacket is pushing seven empty wheelchairs through the snow, occasionally stopping to talk to an unseen person. LY%.P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c3d30dc36a0438d845defd03201b3fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7e1ec42c4fd048d48f09aadeb47d09f7", "source": "vatex", "video_id": "LAx9oAvCugA_000103_000113", "video_description": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing Monopoly.", "task": "SpatialUnderstanding", "clean_prompt": "A boy farther from the camera than a Monopoly game on the dining room table.", "clean_property": {"obj_1": "boy", "relation": "farther from the camera than", "obj_2": "monopoly"}, "target_prompt": "A boy closer to the camera than a Monopoly game on the dining room table.", "target_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "Monopoly"}, "evaluation_question": "Is the boy **farther from the camera than** the Monopoly game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy farther from the camera than a Monopoly game on the dining room table. SL+)S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/620fb3ced5574463b633b3826f567924.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "31a8cb5a157f486588ae025c7cc11974", "source": "vatex", "video_id": "G571V9l2iT4_000095_000105", "video_description": "A young man is demonstrating how to properly tie and untie a necktie in a room.", "task": "Counting", "clean_prompt": "Four people in a room demonstrating how to properly tie and untie a necktie.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person in a room demonstrating how to properly tie and untie a necktie.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people in a room demonstrating how to properly tie and untie a necktie. 9QFOV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c2de1ac952ee4f99a1945e06d989e05f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "30c9601d47e04c0d931b164bbc8d166e", "source": "vatex", "video_id": "XXQZz6FuEYI_000183_000193", "video_description": "A man is in a gym demonstrating exercises using a sledgehammer, swinging it behind and in front of him.", "task": "Counting", "clean_prompt": "Five people in a gym demonstrating exercises with a sledgehammer, swinging it behind and in front of them.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person in a gym demonstrating exercises with a sledgehammer, swinging it behind and in front of them.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people in a gym demonstrating exercises with a sledgehammer, swinging it behind and in front of them. )!0!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ae0219f8bc5841c5a4bf9da309a0bb3b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce473e2962fd413a9a97cedb40cbc33d", "source": "vatex", "video_id": "MVFcxo-Pnq8_000169_000179", "video_description": "A man in a black suit performs a sword swallowing trick in an office setting. A woman assists by pulling the sword out of his mouth while a crowd claps and cheers.", "task": "AttributeRecognition", "clean_prompt": "A man in a black suit performs a sword swallowing trick with a long sword in an office setting.", "clean_property": {"obj": "sword", "attribute": "long"}, "target_prompt": "A man in a black suit performs a sword swallowing trick with a short sword in an office setting.", "target_property": {"obj": "sword", "attribute": "short"}, "evaluation_question": "Is the sword being used in the trick **long**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a black suit performs a sword swallowing trick with a long sword in an office setting. )!0'B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/24cf37b2e5874a149ffecfee36b88ac9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46b2a4aebfaa457d8fdfd1731cd2bc93", "source": "vatex", "video_id": "wywuio4R1LY_000053_000063", "video_description": "A man is inside a building using a heat gun to remove and lay floor tiles, providing advice on the process.", "task": "SpatialUnderstanding", "clean_prompt": "A heat gun positioned farther from the camera than a person inside a building.", "clean_property": {"obj_1": "heat gun", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A heat gun positioned closer to the camera than a person inside a building.", "target_property": {"obj_1": "heat gun", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the heat gun farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A heat gun positioned farther from the camera than a person inside a building. )BADX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5fe4654498994b3b99040b111c6028ae.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c653c8137834f1fb068f57ea2715398", "source": "vatex", "video_id": "hsxpSVlqmsQ_000002_000012", "video_description": "A person is demonstrating how to cook a cobbler using a Dutch oven on a campfire.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a Dutch oven on a campfire.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "dutch oven"}, "target_prompt": "A person standing to the right of a Dutch oven on a campfire.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "Dutch oven"}, "evaluation_question": "Is the person to the **left** of the Dutch oven?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a Dutch oven on a campfire. FE+VV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4065ad6725e24e79adf107ea9a47efcd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "51fee38affd54d44939f9b9e2ed34b3f", "source": "vatex", "video_id": "ad8VP_08yLw_000000_000010", "video_description": "A young boy is sitting in a plastic chair inside a room, practicing and playing rhythms on a large drum set with cymbals.", "task": "ObjectRecognition", "clean_prompt": "A young boy is sitting in a plastic chair inside a room, practicing and playing rhythms on a large drum set with cymbals.", "clean_property": {"obj": "drum set"}, "target_prompt": "A young boy is sitting in a plastic chair inside a room, practicing and playing melodies on a large piano.", "target_property": {"obj": "piano"}, "evaluation_question": "Is the boy playing a **drum set**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is sitting in a plastic chair inside a room, practicing and playing rhythms on a large drum set with cymbals. LYVNJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3185db9add1a4583b492e60229ae6ec3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "59b8d1493a694c02b26000eb65f4174d", "source": "vatex", "video_id": "OiQykGyt2Fk_000095_000105", "video_description": "A woman is demonstrating and explaining how to roll sushi using a bamboo mat and cellophane.", "task": "ActionRecognition", "clean_prompt": "A person making sushi using a bamboo mat and cellophane.", "clean_property": {"obj": "person", "action": "making sushi", "target": null}, "target_prompt": "A person eating sushi at a dining table.", "target_property": {"obj": "person", "action": "eating sushi", "target": null}, "evaluation_question": "Is the person **making** sushi?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person making sushi using a bamboo mat and cellophane. RLTN(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8e63e42bd2a04d6788235a9154be792a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1c5eeba08d26487abf0a3f7daa5d4d8f", "source": "vatex", "video_id": "0FDVa0TOc3A_000000_000010", "video_description": "A woman in gym clothes is climbing a rope hanging from the ceiling in a fitness room, while a man encourages her.", "task": "ObjectRecognition", "clean_prompt": "A woman in gym clothes is climbing a rope hanging from the ceiling in a fitness room, while a man encourages her.", "clean_property": {"obj": "rope"}, "target_prompt": "A woman in gym clothes is climbing a ladder in a fitness room, while a man encourages her.", "target_property": {"obj": "ladder"}, "evaluation_question": "Is the woman climbing a **rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in gym clothes is climbing a rope hanging from the ceiling in a fitness room, while a man encourages her. UFJJJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/84ade682bf524944bdd2c358d9a3c4c0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8831aefc9a84f5d9fceb9a3f686b3ec", "source": "vatex", "video_id": "f9R3_O_PSls_000044_000054", "video_description": "In a professional office, a man with glasses is sitting in a chair and using a knife to skin a pineapple over a trash can.", "task": "ActionRecognition", "clean_prompt": "A person cutting a pineapple in a professional office.", "clean_property": {"obj": "person", "action": "cutting pineapple", "target": null}, "target_prompt": "A person throwing a pineapple in a professional office.", "target_property": {"obj": "person", "action": "throwing pineapple", "target": null}, "evaluation_question": "Is the person **cutting** a pineapple?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cutting a pineapple in a professional office. ''!*-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0d6fb5b352454036a6cde0a975d727cd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9423fc62f04a439ea8c3b3285e353ce8", "source": "vatex", "video_id": "KHHmcaqHH6I_000073_000083", "video_description": "A man is demonstrating and explaining techniques for pouring, swirling, and evaluating wine.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a wine bottle while demonstrating pouring techniques.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "wine"}, "target_prompt": "A person standing to the left of a wine bottle while demonstrating pouring techniques.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "wine"}, "evaluation_question": "Is the person to the **right** of the wine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a wine bottle while demonstrating pouring techniques. =$MCS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6bb2d25735cf4d2abf106aebf13f5783.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eda52f783d99454f9e9ff91c8a8efd5c", "source": "vatex", "video_id": "DUALGvqL5UA_000056_000066", "video_description": "A woman is demonstrating how to play a gong by speaking and then hitting it with a mallet to produce sound.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to play a gong by speaking and then hitting it with a mallet to produce sound.", "clean_property": {"obj": "gong"}, "target_prompt": "A woman demonstrating how to play a drum by speaking and then hitting it with a mallet to produce sound.", "target_property": {"obj": "drum"}, "evaluation_question": "Is the object being played in the video a **gong**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to play a gong by speaking and then hitting it with a mallet to produce sound. ;N)TL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7b7feea4213d435393910f1ff6b44d9f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0f164214154f496888d13a5dd684cc19", "source": "vatex", "video_id": "3gJT6JIisw0_000021_000031", "video_description": "A man is riding a donkey down a dirt road while a black dog follows behind. A woman is narrating about the benefits of donkeys and mules.", "task": "ActionRecognition", "clean_prompt": "A man riding a mule down a dirt road.", "clean_property": {"obj": "man", "action": "riding mule", "target": null}, "target_prompt": "A man walking beside a mule down a dirt road.", "target_property": {"obj": "man", "action": "walking beside mule", "target": null}, "evaluation_question": "Is the man **riding** a mule?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man riding a mule down a dirt road. >4Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/263ce32c57fc4aaba5fe53f7405204c0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "35de3e7b61c240f0a61a5372ed28d1a2", "source": "vatex", "video_id": "Ea_Wr5Lt3lc_000022_000032", "video_description": "A group of people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering.", "task": "Counting", "clean_prompt": "Seven people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering.", "clean_property": {"obj": "people", "count": "seven"}, "target_prompt": "Four people are in a small boat sailing on a calm lake, enjoying the scenery and taking photos.", "target_property": {"obj": "people", "count": "four"}, "evaluation_question": "Are there exactly **seven** people in the amphibious vehicle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are in an amphibious vehicle driving through a river, transitioning onto land, and cheering. =A$XS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/92fbfac4c0784a74b19da765ee058060.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce615bc8be8045c38f0acae16528319b", "source": "vatex", "video_id": "ooQ640FIlMU_000044_000054", "video_description": "A man is discussing and displaying exotic rocks on a table, including two black and two white rocks, while also showing different tools.", "task": "AttributeRecognition", "clean_prompt": "A man discussing and displaying exotic rocks on a table, including two black rocks.", "clean_property": {"obj": "rock", "attribute": "black"}, "target_prompt": "A man discussing and displaying exotic rocks on a table, including two white rocks.", "target_property": {"obj": "rock", "attribute": "white"}, "evaluation_question": "Are there any **black** rocks on the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man discussing and displaying exotic rocks on a table, including two black rocks. SL8;T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f673850b33fa4c398284cae4ce98b171.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd3ad6fe80b242c6b63bccfc721ffeb9", "source": "vatex", "video_id": "nTI5QpazQlo_000020_000030", "video_description": "A man is in a kitchen demonstrating and using an electric pencil sharpener to sharpen pencils.", "task": "Counting", "clean_prompt": "Three people in a kitchen demonstrating an electric pencil sharpener to sharpen pencils.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in a kitchen demonstrating an electric pencil sharpener to sharpen pencils.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in a kitchen demonstrating an electric pencil sharpener to sharpen pencils. !9*9:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e7a24b7737bc43a693cdcf00a7f542c6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "956c37da977e4f34a4205e2df8b37db8", "source": "vatex", "video_id": "X2Qn08i-I48_000062_000072", "video_description": "A man is playing a song on a trumpet in a dimly lit room.", "task": "ActionRecognition", "clean_prompt": "A person playing trumpet in a dimly lit room.", "clean_property": {"obj": "person", "action": "playing trumpet", "target": null}, "target_prompt": "A person playing guitar in a dimly lit room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing trumpet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing trumpet in a dimly lit room. FE@AI", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/408c0220d2224e44bbe84bbbc33c84ed.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "04ed8020008d4ec5b78a166103a0c9de", "source": "vatex", "video_id": "aXzZfGsfSWQ_000004_000014", "video_description": "A woman wearing a costume with animal ears and a tail bends backwards, demonstrating flexibility, while a man talks and a cameraman records.", "task": "SpatialUnderstanding", "clean_prompt": "A man farther from the camera than a cameraman.", "clean_property": {"obj_1": "man", "relation": "farther from the camera than", "obj_2": "cameraman"}, "target_prompt": "A man closer to the camera than a cameraman.", "target_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "cameraman"}, "evaluation_question": "Is the man **farther from the camera than** the cameraman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man farther from the camera than a cameraman. )!/!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/71bc9bf14c9745e7a67c14393d9e5867.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b7f46a9e2ec42dab44cc74ff92bd257", "source": "vatex", "video_id": "x2Acp2ys0QQ_000094_000104", "video_description": "A woman is sitting on the bathroom floor, installing an automatic cleaning device on a toilet.", "task": "AttributeRecognition", "clean_prompt": "A woman is sitting on the bathroom floor, installing a cleaning device made of plastic on a toilet.", "clean_property": {"obj": "cleaning device", "attribute": "plastic"}, "target_prompt": "A woman is sitting on the bathroom floor, installing a cleaning device made of metal on a toilet.", "target_property": {"obj": "cleaning device", "attribute": "metal"}, "evaluation_question": "Is the cleaning device made of **plastic**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is sitting on the bathroom floor, installing a cleaning device made of plastic on a toilet. FE1&J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/baf7735afb28495c89bda30f2e2cf395.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5d12cd023b2c4971960e097c9c8234e8", "source": "vatex", "video_id": "0Fd6dxtroLs_000024_000034", "video_description": "A man is demonstrating exercises using a sledgehammer, including doing push-ups while balancing on the hammer.", "task": "ObjectRecognition", "clean_prompt": "A man demonstrating exercises with a sledgehammer, including push-ups while balancing on the hammer.", "clean_property": {"obj": "person"}, "target_prompt": "A woman demonstrating exercises with a sledgehammer, including push-ups while balancing on the hammer.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man demonstrating exercises with a sledgehammer, including push-ups while balancing on the hammer. )!D|!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/21f5ea04cc58476fb0dabec71c8a9146.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "847e79e3dba842a4a0ce1bc716668299", "source": "vatex", "video_id": "a0P6wn0jyU8_000000_000010", "video_description": "Two young girls are sitting on a recliner chair. One girl releases the footrest, causing the other girl to fall to the floor.", "task": "Counting", "clean_prompt": "Two young girls are sitting on a recliner chair.", "clean_property": {"obj": "recliner chair", "count": "two"}, "target_prompt": "One young girl is sitting on a recliner chair.", "target_property": {"obj": "recliner chair", "count": "one"}, "evaluation_question": "Are there exactly **two** recliner chairs in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young girls are sitting on a recliner chair. )!0*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b57fe2c521b9482cb2e7f9d5c0d3206f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c0bb140b898149149ac9b3ccfc649f04", "source": "vatex", "video_id": "8NyxkE-Vtws_000023_000033", "video_description": "A female softball player is on a baseball field practicing fielding. She catches a ground ball with a glove and throws it to another player.", "task": "ActionRecognition", "clean_prompt": "A female softball player catching a ground ball on a baseball field.", "clean_property": {"obj": "softball player", "action": "catching or throwing softball", "target": "ball"}, "target_prompt": "A female softball player hitting a softball with a bat on a baseball field.", "target_property": {"obj": "softball player", "action": "hitting softball", "target": "bat"}, "evaluation_question": "Is the softball player **catching** a ground ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female softball player catching a ground ball on a baseball field. @X+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2eda41f0506e410aa690d1521e39cc4e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b15d654920d2403c805b59411c38c064", "source": "vatex", "video_id": "2Xk8Ax1rQcA_000000_000010", "video_description": "A person demonstrates how to sharpen a pencil using a manual pencil sharpener.", "task": "Counting", "clean_prompt": "A person demonstrates how to sharpen five pencils using a manual pencil sharpener.", "clean_property": {"obj": "pencil sharpener", "count": "five"}, "target_prompt": "A person demonstrates how to sharpen one pencil using a manual pencil sharpener.", "target_property": {"obj": "pencil sharpener", "count": "one"}, "evaluation_question": "Are there exactly **five** pencil sharpeners being used?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrates how to sharpen five pencils using a manual pencil sharpener. 9EPFF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0692a775d6d9449d93c9233264f75129.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ee449357a10f41ddbf1a17b6ad723598", "source": "vatex", "video_id": "32wivWSlBb4_000000_000010", "video_description": "A doctor, wearing a lab coat, is performing a neck adjustment on a seated woman in a busy store setting.", "task": "ObjectRecognition", "clean_prompt": "A doctor wearing a lab coat is performing a neck adjustment on a seated woman in a busy store setting.", "clean_property": {"obj": "doctor"}, "target_prompt": "A chef preparing a meal in a busy restaurant kitchen.", "target_property": {"obj": "chef"}, "evaluation_question": "Is the professional in the video a **doctor**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A doctor wearing a lab coat is performing a neck adjustment on a seated woman in a busy store setting. &FESX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/12fd20f46a1a4ee6acd982b8d291c214.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fb65011b1f8f4376b57e81fc64e36e05", "source": "vatex", "video_id": "Wg84uh--RYc_000008_000018", "video_description": "A toddler is climbing a small three-step ladder indoors, occasionally looking around and talking.", "task": "Counting", "clean_prompt": "A toddler is climbing two small three-step ladders indoors, occasionally looking around and talking.", "clean_property": {"obj": "ladder", "count": "two"}, "target_prompt": "A toddler is climbing one small three-step ladder indoors, occasionally looking around and talking.", "target_property": {"obj": "ladder", "count": "one"}, "evaluation_question": "Are there exactly **two** ladders in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A toddler is climbing two small three-step ladders indoors, occasionally looking around and talking. 0BC2@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/192d4a9396e64b48a001d2635a27c184.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "02c9c977606543a68e1e581b45d216a9", "source": "vatex", "video_id": "agS5OU-9E7s_000433_000443", "video_description": "A man in an orange shirt stands in a kitchen demonstrating how to make balloon art by twisting balloons into various shapes, including animals.", "task": "SpatialUnderstanding", "clean_prompt": "A balloon is positioned to the left of a person in an orange shirt demonstrating balloon art in a kitchen.", "clean_property": {"obj_1": "balloon", "relation": "left of", "obj_2": "person"}, "target_prompt": "A balloon is positioned to the right of a person in an orange shirt demonstrating balloon art in a kitchen.", "target_property": {"obj_1": "balloon", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the balloon to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A balloon is positioned to the left of a person in an orange shirt demonstrating balloon art in a kitchen. >EZJE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b9f441831334a799564576e420b36e4.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "abc8f3be50c04923adf8ce259b882e39", "source": "vatex", "video_id": "zc1FyinCZPU_000000_000010", "video_description": "A man is sitting outside on a patio or deck, laughing and joking as a woman gives him a short haircut with clippers, while another woman and a man watch.", "task": "ObjectRecognition", "clean_prompt": "A man sitting outside on a patio, laughing and joking as a woman gives him a short haircut with clippers.", "clean_property": {"obj": "man"}, "target_prompt": "A woman sitting outside on a patio, laughing and joking as another woman gives her a short haircut with clippers.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person getting a haircut in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sitting outside on a patio, laughing and joking as a woman gives him a short haircut with clippers. >UME)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/194c3a5bacaf47e58294716c26ff87bb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d07202e55a4943bd9d9e99e7a663f7b3", "source": "vatex", "video_id": "xgsMwJ6LJ24_000003_000013", "video_description": "A young girl is riding and dancing on a hoverboard in her living room, listening to hip hop music.", "task": "SpatialUnderstanding", "clean_prompt": "A girl farther from the camera than a hoverboard.", "clean_property": {"obj_1": "girl", "relation": "farther from the camera than", "obj_2": "hoverboard"}, "target_prompt": "A girl closer to the camera than a hoverboard.", "target_property": {"obj_1": "girl", "relation": "closer to the camera than", "obj_2": "hoverboard"}, "evaluation_question": "Is the girl **farther from the camera than** the hoverboard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl farther from the camera than a hoverboard. )!B*|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d42d703d6c444e7dac2ad8b201a9909e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "39f6c6fda48b4333b5c841c2a1beb877", "source": "vatex", "video_id": "0fZrbXGkLBU_000076_000086", "video_description": "A man in construction gear demonstrates and explains how to lay bricks and apply mortar to build a wall.", "task": "AttributeRecognition", "clean_prompt": "A man in construction gear demonstrates how to apply wet mortar to build a wall.", "clean_property": {"obj": "mortar", "attribute": "wet"}, "target_prompt": "A man in construction gear demonstrates how to apply dry mortar to build a wall.", "target_property": {"obj": "mortar", "attribute": "dry"}, "evaluation_question": "Is the mortar **wet** during the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in construction gear demonstrates how to apply wet mortar to build a wall. ''');", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b6d48270632a4e5b9d06beee5f37964e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "20d44a56e8ce47109d95b83b522cc0b9", "source": "vatex", "video_id": "cUSjW6jh84M_000000_000010", "video_description": "A man is attempting to throw trash bags into a green garbage truck, sometimes missing and causing trash to spill.", "task": "AttributeRecognition", "clean_prompt": "A man is attempting to throw trash bags into a green garbage truck, sometimes missing and causing trash to spill.", "clean_property": {"obj": "garbage truck", "attribute": "green"}, "target_prompt": "A man is attempting to throw trash bags into a red garbage truck, sometimes missing and causing trash to spill.", "target_property": {"obj": "garbage truck", "attribute": "red"}, "evaluation_question": "Is the garbage truck **green**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is attempting to throw trash bags into a green garbage truck, sometimes missing and causing trash to spill. X;LFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c9c0a286621243bbb22ad78066f475b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "381e693022384627a420010fd5fe6e02", "source": "vatex", "video_id": "jsltYtLEKoY_000005_000015", "video_description": "A man performs a sword swallowing act, where he swallows a sword, does a push-up, and then removes the sword from his mouth.", "task": "SpatialUnderstanding", "clean_prompt": "A sword farther from the camera than a person performing a sword swallowing act.", "clean_property": {"obj_1": "sword", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A sword closer to the camera than a person performing a sword swallowing act.", "target_property": {"obj_1": "sword", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the sword **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sword farther from the camera than a person performing a sword swallowing act. ))!%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/10718028e01e43d38ddfd9ce20e93b1d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "255817553e4b47159bbc963953cb048a", "source": "vatex", "video_id": "atLO_DGRq4M_000051_000061", "video_description": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "task": "ObjectRecognition", "clean_prompt": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "clean_property": {"obj": "knife"}, "target_prompt": "A woman is demonstrating how to serve ice cream using a spoon in a kitchen.", "target_property": {"obj": "spoon"}, "evaluation_question": "Is the woman using a **knife** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board. -SL;A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/958cbaa592c341f3a060455cd8ca0e61.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7b79cfbb45b545dbb14a9253ca81ad5f", "source": "vatex", "video_id": "ZAqjBqYjjqo_000047_000057", "video_description": "A group of people are in a desert setting, some riding camels while others are on the ground watching, talking, and taking photos.", "task": "ObjectRecognition", "clean_prompt": "A person in a desert setting, riding a camel while others are watching and taking photos.", "clean_property": {"obj": "person"}, "target_prompt": "An animal in a desert setting, with some camels walking while others are being photographed.", "target_property": {"obj": "animal"}, "evaluation_question": "Is there a **person** riding a camel in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person in a desert setting, riding a camel while others are watching and taking photos. SBB,U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/29dd741ffa0f479c9cfe1f2064f2b183.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "36e7bd8dc68646ffa432db0ea4a18d78", "source": "vatex", "video_id": "f8ahDlvAAhc_000007_000017", "video_description": "A man in a gymnasium is climbing a rope using only his hands, ascending to the top and then descending.", "task": "Counting", "clean_prompt": "Seven people are cheering in a gymnasium as a man climbs a rope using only his hands.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are cheering in a gymnasium as a man climbs a rope using only his hands.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people cheering in the gymnasium?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are cheering in a gymnasium as a man climbs a rope using only his hands. EFSAH", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a61bef2e1a64e60b81fd69e4b8cba84.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c57c83e6e38b4a42a7490f375fca7ec0", "source": "vatex", "video_id": "QgWqXNe-4Ac_000134_000144", "video_description": "A man is in a workshop using a large machine to trim and shape large pieces of wood into smaller planks.", "task": "AttributeRecognition", "clean_prompt": "A man in a workshop using a large machine to trim and shape a wooden slab into smaller planks.", "clean_property": {"obj": "wood", "attribute": "wooden slab"}, "target_prompt": "A man in a workshop using a large machine to trim and shape a bamboo slab into smaller planks.", "target_property": {"obj": "wood", "attribute": "bamboo"}, "evaluation_question": "Is the object being shaped a **wooden** slab?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in a workshop using a large machine to trim and shape a wooden slab into smaller planks. FEYU@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2f669b1e943d4ef79aff80eadac5bf3c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "01e364383e104a9c9ecace3dbc815128", "source": "vatex", "video_id": "aJTF-3Gno6g_000006_000016", "video_description": "A woman is performing a slow sit-up exercise on the ground, repeatedly lying back and sitting up to touch her toes.", "task": "ObjectRecognition", "clean_prompt": "A woman performing a slow sit-up exercise on the ground, repeatedly lying back and sitting up to touch her toes.", "clean_property": {"obj": "person"}, "target_prompt": "A dog playing on the ground, rolling over and stretching.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman performing a slow sit-up exercise on the ground, repeatedly lying back and sitting up to touch her toes. FS7BR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2d78309fb2ab4a85af80a68d8d8d5fa0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2001b336d6ef47c4af32d3b008b3698a", "source": "vatex", "video_id": "s7qkYZTezYs_000002_000012", "video_description": "A person is cleaning a poorly kept toilet using a toilet brush while wearing gloves.", "task": "SpatialUnderstanding", "clean_prompt": "A person cleaning a toilet that is farther from the camera than the person.", "clean_property": {"obj_1": "toilet", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A person cleaning a toilet that is closer to the camera than the person.", "target_property": {"obj_1": "toilet", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the toilet farther from the camera than the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person cleaning a toilet that is farther from the camera than the person. RLQQJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6cf60c1ec32c4ce29b2eb6166a0538d6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7af4b60900d94eaaa54463c82684c25f", "source": "vatex", "video_id": "BuMiSsvP2pE_000001_000011", "video_description": "A group of people are practicing and playing curling inside an ice rink. Teams participate in a curling match, using brush sticks to slide stones towards targets on the ice. Some people are skating on the ice while others focus on the curling game.", "task": "AttributeRecognition", "clean_prompt": "A group of people are practicing and playing curling inside an ice rink.", "clean_property": {"obj": "people", "attribute": "athletes"}, "target_prompt": "A group of cheerleaders performing a routine inside a gym.", "target_property": {"obj": "people", "attribute": "cheerleaders"}, "evaluation_question": "Are the people in the video **athletes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people are practicing and playing curling inside an ice rink. ))*E-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a18c28c2cf504f6e88d3c26e6660fed4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "da8ef47dea2b40158cf13b5c6fa21cf3", "source": "vatex", "video_id": "v2Hr1CH-yb0_000076_000086", "video_description": "A group of workers are operating machinery and filling bags in a large factory-like warehouse while wearing safety masks and helmets. A young woman occasionally walks by and laughs.", "task": "AttributeRecognition", "clean_prompt": "A chute that is slanted in a large factory-like warehouse where workers are operating machinery and filling bags.", "clean_property": {"obj": "chute", "attribute": "slanted"}, "target_prompt": "A chute that is vertical in a large factory-like warehouse where workers are operating machinery and filling bags.", "target_property": {"obj": "chute", "attribute": "vertical"}, "evaluation_question": "Is the chute **slanted**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chute that is slanted in a large factory-like warehouse where workers are operating machinery and filling bags. Q7XBS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f87868c33530436e901b4100dfd56731.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "af523ef85c884760bd8fa919fb2e400d", "source": "vatex", "video_id": "_ccnthBgkJQ_000084_000094", "video_description": "A woman is demonstrating and explaining how to clip a horse's whiskers using a razor.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a horse while demonstrating how to clip its whiskers.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "horse"}, "target_prompt": "A person standing to the right of a horse while demonstrating how to clip its whiskers.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "horse"}, "evaluation_question": "Is the person to the **left** of the horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a horse while demonstrating how to clip its whiskers. -@)CQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e4e2bf2f0788414b86e6d1213b16e832.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "71627bb609524e38bdabe6870ab41139", "source": "vatex", "video_id": "_IEhvtusy8Y_000021_000031", "video_description": "A person is folding various types of decorative paper, including floral and patterned napkins, into squares while soft music plays in the background.", "task": "Counting", "clean_prompt": "Two people are folding various types of decorative paper, including floral and patterned napkins, into squares while soft music plays in the background.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is folding various types of decorative paper, including floral and patterned napkins, into squares while soft music plays in the background.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people folding the paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are folding various types of decorative paper, including floral and patterned napkins, into squares while soft music plays in the background. -SL;$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61c8d585c1d645c5ae33e45bbd49fa7d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8597cf3d38b24371ba8dda0e40f26cc2", "source": "vatex", "video_id": "TjxHZrX44cA_000000_000010", "video_description": "A person is using a shovel to fill and level sand in a bucket, preparing to make a sandcastle.", "task": "ObjectRecognition", "clean_prompt": "A person using a shovel to fill and level sand in a bucket.", "clean_property": {"obj": "sand"}, "target_prompt": "A person using a shovel to fill and level snow in a bucket.", "target_property": {"obj": "snow"}, "evaluation_question": "Is the material being used in the video **sand**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a shovel to fill and level sand in a bucket. !W%|B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1747392040a842d1911d163033f8f1d2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "66e404cd281d4ba7b4eb3de11f7668c4", "source": "vatex", "video_id": "6BeXjA_Rhgg_000000_000010", "video_description": "In a gymnasium, a group of young women are socializing and practicing high jump. One girl runs and jumps over a high jump bar onto a padded mat.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a padded mat in a gymnasium.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "padded mat"}, "target_prompt": "A person closer to the camera than a padded mat in a gymnasium.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "padded mat"}, "evaluation_question": "Is the person **farther from the camera than** the padded mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a padded mat in a gymnasium. HL1FJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/89cc429142c04c5bb54bf361c98d8b46.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6175478edfd548a2a682aad8ddb80e95", "source": "vatex", "video_id": "OASCPKazLIM_000132_000142", "video_description": "A person is demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table.", "task": "Counting", "clean_prompt": "Three people demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people demonstrating the wrapping process?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table. NIVJJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/48a5b255d76b43b5aeef49a51cb8b867.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "16360caf539b4477b5831b246599f429", "source": "vatex", "video_id": "Nrh0vgGq5hY_000388_000398", "video_description": "A young woman is demonstrating and giving tips on how to apply makeup using various brushes.", "task": "ObjectRecognition", "clean_prompt": "A young woman demonstrating makeup application using various brushes.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with makeup brushes.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman demonstrating makeup application using various brushes. 1=))|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/447ca4070fa047dfa60e781894e4efaf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "958c7defee8d4078861052d8608e8700", "source": "vatex", "video_id": "fAacM8XgJQQ_000000_000010", "video_description": "A group of children, including a little girl in winter clothes, are watching small animals like meerkats and weasels running around in a zoo exhibit behind a glass enclosure.", "task": "AttributeRecognition", "clean_prompt": "A group of children watching small animals like meerkats and weasels in a zoo exhibit.", "clean_property": {"obj": "animal", "attribute": "small"}, "target_prompt": "A group of children watching large animals like lions and bears in a zoo exhibit.", "target_property": {"obj": "animal", "attribute": "large"}, "evaluation_question": "Are the animals being watched by the children **small**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children watching small animals like meerkats and weasels in a zoo exhibit. LF7>T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/78298ddfb87c486bb1d7e69dbf1af82f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bd31f46beb57402abf9d1e194ab57e74", "source": "vatex", "video_id": "vLVriglUlpc_000193_000203", "video_description": "Two young boys are sitting on the floor in a room, playing with fidget spinner toys and superhero action figures, discussing their favorite toys.", "task": "AttributeRecognition", "clean_prompt": "Two young boys are sitting on the floor in a room, playing with superhero action figures.", "clean_property": {"obj": "action figure", "attribute": "superhero"}, "target_prompt": "Two young boys are sitting on the floor in a room, playing with villain action figures.", "target_property": {"obj": "action figure", "attribute": "villain"}, "evaluation_question": "Are the boys playing with **superhero** action figures?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys are sitting on the floor in a room, playing with superhero action figures. )?B%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/385ba0d1fb844b87812c494a827afbb2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c8ed8afa5bc448194e4b05e8c6bf134", "source": "vatex", "video_id": "6lEnqtxCuOs_000005_000015", "video_description": "A kid's hockey game is taking place at an indoor arena with sparse attendance. Two junior teams are playing against each other while people watch from the stands.", "task": "ObjectRecognition", "clean_prompt": "A spectator watching a kid's hockey game in an indoor arena.", "clean_property": {"obj": "spectator"}, "target_prompt": "A player skating on the ice during a kid's hockey game.", "target_property": {"obj": "player"}, "evaluation_question": "Is the person in the video a **spectator**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A spectator watching a kid's hockey game in an indoor arena. DPZQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64cbf564f6af4b8fbb09eb2a6098a57f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e42fd1b1502846c4a7a83ee0a7f2551c", "source": "vatex", "video_id": "R2FHFNoyVd4_000086_000096", "video_description": "A group of men are playing a sport on an outdoor field using sticks and a ball, demonstrating the Irish game 'hurling'.", "task": "Counting", "clean_prompt": "Three men playing hurling on an outdoor field with a ball.", "clean_property": {"obj": "ball", "count": "three"}, "target_prompt": "Three men playing hurling on an outdoor field with one ball.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **three** balls being used in the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three men playing hurling on an outdoor field with a ball. /)!%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/600de2305ed74363987ee648bf09317c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6e7b24aeefde46efa4ec5892a6444123", "source": "vatex", "video_id": "wPUeRxWYMPE_000050_000060", "video_description": "A doctor is demonstrating and explaining how to bandage a young man's head.", "task": "SpatialUnderstanding", "clean_prompt": "A doctor standing to the right of a young man while demonstrating how to bandage his head.", "clean_property": {"obj_1": "doctor", "relation": "right of", "obj_2": "young man"}, "target_prompt": "A doctor standing to the left of a young man while demonstrating how to bandage his head.", "target_property": {"obj_1": "doctor", "relation": "left of", "obj_2": "young man"}, "evaluation_question": "Is the doctor to the **right** of the young man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A doctor standing to the right of a young man while demonstrating how to bandage his head. \u00b7F)?B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0143d9d1537c4623bb44257c578f6efb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "caabeb4cf5e4404dadd132fd8edd38e8", "source": "vatex", "video_id": "T8fXPNh7u_M_000000_000010", "video_description": "A woman is performing sit-ups on a yoga mat on a rooftop with a view of tall buildings.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a yoga mat.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "yoga mat"}, "target_prompt": "A person further from the camera than a yoga mat.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "yoga mat"}, "evaluation_question": "Is the person **closer to the camera than** the yoga mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a yoga mat. ))!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cff2a82c22f741a997779e65de55d273.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ce6e1d44496c4f789a6adf72f9613fa5", "source": "vatex", "video_id": "GeG0c-priYo_000000_000010", "video_description": "A group of women in formal dresses are dancing the Macarena on a stage with disco lights and a band playing music.", "task": "ActionRecognition", "clean_prompt": "A woman dancing the Macarena on a stage with disco lights.", "clean_property": {"obj": "woman", "action": "dancing macarena", "target": null}, "target_prompt": "A woman dancing ballet on a stage with bright lights.", "target_property": {"obj": "woman", "action": "dancing ballet", "target": null}, "evaluation_question": "Is the woman **dancing the Macarena**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman dancing the Macarena on a stage with disco lights. !LFRF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0918b69fe173457096a4f2ac2e9a6d0f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6951fb180bc8400b81128f534333dd0b", "source": "vatex", "video_id": "N211QZ5qIag_000077_000087", "video_description": "A person is using a small printer to print out a piece of paper with their identification on it.", "task": "ActionRecognition", "clean_prompt": "A person photocopying a piece of paper.", "clean_property": {"obj": "person", "action": "photocopying", "target": "paper"}, "target_prompt": "A person shredding a piece of paper.", "target_property": {"obj": "person", "action": "shredding", "target": "paper"}, "evaluation_question": "Is the person **photocopying** a piece of paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person photocopying a piece of paper. RL$JC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd447c0c2357497aac46f41307e5feb1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e83307f96a684c57bba12875d5e51627", "source": "vatex", "video_id": "X0tG5hbo9AI_000034_000044", "video_description": "A man is helping a young child, who is wearing a harness, jump on a trampoline. The child is strapped with bungee cords for safety.", "task": "ActionRecognition", "clean_prompt": "A child bouncing on a trampoline with a harness.", "clean_property": {"obj": "child", "action": "bouncing on trampoline", "target": null}, "target_prompt": "A child falling off a trampoline.", "target_property": {"obj": "child", "action": "falling off trampoline", "target": null}, "evaluation_question": "Is the child **bouncing** on the trampoline?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child bouncing on a trampoline with a harness. .FEP#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8afee372fd849f09e892b4b37a1bb5d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "52b4d5a12c12485a982a585bcb64efe4", "source": "vatex", "video_id": "-F4yRGCrKhk_000043_000053", "video_description": "A woman is lying in bed with a young boy sleeping beside her. She has a book over her face, which she removes while trying not to wake the child.", "task": "ObjectRecognition", "clean_prompt": "A woman lying in bed with a young boy sleeping beside her, reading a book quietly.", "clean_property": {"obj": "woman"}, "target_prompt": "A man lying in bed with a young girl sleeping beside him, reading a newspaper quietly.", "target_property": {"obj": "man"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman lying in bed with a young boy sleeping beside her, reading a book quietly. !G*F-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfbad28028c14c4684ae2432f6d3b409.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5e342c6480e740c9a42f2ef0d7bb8320", "source": "vatex", "video_id": "rih-Z4hyeOw_000424_000434", "video_description": "A welder is working in a welding studio, using a machine to weld and cut metal, creating sparks.", "task": "ObjectRecognition", "clean_prompt": "A welder is working in a welding studio, using a machine to weld and cut metal, creating sparks.", "clean_property": {"obj": "welder"}, "target_prompt": "A painter is creating a mural on a large canvas in a bright studio.", "target_property": {"obj": "painter"}, "evaluation_question": "Is the person in the video a **welder**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A welder is working in a welding studio, using a machine to weld and cut metal, creating sparks. LYUOF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e96de02cd5524ecbaa14658e8019f50d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c245b8262bff4bd68b3743409f421d6b", "source": "vatex", "video_id": "oEAl9Xbp4MA_000170_000180", "video_description": "A young boy is demonstrating how to make and fly a paper airplane while sitting at a table in his room.", "task": "SpatialUnderstanding", "clean_prompt": "A boy closer to the camera than a paper airplane.", "clean_property": {"obj_1": "boy", "relation": "closer to the camera than", "obj_2": "paper airplane"}, "target_prompt": "A boy further from the camera than a paper airplane.", "target_property": {"obj_1": "boy", "relation": "further from the camera than", "obj_2": "paper airplane"}, "evaluation_question": "Is the boy **closer to the camera than** the paper airplane?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy closer to the camera than a paper airplane. )BSDX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dfde260f78de4fd9909bf641187abb04.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fbb0ed100c1640de810a979aa30bb590", "source": "vatex", "video_id": "u6SKVk_-uCw_000013_000023", "video_description": "Two adults are attempting to climb a rope ladder on a bouncy house at a carnival. They fall and laugh during the attempt.", "task": "ActionRecognition", "clean_prompt": "An adult laughing while attempting to climb a rope ladder in a bouncy house.", "clean_property": {"obj": "adult", "action": "laughing", "target": null}, "target_prompt": "An adult screaming while attempting to climb a rope ladder in a bouncy house.", "target_property": {"obj": "adult", "action": "screaming", "target": null}, "evaluation_question": "Is the adult **laughing** while climbing the rope ladder?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult laughing while attempting to climb a rope ladder in a bouncy house. FS%N4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/42bdbbda240545528a91fa96108c996b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0743b8c491034a4bb3f6e073186c4759", "source": "vatex", "video_id": "Emwoyf1aorI_000027_000037", "video_description": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide.", "task": "Counting", "clean_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide with seven people watching her.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide with two people watching her.", "target_property": {"obj": "person", "count": "two"}, "evaluation_question": "Are there exactly **seven** people watching her?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates how to knit using large wooden knitting needles and yarn, providing a step-by-step guide with seven people watching her. >LYQF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/625a98e6b4694ce09990339d24232263.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dae8e6b340fd42f1a0bb7ee2df932eee", "source": "vatex", "video_id": "IjKadk2V_Jg_000083_000093", "video_description": "A group of people, including two main individuals, are near a lake and woods, interacting with a large concrete structure covered in graffiti. Some are painting graffiti on the structure, while others are standing or squatting nearby.", "task": "ActionRecognition", "clean_prompt": "A person spray painting on a large concrete structure near a lake.", "clean_property": {"obj": "person", "action": "spray painting", "target": "concrete structure"}, "target_prompt": "A person cleaning a large concrete structure near a lake.", "target_property": {"obj": "person", "action": "cleaning", "target": "concrete structure"}, "evaluation_question": "Is the person **spray painting** on the concrete structure?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person spray painting on a large concrete structure near a lake. !0D0&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/359991769d0f47f9b8330799671dc066.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9b79392d5f5d48a681f511427f24e782", "source": "vatex", "video_id": "JIUnDsaRAvk_000007_000017", "video_description": "Several trapeze artists are practicing aerial routines on multiple trapezes in an open-air setting.", "task": "Counting", "clean_prompt": "Four trapeze artists are practicing aerial routines on multiple trapezes in an open-air setting.", "clean_property": {"obj": "trapeze artist", "count": "four"}, "target_prompt": "One trapeze artist is performing a solo act on a single trapeze in a circus tent.", "target_property": {"obj": "trapeze artist", "count": "one"}, "evaluation_question": "Are there exactly **four** trapeze artists practicing in the open-air setting?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four trapeze artists are practicing aerial routines on multiple trapezes in an open-air setting. MDM1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2e71c820ad27441a894679e3b088d19c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03084fd135844f2e81c0dc28f1a07052", "source": "vatex", "video_id": "j7OpBtPzCsM_000009_000019", "video_description": "A man is welding a large metal object in a workshop, wearing safety gear including a visor. Sparks fly as he works on a pipe structure.", "task": "ObjectRecognition", "clean_prompt": "A man welding a large metal object in a workshop.", "clean_property": {"obj": "welding machine"}, "target_prompt": "A man operating a painting machine in a workshop.", "target_property": {"obj": "painting machine"}, "evaluation_question": "Is the machine being used in the video a **welding machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man welding a large metal object in a workshop. R$$X8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a24bc6c815c4d0d9c17ccaee62baa9f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "635c382d7f554c7c8f3c4f865add9da5", "source": "vatex", "video_id": "SE98Q0WpRps_000096_000106", "video_description": "A man is standing in a house with his dog, holding a leash, and talking about his book on dog training. The scene transitions to show the book while he continues to talk off-camera.", "task": "ActionRecognition", "clean_prompt": "A man talking on a cell phone in a house.", "clean_property": {"obj": "man", "action": "talking on cell phone", "target": null}, "target_prompt": "A man playing with a dog in a house.", "target_property": {"obj": "man", "action": "playing with dog", "target": null}, "evaluation_question": "Is the man **talking on a cell phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man talking on a cell phone in a house. !G%E=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4016a47f1d9647408498ca262e1f4c58.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d6f14cc60ca948bdb6e522fe4863965f", "source": "vatex", "video_id": "tXtLASDaPrY_000026_000036", "video_description": "Two young children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room.", "task": "Counting", "clean_prompt": "Three children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child is playing and riding on a toy vehicle in a living room.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children playing in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children are playing and riding on their toy vehicles, including tricycles and toy cars, in a living room. UMQU\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e872ec11297448509c4d30b399c1a762.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "45f1487f588f45aaa6d8258685e50737", "source": "vatex", "video_id": "NjxF_UXECGY_000331_000341", "video_description": "A woman is lying on a massage table with her eyes closed, receiving a head and scalp massage from another woman.", "task": "SpatialUnderstanding", "clean_prompt": "A woman lying on a massage table with her eyes closed, receiving a head and scalp massage from another woman who is to the right of her.", "clean_property": {"obj_1": "woman_1", "relation": "right of", "obj_2": "woman_2"}, "target_prompt": "A woman lying on a massage table with her eyes closed, receiving a head and scalp massage from another woman who is to the left of her.", "target_property": {"obj_1": "woman_1", "relation": "left of", "obj_2": "woman_2"}, "evaluation_question": "Is the woman who is giving the massage to the **right** of the woman lying on the massage table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman lying on a massage table with her eyes closed, receiving a head and scalp massage from another woman who is to the right of her. &FE@C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9057e9c8fe4240b88935a676f4dc33f6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "55285a6aed5b482b96317ccc4c9e53e5", "source": "vatex", "video_id": "jAu-bQPKJ0o_000103_000113", "video_description": "A man is climbing a steep, rocky cliff face using a rope for safety, while another man watches from below.", "task": "ActionRecognition", "clean_prompt": "A climber rock climbing a steep, rocky cliff face.", "clean_property": {"obj": "climber", "action": "rock climbing", "target": null}, "target_prompt": "A climber bungee jumping off a bridge.", "target_property": {"obj": "climber", "action": "bungee jumping", "target": null}, "evaluation_question": "Is the climber **rock climbing**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A climber rock climbing a steep, rocky cliff face. P#3%M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d415650d395a4c3d8f16f1431d3252dc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fe66c0e9da5a4529abff1a3260e62ca6", "source": "vatex", "video_id": "FLhNVUgSHNQ_000031_000041", "video_description": "A young man is riding a skateboard down a road, performing tricks and adjusting his hat.", "task": "SpatialUnderstanding", "clean_prompt": "A hat positioned to the left of a person riding a skateboard.", "clean_property": {"obj_1": "hat", "relation": "left of", "obj_2": "person"}, "target_prompt": "A hat positioned to the right of a person riding a skateboard.", "target_property": {"obj_1": "hat", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the hat to the **left** of the person riding a skateboard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A hat positioned to the left of a person riding a skateboard. )!B*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6b88663f5e084f9a897d9dd59492bc3f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e41420aa519644e7b3f2cb98b90cecd4", "source": "vatex", "video_id": "bd9RnFJtUJ8_000315_000325", "video_description": "An adult and a child are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground.", "task": "ObjectRecognition", "clean_prompt": "An adult and a child are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground.", "clean_property": {"obj": "child"}, "target_prompt": "An adult and a dog are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground.", "target_property": {"obj": "dog"}, "evaluation_question": "Is there a **child** paragliding in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult and a child are paragliding in tandem, harnessed together and connected to a parachute, flying high above the ground. OF)BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9d927b6e3b4541648b05eff22b21fa27.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fed11ee5cf1f490b89602b9a32f0da63", "source": "vatex", "video_id": "1zXXjwcOXTs_000202_000212", "video_description": "A young boy demonstrates his double-jointed abilities by twisting and bending his arms in various directions while a man comments on his flexibility.", "task": "AttributeRecognition", "clean_prompt": "A man who is a teacher comments on a young boy demonstrating his double-jointed abilities.", "clean_property": {"obj": "man", "attribute": "teacher"}, "target_prompt": "A man who is a doctor comments on a young boy demonstrating his double-jointed abilities.", "target_property": {"obj": "man", "attribute": "doctor"}, "evaluation_question": "Is the man a **teacher**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man who is a teacher comments on a young boy demonstrating his double-jointed abilities. TYNFR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f934c8a30c934a40951863df6c94bfa1.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5d42018d4bf949488330b959f431c1e6", "source": "vatex", "video_id": "23WY0pcM_Z0_000000_000010", "video_description": "A group of people, including children and adults, are jumping rope together in an outdoor setting, such as a park or fairground, during a festival or parade. A man in a hat joins the game, and a crowd cheers them on.", "task": "ObjectRecognition", "clean_prompt": "A group of people, including children and adults, are jumping rope together in a park during a festival.", "clean_property": {"obj": "rope"}, "target_prompt": "A group of people, including children and adults, are playing with balloons together in a park during a festival.", "target_property": {"obj": "balloon"}, "evaluation_question": "Are the people in the video jumping **rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people, including children and adults, are jumping rope together in a park during a festival. )?2BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d1bd8989502b4fbbbcf74841434baf8e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0046271f49ca4d4c95e90d117ac71460", "source": "vatex", "video_id": "q7MfG_x03_Q_000041_000051", "video_description": "A man is speaking about his experiences and challenges with cross-country biking, while also being shown riding a bicycle with bags attached.", "task": "ActionRecognition", "clean_prompt": "A person riding a bike while discussing cross-country biking experiences.", "clean_property": {"obj": "person", "action": "riding a bike", "target": null}, "target_prompt": "A person walking while discussing cross-country biking experiences.", "target_property": {"obj": "person", "action": "walking", "target": null}, "evaluation_question": "Is the person **riding a bike**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a bike while discussing cross-country biking experiences. !LZ%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ad0b603e7df245beb2cdb17e5feb4fac.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9c00ea995e9843a9a809e38d20aed9e2", "source": "vatex", "video_id": "6GBfuQgOJGE_000031_000041", "video_description": "A young man is dancing energetically to techno music on the sidewalk in front of a building, while two friends sit on steps watching him.", "task": "ObjectRecognition", "clean_prompt": "A young man dancing energetically to techno music on the sidewalk in front of a building.", "clean_property": {"obj": "music"}, "target_prompt": "A young man standing still in silence on the sidewalk in front of a building.", "target_property": {"obj": "silence"}, "evaluation_question": "Is the young man dancing to **music**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man dancing energetically to techno music on the sidewalk in front of a building. +TPFC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9341495fd1844748a6b49f2ff05ddc7a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0187986e6dce4ec093a40750f0b98a95", "source": "vatex", "video_id": "hFWkQac2GSc_000016_000026", "video_description": "A person is repairing and painting an old book using a brush, adhesive, and paint in a shop setting.", "task": "ActionRecognition", "clean_prompt": "A person repairing and painting an old book in a shop setting.", "clean_property": {"obj": "person", "action": "bookbinding", "target": null}, "target_prompt": "A person destroying a book in a shop setting.", "target_property": {"obj": "person", "action": "destroying a book", "target": null}, "evaluation_question": "Is the person **repairing** the book?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person repairing and painting an old book in a shop setting. HS-0-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cb59862f8ff0483abc55ff614cbccff1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bbd4d89ee287443d96043f4bea003f7e", "source": "vatex", "video_id": "oukDXzcfbB4_000264_000274", "video_description": "A man is using a blow dryer to heat and mold a baseball cap to his head.", "task": "SpatialUnderstanding", "clean_prompt": "A hat farther from the camera than a person.", "clean_property": {"obj_1": "hat", "relation": "farther from the camera than", "obj_2": "person"}, "target_prompt": "A hat closer to the camera than a person.", "target_property": {"obj_1": "hat", "relation": "closer to the camera than", "obj_2": "person"}, "evaluation_question": "Is the hat **farther from the camera than** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A hat farther from the camera than a person. \u00b7))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a14c303d08b4db8b8a1771096c90001.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0cad50bc96fa43bc8a415ecb547760e4", "source": "vatex", "video_id": "5fE_TmvVPJc_000177_000187", "video_description": "A boy is outside demonstrating how to throw a card, explaining the technique and showing it to the camera.", "task": "AttributeRecognition", "clean_prompt": "A boy outside demonstrating how to throw a credit card.", "clean_property": {"obj": "card", "attribute": "credit"}, "target_prompt": "A boy outside demonstrating how to throw a debit card.", "target_property": {"obj": "card", "attribute": "debit"}, "evaluation_question": "Is the card being thrown a **credit** card?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy outside demonstrating how to throw a credit card. >S1XX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/605896b0ece24231a7eac38e2af01be7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2d2aa936549a403696c96c7f38331636", "source": "vatex", "video_id": "ue6lAqTPP1M_000044_000054", "video_description": "A weatherman is standing in front of a green screen in a studio, giving a weather report about cloudy, foggy, and cold conditions.", "task": "ActionRecognition", "clean_prompt": "A weatherman presenting a weather forecast in front of a green screen.", "clean_property": {"obj": "weatherman", "action": "presenting weather forecast", "target": null}, "target_prompt": "A weatherman reporting traffic conditions in front of a green screen.", "target_property": {"obj": "weatherman", "action": "reporting traffic conditions", "target": null}, "evaluation_question": "Is the weatherman **presenting a weather forecast**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A weatherman presenting a weather forecast in front of a green screen. ))!D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/68367f48ab324b63bf5292b4fe4dd6ff.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "91a0154c0dab4fecb8ff64f18f4b2463", "source": "vatex", "video_id": "_8mOZcLXnO0_000038_000048", "video_description": "A young girl is seated on an airplane, laughing and interacting with a woman next to her.", "task": "ObjectRecognition", "clean_prompt": "A young girl is seated in an airplane seat, laughing and interacting with a woman next to her.", "clean_property": {"obj": "airplane seat"}, "target_prompt": "A young girl is seated in a train seat, laughing and interacting with a woman next to her.", "target_property": {"obj": "train seat"}, "evaluation_question": "Is the girl seated in an **airplane seat**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is seated in an airplane seat, laughing and interacting with a woman next to her. @@H2V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ea7067d770c84ae6b00612a220986904.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "160779f9d7784dc185dc389cf1ed8908", "source": "vatex", "video_id": "UJT5KUNEcMw_000003_000013", "video_description": "A man and a child are lying in bed. The child is making funny faces and pretending to snore while the man is sleeping.", "task": "SpatialUnderstanding", "clean_prompt": "A man lying in bed to the left of a child who is making funny faces.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "child"}, "target_prompt": "A man lying in bed to the right of a child who is making funny faces.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "child"}, "evaluation_question": "Is the man to the **left** of the child?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man lying in bed to the left of a child who is making funny faces. VT/HU", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d2a5381b4dc4471d92ba4ec0c8e416a5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f040e5ca0ba4ee79e105b275de873f3", "source": "vatex", "video_id": "FnGqWbNjO3I_000010_000020", "video_description": "A woman is demonstrating how to properly wrap a gift using paper and tape on a wooden table.", "task": "AttributeRecognition", "clean_prompt": "A woman is demonstrating how to properly wrap a gift using plain brown paper and tape on a wooden table.", "clean_property": {"obj": "paper", "attribute": "plain brown"}, "target_prompt": "A woman is demonstrating how to properly wrap a gift using colorful patterned paper and tape on a wooden table.", "target_property": {"obj": "paper", "attribute": "colorful patterned"}, "evaluation_question": "Is the paper being used **plain brown**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is demonstrating how to properly wrap a gift using plain brown paper and tape on a wooden table. )FEBO", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/86782a94cc5844c7975744c634f18f20.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d8a3b1fac06e403a95230718f1a95cba", "source": "vatex", "video_id": "OASCPKazLIM_000132_000142", "video_description": "A person is demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table.", "task": "AttributeRecognition", "clean_prompt": "A person is demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table.", "clean_property": {"obj": "wrapping paper", "attribute": "colorful"}, "target_prompt": "A person is demonstrating how to wrap a book and a small box using plain wrapping paper on a wooden table.", "target_property": {"obj": "wrapping paper", "attribute": "plain"}, "evaluation_question": "Is the wrapping paper **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to wrap a book and a small box using colorful wrapping paper on a wooden table. #HR\u00b7U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf1ebdc2206f4677aa552d00e9b86821.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f8f8084f4ab48f5aaf9c1d8a864891f", "source": "vatex", "video_id": "s6neX_K5Pus_000015_000025", "video_description": "A man is performing various exercises with weights indoors, including push-ups and weighted rows on a blue mat.", "task": "AttributeRecognition", "clean_prompt": "A man performing exercises with weights on a blue mat.", "clean_property": {"obj": "mat", "attribute": "blue"}, "target_prompt": "A man performing exercises with weights on a red mat.", "target_property": {"obj": "mat", "attribute": "red"}, "evaluation_question": "Is the man performing exercises on a **blue** mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing exercises with weights on a blue mat. ,P$BB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7ff1d3b1debd407b8c865b46d9317e25.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ad0c8d761bba43109a91729566dd006a", "source": "vatex", "video_id": "51v-7Xxpy30_000066_000076", "video_description": "A man demonstrates how to unfold and ride a folding bike, explaining its benefits and features.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a bike.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "bike"}, "target_prompt": "A person closer to the camera than a bike.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "bike"}, "evaluation_question": "Is the person **farther from the camera than** the bike?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a bike. FE7@@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/350d632ed1c347fe9eae480a113f7af9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6eb77f1d53744ea29f68812938685ae1", "source": "vatex", "video_id": "ZcYB6tPK2Eo_000138_000148", "video_description": "A man is demonstrating how to solve a Rubik's cube, explaining his process while manipulating the cube.", "task": "ActionRecognition", "clean_prompt": "A person playing with a Rubik's cube, demonstrating how to solve it.", "clean_property": {"obj": "person", "action": "playing rubiks cube", "target": null}, "target_prompt": "A person throwing a Rubik's cube.", "target_property": {"obj": "person", "action": "throwing a Rubik's cube", "target": null}, "evaluation_question": "Is the person **playing with** a Rubik's cube?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing with a Rubik's cube, demonstrating how to solve it. )!0D-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/993a32f9ca2949d9be64827da8dacf3b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3a5c3cdf2b8043dba714cb9576344d79", "source": "vatex", "video_id": "0HEi6q3bGaw_000011_000021", "video_description": "A group of people on snowmobiles are talking to each other on a snow-covered terrain before riding off.", "task": "ActionRecognition", "clean_prompt": "A person talking on a cell phone in a snowy terrain.", "clean_property": {"obj": "person", "action": "talking on cell phone", "target": null}, "target_prompt": "A person yelling in a snowy terrain.", "target_property": {"obj": "person", "action": "yelling", "target": null}, "evaluation_question": "Is the person **talking on a cell phone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person talking on a cell phone in a snowy terrain. &FE|J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd75fd19f5b14f488ac7f409e089162e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f3242fffcdbb44cabb0773d99f9478cc", "source": "vatex", "video_id": "2YGIhoMqYwM_000015_000025", "video_description": "A woman is demonstrating to a child how to tie a shoelace on a red sneaker.", "task": "ActionRecognition", "clean_prompt": "A woman demonstrating to a child how to tie a shoelace on a red sneaker.", "clean_property": {"obj": "woman", "action": "tying shoe laces", "target": "sneaker"}, "target_prompt": "A woman demonstrating to a child how to remove shoelaces from a red sneaker.", "target_property": {"obj": "woman", "action": "removing shoelaces", "target": "sneaker"}, "evaluation_question": "Is the woman **tying** shoelaces on the sneaker?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating to a child how to tie a shoelace on a red sneaker. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f231dc8a494f4606b34c100496d6fb1d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "74c83412f05d4d7cb970a93ef86e8c6f", "source": "vatex", "video_id": "LAx9oAvCugA_000103_000113", "video_description": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing Monopoly.", "task": "ObjectRecognition", "clean_prompt": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing Monopoly.", "clean_property": {"obj": "monopoly"}, "target_prompt": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing chess.", "target_property": {"obj": "chess"}, "evaluation_question": "Are the boys playing **Monopoly**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young boys wearing monster costumes and masks are sitting at a dining room table playing Monopoly. /!0D=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0f2c4db4b75a46a0978aa57716df02f5.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "11c350b377fa454bb9fdcdcc2238eec6", "source": "vatex", "video_id": "-ZxB7cFx7eo_000038_000048", "video_description": "A person is carving a Jack-O-Lantern from a pumpkin, using a knife to create a face and other designs for Halloween.", "task": "SpatialUnderstanding", "clean_prompt": "A pumpkin farther from the camera than a knife.", "clean_property": {"obj_1": "pumpkin", "relation": "farther from the camera than", "obj_2": "knife"}, "target_prompt": "A pumpkin closer to the camera than a knife.", "target_property": {"obj_1": "pumpkin", "relation": "closer to the camera than", "obj_2": "knife"}, "evaluation_question": "Is the pumpkin **farther from the camera than** the knife?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pumpkin farther from the camera than a knife. EL.,E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c30ff719dc414d90a410762056ac27f2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dd0923278ab34e638d420d63d22638f4", "source": "vatex", "video_id": "gg5NgF4VUBs_000000_000010", "video_description": "A man is demonstrating how to apply moisturizer to his face and hands, using a bottle of moisturizer.", "task": "ActionRecognition", "clean_prompt": "A person applying moisturizer to his face and hands.", "clean_property": {"obj": "person", "action": "applying cream", "target": "moisturizer"}, "target_prompt": "A person applying sunscreen to his face and hands.", "target_property": {"obj": "person", "action": "applying cream", "target": "sunscreen"}, "evaluation_question": "Is the person **applying moisturizer**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person applying moisturizer to his face and hands. F|F);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/69f80f21649b4f258d55b62dcce3cf35.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "acd40418cb1849e3b31d96b7226b75a8", "source": "vatex", "video_id": "UM8n1uCMh4M_000031_000041", "video_description": "A man in a news room is reporting the weather in Beijing, standing in front of a green screen displaying a grassy field and clouds.", "task": "Counting", "clean_prompt": "A man reporting the weather in Beijing, standing in front of three green screens displaying a grassy field and clouds.", "clean_property": {"obj": "green screen", "count": "three"}, "target_prompt": "A man reporting the weather in Beijing, standing in front of one green screen displaying a snowy mountain.", "target_property": {"obj": "green screen", "count": "one"}, "evaluation_question": "Are there exactly **three** green screens in front of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man reporting the weather in Beijing, standing in front of three green screens displaying a grassy field and clouds. \u00b72@FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0c31b0dddb6d48939eea79a2501a8207.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57d94f11470e428b99480b3491390b57", "source": "vatex", "video_id": "W9UK_TCYoA8_000003_000013", "video_description": "A man is timing himself while attaching a pre-tied necktie to his collar, using a stopwatch or phone to measure the time.", "task": "Counting", "clean_prompt": "Two people timing themselves while attaching pre-tied neckties to their collars.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person timing themselves while attaching a pre-tied necktie to their collar.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people timing themselves?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people timing themselves while attaching pre-tied neckties to their collars. )UF/S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/690a7400ed47404d95f2ec13fb95ddf6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ed5911baaf154761bb36e039f98c0a92", "source": "vatex", "video_id": "oHb_TZKeA9Y_000082_000092", "video_description": "A person is sitting at a table, using two pens to tap out a rhythm, creating drumming sounds.", "task": "SpatialUnderstanding", "clean_prompt": "A person sitting to the left of a table, using two pens to tap out a rhythm.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "table"}, "target_prompt": "A person sitting to the right of a table, using two pens to tap out a rhythm.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "table"}, "evaluation_question": "Is the person sitting to the **left** of the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sitting to the left of a table, using two pens to tap out a rhythm. 8LF%\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/53fd73f3487b414886c1dee1ad47d3a0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd7be9dcbb02418c9597e07774522c76", "source": "vatex", "video_id": "CVVTcvOrWv8_000590_000600", "video_description": "Several construction workers are working indoors, using dollies to transport and lay bricks on the ground.", "task": "ObjectRecognition", "clean_prompt": "Several construction workers are working indoors, using dollies to transport and lay bricks on the ground.", "clean_property": {"obj": "brick"}, "target_prompt": "Several construction workers are working indoors, using dollies to transport and lay wooden planks on the ground.", "target_property": {"obj": "wood"}, "evaluation_question": "Are the workers transporting **bricks**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Several construction workers are working indoors, using dollies to transport and lay bricks on the ground. FE|OT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d6c061259251444a93907e83894acb3e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "708a6b277f3840858e310f254e22d5be", "source": "vatex", "video_id": "AehLAPZBSzA_000000_000010", "video_description": "A young boy is learning to ride a unicycle by using a picket fence for support. He initially holds onto the fence, manages to ride a short distance, and eventually falls.", "task": "ObjectRecognition", "clean_prompt": "A young boy is learning to ride a unicycle by using a picket fence for support.", "clean_property": {"obj": "unicycle"}, "target_prompt": "A young boy is learning to ride a bicycle by using a picket fence for support.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is the boy learning to ride a **unicycle**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy is learning to ride a unicycle by using a picket fence for support. @CKQF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/450879bb6e03490aa705d69ce2ed70a9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "689548ebb30243d4af84243e5eb338a5", "source": "vatex", "video_id": "UqAjuPrbD6c_000015_000025", "video_description": "A police officer is riding a Segway at a festival, talking to a person holding a camera. The officer is wearing a helmet and demonstrating the Segway's use for patrolling.", "task": "ObjectRecognition", "clean_prompt": "A police officer riding a Segway at a festival, talking to a person holding a camera.", "clean_property": {"obj": "Segway"}, "target_prompt": "A police officer riding a bicycle at a festival, talking to a person holding a camera.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is the police officer riding a **Segway**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A police officer riding a Segway at a festival, talking to a person holding a camera. )'?FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c5a2838e9a104a66b70a5f2fb3bdee54.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7cd3a48396694258bcc46e67b54ea9cb", "source": "vatex", "video_id": "OOxphqMuui8_000011_000021", "video_description": "A sushi chef is preparing sushi in a kitchen, using fresh ingredients and wearing gloves.", "task": "AttributeRecognition", "clean_prompt": "A sushi chef preparing sushi with fresh ingredients in a kitchen.", "clean_property": {"obj": "ingredients", "attribute": "fresh"}, "target_prompt": "A sushi chef preparing sushi with stale ingredients in a kitchen.", "target_property": {"obj": "ingredients", "attribute": "stale"}, "evaluation_question": "Are the ingredients being used by the sushi chef **fresh**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A sushi chef preparing sushi with fresh ingredients in a kitchen. EL@)C", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8300b21c305642bf892ae02d821caa0b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7cc0871f531d4cde935dc98a27885af0", "source": "vatex", "video_id": "TFFEWqC7pEU_000059_000069", "video_description": "A group of children and adults are playing a game of kickball in a yard behind mobile homes, using a large inflated ball.", "task": "SpatialUnderstanding", "clean_prompt": "A child closer to the camera than a ball in a yard behind mobile homes.", "clean_property": {"obj_1": "child", "relation": "closer to the camera than", "obj_2": "ball"}, "target_prompt": "A child further from the camera than a ball in a yard behind mobile homes.", "target_property": {"obj_1": "child", "relation": "further from the camera than", "obj_2": "ball"}, "evaluation_question": "Is the child **closer to the camera than** the ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child closer to the camera than a ball in a yard behind mobile homes. )/);=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eed844b76e704056aa62ae45ece00c5b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1c3a710b9ba3418499deeb065c7bbb9b", "source": "vatex", "video_id": "Efkj1o-Z8-k_000007_000017", "video_description": "A ballerina performs a ballet dance on stage, spinning and twirling gracefully to music.", "task": "AttributeRecognition", "clean_prompt": "A ballerina performing a ballet dance on stage, spinning and twirling gracefully to music.", "clean_property": {"obj": "ballerina", "attribute": "graceful"}, "target_prompt": "A ballerina performing a ballet dance on stage, spinning and twirling clumsily to music.", "target_property": {"obj": "ballerina", "attribute": "clumsy"}, "evaluation_question": "Is the ballerina performing gracefully?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A ballerina performing a ballet dance on stage, spinning and twirling gracefully to music. =$X8V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d75e84c12d1048b992930e84f2ff5cc9.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b41331c593a2478ca6b8402e6e54d0b6", "source": "vatex", "video_id": "ENGyHpfPnAc_000000_000010", "video_description": "A man and a woman are sitting on a couch playing a board game, specifically Scrabble, and talking to another woman.", "task": "Counting", "clean_prompt": "A man and a woman are sitting on a couch playing three board games, specifically Scrabble, and talking to another woman.", "clean_property": {"obj": "board game", "count": "three"}, "target_prompt": "A man and a woman are sitting on a couch playing one board game, specifically Scrabble, and talking to another woman.", "target_property": {"obj": "board game", "count": "one"}, "evaluation_question": "Are there exactly **three** board games being played on the couch?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man and a woman are sitting on a couch playing three board games, specifically Scrabble, and talking to another woman. !0DEB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/70015395e13e4f659d8f52fa719a74d3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a9725b87bdf40a1aa4a6d3949d320bf", "source": "vatex", "video_id": "WeMpnxtS0Sw_000057_000067", "video_description": "A person is chopping mushrooms on a cutting board and placing them into a pot while music plays.", "task": "Counting", "clean_prompt": "Two people are chopping mushrooms on a cutting board and placing them into a pot while music plays.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person is chopping mushrooms on a cutting board and placing them into a pot while music plays.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people chopping mushrooms?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are chopping mushrooms on a cutting board and placing them into a pot while music plays. /(!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3800c3a4bf1044d99f68dbcb1813feeb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "530fdc1fc77342918bcde67a1b55ae79", "source": "vatex", "video_id": "K5YqC3GAmrw_000001_000011", "video_description": "A young child is playing and crawling inside a bouncy house filled with balls, while adults stand outside watching.", "task": "ObjectRecognition", "clean_prompt": "A young child is playing and crawling inside a bouncy house filled with balls, while adults stand outside watching.", "clean_property": {"obj": "bouncy house"}, "target_prompt": "A young child is jumping on a trampoline while adults stand outside watching.", "target_property": {"obj": "trampoline"}, "evaluation_question": "Is the child playing in a **bouncy house**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young child is playing and crawling inside a bouncy house filled with balls, while adults stand outside watching. !0='|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c76c0dc06a040ada480d4ee73f5ee15.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "255aa7e30b7a4c7294ca33920755c59d", "source": "vatex", "video_id": "c_gQBgPec5c_000014_000024", "video_description": "A man is in a garage using a table saw to cut pieces of wood. The saw is smoking as he cuts.", "task": "SpatialUnderstanding", "clean_prompt": "Wood is located to the left of a table saw.", "clean_property": {"obj_1": "wood", "relation": "left of", "obj_2": "table saw"}, "target_prompt": "Wood is located to the right of a table saw.", "target_property": {"obj_1": "wood", "relation": "right of", "obj_2": "table saw"}, "evaluation_question": "Is the wood to the **left** of the table saw?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Wood is located to the left of a table saw. @JOO;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0a7aa389260c45f396717107e1473ec6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7b20565ad8b249019e938d9c4a2e2b79", "source": "vatex", "video_id": "Z9ti_aZfUM8_000085_000095", "video_description": "A scuba diver is underwater in the ocean, wearing full scuba gear and looking around while blowing bubbles. The diver interacts with a rope.", "task": "ActionRecognition", "clean_prompt": "A scuba diver scuba diving in the ocean.", "clean_property": {"obj": "scuba diver", "action": "scuba diving", "target": null}, "target_prompt": "A scuba diver swimming with a shark in the ocean.", "target_property": {"obj": "scuba diver", "action": "swimming", "target": "shark"}, "evaluation_question": "Is the scuba diver **scuba diving**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A scuba diver scuba diving in the ocean. K0/?&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3278b730998345eb85ade467ac467da2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9448cb7843e84706809c3573584a8923", "source": "vatex", "video_id": "3OJasCVIqrM_000016_000026", "video_description": "A young girl with glasses is in her bedroom, talking to the camera while applying orange lip gloss.", "task": "Counting", "clean_prompt": "A young girl with glasses is in her bedroom, talking to the camera while applying two lip glosses.", "clean_property": {"obj": "lip gloss", "count": "two"}, "target_prompt": "A young girl with glasses is in her bedroom, talking to the camera while applying one lip gloss.", "target_property": {"obj": "lip gloss", "count": "one"}, "evaluation_question": "Is the girl applying exactly **two** lip glosses?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl with glasses is in her bedroom, talking to the camera while applying two lip glosses. JC#VR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/76f34517256440109f30f0b87296006f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4745173d9281456ea5266bd860b6c072", "source": "vatex", "video_id": "0FhPVyStI9M_000000_000010", "video_description": "A young man is juggling three tennis balls in various locations, including an empty lot, outside a building, a parking garage, and indoors.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a tennis ball.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "tennis ball"}, "target_prompt": "A person standing behind a tennis ball.", "target_property": {"obj_1": "person", "relation": "behind", "obj_2": "tennis ball"}, "evaluation_question": "Is the person to the **left** of a tennis ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a tennis ball. SL#CB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bd8606b8ccef448393e7863bcd1a3e32.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8b37ca88c5e54383a365d356ff37beb7", "source": "vatex", "video_id": "6zRgzbfPOcU_000011_000021", "video_description": "A person wearing blue gloves demonstrates the process of tying, removing, and replacing a garbage bag in a trash can.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a trash can while wearing blue gloves and demonstrating how to tie a garbage bag.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "trash can"}, "target_prompt": "A person standing to the right of a trash can while wearing blue gloves and demonstrating how to tie a garbage bag.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "trash can"}, "evaluation_question": "Is the person to the **left** of the trash can?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a trash can while wearing blue gloves and demonstrating how to tie a garbage bag. 3/SL+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/79e30ce68a1f4a62b99f165e62f6428e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ef1b0d37daf54d72847ba38f644a5ae6", "source": "vatex", "video_id": "QPWTCHbhZkI_000008_000018", "video_description": "A man is demonstrating and explaining the process of laying a brick floor using mortar and tools.", "task": "AttributeRecognition", "clean_prompt": "A man is demonstrating and explaining the process of laying a red brick floor using mortar and tools.", "clean_property": {"obj": "brick", "attribute": "red"}, "target_prompt": "A man is demonstrating and explaining the process of laying a blue brick floor using mortar and tools.", "target_property": {"obj": "brick", "attribute": "blue"}, "evaluation_question": "Is the brick being used in the video **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is demonstrating and explaining the process of laying a red brick floor using mortar and tools. VT93M", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f36a6e847c264c1dbaf724aaa9bfe355.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8bb37b2d900b48d1a30b8d50a70ad7dd", "source": "vatex", "video_id": "7GRLn6bWI0c_000005_000015", "video_description": "A woman is training her dog indoors, teaching it various commands such as sit, stay, stand, and lay.", "task": "Counting", "clean_prompt": "A woman is training two dogs indoors, teaching them various commands such as sit, stay, stand, and lay.", "clean_property": {"obj": "dog", "count": "two"}, "target_prompt": "A woman is training one dog indoors, teaching it various commands such as sit, stay, stand, and lay.", "target_property": {"obj": "dog", "count": "one"}, "evaluation_question": "Are there exactly **two** dogs being trained indoors?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is training two dogs indoors, teaching them various commands such as sit, stay, stand, and lay. F''?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/84d0259a2dd64d93bdb7b536e33c11de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "89993e26d9784370bbc6e80b8691ce13", "source": "vatex", "video_id": "Xk0pqmTHL5E_000061_000071", "video_description": "A young woman with brown hair and a black top is smoking a large cigar, laughing, and talking to a man who is filming her.", "task": "SpatialUnderstanding", "clean_prompt": "A man closer to the camera than a cigar.", "clean_property": {"obj_1": "man", "relation": "closer to the camera than", "obj_2": "cigar"}, "target_prompt": "A man further from the camera than a cigar.", "target_property": {"obj_1": "man", "relation": "further from the camera than", "obj_2": "cigar"}, "evaluation_question": "Is the man **closer to the camera than** the cigar?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man closer to the camera than a cigar. !B=1|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/33064be6ca9542d0913491b68819c43b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bf5f79f7d5bd46939705a621ffcd6c79", "source": "vatex", "video_id": "77wHRVllzow_000024_000034", "video_description": "A woman demonstrates tackling techniques by rushing towards a man holding a protective pad during a training session.", "task": "ActionRecognition", "clean_prompt": "A woman tackling a man holding a protective pad during a training session.", "clean_property": {"obj": "woman", "action": "tackling", "target": "man"}, "target_prompt": "A woman running towards a man holding a protective pad during a training session.", "target_property": {"obj": "woman", "action": "running", "target": "man"}, "evaluation_question": "Is the woman **tackling** the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman tackling a man holding a protective pad during a training session. -U*9-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d780c775e7df4734b2d412ff3d36ddb9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9deb7ef0f8ee4518b62b027f0759c20a", "source": "vatex", "video_id": "98ieFdWqr3E_000165_000175", "video_description": "A group of people are playing laser tag in a building, primarily in the stairwells. A man with a toy gun is shooting at others, who fall when hit, as he moves through the building.", "task": "ActionRecognition", "clean_prompt": "A person playing laser tag in a building.", "clean_property": {"obj": "person", "action": "playing laser tag", "target": null}, "target_prompt": "A person playing paintball in a building.", "target_property": {"obj": "person", "action": "playing paintball", "target": null}, "evaluation_question": "Is the person **playing laser tag**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing laser tag in a building. O7V;:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8bc7731182c4cbba1cfe32e9f75864a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "943fbd76b6024c6ba1617ba91b5bb3a1", "source": "vatex", "video_id": "gcW4uVP8Cos_000000_000010", "video_description": "A person is cleaning various windows using a squeegee and soapy water at a gas station.", "task": "Counting", "clean_prompt": "Three people are cleaning various windows using a squeegee and soapy water at a gas station.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is cleaning a window using a squeegee and soapy water at a gas station.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people cleaning the windows?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are cleaning various windows using a squeegee and soapy water at a gas station. >N73>", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5af15ccfc91e42d3a67e42262d63c027.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ac7494c7460448bfae74501d82b96d0b", "source": "vatex", "video_id": "RA90UGf5wxA_000000_000010", "video_description": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them.", "task": "ObjectRecognition", "clean_prompt": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them.", "clean_property": {"obj": "man"}, "target_prompt": "Two women are walking and dancing, including moonwalking, on a windy and icy street, while a man laughs at them.", "target_property": {"obj": "woman"}, "evaluation_question": "Is there a **man** walking and dancing in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are walking and dancing, including moonwalking, on a windy and icy street, while a woman laughs at them. F=''-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c4bca42375b41a0a7453c69aeb54356.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "99a537392d8f4cf2988adf43f48840f4", "source": "vatex", "video_id": "22QytzFKlos_000000_000010", "video_description": "A man in swimming trunks dives into a clear blue swimming pool and swims using breaststroke, sometimes swimming underwater and sometimes on the surface.", "task": "Counting", "clean_prompt": "Five people diving into a clear blue swimming pool and swimming using breaststroke.", "clean_property": {"obj": "person", "count": "five"}, "target_prompt": "One person diving into a clear blue swimming pool and swimming using breaststroke.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **five** people diving into the swimming pool?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five people diving into a clear blue swimming pool and swimming using breaststroke. !D+5B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d902bfaf29804567980500797527aa35.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6c2bd01a4e2d423894377a533d3d9887", "source": "vatex", "video_id": "352eUp-RrsU_000110_000120", "video_description": "A woman is in a beauty salon getting her eyebrows waxed by a beautician using wax strips. She is happy with the results.", "task": "ActionRecognition", "clean_prompt": "A beautician waxing eyebrows on a woman in a beauty salon.", "clean_property": {"obj": "beautician", "action": "waxing eyebrows", "target": "woman"}, "target_prompt": "A beautician applying makeup on a woman in a beauty salon.", "target_property": {"obj": "beautician", "action": "applying makeup", "target": "woman"}, "evaluation_question": "Is the beautician **waxing eyebrows**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A beautician waxing eyebrows on a woman in a beauty salon. SLQF#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7af6f05062f046cba7e8a0a23901e589.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "27e9f8b2953d48e8b78daeef07bb7497", "source": "vatex", "video_id": "Mtzzdluf_BI_000000_000010", "video_description": "A young woman in a pink sweatshirt is in an office or library, standing next to a copy machine. She looks around before placing her face on the machine to make a photocopy of her face.", "task": "Counting", "clean_prompt": "A young woman in a pink sweatshirt is standing next to four copy machines in an office, looking around before placing her face on one of the machines to make a photocopy of her face.", "clean_property": {"obj": "copy machine", "count": "four"}, "target_prompt": "A young woman in a pink sweatshirt is standing next to one copy machine in an office, looking around before placing her face on the machine to make a photocopy of her face.", "target_property": {"obj": "copy machine", "count": "one"}, "evaluation_question": "Are there exactly **four** copy machines in the office?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman in a pink sweatshirt is standing next to four copy machines in an office, looking around before placing her face on one of the machines to make a photocopy of her face. >;D.J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/4c33353ff0014ea684b25250ca1bf522.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dcbab6c48c6d454f949741e332118be0", "source": "vatex", "video_id": "09TihuYjO_s_000012_000022", "video_description": "Multiple groups of people are playing badminton on several indoor courts. Two men, one in a white top and the other in a yellow top, are playing a game of badminton.", "task": "Counting", "clean_prompt": "Three players are playing badminton on an indoor court.", "clean_property": {"obj": "player", "count": "three"}, "target_prompt": "One player is practicing badminton on an indoor court.", "target_property": {"obj": "player", "count": "one"}, "evaluation_question": "Are there exactly **three** players on the court?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three players are playing badminton on an indoor court. DP$RM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/080421ecd46d44f9b5b1d3a86874a028.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "898da830aa1e4e2785dd1453cc0f0774", "source": "vatex", "video_id": "xGe0cXA3OnI_000004_000014", "video_description": "A group of people are riding camels in the desert during the daytime. The camels kneel and sit to allow the riders to dismount.", "task": "Counting", "clean_prompt": "Seven people riding camels in the desert during the daytime.", "clean_property": {"obj": "camel", "count": "seven"}, "target_prompt": "One person riding a camel in the desert during the daytime.", "target_property": {"obj": "camel", "count": "one"}, "evaluation_question": "Are there exactly **seven** camels being ridden in the desert?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people riding camels in the desert during the daytime. FS+|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7ea2c9c48b3b464a944e24c580dde868.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2894104224664f7a961cd2f2f32b5d45", "source": "vatex", "video_id": "TLYBpysImlY_000022_000032", "video_description": "A man is leveling a cement floor with a trowel in an empty room of a house under renovation.", "task": "ObjectRecognition", "clean_prompt": "A person leveling a cement floor with a trowel in an empty room.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing in an empty room.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the main subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person leveling a cement floor with a trowel in an empty room. DVR%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e369633cf11f40628fc2b1a1bbff3499.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "75f93ea1b4de4659b64942f1716e9c7f", "source": "vatex", "video_id": "7mirr6TC1TY_000000_000010", "video_description": "A woman and a young boy are playfully sword fighting with plastic swords and shields in a room filled with weapons and toys. The boy gains the advantage and accidentally hurts the woman.", "task": "Counting", "clean_prompt": "Five women playfully sword fighting with plastic swords and shields in a room filled with weapons and toys.", "clean_property": {"obj": "woman", "count": "five"}, "target_prompt": "One woman playfully sword fighting with a plastic sword and shield in a room filled with weapons and toys.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **five** women sword fighting in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Five women playfully sword fighting with plastic swords and shields in a room filled with weapons and toys. LY%A;", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/52d4ed98e4a14ec5a2d995e6018dedfc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8bc7e590817e4fcc9ea21330fc6d972c", "source": "vatex", "video_id": "XEud0eiMT94_000102_000112", "video_description": "A group of children are playing, jumping, and running inside a colorful bouncy house at a park.", "task": "ObjectRecognition", "clean_prompt": "A group of children are playing, jumping, and running inside a colorful bouncy house at a park.", "clean_property": {"obj": "bouncy house"}, "target_prompt": "A group of children are playing, jumping, and running on a trampoline at a park.", "target_property": {"obj": "trampoline"}, "evaluation_question": "Are the children playing in a **bouncy house**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children are playing, jumping, and running inside a colorful bouncy house at a park. X)BSD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b5176ad450ea43fea708800feda62a09.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dbe92508b57d44f1984b0f32d3ff3114", "source": "vatex", "video_id": "cm66wB7giOM_000000_000010", "video_description": "A group of people, including children, are playing kickball in a grassy field. The game involves rolling, kicking, and catching the ball.", "task": "Counting", "clean_prompt": "Four children are playing kickball in a grassy field.", "clean_property": {"obj": "ball", "count": "four"}, "target_prompt": "One child is playing with a ball in a sandy beach.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **four** children playing kickball in the grassy field?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four children are playing kickball in a grassy field. FE4@I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6418d60732514b32b56f4635596d49ec.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3a4d82b389254d78a418804f8c714af7", "source": "vatex", "video_id": "WjzAWnQZXoQ_000003_000013", "video_description": "A woman in jeans is riding a tan horse that is galloping through various terrains including a wooded trail, a gravel road, and a grassy field.", "task": "ActionRecognition", "clean_prompt": "A person riding a tan horse through various terrains.", "clean_property": {"obj": "person", "action": "riding or walking with horse", "target": null}, "target_prompt": "A person walking with a tan horse through various terrains.", "target_property": {"obj": "person", "action": "walking with horse", "target": null}, "evaluation_question": "Is the person **riding** a horse?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a tan horse through various terrains. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3cbbb41e2367430f94da7704eef28c54.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "576b78e8b23340a98cc06307ed0baf9f", "source": "vatex", "video_id": "2-Wg9UFldCs_000003_000013", "video_description": "A woman is teaching a young girl how to shoot a bow and arrow at a target.", "task": "Counting", "clean_prompt": "Three women teaching a young girl how to shoot a bow and arrow at a target.", "clean_property": {"obj": "woman", "count": "three"}, "target_prompt": "One woman teaching a young girl how to shoot a bow and arrow at a target.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **three** women teaching the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three women teaching a young girl how to shoot a bow and arrow at a target. \u00b7!0WB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/226ed09db0a247c5907d4c5b09e20090.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "91cb17074cf346d5bd88643b0fea6c26", "source": "vatex", "video_id": "BFfOzTssqX4_000000_000010", "video_description": "A young girl is in her bedroom, facing the camera, talking and eating a powdered donut.", "task": "Counting", "clean_prompt": "Two girls in a bedroom, facing the camera, talking and eating powdered donuts.", "clean_property": {"obj": "girl", "count": "two"}, "target_prompt": "A girl in a bedroom, facing the camera, talking and eating a powdered donut.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **two** girls in the bedroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two girls in a bedroom, facing the camera, talking and eating powdered donuts. 93-TY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b95f6fd577df4865827e105996d46117.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c4dddef58efa450da1842f7054d24121", "source": "vatex", "video_id": "e8mFmvfwms0_000046_000056", "video_description": "A group of people are in a room where two men are singing karaoke. The audience is watching and some are interacting with the karaoke machine.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a microphone in a karaoke room.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "microphone"}, "target_prompt": "A person further from the camera than a microphone in a karaoke room.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "microphone"}, "evaluation_question": "Is the person **closer to the camera than** the microphone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a microphone in a karaoke room. ''!);", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d12e19678db44298d13d596c1ea7006.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e13f9e90ae984881b310f062dd6a4eff", "source": "vatex", "video_id": "XCugpFc1CAU_000033_000043", "video_description": "A female news anchor is presenting a top news story in a studio, using a map of a downtown area displayed on a screen to explain the details.", "task": "AttributeRecognition", "clean_prompt": "A female news anchor presenting a top news story using a street map displayed on a screen.", "clean_property": {"obj": "map", "attribute": "street map"}, "target_prompt": "A female news anchor presenting a top news story using a topographic map displayed on a screen.", "target_property": {"obj": "map", "attribute": "topographic map"}, "evaluation_question": "Is the map being used a **street map**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A female news anchor presenting a top news story using a street map displayed on a screen. !G%%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f269d05fc17a4c148a39202c3321d213.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7178a660d58b41a980fd400222adb563", "source": "vatex", "video_id": "ZGiVKNIB6W8_000029_000039", "video_description": "A young man in a white tank top and white capris is practicing backflips onto a stack of mattresses in a yard.", "task": "AttributeRecognition", "clean_prompt": "A young man in a white tank top and white capris practicing backflips onto a stack of white mattresses in a yard.", "clean_property": {"obj": "mattress", "attribute": "white"}, "target_prompt": "A young man in a white tank top and white capris practicing backflips onto a stack of blue mattresses in a yard.", "target_property": {"obj": "mattress", "attribute": "blue"}, "evaluation_question": "Are the mattresses **white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man in a white tank top and white capris practicing backflips onto a stack of white mattresses in a yard. >S\u00b7MT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/92126ef7ccd5450ba5ce6625ba21289a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2bd7b139899b46d595c1045b6df67aaa", "source": "vatex", "video_id": "8_1HELGfvXU_000106_000116", "video_description": "A man is demonstrating and explaining how to use a vacuum cleaner on a carpeted floor in an indoor setting.", "task": "ActionRecognition", "clean_prompt": "A person vacuuming the floor in an indoor setting.", "clean_property": {"obj": "person", "action": "vacuuming floor", "target": null}, "target_prompt": "A person mopping the floor in an indoor setting.", "target_property": {"obj": "person", "action": "mopping floor", "target": null}, "evaluation_question": "Is the person **vacuuming** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person vacuuming the floor in an indoor setting. UB\u00b7)E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/48fc357a235b48e981f6fc86407f9ddc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "00d478dfb91947d78b06f02c0e404bc9", "source": "vatex", "video_id": "2d2_s4Ym6DA_000030_000040", "video_description": "A woman demonstrates and explains the operation of a hand-operable binding machine used for binding documents.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrates and explains the operation of a hand-operable binding machine used for binding documents.", "clean_property": {"obj": "binding machine"}, "target_prompt": "A woman demonstrates and explains the operation of a stapler used for binding documents.", "target_property": {"obj": "stapler"}, "evaluation_question": "Is the object being demonstrated a **binding machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrates and explains the operation of a hand-operable binding machine used for binding documents. TZ%0E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f7ca2cc5713240e2b86cb19486c0bc7a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "25f3bf5c92f843bfa70ba42812b683cc", "source": "vatex", "video_id": "X3mtDsWXRmo_000145_000155", "video_description": "A man is playing a drum set in his room, wearing a blue hat and using drumsticks.", "task": "ActionRecognition", "clean_prompt": "A person playing drums in a room.", "clean_property": {"obj": "person", "action": "playing drums", "target": null}, "target_prompt": "A person playing guitar in a room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing drums**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing drums in a room. 1!0*3", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/77c5fb273fd2428cac0262ed85b9c588.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8213a0821c0148768150ae524d684fc9", "source": "vatex", "video_id": "5mgFRyRigvo_000012_000022", "video_description": "A young woman is sitting indoors, wearing green headphones, and playing a tune on a piccolo.", "task": "SpatialUnderstanding", "clean_prompt": "Headphones positioned to the left of a person sitting indoors.", "clean_property": {"obj_1": "headphones", "relation": "left of", "obj_2": "person"}, "target_prompt": "Headphones positioned to the right of a person sitting indoors.", "target_property": {"obj_1": "headphones", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Are the headphones **left of** the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Headphones positioned to the left of a person sitting indoors. E-SL)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5ebec48313dd4990936228ac128772bb.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "81a2fe75917542be8f4a32586ce9a4cb", "source": "vatex", "video_id": "qeo9KAT0BHA_000025_000035", "video_description": "A group of news anchors, including two men and a woman, are sitting at a desk. They are laughing at a video or image of a woman in a pink shirt and long skirt climbing stairs.", "task": "SpatialUnderstanding", "clean_prompt": "A news anchor sitting to the right of a woman in a pink shirt and long skirt.", "clean_property": {"obj_1": "news anchor", "relation": "right of", "obj_2": "woman in pink"}, "target_prompt": "A news anchor sitting to the left of a woman in a pink shirt and long skirt.", "target_property": {"obj_1": "news anchor", "relation": "left of", "obj_2": "woman in pink"}, "evaluation_question": "Is the news anchor to the **right** of a woman in a pink shirt and long skirt?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A news anchor sitting to the right of a woman in a pink shirt and long skirt. OT.8J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/634abf76334a46afa63606521d3c3828.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d83b7b914eb644048e95892613001bc4", "source": "vatex", "video_id": "7S5p2usqJiI_000098_000108", "video_description": "A woman is using a hair straightening tool on a boy's hair in a bathroom.", "task": "ObjectRecognition", "clean_prompt": "A woman is using a hair straightening tool on a boy's hair in a bathroom.", "clean_property": {"obj": "hair straightening tool"}, "target_prompt": "A woman is using a hair curling tool on a boy's hair in a bathroom.", "target_property": {"obj": "hair curling tool"}, "evaluation_question": "Is the tool being used in the video a **hair straightening tool**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is using a hair straightening tool on a boy's hair in a bathroom. *TZ7,", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c20d3310e8aa4b428e93467a180f710a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aaf28ed610ce4cb29275fef22f7a8863", "source": "vatex", "video_id": "ihaCkiCbZK8_000023_000033", "video_description": "A baby is sitting in a walker, shaking their head happily and smiling. The baby is amused by a parent or someone playing with them, and occasionally reaches towards the camera.", "task": "ObjectRecognition", "clean_prompt": "A baby sitting in a walker, shaking their head happily and smiling.", "clean_property": {"obj": "walker"}, "target_prompt": "A baby sitting on a scooter, shaking their head happily and smiling.", "target_property": {"obj": "scooter"}, "evaluation_question": "Is the baby sitting in a **walker**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby sitting in a walker, shaking their head happily and smiling. RP8QV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cdce44fb69454676adf77a7247462c8e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "991e6ba9118446538e5facf6f20520c0", "source": "vatex", "video_id": "rJZkSIU1ldY_000011_000021", "video_description": "A woman is tutoring a young boy in math, using pennies and paper to teach counting and underlining techniques.", "task": "AttributeRecognition", "clean_prompt": "A boy who is disinterested while being tutored in math with pennies and paper.", "clean_property": {"obj": "boy", "attribute": "disinterested"}, "target_prompt": "A boy who is enthusiastic while being tutored in math with pennies and paper.", "target_property": {"obj": "boy", "attribute": "enthusiastic"}, "evaluation_question": "Is the boy disinterested during the tutoring session?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy who is disinterested while being tutored in math with pennies and paper. MR", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e979bc257bb046e6a997890e1fa4c125.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "85e10be3f007453ea103bc8b9a91f148", "source": "vatex", "video_id": "wgaZUi-Gzqs_000080_000090", "video_description": "A person is high up in a tree, using a chainsaw to cut off branches. The person is equipped with safety gear and is working above houses.", "task": "AttributeRecognition", "clean_prompt": "A person equipped with safety gear is high up in a tree, using a chainsaw to cut off branches above houses.", "clean_property": {"obj": "person", "attribute": "equipped with safety gear"}, "target_prompt": "A person not equipped with safety gear is high up in a tree, using a chainsaw to cut off branches above houses.", "target_property": {"obj": "person", "attribute": "not equipped with safety gear"}, "evaluation_question": "Is the person equipped with safety gear?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person equipped with safety gear is high up in a tree, using a chainsaw to cut off branches above houses. >FEYM", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e90af08e2434491fabea50f2d2776f52.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "126e6c0a6aec457d99a8629f337b2327", "source": "vatex", "video_id": "05V5KJGGzlE_000000_000010", "video_description": "Three young men in swim trunks are dancing to music on a backyard patio. They are shirtless and performing various dance moves, including the moonwalk, while others record them.", "task": "Counting", "clean_prompt": "Seven dancers performing various dance moves on a backyard patio.", "clean_property": {"obj": "dancer", "count": "seven"}, "target_prompt": "Four dancers performing various dance moves on a backyard patio.", "target_property": {"obj": "dancer", "count": "four"}, "evaluation_question": "Are there exactly **seven** dancers on the patio?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven dancers performing various dance moves on a backyard patio. \u00b7G*W!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/410275345b8b470896243f04651bde68.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1e77c23619d4a8698cf8904b4638b32", "source": "vatex", "video_id": "0lmvCP9tOXQ_000074_000084", "video_description": "Two boys are in a yard practicing soccer tricks and dribbling with soccer balls, laughing and having fun.", "task": "Counting", "clean_prompt": "Two boys are in a yard practicing soccer tricks and dribbling with three soccer balls, laughing and having fun.", "clean_property": {"obj": "soccer ball", "count": "three"}, "target_prompt": "Two boys are in a yard practicing soccer tricks and dribbling with one soccer ball, laughing and having fun.", "target_property": {"obj": "soccer ball", "count": "one"}, "evaluation_question": "Are there exactly **three** soccer balls in the yard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys are in a yard practicing soccer tricks and dribbling with three soccer balls, laughing and having fun. MVJ@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3702ac1585ee476bba7f38fc239e1755.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "483c4aa490e94c27a23da05eede293d3", "source": "vatex", "video_id": "iahzubOdvlU_000027_000037", "video_description": "An adult is making a baby laugh by tearing pieces of paper in front of her.", "task": "ActionRecognition", "clean_prompt": "An adult ripping paper in front of a baby to make her laugh.", "clean_property": {"obj": "adult", "action": "ripping paper", "target": "paper"}, "target_prompt": "An adult throwing paper in front of a baby.", "target_property": {"obj": "adult", "action": "throwing paper", "target": "paper"}, "evaluation_question": "Is the adult **ripping** paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An adult ripping paper in front of a baby to make her laugh. M?)'-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0cb137ae0ce744318f976da31cafd0e0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bc26ee179a4a4850a1d354b803ba052d", "source": "vatex", "video_id": "N-LZPc27kjM_000229_000239", "video_description": "A woman is demonstrating how to make tiny mittens using needlework, including knitting and shaping them with a needle and a small wooden stick.", "task": "AttributeRecognition", "clean_prompt": "A foreign person demonstrating how to make tiny mittens using needlework.", "clean_property": {"obj": "person", "attribute": "foreign"}, "target_prompt": "A local person demonstrating how to make tiny mittens using needlework.", "target_property": {"obj": "person", "attribute": "local"}, "evaluation_question": "Is the person demonstrating how to make tiny mittens **foreign**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A foreign person demonstrating how to make tiny mittens using needlework. |5!R\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1d5a333003d5434cb8ba2ed41effc0d7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "734bc5bf170e4f29b9c5a097cfb5b69b", "source": "vatex", "video_id": "Be2eKTN05Rs_000003_000013", "video_description": "Several people, including two men, are using ATM machines outside a bank. One man is wearing a gray jacket and another is wearing black. The ATMs are green and silver, and people are taking out money.", "task": "Counting", "clean_prompt": "Seven people using ATM machines outside a bank.", "clean_property": {"obj": "bank", "count": "seven"}, "target_prompt": "Three people using ATM machines outside a bank.", "target_property": {"obj": "bank", "count": "three"}, "evaluation_question": "Are there exactly **seven** people using ATM machines outside the bank?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people using ATM machines outside a bank. =4;I|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7b4be3828d4e49edb451d88ee64485a7.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "93503de1b02747a7ac46fab8f104658a", "source": "vatex", "video_id": "J9xSHM190hU_000004_000014", "video_description": "A pole vaulter is practicing at night under a spotlight, running with a pole and vaulting over a horizontal bar onto a mat.", "task": "ObjectRecognition", "clean_prompt": "A pole vaulter practicing at night under a spotlight, running with a pole and vaulting over a horizontal bar onto a mat.", "clean_property": {"obj": "pole vaulter"}, "target_prompt": "A high jumper practicing at night under a spotlight, running and jumping over a horizontal bar onto a mat.", "target_property": {"obj": "high jumper"}, "evaluation_question": "Is the athlete in the video a **pole vaulter**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pole vaulter practicing at night under a spotlight, running with a pole and vaulting over a horizontal bar onto a mat. >NJ@E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a46813f97fd54baba9a7d0cb45395e8d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0f2b33657eed4f9c8cecc67fed10cf71", "source": "vatex", "video_id": "P_rpMCioUDs_000000_000010", "video_description": "A man and a woman are having a heated discussion about their inability to conceive a baby.", "task": "SpatialUnderstanding", "clean_prompt": "A woman farther from the camera than a man, who are having a heated discussion about their inability to conceive a baby.", "clean_property": {"obj_1": "woman", "relation": "farther from the camera than", "obj_2": "man"}, "target_prompt": "A woman closer to the camera than a man, who are having a heated discussion about their inability to conceive a baby.", "target_property": {"obj_1": "woman", "relation": "closer to the camera than", "obj_2": "man"}, "evaluation_question": "Is the woman farther from the camera than the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman farther from the camera than a man, who are having a heated discussion about their inability to conceive a baby. ZR%#B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c6a9d0f5f174a7b89e125b50a2113fa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a1f94854245842fa9f1318ffcc1c8c39", "source": "vatex", "video_id": "M41kZ-3XS2c_000003_000013", "video_description": "A man is standing outside in a snow-covered yard, throwing an axe at a brightly colored bullseye target.", "task": "Counting", "clean_prompt": "A man is standing outside in a snow-covered yard, throwing an axe at a brightly colored bullseye target with seven targets set up in a row.", "clean_property": {"obj": "target", "count": "seven"}, "target_prompt": "A man is standing outside in a snow-covered yard, throwing an axe at three brightly colored bullseye targets arranged in a triangle.", "target_property": {"obj": "target", "count": "three"}, "evaluation_question": "Are there exactly **seven** targets set up in the yard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is standing outside in a snow-covered yard, throwing an axe at a brightly colored bullseye target with seven targets set up in a row. #BC80", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/15d569473ddb44ffb379dc7bd2a84789.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f7b80ce7dda14520a874683460d1c13b", "source": "vatex", "video_id": "_zC4lS-_TxU_000183_000193", "video_description": "A young man is in a bathroom, shaving his face with a razor, focusing on his goatee, and cleaning the razor in the sink.", "task": "ActionRecognition", "clean_prompt": "A person washing hands in a bathroom.", "clean_property": {"obj": "person", "action": "washing hands", "target": null}, "target_prompt": "A person brushing teeth in a bathroom.", "target_property": {"obj": "person", "action": "brushing teeth", "target": null}, "evaluation_question": "Is the person **washing hands**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person washing hands in a bathroom. MV@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a56d6787693f435eabfae395dadbfacf.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ca8a62fea2c0442fad5f18e94d90f038", "source": "vatex", "video_id": "cqL8A6sznp8_000458_000468", "video_description": "A woman is demonstrating various methods of cooking eggs, including frying, poaching, and boiling, using a pan and a spoon.", "task": "AttributeRecognition", "clean_prompt": "A woman demonstrating various methods of cooking eggs using a metal spoon.", "clean_property": {"obj": "spoon", "attribute": "metal"}, "target_prompt": "A woman demonstrating various methods of cooking eggs using a wooden spoon.", "target_property": {"obj": "spoon", "attribute": "wooden"}, "evaluation_question": "Is the woman using a **metal** spoon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating various methods of cooking eggs using a metal spoon. /?))=", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/adb578b625754d6ab137f34b374a4798.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "33642d7bb3bd441b8050c0311416bd0c", "source": "vatex", "video_id": "mkAta6Qm08k_000405_000415", "video_description": "Two little girls are having a beauty day, playing with makeup and eating snacks in their bedroom. One girl is wearing a face mask or sleep mask, and they are sitting at a table or on the bed.", "task": "Counting", "clean_prompt": "Two little girls are having a beauty day, playing with makeup and eating two snacks in their bedroom.", "clean_property": {"obj": "snack", "count": "two"}, "target_prompt": "Two little girls are having a beauty day, playing with makeup and eating four snacks in their bedroom.", "target_property": {"obj": "snack", "count": "four"}, "evaluation_question": "Are there exactly **two** snacks being eaten by the girls?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two little girls are having a beauty day, playing with makeup and eating two snacks in their bedroom. |BCJV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d9685af9b4240cd8c6ff9bc11400038.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "47228860d7cf4993a15eaff2c27660ec", "source": "vatex", "video_id": "5kGXuLG3sl8_000000_000010", "video_description": "A man in a workshop is welding metal objects, including pipes, while wearing protective gear.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of welding equipment in a workshop.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "welding equipment"}, "target_prompt": "A person standing to the left of welding equipment in a workshop.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "welding equipment"}, "evaluation_question": "Is the person to the **right** of the welding equipment?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of welding equipment in a workshop. ))!F*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/88220b1a771140288c11b8c07da6a810.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d458596ca02499ea6db276096800983", "source": "vatex", "video_id": "MDv3kRCzIG4_000002_000012", "video_description": "A man in a gym is performing weightlifting exercises, lifting a heavy barbell from the floor to above his head in multiple movements.", "task": "SpatialUnderstanding", "clean_prompt": "A barbell positioned to the left of a person lifting weights in a gym.", "clean_property": {"obj_1": "barbell", "relation": "left of", "obj_2": "person"}, "target_prompt": "A barbell positioned to the right of a person lifting weights in a gym.", "target_property": {"obj_1": "barbell", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the barbell to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A barbell positioned to the left of a person lifting weights in a gym. @EZ'E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/daf54d23067c400ca44ba551bd8b57be.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "003ccc2d0b9e4b0b8c3f4d8cff254414", "source": "vatex", "video_id": "uAgowt0SvBg_000002_000012", "video_description": "A young woman is performing sit-up exercises with a twist on a gym floor.", "task": "AttributeRecognition", "clean_prompt": "A young woman is performing sit-up exercises with a twist on a hard floor.", "clean_property": {"obj": "floor", "attribute": "hard"}, "target_prompt": "A young woman is performing sit-up exercises with a twist on a soft floor.", "target_property": {"obj": "floor", "attribute": "soft"}, "evaluation_question": "Is the floor **hard**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman is performing sit-up exercises with a twist on a hard floor. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3da877e809124318852938d5f60a9c57.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3c052fa7788f49398735230df6353dac", "source": "vatex", "video_id": "458ISYfR7dU_000000_000010", "video_description": "A person is watching and recording a professional ice hockey game on television, occasionally pausing the playback.", "task": "SpatialUnderstanding", "clean_prompt": "A crowd standing to the left of a television.", "clean_property": {"obj_1": "crowd", "relation": "left of", "obj_2": "television"}, "target_prompt": "A crowd standing to the right of a television.", "target_property": {"obj_1": "crowd", "relation": "right of", "obj_2": "television"}, "evaluation_question": "Is the crowd to the **left** of a television?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd standing to the left of a television. GN@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/37d83a5dc013432cb7f46016b4efeba3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "80fa0757f60e4208885104762231f344", "source": "vatex", "video_id": "hGavd8uM6GY_000003_000013", "video_description": "A man is holding a saxophone, posing for a photo, and then begins to play the saxophone.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a trombone.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "trombone"}, "target_prompt": "A person standing to the left of a trombone.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "trombone"}, "evaluation_question": "Is the person to the **right** of a trombone?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a trombone. !0||B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/05e4e2da7fb042cf887657a536016aad.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7d303b037cdf4e459d61867bf531f854", "source": "vatex", "video_id": "RFyFZJJGK_g_000000_000010", "video_description": "A woman is practicing scuba diving skills in a deep swimming pool, wearing full scuba gear.", "task": "ObjectRecognition", "clean_prompt": "A woman practicing scuba diving skills in a deep swimming pool, wearing full scuba gear.", "clean_property": {"obj": "scuba diver"}, "target_prompt": "A skydiver performing a jump from an airplane.", "target_property": {"obj": "skydiver"}, "evaluation_question": "Is the person in the video a **scuba diver**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman practicing scuba diving skills in a deep swimming pool, wearing full scuba gear. ELLG+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8833ad179a864c35b3724c2d34aa6504.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b1eb8a8c4e4949a494e5f27a0361e593", "source": "vatex", "video_id": "oRrwzU5iADM_000025_000035", "video_description": "A young man opens a refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "task": "Counting", "clean_prompt": "A young man opens two refrigerator doors in a living room, and then disappears as the doors close by themselves, creating a magical effect.", "clean_property": {"obj": "refrigerator", "count": "two"}, "target_prompt": "A young man opens one refrigerator door in a living room, and then disappears as the door closes by itself, creating a magical effect.", "target_property": {"obj": "refrigerator", "count": "one"}, "evaluation_question": "Are there exactly **two** refrigerators in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man opens two refrigerator doors in a living room, and then disappears as the doors close by themselves, creating a magical effect. U0Y0A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/16d974cd01da4341b3cd8037853cda3b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c31dfa5c635547bc930cdb0ebeb864d4", "source": "vatex", "video_id": "9i4GqMpwyxs_000000_000010", "video_description": "A man is speaking on a large screen, such as a television or jumbo tron, while a woman interprets his speech into sign language. A crowd, including children and young people, is watching the event.", "task": "Counting", "clean_prompt": "Two women interpreting a man's speech into sign language on a large screen while a crowd watches.", "clean_property": {"obj": "woman", "count": "two"}, "target_prompt": "One woman interpreting a man's speech into sign language on a large screen while a crowd watches.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **two** women interpreting the speech?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women interpreting a man's speech into sign language on a large screen while a crowd watches. FE(.X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/46ba2b132e764775a06f2c546ebaf8d2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7dfff72adb0c4bd78dcbeaf4c9ab6285", "source": "vatex", "video_id": "p5xrAJ4t65Q_000004_000014", "video_description": "A woman is grooming a dog on a table outdoors, using a brush to comb through the dog's fur.", "task": "ActionRecognition", "clean_prompt": "A woman grooming a dog on a table outdoors.", "clean_property": {"obj": "woman", "action": "grooming dog", "target": "dog"}, "target_prompt": "A woman playing with a dog on a table outdoors.", "target_property": {"obj": "woman", "action": "playing with dog", "target": "dog"}, "evaluation_question": "Is the woman **grooming** the dog?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman grooming a dog on a table outdoors. !G%|A", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3750342195664ca4a5e1a716eacf7881.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c05d407dee7b4235bd1c47157c23a53d", "source": "vatex", "video_id": "g6yEo68W2Ic_000038_000048", "video_description": "A group of motorcyclists perform stunts inside a large metal spherical cage, with a cheering crowd.", "task": "SpatialUnderstanding", "clean_prompt": "A crowd closer to the camera than a motorcycle in a large metal spherical cage.", "clean_property": {"obj_1": "crowd", "relation": "closer to the camera than", "obj_2": "motorcycle"}, "target_prompt": "A crowd further from the camera than a motorcycle in a large metal spherical cage.", "target_property": {"obj_1": "crowd", "relation": "further from the camera than", "obj_2": "motorcycle"}, "evaluation_question": "Is the crowd **closer to the camera than** the motorcycle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A crowd closer to the camera than a motorcycle in a large metal spherical cage. FS%A(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b6cbfd15be5d4ffa8f97930075add271.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6bf51c25c35c4ec58d8edd4a9e15923d", "source": "vatex", "video_id": "6XVUY3rdGtk_000000_000010", "video_description": "A woman is exercising outdoors on a court, using two heavy ropes to perform a workout by swinging them up and down.", "task": "ActionRecognition", "clean_prompt": "A woman performing battle rope training outdoors on a court.", "clean_property": {"obj": "woman", "action": "battle rope training", "target": null}, "target_prompt": "A woman practicing yoga outdoors on a court.", "target_property": {"obj": "woman", "action": "yoga", "target": null}, "evaluation_question": "Is the woman **performing battle rope training**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman performing battle rope training outdoors on a court. OF.BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/195f5a16b880477cb297cad3309530fd.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b0a3052b2d134e7da98fa9c2179e0327", "source": "vatex", "video_id": "IH4_ueC5oV0_000007_000017", "video_description": "A young man is standing in a room, practicing and playing music on a saxophone.", "task": "ActionRecognition", "clean_prompt": "A person playing saxophone in a room.", "clean_property": {"obj": "person", "action": "playing saxophone", "target": null}, "target_prompt": "A person playing guitar in a room.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing saxophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing saxophone in a room. OF,BS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5761c5fd9f6d4bb5bcb19965629a4001.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e8fcba1dc7264da5a972fda20b52c043", "source": "vatex", "video_id": "uGu7ZUTyoew_000000_000010", "video_description": "Two young girls in matching dresses are swinging on a swing set in a park on a sunny day.", "task": "Counting", "clean_prompt": "Seven girls in matching dresses are swinging on a swing set in a park on a sunny day.", "clean_property": {"obj": "girl", "count": "seven"}, "target_prompt": "Three girls in colorful outfits are playing on a playground with slides and climbing structures.", "target_property": {"obj": "girl", "count": "three"}, "evaluation_question": "Are there exactly **seven** girls swinging on the swing set?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven girls in matching dresses are swinging on a swing set in a park on a sunny day. UD1@#", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cd96a45db96b43e88bdb2fe9b31484c6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "179d2037f530443c854535f8a1534554", "source": "vatex", "video_id": "6p5XzdD0dYo_000086_000096", "video_description": "A person is demonstrating how to fold a green piece of paper into origami shapes.", "task": "AttributeRecognition", "clean_prompt": "A person is demonstrating how to fold a green piece of paper into origami shapes.", "clean_property": {"obj": "paper", "attribute": "green"}, "target_prompt": "A person is demonstrating how to fold a red piece of paper into origami shapes.", "target_property": {"obj": "paper", "attribute": "red"}, "evaluation_question": "Is the piece of paper **green**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is demonstrating how to fold a green piece of paper into origami shapes. JSJFV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ca5356ac18304dc081a2b9581c1319b7.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "58faaf445d4242c8b3ed364ea51c34d6", "source": "vatex", "video_id": "PetC18IbTtQ_000155_000165", "video_description": "A choir of African American men and women sing gospel songs enthusiastically in a church, led by a pastor. They sway, clap, and sing hymns during a service.", "task": "SpatialUnderstanding", "clean_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically.", "clean_property": {"obj_1": "choir", "relation": "left of", "obj_2": "pastor"}, "target_prompt": "A choir to the right of a pastor in a church, singing gospel songs enthusiastically.", "target_property": {"obj_1": "choir", "relation": "right of", "obj_2": "pastor"}, "evaluation_question": "Is the choir to the **left** of the pastor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A choir to the left of a pastor in a church, singing gospel songs enthusiastically. X$B$V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/85b755a51ece433e9fbd625eef0b83de.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "46d9c77f37914632a59bb8ac845f1083", "source": "vatex", "video_id": "H-WKE7WUY5k_000045_000055", "video_description": "A man in a workshop is welding a large metal piece while wearing full protective gear, including a safety mask.", "task": "ObjectRecognition", "clean_prompt": "A man welding a large metal piece in a workshop while wearing full protective gear.", "clean_property": {"obj": "metal"}, "target_prompt": "A man carving a large wooden piece in a workshop while wearing full protective gear.", "target_property": {"obj": "wood"}, "evaluation_question": "Is the man working with **metal** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man welding a large metal piece in a workshop while wearing full protective gear. LYXAA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bf464420276449e28b061e36bb3a1828.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5cda6f347c004ad6a52f0a17ea9d31ea", "source": "vatex", "video_id": "8ji3VkUal2c_000003_000013", "video_description": "A man is sitting on the floor holding a board while a young boy breaks it with a karate kick, with a cheering crowd.", "task": "ActionRecognition", "clean_prompt": "A boy breaking boards with a karate kick in front of a cheering crowd.", "clean_property": {"obj": "boy", "action": "breaking boards", "target": "board"}, "target_prompt": "A boy throwing boards in front of a cheering crowd.", "target_property": {"obj": "boy", "action": "throwing boards", "target": "board"}, "evaluation_question": "Is the boy **breaking** boards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy breaking boards with a karate kick in front of a cheering crowd. &MEO@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b01457cf9b4843788042fc5baf42bb7e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1ad586ea50f64bc19feafa61a6965559", "source": "vatex", "video_id": "a5YwI62ouao_000176_000186", "video_description": "A person is demonstrating how to make balloon animals using brown and yellow balloons, while explaining the process.", "task": "AttributeRecognition", "clean_prompt": "A person demonstrating how to make balloon animals using a yellow balloon.", "clean_property": {"obj": "balloon", "attribute": "yellow"}, "target_prompt": "A person demonstrating how to make balloon animals using a red balloon.", "target_property": {"obj": "balloon", "attribute": "red"}, "evaluation_question": "Is the balloon being used in the demonstration **yellow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating how to make balloon animals using a yellow balloon. W%|>2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f28ef5a17caf486f843cb1692f7ca3c6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "03b3b132da16408c9cf37e9209fdb6f5", "source": "vatex", "video_id": "X9zMOVnZmN0_000048_000058", "video_description": "A group of young women in black and pink costumes are performing a tap dance routine on stage in front of a large audience.", "task": "ObjectRecognition", "clean_prompt": "A group of young women in black and pink costumes performing a tap dance routine on stage in front of a large audience.", "clean_property": {"obj": "dancer"}, "target_prompt": "A group of young women in black and pink costumes singing on stage in front of a large audience.", "target_property": {"obj": "singer"}, "evaluation_question": "Are the performers in the video **dancers**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of young women in black and pink costumes performing a tap dance routine on stage in front of a large audience. SG/PD", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/049ac7c2d9d842f28f28fb7811ab3cc5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "09ddb57a79fa46188e622c5e130ee3de", "source": "vatex", "video_id": "ZiUz5arlOhk_000172_000182", "video_description": "A person is drawing a cartoon character resembling a princess or Snow White using a black pen on white paper, accompanied by whimsical music.", "task": "AttributeRecognition", "clean_prompt": "A person is drawing a cartoon character resembling a princess using a black pen on white paper, accompanied by whimsical music.", "clean_property": {"obj": "pen", "attribute": "black"}, "target_prompt": "A person is drawing a cartoon character resembling a princess using a red pen on white paper, accompanied by whimsical music.", "target_property": {"obj": "pen", "attribute": "red"}, "evaluation_question": "Is the person using a **black** pen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is drawing a cartoon character resembling a princess using a black pen on white paper, accompanied by whimsical music. .'NYJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8a7fdd07f4214ff5bdfea826ebe19b4a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42628a98236e495ea96061a00d85df17", "source": "vatex", "video_id": "73GtJJmiSe4_000000_000010", "video_description": "A young boy is eating a vanilla ice cream cone and talking while riding in a car with his mother, who is driving and also eating ice cream.", "task": "ActionRecognition", "clean_prompt": "A mother driving a car.", "clean_property": {"obj": "mother", "action": "driving car", "target": null}, "target_prompt": "A mother playing guitar.", "target_property": {"obj": "mother", "action": "playing guitar", "target": null}, "evaluation_question": "Is the mother **driving** a car?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A mother driving a car. FS+\u00b7K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/94ae396feac7425ea45c26b959478471.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e2e3f15b585440eaa4b21004b92ef4a7", "source": "vatex", "video_id": "Lrgs9rwTHuY_000043_000053", "video_description": "A person is performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music.", "task": "Counting", "clean_prompt": "Three people performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people performing water sports on the lake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people performing water sports at night on a well-lit lake, including water skiing and wakeboarding, accompanied by rock music. GNFE@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ce092747482449a18cbc6be650f84bb3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1243a3363ca94bc69e4ae77b3c28398d", "source": "vatex", "video_id": "m4xsBl0bp9A_000025_000035", "video_description": "A man, acting as a teacher, is demonstrating and explaining math problems on a chalkboard, including equations involving triangles and angles.", "task": "ActionRecognition", "clean_prompt": "A teacher writing math problems on a chalkboard.", "clean_property": {"obj": "teacher", "action": "writing", "target": "chalkboard"}, "target_prompt": "A teacher erasing a chalkboard.", "target_property": {"obj": "teacher", "action": "erasing", "target": "chalkboard"}, "evaluation_question": "Is the teacher **writing** on the chalkboard?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teacher writing math problems on a chalkboard. MB=V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fc74b6a293334393b37ce65ea40a3a7c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2b52d6736d204716851e5b1746bbdb87", "source": "vatex", "video_id": "9ANMf4YyG9c_000046_000056", "video_description": "A young boy is playing with a fidget spinner indoors, demonstrating how to use it, and occasionally dropping it.", "task": "ActionRecognition", "clean_prompt": "A boy fidgeting with a fidget spinner indoors.", "clean_property": {"obj": "boy", "action": "fidgeting", "target": "fidget spinner"}, "target_prompt": "A boy throwing a fidget spinner indoors.", "target_property": {"obj": "boy", "action": "throwing", "target": "fidget spinner"}, "evaluation_question": "Is the boy **fidgeting** with the fidget spinner?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy fidgeting with a fidget spinner indoors. >38FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2c71f3367890497b99a8315337e288ad.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0f3e0b6c4385443dac78d8181cc066af", "source": "vatex", "video_id": "a0--3BQHfwk_000065_000075", "video_description": "A young man is demonstrating and explaining how to clean a pair of black leather boots using a cloth and a blue towel.", "task": "Counting", "clean_prompt": "Two young men demonstrating how to clean a pair of black leather boots using a cloth and a blue towel.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One young man demonstrating how to clean a pair of black leather boots using a cloth and a blue towel.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** young men demonstrating the cleaning process?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two young men demonstrating how to clean a pair of black leather boots using a cloth and a blue towel. >BC$K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b9d26a8c8cf44859bdd57ea0efbf69c0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3f22f16eca964c9f8d1a3aabe609a6f0", "source": "vatex", "video_id": "h-1VpOK07vg_000067_000077", "video_description": "Two teams of children, wearing team uniforms and safety gear, are playing a game of lacrosse on an open field in a park. The teams are in red and white uniforms, and the game is taking place on a sunny day.", "task": "Counting", "clean_prompt": "Six children in red and white uniforms are playing lacrosse with a ball on a sunny day in a park.", "clean_property": {"obj": "ball", "count": "six"}, "target_prompt": "Two teams of children in uniforms are playing lacrosse with one ball on a sunny day in a park.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **six** balls being used in the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six children in red and white uniforms are playing lacrosse with a ball on a sunny day in a park. -0BC1", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7474f0f2588c4382a7275576ec2f9f21.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7babab5c78fc4c4db537f7f1f6d20d04", "source": "vatex", "video_id": "uERX4zE4-4U_000008_000018", "video_description": "A group of young children, including four girls and one boy, are practicing tap dancing in a dance studio. They are wearing ballet dresses and tap dance shoes. A woman is instructing them.", "task": "Counting", "clean_prompt": "A woman instructing seven young children in tap dancing.", "clean_property": {"obj": "woman", "count": "seven"}, "target_prompt": "A woman instructing three young children in tap dancing.", "target_property": {"obj": "woman", "count": "three"}, "evaluation_question": "Are there exactly **seven** young children being instructed?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman instructing seven young children in tap dancing. RL+.E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cf885d195b954b749629d749577cb03c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5cfa8fd2f5e345f9a97db83bf5a5ff24", "source": "vatex", "video_id": "zAO7HLux_I8_000025_000035", "video_description": "A man is demonstrating how to properly do push-ups in a gym setting.", "task": "AttributeRecognition", "clean_prompt": "A screen displaying exercise instructions for push-ups in a gym setting.", "clean_property": {"obj": "screen", "attribute": "displaying exercise instructions"}, "target_prompt": "A screen displaying cooking recipes in a kitchen setting.", "target_property": {"obj": "screen", "attribute": "displaying cooking recipes"}, "evaluation_question": "Is the screen displaying **exercise instructions**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A screen displaying exercise instructions for push-ups in a gym setting. JS$M4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7965eeaa17d042d39ae6fa17277518e6.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "20331400003d49a687a3eba2804b4b2f", "source": "vatex", "video_id": "uGt1mpsoERY_000048_000058", "video_description": "A woman is demonstrating various techniques and tools to adjust and fasten traditional garments, including a sari.", "task": "SpatialUnderstanding", "clean_prompt": "A garment positioned to the left of a person demonstrating how to adjust and fasten it.", "clean_property": {"obj_1": "garment", "relation": "left of", "obj_2": "person"}, "target_prompt": "A garment positioned to the right of a person demonstrating how to adjust and fasten it.", "target_property": {"obj_1": "garment", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the garment to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A garment positioned to the left of a person demonstrating how to adjust and fasten it. XVDRV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0aedc5755ce948f691b4eaa0d9734f16.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2abb4a2d3da440acb7f93e23ce59cd03", "source": "vatex", "video_id": "A-j7rCGIrI4_000086_000096", "video_description": "A young man, frustrated and angry, searches for food in a refrigerator, finds nothing, then opens the freezer and finds hot dogs, calming down.", "task": "SpatialUnderstanding", "clean_prompt": "A freezer located to the left of a person searching for food.", "clean_property": {"obj_1": "freezer", "relation": "left of", "obj_2": "person"}, "target_prompt": "A freezer located to the right of a person searching for food.", "target_property": {"obj_1": "freezer", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Is the freezer to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A freezer located to the left of a person searching for food. ;C:OC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed8917b2db9d4e808f494ed69ce2eb45.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a276ffe5b3747c4a63e632878136c0f", "source": "vatex", "video_id": "95X9TWCXS90_000057_000067", "video_description": "A large group of people, including men, women, and children, are roller skating in an indoor roller skating rink with flashing lights and music playing.", "task": "ObjectRecognition", "clean_prompt": "A large group of people, including men, women, and children, are roller skating in an indoor roller skating rink with flashing lights and music playing.", "clean_property": {"obj": "roller skates"}, "target_prompt": "A large group of people, including men, women, and children, are ice skating in an indoor ice skating rink with flashing lights and music playing.", "target_property": {"obj": "ice skates"}, "evaluation_question": "Are the people in the video using **roller skates**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A large group of people, including men, women, and children, are roller skating in an indoor roller skating rink with flashing lights and music playing. %|!:&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e9982d5e43e947aa800eaf094c7fb502.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "118138aadd68459bb1932e6ce16b165e", "source": "vatex", "video_id": "OqaokhKLJDw_000001_000011", "video_description": "A person is practicing archery indoors, using a bow and arrow to shoot at a target.", "task": "AttributeRecognition", "clean_prompt": "A person practicing archery indoors, shooting arrows at a wooden target.", "clean_property": {"obj": "target", "attribute": "wood"}, "target_prompt": "A person practicing archery indoors, shooting arrows at a metal target.", "target_property": {"obj": "target", "attribute": "metal"}, "evaluation_question": "Is the target made of **wood**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person practicing archery indoors, shooting arrows at a wooden target. UTB91", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e3841a7632a74b5d8c7e2403c044c3ea.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "dfc8f74e46704e7e89709e680819c79c", "source": "vatex", "video_id": "Ca78lDSy4to_000122_000132", "video_description": "A person is demonstrating how to fold a piece of white paper into an origami design on a table.", "task": "ActionRecognition", "clean_prompt": "A person folding a piece of white paper into an origami design on a table.", "clean_property": {"obj": "person", "action": "folding paper", "target": null}, "target_prompt": "A person tearing a piece of white paper on a table.", "target_property": {"obj": "person", "action": "tearing paper", "target": null}, "evaluation_question": "Is the person **folding** paper?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding a piece of white paper into an origami design on a table. FE%%T", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/eb380e4e82ce4479b02d1e54236c11f6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b2b673114f9243589a6df2b4a87254ac", "source": "vatex", "video_id": "qIWQHyOIpEY_000003_000013", "video_description": "Three cats are in a living room with a man and a woman. Two cats are lounging on the floor, and one cat is being petted by the man. The floor is hardwood, and a non-English language is spoken in the background.", "task": "AttributeRecognition", "clean_prompt": "A black and white cat lounging in a living room with a man and a woman.", "clean_property": {"obj": "cat", "attribute": "black and white"}, "target_prompt": "An orange cat lounging in a living room with a man and a woman.", "target_property": {"obj": "cat", "attribute": "orange"}, "evaluation_question": "Is the cat **black and white**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A black and white cat lounging in a living room with a man and a woman. =SLG$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57d1b989b0834535ae2c68e109bbeec6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5c37bf29d84d464fb41c4f8ab268f3ae", "source": "vatex", "video_id": "GHPGrJdclxs_000005_000015", "video_description": "A shirtless man is in a gym lifting a heavy barbell and performing squats while another person instructs and encourages him.", "task": "ActionRecognition", "clean_prompt": "A person squatting with a heavy barbell in a gym.", "clean_property": {"obj": "person", "action": "squat", "target": "barbell"}, "target_prompt": "A person lifting dumbbells in a gym.", "target_property": {"obj": "person", "action": "lifting weights", "target": "dumbbells"}, "evaluation_question": "Is the person **squatting** with a barbell?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person squatting with a heavy barbell in a gym. *SLMV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/abb0bb7250f44f43a0c2fa497d44eb0f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "42a88aa2d6b14087ac8c0ee64a3f0f17", "source": "vatex", "video_id": "VZIcu3ibJew_000085_000095", "video_description": "A person is lying down while a technician pierces their ear and installs jewelry.", "task": "SpatialUnderstanding", "clean_prompt": "A technician standing to the left of a needle while piercing an ear.", "clean_property": {"obj_1": "technician", "relation": "left of", "obj_2": "needle"}, "target_prompt": "A technician standing to the right of a needle while piercing an ear.", "target_property": {"obj_1": "technician", "relation": "right of", "obj_2": "needle"}, "evaluation_question": "Is the technician to the **left** of the needle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A technician standing to the left of a needle while piercing an ear. !0D$)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dc0777420f1e47e1be89d92a34e81019.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e6f89580c5174caba46d276da48c6356", "source": "vatex", "video_id": "p6TviZmyrDc_000063_000073", "video_description": "A woman is grooming a small white dog with curly hair on a grooming table, using scissors to trim and style the dog's fur.", "task": "Counting", "clean_prompt": "A woman is grooming three small white dogs with curly hair on a grooming table, using scissors to trim and style their fur.", "clean_property": {"obj": "table", "count": "three"}, "target_prompt": "A woman is grooming one small white dog with curly hair on a grooming table, using scissors to trim and style its fur.", "target_property": {"obj": "dog", "count": "one"}, "evaluation_question": "Are there exactly **three** small white dogs being groomed on the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is grooming three small white dogs with curly hair on a grooming table, using scissors to trim and style their fur. #HR@@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8d89c3efa6cc4cadb1909beaa12e4ad3.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9224017424344a66a9103c69620e4b4b", "source": "vatex", "video_id": "e5qBwONhahU_000000_000010", "video_description": "A young man is riding a skateboard down a city sidewalk. Another young man appears and looks at the camera.", "task": "ObjectRecognition", "clean_prompt": "A young man is riding a skateboard down a city sidewalk.", "clean_property": {"obj": "skateboard"}, "target_prompt": "A young man is riding a bicycle down a city sidewalk.", "target_property": {"obj": "bicycle"}, "evaluation_question": "Is the young man riding a **skateboard**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man is riding a skateboard down a city sidewalk. /?W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/adb9573d75914227ad1b31a78e1e01d5.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "347532cd47664835bbd47e2ca90e9847", "source": "vatex", "video_id": "k1D0uRYd28E_000074_000084", "video_description": "A young person is sitting at a table, creating rhythmic beats using a pen and their hands.", "task": "ActionRecognition", "clean_prompt": "A person tapping a pen on a table.", "clean_property": {"obj": "person", "action": "tapping pen", "target": "table"}, "target_prompt": "A person throwing a pen on the floor.", "target_property": {"obj": "person", "action": "throwing pen", "target": "floor"}, "evaluation_question": "Is the person **tapping** a pen on a table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person tapping a pen on a table. &)!0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/118dca4428ed407a84fed1633addcd05.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1125027c71b14de689aba86a2a7e8cc9", "source": "vatex", "video_id": "bCWg_x56TAM_000006_000016", "video_description": "A group of people, including adults and children, are sitting around a campfire, roasting marshmallows, and interacting with a camera by waving and saying hello.", "task": "ActionRecognition", "clean_prompt": "A person waving hand at the camera while sitting around a campfire with others.", "clean_property": {"obj": "person", "action": "waving hand", "target": "camera"}, "target_prompt": "A person jumping at the camera while sitting around a campfire with others.", "target_property": {"obj": "person", "action": "jumping", "target": "camera"}, "evaluation_question": "Is the person **waving hand** at the camera?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person waving hand at the camera while sitting around a campfire with others. =-ET?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13734a7b0d9240d1b3a1e19e79aefd43.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "77680d9556604fb288190f70b8972b1a", "source": "vatex", "video_id": "n4D9Vp_sKQU_000006_000016", "video_description": "A man is sitting at a table eating a large, multilayered hamburger with lettuce and tomato, taking big bites.", "task": "Counting", "clean_prompt": "Two people sitting at a table, one eating a large, multilayered hamburger with lettuce and tomato, taking big bites.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person sitting at a table, eating a large, multilayered hamburger with lettuce and tomato, taking big bites.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people sitting at a table, one eating a large, multilayered hamburger with lettuce and tomato, taking big bites. U*D=!", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/41aa3c138d54482395b5f7a2d3799e43.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fd4a5f1cd7354e7e84bbf4cc57cac950", "source": "vatex", "video_id": "PWPcYEaGYRU_000001_000011", "video_description": "Martial arts students are practicing breaking wooden boards in a gym setting. Instructors hold the boards while students perform various techniques to break them.", "task": "Counting", "clean_prompt": "Four instructors holding wooden boards while martial arts students practice breaking them in a gym.", "clean_property": {"obj": "instructor", "count": "four"}, "target_prompt": "One instructor holding a wooden board while a martial arts student practices breaking it in a gym.", "target_property": {"obj": "instructor", "count": "one"}, "evaluation_question": "Are there exactly **four** instructors holding wooden boards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four instructors holding wooden boards while martial arts students practice breaking them in a gym. MT9O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95d1946dfc26474b87e51dbf6fc79dfb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f079bd4c39fe4c45a80462893346eda8", "source": "vatex", "video_id": "cNGqWxux-i0_000006_000016", "video_description": "Two people, a man and a woman, are fencing with balloons attached to their heads at an outdoor festival. A crowd watches and laughs as they try to pop each other's balloons.", "task": "SpatialUnderstanding", "clean_prompt": "A fencer farther from the camera than a crowd at an outdoor festival.", "clean_property": {"obj_1": "fencer", "relation": "farther from the camera than", "obj_2": "crowd"}, "target_prompt": "A fencer closer to the camera than a crowd at an outdoor festival.", "target_property": {"obj_1": "fencer", "relation": "closer to the camera than", "obj_2": "crowd"}, "evaluation_question": "Is the fencer **farther from the camera than** the crowd?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A fencer farther from the camera than a crowd at an outdoor festival. !B*2B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c9489d96bf874145aafe421c84bb9f4c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c7a35aef3db240ea893859aa5af97eb4", "source": "vatex", "video_id": "e2gxZe1Q-us_000251_000261", "video_description": "A young girl is sitting at a table demonstrating the basics of playing dominoes, explaining the rules and how to match numbers on the tiles.", "task": "ActionRecognition", "clean_prompt": "A girl playing dominoes at a table.", "clean_property": {"obj": "girl", "action": "playing dominoes", "target": null}, "target_prompt": "A girl building a tower with blocks at a table.", "target_property": {"obj": "girl", "action": "building a tower", "target": null}, "evaluation_question": "Is the girl **playing dominoes**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl playing dominoes at a table. JSLTP", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2fc2221176da48e48a6c92be85629612.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b3664d7c5f2e4ada9a104d3e9b91e3c5", "source": "vatex", "video_id": "yVRvu8xCixY_000248_000258", "video_description": "A man is sitting at a desk by a window, typing on a computer keyboard while smoking a pipe.", "task": "Counting", "clean_prompt": "Two people sitting at a desk by a window, one typing on a computer keyboard while the other reads a book.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "A person sitting at a desk by a window, typing on a computer keyboard while smoking a pipe.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people at the desk?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people sitting at a desk by a window, one typing on a computer keyboard while the other reads a book. @,)S\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c802d4afdd774fc789b5d9fba16b71d1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8755a39b572d4ebca0bebacf6425a334", "source": "vatex", "video_id": "Lmwnxz5L1Eo_000007_000017", "video_description": "A group of people, including men and a woman, are singing, clapping, and dancing together in a dimly lit living room.", "task": "Counting", "clean_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person singing alone in a brightly lit room.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people singing in the living room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people singing, clapping, and dancing together in a dimly lit living room. >3%SJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/965ee2d5975d4d749164cc229813f4ab.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3ee7b1148c2545c686a275724113f7be", "source": "vatex", "video_id": "n_YDbQ_ZSTA_000000_000010", "video_description": "A young boy is laying on his stomach on a bed in a bedroom, reading from a piece of paper or newspaper and smiling.", "task": "ActionRecognition", "clean_prompt": "A boy reading a book on a bed in a bedroom.", "clean_property": {"obj": "boy", "action": "reading book", "target": "paper"}, "target_prompt": "A boy drawing on a piece of paper in a bedroom.", "target_property": {"obj": "boy", "action": "drawing", "target": "paper"}, "evaluation_question": "Is the boy **reading** a book?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy reading a book on a bed in a bedroom. LY%R@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9171879861694205b485dbcc65000ba3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d891032b84064537ac75d11961b02a8b", "source": "vatex", "video_id": "JSd8C0Ms-G0_000050_000060", "video_description": "A teenage girl with red hair is sitting in her bedroom, rubbing lotion on her hands while talking to the camera.", "task": "AttributeRecognition", "clean_prompt": "A teenage girl with red hair sitting in her bedroom, rubbing lotion on her hands while talking to the camera.", "clean_property": {"obj": "girl", "attribute": "teenage"}, "target_prompt": "A child with red hair sitting in a colorful playroom, playing with toys while talking to the camera.", "target_property": {"obj": "girl", "attribute": "child"}, "evaluation_question": "Is the girl a **teenager**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A teenage girl with red hair sitting in her bedroom, rubbing lotion on her hands while talking to the camera. SL/J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed82271c76f047829557d2e8d1ad7f8b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "84944a7629654392a3a932da516ff164", "source": "vatex", "video_id": "22glIZfA9R4_000115_000125", "video_description": "A group of people, including children and adults, are assembling and playing with a toy train track and toy cars on the floor. A bridge is part of the track setup.", "task": "Counting", "clean_prompt": "Three toy cars racing on a colorful toy train track.", "clean_property": {"obj": "toy car", "count": "three"}, "target_prompt": "One toy car racing on a colorful toy train track.", "target_property": {"obj": "toy car", "count": "one"}, "evaluation_question": "Are there exactly **three** toy cars racing on the track?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three toy cars racing on a colorful toy train track. @&,OC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d62fce25538441c586f37b4eaef5162a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5f0a383517d54c0bb573d614ed037689", "source": "vatex", "video_id": "B4Zk7uw432k_000000_000010", "video_description": "A woman is using an iron and a hand-held steamer to press clothes on an ironing board in a large room while music plays.", "task": "Counting", "clean_prompt": "Four people are in a large room, with one woman using an iron and a hand-held steamer to press clothes on an ironing board while music plays.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "One person is in a large room, using an iron and a hand-held steamer to press clothes on an ironing board while music plays.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four people are in a large room, with one woman using an iron and a hand-held steamer to press clothes on an ironing board while music plays. ?)!F:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd5286aceb474c63b76fb551806dbf52.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fa144abde3cf4ff3ae596d1d183af3e5", "source": "vatex", "video_id": "Q4RRc_nYQpA_000223_000233", "video_description": "A person is folding a piece of yellow paper into an intricate origami design.", "task": "AttributeRecognition", "clean_prompt": "A person folding a piece of yellow paper into an intricate origami design.", "clean_property": {"obj": "paper", "attribute": "yellow"}, "target_prompt": "A person folding a piece of blue paper into an intricate origami design.", "target_property": {"obj": "paper", "attribute": "blue"}, "evaluation_question": "Is the paper being folded **yellow**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding a piece of yellow paper into an intricate origami design. FEHUK", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c864f91124e045d1b1c6afb5d728372a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6d2a8678cd8f44d4b95b87ade7df4f92", "source": "vatex", "video_id": "6ax1E41RuDw_000000_000010", "video_description": "Two men are working together in a kitchen using a machine to make sausages. One man is turning the crank on the machine while the other is attempting to curl the sausages on his lap.", "task": "AttributeRecognition", "clean_prompt": "Two men are working together in a kitchen using a machine to make sausages.", "clean_property": {"obj": "machine", "attribute": "sausage"}, "target_prompt": "Two men are working together in a kitchen using an ice cream maker.", "target_property": {"obj": "machine", "attribute": "ice cream maker"}, "evaluation_question": "Are the men using a **sausage** making machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are working together in a kitchen using a machine to make sausages. 9E%;)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/1292c1113b2d47edb596805cb0630dfa.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2c534138fa3a4210bb60e1dbd40b4273", "source": "vatex", "video_id": "M4_oCq6M_gk_000000_000010", "video_description": "A boy is attempting a handstand on a skateboard in a parking lot. He manages to hold the handstand briefly before falling.", "task": "SpatialUnderstanding", "clean_prompt": "A skateboard farther from the camera than a boy attempting a handstand in a parking lot.", "clean_property": {"obj_1": "skateboard", "relation": "farther from the camera than", "obj_2": "boy"}, "target_prompt": "A skateboard closer to the camera than a boy attempting a handstand in a parking lot.", "target_property": {"obj_1": "skateboard", "relation": "closer to the camera than", "obj_2": "boy"}, "evaluation_question": "Is the skateboard **farther from the camera than** the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A skateboard farther from the camera than a boy attempting a handstand in a parking lot. SG.TY", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dd0ee8a926d5470a86c77cf2d1f50803.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "26f81750664f42ddb7a00cc31e94bcd4", "source": "vatex", "video_id": "XU8FBzKJT-U_000000_000010", "video_description": "A young boy is playing a silver flute in a messy room with dirty laundry.", "task": "Counting", "clean_prompt": "Two boys playing a silver flute in a messy room with dirty laundry.", "clean_property": {"obj": "boy", "count": "two"}, "target_prompt": "A girl playing a golden flute in a tidy room.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **two** boys playing the flute in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys playing a silver flute in a messy room with dirty laundry. )!G%E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0921a5f94d3d4b8ba18d43c3bcf43248.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "82bd1a7ab7be419fa22758bda397e4b6", "source": "vatex", "video_id": "EnU69wUlwqk_000002_000012", "video_description": "A man in an office is using a photocopier to print large black circles on paper.", "task": "ObjectRecognition", "clean_prompt": "A man using a photocopier to print large black circles on paper.", "clean_property": {"obj": "paper"}, "target_prompt": "A man using a photocopier to print large black circles on canvas.", "target_property": {"obj": "canvas"}, "evaluation_question": "Is the man printing on **paper**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man using a photocopier to print large black circles on paper. |-&&:", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/26a3a1d65be74fbc90ab9f4f2c43a610.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9d05e63b01784f719f7c41aee29a5359", "source": "vatex", "video_id": "R6kve7ImQ_Y_000004_000014", "video_description": "A person wearing a hood with cat ears or horns, and makeup, is speaking to the camera and making facial gestures.", "task": "ObjectRecognition", "clean_prompt": "A person wearing a hood with cat ears is speaking to the camera and making facial gestures.", "clean_property": {"obj": "person"}, "target_prompt": "An animal wearing a hood with cat ears is speaking to the camera and making facial gestures.", "target_property": {"obj": "animal"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a hood with cat ears is speaking to the camera and making facial gestures. ''!,%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6eb30ac655114737a7e52dbb8b9396e3.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "47f0c9dffa1b49b19a1d8948ff1a19e2", "source": "vatex", "video_id": "dtmIEWSdjRs_000262_000272", "video_description": "A man is demonstrating and explaining how to sharpen a knife using a sharpening tool and a clamp.", "task": "ActionRecognition", "clean_prompt": "A person sharpening knives using a sharpening tool and a clamp.", "clean_property": {"obj": "person", "action": "sharpening knives", "target": null}, "target_prompt": "A person throwing knives in a workshop.", "target_property": {"obj": "person", "action": "throwing knives", "target": null}, "evaluation_question": "Is the person **sharpening** knives?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sharpening knives using a sharpening tool and a clamp. 41SMC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/245cc47e54d94b22a7391f0877a98268.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d0dbde37422d478fa9bfcff8d764aa37", "source": "vatex", "video_id": "MEXUFRdSvyM_000150_000160", "video_description": "A group of four trapeze artists are practicing and performing tricks on a trapeze outdoors.", "task": "SpatialUnderstanding", "clean_prompt": "A net closer to the camera than a trapeze.", "clean_property": {"obj_1": "net", "relation": "closer to the camera than", "obj_2": "trapeze"}, "target_prompt": "A net farther from the camera than a trapeze.", "target_property": {"obj_1": "net", "relation": "farther from the camera than", "obj_2": "trapeze"}, "evaluation_question": "Is the net closer to the camera than the trapeze?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A net closer to the camera than a trapeze. \u00b7H*ZB", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a1cd8b424b0c486db7c694f3c7b2082e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "13dc347cbc004fb599975e0c33abf343", "source": "vatex", "video_id": "OSaK0ClHirQ_000075_000085", "video_description": "Three young girls are indoors, with two of them washing the hair of the third girl who is reclining in a sink.", "task": "ActionRecognition", "clean_prompt": "A girl washing her hair in a sink.", "clean_property": {"obj": "girl", "action": "washing hair", "target": "girl"}, "target_prompt": "A girl drying her hair in a sink.", "target_property": {"obj": "girl", "action": "drying hair", "target": "girl"}, "evaluation_question": "Is the girl **washing** her hair?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl washing her hair in a sink. >Q#XW", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9fa02797bd57403f94f17da6603da920.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8bfb00a82804c55b1c4ee4af1838d4e", "source": "vatex", "video_id": "E-gaCwIVipE_001233_001243", "video_description": "A young man with long, shoulder-length hair is sitting in a chair while a teenage girl uses a flat iron to straighten his hair. They are in a bedroom, and there is conversation happening in the background.", "task": "Counting", "clean_prompt": "Four teenage girls in a bedroom, one of them straightening a young man's hair with a flat iron while they chat.", "clean_property": {"obj": "teenage girl", "count": "four"}, "target_prompt": "One teenage girl in a bedroom, straightening a young man's hair with a flat iron while they chat.", "target_property": {"obj": "teenage girl", "count": "one"}, "evaluation_question": "Are there exactly **four** teenage girls in the bedroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four teenage girls in a bedroom, one of them straightening a young man's hair with a flat iron while they chat. NKJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/452ac8d35f3b4ce6b358e46631fa9035.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb6bcaa4b4f44c46977b4df726ecd7c7", "source": "vatex", "video_id": "M6jspQBmGx8_000353_000363", "video_description": "A young boy is in a backyard or garden, collecting Easter eggs with a basket, guided by a woman and with a man talking in the background.", "task": "AttributeRecognition", "clean_prompt": "A young boy collecting Easter eggs with a basket in a garden.", "clean_property": {"obj": "basket", "attribute": "Easter"}, "target_prompt": "A young boy collecting Halloween candies with a basket in a garden.", "target_property": {"obj": "basket", "attribute": "Halloween"}, "evaluation_question": "Is the boy collecting Easter eggs with a basket?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young boy collecting Easter eggs with a basket in a garden. !D'?)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/57bae4a0e3444866a1750f452990023e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9dfd6bc711a649768d94c04268f910d1", "source": "vatex", "video_id": "znzMrMEYehs_000000_000010", "video_description": "A group of people are playing a game of kickball outdoors on a park field. Players kick a ball and run around bases while others cheer.", "task": "ObjectRecognition", "clean_prompt": "A group of people playing kickball outdoors on a park field.", "clean_property": {"obj": "ball"}, "target_prompt": "A group of people playing frisbee outdoors on a park field.", "target_property": {"obj": "frisbee"}, "evaluation_question": "Are the people playing with a **kickball**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people playing kickball outdoors on a park field. )SLZ$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/14e36545050e479ca1cf769bf340ef6f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "373f0bbe7d4746f5914bcec1b1194a5e", "source": "vatex", "video_id": "D7ldAgVmg5M_000001_000011", "video_description": "A young man is riding a Segway through an outdoor obstacle course.", "task": "ObjectRecognition", "clean_prompt": "A person riding a Segway through an outdoor obstacle course.", "clean_property": {"obj": "person"}, "target_prompt": "A dog running through an outdoor obstacle course.", "target_property": {"obj": "dog"}, "evaluation_question": "Is the subject in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person riding a Segway through an outdoor obstacle course. >R@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ceebf93cee244657842864307d872bbe.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9592091dd8bd4987b166f850286ec83d", "source": "vatex", "video_id": "OqaokhKLJDw_000001_000011", "video_description": "A person is practicing archery indoors, using a bow and arrow to shoot at a target.", "task": "ObjectRecognition", "clean_prompt": "A person is practicing archery indoors, using a bow and arrow to shoot at a target.", "clean_property": {"obj": "bow"}, "target_prompt": "A person is practicing shooting indoors, using a crossbow to hit a target.", "target_property": {"obj": "crossbow"}, "evaluation_question": "Is the person using a **bow** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is practicing archery indoors, using a bow and arrow to shoot at a target. !%=YV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e284e29693014a6198cb1c87a678e838.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "385ee818830245b2a2257ad9181095bf", "source": "vatex", "video_id": "pFYbvFzOQVc_000028_000038", "video_description": "A young girl is practicing handstands and headstands in her living room, using the wall for support. She occasionally falls, crawls, and talks to the camera.", "task": "ActionRecognition", "clean_prompt": "A girl standing on her hands in her living room.", "clean_property": {"obj": "girl", "action": "standing on hands", "target": null}, "target_prompt": "A girl jumping on a trampoline.", "target_property": {"obj": "girl", "action": "jumping", "target": "trampoline"}, "evaluation_question": "Is the girl **standing on her hands**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl standing on her hands in her living room. A*W0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f7d77fb991c648eb90ba3f18c7cea778.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "5318a2e851c343d7ac53f4282a19e6a4", "source": "vatex", "video_id": "yZnVFmHkwdM_000114_000124", "video_description": "A man is installing and sanding a wooden floor in a room, captured in time-lapse photography.", "task": "Counting", "clean_prompt": "A man is installing and sanding four wooden floors in a room, captured in time-lapse photography.", "clean_property": {"obj": "floor", "count": "four"}, "target_prompt": "A man is installing and sanding one wooden floor in a room, captured in time-lapse photography.", "target_property": {"obj": "floor", "count": "one"}, "evaluation_question": "Are there exactly **four** wooden floors being installed and sanded in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is installing and sanding four wooden floors in a room, captured in time-lapse photography. .AN)|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e87d9fa3044c47cc8152aa2f94074476.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "268d11d043984453b122a9ce5f4fe0dc", "source": "vatex", "video_id": "tMh2VAsrgh4_000053_000063", "video_description": "A person is wrapping a present on the floor near a Christmas tree, using a lot of tape and ribbon, and gives a thumbs up upon completion.", "task": "Counting", "clean_prompt": "A person is wrapping a present on the floor near a Christmas tree, using a lot of tape and ribbon, and gives a thumbs up upon completion with four people watching.", "clean_property": {"obj": "person", "count": "four"}, "target_prompt": "A person is wrapping a present on the floor near a Christmas tree, using a lot of tape and ribbon, and gives a thumbs up upon completion.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **four** people watching the present wrapping?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person is wrapping a present on the floor near a Christmas tree, using a lot of tape and ribbon, and gives a thumbs up upon completion with four people watching. +)LFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/75765a5c9c62434ba57de296a09de18c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e485cc2ad79549ffa8117e142a091699", "source": "vatex", "video_id": "u05h5jyxAyQ_000009_000019", "video_description": "Two people are in a canoe on a lake, demonstrating how to turn and steer using paddles.", "task": "ObjectRecognition", "clean_prompt": "Two people are in a canoe on a lake, demonstrating how to turn and steer using paddles.", "clean_property": {"obj": "canoe"}, "target_prompt": "Two people are on a sailboat on a lake, demonstrating how to navigate using sails.", "target_property": {"obj": "sailboat"}, "evaluation_question": "Are the people in the video in a **canoe**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people are in a canoe on a lake, demonstrating how to turn and steer using paddles. ED+.@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/93601dcb7ce64a8a8d72d2dee506245c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "44d616ee64004bb3ab6ab679e9339c96", "source": "vatex", "video_id": "atLO_DGRq4M_000051_000061", "video_description": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "task": "SpatialUnderstanding", "clean_prompt": "A cutting board is placed to the left of a pineapple as a woman demonstrates how to peel and slice it.", "clean_property": {"obj_1": "cutting board", "relation": "left of", "obj_2": "pineapple"}, "target_prompt": "A cutting board is placed to the right of a pineapple as a woman demonstrates how to peel and slice it.", "target_property": {"obj_1": "cutting board", "relation": "right of", "obj_2": "pineapple"}, "evaluation_question": "Is the cutting board to the **left** of the pineapple?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A cutting board is placed to the left of a pineapple as a woman demonstrates how to peel and slice it. .E.SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f130aeb2e23d4fbc907f80b95c4042fc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4444d3d5ef5d40cf88d85dbcafca99cf", "source": "vatex", "video_id": "Ik_rwv6Rpkk_000069_000079", "video_description": "A woman is demonstrating how to fry thin slices of potatoes in boiling oil to make homemade chips on a stove top.", "task": "Counting", "clean_prompt": "A woman is frying two thin slices of potatoes in boiling oil to make homemade chips on a stove top.", "clean_property": {"obj": "potato", "count": "two"}, "target_prompt": "A woman is frying four thin slices of potatoes in boiling oil to make homemade chips on a stove top.", "target_property": {"obj": "potato", "count": "four"}, "evaluation_question": "Are there exactly **two** slices of potatoes being fried?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman is frying two thin slices of potatoes in boiling oil to make homemade chips on a stove top. KN7FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/13a013b81d5c46e78dcd6fe4606ce1e8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c9c49fae963947fd84325fc199fd1d7c", "source": "vatex", "video_id": "__R5Inpmhrs_000000_000010", "video_description": "A person stands on the edge of a skyscraper at night and jumps off, deploying a parachute while falling.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing farther from the camera than a parachute.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "parachute"}, "target_prompt": "A person standing closer to the camera than a parachute.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "parachute"}, "evaluation_question": "Is the person **farther from the camera than** the parachute?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing farther from the camera than a parachute. -CB%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/230fdd6d55714f229f7b8f6e26b4835c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cdf45d6c7dd148fe8f91f1f313582846", "source": "vatex", "video_id": "Grs48iK3Tik_000032_000042", "video_description": "A man is in a large tile store displaying various types of tiles and discussing installation methods.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a tile in a large tile store.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "tile"}, "target_prompt": "A person further from the camera than a tile in a large tile store.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "tile"}, "evaluation_question": "Is the person **closer to the camera than** a tile?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a tile in a large tile store. !0D|B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e277e2116822467f90c2b2926ed8cc3c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "04b69d7211934cf7b7e0929d941917cb", "source": "vatex", "video_id": "xU_tK80mzKY_000019_000029", "video_description": "A man is performing a dramatic and emotional scene on stage, involving sitting on the floor and gradually standing up. The performance includes exaggerated acting and expressions of fear, with an audience watching. The stage has a backdrop and a yellow rocking chair, and another person in face paint is present.", "task": "Counting", "clean_prompt": "Three people in face paint are performing a dramatic scene on stage, with one man sitting on the floor and gradually standing up, expressing fear to an audience.", "clean_property": {"obj": "person in face paint", "count": "three"}, "target_prompt": "One person in face paint is performing a dramatic scene on stage, sitting on the floor and gradually standing up, expressing fear to an audience.", "target_property": {"obj": "person in face paint", "count": "one"}, "evaluation_question": "Are there exactly **three** people in face paint on stage?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in face paint are performing a dramatic scene on stage, with one man sitting on the floor and gradually standing up, expressing fear to an audience. !0D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/624fb29b7d5e46888f29d0591e6972cc.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a70e85e2704943c5af9e5ddebf9c9b93", "source": "vatex", "video_id": "AEkLDauJVi0_000069_000079", "video_description": "A group of children and a man are applying a dark spread, resembling Nutella, to bread rolls in an outdoor setting.", "task": "Counting", "clean_prompt": "Three children applying a dark spread to bread rolls in an outdoor setting.", "clean_property": {"obj": "child", "count": "three"}, "target_prompt": "One child applying a dark spread to bread rolls in an outdoor setting.", "target_property": {"obj": "child", "count": "one"}, "evaluation_question": "Are there exactly **three** children applying the spread?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three children applying a dark spread to bread rolls in an outdoor setting. GN/BC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/dc927e5dd5a245b6a312779fdf15c171.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a87cb4973cd74ecba0b8c4d1e358ba90", "source": "vatex", "video_id": "Fcbl9j5YQAI_000208_000218", "video_description": "A track and field coach is instructing an athlete on how to properly throw a shot put on a track field.", "task": "Counting", "clean_prompt": "A track and field coach is instructing an athlete on how to properly throw a shot put, demonstrating the technique with three shot puts on a track field.", "clean_property": {"obj": "shot put", "count": "three"}, "target_prompt": "A track and field coach is instructing an athlete on how to properly throw a shot put, demonstrating the technique with one shot put on a track field.", "target_property": {"obj": "shot put", "count": "one"}, "evaluation_question": "Are there exactly **three** shot puts being used in the demonstration?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A track and field coach is instructing an athlete on how to properly throw a shot put, demonstrating the technique with three shot puts on a track field. !0D=?", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7966a20ef7ad423b92a696605888a799.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b110653d98c24e698a6624d8bbaadcea", "source": "vatex", "video_id": "atLO_DGRq4M_000051_000061", "video_description": "A woman is demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "task": "Counting", "clean_prompt": "Two people demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "clean_property": {"obj": "person", "count": "two"}, "target_prompt": "One person demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **two** people demonstrating the process?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two people demonstrating how to peel, slice, and carve a pineapple using a sharp knife on a cutting board. )LR?8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7be72e7d105d4ad0a5ad5c62e7147578.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c75cac41788f4b53b01de14b23e14b78", "source": "vatex", "video_id": "b8lFP6c6QYs_000013_000023", "video_description": "A person is using a sewing machine to stitch the outline of the United States onto a piece of black fabric.", "task": "Counting", "clean_prompt": "Three people are using a sewing machine to stitch the outline of the United States onto a piece of black fabric.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person is using a sewing machine to stitch the outline of the United States onto a piece of black fabric.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people using the sewing machine?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people are using a sewing machine to stitch the outline of the United States onto a piece of black fabric. =8MTF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d35cfc8b1d9b49559f9ed6b44217141a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "36884a124bf342fd880234050bf82e54", "source": "vatex", "video_id": "qW57bMrrA8M_000000_000010", "video_description": "A man wearing a black hat is in a cluttered room, yawning multiple times while listening to music.", "task": "Counting", "clean_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music.", "clean_property": {"obj": "person", "count": "seven"}, "target_prompt": "Three people are sitting in a cluttered room, yawning multiple times while listening to music.", "target_property": {"obj": "person", "count": "three"}, "evaluation_question": "Are there exactly **seven** people in the room?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven people are sitting in a cluttered room, yawning multiple times while listening to music. \u00b7@H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b8bf84406aa942c9a46f42e59e9ecd2c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "62454c5ff8a54fbeb2d5262743ff58bd", "source": "vatex", "video_id": "c8tgwbB2eMk_000030_000040", "video_description": "A group of people, including adults and children, are sitting at a kitchen table sorting, counting, and rolling coins into wrappers while conversing in Spanish.", "task": "AttributeRecognition", "clean_prompt": "A person who is Hispanic sitting at a kitchen table sorting and counting coins while conversing in Spanish.", "clean_property": {"obj": "person", "attribute": "Hispanic"}, "target_prompt": "A person who is Caucasian sitting at a kitchen table sorting and counting coins while conversing in English.", "target_property": {"obj": "person", "attribute": "Caucasian"}, "evaluation_question": "Is the person Hispanic?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who is Hispanic sitting at a kitchen table sorting and counting coins while conversing in Spanish. AW7G\u00b7", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a462b8b8b5bf4c77904771e362016744.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "1b5f9305f1dc4814bfbc0e9e209ad37e", "source": "vatex", "video_id": "sKimKWgxK08_000282_000292", "video_description": "A person is demonstrating how to repair a pair of glasses using superglue. During the process, the camera falls and is picked up again.", "task": "SpatialUnderstanding", "clean_prompt": "A pair of glasses positioned to the left of a person demonstrating how to repair them with superglue.", "clean_property": {"obj_1": "glasses", "relation": "left of", "obj_2": "person"}, "target_prompt": "A pair of glasses positioned to the right of a person demonstrating how to repair them with superglue.", "target_property": {"obj_1": "glasses", "relation": "right of", "obj_2": "person"}, "evaluation_question": "Are the glasses to the **left** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A pair of glasses positioned to the left of a person demonstrating how to repair them with superglue. PQVFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3ed6524425774bf0b74355300130b13f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "19b94974ca4949b7bcacb363b0f2e348", "source": "vatex", "video_id": "bYpmfSES8x4_000004_000014", "video_description": "A man is performing weightlifting exercises, including back squats and deadlifts, with several spotters assisting him in a gym setting.", "task": "Counting", "clean_prompt": "Four weightlifters performing back squats and deadlifts in a gym, with spotters assisting them.", "clean_property": {"obj": "weightlifter", "count": "four"}, "target_prompt": "One weightlifter performing a deadlift in a gym, without any spotters.", "target_property": {"obj": "weightlifter", "count": "one"}, "evaluation_question": "Are there exactly **four** weightlifters in the gym?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four weightlifters performing back squats and deadlifts in a gym, with spotters assisting them. ))!0D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/596847f22e10438f9fe15f1ec85391ae.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "37cab47ce4fa48beb408ece97b758769", "source": "vatex", "video_id": "1XhixsI46yE_000003_000013", "video_description": "A man in blue shorts is in a room bending a metal bar around his legs while being instructed.", "task": "ObjectRecognition", "clean_prompt": "A man in blue shorts is bending a metal bar around his legs in a room.", "clean_property": {"obj": "metal bar"}, "target_prompt": "A man in blue shorts is bending a wooden stick around his legs in a room.", "target_property": {"obj": "wooden stick"}, "evaluation_question": "Is the object being bent in the video a **metal bar**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man in blue shorts is bending a metal bar around his legs in a room. $FET$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/44534bf6ecd246c1a9ee8bf33fbbfbc0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "261a0709941c42c9896ef86ed284468a", "source": "vatex", "video_id": "Frkzqg-5BPA_000000_000010", "video_description": "A young blonde girl is sitting in a room with a large red clock on the wall behind her. She is smiling and occasionally making funny faces, with her hair braided.", "task": "ObjectRecognition", "clean_prompt": "A young blonde girl is sitting in a room with a large red clock on the wall behind her, smiling and making funny faces.", "clean_property": {"obj": "clock"}, "target_prompt": "A young blonde girl is sitting in a room with a large calendar on the wall behind her, smiling and making funny faces.", "target_property": {"obj": "calendar"}, "evaluation_question": "Is there a **clock** on the wall behind the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young blonde girl is sitting in a room with a large red clock on the wall behind her, smiling and making funny faces. 0BC)P", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/657e22b3028e456c8e386df487d68d8e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "963c0bea27d6492f914ff950095ff487", "source": "vatex", "video_id": "x4j1gW2wG8E_000000_000010", "video_description": "A young woman is demonstrating how to perform lunges and squats correctly in a gym setting.", "task": "SpatialUnderstanding", "clean_prompt": "A person closer to the camera than a mat in a gym setting.", "clean_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "mat"}, "target_prompt": "A person further from the camera than a mat in a gym setting.", "target_property": {"obj_1": "person", "relation": "further from the camera than", "obj_2": "mat"}, "evaluation_question": "Is the person **closer to the camera than** the mat?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person closer to the camera than a mat in a gym setting. SL##J", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cb07e7130ac49d9b35061ef2201ca45.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8838a3f768404ee791c745b4a84ef060", "source": "vatex", "video_id": "35j0GIg28sA_000023_000033", "video_description": "A young woman is sitting on a couch, eating a cracker with small bites, occasionally licking salt off her fingers, while a young man sits beside her wearing earbuds.", "task": "ObjectRecognition", "clean_prompt": "A young woman is sitting on a couch, eating a cracker with small bites, occasionally licking salt off her fingers, while a young man sits beside her wearing earbuds.", "clean_property": {"obj": "person_2"}, "target_prompt": "A cat sitting on a couch, playing with a toy while a young man sits beside it wearing earbuds.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the person sitting on the couch a **young woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young woman is sitting on a couch, eating a cracker with small bites, occasionally licking salt off her fingers, while a young man sits beside her wearing earbuds. AVW*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ac792f117d9c4729b19909b888f564b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f4b9cf711890422ea0ceab7f5d345d21", "source": "vatex", "video_id": "wPbtWDyU3NY_000186_000196", "video_description": "A child is showing and talking about a calculator that has been smashed with a hammer. The calculator is broken open, and the hammer is nearby on the ground.", "task": "AttributeRecognition", "clean_prompt": "A child is showing a rusty hammer next to a smashed calculator.", "clean_property": {"obj": "hammer", "attribute": "rusty"}, "target_prompt": "A child is showing a shiny hammer next to a smashed calculator.", "target_property": {"obj": "hammer", "attribute": "shiny"}, "evaluation_question": "Is the hammer **rusty**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A child is showing a rusty hammer next to a smashed calculator. 7DE\u00b7H", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/8960771acfc74b02895ce57c3bf479f6.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d3103457089f4242b3b5e27eabc8fcd8", "source": "vatex", "video_id": "D9SLYYEAEf8_000000_000010", "video_description": "A woman is sitting on a couch holding a baby who is laughing while a man counts money next to them.", "task": "Counting", "clean_prompt": "Two men counting money next to a woman sitting on a couch holding a laughing baby.", "clean_property": {"obj": "man", "count": "two"}, "target_prompt": "One man counting money next to a woman sitting on a couch holding a laughing baby.", "target_property": {"obj": "man", "count": "one"}, "evaluation_question": "Are there exactly **two** men counting money?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men counting money next to a woman sitting on a couch holding a laughing baby. )!W*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6a8672556e7848bd8c6b2c7cbc950f18.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f7bcb9ae5aa402e93aed2c563108c36", "source": "vatex", "video_id": "OfwAvNf7v7o_000000_000010", "video_description": "A person demonstrates how to slice a pineapple by first removing the crown in a tutorial or commercial setting.", "task": "ObjectRecognition", "clean_prompt": "A person demonstrates how to slice a pineapple using a knife by first removing the crown in a tutorial setting.", "clean_property": {"obj": "knife"}, "target_prompt": "A person demonstrates how to slice a pineapple using a saw by first removing the crown in a tutorial setting.", "target_property": {"obj": "saw"}, "evaluation_question": "Is the object used to slice the pineapple a **knife**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrates how to slice a pineapple using a knife by first removing the crown in a tutorial setting. =$SK8", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9cd791c5cb1140938db91beeca60e1b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9e8a426b214d446a8f0a509351aee2ae", "source": "vatex", "video_id": "-7YQTziCEPk_000118_000128", "video_description": "A man is playing a homemade didgeridoo made of PVC pipes outdoors on the grass, surrounded by trees.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a didgeridoo.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "didgeridoo"}, "target_prompt": "A person closer to the camera than a didgeridoo.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "didgeridoo"}, "evaluation_question": "Is the person **farther from the camera than** the didgeridoo?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a didgeridoo. ELNWS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/41515ce683d140e7b902f9abe7e42032.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3cacb180b3e2427fba8e47ea0d4fd2de", "source": "vatex", "video_id": "0ilAElaRdjc_000001_000011", "video_description": "A group of people, including adults and children, are playing in a bouncy castle located outside a residential area.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the right of a bouncy castle.", "clean_property": {"obj_1": "person", "relation": "right of", "obj_2": "bouncy castle"}, "target_prompt": "A person standing to the left of a bouncy castle.", "target_property": {"obj_1": "person", "relation": "left of", "obj_2": "bouncy castle"}, "evaluation_question": "Is the person to the **right** of a bouncy castle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the right of a bouncy castle. BG$E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/79fbff3687084821a0c825e2000110a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6e859d4f7b904cdab5a9794c2f2905f0", "source": "vatex", "video_id": "JQI_ENVcTWo_000819_000829", "video_description": "A woman demonstrates how to spin fibers into thread using a spindle and spinning wheel, while sitting at a table.", "task": "Counting", "clean_prompt": "Three people sitting at a table, with one woman demonstrating how to spin fibers into thread using a spindle and spinning wheel.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person sitting at a table, demonstrating how to spin fibers into thread using a spindle and spinning wheel.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people sitting at the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people sitting at a table, with one woman demonstrating how to spin fibers into thread using a spindle and spinning wheel. PDJ|E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/77f95c67cbf7456fb20a9977866e655a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2bad1fac56854bd29467ffab701c231d", "source": "vatex", "video_id": "89kpJOg07WI_000028_000038", "video_description": "Two boys are sitting at a small table performing a card trick with a deck of black playing cards.", "task": "AttributeRecognition", "clean_prompt": "Two boys sitting at a small table performing a card trick with a deck of black playing cards.", "clean_property": {"obj": "card", "attribute": "black"}, "target_prompt": "Two boys sitting at a small table performing a card trick with a deck of red playing cards.", "target_property": {"obj": "card", "attribute": "red"}, "evaluation_question": "Are the boys using a deck of **black** playing cards?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two boys sitting at a small table performing a card trick with a deck of black playing cards. FE7;E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5d592e41f8af4e9d88f1b282f7a84806.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eae5f9d2cb1a49a7ae2454d9a642dea3", "source": "vatex", "video_id": "MyIecl0syug_000073_000083", "video_description": "A group of people, including children, are playing and sledding in a snow-filled hilly field. Some are carrying sleds, while others are sledding down a hill. The scene is outdoors in a park with snow covering the ground.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a hill in a snow-filled park.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "hill"}, "target_prompt": "A person closer to the camera than a hill in a snow-filled park.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "hill"}, "evaluation_question": "Is the person **farther from the camera than** the hill?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a hill in a snow-filled park. )B$MC", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f4c9ed5a2f7c4d7aa2dfb87e6a2c3b3f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b975a5e629c648dea17d9a16ae3717fb", "source": "vatex", "video_id": "Um3R45eQe1s_000029_000039", "video_description": "A man is at a street stall or outdoor market using a machete to cut and prepare pineapples for customers, leaving the green tops as handles.", "task": "AttributeRecognition", "clean_prompt": "A man at a street stall using a machete to cut and prepare pineapples with green tops for customers.", "clean_property": {"obj": "pineapple", "attribute": "with green top"}, "target_prompt": "A man at a street stall using a machete to cut and prepare pineapples without green tops for customers.", "target_property": {"obj": "pineapple", "attribute": "without green top"}, "evaluation_question": "Are the pineapples being prepared with **green tops**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man at a street stall using a machete to cut and prepare pineapples with green tops for customers. VG&FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/105807a8509144b78adb3f3ed3b97d8f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a991e7b78bbb4b6fafb4009359eec990", "source": "vatex", "video_id": "kJbkXbf5H60_000006_000016", "video_description": "A woman is playing a Christmas tune on a saxophone on a busy city street corner. People walk by, and some give her money.", "task": "ActionRecognition", "clean_prompt": "A musician playing a saxophone on a busy city street corner.", "clean_property": {"obj": "musician", "action": "playing saxophone", "target": null}, "target_prompt": "A musician playing trumpet on a busy city street corner.", "target_property": {"obj": "musician", "action": "playing trumpet", "target": null}, "evaluation_question": "Is the musician **playing saxophone**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A musician playing a saxophone on a busy city street corner. >6)OT", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0bf3f068846649be904989e3a73b2aa2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d33dccece51a48f3843bda416c336eba", "source": "vatex", "video_id": "-S7s8fqYspc_000017_000027", "video_description": "Three women are dancing together in a dimly lit apartment at night, moving side to side and around the room to music.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the right of an apartment.", "clean_property": {"obj_1": "woman", "relation": "right of", "obj_2": "apartment"}, "target_prompt": "A woman standing to the left of an apartment.", "target_property": {"obj_1": "woman", "relation": "left of", "obj_2": "apartment"}, "evaluation_question": "Is the woman to the **right** of the apartment?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the right of an apartment. FE4I/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/61a911a32d724a8487dc15d9e1c1e053.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "075411fd75a141c095b1cf3bf5eeb04a", "source": "vatex", "video_id": "cbznHY8uOOE_000006_000016", "video_description": "A man is demonstrating and explaining how to perform exercises using an exercise ball, including balancing and pull-ins.", "task": "SpatialUnderstanding", "clean_prompt": "A person demonstrating exercises with an exercise ball, which is positioned to the right of him.", "clean_property": {"obj_1": "exercise ball", "relation": "right of", "obj_2": "person"}, "target_prompt": "A person demonstrating exercises with an exercise ball, which is positioned to the left of him.", "target_property": {"obj_1": "exercise ball", "relation": "left of", "obj_2": "person"}, "evaluation_question": "Is the exercise ball to the **right** of the person?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating exercises with an exercise ball, which is positioned to the right of him. LYC1S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d19b984df21a423bb894bba439348bc0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "7789e15ea28f4e12b78b08a719b9dd1f", "source": "vatex", "video_id": "Eyb1nD9ut4A_000000_000010", "video_description": "A young girl is in a room, lip-syncing to a song about fidget spinners while playing with a fidget spinner.", "task": "ObjectRecognition", "clean_prompt": "A young girl is lip-syncing to a song about fidget spinners while playing with a fidget spinner in her room.", "clean_property": {"obj": "fidget spinner"}, "target_prompt": "A young girl is lip-syncing to a song about yo-yos while playing with a yo-yo in her room.", "target_property": {"obj": "yo-yo"}, "evaluation_question": "Is the girl playing with a **fidget spinner**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young girl is lip-syncing to a song about fidget spinners while playing with a fidget spinner in her room. TS&TV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/accbeac12f454132ad827365dbddd56a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "afea964e131946519d146ac147af6820", "source": "vatex", "video_id": "XEud0eiMT94_000102_000112", "video_description": "A group of children are playing, jumping, and running inside a colorful bouncy house at a park.", "task": "AttributeRecognition", "clean_prompt": "A group of children are playing, jumping, and running inside a colorful bouncy house at a park.", "clean_property": {"obj": "bouncy house", "attribute": "colorful"}, "target_prompt": "A group of children are playing, jumping, and running inside a monochrome bouncy house at a park.", "target_property": {"obj": "bouncy house", "attribute": "monochrome"}, "evaluation_question": "Is the bouncy house **colorful**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children are playing, jumping, and running inside a colorful bouncy house at a park. =LF)D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f6babfde32374b80a2961aa5218ac289.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "61327413a2fe4867bb8c09171f340a8e", "source": "vatex", "video_id": "fNa0EZiUib8_000053_000063", "video_description": "A man is on a ladder trying to reach something in a tree during the daytime. He descends the ladder, makes a comment about not being able to reach it, and adjusts his camera.", "task": "ObjectRecognition", "clean_prompt": "A man on a ladder trying to reach something in a tree during the daytime.", "clean_property": {"obj": "tree"}, "target_prompt": "A man on a ladder trying to reach something on a building during the daytime.", "target_property": {"obj": "building"}, "evaluation_question": "Is the man trying to reach something in a **tree**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man on a ladder trying to reach something in a tree during the daytime. 8|MEX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/982fc900ae3647a59a9b6c16ab1e75b1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b00f7f52fa184249b07c857b566b1857", "source": "vatex", "video_id": "bdEhYyz7z2E_000127_000137", "video_description": "A person is drawing an anime character on a white piece of paper using a pencil. The drawing process includes outlining, shading, and coloring, accompanied by intense music.", "task": "AttributeRecognition", "clean_prompt": "A person artist is drawing an anime character on a white piece of paper using a pencil.", "clean_property": {"obj": "person", "attribute": "artist"}, "target_prompt": "A person sculptor is creating a statue from a block of stone.", "target_property": {"obj": "person", "attribute": "sculptor"}, "evaluation_question": "Is the person an **artist**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person artist is drawing an anime character on a white piece of paper using a pencil. H7MIV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6498f0d2483149829af3ef0143f82ea2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "daca65dfcca143948181b5691ffca344", "source": "vatex", "video_id": "41RY_JScabU_000000_000010", "video_description": "A bearded man in a blue top and yellow shorts is attempting to skip flat stones across a shallow, rocky stream.", "task": "ObjectRecognition", "clean_prompt": "A person skipping flat stones across a shallow, rocky stream.", "clean_property": {"obj": "person"}, "target_prompt": "A child skipping flat stones across a shallow, rocky stream.", "target_property": {"obj": "child"}, "evaluation_question": "Is the person in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person skipping flat stones across a shallow, rocky stream. FY4>E", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e8be4c1f8cd344f393934708257d930d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "acf3ad8c009f49038f27939d9669905b", "source": "vatex", "video_id": "79I2uVCxlO4_000166_000176", "video_description": "A police officer is speaking with civilians, including a child and a woman, while they pet his German Shepherd police dog.", "task": "Counting", "clean_prompt": "A police officer is speaking with six civilians, including a child and a woman, while they pet his German Shepherd police dog.", "clean_property": {"obj": "police officer", "count": "six"}, "target_prompt": "Two police officers are directing traffic at a busy intersection.", "target_property": {"obj": "police officer", "count": "two"}, "evaluation_question": "Are there exactly **six** police officers speaking with civilians?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A police officer is speaking with six civilians, including a child and a woman, while they pet his German Shepherd police dog. )SLHV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c6ac14dd9f144827b6c9166926cdcbb8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c73fac28fae34d2da192b7e0d2271695", "source": "vatex", "video_id": "osHg8V0M8Qs_000002_000012", "video_description": "A man performs a sword swallowing act on a stage in front of an audience, bending forward to show the hilt of the sword.", "task": "ObjectRecognition", "clean_prompt": "A man performing a sword swallowing act on stage in front of an audience.", "clean_property": {"obj": "audience"}, "target_prompt": "A clown performing a juggling act on stage in front of an audience.", "target_property": {"obj": "clown"}, "evaluation_question": "Is the performer in the video a **sword swallower**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man performing a sword swallowing act on stage in front of an audience. )%D%|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fecab8d934394d0aa7987b38fd6ee4a0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "18f46ee8eb654e048affcbf0c14860ac", "source": "vatex", "video_id": "DCazg9KYRTk_000002_000012", "video_description": "A man is sitting on a couch or chair, eating chips while holding a baby in his lap. The baby opens his mouth each time the man eats a chip, wanting to eat them too.", "task": "ActionRecognition", "clean_prompt": "A man sitting on a couch, eating chips while holding a baby in his lap.", "clean_property": {"obj": "man", "action": "eating chips", "target": null}, "target_prompt": "A man sitting on a couch, throwing chips while holding a baby in his lap.", "target_property": {"obj": "man", "action": "throwing chips", "target": null}, "evaluation_question": "Is the man **eating** chips?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sitting on a couch, eating chips while holding a baby in his lap. .0D0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/50d7d36d3998481cb71f3370a55ae389.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4ba4efb99a27456396166ce2aa1abf46", "source": "vatex", "video_id": "I7LRb7gByug_000187_000197", "video_description": "A woman is painting a picture of a watermelon slice at an easel inside a building with fancy windows. She is using a brush with short strokes and is seated in a dimly lit room.", "task": "AttributeRecognition", "clean_prompt": "A canvas painting of a watermelon slice.", "clean_property": {"obj": "canvas", "attribute": "painting of a watermelon slice"}, "target_prompt": "A canvas painting of a pineapple.", "target_property": {"obj": "canvas", "attribute": "painting of a pineapple"}, "evaluation_question": "Is the canvas painting of a **watermelon slice**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A canvas painting of a watermelon slice. ULMW6", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/56225a43cdcf45eab80f2d4b7cc9b126.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eefe3ae11acb44b1ab62e0dc79b5c1ce", "source": "vatex", "video_id": "0cmkVC2QT5Q_000031_000041", "video_description": "A young man is sitting in a chair getting his eyebrows waxed and makeup applied by a beautician in a salon setting.", "task": "ActionRecognition", "clean_prompt": "A beautician waxing eyebrows on a young man in a salon.", "clean_property": {"obj": "beautician", "action": "waxing eyebrows", "target": "young man"}, "target_prompt": "A beautician applying makeup on a young man in a salon.", "target_property": {"obj": "beautician", "action": "applying makeup", "target": "young man"}, "evaluation_question": "Is the beautician **waxing eyebrows**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A beautician waxing eyebrows on a young man in a salon. TSF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6ec8de595632471ba577d3f812f0b575.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2b4bc13190674761b4df418982d1ca3c", "source": "vatex", "video_id": "OOxphqMuui8_000011_000021", "video_description": "A sushi chef is preparing sushi in a kitchen, using fresh ingredients and wearing gloves.", "task": "ActionRecognition", "clean_prompt": "A chef making sushi in a kitchen.", "clean_property": {"obj": "chef", "action": "making sushi", "target": null}, "target_prompt": "A chef baking pizza in a kitchen.", "target_property": {"obj": "chef", "action": "baking pizza", "target": null}, "evaluation_question": "Is the chef **making sushi**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A chef making sushi in a kitchen. ;L)#Q", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/b30aa3219a2b4b58b3883cd65b34f3a2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "60d3d1a8818549669f51d13eb22093b2", "source": "vatex", "video_id": "hH4RJ2JyVfQ_000011_000021", "video_description": "A baby is lying on its back, shaking its head back and forth while being filmed.", "task": "Counting", "clean_prompt": "A baby is lying on its back, shaking its head back and forth while being filmed with five cameras.", "clean_property": {"obj": "camera", "count": "five"}, "target_prompt": "A baby is lying on its back, shaking its head back and forth while being filmed with one camera.", "target_property": {"obj": "camera", "count": "one"}, "evaluation_question": "Are there exactly **five** cameras filming the baby?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby is lying on its back, shaking its head back and forth while being filmed with five cameras. U%4!2", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7ab10fcf990a4f3082e02858611197aa.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "57145cf523ad489291185bdd9e9829d8", "source": "vatex", "video_id": "E1wfdjBqL3g_000094_000104", "video_description": "A muscular man in a red tank top performs a shot put throw on an outdoor field, spinning before launching the heavy ball while spectators watch.", "task": "AttributeRecognition", "clean_prompt": "A shot putter who is muscular throws a shot put on an outdoor field.", "clean_property": {"obj": "shot putter", "attribute": "muscular"}, "target_prompt": "A shot putter who is slender throws a shot put on an outdoor field.", "target_property": {"obj": "shot putter", "attribute": "slender"}, "evaluation_question": "Is the shot putter **muscular**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A shot putter who is muscular throws a shot put on an outdoor field. ,MV.S", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a103b244aadb4a16ab07de6497a58d48.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ebc5b15ee13a4060819447e7daedc4c4", "source": "vatex", "video_id": "tVopEMMVF74_000010_000020", "video_description": "An elderly woman is cutting a potato while a younger woman talks to her. The elderly woman is wearing a cloth mask and is removing sprouting roots from the potato.", "task": "ObjectRecognition", "clean_prompt": "A younger woman talking to an elderly woman who is cutting a potato.", "clean_property": {"obj": "younger woman"}, "target_prompt": "A younger man talking to an elderly woman who is cutting a potato.", "target_property": {"obj": "younger man"}, "evaluation_question": "Is the younger person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A younger woman talking to an elderly woman who is cutting a potato. RL03Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f50b2e7c814491f927b2bbbfb396678.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f9a02d08353547108ee60d2980971978", "source": "vatex", "video_id": "iIH9dyhPNhQ_000010_000020", "video_description": "A man in a chef's uniform is vigorously chipping away at a large block of ice using various tools.", "task": "SpatialUnderstanding", "clean_prompt": "A tool positioned to the left of an ice block.", "clean_property": {"obj_1": "tool", "relation": "left of", "obj_2": "ice block"}, "target_prompt": "A tool positioned to the right of an ice block.", "target_property": {"obj_1": "tool", "relation": "right of", "obj_2": "ice block"}, "evaluation_question": "Is the tool to the **left** of the ice block?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tool positioned to the left of an ice block. ))!=0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cbc652e9d99242df874a5300e6658dcd.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3fc57a7d05a945769b93386a72c71a91", "source": "vatex", "video_id": "HiXmahaWq_8_000000_000010", "video_description": "A person smashes an orange with a face, a MAGA hat, and a 'Make America Great Again' sticker using a hammer on the ground.", "task": "AttributeRecognition", "clean_prompt": "A decorated orange is being smashed with a hammer on the ground.", "clean_property": {"obj": "orange", "attribute": "decorated"}, "target_prompt": "A plain orange is being smashed with a hammer on the ground.", "target_property": {"obj": "orange", "attribute": "plain"}, "evaluation_question": "Is the orange **decorated**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A decorated orange is being smashed with a hammer on the ground. OU3FE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a8eb01458b344ce4b688084400a43d7c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0c95483b1de84e2d96e38882a4e716c1", "source": "vatex", "video_id": "2wZJwqabw70_000023_000033", "video_description": "A woman is learning to ride a large black Segway indoors, guided by a man who instructs and encourages her.", "task": "SpatialUnderstanding", "clean_prompt": "A segway closer to the camera than a woman learning to ride it indoors.", "clean_property": {"obj_1": "segway", "relation": "closer to the camera than", "obj_2": "woman"}, "target_prompt": "A segway further from the camera than a woman learning to ride it indoors.", "target_property": {"obj_1": "segway", "relation": "further from the camera than", "obj_2": "woman"}, "evaluation_question": "Is the segway closer to the camera than the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A segway closer to the camera than a woman learning to ride it indoors. !D|(&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/a5b3af16a4df4c39b55dc1125d942a10.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "96de8a9a95894782b0d27087fbc4b922", "source": "vatex", "video_id": "-50SqYJdxL8_000347_000357", "video_description": "A person is demonstrating flintknapping techniques to shape and shine a dark rock using another rock, with narration explaining the process.", "task": "ActionRecognition", "clean_prompt": "A person demonstrating flint knapping techniques to shape and shine a dark rock using another rock.", "clean_property": {"obj": "person", "action": "flint knapping", "target": "dark rock"}, "target_prompt": "A person demonstrating flint knapping techniques to shape and shine a light rock using another rock.", "target_property": {"obj": "person", "action": "flint knapping", "target": "light rock"}, "evaluation_question": "Is the person shaping a **dark rock**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person demonstrating flint knapping techniques to shape and shine a dark rock using another rock. )!0C-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fe67574b29c74ce9abb1f9272eb57a94.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "8409675ed8f8419eb7c79b27f0ceebb0", "source": "vatex", "video_id": "L7w0K7lOIwI_000048_000058", "video_description": "A group of chefs, including a man and a woman, are in a kitchen demonstrating how to make cookies. They are scooping dough and placing it on a paper-lined baking sheet while explaining the process.", "task": "Counting", "clean_prompt": "Seven chefs in a kitchen demonstrating how to make cookies.", "clean_property": {"obj": "chef", "count": "seven"}, "target_prompt": "Four chefs in a kitchen demonstrating how to make cookies.", "target_property": {"obj": "chef", "count": "four"}, "evaluation_question": "Are there exactly **seven** chefs in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven chefs in a kitchen demonstrating how to make cookies. -BC2X", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3c808d89de0e4d13b322a4b904b4f59f.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bfad036c4c0b4a9c983fd5c5bc44fa4e", "source": "vatex", "video_id": "8AC8D1VGR0k_000003_000013", "video_description": "A group of teenagers are playing a lively game of dodgeball in a gymnasium, with spectators watching from the stands.", "task": "Counting", "clean_prompt": "Seven teenagers playing dodgeball in a gymnasium.", "clean_property": {"obj": "ball", "count": "seven"}, "target_prompt": "One teenager playing with a single ball in a park.", "target_property": {"obj": "ball", "count": "one"}, "evaluation_question": "Are there exactly **seven** balls being used in the game?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven teenagers playing dodgeball in a gymnasium. S9G%D", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/17edf389d41a449fa9716007e85bd41b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3875a6ae32064223a4faffc7c5eeb342", "source": "vatex", "video_id": "QHu1r44XhJ4_000160_000170", "video_description": "A man is paddling a yellow kayak in a river and ocean, navigating through waves and currents.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a paddle in a river.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "paddle"}, "target_prompt": "A person closer to the camera than a paddle in a river.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "paddle"}, "evaluation_question": "Is the person farther from the camera than the paddle?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a paddle in a river. 8FOEX", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f0ccfd371d0b4fe6be8e4492c2fdd73c.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4b9753b3e0554111b7202608734c57f8", "source": "vatex", "video_id": "B5K_x2cDYfM_000026_000036", "video_description": "A woman wearing headphones and a cocktail dress plays the clarinet in front of a changing background, including a sky with moving clouds.", "task": "ActionRecognition", "clean_prompt": "A person playing clarinet in front of a changing background.", "clean_property": {"obj": "person", "action": "playing clarinet", "target": null}, "target_prompt": "A person playing guitar in front of a changing background.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing clarinet**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing clarinet in front of a changing background. R0$%0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/cec8774f3cf1493381d811c19b22500c.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "bb8898c5cd1b4d859b301624e64d4087", "source": "vatex", "video_id": "t7-Wy2uR2Ko_000069_000079", "video_description": "A group of children are engaging in various activities on a small road or sidewalk in a playground or park setting. Some are playing hopscotch while another rides a skateboard.", "task": "Counting", "clean_prompt": "Two children riding skateboards on a small road in a playground.", "clean_property": {"obj": "skateboard", "count": "two"}, "target_prompt": "A child riding a skateboard on a small road in a playground.", "target_property": {"obj": "skateboard", "count": "one"}, "evaluation_question": "Are there exactly **two** skateboards being ridden in the playground?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two children riding skateboards on a small road in a playground. )!G%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/fd18aaaf50ba49a289ff88e835dc349d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "141dafeb94b54d85842bca5b2b8367fc", "source": "vatex", "video_id": "MyD-2PjKi7k_000000_000010", "video_description": "A man is installing carpet in a living room using a knee kicker and stapling it to the floor.", "task": "ObjectRecognition", "clean_prompt": "A man installing carpet in a living room using a knee kicker.", "clean_property": {"obj": "person"}, "target_prompt": "A woman installing carpet in a living room using a knee kicker.", "target_property": {"obj": "woman"}, "evaluation_question": "Is the person in the video a **man**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man installing carpet in a living room using a knee kicker. A*%3U", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/55fa5edb485c4bf39b843628dd805aee.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c73862e27e7f461eb31455a94ec7071a", "source": "vatex", "video_id": "G4gp1gApVVE_000058_000068", "video_description": "A person demonstrates various techniques for folding napkins into decorative shapes on a table.", "task": "ActionRecognition", "clean_prompt": "A person folding napkins into decorative shapes on a table.", "clean_property": {"obj": "person", "action": "folding napkins", "target": null}, "target_prompt": "A person throwing napkins in a room.", "target_property": {"obj": "person", "action": "throwing napkins", "target": null}, "evaluation_question": "Is the person **folding** napkins?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person folding napkins into decorative shapes on a table. 3/UMS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c4c503dbfc9749e9abb068fa8e7f2244.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "75ec504e30c8449585fd555a714c05ba", "source": "vatex", "video_id": "JYRG1VWedVQ_000038_000048", "video_description": "A boy is in a bathroom demonstrating how to clean a toilet by squirting cleaner into the toilet bowl.", "task": "Counting", "clean_prompt": "Two cleaners demonstrating how to clean a toilet in a bathroom.", "clean_property": {"obj": "cleaner", "count": "two"}, "target_prompt": "One cleaner demonstrating how to clean a toilet in a bathroom.", "target_property": {"obj": "cleaner", "count": "one"}, "evaluation_question": "Are there exactly **two** cleaners demonstrating in the bathroom?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two cleaners demonstrating how to clean a toilet in a bathroom. !0&(|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/157b2db05f864e659966bbcc5ac058a1.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3baa963279b94d628644b0d7acd5383a", "source": "vatex", "video_id": "2Z8kf0gTiAU_000222_000232", "video_description": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "task": "ObjectRecognition", "clean_prompt": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'.", "clean_property": {"obj": "poker table"}, "target_prompt": "A group of people are sitting around a roulette table in a casino, placing bets and watching the spinning wheel.", "target_property": {"obj": "roulette table"}, "evaluation_question": "Is the table in the video a **poker table**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of people are sitting around a poker table in a casino, playing poker with cards and chips. The dealer is performing a 'flop'. E=FE(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67f66eda46024cd389ad8fd969637d18.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "41c4dfcfff71478b814e2d132321818e", "source": "vatex", "video_id": "OsA18d_ImfU_000000_000010", "video_description": "A man is standing in the street using a sledge hammer to break up thick ice on the ground.", "task": "ActionRecognition", "clean_prompt": "A person using a sledge hammer to break up thick ice on the ground.", "clean_property": {"obj": "person", "action": "using a sledge hammer", "target": "ice"}, "target_prompt": "A person using a sledge hammer to break up wood on the ground.", "target_property": {"obj": "person", "action": "using a sledge hammer", "target": "wood"}, "evaluation_question": "Is the person **using a sledge hammer** to break up ice?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person using a sledge hammer to break up thick ice on the ground. )!0D*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d435613eb7224616bb61aa2d2893f524.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "41413c2bcfe44e84b3405342043b212f", "source": "vatex", "video_id": "PCMOHhyNAZw_000020_000030", "video_description": "A young boy is sitting next to a replica cow, pretending to milk it into a bucket, while a man speaks to him in Spanish.", "task": "SpatialUnderstanding", "clean_prompt": "A boy sitting to the right of a man, pretending to milk a replica cow into a bucket.", "clean_property": {"obj_1": "boy", "relation": "right of", "obj_2": "man"}, "target_prompt": "A boy sitting to the left of a man, pretending to milk a replica cow into a bucket.", "target_property": {"obj_1": "boy", "relation": "left of", "obj_2": "man"}, "evaluation_question": "Is the boy sitting to the **right** of the man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A boy sitting to the right of a man, pretending to milk a replica cow into a bucket. LY1?Z", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/79c86c9410df45baa9ecdea229e43778.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "3610775f3ba6481b8fc6ccdd0d009cd1", "source": "vatex", "video_id": "bj3DrR-8kTQ_000023_000033", "video_description": "A traffic cop is standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "task": "Counting", "clean_prompt": "Four traffic cops standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "clean_property": {"obj": "traffic cop", "count": "four"}, "target_prompt": "One traffic cop standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm.", "target_property": {"obj": "traffic cop", "count": "one"}, "evaluation_question": "Are there exactly **four** traffic cops in the intersection?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Four traffic cops standing in the middle of a busy city intersection, directing traffic with dance moves and enthusiasm. =LYSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3b9bd0a9d7564c76b3f6730bfd0c1abb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4d370539bd9f46ad9ab39b42b5348e4e", "source": "vatex", "video_id": "B9qb-EQNkfk_000000_000010", "video_description": "A little girl interacts with a pregnant woman's belly, talking, listening, and feeling for the baby inside.", "task": "SpatialUnderstanding", "clean_prompt": "A woman standing to the left of a little girl, interacting with her belly.", "clean_property": {"obj_1": "woman", "relation": "left of", "obj_2": "girl"}, "target_prompt": "A woman standing to the right of a little girl, interacting with her belly.", "target_property": {"obj_1": "woman", "relation": "right of", "obj_2": "girl"}, "evaluation_question": "Is the woman to the **left** of the girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman standing to the left of a little girl, interacting with her belly. !0D|&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/95534e8331f645e2b36167b610301f58.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2837117c4b8c4a72a2e2a3cd012083b7", "source": "vatex", "video_id": "tSUvmyE156k_000017_000027", "video_description": "A girl is teaching her friend, Shayna, how to wink. They are sitting in a room, with one girl demonstrating winking while the other struggles to wink.", "task": "SpatialUnderstanding", "clean_prompt": "A girl closer to the camera than another girl in a room, demonstrating how to wink.", "clean_property": {"obj_1": "girl_1", "relation": "closer to the camera than", "obj_2": "girl_2"}, "target_prompt": "A girl further from the camera than another girl in a room, demonstrating how to wink.", "target_property": {"obj_1": "girl_1", "relation": "further from the camera than", "obj_2": "girl_2"}, "evaluation_question": "Is the girl **closer to the camera than** the other girl?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl closer to the camera than another girl in a room, demonstrating how to wink. ?'))*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6ca75444e101459b8868ebb99c33ae7b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "aa5a2d761338450c8e5913bb1fda8a48", "source": "vatex", "video_id": "ddvn5kqT9MU_000007_000017", "video_description": "A woman is using a sewing machine to sew a large black item with wires, possibly solar power cells, onto an orange background. The material is soft, and music plays in the background.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than an orange background.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "orange background"}, "target_prompt": "A person closer to the camera than an orange background.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "orange background"}, "evaluation_question": "Is the person **farther from the camera than** the orange background?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than an orange background. RLJ>)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/985be30a3d18401997b1567eadbe3941.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "e02e10d685d24a8d8d5eb3684e9053b4", "source": "vatex", "video_id": "B6wOVvo6DjY_000000_000010", "video_description": "A baby and a man are having a cake-eating contest in a kitchen, with the mother recording the event.", "task": "SpatialUnderstanding", "clean_prompt": "A baby farther from the camera than a cake in a kitchen.", "clean_property": {"obj_1": "baby", "relation": "farther from the camera than", "obj_2": "cake"}, "target_prompt": "A baby closer to the camera than a cake in a kitchen.", "target_property": {"obj_1": "baby", "relation": "closer to the camera than", "obj_2": "cake"}, "evaluation_question": "Is the baby **farther from the camera than** the cake?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A baby farther from the camera than a cake in a kitchen. FEYSS", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d0dd0667e1c243729df11d92875e7d2a.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0cdbd792803c475d825fee70f5318f19", "source": "vatex", "video_id": "9iMoFY54i68_000058_000068", "video_description": "Children are playing and jumping on a large trampoline in a backyard on a sunny day.", "task": "Counting", "clean_prompt": "Six children are playing and jumping on a large trampoline in a backyard on a sunny day.", "clean_property": {"obj": "child", "count": "six"}, "target_prompt": "Two children are playing and jumping on a small trampoline in a shaded area.", "target_property": {"obj": "child", "count": "two"}, "evaluation_question": "Are there exactly **six** children playing on the trampoline?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Six children are playing and jumping on a large trampoline in a backyard on a sunny day. FE(E)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/35de3602454a4dd783a75b12eb0f780e.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4e2fc60472f441acbfb716e80d55e341", "source": "vatex", "video_id": "i3notciKv3w_000240_000250", "video_description": "A woman and a child are roasting marshmallows over a gas stove. The woman is melting marshmallows while the child watches and participates by sticking marshmallows onto a metal stick and melting them under the flame.", "task": "Counting", "clean_prompt": "Two women roasting marshmallows over a gas stove.", "clean_property": {"obj": "woman", "count": "two"}, "target_prompt": "One woman roasting marshmallows over a gas stove.", "target_property": {"obj": "woman", "count": "one"}, "evaluation_question": "Are there exactly **two** women roasting marshmallows over the gas stove?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two women roasting marshmallows over a gas stove. \u00b7))!0", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/29b317477158491a99fd8bc6fd654f03.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "08123bdf78324b49ada3ce68b69fd71e", "source": "vatex", "video_id": "FZx-h2nfHnY_000255_000265", "video_description": "A woman with short hair and large glasses demonstrates how to peel a sticker and apply a patch to a bicycle tire, including the inner tube, while wearing a blue shirt.", "task": "ObjectRecognition", "clean_prompt": "A woman with short hair and large glasses demonstrates how to peel a sticker and apply a patch to a bicycle tire while wearing a blue shirt.", "clean_property": {"obj": "bicycle"}, "target_prompt": "A woman with short hair and large glasses demonstrates how to peel a sticker and apply a patch to a motorcycle tire while wearing a blue shirt.", "target_property": {"obj": "motorcycle"}, "evaluation_question": "Is the object being patched in the video a **bicycle**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman with short hair and large glasses demonstrates how to peel a sticker and apply a patch to a bicycle tire while wearing a blue shirt. .Q=SL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3bb869516b6d45c6a93bd3af392787db.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "cb002b51ea3147bdaec0a5af883c52cb", "source": "vatex", "video_id": "IqaFjJZQVFM_000219_000229", "video_description": "A group of boys are outside on a neighborhood street, discussing and then smashing an old red phone with a hammer.", "task": "AttributeRecognition", "clean_prompt": "A group of boys outside on a neighborhood street discussing and then smashing an old red phone with a hammer.", "clean_property": {"obj": "phone", "attribute": "red"}, "target_prompt": "A group of boys outside on a neighborhood street discussing and then smashing an old blue phone with a hammer.", "target_property": {"obj": "phone", "attribute": "blue"}, "evaluation_question": "Is the phone being smashed **red**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of boys outside on a neighborhood street discussing and then smashing an old red phone with a hammer. *=-LF", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49288a0826bf49f2a7a38c7665b7001a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "caadcc54e26f48858f01cf8c3e4fbdc2", "source": "vatex", "video_id": "yOLcO75Mc98_000026_000036", "video_description": "A woman is in a kitchen demonstrating how to make chocolate chip cookies by mixing ingredients and baking them.", "task": "Counting", "clean_prompt": "Three people in a kitchen demonstrating how to make chocolate chip cookies by mixing ingredients and baking them.", "clean_property": {"obj": "person", "count": "three"}, "target_prompt": "One person in a kitchen demonstrating how to make chocolate chip cookies by mixing ingredients and baking them.", "target_property": {"obj": "person", "count": "one"}, "evaluation_question": "Are there exactly **three** people in the kitchen?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three people in a kitchen demonstrating how to make chocolate chip cookies by mixing ingredients and baking them. W%((3", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/ed16f68ecdd145f1bc1e33776aba8b66.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c9a09fed172842e28ad0f8b9719e869a", "source": "vatex", "video_id": "jLA7aHeb134_000041_000051", "video_description": "Two children, a girl and a boy, are having a pillow fight in a room, possibly a living room or bedroom.", "task": "Counting", "clean_prompt": "Three girls having a pillow fight in a living room.", "clean_property": {"obj": "girl", "count": "three"}, "target_prompt": "One girl having a pillow fight in a living room.", "target_property": {"obj": "girl", "count": "one"}, "evaluation_question": "Are there exactly **three** girls having a pillow fight?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Three girls having a pillow fight in a living room. 1!X3&", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f4ea933dd73745e288119e91aeba294a.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "808461992b96400f96ac981bbf844ce6", "source": "vatex", "video_id": "8PooUyGdc20_000006_000016", "video_description": "A person is using a razor blade to cut and tear off very long fingernails.", "task": "AttributeRecognition", "clean_prompt": "A person with very long fingernails is using a razor blade to cut and tear off their nails.", "clean_property": {"obj": "person", "attribute": "with very long fingernails"}, "target_prompt": "A person with very short fingernails is using a razor blade to cut and tear off their nails.", "target_property": {"obj": "person", "attribute": "with very short fingernails"}, "evaluation_question": "Does the person have **very long** fingernails?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person with very long fingernails is using a razor blade to cut and tear off their nails. N&|%/", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/6e2ce38d10e24909be4784f94bad0289.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "86d88a9c801e49f0a04e46ba4d57368f", "source": "vatex", "video_id": "3vH5mnAy98Y_000016_000026", "video_description": "A man is juggling illuminated balls of various colors, including red and green, in the middle of a street at night.", "task": "SpatialUnderstanding", "clean_prompt": "A juggler farther from the camera than a ball, juggling illuminated balls of various colors in the middle of a street at night.", "clean_property": {"obj_1": "juggler", "relation": "farther from the camera than", "obj_2": "ball"}, "target_prompt": "A juggler closer to the camera than a ball, juggling illuminated balls of various colors in the middle of a street at night.", "target_property": {"obj_1": "juggler", "relation": "closer to the camera than", "obj_2": "ball"}, "evaluation_question": "Is the juggler farther from the camera than the ball?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A juggler farther from the camera than a ball, juggling illuminated balls of various colors in the middle of a street at night. EETP%", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/67956926ca934625909415a818588be2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "ec29b53f4e444f9ca1842de65e21aed2", "source": "vatex", "video_id": "Vo1Ezk5nSXc_000231_000241", "video_description": "A man is in an auto shop demonstrating how to pour motor oil into a car engine using a funnel and then replace the oil cap.", "task": "AttributeRecognition", "clean_prompt": "A person who is a mechanic pouring motor oil into a car engine using a funnel.", "clean_property": {"obj": "person", "attribute": "mechanic"}, "target_prompt": "A person who is a chef pouring oil into a frying pan.", "target_property": {"obj": "person", "attribute": "chef"}, "evaluation_question": "Is the person a **mechanic**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person who is a mechanic pouring motor oil into a car engine using a funnel. =BSTL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e2206c6b29d7440580466b8005e7819d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "df75e02bd16044eb8dbe5d3777fafa73", "source": "vatex", "video_id": "nZt6VHJ73Ls_000010_000020", "video_description": "A group of children and teenagers are riding sleds down a snowy hill, taking turns and expressing excitement.", "task": "ObjectRecognition", "clean_prompt": "A group of children and teenagers are riding sleds down a snowy hill, taking turns and expressing excitement.", "clean_property": {"obj": "sled"}, "target_prompt": "A group of children and teenagers are riding surfboards on a sunny beach, taking turns and expressing excitement.", "target_property": {"obj": "surfboard"}, "evaluation_question": "Are the children riding **sleds** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A group of children and teenagers are riding sleds down a snowy hill, taking turns and expressing excitement. LFE7I", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/11b778c6792d446f8e99793e1cbbc2bb.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b5aeec41adcc49d9a45ebafd3b69d94a", "source": "vatex", "video_id": "qWdw_6eIPAQ_000035_000045", "video_description": "In a martial arts studio, a group of children and a few adults are practicing board breaking techniques. A sports reporter comments on the activities while an instructor provides guidance.", "task": "SpatialUnderstanding", "clean_prompt": "An instructor farther from the camera than the board in a martial arts studio.", "clean_property": {"obj_1": "instructor", "relation": "farther from the camera than", "obj_2": "board"}, "target_prompt": "An instructor closer to the camera than the board in a martial arts studio.", "target_property": {"obj_1": "instructor", "relation": "closer to the camera than", "obj_2": "board"}, "evaluation_question": "Is the instructor **farther from the camera than** the board?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "An instructor farther from the camera than the board in a martial arts studio. )'B%B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/f8a2595f702344b582fcfeedee0f32b0.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "b38c66d845b9427ab3a196893c616b5d", "source": "vatex", "video_id": "Ua7qoMG0aBU_000504_000514", "video_description": "A boy is fishing in a muddy swamp, catching and cleaning fish using a net and stringer.", "task": "SpatialUnderstanding", "clean_prompt": "A stringer farther from the camera than a fish in a muddy swamp.", "clean_property": {"obj_1": "stringer", "relation": "farther from the camera than", "obj_2": "fish"}, "target_prompt": "A stringer closer to the camera than a fish in a muddy swamp.", "target_property": {"obj_1": "stringer", "relation": "closer to the camera than", "obj_2": "fish"}, "evaluation_question": "Is the stringer **farther from the camera than** the fish?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A stringer farther from the camera than a fish in a muddy swamp. ,2BC$", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/81a3ba920b78408ea04ab6a8f2e6281e.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "36b9a39dc0894d0d903cf7acf17cf9fa", "source": "vatex", "video_id": "o2Qng5w4bUU_000000_000010", "video_description": "A group of men are playing dominoes and chatting around a table outside on a nice day.", "task": "Counting", "clean_prompt": "Seven men are playing dominoes and chatting around a table outside on a nice day.", "clean_property": {"obj": "table", "count": "seven"}, "target_prompt": "Three men are playing dominoes and chatting around a table outside on a nice day.", "target_property": {"obj": "table", "count": "three"}, "evaluation_question": "Are there exactly **seven** men around the table?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Seven men are playing dominoes and chatting around a table outside on a nice day. P)FEA", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/e97c4b01a14846d180598738ab30802d.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d64d7791e0dd4202951515874ab3e5bc", "source": "vatex", "video_id": "UPYWbockBsU_000251_000261", "video_description": "A medical professional is applying bandages to a patient's lower back while the patient sits quietly on a bed or cushion.", "task": "AttributeRecognition", "clean_prompt": "A medical professional gloved applying bandages to a patient's lower back.", "clean_property": {"obj": "medical professional", "attribute": "gloved"}, "target_prompt": "A medical professional barehanded applying bandages to a patient's lower back.", "target_property": {"obj": "medical professional", "attribute": "barehanded"}, "evaluation_question": "Is the medical professional **gloved** while applying bandages?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A medical professional gloved applying bandages to a patient's lower back. KMV%@", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/94e840866c2147c78d038561d05bbcd2.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6a27af02bd0d4ea2aab75ff5ded59b56", "source": "vatex", "video_id": "YblpmT2EQDo_000168_000178", "video_description": "An elderly man is sitting on a wooden chair in a kitchen, playing a tune on an accordion.", "task": "ActionRecognition", "clean_prompt": "A person playing accordion in a kitchen.", "clean_property": {"obj": "person", "action": "playing accordion", "target": null}, "target_prompt": "A person playing guitar in a kitchen.", "target_property": {"obj": "person", "action": "playing guitar", "target": null}, "evaluation_question": "Is the person **playing accordion**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person playing accordion in a kitchen. FEYJ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9f845ba9ae7a44aca65cd5d935e0a688.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "6f408ac00c3841daa52b94933fd22c8f", "source": "vatex", "video_id": "702CL3eTNzg_000000_000010", "video_description": "A tattoo artist is applying a tattoo on a man's abdomen while a television plays in the background.", "task": "ActionRecognition", "clean_prompt": "A tattoo artist getting a tattoo on a man's abdomen.", "clean_property": {"obj": "tattoo artist", "action": "getting a tattoo", "target": "man"}, "target_prompt": "A tattoo artist removing a tattoo from a woman's arm.", "target_property": {"obj": "tattoo artist", "action": "removing a tattoo", "target": "woman"}, "evaluation_question": "Is the tattoo artist **getting a tattoo** on a man?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A tattoo artist getting a tattoo on a man's abdomen. ''.:-", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0de04b37ac1a4edab4e4d362f4101d1b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "69dbc5b877de4e8183875098f214cfb6", "source": "vatex", "video_id": "xCmwLTWlPtY_000003_000013", "video_description": "Four girls are in a bedroom eating chips, some sitting on the floor and others on the bed, while looking at the camera.", "task": "ActionRecognition", "clean_prompt": "A girl eating chips in a bedroom.", "clean_property": {"obj": "girl", "action": "eating chips", "target": null}, "target_prompt": "A girl playing video games in a bedroom.", "target_property": {"obj": "girl", "action": "playing video games", "target": null}, "evaluation_question": "Is the girl **eating chips**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A girl eating chips in a bedroom. ;D,MV", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/824d69942208435d8f7d2bfad815365d.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "d337b71c5af0434682e0aa96012e37c8", "source": "vatex", "video_id": "Pd4-fmq61kw_000014_000024", "video_description": "A boy is seated on a couch, tearing pages from a composition notebook.", "task": "SpatialUnderstanding", "clean_prompt": "A composition notebook to the right of a boy seated on a couch.", "clean_property": {"obj_1": "composition notebook", "relation": "right of", "obj_2": "boy"}, "target_prompt": "A composition notebook to the left of a boy seated on a couch.", "target_property": {"obj_1": "composition notebook", "relation": "left of", "obj_2": "boy"}, "evaluation_question": "Is the composition notebook to the **right** of the boy?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A composition notebook to the right of a boy seated on a couch. PD0O(", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/2fd1c00b30fa40bb976dd5a72de3e5d0.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f487c2ab8d554ac5a207a7bd2029c33f", "source": "vatex", "video_id": "YBigBq8OlIE_000012_000022", "video_description": "A man is being pulled by a boat while laying on a surfboard, holding onto a rope, and then lets go of the rope.", "task": "ObjectRecognition", "clean_prompt": "A man is being pulled by a boat while laying on a surfboard, holding onto a rope.", "clean_property": {"obj": "rope"}, "target_prompt": "A man is being pulled by a boat while laying on a surfboard, holding onto a kite.", "target_property": {"obj": "kite"}, "evaluation_question": "Is the man holding onto a **rope**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is being pulled by a boat while laying on a surfboard, holding onto a rope. !2J0B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/5dba7f5e2ecf4bb8b6bb913e97ceebed.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "a8015fc7b936402e8a44149cd6da4660", "source": "vatex", "video_id": "B5K_x2cDYfM_000026_000036", "video_description": "A woman wearing headphones and a cocktail dress plays the clarinet in front of a changing background, including a sky with moving clouds.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a clarinet.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "clarinet"}, "target_prompt": "A person closer to the camera than a clarinet.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "clarinet"}, "evaluation_question": "Is the person **farther from the camera than** the clarinet?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a clarinet. RL", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/49d873711ee84d8a8362cc6dd9e664d9.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "2219377ef1c34ed4a5e8f107ec3bb240", "source": "vatex", "video_id": "wduiTN5eP9g_000032_000042", "video_description": "A man is balancing and walking on a tightrope while juggling three flaming sticks in front of a cheering crowd.", "task": "AttributeRecognition", "clean_prompt": "A man is balancing and walking on a tightrope while juggling three flaming sticks that are lit in front of a cheering crowd.", "clean_property": {"obj": "flaming stick", "attribute": "lit"}, "target_prompt": "A man is balancing and walking on a tightrope while juggling three flaming sticks that are extinguished in front of a cheering crowd.", "target_property": {"obj": "flaming stick", "attribute": "extinguished"}, "evaluation_question": "Are the flaming sticks **lit**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man is balancing and walking on a tightrope while juggling three flaming sticks that are lit in front of a cheering crowd. ))'W*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/bfdb66ed9a1547f2815f901cb8d721c4.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "eb1681ce7c0b4b93b644df1662786233", "source": "vatex", "video_id": "DNdZBDJL09E_000004_000014", "video_description": "A man wearing a breathing mask uses a sledgehammer to demolish a bathroom sink.", "task": "AttributeRecognition", "clean_prompt": "A person wearing a breathing mask using a sledgehammer to demolish a bathroom sink.", "clean_property": {"obj": "person", "attribute": "wearing breathing mask"}, "target_prompt": "A person using a sledgehammer to demolish a bathroom sink.", "target_property": {"obj": "person", "attribute": "wearing no mask"}, "evaluation_question": "Is the person wearing a **breathing** mask?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person wearing a breathing mask using a sledgehammer to demolish a bathroom sink. ERTEQ", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/3d96136e44534f879a3e6870642a6f39.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "35de5ce7d01e43f8a63b1356cf5bc3d5", "source": "vatex", "video_id": "NvWa1-YwfaY_000042_000052", "video_description": "Two men are at a stream in Texas, taking samples and possibly panning for gold. They are in a forested area near a river bank, using tools and a machine.", "task": "ObjectRecognition", "clean_prompt": "Two men are at a river in Texas, taking samples and possibly panning for gold.", "clean_property": {"obj": "river"}, "target_prompt": "Two men are at an ocean in Texas, taking samples and possibly panning for gold.", "target_property": {"obj": "ocean"}, "evaluation_question": "Are the men at a **river** in the video?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "Two men are at a river in Texas, taking samples and possibly panning for gold. ;E?@O", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/865bce49065840448146288d112ab583.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "100bfc9e93834df1a286b72e0c87aab3", "source": "vatex", "video_id": "Z0WYFjwIpwU_000000_000010", "video_description": "A woman is applying and removing wax strips to a man's leg for hair removal while they talk.", "task": "SpatialUnderstanding", "clean_prompt": "A man sitting to the left of a woman while she applies wax strips to his leg.", "clean_property": {"obj_1": "man", "relation": "left of", "obj_2": "woman"}, "target_prompt": "A man sitting to the right of a woman while she applies wax strips to his leg.", "target_property": {"obj_1": "man", "relation": "right of", "obj_2": "woman"}, "evaluation_question": "Is the man sitting to the **left** of the woman?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man sitting to the left of a woman while she applies wax strips to his leg. !0D\u00b7)", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/847025db09c043da8e6ba59dd4052a3b.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "fa8ed143fefe4b83bd7b4c65ca5f66b4", "source": "vatex", "video_id": "uk0GF4oBtZ8_000036_000046", "video_description": "A woman is demonstrating how to clip fingernails, counting each nail as she clips, in a therapy-like setting.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to clip fingernails using a nail clipper in a therapy-like setting.", "clean_property": {"obj": "nail clipper"}, "target_prompt": "A woman demonstrating how to cut fingernails using scissors in a therapy-like setting.", "target_property": {"obj": "scissors"}, "evaluation_question": "Is the woman using a **nail clipper** to clip her fingernails?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to clip fingernails using a nail clipper in a therapy-like setting. ))'!*", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/634f834dfcbc4dba805c0bcb1d15a908.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "acc3de0bb4124e4094a8fa8e6b8c4ee2", "source": "vatex", "video_id": "7N6ionlMMZw_000025_000035", "video_description": "A woman demonstrates how to sew a zigzag pattern and fix a garment using a sewing machine on a piece of fabric.", "task": "ObjectRecognition", "clean_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine.", "clean_property": {"obj": "person"}, "target_prompt": "A robot demonstrating how to sew a zigzag pattern on a sewing machine.", "target_property": {"obj": "robot"}, "evaluation_question": "Is the person in the video a **woman**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman demonstrating how to sew a zigzag pattern on a sewing machine. >FO7G", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/9321942c6fd642dc9d01fca17a7c6214.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "9f6188bd27ee43cda945507cee6bafb4", "source": "vatex", "video_id": "h4T6K47kxv4_000000_000010", "video_description": "A young man wearing a fuzzy hat with ears plays a tune on a six-hole ocarina while seated.", "task": "ObjectRecognition", "clean_prompt": "A young man wearing a fuzzy hat with ears plays a tune on a six-hole ocarina while seated.", "clean_property": {"obj": "person"}, "target_prompt": "A cat playing with a six-hole ocarina while seated.", "target_property": {"obj": "cat"}, "evaluation_question": "Is the character in the video a **person**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A young man wearing a fuzzy hat with ears plays a tune on a six-hole ocarina while seated. >FE,|", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/d7d8a1746083406fa5248f4d0572855f.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "c3ee0cd0cb754a91a6401a7bbc1eab21", "source": "vatex", "video_id": "jODN7qCOn1U_000004_000014", "video_description": "Multiple people are working on cleaning and smoothing a wooden floor using various tools such as a steam machine, vacuum, and electric sander.", "task": "ActionRecognition", "clean_prompt": "A person sanding a wooden floor.", "clean_property": {"obj": "person", "action": "sanding floor", "target": null}, "target_prompt": "A person vacuuming a wooden floor.", "target_property": {"obj": "person", "action": "vacuuming floor", "target": null}, "evaluation_question": "Is the person **sanding** the floor?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person sanding a wooden floor. )))*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/111a7208599f447a80fc767c07a96d49.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f258c0b9533045a5add214ab0d3b3f3f", "source": "vatex", "video_id": "meL-J5bKds8_000106_000116", "video_description": "A man in a suit, who is a magician, demonstrates how to create various shapes and tricks using twisty balloons in a room.", "task": "AttributeRecognition", "clean_prompt": "A magician in a suit demonstrating tricks with a twisty balloon.", "clean_property": {"obj": "balloon", "attribute": "twisty"}, "target_prompt": "A magician in a suit demonstrating tricks with a round balloon.", "target_property": {"obj": "balloon", "attribute": "round"}, "evaluation_question": "Is the magician demonstrating tricks with a **twisty** balloon?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A magician in a suit demonstrating tricks with a twisty balloon. !DP/V", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/c4df1b48752648c687c05509d98dc516.mp4", "clean_score": 1.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "be1589b8ef52419d8501c3ae1f4b38a3", "source": "vatex", "video_id": "9AeWKJVrXLo_000000_000010", "video_description": "A man in a black suit is conducting an auction at a real estate seminar, speaking into a microphone while another man operates slides on stage. The event takes place in front of an audience, with information displayed on a screen beside the speaker.", "task": "ActionRecognition", "clean_prompt": "A man auctioning at a real estate seminar.", "clean_property": {"obj": "man", "action": "auctioning", "target": null}, "target_prompt": "A man bidding at a real estate seminar.", "target_property": {"obj": "man", "action": "bidding", "target": null}, "evaluation_question": "Is the man **auctioning**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man auctioning at a real estate seminar. R)*'4", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/7d9984784eea494cbc9f532f931f5077.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "870d4e6312454634b7945f47cb7fd1dd", "source": "vatex", "video_id": "QAgcSr8Khus_000012_000022", "video_description": "A man wearing a winter coat takes out garbage bags to the trash bins on a snowy day and pets a cat.", "task": "Counting", "clean_prompt": "A man wearing a winter coat takes out three garbage bags to the trash bins on a snowy day and pets a cat.", "clean_property": {"obj": "trash bin", "count": "three"}, "target_prompt": "A man wearing a winter coat takes out one garbage bag to the trash bin on a snowy day and pets a cat.", "target_property": {"obj": "trash bin", "count": "one"}, "evaluation_question": "Are there exactly **three** trash bins in the scene?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man wearing a winter coat takes out three garbage bags to the trash bins on a snowy day and pets a cat. !G*9B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/51b114b747d5439bae47d56e8de3dce2.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "917cda9f2f2d463c824610af6fe4ecd7", "source": "vatex", "video_id": "JkIUS-CIVEY_000002_000012", "video_description": "A woman is performing a lower body exercise in a gym, using dumbbells and a bench for support.", "task": "SpatialUnderstanding", "clean_prompt": "A person farther from the camera than a bench in a gym.", "clean_property": {"obj_1": "person", "relation": "farther from the camera than", "obj_2": "bench"}, "target_prompt": "A person closer to the camera than a bench in a gym.", "target_property": {"obj_1": "person", "relation": "closer to the camera than", "obj_2": "bench"}, "evaluation_question": "Is the person **farther from the camera than** the bench?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person farther from the camera than a bench in a gym. )?G*B", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/64ba7972ce344f239155f88d1752807b.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "0825e6e91b204c2eb9b121d117247ed7", "source": "vatex", "video_id": "dfo3WR33AcY_000407_000417", "video_description": "A man is applying polish to a boot and using a heat gun to cure and shine the material.", "task": "ObjectRecognition", "clean_prompt": "A man applying polish to a boot using a heat gun to cure and shine the material.", "clean_property": {"obj": "heat gun"}, "target_prompt": "A man applying polish to a boot using a blow dryer to cure and shine the material.", "target_property": {"obj": "blow dryer"}, "evaluation_question": "Is the tool used by the man a **heat gun**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A man applying polish to a boot using a heat gun to cure and shine the material. )FE;K", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/98900c61c41043fcb01d03407836bd52.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "f1ab0b5e2f2748bdb1abc346b01b37db", "source": "vatex", "video_id": "1HPBOjRFnyo_000004_000014", "video_description": "Two people are parasailing in the ocean, being pulled by a boat with a colorful parachute.", "task": "SpatialUnderstanding", "clean_prompt": "A person standing to the left of a parachute.", "clean_property": {"obj_1": "person", "relation": "left of", "obj_2": "parachute"}, "target_prompt": "A person standing to the right of a parachute.", "target_property": {"obj_1": "person", "relation": "right of", "obj_2": "parachute"}, "evaluation_question": "Is the person to the **left** of the parachute?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A person standing to the left of a parachute. @JS$+", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/084a6ee761824add8a1d2ec9b2419fca.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
{"id": "4a0ed619244a46aeb98062c4bb04cacf", "source": "vatex", "video_id": "UEir8hX3aJA_000000_000010", "video_description": "A woman is in a gym performing exercises with battle ropes, including squats and side lunges, demonstrating the oscillating wave principle.", "task": "ObjectRecognition", "clean_prompt": "A woman in a gym performing exercises with battle ropes, including squats and side lunges, demonstrating the oscillating wave principle with a machine.", "clean_property": {"obj": "machine"}, "target_prompt": "A woman in a gym performing exercises with a ball, including squats and side lunges, demonstrating the oscillating wave principle.", "target_property": {"obj": "ball"}, "evaluation_question": "Is the object being used in the video a **machine**?", "surrogate_model": "CogVideoX-2b", "attack": "greedy", "adversarial_prompt": "A woman in a gym performing exercises with battle ropes, including squats and side lunges, demonstrating the oscillating wave principle with a machine. \u00b7HGFE", "eval_results": {"CogVideoX-2b": {"clean_vid_id": "vids/0b53eac6a4e5406280cc6627e9a305c8.mp4", "clean_score": 0.0, "clean_xclip": null, "clean_vbench": {}, "adv_vid_id": null, "adv_score": null, "adv_xclip": null, "adv_vbench": {}}}}
