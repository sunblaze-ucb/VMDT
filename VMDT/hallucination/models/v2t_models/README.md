# INSTALL

Use the v2t.yml file to initialize a coda environment. Then each file contains a main that tests the correct execution of the code on a test video.

# Model list

- Qwen2-VL (open source): https://github.com/QwenLM/Qwen2-VL 

- LLaVA-Video (open source): https://huggingface.co/lmms-lab/LLaVA-Video-72B-Qwen2 

- DAMO-NLP-SG/VideoLLaMA2.1-7B-AV (open source): https://huggingface.co/DAMO-NLP-SG/VideoLLaMA2.1-7B-AV 

- InternVL2.5 (open source): https://internvl.github.io/blog/2024-12-05-InternVL-2.5/

- gpt-4o-2024-11-20 (closed source) + gpt-4o-audio-preview-2024-12-17 (for audio support) --> To run gpt4o.py code, please run the following

```bash
pip install opencv-python
pip install moviepy
```
